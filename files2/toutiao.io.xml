<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>eb8826f51d99aaf47901bcc14d1b24bc</guid>
<title>颠覆Kafka的统治，新一代云原生消息系统Pulsar震撼来袭！</title>
<link>https://toutiao.io/k/zfkdb6h</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;58&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/VY8SELNGe977Xa5zfy5iaV3agpS11Cqm4psjPOibic6BZSicnBFh6uWzCFp3uqN5R114Fq85DmuCzdL3eESlQ37bFA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;导语 |&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;在信息流场景，内容的请求处理、原子模块调度、结果的分发等至关重要，将会直接影响到内容的外显、推荐、排序等。基于消息100%成功的要求，我对Pulsar进行了调研，并采用Pulsar实现消息的可靠处理。本文主要参考Pulsar的官方文档和技术文章，对Pulsar的特性、机制、原理等进行整理总结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;一、Pulsar概述&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Apache Pulsar是Apache软件基金会顶级项目，是下一代云原生分布式消息流平台，集消息、存储、轻量化函数式计算为一体，采用计算与存储分离架构设计，支持多租户、持久化存储、多机房跨区域数据复制，具有强一致性、高吞吐、低延时及高可扩展性等流数据存储特性，被看作是云原生时代实时消息流传输、存储和计算最佳解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pulsar是一个pub-sub (发布-订阅)模型的消息队列系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（一）Pulsar架构&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pulsar由Producer、Consumer、多个Broker、一个BookKeeper集群、一个Zookeeper集群构成，具体如下图所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7926484448633365&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tIJyvGNPykyznciaZqGrINRDCUJl23Oja0SnfS0cqCL4tpL2FwxibsibDA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1061&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从Pulsar的架构图上可以看出，Pulsar在架构设计上采用了计算与存储分离的模式，发布/订阅相关的计算逻辑在Broker上完成，而数据的持久化存储交由BookKeeper去实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在Pulsar中Broker是无状态的，当需要支持更多的消费者或生产者时，可以简单地添加更多的Broker节点来满足业务需求。Pulsar支持自动的分区负载均衡，在Broker节点的资源使用率达到阈值时，会将负载迁移到负载较低的Broker节点，这个过程中分区也将在多个Broker节点中做平衡迁移，一些分区的所有权会转移到新的Broker节点。在后面&lt;/span&gt;&lt;span&gt;Bundle&lt;/span&gt;&lt;span&gt;小节会具体介绍这部分的实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;存储层的扩容，通过增加Bookie节点来实现。在BooKie扩容的阶段，由于分片机制，整个过程不会涉及到不必要的数据搬迁，即不需要将旧数据从现有存储节点重新复制到新存储节点。在后续的Bookkeeper小节中会具体介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（二）Topic&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;和其他消息队列类似，Pulsar中也有Topic。Topic即在生产者与消费者中传输消息的通道。消息可以以Topic为单位进行归类，生产者负责将消息发送到特定的Topic，而消费者指定特定的Topic进行消费。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pulsar的Topic可以分为非分区Topic和分区Topic。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;普通的Topic仅仅被保存在单个Broker中，这限制了Topic的最大吞吐量。分区Topic是一种特殊类型的主题，支持被多个Broker处理，从而实现更高的吞吐量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对一个Topic，可以设置多个Topic分区来提高Topic的吞吐量。每个Topic Partition由Pulsar分配给某个Broker，该Broker称为该Topic Partition的所有者。生成者和消费者会与每个Topic分区的Broker创建链接，发送消息并消费消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图所示，Topic1有Partition1、Partition2、Partition3、Partition4、Partition5五个分区，Partition1和Partition4由Broker1处理，Partition2和Partition5由Broker2处理，Partition3由Broker3处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.59763851044505&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tW98ruT6IYVq0NXMrsmn8g9Axz9BMljwXexSgqVIaJsQQGWcy4pDcwg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1101&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从Pulsar社区版的golang-sdk可以看出，客户端的Producer和Consumer在初始化的时候，都会与每一个Topic-Partition创建链接，并且会监听是否有新的Partition，以创建新的链接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;默认情况下，Pulsar会保存所有没确认的消息到BookKeeper中。持久Topic的消息在Broker重启或者Consumer出现问题时保存下来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了持久Topic，Pulsar也支持非持久Topic。这些Topic的消息只存在于内存中，不会存储到磁盘。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为Broker不会对消息进行持久化存储，当Producer将消息发送到Broker时，Broker可以立即将ack返回给Producer，所以非持久Topic的消息传递会比持久Topic的消息传递更快一些。相对的，当Broker因为一些原因宕机、重启后，非持久Topic的消息都会消失，订阅者将无法收到这些消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于业务逻辑处理出现异常，消息一般需要被重新消费。Pulsar支持生产者同时将消息发送到普通的Topic和重试Topic，并指定允许延时和最大重试次数。当配置了允许消费者自动重试时，如果消息没有被消费成功，会被保存到重试Topic中，并在指定延时时间后，重新被消费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当Consumer消费消息出错时，可以通过配置重试Topic对消息进行重试，但是，如果当消息超过了最大的重试次数仍处理失败时，该怎么办呢？Pulsar提供了死信Topic，通过配置deadLetterTopic，当消息达到最大重试次数的时候，Pulsar会将消息推送到死信Topic中进行保存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（三）订阅（subscription）&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过订阅的方式，我们可以指定消息如何投递给消费者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pulsar支持独占（Exclusive）、灾备（Failover）、共享（Shared）、Key_Shared这四种订阅类型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;独占（Exclusive）SinglePartition&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Exclusive下，只允许Subscription存在一个消费者，如果多个消费者使用同一个订阅名称去订阅同一个Topic，则会报错。如下图，只有Consumer A-0可以消费数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.3453125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tsoCy45Z8JXswMP7BeGAO501qJmoE7xXd5rQgFw8CudmxxWeVgia8bdg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;灾备（Failover）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Failover下，一个Subscription中可以有多个消费者，但只有Master Consumer可以消费数据。当Master Consumer断开连接时，消息会由下一个被选中的Consumer进行消费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图，Consumer-B-0是Master Consumer。当Consumer-B-0发生问题与Broker断开连接时，Consumer-B-1将成为下一个Master Consumer来消费数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.38046875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4t99qbTqeoAe4iaRuldV14HAKbRic2ibiaFPQrUccbxyj5XNq5U06ftzHU2A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;共享（Shared）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;shared中，多个消费者可以绑定到同一个Subscription上。消息通过 round robin即轮询机制分发给不同的消费者，并且每个消息仅会被分发给一个消费者。当消费者断开连接，所有被发送给消费者但没有被确认的消息将被重新处理，分发给其它存活的消费者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图, Consumer-C-1、Consumer-C-2、Consumer-C-3都可以订阅 Topic消费数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4171875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tKk3QUCzdIpzhUpBJppQcuib3jibPSTqGlm6uc9urxdDnkiaup4ES3woYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Key_Shared&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Key_Shared中，多个Consumer可以绑定到同一个Subscription。消息在传递给Consumer时，具有相同键的消息只会传递给同一个Consumer。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4328125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tUBcCwoIMhlAg9m13FgFdSD69P6eVqibQceHDbO9s3kkAIJ6HNWb7ibqw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;订阅模式有持久化和非持久化两种。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;订阅模式取决于游标(cursor)的类型&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创建订阅时，将创建一个相关的游标来记录最后使用的位置。当订阅的consumer重新启动时，它可以从它所消费的最后一条消息继续消费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个订阅可以有一个或多个消费者。当使用者订阅主题时，它必须指定订阅名称。持久订阅和非持久订阅可以具有相同的名称，它们彼此独立。如果使用者指定了以前不存在的订阅，则会自动创建订阅。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;默认情况下，没有任何持久订阅的Topic的消息将被标记为已删除。如果要防止消息被标记为已删除，可以为此Topic创建持久订阅。在这种情况下，只有被确认的消息才会被标记为已删除。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当Consumer订阅Topic时，默认指定订阅一个主题。从Pulsar的1.23.0-incubating的版本开始，Pulsar消费者可以同时订阅多个Topic。可以通过两种方式进行订阅：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;二、Pulsar生产者（Producer）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;Producer是连接topic的程序，它将消息发布到一个Pulsar &lt;/span&gt;&lt;span&gt;broker&lt;/span&gt;&lt;span&gt;上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（一）访问模式&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;消息生成者有多种模式访问Topic ，可以使用以下几种方式将消息发送到Topic。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（二）路由模式&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当将消息发送到分区Topic时，需要指定消息的路由模式，这决定了消息将会被发送到哪个分区Topic。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;Pulsar有以下三种消息路由模式，RoundRobinPartition为默认路由模式&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（三）批量处理&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pulsar支持对消息进行批量处理。批量处理启用后，Producer会在一次请求中累积并发送一批消息。批量处理时的消息数量取决于最大消息数（单次批量处理请求可以发送的最大消息数）和最大发布延迟（单个请求的最大发布延迟时间）决定。开启批量处理后，积压的数量是批量处理的请求总数，而不是消息总数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常情况下，只有Consumer确认了批量请求中的所有消息，这个批量请求才会被认定为已处理。当这批消息没有全部被确认的情况下，发生故障时，会导致一些已确认的消息被重复确认。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了避免Consumer重复消费已确认的消息，Pulsar从Pulsar 2.6.0开始采用批量索引确认机制。如果启用批量索引确认机制，Consumer将筛选出已被确认的批量索引，并将批量索引确认请求发送给Broker。Broker维护批量索引的确认状态并跟踪每批索引的确认状态，以避免向Consumer发送已确认的消息。当该批信息的所有索引都被确认后，该批信息将被删除。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;默认情况下，索引确认机制处于关闭状态。开启索引确认机制将产生导致更多内存开销。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;key_shared模式下，Broker会根据消息的key来分发消息，但默认的批量处理模式，无法保证将所有的相同的key都打包到同一批中，而且Consumer在接收到批数据时，会默认把第一个消息的key当作这批消息的key，这会导致消息的错乱。因此key_shared模式下，不支持默认的批量处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;key-based batching能够确保Producer在打包消息时，将相同key的消息打包到同一批中，从而consumer在消费的时候，也能够消费到指定key的批数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没有指定key的消息在打包成批后，这一批数据也是没有key的，Broker在分发这批消息时，会使用NON_KEY作为这批消息的key。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（四）消息分块&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;启用分块后，如果消息大小超过允许发送的最大消息大小时，Producer会将原始消息分割成多个分块消息，并将分块消息与消息的元数据按顺序发送到Broker。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在Broker中，分块消息会和普通消息以相同的方式存储在Ledger中。唯一的区别是，Consumer需要缓存分块消息，并在接收到所有的分块消息后将其合并成真正的消息。如果Producer不能及时发布消息的所有分块，Consumer不能在消息的过期时间内接收到所有的分块，那么Consumer已接收到的分块消息就会过期。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Consumer会将分块的消息拼接在一起，并将它们放入接收器队列中。客户端从接收器队列中消费消息。当Consumer消费到原始的大消息并确认后，Consumer就会发送与该大消息关联的所有分块消息的确认。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;处理一个producer和一个订阅consumer的分块消息&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图所示，当生产者向主题发送一批大的分块消息和普通的非分块消息时。假设生产者发送的消息为M1，M1有三个分块M1-C1，M1-C2和M1-C3。这个Broker在其管理的Ledger里面保存所有的三个块消息，然后以相同的顺序分发给消费者（独占/灾备模式）。消费者将在内存缓存所有的块消息，直到收到所有的消息块。将这些消息合并成为原始的消息M1，发送给处理进程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.2582025677603424&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tBPsgeiaPyhpIhicojsx8SyOcCD8xfatfrjNleGCyDg1JfQqjXdgUCc2Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;701&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当多个生产者发布块消息到单个主题，这个Broker在同一个Ledger里面保存来自不同生产者的所有块消息。如下所示，生产者1发布的消息M1，M1 由M1-C1，M1-C2和M1-C3三个块组成。生产者2发布的消息M2，M2由M2-C1，M2-C2和M2-C3三个块组成。这些特定消息的所有分块是顺序排列的，但是其在Ledger里面可能不是连续的。这种方式会给消费者带来一定的内存负担。因为消费者会为每个大消息在内存开辟一块缓冲区，以便将所有的块消息合并为原始的大消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4356005788712012&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4t9PJj02ibZFjiaxz4ZjsicG9GKJiaSoWAdyxW6J8qamMEWXHZjvZlbNicPDg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;691&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;三、Pulsar消费者（Consumer）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Consumer是通过订阅关系连接Topic，接收消息的程序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Consumer向Broker发送&lt;/span&gt;&lt;span&gt;flow permit request&lt;/span&gt;&lt;span&gt;以获取消息。在 Consumer端有一个队列，用于接收从Broker推送来的消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（一）消息确认&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pulsar提供两种确认模式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7797783933518005&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tlDfAib4K2icdjIKSo5CTYIUxOV5oh9uBPBtoHcewnDEnQJeouIfIGU4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;722&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图，上方为累积确认模式，当消费者发送M12的确认消息给Broker后，Broker会把M12之前的消息和M12一样都标记为已确认。下方为单条确认模式，当消费者发送M7的确认消息给Broker后，Broker会把M7这条消息标记为已确认。当消费者发送M12的确认消息给Broker后，Broker会把M12这条消息标记为已确认。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;需要注意的是，订阅模式中的shared模式是不支持累积确认的。因为该订阅模式下的每个消费者都能消费数据，无法保证单个消费者的消费消息的时序和顺序。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;AcknowledgmentsGroupingTracker&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;消息的单条确认和累积确认并不是直接发送确认请求给Broker，而是把请求转交给AcknowledgmentsGroupingTracker处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了保证消息确认的性能，并避免Broker接收到非常高并发的ack请求，Tracker默认支持批量确认，即使是单条消息的确认，也会先进入队列，然后再一批发往Broker。在创建consumer的时候，可以设置acknowledgementGroupTimeMicros，默认情况下，每100ms或者堆积超过1000时，AcknowledgmentsGroupingTracker会发送一批确认请求。如果设置为0，则每次确认消息后，Consumer都会立即发送确认请求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（二）取消确认&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当Consumer无法处理一条消息并想重新消费时，Consumer可以发送一个取消确认的消息给Broker，Broker会重新将这条消息发送给Consumer。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果启用了批量处理，那这一批中的所有消息都会重新发送给消费者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;消息取消确认也有单条取消模式和累积取消模式，取决于消费者使用的订阅模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在Exclusive模式和Failover订阅模式中，消费者仅仅只能对收到的最后一条消息进行取消确认。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在&lt;/span&gt;&lt;span&gt;Shared&lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt;Key_Shared&lt;/span&gt;&lt;span&gt;的订阅类型中，消费者可以单独否定确认消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果启用了批量处理，那这一批中的所有消息都会重新发送给消费者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;取消确认和其他消息确认一样，不会立即请求Broker，而是把请求转交NegativeAcksTracker进行处理。Tracker中记录着每条消息以及需要延迟的时间。Tracker默认是33ms左右一个时间刻度进行检查，默认延迟时间是1分钟，抽取出已经到期的消息并触发重新投递。Tracker存在的意义是为了合并请求。另外如果延迟时间还没到，消息会暂存在内存，如果业务侧有大量的消息需要延迟消费，还是建议使用reconsumeLater接口。NegativeAck唯一的好处是不需要每条消息都指定时间，可以全局设置延迟时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（三）redelivery backoff机制&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常情况下可以使用取消确认来达到处理消息失败后重新处理消息的目的，但通过redelivery backoff可以更好的实现这种目的。可以通过指定消息重试的次数、消息重发的延迟来重新消费处理失败的消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（四）确认超时&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了取消确认和redelivery backoff机制外，还可以通过开启自动重传递机制来处理未确认的消息。启用自动重传递后，client会在ackTimeout时间内跟踪未确认的消息，并在消息确认超时后自动向代理重新发送未确认的消息请求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（五&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;）消息预拉取&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Consumer客户端SDK会默认预先拉取消息到Consumer本地，Broker侧会把这些已经推送到Consumer本地的消息记录为pendingAck，这些消息既不会再投递给别的消费者，也不会ack超时，除非当前Consumer被关闭，消息才会被重新投递。Broker侧有一个RedeliveryTracker接口，这个Tracker会记录消息到底被重新投递了多少次，每条消息推送给消费者时，会先从Tracker的哈希表中查询一下重投递的次数，和消息一并推送给消费者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（六）未确认的消息处理&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果消息被消费者消费后一直没有确认怎么办？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;unAckedMessageTracker中维护了一个时间轮，时间轮的刻度根据ackTimeout、tickDurationInMs这两个参数生成，每个刻度时间=ackTimeout/tickDurationInMs。新追踪的消息会放入最后一个刻度，每次调度都会移除队列头第一个刻度，并新增一个刻度放入队列尾，保证刻度总数不变。每次调度，队列头刻度里的消息将会被清理，unAckedMessageTracker会自动把这些消息做重投递。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;重投递就是客户端发送一个redeliverUnacknowledgedMessages命令给Broker。每一条推送给消费者但是未ack的消息，在Broker侧都会有一个集合来记录（pengdingAck），这是用来避免重复投递的。触发重投递后，Broker会把对应的消息从这个集合里移除，然后这些消息就可以再次被消费了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;四、Pulsar服务端 &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;Broker是Pulsar的一个无状态组件，主要负责运行以下两个组件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（一）消息确认与留存&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pulsar Broker会默认删除已经被所有Consumer确认的消息，并以backlog的方式持久化存储所有未被确认的内消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pulsar的message retention(消息留存) 和message expiry (消息过期)这两个特性可以调整Broker的默认设置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过留存规则的设定，可以保证已经被确认且符合留存规则的消息持久地保存在Pulsar中，而没有被留存规则覆盖、已经被确认的消息会被删除。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.234375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4ticdicibWUdu4KttxZBw6eKcV4YOUMOZR3DnZaLepNcBHkwBhtBibnkFrhg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过设置消息的TTL，有些即使还没有被确认，但已经超过TTL的消息，也会被删除。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.259375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tocAmwUWLBKoiaWvVibzdPdP13TK6Npemgv4PcGntiaRs21o4NaPevM1lw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（二）消息去重&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实现消息去重的一种方式是确保消息仅生成一次，即生产者幂等。这种方式的缺点是把消息去重的工作交由应用去做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在Pulsar中，Broker支持配置开启消息去重，用户不需要为了消息去重去调整Producer的代码。启用消息去重后，即使一条消息被多次发送到Topic上，这条消息也只会被持久化到磁盘一次。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图，未开启消息去重时，Producer发送消息1到Topic后，Broker会把消息1持久化到BookKeeper，当Producer又发送消息1时，Broker会把消息1再一次持久化到BookKeeper。开启消息去重后，当Producer再次发送消息1时，Broker不会把消息1再一次持久化到磁盘。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.8171875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tSjX7NyiarERaQXRFibibkWs50ic6teu0AW8aibQeaJtd5wTouhUtOMcPAgg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Producer对每一个发送的消息，都会采用递增的方式生成一个唯一的sequenceID，这个消息会放在message的元数据中传递给Broker。同时，Broker也会维护一个PendingMessage队列，当Broker返回发送成功ack后，Producer会将PendingMessage队列中的对于的sequence id删除，表示Producer任务这个消息生产成功。Broker会记录针对每个 Producer接收到的最大Sequence ID和已经处理完的最大Sequence ID。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当Broker开启消息去重后，Broker会对每个消息请求进行是否去重的判断。收到的最新的Sequence ID是否大于Broker端记录的两个维度的最大Sequence ID，如果大于则不重复，如果小于或等于则消息重复。消息重复时，Broker端会直接返回ack，不会继续走后续的存储处理流程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（三）消息延迟传递&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;延时消息功能允许Consumer能够在消息发送到Topic后过一段时间才能消费到这条消息。在这种机制中，消息在发布到Broker后，会被存储在BookKeeper中，当到消息特定的延迟时间时，消息就会传递给Consumer。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图为消息延迟传递的机制。Broker在存储延迟消息的时候不会进行特殊的处理。当Consumer消费消息的时候，如果这条消息设置了延迟时间，则会把这条消息加入DelayedDeliveryTracker中，当到了指定的发送时间时，DelayedDeliveryTracker才会把这条消息推送给消费者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.40312876052948254&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tn4NiaFDlEIYicf0b30xpvMSG0RgcJjpLA31Rz98qDHlPo2FhWkuZ3m8w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;831&quot;/&gt;&lt;/p&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在Pulsar中，可以通过两种方式实现延迟投递。分别为deliverAfter和deliverAt。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;deliverAfter可以指定具体的延迟时间戳，deliverAt可以指定消息在多长时间后消费。两种方式本质时一样的，deliverAt方式下，客户端会计算出具体的延迟时间戳发送给Broker。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DelayedDeliveryTracker会记录所有需要延迟投递的消息的index。index由Timestamp、Ledger ID、Entry ID三部分组成，其中Ledger ID和Entry ID用于定位该消息，Timestamp除了记录需要投递的时间，还用于延迟优先级队列排序。DelayedDeliveryTracker会根据延迟时间对消息进行排序，延迟时间最短的放在前面。当Consumer在消费时，如果有到期的消息需要消费，则根据DelayedDeliveryTracker index的Ledger ID、Entry ID找到对应的消息进行消费。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图，Producer依次投递m1、m2、m3、m4、m5这五条消息，m2没有设置延迟时间，所以会被Consumer直接消费。m1、m3、m4、m5在DelayedDeliveryTracker会根据延迟时间进行排序，并在到达延迟时间时，依次被Consumer进行消费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6571125265392781&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4ttv3RrZ4DTFf5A174WVAQAMDhiaRZJe6iarPlla9txGKllKT58dpLC4mA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;942&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（四）Bundle&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们知道，Topic分区会散落在不同的Broker中，那Topic分区和Broker的关系是如何维护的呢？当某个Broker负载过高时，Pulsar怎么处理呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Topic分区与Broker的关联是通过Bundle机制进行管理的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个namespace存在一个Bundle列表，在namesapce创建时可以指定Bundle的数量。Bundle其实是一个分片机制，每个Bundle拥有 namespace 整个hash范围的一部分。每个Topic (分区) 通过hash运算落到相应的Bundle区间，进而找到当前区间关联的Broker。每个Bundle绑定唯一的一个Broker，但一个Broker可以有多个Bundle。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图，T1、T2这两个Topic的hash结果落在[0x0000000L——0x4000000L]中，这个hash范围的Bundle对应Broker2，Broker2会对T1、T2进行处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同理，T4的hash结果落在[0x4000000L——0x8000000L]中，这个hash范围的Bundle对应Broker1，Broker1会对T4进行处理；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;T5的hash结果落在[0x8000000L——0xC000000L]中，这个hash范围的Bundle对应Broker3，Broker3会对T5进行处理；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;T3的hash结果落在[0xC000000L——0x0000000L]中，这个hash范围的Bundle对应Broker3，Broker3会对T3进行处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.51953125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tulSKfSS9yviczgG12eick9zmo4YqIsKL1rpDAuia4bfDwMeMictU4fL2Ng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Bundle可以根据绑定的Broker的负载进行动态的调整、绑定。当Bundle绑定的Broker的Topic数过多、负载过高时，都会触发Bundle拆分，将原有的Bundle拆分成2个Bundle，并将其中一个Bundle重新分配给不同的Broker，以降低原Broker的Topic数或负载。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;五、Pulsar存储层（Bookkeeper）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;BookKeeper是Pulsar的存储组件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于Pulsar的每个Topic（分区），其数据并不会固定的分配在某个 Bookie上，具体的逻辑实现我们在&lt;/span&gt;&lt;span&gt;Bundle&lt;/span&gt;&lt;span&gt;一节已经讨论过，而Topic的物理存储，实际上是通过BookKeeper组件来实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（一）分片存储&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;概念：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pulsar在物理上采用分片存储的模式，存储粒度比分区更细化、存储负载更均衡。如图，一个分区Topic-Partition2的数据由多个分片组成。每个分片作为BookKeeper中的一个Ledger，均匀的分布并存储在BookKeeper的多个Bookie节点中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于分配存储的机制，使得Bookie的扩容可以即时完成，无需任何数据复制或者迁移。当Bookie扩容时，Broker可以立刻发现并感知新的Bookie，并尝试将新的分片Segment写入新增加的Bookie中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6882406563354604&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tpMPJ94AQAld912n1QCbCot34iaVd1XRRKAZ3mH6oQ3t76qgY7Kr6O9g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1097&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如上图，在Broker中，消息以Entry的形式追加的形式写入Ledger中，每个Topic分区都有多个非连续ID的Ledger，Topic分区的Ledger同一时刻只有一个处于可写状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Topic分区在存储消息时，会先找到当前使用的Ledger，生成Entry ID（每个Entry ID在同一个Ledger内是递增的）。当Ledger的长度或Entry个数超过阈值时，新消息会存储到新Ledger中。每个messageID由[Ledger ID，Entry ID，Partition编号，batch-index]组成。（Partition：消息所属的Topic分区，batch-index：是否为批量消息）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个Ledger会根据Topic指定的副本数量存储到多个Bookie中。一个Bookie可以存放多个不连续的Ledger。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;（二）读写数据的流程&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt; &lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.0951940850277264&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tiaXw8NWHicCk2VMOfWQY3YIpZXEbEqEUw2DlOAibp6ODEKHYX8gl1gVyw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1082&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将Entry追加写入Ledger中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将这次Entry的更新操作写入Journal日志中，当由多个数据写入时，可以批量提交，将数据刷到Journal磁盘中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将Entry数据写入写缓存中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;返回写入成功响应。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到这里，消息写入的同步流程已经完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3-A. 内存中的Entry数据会根据Ledger和写入Ledger的时间顺序进行排序，批量写入Entry Log中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3-B. Entry在Entry log中的偏移量以Index Page的方式写入Ledger Cache中，即iIdex Files。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Entry Log和Ledger Cache中的Index File会Flush到磁盘中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;A.先从写缓存中以尾部读的方式读取。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;B.如果写缓存未命中，则从读缓存中读取。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;C.如果读缓存未命中，则从磁盘中读取。&lt;/span&gt;&lt;span&gt;磁盘读取有三步：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.Pulsar官方文档&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.BookKeeper官方文档&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.Apache Pulsar 技术系列-客户端消息确认&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.Apache Pulsar 技术系列-Message deduplication这里的去重与你想的可能不一样&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5.Apache Pulsar 技术系列-Pulsar延迟消息投递解析&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6.Apache 系列—Pulsar核心特性解析&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt; 作者简介&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;105&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;107&quot; data-fileid=&quot;100044396&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/VY8SELNGe97yMQ5oyKo9yNzKdVJTqN4tHpv2yFE45SlYNjtpo7bjTKAmefNDicfT3zJVdlAxPclJvzn380xq42Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;雷洁彦&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span/&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;腾讯后端开发工程师&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;腾讯后端开发工程师，目前负责QQ浏览器信息流内容业务的后端开发工作。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt; 推荐阅读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247532240&amp;amp;idx=1&amp;amp;sn=bb7e1b07f9eef04f074bd32305a7d9f1&amp;amp;chksm=eaa86480dddfed968078a46456d86586cb78ab6a91ea8e28f36c5a09c5a5e1c72eaca804b235&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;七年激荡！Serverless的下一站将去往何方？&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;七年激荡！Serverless的下一站将去往何方？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247532236&amp;amp;idx=1&amp;amp;sn=98558d0331d44be6b9385e8b40aa957c&amp;amp;chksm=eaa8649cdddfed8a278d3fe8e6975982d6b34f7e0127af85c505c96d6a86c2f461d43e71c901&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;基于流计算Oceanus和Elasticsearch Service构建百亿级实时监控系统&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;基于流计算Oceanus和Elasticsearch Service构建百亿级实时监控系统&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247532178&amp;amp;idx=1&amp;amp;sn=daaca51a86e597bf7c8526562d823d24&amp;amp;chksm=eaa864c2dddfedd4b3b9315c955638730eafa903083c2a94628e04a075816a39daf95a670895&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;云原生吞噬世界，是大势所趋还是技术炒作？&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;云原生吞噬世界，是大势所趋还是技术炒作？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247532130&amp;amp;idx=1&amp;amp;sn=877fda743f14583b00283fdb147580b8&amp;amp;chksm=eaa86432dddfed243a4c404aa4a5111a0a0a9b1ed6a6d63f2700c5d5cb9c2dbe44a2537ecabb&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;带你彻底击溃跳表原理及其Golang实现！（内含图解）&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;带你彻底击溃跳表原理及其Golang实现！（内含图解）&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzI2NDU4OTExOQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96FK2eEg86vUicOR3n6kAHk1PHvTb8VBicYk0RmNQYsQyibgg8iaZqT0bCEU9VKo3Z3iceoQfgycyMpKWQ/0?wx_fmt=png&quot; data-nickname=&quot;云加社区&quot; data-alias=&quot;QcloudCommunity&quot; data-signature=&quot;腾讯云官方社区公众号，汇聚技术开发者群体，分享技术干货，打造技术影响力交流社区。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.59375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/VY8SELNGe977Xa5zfy5iaV3agpS11Cqm4xV7ckfbmtFLyUjFID2k7yO4q8hvB4OqYoNkARZ2xuvzKvMtnmVN2BQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>3de7d04484e24867514706c4780a55f6</guid>
<title>平台化建设思路浅谈 | 木小丰的博客</title>
<link>https://toutiao.io/k/gyrx2g8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;article class=&quot;markdown-body mt-4&quot;&gt;
        &lt;p&gt;随着业务的不断发展，软件系统不可避免的走向熵增：复杂度越来越高、研发效率越来越差、稳定性逐渐降低等。这时抽象核心能力，走向平台化的道路成为很多系统的首要选择。笔者结合自己的经验，总结了平台化建设的几种思路，希望对大家建设平台化有所帮助。&lt;/p&gt;
&lt;p&gt;平台化有以下优点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;复用性强：复用核心逻辑，业务功能只在平台之上的业务层建设，降低建设成本；&lt;/li&gt;
&lt;li&gt;研发效率高：平台服务作为通用能力基建，业务只需要关注需求，不用关心平台底层复杂能力实现；&lt;/li&gt;
&lt;li&gt;降低复杂性：平台都有合理的职责边界和模块划分，对外开发的接口也都直观简洁；&lt;/li&gt;
&lt;li&gt;稳定性：平台服务的稳定性是重中之重，一般有专门的团队维护，稳定性比一般的业务系统强；&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;平台化建设几种方式&quot;&gt;平台化建设几种方式&lt;/h1&gt;
&lt;h3 id=&quot;1嵌入式&quot;&gt;1、嵌入式&lt;/h3&gt;
&lt;p&gt;平台提供类似容器的功能，业务方以Jar包形式嵌入到平台当中，类似于传统的多个war包部署在tomcat中。这种实现方式平台提供通用能力接口和业务扩展点，业务方实现业务扩展点来实现业务逻辑。一般有统一的入口（比如tomcat提供的域名+端口），根据租户标识来区分业务方（比如tomcat的serverPath），平台底层的存储及模型中也都有租户ID标识。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blogpic.chekuspace.com/aNiAkZdwGzBRnPCQXYy8gQUByOu9iNot-bl_b_Yb1L4.png&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;运维： 平台统一运维，业务方工作量降低；&lt;/li&gt;
&lt;li&gt;对外接口：对外统一接口，调用者的工作量会降低；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;劣势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;业务方功能受限：一般不能做重量级任务，平台以扩展点方式提供给业务方扩展，除此之外的能力都应该被限制；&lt;/li&gt;
&lt;li&gt;jar包冲突、类冲突问题：平台本身包含了很多依赖，业务方jar包也会有很多依赖，如果有冲突会导致整个平台不可用，下文会介绍几种规避方法；&lt;/li&gt;
&lt;li&gt;业务隔离性差：不同业务方之间可能相互影响；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;处理业务隔离的常用方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个业务方提供一个集群；&lt;/li&gt;
&lt;li&gt;使用类加载器隔离jar包，但可能依然解决不了jar包冲突的问题；&lt;/li&gt;
&lt;li&gt;业务方提供fatjar，更改所有依赖包的package路径，比如&lt;strong&gt;MavenShadePlugin&lt;/strong&gt;插件；&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;2接口依赖式&quot;&gt;2、接口依赖式&lt;/h3&gt;
&lt;p&gt;平台也可以通过远程依赖的形式来整合业务的功能。这样能避免jar包冲突、业务功能受限等问题。此方案也会有一些限制，比如原jar包依赖的方式都是本地调用，现在都是远程调用，对性能、事务保证等都提出了新的挑战；需要保证接口的兼容性；平台与业务的交互由原来对象交互变成RPC接口，设计到编解码等；&lt;/p&gt;
&lt;p&gt;这种方案适合平台与业务层交互较少、扩展点比较固定的场景，比如API渲染服务，平台提供渲染模板接口，业务方实现接口填充字段。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blogpic.chekuspace.com/fKUY_JDS9b_5Sfed2f11HyUdNqrSqExDbYu1e0YAt4k.png&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;隔离性：平台和业务完全隔离；&lt;/li&gt;
&lt;li&gt;业务方方便整合其他业务：平台扩展点只是作为业务方的一种能力，可以在已有的服务上提供；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;劣势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;接口变更复杂：如果要变更接口，所有业务方都需要迭代；&lt;/li&gt;
&lt;li&gt;交互复杂：都是通过RPC交互，一些扩展字段需要编解码成String传输；&lt;/li&gt;
&lt;li&gt;平台方兜底：如果业务方服务异常，平台方需要提供限流、降级、兜底的能力；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;3中台式&quot;&gt;3、中台式&lt;/h3&gt;
&lt;p&gt;上面讲到两种模式都是以平台为主，对上层来说都是感知的平台，适合交互接口比较固定的场景，对交互差异性大的业务不是很适合。中台式的思路是提供业务通用能力，业务方基于中台能力快速开发自己的业务，并独立提供服务或页面。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blogpic.chekuspace.com/6dZ8y9ikM1h7wGDu-FawurgC1ZkBwT_Du6ae0QlBVOE.png&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;中台和平台的区别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;视角不同：平台关注的是去重、整合；中台关注的是复用；&lt;/li&gt;
&lt;li&gt;价值体现：平台直接对外提供服务，是一个功能大集合；中台是其他产品的一部分，为了其他产品更好的提供服务；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;能力聚焦：只需要提供核心能力支撑，不关心和用户交互；&lt;/li&gt;
&lt;li&gt;复用性更强：平台不依赖业务的扩展点，而只是业务方到平台的单向依赖；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;劣势：&lt;/p&gt;

&lt;h1 id=&quot;平台化建设常用模式&quot;&gt;平台化建设常用模式&lt;/h1&gt;
&lt;h3 id=&quot;1dsl领域特性语言&quot;&gt;1、DSL领域特性语言&lt;/h3&gt;
&lt;p&gt;DSL（Domain Specific Language）是针对某一&lt;strong&gt;领域&lt;/strong&gt;，具有&lt;strong&gt;受限表达性&lt;/strong&gt;的一种计算机程序设计&lt;strong&gt;语言&lt;/strong&gt;。 DSL 具备强大的表现力，常用于聚焦指定的领域或问题。&lt;/p&gt;
&lt;p&gt;在平台化建设中，DSL一般用来屏蔽平台复杂的业务逻辑，以DSL的形式对业务方暴露简洁能力接口。&lt;/p&gt;
&lt;p&gt;比如非常有名的Gradle，就是一种DSL表达，具有比Maven更灵活的特性，关于如何构建DSL，请参考作者博客：&lt;a href=&quot;https://lesofn.com/archives/shi-yong-groovy-gou-jian-dsl&quot;&gt;使用Groovy构建DSL&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;2specification规约模式&quot;&gt;2、Specification规约模式&lt;/h3&gt;
&lt;p&gt;Specification 模式用于解决「业务规则」相关的复杂性。&lt;/p&gt;
&lt;p&gt;什么是业务规则呢？比如电商业务场景中需要判断：账户有效状态、是否是VIP、活动价有效期、账户余额等。在常规的代码开发中，有三种处理方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在业务流程代码中case by case的编写；缺点是会导致能力复用性、可维护性越来越差；&lt;/li&gt;
&lt;li&gt;新建静态类，比如OrderValidator、TimeValidator等，缺点是处理组合逻辑（and、or）力不从心；&lt;/li&gt;
&lt;li&gt;在模型类中校验，缺点是类中会掺杂越来越多的非领域逻辑，这种逻辑太多会掩盖业务核心的业务规则；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Specification模式认为校验逻辑都是“动作”，需要单独建模，且模型都是值对象，接口通用模式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;public interface Specification&amp;lt;T&amp;gt; {
    boolean isMatch(T domainObject);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;通过实现 &lt;code&gt;Specification&lt;/code&gt; 接口，我们可以对不同的领域对象扩展不同的校验逻辑，而这些类都是可以复用的。&lt;/p&gt;
&lt;p&gt;同时这些 &lt;code&gt;Specification&lt;/code&gt; 可以作为基础元素进行任意的组合，组合更为复杂的校验规则与筛选逻辑。&lt;/p&gt;
&lt;p&gt;当然&lt;code&gt;Specification&lt;/code&gt; 不仅仅适用于过滤数据，它的核心是组装业务规则。例如 Spring Data JPA 提供了基于 JPA 的 Specification 模式的查询功能，使用起来非常方便，以下是一个示例：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt; public List&amp;lt;Student&amp;gt; getStudent(String studentNumber, String name) {
        Specification&amp;lt;Student&amp;gt; specification = new Specification&amp;lt;Student&amp;gt;(){
            @Override
            public Predicate toPredicate(Root&amp;lt;Student&amp;gt; root, CriteriaQuery&amp;lt;?&amp;gt; query, CriteriaBuilder cb) {
                //用于暂时存放查询条件的集合
                List&amp;lt;Predicate&amp;gt; predicatesList = new ArrayList&amp;lt;&amp;gt;();
                //equal
                if (!StringUtils.isEmpty(name)){
                    Predicate namePredicate = cb.equal(root.get(&quot;name&quot;), name);
                    predicatesList.add(namePredicate);
                }
                //like
                if (!StringUtils.isEmpty(nickName)){
                    Predicate nickNamePredicate = cb.like(root.get(&quot;nickName&quot;), &#x27;%&#x27;+nickName+&#x27;%&#x27;);
                    predicatesList.add(nickNamePredicate);
                }
                //最终将查询条件拼好然后return
                Predicate[] predicates = new Predicate[predicatesList.size()];
                return cb.and(predicatesList.toArray(predicates));
            }
        };
        return repository.findAll(specification);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;3异构&quot;&gt;3、异构&lt;/h3&gt;
&lt;p&gt;平台提供的通用能力如果不能直接满足业务的需求，需要提供扩展能力以适配业务模型来达到异构的目的。支持业务扩展模型一般有以下几种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;String ext&lt;/li&gt;
&lt;li&gt;Map&amp;lt;String,String&amp;gt; ext&lt;/li&gt;
&lt;li&gt;Class：一般用于嵌入jar式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;还有另外一个问题需要解决，平台作为通用能力，有平台自身的模型，如何将平台模型转换为业务模型？简单的做法是作为扩展点开放给业务方实现，不过作为业务方，应该关注的是业务模型，平台模型有自己的规则且平台为了通用化，模型都会非常复杂。&lt;/p&gt;
&lt;p&gt;一个更完善的平台应该支持更灵活的异构模型支持，常用是方案是字段配置化：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在平台申请一个模型的定义，一般包括类型，长度，限制规则等（比如必须是正整数）；&lt;/li&gt;
&lt;li&gt;业务方配置字段和平台模型的映射关系，如果需要动态能力，可提供Groovy或Aviator等脚本支持；&lt;/li&gt;
&lt;li&gt;转换为业务方模型：根据用户配置，自动转换并给用户返回业务模型；&lt;/li&gt;
&lt;li&gt;转化为平台模型：参数中需要传入元数据类名，平台按照配置规则进行有效性校验；如果需要自动转化，则需要在配置服务支持双向映射&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;4统一存储&quot;&gt;4、统一存储&lt;/h3&gt;
&lt;p&gt;平台除了平台通用模型的存储支持，还需要支持不能转换为平台模型业务模型存储。有以下几种方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;宽表：采用列式存储引擎，可方便的创建、修改列，缺点是常用的列式存储引擎一般不能提供的很好的事务支持；&lt;/li&gt;
&lt;li&gt;列转行：数据表只有三列：id、key、value，查询及存储时在repository层进行转换，缺点是不能join、不支持修改列；适用于不太复杂的业务场景；&lt;/li&gt;
&lt;li&gt;元数据：完全接管数据库操作，根据不同字段格式自动存储到不同列，完善的元数据平台还支持分库分表、扩缩容、数据迁移等能力，建设成本最高；&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;
&lt;p&gt;平台化建设是一个非常复杂的工程，涉及的业务方、方案选择比较多，难点和投入成本也都差异较大，没有一套完美的方案能覆盖所有业务场景，本文提供了几种参考方案和设计模式，具体的方案还需要读者结合自己的业务场景来挑选最适合自己的方案。&lt;/p&gt;
&lt;p&gt;作者简介：木小丰，美团Java技术专家，专注分享软件研发实践、架构思考。欢迎关注公共号：&lt;strong&gt;Java研发&lt;/strong&gt;&lt;br/&gt;
本文链接：&lt;a href=&quot;https://lesofn.com/archives/ping-tai-hua-jian-she-si-lu-qian-tan&quot;&gt;平台化建设思路浅谈&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blogpic.chekuspace.com/二维码小_1607785087313.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

    &lt;/article&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>34f5d544750e794f0bc96c53e8ed9983</guid>
<title>汤楚熙：美团实时数仓架构演进与建设实践</title>
<link>https://toutiao.io/k/8ky7vrp</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p class=&quot;original_area_primary&quot;&gt;
                                                                                                &lt;/p&gt;

                    
                                            &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjdrlkyhHH3BZDV05IvhuKOic0so28M9B0cD8Hqia6HMpWBZhzfsTqP48RHZwSfonCSA3OtgJoM212A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section data-width=&quot;100%&quot; data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot;&gt;&lt;section data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot; data-style=&quot;margin-bottom: -10px; margin-left: -8px; max-width: 100%; width: 18px; height: 18px; border-top: 8px solid rgb(54, 65, 173); border-left: 8px solid rgb(54, 65, 173); box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible;&quot;&gt;&lt;br data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot;/&gt;&lt;/section&gt;&lt;section data-bgopacity=&quot;50%&quot; data-darkmode-bgcolor-16008590572276=&quot;rgb(33, 33, 33)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(247, 247, 247)&quot; data-style=&quot;max-width: 100%; width: 543.333px; background: rgb(247, 247, 247); box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible;&quot;&gt;&lt;section data-darkmode-bgcolor-16008590572276=&quot;rgb(33, 33, 33)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(247, 247, 247)&quot;&gt;&lt;p data-darkmode-bgcolor-16008590572276=&quot;rgb(33, 33, 33)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(247, 247, 247)&quot;&gt;&lt;span&gt;分享嘉宾：汤楚熙 美团&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16008590572276=&quot;rgb(33, 33, 33)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(247, 247, 247)&quot;&gt;&lt;span&gt;编辑整理：李瑶 DataFun&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16008590572276=&quot;rgb(33, 33, 33)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(247, 247, 247)&quot;&gt;&lt;span&gt;出品平台：DataFunTalk&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-width=&quot;100%&quot; data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot;&gt;&lt;section data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot; data-style=&quot;max-width: 100%; width: 18px; height: 18px; border-bottom: 8px solid rgb(54, 65, 173); border-right: 8px solid rgb(54, 65, 173); box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible;&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;导读：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;大家好，我叫汤楚熙，来自美团数据平台中心的计算平台团队，当前主要工作内容是实时数仓平台的研发。&lt;/span&gt;&lt;span&gt;今天和大家分享一下实时数据在美团的典型应用场景，实时数仓建设中的挑战和解决方案，包括一些关键的设计细节。主要介绍以下几方面内容：&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;01&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;建设背景&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;首先，来介绍一下美团实时数据的典型应用场景以及建设过程遇到的一些问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. &lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;实时数据在美团的典型应用场景&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBYFqejv3H9cOFUiaYZMMtWHlQIFU2ZNicMOHo0Ir7xFmoHEvlZPE1t8icg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美团作为本地生活领域的头部公司，在内部孵化了许多独立业务，可以看到有大家所熟悉的美团外卖、酒店、美团优选等，这些业务通过实时数据来支撑其内部各种各样的数据应用场景，比如BI、算法、骑手调度等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBUZBnjRrm4hw0O5g2e6zS26FpavVq3eMN4N0Zu10MTTiaw18TIQl2C3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们对业务场景做了一个简单的分类：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;指标监控：比如有实时大盘，用来即时反馈业务当日运转的健康度等场景；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;实时特征：比如搜索、广告CTR预估、骑手调度等，对算法特征数据新鲜度要求较高的场景；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;事件处理：比如一些风控类、运营活动发券等事件驱动型场景；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据对账：比如&lt;/span&gt;&lt;span&gt;金融的支付业务，支付部门与业务部门各自独立，当业务部门的支付单据与支付部门不一致时，会造成资损，这时数据的实时对账就非常关键。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBltMbWY2ZMQeDxvVmvlkUbEBbmibAml51DKUby922H1AnDu1UU2Y32RA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图可以看到，截至目前，实时计算平台所支撑的实时数据处理场景的整体规模，&lt;/span&gt;&lt;span&gt;说明实时数据在美团已经影响到了业务的方方面面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQB0uzg3I8AelZ5NWuGWj9aphsyvuhaHIgLcnk6bXZibDJC4gPicLwcfyuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实时计算平台从成立以来，经历了上图中的几个关键发展阶段。&lt;/span&gt;&lt;span&gt;平台正式成立于2014年，我们引入Storm和Spark Streaming作为美团的第一代实时计算引擎，并且发布了第一版作业托管平台。接下来在2017年，平台正式引进了Flink，并开始初步探索以Flink SQL为主的实时数仓开发方式。并于2019年，正式将Flink SQL作为主要编程接口暴露给业务，将以任务为中心的开发模式，升级为以数据为中心的开发模式。当前，计算平台紧跟业界发展潮流，将工作内容都聚焦在数仓增量化生产、流批语义统一、统一实时离线数仓建模方式等几个方向上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 实时数仓建设过程中的问题及痛点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBGQLyjJ6tk2ItdkURNXZKD5wcZAQhjBxoVFhnN18Qcy6oHP8wFZQARA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在正式开始介绍数仓平台的建设实践之前，先来回顾下平台初期所遇到的问题。&lt;/span&gt;&lt;span&gt;实时数据开始建设之初，是没有离&lt;/span&gt;&lt;span&gt;线数仓那样成熟的建设方法论的，而且也没有离线数仓领域那样成熟的开发工具，所以带来了以下几点问题&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首先就是高昂的开发运维成本，每次计算框架的升级，业务都需要学习一遍计算框架的API。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;代码本地开发，再去线上调试，本地的case难以覆盖线上的数据问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;业务各自的数据协议不统一，相互之间进行数据交换，沟通协作的成本也是比较高昂的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数仓的建设方式没有统一规范，导致数据的冗余和重复建设，给后期的资源治理带来了非常大的麻烦。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBvM4Pjq9dOW3mX6JKWKtEefZNS8GJ7EqUH5dulF3cZ0iaQZdhoAW2MFA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从上面的问题出发，我们制定了平台的建设路线。&lt;/span&gt;&lt;span&gt;主要集中在两个层面，&lt;/span&gt;&lt;span&gt;首先是降低业务的开发运维门槛，让实时数仓开发可以像离线数仓开发那样简单高效。&lt;/span&gt;&lt;span&gt;比如我们提供了标准的ETL作业模板，web集成开发环境，并且扩展了SQL的能力，使业务可以尽量以符合其认知的形式去进行代码开发。&lt;/span&gt;&lt;span&gt;还有数仓建设中业务最关心的数据质量问题，我们也提供了相应的配套工具，帮助业务以尽可能低的成本将可靠的数据交付应用方。&lt;/span&gt;&lt;span&gt;可用性在离线数仓建设过程中可能大多体现在数据是否按时就绪，那么实时数仓对数据的时延要求更高，所以可用性的保障也非常关键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前面提到的都是在开发运维效率方面我们所做的一些建设规划，在大数据领域，一个&lt;/span&gt;&lt;span&gt;底层算子性能的小小改进，都会使执行效率成倍的放大，所以我们也会花费一些精力在底层算子的优化上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;两横三纵，其中&lt;/span&gt;&lt;span&gt;两横包括&lt;/span&gt;&lt;span&gt;开发迭代效率，面向人的优化，重点在于对工作流。&lt;/span&gt;&lt;span&gt;三纵包括&lt;/span&gt;&lt;span&gt;能做（&lt;/span&gt;&lt;span&gt;看得见、摸得着的问题）、&lt;/span&gt;&lt;span&gt;做好和&lt;/span&gt;&lt;span&gt;最优化。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;02&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;平台架构设计&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;接下来开始着重介绍我们是如何解决上面所提到的问题的。&lt;/span&gt;&lt;span/&gt;&lt;span&gt;首先从整体上来介绍下平台解决上面问题的思路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQB98QiaZpChXWSFTYzbS2nRYAxb3sWicmzfxFnmsxJPXL7cEJ13kRdIibUQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图是平台整体架构。&lt;/span&gt;&lt;span&gt;从下向上来看，存储、计&lt;/span&gt;&lt;span&gt;算、调度加上日志服务构成了我们的基础服务层。&lt;/span&gt;&lt;span&gt;基础服务层之上是平台对业务提供的一些中间件。&lt;/span&gt;&lt;span&gt;上层是平台抽象出的一些可自行组合的微服务集合，比如作业模板服务、&lt;/span&gt;&lt;span&gt;UDF&lt;/span&gt;&lt;span&gt;托管服务、元数据服务、指标采集监控、数据质量管理等，这些服务业务可以按自身的场景需要来在自己的业务内部自行组合，也可以直接使用平台包装好的大而全的集成开发平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQB4HY4vx39LcKJPn4eNW2DAdGw3bkicP69ve7H8xVnSs3wYNQcGaCYuwA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图展示了平台基础服务中最关键的计算服务的选型过程。&lt;/span&gt;&lt;span&gt;实时数仓场景的最根本业务诉求是数据的时效性，这里的时效性通常指的是秒级的延迟，所以这里Flink和Storm胜出。&lt;/span&gt;&lt;span&gt;其次是数据的正确性，Flink是这里唯一能够保证Exectly-Once计算语义的框架，所以Flink要优于storm。&lt;/span&gt;&lt;span&gt;之后我们有做了benchmark测试，通过实验证明了，在绝大多数场景下Flink任务的吞吐要优于Storm，而且Flink还提供了更加成熟的SQL编程接口，&lt;/span&gt;&lt;span&gt;所以我们最终确认选择Flink作为实时数仓的核心计算框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBaWbN38PIibEQB6ubYWibEejXRlvYgXnm52IwRMXs6fyEdENhBIE4Nhpg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解决了计算框架的问题，接下来我们要从上层概念入手，让熟悉离线数仓开发的同学能够更快的上手实时数仓的开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从下向上看，我们先统一了离线和实时数仓的数据模型，无论是&lt;/span&gt;&lt;span&gt;HiveT&lt;/span&gt;&lt;span&gt;able&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;Kafka&lt;/span&gt;&lt;span&gt;Topic&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;Redis&lt;/span&gt;&lt;span&gt;的一个域，在上层暴露给业务的都是一张&lt;/span&gt;&lt;span&gt;Table&lt;/span&gt;&lt;span&gt;，这样业务没有过多认知上的负担了，可以在不同开发场景的概念之间轻松切换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从上向下看，我们又统一了编程接口，使用SQL作为数仓开发的首选，这样实时和离线数仓的ETL逻辑甚至可以完全共用一套，对开发效率上也有显著的提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBgVSWYyNU8mM1d2LhfUIuZrlaccT4TLLngd9wOxn2r2DW1nicicdFcRvQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有同学可能会问，实时和离线场景的计算语义不完全相同，实时计算场景需要包含大量跟时态相关的语法，比如window，interval等，离线场景上没有，那么怎么统一呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;的确如此，所以我们独立出一套SQL服务，短期用户也可以在SQL中加入HINT提升或者是直接提供一些参数，来告诉我们这是什么离线还是实时场景的ETL，未来我们会自动根据业务的输入、输出表的存储类型，ETL的模式，自动判断使用哪种类型的执行模式更有效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;跟社区如果对不齐怎么办：&lt;/span&gt;&lt;span&gt;先对内解问题，如果效果真的不错，可以推回社区，如果社区有更好的方案，我们可以判断是否能够&lt;/span&gt;&lt;span&gt;merge&lt;/span&gt;&lt;span&gt;进来，如果不行，说明我们的架构设计本身就是有问题的。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;03&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;平台建设实践&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 实时数仓开发解决方案&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBneF2W9VxhscZ6DEaWnny3PeCM8POTNvllHQ4DsiatwQjQR9ibPx586lg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们对数仓平台的定位是：集需求准备、开发测试、发布和运维监控能力的一站式实时数仓生产解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面简单来介绍一下用户在平台上的工作流程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在需求准备阶段，用户可以结合业务需求先来检索是否有满足需求的数据模&lt;/span&gt;&lt;span&gt;型，如果没有找到，那么可以选择从源头开始接入，或者新建模型。模型接入或创建好之后，进入&lt;/span&gt;&lt;span&gt;ETL&lt;/span&gt;&lt;span&gt;开发阶段，开发过程可能会伴随着一些简单的任务调试，这些工作也全部都可以在平台上完成。在开发完成准备上线之前，用户可以创建一条发布流水线，这块内容后面还有详细的介绍，待流水线执行通过后，就可以正式发布作业了，作业上线后，平台会自动收集作业的运行时指标，用来监控作业的运行状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBp5Mumbhu569BCsOKajL31De9oB7CLzib58sGzEV1mPOE2rqZ4yG7Inw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面介绍下，平台是如何规范业务的数仓接入流程的。&lt;/span&gt;&lt;span&gt;从上图（左）&lt;/span&gt;&lt;span&gt;大家可以看到，跟离线数仓的入仓流程相比，在没有数仓平台前，实时数仓的入参过程突出了一个乱字，而这样会带来如下问题：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数&lt;/span&gt;&lt;span&gt;据建设过程没有规范，后面接手的同学不知道从何入手。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;接着上面的问题，如果后面同学按照自己的理解，重新接入一遍数据，长此以往，会造成大量的冗余数据，造成烟囱林立，资源浪费，后面还&lt;/span&gt;&lt;span&gt;需要花大量的时间治理。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数仓接入这个动作本身是没有过多业务逻辑的，是可以标准化和系统化的，这样重复机械的工作内容，会造成人力资源的浪费。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQB88KCrrpm37m535yQ9ZbicE1NMtvE8sNQYzxjJY3x4uvA47G6sfFwoQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;面对上述问题，数仓平台提供了一套完整的实时数仓接入方案。&lt;/span&gt;&lt;span&gt;明确的帮用户生成&lt;/span&gt;&lt;span&gt;ODS&lt;/span&gt;&lt;span&gt;层，这样同项目成员之间的合作，有了共同的规范和约束，不会再有因信息未对齐而造成的数据重复接入。&lt;/span&gt;&lt;span&gt;我们不光帮助用户规范了入仓的流程，还提供了一系列数据正确性、作业稳定性的保障机制，使业务同学可以将精力集中在数仓的建设上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBvIQ1OCelPys7JeKECarpg3YZcb1I47fB43V6nvUNlCNhaghCJNFfDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在规范化业务数仓接入流程的方案设计过程中，有个小小的挑战，那就是我们的数据源并不仅仅来自MySQL binlog和nginx日志，还有大量业务自行通过SDK上报的日志，这些日志的格式难以从整体上进行抽象，而且不同业务因为服务场景不同，数据的序列化方式也难以统一，所以我们抽象出一个Adapter模块，专门用来解决这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;P&lt;span&gt;arser&lt;/span&gt;&lt;span&gt;用来适配业务自定义消息格式，&lt;/span&gt;&lt;span&gt;Formatter&lt;/span&gt;&lt;span&gt;将用来监控作业稳定性和数据正确性的元数据信息融入到消息中，最后按照业务场景的实际诉求，允许业务根据自身场景定义序列化方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBiaBtOvNsHeZA481jLn7UzEsm5sJLNGcXJuhtFHKPNNPFAMHtYXT9e0Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前面介绍了平台在数据入仓阶段如何提升开发效率。&lt;/span&gt;&lt;span&gt;接下来介绍如何帮助业务更低门槛的进行实时数据的开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;平台上线之初是基于&lt;/span&gt;&lt;span&gt;Flink1.&lt;/span&gt;&lt;span&gt;9&lt;/span&gt;&lt;span&gt;的&lt;/span&gt;&lt;span&gt;SQL&lt;/span&gt;&lt;span&gt;实现的模板任务，在当时来看，他们的能力并不成熟，一些在离线场景比如&lt;/span&gt;&lt;span&gt;SparkSQL&lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt;HiveSQL&lt;/span&gt;&lt;span&gt;都支持的语法，在&lt;/span&gt;&lt;span&gt;Flink&lt;/span&gt;&lt;span&gt;上支持的并不好。&lt;/span&gt;&lt;span&gt;所以我们决定先由平台自行根据业务需求对语法进行扩展。&lt;/span&gt;&lt;span&gt;比如t&lt;/span&gt;&lt;span&gt;able&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;view&lt;/span&gt;&lt;span&gt;、&lt;/span&gt;&lt;span&gt;UDF&lt;/span&gt;&lt;span&gt;的声明，还有insert into&lt;/span&gt;&lt;span&gt;等语法的支持。&lt;/span&gt;&lt;span&gt;当然这并不是全部。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBGsYT3LRI7PkSXdGoVsj4AeRa91oHTc0V8qpFbNBLuc90cwHEgbCLVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们不仅仅在&lt;/span&gt;&lt;span&gt;SQL&lt;/span&gt;&lt;span&gt;语法层面进行了改进，&lt;/span&gt;&lt;span&gt;还对作业模板进行了增强。像&lt;/span&gt;&lt;span&gt;watermark&lt;/span&gt;&lt;span&gt;提取对业务时间格式有一些要求，&lt;/span&gt;&lt;span&gt;这种业务场景强相关的逻辑并不适合直接写死在我们的模板程序代码中。&lt;/span&gt;&lt;span&gt;所以我们在作业模板中加入了几个切面，可以由业务自行上传代码来扩充这部分能力。&lt;/span&gt;&lt;span&gt;比如我们会在&lt;/span&gt;&lt;span&gt;Source&lt;/span&gt;&lt;span&gt;注册之后，提供一个切面，引入用户代码，进行日期格式转换，再执行&lt;/span&gt;&lt;span&gt;SQL&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;官方虽然已经提供了计算列，我们也调研了相关能力，但是我们认为除非有一个数量级的开发效率优化效果，否则我们没必要一定&lt;/span&gt;&lt;span&gt;follow&lt;/span&gt;&lt;span&gt;官方的语法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBwOuETjKDeaBYib0If5Bvy6iczgCk8omeU2uQ0I2eZEBg9BmQhw0DrDWw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经&lt;/span&gt;&lt;span&gt;过对模板的升级改造，可以看到平台能够支持的&lt;/span&gt;&lt;span&gt;ETL&lt;/span&gt;&lt;span&gt;模式已经非常丰富了，后面我们也会继续迭代，目标是可以覆盖&lt;/span&gt;&lt;span&gt;95%&lt;/span&gt;&lt;span&gt;以上的实时&lt;/span&gt;&lt;span&gt;ETL&lt;/span&gt;&lt;span&gt;场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBjNMjAURAQpcYyrQWNcxj1tlLQ4Tr6Fke0icTMnlQPb9ymZqNh6nTBjQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;UDF是一种扩展SQL表意能力的重要功能，在没有平台的时候，用户UDF都是散布在各自的代码仓库中的，这样一些较通用的UDF，不能被其他业务直接使用，业务在代码中执行一些有安全风险的行为，平台也无法有效管控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们建设了一套&lt;/span&gt;&lt;span&gt;UDF&lt;/span&gt;&lt;span&gt;托管服务，帮助业务集中托管&lt;/span&gt;&lt;span&gt;UDF&lt;/span&gt;&lt;span&gt;代码，可以编译打包时，进行提前检查、并暴露安全风险，而且通用&lt;/span&gt;&lt;span&gt;UDF&lt;/span&gt;&lt;span&gt;可以在业务之间共享，也能够帮助业务提升开发效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBAIZ160SJIQjjicC9Eibs6zlYoQlMWveRaiaz6VRM6M8LcSBpoaewAFPicQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前面的内容，主要是如何解决开发效率的问题，下&lt;/span&gt;&lt;span&gt;部分内容的重点是，如何保证业务的数据质量。&lt;/span&gt;&lt;span&gt;可能在场的各位同学，有后台开发的相关经验，大家可能都了解&lt;/span&gt;&lt;span&gt;Devops&lt;/span&gt;&lt;span&gt;方法论的核心目标，是保证迭代效率和工程质量。&lt;/span&gt;&lt;span&gt;实时数据开发其实与后台服务开发过程有相似的地方，作业发布后，数据就会立即生效，&lt;/span&gt;&lt;span&gt;并作用于线上，所以我们也需要一套流程，来保证我们每次实时任务发布的数据质量不用影响到我们的数据服务质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们设计了一套数仓发布的&lt;/span&gt;&lt;span&gt;Pipeline&lt;/span&gt;&lt;span&gt;，在每次任务迭代上线过程都会执行一次&lt;/span&gt;&lt;span&gt;Pipeline&lt;/span&gt;&lt;span&gt;过程，&lt;/span&gt;&lt;span&gt;TestCase&lt;/span&gt;&lt;span&gt;就类似于单测用例，理论上所有&lt;/span&gt;&lt;span&gt;TestCase&lt;/span&gt;&lt;span&gt;都通过才可以发布作业。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Pipeline服务是通过一个异步任务调度框架来实现的，每个Worker内会启动一个Flink的MiniCluster进程，执行后会将结果存入DB并在前端打印执行结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBfz5pZlAyAB3MsjTdZicicjQjzSQQHQ1cibIGd7RANicq2INkicwb7DDVn0w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于数据质量，业务还有一项非常关心的事项，也就是数据的时延。时延一方面可以说明业务交付的数据是否符合应用方的预期，另一方面也方便业务自己去排查问题，确定作业的性能瓶颈点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Flink&lt;/span&gt;&lt;span&gt;官方提供了一个用来计算延迟情况的机制，&lt;/span&gt;&lt;span&gt;Latency Marker&lt;/span&gt;&lt;span&gt;，这个东西近似于&lt;/span&gt;&lt;span&gt;Watermark&lt;/span&gt;&lt;span&gt;，是一类与业务数据无关的，由框架周期性产生的消息，我们要做的是根据业务的流量和业务延迟时间精度的要求，控制这类消息的发送频率和发送量，&lt;/span&gt;&lt;span&gt;并支持跨任务传递&lt;/span&gt;&lt;span&gt;Marker&lt;/span&gt;&lt;span&gt;。因为平台收口了数仓接入层，所以这也使我们获取到真正的端到端延迟成为可能，&lt;/span&gt;&lt;span&gt;我们会通过&lt;/span&gt;&lt;span&gt;emitter&lt;/span&gt;&lt;span&gt;向下游发送特殊的消息协议，并且下游任务的&lt;/span&gt;&lt;span&gt;Reciver&lt;/span&gt;&lt;span&gt;会对这类消息做特殊判断，在发送和接受数据时都会将指标上报到&lt;/span&gt;&lt;span&gt;Raptor&lt;/span&gt;&lt;span&gt;，即美团内部的一个业务指标监控，并最终提供给业务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBOPQP4lGiaWIM7etaHsiaicaznYjOKRLdS2ic0otEEsuPbcCwlwVIWgucNA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前面我们分别介绍了平台是如何提升开发效率和保证业务的数据质量的，主要解决的是数仓开发者的问&lt;/span&gt;&lt;span&gt;题。&lt;/span&gt;&lt;span&gt;平台还有一类用户是数仓架构师，他们不仅仅要参与数仓的建设，还需要对数仓的建设情况做整体性把控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以前大家都是通过wiki的形式来进行数仓的规范和约束。数仓平台提出了一个项目空间的概念，每个项目空间都可以由架构师定义符合自身业务场景的一些约束项，比如架构师可以定义数仓的主题、分层规范，表、字段的命名规则，同项目空间下的实体都必须遵守负责人做定义的规范。&lt;/span&gt;&lt;span&gt;这样可以在开发之前就保证数仓的建设质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 算子性能优化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面来分享下我们在flink算子层面所做的一些优化工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBsib9hIGK6FWianKfdhLpibIlYTf7KhcQ1tSzj3XYNHZQak2CeDh8SFdXA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先实时数仓有很大一部分计算场景是用来做扩维的，也就是流表关联。流数据来自kafka，表数据通常是借助redis、hbase等分布式kv存储，当流量小的时候，每一条流数据都请求一次外存，发起一次网络io，也没有多大影响。但是像基础流量等业务，每天几百上千亿条消息，都去单独请求外存，压力可想而知。所以平台为用户准备了本地缓存机制，通过一个多级缓存的架构，来缓解超大流量下外存访问的IO的压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBAY2Z54cKqOjGDQmSRcJibxVA85Sia23apphkRaaicoWzxb2JKm7MXicDEQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数仓&lt;/span&gt;&lt;span&gt;ETL&lt;/span&gt;&lt;span&gt;会包含大量聚合、关联和排序等逻辑，在有界数据处理的时候，我们对算子行为能够做出较准确的判断。&lt;/span&gt;&lt;span&gt;但是在无界数据处理的情况下，像关联、聚合等逻辑为了保证数据的正确性，会在更新一条记录的同时产生一条回撤消息，用来修复下游已经受到影响的数据，所以实际向下游传递的消息量可能会翻倍。而当涉及到多层算子嵌套，比如聚合嵌套关联，那么消息量还会继续膨胀。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决这个问题，我们研究了框架的源码，并分析了业务数据的特征，发现实际上大多数情况消息在极短的时间内会被频繁更新多次，这也就意味着我们可以将多次请求合并成一次请求，来减少状态更新的次数，从而减少向下游发送的消息量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBeuh9E26WdjtRQqPLxgP1qeGTt6ibpxydfeSKXwWBuMG3icf1hiaHCeMhg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图是一个&lt;/span&gt;&lt;span&gt;Join&lt;/span&gt;&lt;span&gt;算子的&lt;/span&gt;&lt;span&gt;优化案例，在分析了原理后，&lt;/span&gt;&lt;span&gt;我们认为可以分三个阶段来对算子进行优化：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首先在输入阶段，可以对输入的消息做预处理，如果发现同key数据紧跟一条回撤事件，我们这两条消息可以同时消除，而保留最新的一条消息；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;接下来在计算阶段，因为双流关联需要缓存左右流各自的状态，这样我们可以将短时间同&lt;/span&gt;&lt;span&gt;key&lt;/span&gt;&lt;span&gt;对状态的访问，合并成一次，减少状态访问次数；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最后在事件下发阶段，可以判断消息之间的关系，重复记录直接可被直接消除。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. 建设成果展示&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBs4diaNcHdWBcSlVorf9jOzzlan7QcgVMmRw7RfBORhIIbjEtLsz8a4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先是我们的Web IDE，左面是菜单栏，可以用来管理项目空间，右面是一个web编辑器，用来开发ETL脚本，编辑器下还提供了控制台，用来查看调试日志和对比调试结果，还有语法错误提示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBeOmVm0x2IXh98nicBibbv3c0pIHD9TOq3orVL2Sqe6YOhFx721SRwDXg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图是我们的逻辑模型管理模块，在此我们可以编辑自己的模型信息，查看血缘，资源占用量，数仓相关的业务属性等元数据，来辅助业务更好地进行数仓建模。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBROVS5khzLInia3S8YkT6bMIdxoovquk1HU6a0LC8CXVwMt51FicLajcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后展示的是运维中心，所有的作业运行状况，运行指标，操作日志都可以通过这个平台来管理。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;04&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;未来计划&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBFrJatQcJlib3YQDHc9FSSns7LL5NqPxqXibKYaPtb0gUmkUac2oHJkwQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从前面的分享大家可能会看出，平台前期的大部分精力都集中在解决业务实时数仓建设流程方面的问题上。&lt;/span&gt;&lt;span&gt;随着数仓平台在业务上的逐渐推广，以及业务的深度使用，问题更多的出现在框架的&lt;/span&gt;&lt;span&gt;runtime&lt;/span&gt;&lt;span&gt;层面，比如超大作业的调度成功率和时长问题，&lt;/span&gt;&lt;span&gt;超大数据量作业的状态访问性能问题。&lt;/span&gt;&lt;span&gt;希望通过流批一套语义、一套执行层、一套存储，来彻底解决开发运维的成本问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，&lt;/span&gt;&lt;span&gt;随着实时数据扩展至一些ToC业务场景，这些应用有着非常高的可用性要求，所以在这个方向上我们也要继续攻关下去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后就是终极问题，资源和性能比的问题，也就是在确定性的条件下，用最少的资源做最多的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgibXIibpMibxcUJCjgYnuTJQBDafUPSRtF5CoibhFle6iaIj2b4EhZZia3Gc4rOKcxicyRN54tibkSo21gYw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2560&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是我们平台当前在建设的一个重点项目——数仓增量化生产，为达成真正的流批一体做一些前置性的技术储备和路径探索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;今天的分享就到这里，谢谢大家。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;span&gt;在文末分享、点赞、在看，给个3连击呗~&lt;/span&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;分享嘉宾：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;289&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPjdrlkyhHH3BZDV05IvhuKOLmiagvjMPlliaqSQNYsx5T6c3b9RgSj29egrVabhnl5n6Av9MqAGUhibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt; &lt;/p&gt;&lt;p&gt;&lt;span&gt;🧐&lt;strong&gt;分享、点赞、在看&lt;/strong&gt;，给个&lt;strong&gt;3连击&lt;/strong&gt;呗！&lt;strong&gt;👇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e7e3e297ab653573b44aeac4e0b8a48e</guid>
<title>Go 模糊测试</title>
<link>https://toutiao.io/k/kul5ja2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从 Go 1.18 版本开始，标准工具集开始支持模糊测试。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;/h4&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;1&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.11&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_svg/Ib5852jAybicPam0Snw7000AS1gf883SNuia90CEuiaBJzed3E0ro4A34pibwxqfHFicdoEsXll4GTWfstNru18ibLHoSTQlT8tdLC/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;300&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;模糊测试（Fuzzing）是一种自动化测试方法，通过不断地控制程序输入来发现程序错误。Go 中模糊测试使用覆盖率引导来智能浏览被测试代码，发现并向用户报告错误。因为模糊测试可以触达人们常常忘记的边界测试用例，所以对查找安全隐患和漏洞特别有价值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面是 模糊测试（https://tip.golang.org/doc/fuzz/#glos-fuzz-test） 的一个例子，标注了其中主要组成部分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;示例代码中展示了整个模糊测试的情况，其中有一个模糊目标。用f.Add在模糊目标之前添加测试种子语料库，模糊目标的参数作为模糊参数被突出显示。&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;2&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;编写和运行模糊测试&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.11&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_svg/Ib5852jAybicPam0Snw7000AS1gf883SNuia90CEuiaBJzed3E0ro4A34pibwxqfHFicdoEsXll4GTWfstNru18ibLHoSTQlT8tdLC/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;300&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;要求&lt;/span&gt;&lt;br/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面是模糊测试必须遵守的规则：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;模糊测试必须是以 &lt;code&gt;FuzzXxx&lt;/code&gt; 命名的函数，只能接收一个 &lt;code&gt;*testing.F&lt;/code&gt; 的参数，且没有返回值&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;模糊测试必须在 *_test.go 文件中运行&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一个 模糊目标（https://tip.golang.org/doc/fuzz/#glos-fuzz-target） 必须是调用 (*testing.F).Fuzz 的方法，该方法接收 *testing.T 作为首个参数，紧随之后的是模糊参数。该函数没有返回值&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;每个模糊测试中必须有一个模糊目标&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;所有的 语料库（https://tip.golang.org/doc/fuzz/#glos-seed-corpus—— 中的条目必须和 模糊参数（https://tip.golang.org/doc/fuzz/#fuzzing-arguments） 相同类型、顺序一致。这一要是适用于调用 (*testing.F).Add 函数和模糊测试 testdata/fuzz 目录下的所有文件&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;模糊参数只能是如下类型：&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;string, []byte&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;int, int8, int16, int32/rune, int64&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;uint, uint8/byte, uint16, uint32, uint64&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;float32, float64&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;bool&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;建议&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面的建议将帮助你从模糊处理中获得最大收益。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;模糊测试应该在支持覆盖检测的平台上运行（目前是 AMD64 和 ARM64），如此语料库可以在运行过程中进行有意义的增长，并且在模糊测试时可以覆盖更多代码&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;模糊目标应该是快速和确定的，这样模糊引擎就能有效地工作，新的失败和代码覆盖率就能轻易地重现&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;由于模糊目标是以非确定性的顺序在多个 worker 间并行调用，所以模糊目标的状态不应该在每次调用结束后持续存在，而且模糊目标的行为不应该依赖于全局状态&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;自定义设置&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;默认的 go 命令设置适用于大多数模糊测试的情况。通常情况下，在命令行上执行的模糊测试应该是这样的&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;$ go &lt;span&gt;test&lt;/span&gt; -fuzz={FuzzTestName}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，&lt;code&gt;go&lt;/code&gt;命令在运行模糊测试时也提供了一些设置，这些设置在 &lt;code&gt;cmd/go&lt;/code&gt;包文档（https://pkg.go.dev/cmd/go） 中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中几个:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;-fuzztime&lt;/code&gt;: 在退出前执行模糊目标的总时间或迭代次数，默认为无限期地&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;-fuzzminimizetime&lt;/code&gt;: 在每次最小化尝试中，模糊目标将被执行的时间或迭代次数，默认为 60 秒。你可以通过 &lt;code&gt;-fuzzminimizetime 0&lt;/code&gt; 完全禁用最小化设置&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;-parallel&lt;/code&gt;: 同时运行的模糊处理进程的数量，默认为&lt;code&gt;$GOMAXPROCS&lt;/code&gt;。目前，在模糊摸索过程中设置 &lt;code&gt;-cpu&lt;/code&gt; 没有作用&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;语料库文件格式&lt;/span&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;语料库文件是以一种特殊的格式进行编码的。这对于种子语料库（https://tip.golang.org/doc/fuzz/#glos-seed-corpus）和生成语料库（https://tip.golang.org/doc/fuzz/#glos-generated-corpus）是相同的格式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面是一个语料库文件的例子：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;go &lt;span&gt;test&lt;/span&gt; fuzz v1&lt;br/&gt;[]byte(&lt;span&gt;&quot;hello\\xbd\\xb2=\\xbc ⌘&quot;&lt;/span&gt;)&lt;br/&gt;int64(572293)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一行是用来通知模糊测试引擎文件的编码版本。虽然目前没有计划未来的编码格式版本，但设计上必须支持这种可能性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面的每一行都是构成语料库条目的值，如果需要，可以直接复制到 Go 代码中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上面的例子中，我们有一个&lt;code&gt;[]byte&lt;/code&gt;，后面是一个&lt;code&gt;int64&lt;/code&gt;。这些类型必须与模糊处理的参数完全类型匹配、顺序一致。这些类型的模糊测试目标会是这样的：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;f.Fuzz(func(*testing.T, []byte, int64) {})&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;指定自定义种子语料库的最简单方法是使用&lt;code&gt;(*testing.F).Add&lt;/code&gt;方法。在上面的例子中，可以这样操作：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;f.Add([]byte(&lt;span&gt;&quot;hello\\xbd\\xb2=\\xbc ⌘&quot;&lt;/span&gt;), int64(572293))&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，可能有一些大的二进制文件，你不希望将其作为代码复制到你的测试中，而是作为单独的种子语料库条目保留在 &lt;code&gt;testdata/fuzz/{FuzzTestName}&lt;/code&gt; 目录下。&lt;code&gt;file2fuzz&lt;/code&gt;工具可以用来将这些二进制文件转换成以 &lt;code&gt;[]byte&lt;/code&gt; 编码的语料库文件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如此使用该工具:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;$ go install golang.org/x/tools/cmd/file2fuzz@latest&lt;br/&gt;$ file2fuzz&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;/h4&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;3&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;相关资源&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.11&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_svg/Ib5852jAybicPam0Snw7000AS1gf883SNuia90CEuiaBJzed3E0ro4A34pibwxqfHFicdoEsXll4GTWfstNru18ibLHoSTQlT8tdLC/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;300&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;教程:&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;关于用 Go 进行模糊测试的介绍性教程，请参见博文&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;更多内容即将来临!&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;文档:&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;testing&lt;/code&gt;包文档描述了在编写模糊测试时使用的&lt;code&gt;testing.F&lt;/code&gt;类型&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;cmd/go&lt;/code&gt; 包文档描述了与模糊处理相关的标志&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;技术细节:&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;设计初稿（https://golang.org/s/draft-fuzzing-design）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;提案（https://golang.org/issue/44551）&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;/h4&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;4&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;词汇表&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.11&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_svg/Ib5852jAybicPam0Snw7000AS1gf883SNuia90CEuiaBJzed3E0ro4A34pibwxqfHFicdoEsXll4GTWfstNru18ibLHoSTQlT8tdLC/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;300&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;语料库条目（corpus entry）&lt;/strong&gt;: 语料库中的一条输入记录，可以在模糊测试时使用。这可以是一个特殊格式的文件，或者是对&lt;code&gt;(*testing.F).Add&lt;/code&gt;的调用&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;覆盖面指导（coverage guidance）&lt;/strong&gt;: 一种使用代码覆盖率的扩展来确定哪些语料库条目值得保留以供将来使用的模糊测试方法&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;模糊目标（fuzz target）&lt;/strong&gt;: 模糊测试的函数，用来在模糊测试时执行语料库条目和生成对应的值。它通过向&lt;code&gt;(*testing.F).Fuzz&lt;/code&gt;传递函数来提供给模糊测试&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;模糊测试（fuzz test）&lt;/strong&gt;: 测试文件中用于模糊处理的一个函数，其形式为&lt;code&gt;func FuzzXxx(*testing.F)&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;模糊化（fuzzing）&lt;/strong&gt;: 一种自动测试，它不断地操纵程序的输入，以发现代码潜在问题，如错误或漏洞&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;模糊参数（fuzzing arguments）&lt;/strong&gt;: 传递给模糊目标的类型，并由mutator进行变异处理&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;模糊引擎（fuzzing engine）&lt;/strong&gt;: 一个管理模糊处理的工具，包括维护语料库、调用突变器、识别新的覆盖范围和报告错误&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;生成的语料库（generated corpus）&lt;/strong&gt;: 一个语料库，它由模糊引擎在模糊处理过程中长期维护，以跟踪进展。它被保存在&lt;code&gt;$GOCACHE/fuzz&lt;/code&gt;中&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;突变器（ mutator）&lt;/strong&gt;: 一个在模糊处理时使用的工具，在将语料库条目传递给模糊处理目标之前，对其进行随机处理&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;包（package）&lt;/strong&gt;: 同一目录下的源文件的集合，这些文件被编译在一起。请参阅 Go 语言规范中的 Packages 部分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;种子语料库（seed corpus）&lt;/strong&gt;: 用户为模糊测试提供的语料库，可用于指导模糊测试引擎。它由模糊测试中f.Add调用添加的语料库条目，以及软件包中testdata/fuzz/{FuzzTestName}目录下的文件组成&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;测试文件（test file）&lt;/strong&gt;: 一个格式为 xxx_test.go 的文件，可以包含测试、基准、例子和模糊测试&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;漏洞（vulnerability）:&lt;/strong&gt; 一种代码中安全敏感的弱点，可被攻击者所利用&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;5&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;反馈&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.11&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_svg/Ib5852jAybicPam0Snw7000AS1gf883SNuia90CEuiaBJzed3E0ro4A34pibwxqfHFicdoEsXll4GTWfstNru18ibLHoSTQlT8tdLC/640?wx_fmt=svg&quot; data-type=&quot;svg&quot; data-w=&quot;300&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你遇到任何问题或有一个关于功能的想法，欢迎提交问题（https://github.com/golang/go/issues/new?&amp;amp;labels=fuzz）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于该功能的讨论和一般反馈，也可以参与 Gophers Slack 的#fuzzing 频道（https://gophers.slack.com/archives/CH5KV1AKE）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d8a1752c60f0d16fe2807d0f6663077b</guid>
<title>猫咪招财喜庆铃铛项圈，原价26元，点击链接立减10元！</title>
<link>https://toutiao.io/k/kln056s</link>
<content:encoded>&lt;div&gt;&lt;body data-spm=&quot;10720394/n&quot; id=&quot;readabilityBody&quot;&gt;
    
    
    
    
    
    
      
      
    
    
    
    
    
  &lt;/body&gt;
&lt;/div&gt;</content:encoded>
</item>
</channel></rss>