<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>afebc7932b635e04f645bf623c43ba46</guid>
<title>百亿级小文件存储，JuiceFS 在自动驾驶行业的最佳实践</title>
<link>https://toutiao.io/k/lbsevhj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;post_content markdown&quot;&gt;&lt;p&gt;自动驾驶是最近几年的热门领域，专注于自动驾驶技术的创业公司、新造车企业、传统车厂都在这个领域投入了大量的资源，推动着 L4、L5 级别自动驾驶体验能尽早进入我们的日常生活。&lt;/p&gt;&lt;p&gt;自动驾驶技术实现的核心环节是自动驾驶模型的训练，训练数据是由汽车实际采集回来的真实道路驾驶视频，数据规模有数 PB 到数十 PB 之多。在模型训练之前，先要对这些原始视频进行处理，截取其中的关键帧保存为照片。然后再由专业数据标注团队在图片上标记关键信息，比如红绿灯、道路标记等。最终经过标记的数十亿图片和标记数据成为真正要「喂给」训练框架的内容。&lt;/p&gt;&lt;p&gt;熟悉分布式系统和分布式存储的朋友一定知道，LOSF（Lots of Small Files，海量小文件）是存储领域的大难题。而在人工智能 CV（Computer Vision）领域中基于 LOSF 的训练又是刚需，包括自动驾驶、人脸识别、物体检测等细分领域。&lt;/p&gt;&lt;p&gt;本篇文章来自 JuiceFS 某自动驾驶行业客户的架构实践，在百亿规模小文件训练场景下进行了一系列成功的探索，希望能为相关行业的应用带来一些参考和启发。&lt;/p&gt;&lt;h2 id=&quot;百亿小文件管理的极致挑战&quot;&gt;百亿小文件管理的极致挑战&lt;/h2&gt;&lt;p&gt;自动驾驶系统的训练数据集大多有数十亿到数百亿小文件（小于 1MiB 的文件），一次训练通常需要数千万到数亿文件。而且训练 worker 每一次生成 mini-batch 都需要频繁访问存储系统，其中大部分是对元数据的请求，因此，元数据性能直接影响模型训练的效率。&lt;/p&gt;&lt;p&gt;这就要求存储系统不仅要具备管理百亿文件的能力，还必须在高并发请求下，保持低时延、高吞吐的元数据性能。&lt;/p&gt;&lt;p&gt;在存储系统选型中，对象存储是能够承载百亿规模文件的，但是缺少原生目录支持、缺少完整 POSIX 语义支持、元数据性能弱这三方面的问题让对象存储并不适合海量小文件训练场景。&lt;/p&gt;&lt;p&gt;在一些常见的分布式文件系统架构设计中，HDFS 并不适合存储小文件，虽然可以采用 Scale-Up NameNode 和联邦（federation）的方式容纳一定规模的数据，但要存储百亿级小文件依然是一件非常困难的事情；CephFS 的 MDS 虽然有 Scale-Out 能力，但单进程的并发处理能力不高，随着 MDS 集群规模的增长进程间协调开销增大，使得整体性能达不到线性增长。&lt;/p&gt;&lt;p&gt;虽然在 TensorFlow 中支持将多个小文件合并成大文件的 TFRecord 格式来降低训练过程中对存储系统的元数据负载压力，但是在自动驾驶领域，这种方案降低了数据集随机取样的精度，而且其它训练框架（如 PyTorch）也不兼容，造成很多不便。&lt;/p&gt;&lt;h3 id=&quot;juicefs-如何解决&quot;&gt;JuiceFS 如何解决？&lt;/h3&gt;&lt;p&gt;JuiceFS 是面向云原生环境设计的开源分布式文件系统，JuiceFS 的创新在于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;可以用任意对象存储作为数据持久层，保存数据内容。无论任何公有云、私有云环境，只要有对象存储服务，都能用 JuiceFS；&lt;/li&gt;&lt;li&gt;100% 兼容 POSIX、HDFS、S3 三大主流访问协议，能对接所有应用；&lt;/li&gt;&lt;li&gt;元数据引擎是可插拔架构，支持包括 Redis、TiKV、MySQL 等多种数据库作为存储引擎，同时，也提供兼具高性能和海量存储的商用元数据引擎。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;JuiceFS 的商用元数据引擎采用 Raft 算法组成分布式集群，保证数据的可靠性、一致性和高可用性。元数据全部存储在节点的内存中，保证低时延响应。元数据引擎采用动态目录树方案进行横向扩展，每个分片（shard）是一个独立的 Raft 组，文件系统目录树可以任意划分，分配到需要的分片中，自动均衡与手动均衡相结合。分片机制对于客户端访问透明。&lt;/p&gt;&lt;h2 id=&quot;灵活配置缓存大幅提升训练效率&quot;&gt;灵活配置缓存大幅提升训练效率&lt;/h2&gt;&lt;p&gt;既然训练任务需要频繁访问存储系统，每次经过网络的开销叠加起来也是不小的冗余，目前工业界都在探索存储与计算分离后的缓存加速方案。JuiceFS 已经内置了缓存能力，客户端访问过的数据，可以自动缓存在该节点指定的存储介质上，下次访问就能直接命中缓存，不用再通过网络读取。同样，元数据也会自动缓存到客户端内存中。&lt;/p&gt;&lt;p&gt;缓存机制在使用上是透明的，无需改变现有应用，只要在 JuiceFS 客户端挂载时添加几个参数，说明缓存的路径、容量等信息即可。缓存对于训练加速的效果非常明显，可以参考我们另外一篇文章&lt;a href=&quot;https://juicefs.com/blog/cn/posts/how-to-use-juicefs-to-speed-up-ai-model-training-by-7-times&quot;&gt;「如何借助 JuiceFS 为 AI 模型训练提速 7 倍」&lt;/a&gt;。缓存不仅能加速训练，还能显著减少对象存储 API 的调用，从而降低费用开销。&lt;/p&gt;&lt;p&gt;对于分布式训练平台来说，相同的训练数据可能会被不同的任务共享，这些任务不一定会被调度到同一个节点上，如果是分布在不同节点那缓存数据还能共享吗？利用 JuiceFS 的&lt;a href=&quot;https://juicefs.com/docs/zh/cache.html#client-cache-sharing&quot;&gt;「缓存数据共享」&lt;/a&gt;特性，多个训练节点共同组成一个缓存集群，在这个集群中的训练任务都可以共享缓存数据。也就是说当训练任务所处的节点没有命中缓存时，能够通过同一集群中的其它节点来获取数据，而不用去请求远端的对象存储。&lt;/p&gt;&lt;p&gt;训练节点可能不是一个静态的资源，特别是在容器平台里，生命周期的变换是很快的，是否会影响缓存数据共享的效果呢？这就要引出下一个问题。&lt;/p&gt;&lt;h3 id=&quot;缓存机制在弹性集群中的挑战&quot;&gt;缓存机制在弹性集群中的挑战&lt;/h3&gt;&lt;p&gt;每一家自动驾驶领域的公司都有很多算法研究员、工程师，他们的算法要共享公司的计算资源完成训练和验证。从平台角度讲，资源弹性伸缩是一个提高整体利用率的好方法，按需给每个训练任务分配资源，避免浪费。&lt;/p&gt;&lt;p&gt;但在这种弹性伸缩的集群中，前面提到的本地缓存数据会受到一定影响。虽然缓存集群通过一致性哈希确保了当集群成员发生变化时，需要迁移的数据尽量少，但是对于大规模的训练集群来说这样的数据迁移还是会对整体的训练效率造成影响。&lt;/p&gt;&lt;p&gt;有没有一种方法既能满足训练集群资源弹性伸缩的需求，又不显著影响模型训练效率呢？&lt;/p&gt;&lt;p&gt;这就需要 JuiceFS 独有的&lt;a href=&quot;https://juicefs.com/docs/zh/cache.html#independent-cache-cluster&quot;&gt;「独立缓存集群」&lt;/a&gt;特性了。&lt;/p&gt;&lt;p&gt;所谓独立缓存集群，就是将负责存储缓存数据的节点独立部署，提供常驻的缓存数据服务。这样不会受训练集群动态变化的影响，让训练任务有更高、更稳定的缓存命中率。&lt;/p&gt;&lt;p&gt;整体系统的架构如下图所示：&lt;/p&gt;&lt;p&gt;比如有一个动态的训练集群 A 和专门用来做缓存的集群 B，他们都需要使用相同的挂载参数 &lt;code&gt;--cache-group=CACHEGROUP&lt;/code&gt; 来构建一个缓存组，其中集群 A 的节点挂载时需要加上 &lt;code&gt;--no-sharing&lt;/code&gt; 参数。当集群 A 的应用读数据时，如果当前节点的内存和缓存盘上没有该缓存数据，它就会根据一致性哈希从集群 B 中选择一个节点来读取数据。&lt;/p&gt;&lt;p&gt;此时整个系统由 3 级缓存构成：训练节点的系统缓存、训练节点的磁盘缓存、缓存集群 B 中的缓存，用户可以根据具体应用的访问特点配置各个层级的缓存介质和容量。&lt;/p&gt;&lt;p&gt;为了确保当磁盘损坏时不会对训练任务产生影响，JuiceFS 还提供了缓存数据容灾能力。如果缓存节点的磁盘意外损坏，更换新的磁盘后 JuiceFS 可以自动重建需要的缓存数据。&lt;/p&gt;&lt;h2 id=&quot;如何实现混合云中的降本增效&quot;&gt;如何实现混合云中的降本增效？&lt;/h2&gt;&lt;p&gt;自动驾驶的训练任务需要大量的 GPU 资源，在充分利用的情况下，自己在机房中采购 GPU，可以比使用公有云便宜不少，这也是目前很多自动驾驶公司的选择。但是，在机房中自建存储系统则没这么简单，会遇到两个挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据增长快，采购很难跟上扩容速度，一次买太多，又会造成浪费；&lt;/li&gt;&lt;li&gt;维护大规模的存储集群，必须面对磁盘损坏等问题，运维成本高，效率低；&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;相比自建存储系统，公有云上的对象存储服务可以弹性伸缩，无限扩容，单位成本便宜，数据的可靠性和服务的可用性相比机房自建存储都更高，是存储海量数据的不错选择。&lt;/p&gt;&lt;p&gt;JuiceFS 非常适合这种 IDC 机房 + 公有云的混合云架构。用户将自己的 IDC 机房与公有云专线连接，数据通过 JuiceFS 持久化到公有云对象存储中，在 IDC 机房里设置一个缓存集群，起到缓存数据加速训练的效果，相比每次从对象存储访问数据，既能节省专线带宽，还能节省对象存储 API 调用费用。&lt;/p&gt;&lt;p&gt;当混合云架构结合 JuiceFS 之后，既享受了云存储带来的便利，又通过自建 IDC 降低了 GPU 成本。对于训练平台的使用者、维护者来说都非常简单方便，满足企业多样化的基础设施架构设计需求。&lt;/p&gt;&lt;h2 id=&quot;多机房的数据同步与管理&quot;&gt;多机房的数据同步与管理&lt;/h2&gt;&lt;p&gt;在这个实践案例中，客户有两个 IDC，相距上千公里，训练任务也会被分配到两个 IDC 中，因此数据集也需要在两个 IDC 中被访问。之前，客户是手工维护将数据集复制到两个 IDC 中。使用 JuiceFS 后，&lt;a href=&quot;https://juicefs.com/docs/zh/mirror.html&quot;&gt;「数据镜像」&lt;/a&gt;特性可以省去此前的手工劳动，数据实时同步，满足多地协同工作的需求。&lt;/p&gt;&lt;p&gt;具体来说，数据镜像功能需要在两个 IDC 中都部署 JuiceFS 的元数据集群，当数据镜像启用后，原始文件系统会自动将元数据复制到镜像区域。镜像文件系统被挂载后，客户端会从原始文件系统的对象存储拉取数据，写入到镜像文件系统的对象存储。镜像文件系统挂载后，数据会优先从本地的对象存储读取，如果因同步未完成而出现读取失败，则会尝试从原始文件系统的对象存储读取。&lt;/p&gt;&lt;p&gt;启用数据镜像后，所有数据可以自动复制到两个对象存储中，起到异地灾备的作用。如果不需要异地灾备，在镜像区域可以不配置对象存储，只进行元数据的复制，数据可以提前预热到镜像区域的独立缓存集群来加速训练。这样可以省去一份对象存储的成本，本案例中的客户就采用了此方案。&lt;/p&gt;&lt;h2 id=&quot;全方位数据安全保护&quot;&gt;全方位数据安全保护&lt;/h2&gt;&lt;p&gt;不管是为了实现辅助驾驶还是真正的自动驾驶，日常都需要通过路采车收集大量的路采数据，这些数据会再经过一些处理流程二次加工以后最终存储到企业的存储系统中。自动驾驶企业对于这些数据的安全性和可靠性有着极高的要求，因此数据保护是一个非常关键的问题。&lt;/p&gt;&lt;p&gt;我们首先来看看企业上云以后的安全问题。很多时候企业对于上云会存在一定的数据安全担忧，特别是当涉及到一些敏感数据时。JuiceFS 提供的&lt;a href=&quot;https://juicefs.com/docs/zh/encryption.html&quot;&gt;「数据加密」&lt;/a&gt;特性同时支持传输中加密（encryption in transit）和静态加密（encryption at rest），保障上云过程中各个环节的数据安全性。&lt;/p&gt;&lt;p&gt;其次可能面临的是数据管理问题。为了防止数据泄漏或误操作，企业可能需要针对不同团队、不同用户进行权限管理和控制。JuiceFS 托管服务通过&lt;a href=&quot;https://juicefs.com/docs/zh/metadata.html&quot;&gt;「访问令牌」&lt;/a&gt;可以限定某个 IP 范围的读写权限以及可访问的子目录。挂载之后，JuiceFS 支持基于「用户/用户组」 的权限管理模型，可以灵活针对团队或者个人进行权限设置。&lt;/p&gt;&lt;p&gt;如果某个用户已经具备访问某些数据的权限，也还是需要进一步对数据进行保护，比如用户可能误删除或者误更新数据。对于误删除，JuiceFS 托管服务提供的&lt;a href=&quot;https://juicefs.com/docs/zh/trash.html&quot;&gt;「回收站」&lt;/a&gt;功能可以确保数据被删除以后的一段时间内能够再次恢复。&lt;/p&gt;&lt;p&gt;但是如果数据被误更新了或者因为某种原因损坏了，即使有回收站也无济于事，此时 JuiceFS 的&lt;a href=&quot;https://juicefs.com/blog/cn/posts/juicefs-realtime-data-protect&quot;&gt;「实时数据保护」&lt;/a&gt;特性就非常有用了。这个功能的实现原理是保留一定时间的 Raft 日志，这样当数据误更新发生时可以通过回放历史日志的方式将当时的元数据恢复。同时由于 JuiceFS 写入对象存储的文件是分块（block）存储，更新文件不会修改历史的 block 而是生成新的 block，因此只要对象存储上的历史 block 还没有被删除就可以完整恢复数据，就像一个可以随时时光倒流的「时间机器」一样！&lt;/p&gt;&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;&lt;h3 id=&quot;完整架构设计&quot;&gt;完整架构设计&lt;/h3&gt;&lt;p&gt;下图是本案例的整体架构图，在机房 A、B 中都部署了 JuiceFS 的元数据集群以及对应的独立缓存集群，模型训练时将会优先通过缓存集群读取数据集，如果缓存没有命中再从对象存储读取数据。在实际测试中，因为缓存命中率非常高，机房 B 几乎不需要跨机房访问对象存储。&lt;/p&gt;&lt;p&gt;下图描述了数据写入流程。客户通过 JuiceFS 提供的 S3 网关写入数据。当新数据写入以后，就会按照前面介绍的数据镜像流程来将元数据复制到另一个机房。同时在两个机房中都有对应的任务负责预热独立缓存集群，确保新数据能够及时建立缓存。&lt;/p&gt;&lt;h3 id=&quot;客户收益&quot;&gt;客户收益&lt;/h3&gt;&lt;p&gt;这套方案已经上线到客户生产环境中，下面列一些重要指标：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;已经存储了数十亿的文件，仍在持续增长；&lt;/li&gt;&lt;li&gt;JuiceFS 元数据在数十万 QPS 压力下依然能提供 1ms 时延响应；&lt;/li&gt;&lt;li&gt;模型训练吞吐数十 GiB/s；&lt;/li&gt;&lt;li&gt;独立缓存集群命中率 95%+；&lt;/li&gt;&lt;li&gt;两个 IDC 之间数据同步的平均时延在数十毫秒级别。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过升级到基于 JuiceFS 的存储系统，客户不仅能够轻松管理好海量数据集，同时借助 JuiceFS 的独立缓存集群特性保证了模型训练的效率。&lt;strong&gt;运维成本显著降低的同时，机房 + 公有云的混合云架构相比单一公有云的架构 TCO 也更低，既能利用机房高性价比的计算资源，也能结合公有云上弹性的存储资源。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;得益于 JuiceFS 完全兼容 POSIX 的特性，客户在迁移过程中，训练任务的代码不需要做任何修改。&lt;/p&gt;&lt;p&gt;通过 JuiceFS 的数据镜像特性，自动地将数据从一个机房同步到另一个机房，解决多地协作问题，也满足了企业异地灾备的需求。&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>ca009e93a12b5509b5684f52a55f3edf</guid>
<title>如何将代码同时提交到 GitHub 和码云 Gitee 上</title>
<link>https://toutiao.io/k/ni72ekk</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;主页：https://gozhuyinglong.github.io&lt;/p&gt;&lt;p&gt;Gitee：https://gitee.com/gozhuyinglong/blog-demos&lt;/p&gt;&lt;p&gt;Github：https://github.com/gozhuyinglong/blog-demos&lt;/p&gt;&lt;p&gt;微信搜索：码农StayUp&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相信很多写开源项目的小伙伴都会将代码托管到Github上，但随着近些年码云Gitee的火热，也有不少用户选择码云做为远程仓库。为了提高开源项目的曝光度，会选择将代码同时在两个平台进行托管。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么如何将代码同时提交到Github和Gitee上呢？本文将进行详细介绍，并列出常见错误及解决方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文目录：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5460526315789473&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BXKXSFic7o21LqMAk9Xiacnh5OQA3BYGfsWQHRiazsPxZGn4PPshOAIepjXZI6lDEAbgY2KHNvva5XUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1216&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1. 多个远程仓库的使用&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;多个远程仓库在项目中很少使用，但Git本身是支持的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那让我们跟着一个案例来温习一下Git命令吧：案例代码已经在Github中托管了，现在要增加Gitee远程仓库。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;1.1 查看远程仓库&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先来查看下当前项目的远程仓库&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;git remote&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不出意外，应该会输出：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;origin&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个&lt;code&gt;origin&lt;/code&gt;就是一个指向远程仓库的名称，是你在&lt;code&gt;clone&lt;/code&gt;时 &lt;code&gt;git&lt;/code&gt; 为你默认创建的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以通过命令查看&lt;code&gt;origin&lt;/code&gt;指向的远程仓库地址：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;git remote -v&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输出结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;origin  https://github.com/gozhuyinglong/blog-demos.git (fetch)&lt;br/&gt;origin  https://github.com/gozhuyinglong/blog-demos.git (push)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该命令会显示读写远程仓库的名称和地址，我这里指向的是Github。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;1.2 远程仓库重命名&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;既然这个地址是Github，为了好识别，就将名称改成 github 吧。输入命令：&lt;code&gt;git remote rename &amp;lt;old_remote&amp;gt; &amp;lt;new_remote&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;git remote rename origin github&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输入查看远程仓库命令，验证下是否成功，输出结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;github  https://github.com/gozhuyinglong/blog-demos.git (fetch)&lt;br/&gt;github  https://github.com/gozhuyinglong/blog-demos.git (push)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;成功！&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;1.3 添加另一个远程仓库&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我们再添加Gitee上的远程仓库，首先在Gitee上创建一个空的仓库，名称与Github上相同。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后在【克隆/下载】处复制地址。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.549079754601227&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BXKXSFic7o21LqMAk9Xiacnh5VdqhhlByWsvWm7nsHG5d4Mf8CuGKOqiacDpCjsib3RAm7T7RXHhvtpxA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;326&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输出添加远程仓库命令：&lt;code&gt;git remote add &amp;lt;remote&amp;gt; &amp;lt;url&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;git remote add gitee https://gitee.com/gozhuyinglong/blog-demos.git&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再来验证下是否成功，输出结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;gitee   https://gitee.com/gozhuyinglong/blog-demos.git (fetch)&lt;br/&gt;gitee   https://gitee.com/gozhuyinglong/blog-demos.git (push)&lt;br/&gt;github  https://github.com/gozhuyinglong/blog-demos.git (fetch)&lt;br/&gt;github  https://github.com/gozhuyinglong/blog-demos.git (push)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;成功！&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;1.4 多个远程仓库的推送/拉取&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有了多个远程仓库，推送和拉取再也不能像以前那样&lt;code&gt;git push&lt;/code&gt;和&lt;code&gt;git pull&lt;/code&gt;了，必须得加上远程仓库的名称，以识别操作的是哪个远程仓库。命令如下：&lt;code&gt;git push &amp;lt;remote&amp;gt; &amp;lt;branch&amp;gt;&lt;/code&gt;、&lt;code&gt;git pull &amp;lt;remote&amp;gt; &amp;lt;branch&amp;gt;&lt;/code&gt;：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;git push github main&lt;br/&gt;git pull github main&lt;br/&gt;&lt;br/&gt;git push gitee main&lt;br/&gt;git pull gitee main&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果不想每次操作都带着分支，需要将本地分支与远程分支进行关联：&lt;code&gt;git branch --set-upstream-to=&amp;lt;remote&amp;gt;/&amp;lt;remote_branch&amp;gt; &amp;lt;local_branch&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;git branch --set-upstream-to=gitee/main main&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关联后就可以不指定分支了&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;git push github&lt;br/&gt;git pull github&lt;br/&gt;&lt;br/&gt;git push gitee&lt;br/&gt;git pull gitee&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;1.5 移除一个远程仓库&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果想要移除一个远程仓库，可以使用下面命令：&lt;code&gt;git remote remove &amp;lt;remote&amp;gt;&lt;/code&gt;或&lt;code&gt;git remote rm &amp;lt;remote&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;git remote remove gitee&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;执行移除远程仓库后，该仓库在本地的所有分支与配置信息也会一并删除。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2. 常见错误及解决方案&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在执行上面操作当然不是一帆风顺的，如果你遇到一些错误，这里可能有你想要的答案。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.1 提示未指定分支&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当在拉取时报下面错误：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;You asked to pull from the remote &lt;span&gt;&#x27;gitee&#x27;&lt;/span&gt;, but did not specify&lt;br/&gt;a branch. Because this is not the default configured remote&lt;br/&gt;&lt;span&gt;for&lt;/span&gt; your current branch, you must specify a branch on the &lt;span&gt;command&lt;/span&gt; line.&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;表示本地分支与远程分支未做关联，进行关联一下即可，执行下面命令：&lt;code&gt;git branch --set-upstream-to=&amp;lt;remote&amp;gt;/&amp;lt;remote_branch&amp;gt; &amp;lt;your_branch&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;git branch --set-upstream-to=gitee/main main&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.2 没有存储库的权限&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当执行推送操作时，提示下面信息：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;remote: You &lt;span&gt;do&lt;/span&gt; not have permission push to this repository&lt;br/&gt;fatal: unable to access &lt;span&gt;&#x27;https://gitee.com/gozhuyinglong/blog-demos.git/&#x27;&lt;/span&gt;: The requested URL returned error: 403&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;表示没有远程仓库的权限，应该首先查看远程仓库是否公开，再检查本地账号和密码是否正确。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.3 远程仓库未公开&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;登录Gitee，检查该代码库是否公司。若未公开，则设置为公开。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.4 Windows凭据中的账号和密码错误&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;打开控制面板，点击【用户账户】&lt;img data-ratio=&quot;0.5131578947368421&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BXKXSFic7o21LqMAk9Xiacnh523Kpcr6CibibZhBibOeI0lR6Be0P1wRAcXgfnYwrPGUKsEzKG2LgSEJicg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再点击【管理Windows凭据】&lt;img data-ratio=&quot;0.43130227001194743&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BXKXSFic7o21LqMAk9Xiacnh5M7icJFy9sgiboxcoXJ2jJdYtJzQBffMpT7xFsEctP0bx5FbUAt8VUm9A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;837&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;找到你的账号，修改账号和密码即可。&lt;img data-ratio=&quot;0.7583732057416268&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BXKXSFic7o21LqMAk9Xiacnh5Hcibc2pPnibQ9qmiaJ1EvDo8p4VceGibJW72hT7QztxSI9ic6n1Zz4OXJng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;836&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.5 删除Windows凭据，重新登录&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你也可以直接将Windows凭据删掉，当执行推送命令后，会弹出Windows安全中心登录框。&lt;img data-ratio=&quot;0.6162280701754386&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BXKXSFic7o21LqMAk9Xiacnh5I2MZyexCZgB4Eg200k9BHAl6gILtypCb5VEnCPPlrvOibGheX8yxGFg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;456&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输入你的账号或密码就可以了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.6 无法弹出Windows安全中心登录&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果无法弹出Windows安全中心登录框，则将其卸载掉，执行下面命令：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;git credential-manager uninstall&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再重新下载并安装，下载地址：https://github.com/microsoft/Git-Credential-Manager-for-Windows/releases&lt;img data-ratio=&quot;0.5568807339449541&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BXKXSFic7o21LqMAk9Xiacnh5GS8j8pIwfOvJs1xueTp4dianDID79280k483Fgn6RjPUpico5g95ib0Mw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1090&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.7 每次推送Github时弹出登录框，可以使用SSH地址&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下图所示，当你每次&lt;code&gt;push&lt;/code&gt;代码时，都会弹出下面登录框。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.0248756218905473&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BXKXSFic7o21LqMAk9Xiacnh57eVd7XIgbKZYsC18L1MCFMWbgxy9v4vXk905clCWuL5NXoBvXvvy5Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;402&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以将远程地址改为SSH地址：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.8385269121813032&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BXKXSFic7o21LqMAk9Xiacnh52u3Xz0sWhWEosmPQVNIJrx5ZaZvlfF69wo4DQ2mOYJd256VJTx97lQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;353&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;移除现在的github地址，重新添加ssh地址，具体代码参照上文。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;添加好地址后，还需要在github上设置SSH Key&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.8 生成SSH Key，并添加到Github&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输入下面命令来生成SSH Key，双引号内填写你的登录邮箱地址&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;ssh-keygen -t rsa -C &quot;xxxxx@xxxxx.com&quot; &lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果弹出下面提示，直接回车即可。（若已存在，会提示是否替换，输入Y再回车）&lt;img data-ratio=&quot;0.7413793103448276&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BXKXSFic7o21LqMAk9Xiacnh5Q6iaicXzu6hAIsvozTO06BeoNIONO8unVdg29GJap7CZlibpJ4RyOmzNw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;812&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;会在你的磁盘目录【C:\Users\你的用户名.ssh\】中生成公钥，将文件【id_rsa.pub】中的内存拷贝。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;打开github的【SSH and GPG keys】页面，添加即可：&lt;img data-ratio=&quot;0.4368159203980099&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BXKXSFic7o21LqMAk9Xiacnh5ZxEwLSIbGp9a6Qibnic2ZgLvmYsdfQA9J1zvo3s8Wbia6kicHzRuBst85g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1005&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;往期推荐&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9a01a363ad20b2f8e10165ae0054270b</guid>
<title>广告模块化设计与实现</title>
<link>https://toutiao.io/k/48fv42l</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;h2&gt;前言&lt;/h2&gt;&lt;p&gt;随着APP需求的不断迭代和团队人员规模的增加，代码的坏味道越来越多，编译时长变长、代码冲突增加、新需求的工期变长。面对这些问题模块化拆分是一个好的解决思路。合理的模块化拆分可以降低代码的耦合度，方便单个模块的调试、升级、测试等。本文将对Android模块化拆分做一个探索。&lt;/p&gt;&lt;h2&gt;目标&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100000309&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6333333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UZibibiaQhjHtlHQFwJ8vibzpGcTfkvKnYhuHCgaBlabaxY76rBVakwYOUO434r7e9ub24gC3q7nHnHdTcS3gu04Hg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;宿主：不做具体的功能实现，只负责组合业务模块，组装成一个完成的APP，即可以实现一套代码生成多APP&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;业务模块：将项目拆分成一个一个独立的module，可独立运行&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;基础组件层：与业务无关、与项目无关，所有项目都可以复用，包含各种开源库以及与业务无关的自研库&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;优点&lt;/h3&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;架构灵活，焦点分离&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;耦合低，模块间可自由组合、分解&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;方便单个模块功能调试、升级、测试，提高开发效率&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多人协作只负责单独模块，互不干扰&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;模块化实战-广告模块化拆分&lt;/h2&gt;&lt;h3&gt;现状&lt;/h3&gt;&lt;h3&gt;目标&lt;/h3&gt;&lt;h3&gt;实现方案&lt;/h3&gt;&lt;h4&gt;广告流程&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100000310&quot; data-galleryid=&quot;&quot; data-ratio=&quot;4.642045454545454&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UZibibiaQhjHtlHQFwJ8vibzpGcTfkvKnYhuwUqdP0MRb7If3drCAOp1A81ACZ84KdLhBYwbKMtQ5xoLrccpTruicibw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;352&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;广告流程接口化&lt;/h3&gt;&lt;p&gt;所有广告的加载流程都一致，将流程抽象到抽象类AdBaseImpl中，具体的广告sdk实现AdBaseImpl&lt;/p&gt;&lt;h3&gt;ARouter动态发现广告实现&lt;/h3&gt;&lt;p&gt;拆分各个广告的module，module中包括广告的aar、不同广告类型的实现类(继承AdBaseImpl)，module只对外提供一个ARouter的IAdInitProvider，在IAdInitProvider中初始化相应的广告sdk，并将实现类注册到AdFactory&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100000311&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6203703703703703&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UZibibiaQhjHtlHQFwJ8vibzpGcTfkvKnYhuqoNc44T89sgrt0H8gXO7dwB1bsycxHhHHljCCibUmQruRsZmaoiaQyPw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;普通包不依赖oppo、华为、小米的module，所以普通包apk ARouter init时是不能发现oppo、华为、小米的广告实现。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100000312&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6074074074074074&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UZibibiaQhjHtlHQFwJ8vibzpGcTfkvKnYhuG95LRCBVPF0FRTHCoI4CMWUFqjnCgY1pUg1RFHSkomjiaHgz3iayl03A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;oppo联运包不依赖华为、小米的module，所以普通包apk ARouter init时是能发现oppo的广告实现，但是不能发现华为、小米的广告实现。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;351&quot; data-fileid=&quot;100000313&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4884287454323995&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UZibibiaQhjHtlHQFwJ8vibzpGcTfkvKnYhu8eAgHwibZ7CcZpwuP0BOoJ2enKcwZMFE6zhOuIuyqV1icvBCpd1hNuMA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;821&quot;/&gt;&lt;/p&gt;&lt;br/&gt;&lt;p&gt;所有广告位可以根据providerId获取到具体的广告实现类，根据AdBaseImpl的流程填充广告&lt;/p&gt;&lt;h3&gt;接入文档&lt;/h3&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;新建module，添加广告的aar等；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;module的build.gradle中，使用implementation方式依赖aar，保证app中不会引用到aar中的代码；ARouter相关配置；依赖 base module&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;module中build.gradle &lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100000316&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.617965367965368&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UZibibiaQhjHtlHQFwJ8vibzpGcTfkvKnYhufZyn04diagE6DiaJRYO7bRIaEMDfcKhbVWk9gz4HhI45AE75pCX9SMVQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;924&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100000317&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.9063745019920318&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UZibibiaQhjHtlHQFwJ8vibzpGcTfkvKnYhuy3iaFL5uAa4Flxg8QoI4pGOHicfjDAmFaqut5j7J3XdtjJWsg4AsDLzQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1004&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;实现AdBaseImpl&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;542&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;491&quot; data-fileid=&quot;100000317&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6203703703703703&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UZibibiaQhjHtlHQFwJ8vibzpGcTfkvKnYhua6A1MeDIHeqibibCP7ITQciaFBBwXV8S0cLOeGmjOeDpMaWGH3e3vORxA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;实现IAdInitProvider接口，在ARouterConstant中定义ARouter的path，path的规范是/moduleName/(provider/activity/service)/业务/功能，例如/baiduAd/provider/ad/init&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;IAdInitProvider#initAdSAdk()中初始化sdk，也可以在使用的时候再延迟初始化；调用AdFactory.registerAdInterface注册广告的实现类&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100000319&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5222222222222223&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UZibibiaQhjHtlHQFwJ8vibzpGcTfkvKnYhuol4N3qvQlaMx7NdVlcLeEWGjBHhVicx9eic6X4MZHb84eiaUMGjNf6hKA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AdFactory的sInitPaths增加这个path&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;只有IAdInitProvider的实现类是public的，其他类都设置为包内可见，防止app中误用&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;踩坑之旅&lt;/h3&gt;&lt;p&gt;代码本身没有问题，这样做可以加快初始化速度。&lt;br/&gt;但对于版本号相同的不同的联运包之间相互覆盖却会出现ClassNotFound问题，不同联运包的代码是不相同的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b01676bfd1af226338ef9b4bd10c0110</guid>
<title>亿级流量架构演进实战：架构演进构建 TCP 长连接网关（四）</title>
<link>https://toutiao.io/k/6lus7y3</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p id=&quot;js_tags&quot; class=&quot;article-tag__list single-tag__wrp js_single&quot; data-len=&quot;1&quot; role=&quot;link&quot; aria-labelledby=&quot;js_article-tag-card__left&quot; aria-describedby=&quot;js_article-tag-card__right&quot;&gt;
                                            
                                                                                    &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__left&quot; class=&quot;article-tag-card__left&quot;&gt;
                                    &lt;span class=&quot;article-tag-card__title&quot;&gt;收录于话题&lt;/span&gt;
                                    &lt;span class=&quot;article-tag__item-wrp no-active js_tag&quot; data-url=&quot;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI3MDU5OTU0MA==&amp;amp;action=getalbum&amp;amp;album_id=2087433865563832322#wechat_redirect&quot; data-tag_id=&quot;&quot; data-album_id=&quot;2087433865563832322&quot; data-tag_source=&quot;0&quot;&gt;
                                        &lt;span class=&quot;article-tag__item&quot;&gt;#亿级流量架构演进实战&lt;/span&gt;
                                    &lt;/span&gt;
                                &lt;/span&gt;
                                &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__right&quot; class=&quot;article-tag-card__right&quot;&gt;5个&lt;span class=&quot;weui-hidden_abs&quot;&gt;内容&lt;/span&gt;&lt;/span&gt;
                                                                                        &lt;/p&gt;

                
                                
                
                

                
                                                                

                
                                


                
                
                
                
                                                
                                                                
                                
                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;这不是一个讲概念的专栏，而且我也不擅长讲概念，每一篇文章都是一个故事，我希望你可以通过这些故事了解我当时在实际工作中遇到问题和背后的思考，架构设计是种经验，我有幸参与到多个亿级系统的架构设计中，有所收获的同时也希望把这些收获分享与大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;承接上篇，网关是负责接口调用获取请求数据的，HTTP 属于单向操作，建客户端与服务平台的 TCP 双向通道，保持客户端与服务平台的会话状态，则可以提供更多、更灵活的技术实现和业务实现。在业务服务调用上通过 HTTP 网关，在平台服务调用上则通过 TCP 网关，实现平台与业务解耦，并且平台采用 TCP 通道还可以增加对平台的控制力，如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100000872&quot; data-ratio=&quot;0.48828125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/FAeR52xeN38eq9eAmDCtjIA4v7Zfc3sgYsxId1XU4o2TaPjwYZjKaiaicIaz4MrOicibpicdjzP8nQEiapyULlDIkwWA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;本文继续讲述构建 TCP 长连接网关的故事。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;1。Session 管理&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;网关为什么需要 Session 管理？因为 HTTP 网关是单向通信的短连接，是无状态的；而 TCP 网关是双向通信的长连接，是有状态的。所谓有状态，简单的理解，用户在 Web 网站登录会后浏览器会基于 Session 缓存用户的认证信息，以实现用户有状态下的服务访问。HTTP 网关 API 的安全访问目前是基于 OAuth2 技术，而 TCP 网关则可以通过长连接实现访问鉴权后基于 Session 管理实现 API 有状态下的服务访问。而且 TCP 属于 OSI 的传输层，所以建立 Session 管理机制构建会话层来提供应用层服务，可以极大的降低系统复杂度。&lt;/p&gt;&lt;p&gt;TCP 网关的 Session 是客户端与服务端建立的一次会话链接，会话信息中保存着 SessionId、连接创建时间、上次访问事件，以及 Connection 和 SessionListener 对象。因为 TCP 网关采用 Netty 框架，所以 Session 中的 Connection 保存了 Netty 的 ChannelHandlerContext 上下文信息。所有连接的 Session 会话信息会保存在 SessionManager 内存管理器中。&lt;/p&gt;&lt;p&gt;TCP 网关通过在 Netty 的 ChannelPipe 中加载自定义 ChannelHandler，构建 Container 容器，将每个 TCP Connection 封装到一个 Session 会话中，保存在 Container 容器中，由 Container 容器构建 Session Layer 提供 Logic 请求调用，如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100000874&quot; data-ratio=&quot;1.1997563946406822&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/FAeR52xeN38eq9eAmDCtjIA4v7Zfc3sg86QEn51Cx9vjW08VHoj2Eiaicib9n7aIot6wT9dsBo1YT3xjvNKVfsCqA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;821&quot;/&gt;&lt;/p&gt;&lt;p&gt;每一次 Session 的会话请求（ChannelRead）都是通过 Proxy 代理机制调用 Service 层，数据请求完毕后通过写入 ChannelHandlerConext 再传送到 Channel 中。同样，数据下行主动推送也是如此，通过 Session Manager 找到 Active 的 Session，轮询写入 Session 中的 ChannelHandlerContext，就可以实现广播或点对点的数据推送逻辑。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据上行&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;数据上行特指从客户端发送数据到服务端，数据从 ChannelHander 的 channelRead 方法获取数据。数据包括创建会话、发送心跳、数据请求等。这里注意的是，channelRead 的数据包括客户端主动请求服务端的数据，以及服务端下行通知客户端的返回数据，所以在处理 object 数据时，通过数据标识区分是请求-应答，还是通知-回复。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据下行&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;数据下行通过 MQ 广播机制到所有服务器，所有服务器收到消息后，获取当前服务器所持有的所有 Session 会话，进行数据广播下行通知。如果是点对点的数据推送下行，数据也是先广播到所有服务器，每天服务器判断推送的端是否是当前服务器持有的会话，如果判断消息数据中的信息是在当前服务，则进行推送，否则抛弃。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;2。心跳&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;心跳是用来检测保持连接的客户端是否还存活着，客户端每间隔一段时间就会发送一次心跳包上传到服务端，服务端收到心跳之后更新 Session 的最后访问时间。在服务端长连接会话检测通过轮询 Session 集合判断最后访问时间是否过期，如果过期则关闭 Session 和 Connection，包括将其从内存中删除，同时注销 Channel 等。&lt;/p&gt;&lt;p&gt;上文已提到，TCP 网关长连接容器的 Handler 就是放在 Pipeline 的中，所以，每一个 Channel 对应一个 Connection，一个 Connection 就对应一个 Session，Session 由 Session Manager 管理，Session 与 Connection 是一一对应，Connection 保存着 ChannelHandlerContext（ChannelHanderContext 可以找到 Channel），Session 通过心跳机制来保持 Channel 的 Active 状态。&lt;/p&gt;&lt;p&gt;当然，除了这种方法之外，还可以通过在服务端基于 Session Manager 发送心跳包检测客户端是否还活着，如果尝试无响应，则关闭 Session 和 Connection。&lt;/p&gt;&lt;p&gt;除此之外，Netty 框架也提供了 IdleStateHandler 方法，IdleStateHandler 会检测 channelRead 和 write 方法多久没有被调用了，如果长时间没有调用，就会调用 userEventTriggered 方法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;3。断线重连&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;客户端与服务端通过 TCP 长连接进行通信，但在中国复杂的网络环境下，移动客户端可能由于网络抖动、弱网络情况下，遭遇非正常网络闪断，如何处理断开后的断线重连？TCP 长连接断开之后，如果重连？如果处理断开后的连接再重连后，找到上一次连接的会话呢？&lt;/p&gt;&lt;p&gt;这个解决得益于 Netty 的 ChannelHandlerContext，它可以存储一些自定义属性到 Channel 的上下文中。在每次成功建立请求的 Channel 里存入 SessionId，将它作为一个钩子，当网络闪断后，再次请求建立连接的 Channel，可以通过判断是否存在 SessionId 的钩子，进行处理。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100000875&quot; data-ratio=&quot;0.57578125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/FAeR52xeN38eq9eAmDCtjIA4v7Zfc3sg9u3oKib20rk3Cjqplq4xkZI0Y6e289JHOqUw2Qhwt3iaBEzdlEYj2Trg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;客户端每通过 TCP 与服务端进行一次建连，都会在服务容器里创建一个 Session 会话，该会话保存 Connection 的句柄，对应 Netty 的一个 Channel 通道。建连成功后，通过定时的心跳保持 Channel 属于 Active 活跃。但客户端进入弱网络环境下，客户端可能已经掉线，但并未向服务端主动发送关闭 Channel 请求，而服务端仍认为该 Channel 仍存活。直到在由服务端的会话存活检测机制检测到 Channel 已经 InActive，才会由服务端销毁该 Channel。&lt;/p&gt;&lt;p&gt;服务端的会话存活检测是 5 分钟一次，所以存在客户端掉线后，在 5 分钟内又重新建连，而这时服务端的建连逻辑，不是重新创建一个 Session，而是去寻找上一次的 Session，并更新标识存活。具体的实现是在每次建连的 Channel 里存入 SessionId，当网络闪断后，判断 Channel 是否存在 Session，之所以实现是得益于 Netty 的 ChannelHandlerContext，可以存储一个自定义属性到 Channel 的上下文中。&lt;/p&gt;&lt;p&gt;当然，TCP 网关一定是集群，所以，断线重连也是极有可能请求到不同的服务器上，而这种情况按照新 Connection 创建的 Session 处理，只有出现重连到同一服务器时，才需要考虑上述的处理逻辑。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;4。总结&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;言而总之，本篇文章重点讲述了 TCP 网关的心跳、Session 管理、断线重连。下篇文章，我将介绍架构演进重构消息 PUSH 系统。如果你觉得有收获，欢迎你把今天的内容分享给更多的朋友。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;5。扩展阅读&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;故事1：从零构建亿级流量API网关&lt;/strong&gt;&lt;br/&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3MDU5OTU0MA==&amp;amp;mid=2247484496&amp;amp;idx=1&amp;amp;sn=30a3646447bf11623a0467edb1902b67&amp;amp;chksm=eacfd04bddb8595d6d4f94fa44733d887a7dd1b747ddf16c1b4d157daba375d0fce8304d0d82&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;01 | API网关：统一接入、分层架构、高可用架构&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;01 | API网关：统一接入、分层架构、高可用架构&lt;/a&gt;&lt;br/&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3MDU5OTU0MA==&amp;amp;mid=2247484503&amp;amp;idx=1&amp;amp;sn=0070063512585db2534e199902791733&amp;amp;chksm=eacfd04cddb8595a0ecace64fcf4ea438008f0394f177080470a7d55fc793a6d8da3a5f040c5&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;02 | 流量调度：配置中心、泛化调用&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;02 | 流量调度：配置中心、泛化调用&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;故事2：架构演进构建TCP长连接网关&lt;/strong&gt;&lt;br/&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3MDU5OTU0MA==&amp;amp;mid=2247484516&amp;amp;idx=1&amp;amp;sn=9b03daf2c78feb9ca3a6e6187c74b684&amp;amp;chksm=eacfd07fddb859698b1e45e247aa6efb3151fb111726ec2812598482ea8588e773652176d1f1&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;03 | TCP网关：Netty框架、Protobuf格式、业务线程池&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;03 | TCP网关：Netty框架、Protobuf格式、业务线程池&lt;/a&gt;&lt;br/&gt;04 | TCP长连接：心跳、Session管理、断线重连&lt;/p&gt;&lt;p&gt;&lt;strong&gt;故事3：架构演进重构消息PUSH系统&lt;/strong&gt;&lt;br/&gt;05 | 消息PUSH：消息推送、消息送达率、APNs&lt;/p&gt;&lt;p&gt;&lt;strong&gt;故事4：从焦油坑爬出来的交易系统&lt;/strong&gt;&lt;br/&gt;06 | 交易平台：订单管道、订单状态机、服务编排、任务引擎&lt;br/&gt;07 | 微服务化：服务治理、领域设计&lt;/p&gt;&lt;p&gt;&lt;strong&gt;故事5：烦人的焦油开始到处都是&lt;/strong&gt;&lt;br/&gt;08 | 新老系统：业务整合、数据融合、系统迁移&lt;br/&gt;09 | 高可用架构：隔离部署、系统监控与日志、可灰度、可降级&lt;/p&gt;&lt;p&gt;&lt;strong&gt;故事6：稳定性架构与大促保障&lt;/strong&gt;&lt;br/&gt;10 | 大道至简：系统复杂度、三明治架构&lt;br/&gt;11 | 大促保障：自动化测试、故障演练、性能压测&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>40cc4ca8c079e5165dcaa5ea2a0a41f3</guid>
<title>小米数据管理与应用实践</title>
<link>https://toutiao.io/k/h4oa2g3</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img __bg_gif&quot; data-backh=&quot;161&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;193&quot; data-fileid=&quot;100071921&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2777777777777778&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/lAStFsJ0Pm2BEnLgiaJjAGyHnnpJ4NzkDSicdCgIdCxBVMKkuQMDsx8iaX4ibXnbXFcRAjRECy6aJibGMUdQnI6hrtw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;249&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;289&quot; data-fileid=&quot;100071922&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.43156424581005587&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3za9ZjF1PvXiaYvUAQEUIAQibZrraoZw8pP1GSEbn8fWLb0HupP82ImOCA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1432&quot;/&gt;&lt;/section&gt;&lt;section data-width=&quot;100%&quot; data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot;&gt;&lt;section data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot; data-style=&quot;margin-bottom: -10px; margin-left: -8px; max-width: 100%; width: 18px; height: 18px; border-top: 8px solid rgb(54, 65, 173); border-left: 8px solid rgb(54, 65, 173); box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible;&quot;&gt;&lt;br data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot;/&gt;&lt;/section&gt;&lt;section data-bgopacity=&quot;50%&quot; data-darkmode-bgcolor-16008590572276=&quot;rgb(33, 33, 33)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(247, 247, 247)&quot; data-style=&quot;max-width: 100%; width: 543.333px; background: rgb(247, 247, 247); box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible;&quot;&gt;&lt;section data-darkmode-bgcolor-16008590572276=&quot;rgb(33, 33, 33)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(247, 247, 247)&quot;&gt;&lt;p data-darkmode-bgcolor-16008590572276=&quot;rgb(33, 33, 33)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(247, 247, 247)&quot;&gt;&lt;span&gt;分享嘉宾：勇幸 小米&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16008590572276=&quot;rgb(33, 33, 33)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(247, 247, 247)&quot;&gt;&lt;span&gt;编辑整理：曾新宇 对外经贸大学&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16008590572276=&quot;rgb(33, 33, 33)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(247, 247, 247)&quot;&gt;&lt;span&gt;出品平台：DataFunSummit&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-width=&quot;100%&quot; data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot;&gt;&lt;section data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot; data-style=&quot;max-width: 100%; width: 18px; height: 18px; border-bottom: 8px solid rgb(54, 65, 173); border-right: 8px solid rgb(54, 65, 173); box-sizing: border-box !important; overflow-wrap: break-word !important; visibility: visible;&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;导读：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;本文的主题为小米数据管理与应用实践，主要介绍小米在数据管理建设方面的理解和探索。数据管理的核心重点在于元数据平台的建设，用以支撑数据管理的上层应用，包括数据地图、数据规范治理、数据成本治理及数据质量建设，以及未来的规划。将围绕以下三个方向展开：① 元数据平台的建设；② 元数据应用；③ 未来规划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071924&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3z4kHicRDyA10sTEVvTyDX404keJJFY7GBDXVc1E4F8XKDcn7GKJ4Oplw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图1 元数据平台包含的内容&lt;/span&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;01&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;元数据平台的建设&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;小米元数据平台的建设内容，主要包括数据管理架构的现状、以及架构的演化过程。在建设元数据技术平台的过程中，针对以下三个方面进行了改进，也是平台进化的三个关键点：&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 元数据&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;元数据是用来描述数据的数据。请参见图2 。从抽象来看，包括分为实体、实体的属性以及实体与实体之间的关系三个方面来进行分类。实体主要指表元数据和作业元数据，来自于工程师在ETL的实际工作中所涉及到的系统。如：Hive、Doras、Kudu、MQ、ES、Iceberg，即传统的数仓及上下游。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如：实体包含了技术元数据和生产元数据。其中技术元数据用于支撑数据资产管理的资产地图；生产元数据，主要是作业的一些调度信息和运行信息，用于支撑数据资产管理的数据质量和成本治理的服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实体的属性，包含业务元数据和衍生元数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;业务元数据包括数仓分层、数据分类、指标关联、应用信息、隐私分级等内容。内容来源于建模规范、业务、指标系统、BI看板、数据报表，以及来自于业务的隐私分级定义等。业务元数据用于支撑资产管理的资产价值、安全治理以及规范治理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;衍生元数据包含元数据的存储计量和访问计量。存储计量是服务于存储层面的成本治理；访问计量用于描述数据的使用情况，从技术角度去衡量资产的价值。衍生元数据来源于ETL工作中涉及的HDFS-Image、Doris、Kudu、MQ、ES以及HDFS-Log、SQL-Log。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;描述实体的关系，包括血缘元数据，用于描述元数据之间的关联关系，用于支撑数据资产管理中的影响分析和资产地图服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071925&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3z9pRpLkOXcvV5LjUD58IwwPPfeGiaibTRsbaV7edQSkhvoJapQQYJCvDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 2 元数据分类&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 元数据平台技术架构&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;小米元数据平台的技术架构如图3所示，整体架构与Apache的Atlas非常相似。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整体上可以划分为三层。最上层是数据采集的源头，以及最终数据支撑的应用，包括Metadata Source、Lineage Source、Log Source和应用Application。中间层是集成层，集成层是由Metacat、MQ以及API层组成。最底层是核心的存储层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最上层的Metadata Source用于对表元数据采集。最早只限于Hive表，后来实现了全域元数据的采集。主要包括ETL整个生产链路及上下游的全链路。比如：元数据采自于业务的Mysql数据库。其中消息队列采用了小米自研的Talos，简单说实现了数据集成与分发的总线。而下游元数据的采集由Hive、Doris、ES、Kudu等实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100071926&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3z2hViaOgicsr5W3K6e2UxT8Q15gIxNVVNjAqF4RLTiaYWVEciaRUjtMFwzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 3 元数据平台技术架构&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lineage Source实现血缘信息采集。血缘元数据是来自于从各个计算引擎。通常血缘元数据是通过SQL的查询入口或者调度入口去采集。由于小米的业务特别多，且部门各自独立，因此入口也特别多，很难通过常规的入口采集的方式提升数据采集覆盖率。考虑到各部门的计算引擎都是在部门的计算平台进行维护，从而可以在引擎侧打点，实现血缘元数据的采集。同时结合SQL入口对SQL的审计日志做补充，两者的数据进行合并，得到较为满意的血缘元数据采集及采集覆盖率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lineage Source中的DataHub是小米内部的数据集成平台，包括离线整理集成和实时集成。DataHub集成平台也有上下游的血缘关系，也进行血缘元数据的采集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;日志层面调度日志、计量日志以及运行日志。这些日志跟质量建设和访问相关。Application应用，包含数据平台的上层应用、数据地图、成本治理、规范治理等内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在中间层的Metacat，是在采集诸多原图的元数据时，提供一个统一元数据的视角。所以通过基于Metacat进行二次定制开发，实现内部的各个系统的适配。元数据的采集统一通过Metacat实现，包括T+1和增量变更，都要通过Metacat来实现。因此，Metacat与Messaging连接起来，Metacat把每天增量变更送到Messaging。之后包含血缘信息的日志通过Messaging送到数据总线，使下游层面可以使用这些数据，通过API为上层应用提供数据服务和支撑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最底层的存储部分，基本信息都存储在Mysql中；T+1的快照存储在Hive中；血缘图关系存储在JanusGraph。元数据的检索，包括权限的检索过滤、审计检索等都放在ElasticSearch。&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. 全域元数据&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;元数据平台进化过程中，关键的演化点之一是全域元数据。之前提到元数据都是基于Hive进行管理，显然只能看到Hive层的数据，无法知道产生的Hive表，到下游后最终有没有被使用。举例来说，有一堆数据给上层应用，用于看板或者指标，产生了一张Doris表；但对应的看板可能并没有人看，所以可以通过倒推，把链路中的这一条链路进行优化或者治理。而实现这样的场景，就需要打通全链路，包括看板信息，搜索等，都需要全域元数据进行支撑。此时就需要进行域拓展。以Hive为中心去看上下游，包括上游的业务数据库、Messaging，下游的Doris、Kudu、ES，包括内部重构传统Hive 数仓的Iceberg，都要采集元数据。在实现全域的过程中，同时打开统一元数据的Hive Metastore，实现统一的表数据视角和管理。请参见图4。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071928&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3zAvGTakibvexOcL0kItiaM9GeYmeESBgACVLpfia7yBhib4ktLAjCEOfnVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 4 实现全域元数据&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4. 实时血缘&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;关键的演化点之二是实时血缘。如前所述，小米入口非常多，血缘关系采集很难实现面面俱到。最早采用解析HDFS日志的办法，存在血缘很难正确解析的问题。例如：读一个表，可能会有很多open操作，这些Open操作很难对应表和表之间的关系，就会带来血缘关系不准的问题。早期的解决方案是找出所有的读和写操作后，做一个笛卡尔乘积，但这样就会产生大量不存在的血缘。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上这些痛点严重影响了上层的数据治理，影响了解决问题的溯源过程。此外解析日志，由于只能T+1，认知量也比较大；而如果出现一个流式数据，就根本无法解析。这些都与通过SQL解析、能确定血缘的情况完全不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以在进化版的新版方案中，考虑到 了入口问题和引擎接入的改造成本问题。方案最终采用实时引擎MQ埋点的方案。同时各个引擎本身要去执行这个SQL，比如Hive、Flink、Spark等，包括Presto、Distcp。因为需要执行这种操作，本身就需要去解析执行计划。而Spark、Flink也都支持对这些操作。通过对血缘关系的解析进行了内部改造（请参见图5），整体运行流畅。同时结合SQL Proxy Log去做血缘关系整合，从而实现血缘关系的精准解析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071927&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3zvFIQfFoMTibxXaia1PIjibeJgCN1xScia8aE43iahIrbGvFUDxM18fwGm5g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 5 元数据实时血缘&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5. 精准计量&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;关键的演化点之三是精准计量。精准计量目前还不能做到完全精准的计量，但是解决了计量的零和一的问题。 在最早的入口问题中，计量不准就无法对数据的冷热程度进行判断。比如用户操作Hive表，会有各种各样的形式，通过各种各样的SQL。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尤其研发的种查询需求就很难应对。比如：Spark SQL分为常驻服务和非常驻服务，都是为了解决Spark SQL作业执行的启动问题。非常驻服务与Hive  SQL一样，每次都要有一个启动过程。常驻服务则可以及时响应SQL需求，直接执行，减少了几分钟的启动过程，其查询过程能够快速响应。还有Flink SQL、 Beeline、Flink  Jar和Spark Jar，包括Distcp想去覆盖这些入口的计量，访问情况的确定也是解析HDFS日志。通过这些日志解析血缘存在的问题，就是在Hive  Jar的层面，无法确定上层谁提交的访问。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计量部分现阶段解决了零和一的问题。简单的说当数据被访问后，能基本保证打上数据访问的标记。同时，通过与HDFS日志提供的足够信息、进行精准的统计和整理，并结合顶层的SQL审计进行修正后，可以得到具体被访问次数的精准计量。请参见图6。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071929&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3zGiclDZF6xWDMgs2oBPydXmDTebt4LtKlmu2XfVFcm6tsthDg1ew9GhA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 6 元数据精准计量&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面在元数据平台建设的基础上，讲述小米元数据应用在以下四个方面的进展：&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;02&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;数据地图&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;数据地图是元数据应用的典型应用，包含两个方面的内容：数据地图中数据的搜索和血缘关系。&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 数据地图-搜索&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;数据地图在业界已经是比较成熟的服务，小米的数据地图建设目前处在追赶阶段。数据地图需要支持元数据的搜索与发现，具体包括以下三个方面的内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;① 支持表、字段、描述信息、数仓分层、数据分类、标签、部门等信息搜索，即实现可对实体属性再加关系的数据进行的全域搜索；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;② 除了Hive 表，完善全域元数据概念中的其它引擎，如：Talos、Doris、Kudu、Iceberg、ES、MySQL等数据引擎；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;③ 实现支持对指标、维度、看板等信息的搜索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如：一个新零售的搜索，如图7的左侧所示。根据用户的收藏数据域分类打了标签。将大权重记录放在上面，搜索的结果更多的作为展示产品的形式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071930&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3zLMKt5WglEZhPVngfiaOiagHemla7ym4aqWPcEuVhWTCjdTt3Mk5Y25vQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 7 数据地图-搜索结果&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 数据地图-血缘&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;通过数据地图，可以更清晰展现数据之间的血缘关系。通过技术架构改造，实现了全链路的数据血缘，使不同系统的链路关系都能展示（如图8），包括 MySQL/MQ/Hive/Iceberg/Doris 等。这样用户就能很方便的从数据最早的源头，一直追溯到最上层的应用。大大方便了对问题的追溯，也更方便的实现对整体数据价值的评估。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据地图的后续建设会增加对血缘的搜索和变更通知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071931&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3zmoia8A3LibmvE6XELGNjIf4JH6LhvEPtsyxdvlXGwictibqfHEkkplSnrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 8 数据地图-血缘关系&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;03&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;数据规范治理&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;元数据应用中的重点应用是数据规范治理，对元数据的生态健康起到至关重要的作用。数据规范治理分为两个度量维度：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据规范治理通过以上两个维度作为指标，量化数据健康完善的程度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071932&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3z0Bfdg5fV3SMdIZaUduvNTVht6BDREwt7jbv4OxtmkuUXXcJKQpjcCw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 9 元数据应用-数据规范治理&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 建模规范度&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;建模规范度又分为以下三个方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;① 命名，是指表的命名是否符合收藏的规范；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;② 分层，是指表需要按照收藏的规范进行分层。比如：目前有超过70%的表是没有按照收藏的规范来分层。希望能结合一系列的整改措施，配合整体的数据治理，推动用户进行分层治理或者整改；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;③ 打标，是对业务板块数据域、标签等进行标记。&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 建模完善度&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;建模完善度包括以下二个方面：&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;04&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;数据成本治理&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;元数据应用中数据成本治理是优化数据使用成本最直接的部分。数据成本治理在元数据应用中是重点投入。因为小米的数据量增长比较快，整体的业务成本就上涨也比较多，对成本的诉求也比较高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071933&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3zRWO4pNCTnOJERgVqUykH6ibpdSIzuXE9TlKFaVypYRkLX4wLR4sOWCA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 10 元数据应用-成本治理&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 数据成本治理的起因&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;成本治理是从商务的角度出发，成本的根因最终回归到底层，即主机和整个网络这样的资源；再往上层应用追寻则是存储计算的资源。对主机的成本来说，从商务谈判层面，包括折扣已经做了很大的努力，单纯的再依赖商务层面，无法再挖掘成本优化的潜力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;存储计算的技术也在追赶阶段，尤其涉及到成本，比如：分层存储。此外计算层面的弹性算力也在建设过程中，很难快速把成本治理做到位，把成本降下来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在当商务已经达到极限，技术层面也在追赶业务，此时从元数据的角度思考成本优化，面临一个简单问题，业务不知道自己有多少数据，这些数据好比就是花了多少钱，最后这些钱到底花在哪里了，应该怎么优化，优化了之后会有什么反馈？。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对这个问题做了产品层面的分析优化的闭环，即成本分析优化闭环。这个闭环的关键环节简单称作：观现状、查问题、做优化、拿反馈。&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 数据成本治理方案&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;为了支撑成本分析优化闭环，对数据成本治理进行了改造。改造主要包括以下四个方面内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;① 数出一孔，指是使用的数据要跟底层HDFS存储的数据进行对齐，保证数据量的统一计量口径。在成本治理存储在计算中是指存储维度，存储本质上要回归到底层的数据存储。比如：HDFS层面存储的数据， 通过HDFS-Image计量最精确。它会精准的描述每一个文件到每一个路径、以及存储量。数据成本治理的首要工作就是数据与底层HDFS存储的数据对齐，保证存储量的数出一孔；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;② 天级帐单，由于数据太多，需要及时跟踪数据的费用优化情况。否则选定了数据，过一个月才说这个数据优化能省多少钱，反馈太长，难以完成闭环；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;③ 按人归属，明确数据对应的使用人。使用数据频度高的人，其名下的表也比较多，对应的的费用也比较高；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;④ 及时预估，对于任何一个数据相关的操作，都应该能及时预估、反馈数据量及成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些优化，确定到底能省多少钱？&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. 数据成本治理成果&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;通过提供成本分析优化的闭环能力，成本治理短期取得了不错的成果，合计优化了 40% 的数据，如图11所示，可以清晰的描述成本治理的效果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最上侧的曲线表示过去一年公司离线数据的增长趋势；下面的分叉线左侧黑色部分表示治理之前的历史成本曲线；右侧红色线表示顺着历史成本曲线，使用最小二乘模拟出未来业务正常增长情况下的成本曲线；蓝色横线表示假设业务不增长的成本控制线；最下面的橙色表示成本治理后实际的成本曲线；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;橙色线与红色线之间的 gap 就是成本治理的价值所在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071934&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3zYicpMAxQAmuNOBZ6xHMIWHNLWXq8FbDnDTNmRFQWel9M3QGoZgCpyjg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 11 元数据应用-成本治理&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;05&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;数据质量建设&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 数据质量建设的内容&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;首先数据质量建设中，采用了业界比较成熟的一些质量管理方法。如图12所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;小米的数据质量建设强调以下两方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;合格的数据产品具有以下特征：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;唯一性，即主键唯一准确；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;准确性，即数值要在一个范围内，符合预设数值要求，必须非空等条件；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;完整性，即每天产出数据的波动情况。如果出现较大的波动率，会影响完整性；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一致性，即数据在上下游的链路系统中，对特定字段进行一致性校验。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071935&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3zBIUPDSvnptAvicgXsGJ3zwXndwxoK1xUSiaxUJpjqPLWMdy6Vdn7U5YQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 12 元数据应用-质量建设&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 质量建设的技术架构&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;数据质量建设的技术架构，没有采用开源的技术架构，而是采用内部开发的方式。架构示意图所图13所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071936&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3zSfq0ice5Aw63mequDe8YTQGPib4QhZ7ujQsoxgpZmIbFH6lw9WZ83Fvw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 13 元数据应用-质量建设之技术架构&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;① 事件触发&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在图12中，最左侧是调度系统对DAG（有向无环图）执行完成、产出DAG对应的表后，专设用户会配置事件触发条件、触发对表的内容进行质量检查，以确定产出的表是否符合质量要求。进行的事件触发配置会把检查事件放在MQ中，质量系统则从消费视角，实现实时的事件触发。即把对内容的质量检查任务，直接挂载到调度系统DAG，在数据产出后，通过事件触发，实现自动对产出数据进行质量检查。&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;② 时间触发&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在图12中，架构的最上层就是RestServer，它是一个可扩展的接收器，接收上述质量规则的配置，或者查询及对结果的查询等。通过DB层面，触发触发器，实现时间触发。比如：业务不是通过DAG实现事件触发，而是可以通过设置的时间点去触发。&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;③ 可扩展无状态Worker&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;触发器连接下层的Worker实现服务的执行。Worker是无状态的、可扩展执行机。通过Worker可以实现支持多个数据源，比如：检查HDFS。通过Presto、Spark SQL以及Doris，实现对表的检查。&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;06&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;未来规划&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;根据元数据平台及元数据应用的需求，未来的规划包括三个方面：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;生产保障联动资源调度；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;元数据建设的长期路线；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;业务赋能。&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 生产保障联动资源调度&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;生产保障联动资源调度，是将生产保障从基线、到作业、到调度、到Yarn的全链路打通。包括基线管理、生产执行，还有监控预警等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;计算资源治理，目前还在开发进展中。如图14所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071937&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3z8p7m5GS4L9lkhYJLNkiaaIrw5G3fIDecVm3XibJ83Zia19PKzB2ryW22A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 14 数据管理与应用的未来规划&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 元数据建设的长期路线&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;元数据建设的长期路线就是数据管理，需要回答好两个问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综合元数据平台和元数据应用中的经验，要回答上述问题，需要从数据治理、数据模型规范、资源的使用与计量、数据安全与防范、数据价值及其挖掘等多方面考虑，进行规划和建设。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071938&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3zRkgaZQ9oZE23SQiagSYddvd6Zolx6DdibYXWoKBAh6YmqeBeOGQZooXg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 15 未来规划-长期路线&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. 业务赋能&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;业务赋能就是如何让业务愿意把数据接入到中台。根据以往做消息中间件的经验，需要从业务所重视的痛点出发。比如：对于任何一个业务，它在质量层面都涉及到的重要数据，是否能及时产出；以及产出之后数据的质量是否可信？是否有问题？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据以往经验，业务赋能需要从数据治理的层面综合考虑，通过质量、效率、成本三个维度，确保能切实解决业务在质量、效率和成本这三个维度的痛点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;① 在质量层面，通过基线管理、数据质量检查、内容检查，包括重保数据产出的整体链路，都能够实现实时监控产出；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;② 在效率层面，可以通过规范建模、查询优化，出数加快和对数据地图的优化，让业务找数速度加快。包括元数据血缘的建设，需要加快对业务中问题的追溯，即提升业务的效率；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;③ 在成本层面，帮助业务实现成本分析优化的闭环，就能够为成本优化提供一些工具或者抓手。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当能够提供这样完整的解决方案，让业务觉得好用时，业务就有意愿进行尝试。解决业务会遇到的风险，必须要从这三个方面得到切实的落实。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上的经验得到证实：最早小米内部有特别多的MQ，通过与各部门沟通与策划各自的MQ对接业务，最终统一了所有的MQ。其中包括Talos，成为小米数据总线的实施标准。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-fileid=&quot;100071939&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3z9miaLxjCgRDAGSI38ODT9HzYpo1tCytic34Er46S2WPKGOdeCTibV2Hwg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图 16 未来规划-业务赋能&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-16008590572276=&quot;rgb(136, 151, 171)&quot; data-darkmode-original-color-16008590572276=&quot;rgb(63, 74, 89)&quot; data-style=&quot;color: rgb(63, 74, 89); font-family: 微软雅黑; font-size: 11pt; letter-spacing: 0.4pt; text-align: left; text-indent: 0pt; visibility: visible;&quot;&gt;今天的分享就到这里，谢谢大家。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;hr/&gt;&lt;p&gt;&lt;span&gt;在文末分享、点赞、在看，给个3连击呗~&lt;/span&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;分享嘉宾：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;289&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;289&quot; data-fileid=&quot;100071943&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgcEq2ITibOHunXIEMefYu3zU90vnMPvtJOupibfFiakiaTOIMlhQPia9ChTyAfdS69IiazGmzBrmnIhWPA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;社群推荐：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;欢迎加入 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;DataFunTalk 大数据 &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;交流群，跟同行零距离交流。&lt;strong&gt;识别二维码&lt;/strong&gt;，添加小助手微信，&lt;strong&gt;入群。&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;146&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;145&quot; data-fileid=&quot;100071942&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/lAStFsJ0Pm2BEnLgiaJjAGyHnnpJ4NzkD1Ig2HTThvqVxBb6uBt604Q86gs7ytf7yukPbVPSJZ1vb8JFaacMeaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;关于我们：&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;DataFun：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;专注于大数据、人工智能技术应用的分享与交流。发起于2017年，在北京、上海、深圳、杭州等城市举办超过100+线下和100+线上沙龙、论坛及峰会，已邀请近1000位专家和学者参与分享。其公众号 DataFunTalk 累计生产原创文章500+，百万+阅读，12万+精准粉丝。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp custom_select_card_wrp wx-edui-media-wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU1NTMyOTI4Mw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPgiaIKm4YqA09u83TvzKbfsabjfX1TLzaXLAK9MWmC4qI6cuTBJnxygZLZPU49O8g6j8QI9264NMqQ/0?wx_fmt=png&quot; data-nickname=&quot;DataFunTalk&quot; data-alias=&quot;datafuntalk&quot; data-signature=&quot;专注于大数据、人工智能技术应用的分享与交流。致力于成就百万数据科学家。定期组织技术分享直播，并整理大数据、推荐/搜索算法、广告算法、NLP 自然语言处理算法、智能风控、自动驾驶、机器学习/深度学习等技术应用文章。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;🧐&lt;strong&gt;分享、点赞、在看&lt;/strong&gt;，给个&lt;strong&gt;3连击&lt;/strong&gt;呗！&lt;strong&gt;👇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>