<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>4fc9361213d8ba43b7310754695bd4c9</guid>
<title>[推荐] 高性能网关设计实践</title>
<link>https://toutiao.io/k/7579qvt</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;前言&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前的&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MTU1MzM3MQ==&amp;amp;mid=2247483977&amp;amp;idx=1&amp;amp;sn=9f932e774b680d06d105f495b96bb933&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;高性能短链设计&lt;/a&gt;一文颇受大家好评，共被转载 &lt;strong&gt;「47」&lt;/strong&gt; 次，受宠若惊，在此感谢大家的认可！在文末简单提了一下 OpenResty，一些读者比较感兴趣，刚好我们接入层网关也是用的 OpenResty，所以希望通过对网关设计的介绍来简单总结一下 OpenResty 的相关知识点，争取让大家对 OpenResty 这种高性能 Web 平台有一个比较全面的了解。本文会从以下几个方面来讲解。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;网关的作用&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;接入层网关架构设计与实现&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;技术选型&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;OpenResty 原理剖析&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;网关的作用&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;网关作为所有请求的流量入口，主要承担着安全，限流，熔断降级，监控，日志，风控，鉴权等功能，网关主要有两种类型&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;一种是接入层网关（access gateway），主要负责路由，WAF（防止SQL Injection, XSS, 路径遍历, 窃取敏感数据,CC攻击等），限流，日志，缓存等，这一层的网关主要承载着将请求路由到各个应用层网关的功能&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;另一种是应用层网关，比如现在流行的微服务，各个服务可能是用不同的语言写的，如 PHP，Java 等，那么接入层就要将请求路由到相应的应用层集群，再由相应的应用层网关进行鉴权等处理，处理完之后再调用相应的微服务进行处理，应用层网关也起着路由，超时，重试，熔断等功能。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目前市面上比较流行的系统架构如下&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3899905571293673&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLUMiaGVniaicPvJeN6G8SXFPYR6XbHeLXs3z9UAOfdicwIMEvyI9uiakDWraUSILW291G6cZjO9LW5RPFQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1059&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到接入层网关承载着公司的所有流量，对性能有很高的要求，它的设计决定着整个系统的上限。所以我们今天主要谈谈接入层网关的设计。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;接入层网关架构设计与实现&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先我们要明白接入层网关的核心功能是：&lt;strong&gt;「根据路由规则将请求分发到对应的后端集群」&lt;/strong&gt;，所以要实现如下几个功能模型 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、 路由：根据请求的 host, url 等规则转发到指定的上游（相应的后端集群）
2、 路由策略插件化：这是网关的&lt;strong&gt;「灵魂所在」&lt;/strong&gt;，路由中会有身份认证，限流限速，安全防护（如 IP 黑名单，refer异常，UA异常，需第一时间拒绝）等规则，这些规则以插件的形式互相组合起来以便只对某一类的请求生效，每个插件都即插即用，互不影响，这些插件应该是&lt;strong&gt;「动态可配置」&lt;/strong&gt;的，动态生效的（无须重启服务），为啥要可动态可配置呢，因为每个请求对应的路由逻辑，限流规则，最终请求的后端集群等规则是不一样的&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.0770465489566614&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLUMiaGVniaicPvJeN6G8SXFPYRlVRYaicH8DvefIeNYALbJYpiaaLTm6NBh5AicXaeozGHThVGh8P8PKBQg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;623&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如图示，两个请求对应的路由规则是不一样的，它们对应的路由规则（限流，rewrite）等通过各个规则插件组合在一起，可以看到，光两个请求 url 的路由规则就有挺多的，如果一个系统大到一定程度，url 会有不少，就会有不少规则，这样每个请求的规则就必须&lt;strong&gt;「可配置化」&lt;/strong&gt;，&lt;strong&gt;「动态化」&lt;/strong&gt;，最好能在管理端集中控制，统一下发。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、后端集群的动态变更&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;路由规则的应用是为了确定某一类请求经过这些规则后最终到达哪一个集群，而我们知道请求肯定是要打到某一台集群的 ip 上的，而机器的扩缩容其实是比较常见的，所以必须支持动态变更，总不能我每次上下线机器的时候都要重启系统让它生效吧。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4、监控统计，请求量、错误率统计等等&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个比较好理解，在接入层作所有流量的请求，错误统计，便于打点，告警，分析。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要实现这些需求就必须对我们采用的技术：OpenResty 有比较详细的了解，所以下文会简单介绍一下 OpenResty 的知识点。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;技术选型&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有人可能第一眼想到用 Nginx,没错，由于 Nginx 采用了 epoll 模型（非阻塞 IO 模型），确实能满足大多数场景的需求（经过优化 100 w + 的并发数不是问题），但是 Nginx 更适合作为静态的 Web 服务器，因为对于 Nginx 来说，如果发生任何变化，都需要修改磁盘上的配置，然后重新加载才能生效，它并没有提供 API 来控制运行时的行为，而如上文所述，动态化是接入层网关非常重要的一个功能。所以经过一番调研，我们选择了 OpenResty，啥是 OpenResty 呢，来看下官网的定义：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;OpenResty® 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。OpenResty® 的目标是让你的Web服务直接跑在 Nginx 服务内部，充分利用 Nginx 的非阻塞 I/O 模型，不仅仅对 HTTP 客户端请求,甚至于对远程后端诸如 MySQL、PostgreSQL、Memcached 以及 Redis 等都进行一致的高性能响应。&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以简单理解为，OpenResty = Nginx + Lua, 通过 Lua 扩展 Nginx 实现的可伸缩的 Web 平台
。它利用了 Nginx 的高性能，又在其基础上添加了 Lua 的脚本语言来让 Nginx 也具有了动态的特性。通过 OpenResty 中 lua-Nginx-module 模块中提供的 Lua API，我们可以动态地控制路由、上游、SSL 证书、请求、响应等。甚至可以在不重启 OpenResty 的前提下，修改业务的处理逻辑，并不局限于 OpenResty 提供的 Lua API。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于静态和动态有一个很合适的类比：如果把 Web 服务器当做是一个正在高速公路上飞驰的汽车，Nginx 需要停车才能更换轮胎，更换车漆颜色，而 OpenResty 中可以边跑边换轮胎，更换车漆，甚至更换发动机，直接让普通的汽车变成超跑！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了以上的动态性，还有两个特性让 OpenResty 独出一格。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「1.详尽的文档和测试用例」&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作为开源项目，文档和测试毫无疑问是其是否靠谱的关键，它的文档非常详细，作者把每个注意的点都写在文档上了，多数时候只要看文档即可，每一个测试案例都包含完整的 Nginx 配置和 lua 代码。以及测试的输入数据和预期的输出数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「2.同步非阻塞」&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;OpenResty 在诞生之初就支持了协程，并且基于此实现了同步非阻塞的编程模型。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「画外音：协程（coroutine）我们可以将它看成一个用户态的线程，只不过这个线程是我们自己调度的，而且不同协程的切换不需要陷入内核态，效率比较高。（一般我们说的线程是要指内核态线程，由内核调度，需要从用户空间陷入内核空间，相比协程，对性能会有不小的影响）」&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;啥是同步非阻塞呢。假设有以下两个两行代码：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;local&lt;/span&gt; res, err  = query-mysql(sql)&lt;br/&gt;&lt;span&gt;local&lt;/span&gt; value, err = query-redis(key)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「同步」&lt;/strong&gt;：必须执行完查询 mysql，才能执行下面的 redis 查询，如果不等 mysql 执行完成就能执行 redis 则是异步。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「阻塞」&lt;/strong&gt;：假设执行 sql 语句需要 1s，如果在这 1s 内，CPU 只能干等着不能做其它任何事，那就是阻塞，如果在 sql 执行期间可以做其他事（注意由于是同步的，所以不能执行以下的 redis 查询），则是非阻塞。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同步关注的是语句的先后执行顺序，如果上一个语句必须执行完才能执行下一个语句就是同步，如果不是，就是异步，阻塞关注的是线程是 CPU 是否需要在 IO 期间干等着，如果在 IO（或其他耗时操作期间）期间可以做其他事，那就是非阻塞，不能动，则是阻塞。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么 OpenResty 的工作原理是怎样的呢，又是如何实现同步非阻塞的呢。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;OpenResty 原理剖析&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;工作原理剖析&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于 OpenResty 基于 Nginx 实现的，我们先来看看 Nginx 的工作原理&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.7869415807560137&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLUMiaGVniaicPvJeN6G8SXFPYR56Uv0OeVibs6qu7pMyrD2WwODOeU24WYfmckf3cdp01exEia15ygz1pw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1164&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Nginx 启动后，会有一个 master 进程和多个 worker 进程 ， master 进程接受管理员的信号量（如 Nginx -s reload, -s stop）来管理 worker 进程，master 本身并不接收 client 的请求，主要由 worker 进程来接收请求，不同于 apache 的每个请求会占用一个线程，且是同步IO，Nginx 是异步非阻塞的，每个 worker 可以同时处理的请求数只受限于内存大小，这里就要简单地了解一下 nginx 采用的 epoll 模型：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;epoll 采用多路复用模型，即同一时间虽然可能会有多个请求进来， 但只会用一个线程去监视，然后哪个请求数据准备好了，就调用相应的线程去处理，就像图中所示，如同拨开关一样，同一时间只有一个线程在处理， Nginx 底层就是用的 epoll ，基于事件驱动模型，每个请求进来注册事件并注册 callback 回调函数，等数据准入好了，就调用回调函数进行处理，它是异步非阻塞的，所以性能很高。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.2975&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLUMiaGVniaicPvJeN6G8SXFPYRYbNPicgOHBWWvhjicriaIDayYvicuVJAicicdsm0fXyZAnAt95cCnBlO7Rsw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;400&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;打个简单的比方，我们都有订票的经验，当我们委托酒店订票时，接待员会先把我们的电话号码和相关信息等记下来（注册事件），挂断电话后接待员在操作期间我们就可以去做其他事了（非阻塞），当接待员把手续搞好后会主动打电话给我们通知我们票订好了（回调）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;worker 进程是从  master fork  出来的，这意味着 worker 进程之间是互相独立的，这样不同 worker 进程之间处理并发请求几乎没有同步锁的限制，好处就是一个 worker 进程挂了，不会影响其他进程，我们一般把 worker 数量设置成和 CPU 的个数，这样可以减少不必要的 CPU 切换，提升性能，每个 worker 都是单线程执行的。那么 LuaJIT 在 OpenResty 架构中的位置是怎样的呢。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.7406779661016949&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLUMiaGVniaicPvJeN6G8SXFPYRWJM9Yicib5gTYnO2q3oiajc3bxIFQRaYtue0lLmC0aCq2iavlCPmyiccAwA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1180&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先启动的 master 进程带有 LuaJIT 的机虚拟，而 worker 进程是从 master 进程 fork 出来的，在 worker 内进程的工作主要由 Lua 协程来完成，也就是说在同一个 worker 内的所有协程，都会共享这个 LuaJIT 虚拟机，每个 worker 进程里 lua 的执行也是在这个虚拟机中完成的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同一个时间点，worker 进程只能处理一个用户请求，也就是说只有一个 lua 协程在运行，那为啥 OpenResty 能支持百万并发请求呢，这就需要了解 Lua 协程与 Nginx 事件机制是如何配合的了。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.44212962962962965&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLUMiaGVniaicPvJeN6G8SXFPYRf6iaxtA6nYxicoibbYDqvVJaXcMeBInzNSK1OnkHsmGX8xOxQAOrjp5oQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1728&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如图示，当用 Lua 调用查询 MySQL 或 网络 IO 时，虚拟机会调用 Lua 协程的 yield 把自己挂起，在 Nginx 中注册回调，此时 worker 就可以处理另外的请求了（非阻塞），等到 IO 事件处理完了， Nginx 就会调用 resume 来唤醒 lua 协程。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事实上，由 OpenResty 提供的所有 API，都是非阻塞的，下文提到的与 MySQL，Redis 等交互，都是非阻塞的，所以性能很高。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;OpenResty 请求生命周期&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Nginx 的每个请求有 11 个阶段，OpenResty 也有11 个 *_by_lua 的指令，如下图示:&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.9054726368159204&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLUMiaGVniaicPvJeN6G8SXFPYRhPmBh7drKKhs7EzBFo749o0vRKVtBmNvv7QSlGZic6qAFR6GGEGicOlw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1005&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;各个阶段 *_by_lua 的解释如下&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;set_by_lua：设置变量；&lt;br/&gt;rewrite_by_lua：转发、重定向等；&lt;br/&gt;access_by_lua：准入、权限等；&lt;br/&gt;content_by_lua：生成返回内容；&lt;br/&gt;header_filter_by_lua：应答头过滤处理；&lt;br/&gt;body_filter_by_lua：应答体过滤处理；&lt;br/&gt;log_by_lua：日志记录。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样分阶段有啥好处呢，假设你原来的 API 请求都是明文的&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;br/&gt;# 明文协议版本&lt;br/&gt;location /request {&lt;br/&gt;    content_by_lua &#x27;...&#x27;;       # 处理请求&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在需要对其加上加密和解密的机制，只需要在 access 阶段解密， 在 body filter 阶段加密即可，原来 content 的逻辑无需做任务改动，有效实现了代码的解藕。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;# 加密协议版本&lt;br/&gt;location /request {&lt;br/&gt;    access_by_lua &#x27;...&#x27;;        # 请求体解密&lt;br/&gt;    content_by_lua &#x27;...&#x27;;       # 处理请求，不需要关心通信协议&lt;br/&gt;    body_filter_by_lua &#x27;...&#x27;;   # 应答体加密&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再比如我们不是要要上文提到网关的核心功能之一不是要监控日志吗，就可以统一在 log_by_lua 上报日志，不影响其他阶段的逻辑。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;worker 间共享数据利器: shared dict&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;worker 既然是互相独立的进程，就需要考虑其共享数据的问题， OpenResty 提供了一种高效的数据结构: shared dict ,可以实现在 worker 间共享数据，shared dict 对外提供了 20 多个 Lua API，都是原子操作的，避免了高并发下的竞争问题。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;路由策略插件化实现&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有了以上 OpenResty 点的铺垫，来看看上文提的网关核心功能 「路由策略插件化」,「后端集群的动态变更」如何实现&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先针对某个请求的路由策略大概是这样的&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5445026178010471&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLUMiaGVniaicPvJeN6G8SXFPYR15ic2oCkicU4fQrG83TMVVbjG4GmbrHk0Z4iaias7fuXMvUvE9FyK7zzCA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;764&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整个插件化的步骤大致如下&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、每条策略由 url ,action, cluster 等组成，代表请求 url 在打到后端集群过程中最终经历了哪些路由规则，这些规则统一在我们的路由管理平台配置，存在 db 里。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、OpenResty 启动时，在请求的 init 阶段 worker 进程会去拉取这些规则，将这些规则编译成一个个可执行的 lua 函数，这一个个函数就对应了一条条的规则。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.2373134328358209&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLUMiaGVniaicPvJeN6G8SXFPYRwSL7sMjA8Viaia5OtEKUgtHbwibJY1bEo9dOnpH4KGeW4NLR1pnIB5Drg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;670&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;需要注意的是为了避免重复去 MySQL 中拉取数据，某个 worker 从 MySQL 拉取完规则（此步需要加锁，避免所有 worker 都去拉取）或者后端集群等配置信息后要将其保存在 shared dict 中，这样之后所有的 worker 请求只要从 shared dict 中获取这些规则，然后将其映射成对应模块的函数即可，如果配置规则有变动呢，配置后台通过接口通知 OpenResty 重新加载一下即可&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.7426160337552743&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLUMiaGVniaicPvJeN6G8SXFPYRE1y6rRic4kf21nnBO6GaG3kRRic3aHDJaKQIZpLu1HdOWUk3L3AA3icCA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;474&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;经过路由规则确定好每个请求对应要打的后端集群后，就需要根据 upstream 来确定最终打到哪个集群的哪台机器上，我们看看如何动态管理集群。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;后端集群的动态配置&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 Nginx 中配置 upstream 的格式如下&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;upstream backend {&lt;br/&gt;    server backend1.example.com weight=&lt;span&gt;5&lt;/span&gt;;&lt;br/&gt;    server backend2.example.com;&lt;br/&gt;    server &lt;span&gt;192.0&lt;/span&gt;&lt;span&gt;.0&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt; backup;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上这个示例是按照权重（weight）来划分的，6 个请求进来，5个请求打到 backend1.example.com, 1 个请求打到 backend2.example.com,如果这两台机器都不可用，就打到 192.0.0.1，这种静态配置的方式 upstream 的方式确实可行，但我们知道机器的扩缩容有时候比较频繁，如果每次机器上下线都要手动去改，并且改完之后还要重新去 reload 无疑是不可行的，出错的概率很大，而且每次配置都要 reload 对性能的损耗也是挺大的，为了解决这个问题，OpenResty 提供了一个 dyups 的模块来解决此问题， 它提供了一个 dyups api,可以动态增，删，创建 upsteam，所以在 init 阶段我们会先去拉取集群信息，构建 upstream，之后如果集群信息有变动，会通过如下形式调用 dyups api 来更新 upstream&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;br/&gt;&lt;span&gt;-- 动态配置 upstream 接口站点&lt;/span&gt;&lt;br/&gt;server {&lt;br/&gt;     listen &lt;span&gt;127.0&lt;/span&gt;&lt;span&gt;.0&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;:&lt;span&gt;81&lt;/span&gt;;&lt;br/&gt;      location / {&lt;br/&gt;          dyups_interface;&lt;br/&gt;     }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;-- 增加 upstream:user_backend&lt;/span&gt;&lt;br/&gt;curl -d &lt;span&gt;&quot;server 10.53.10.191;&quot;&lt;/span&gt; &lt;span&gt;127.0&lt;/span&gt;&lt;span&gt;.0&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;:&lt;span&gt;81&lt;/span&gt;/upstream/user_backend&lt;br/&gt;&lt;br/&gt;&lt;span&gt;-- 删除 upstream:user_backend&lt;/span&gt;&lt;br/&gt;curl -i -X DELETE &lt;span&gt;127.0&lt;/span&gt;&lt;span&gt;.0&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;:&lt;span&gt;81&lt;/span&gt;/upstream/user_backend&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用 dyups 就解决了动态配置 upstream 的问题&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;网关最终架构设计图&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5574412532637075&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLUMiaGVniaicPvJeN6G8SXFPYRU7OUERPAjCUs66XkNwg1hIC18MIwUrn3VFkqRWl2RFFnzaSaEVO4CA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;766&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过这样的设计，最终实现了网关的配置化，动态化。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;总结&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;网关作为承载公司所有流量的入口，对性能有着极高的要求，所以技术选型上还是要慎重，之所以选择 OpenResty，一是因为它高性能，二是目前也有小米，阿里，腾讯等大公司在用，是久经过市场考验的，本文通过对网关的总结简要介绍了 OpenResty 的相关知识点，相信大家对其主要功能点应该有所了解了，不过 OpenResty 的知识点远不止以上这些，大家如有兴趣，可以参考文末的学习教程深入学习，相信大家会有不少启发的。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;题外话&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;「码海」历史精品文章已经做成电子书了，如有需要欢迎添加我的个人微信，除了发你电子书外，也可以加入我的读者群，一起探讨问题，共同进步！里面有不少技术总监等大咖，相信不管是职场进阶也好，个人困惑也好，都能对你有所帮助哦&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.0225225225225225&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OyweysCSeLUMiaGVniaicPvJeN6G8SXFPYRKknvTeoScgA19PpnyRFhoMFotpa4KBWp6471bvUH5F8aibmVRNQibaXw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;222&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;巨人的肩膀&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;谈谈微服务中的 API 网关 https://www.cnblogs.com/savorboard/p/api-gateway.html&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Openresty动态更新(无reload)TCP Upstream的原理和实现 https://developer.aliyun.com/article/745757&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;http://www.ttlsa.com/Nginx/Nginx-modules-ngx_http_dyups_module/&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;极客时间 OpenResty 从入门到实战&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4e520a517ae609b77d044b93be8e8ca6</guid>
<title>[推荐] 常见面试题之缓存雪崩、缓存穿透、缓存击穿</title>
<link>https://toutiao.io/k/o904vp0</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;前言&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;❝&lt;/span&gt;&lt;p&gt;Hello，everybody，我是asong，今天与大家一起来聊一聊面试中几个常见的缓存问题。为什么会突然想做一篇这个文章呢，今天翻了一下我当初准备面试时整理的一些资料，发现缓存在面试中占比还是很高的，当初为了面试也是背了好久的，不过因为都是背的，现在也有点忘了，今天就想着好好整理一下这一部分，好好记录一下。因为自己能力有限，这一篇主讲通俗易懂，不涉及太难的缓存使用场景。好啦，我们开始吧。&lt;/p&gt;&lt;span&gt;❞&lt;/span&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;缓存应用&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缓存在我们平常的项目中多多少少都会使用到，缓存使用的使用场景还是比较多的，缓存是分布式系统中的重要组件，主要解决高并发、大数据场景下，热点数据访问的性能问题。提高性能的数据快速访问。一提到缓存，这些是我们都能想到的一些缓存应用场景，但是我们是不太清楚缓存的本质思想是什么的。缓存的基本思想就是我们非常熟悉的空间换时间。缓存也并不是那么的高大上，虽然他可以为系统的性能进行提升。缓存的思想实际在操作系统或者其他地方都被大量用到。比如 &lt;strong&gt;「CPU Cache 缓存的是内存数据用于解决 CPU 处理速度和内存不匹配的问题，内存缓存的是硬盘数据用于解决硬盘访问速度过慢的问题。」&lt;/strong&gt; &lt;strong&gt;「再比如操作系统在 页表方案 基础之上引入了 快表 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache）。」&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面简单介绍了缓存的基本思想，现在回到业务系统来说：**我们为了避免用户在请求数据的时候获取速度过于缓慢，所以我们在数据库之上增加了缓存这一层来弥补。**画个图能更加方便大家的理解：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/k5430ljpYPNic3ic6iaK8z8O1MpctWOYFLE91dVboLNzdrO8eSNBiaEgp1IaDptSTdPgiaWnj8lpMY6FwoArcxWHNFQ/640?wx_fmt=png&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单点说当我们查询一条数据时，先去查询缓存，如果缓存有就直接返回，如果没有就去查询数据库，然后返回。这种情况下就可能会出现一些现象。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;1. 缓存雪崩&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;1.1 什么是缓存雪崩&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我们通过一个例子进行分析。比如马老师的某宝，我们打开某宝的首页时，看到一些图片呀、推荐店铺信息呀等等，这些都属于热点数据，为什么他们会加载的那么快呢？因为使用到了缓存呗。这些热点数据都做了缓存，假设现在把这些热点数据的缓存失效时间为一样，现在我们马老师要做一个秒杀活动，假设在秒杀活动时每秒有8000个请求，本来有缓存我们是可以扛住每秒 6000 个请求，但是缓存当时所有的Key都失效了。此时 1 秒 8000 个请求全部落数据库，数据库必然扛不住，它会报一下警，真实情况可能DBA都没反应过来就直接挂了。此时，如果没用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。上面造成缓存雪崩的原因是因为失效时间造成，还有一种可能是因为缓存服务宕机。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;1.213740458015267&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/k5430ljpYPNic3ic6iaK8z8O1MpctWOYFLEGcGRberfhhicw8BbeA1DIAyhhl3wNTz9VTVEHBvHFbMuL9Mt4jYfWBA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;786&quot;/&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;1.2 解决办法&lt;/span&gt;&lt;span/&gt;&lt;br/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里分三个时间段进行进行分析&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.2.1 事前&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果缓存雪崩造成的原因是因为缓存服务宕机造成的，可以将&lt;code&gt;redis&lt;/code&gt;采用集群部署，可以使用 主从+哨兵 ，Redis Cluster 来避免 Redis 全盘崩溃的情况。若缓存雪崩是因为大量缓存因为失效时间而造成的，我们在批量往&lt;code&gt;redis&lt;/code&gt;存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效，或者设置热点数据永远不过期，有更新操作就更新缓存就可以了。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.2.2 事中&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果我们之前没有考虑缓存雪崩的问题，那么在实际使用中真的发生缓存雪崩了，我们该怎么办呢？这时我们就要考虑使用其他方法避免出现这种情况了。我们可以使用ehcache 本地缓存 + Hystrix 限流&amp;amp;降级 ,避免 MySQL 被打死的情况发生。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里使用&lt;code&gt;echache&lt;/code&gt;本地缓存的目的就是考虑在 Redis Cluster 完全不可用的时候，ehcache 本地缓存还能够支撑一阵。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用 Hystrix 进行 限流 &amp;amp; 降级 ，比如一秒来了5000个请求，我们可以设置假设只能有一秒 2000 个请求能通过这个组件，那么其他剩余的 3000 请求就会走限流逻辑，然后去调用我们自己开发的降级组件（降级）。比如设置的一些默认值呀之类的。以此来保护最后的 MySQL 不会被大量的请求给打死。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.2.3 事后&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果缓存服务宕机了，这里我们可以开启&lt;strong&gt;「Redis」&lt;/strong&gt; 持久化 &lt;strong&gt;「RDB」&lt;/strong&gt;+&lt;strong&gt;「AOF」&lt;/strong&gt;，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上所述，可画出如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.49296875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/k5430ljpYPNic3ic6iaK8z8O1MpctWOYFLEm3nLmcLGxT5M3SVOoKn842IJWazutbibkpaxr7ia8hv1ic4PmqypiaI7xQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2. 缓存穿透&lt;/span&gt;&lt;span/&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.1 什么是缓存穿透&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在正常的情况下，用户查询数据都是存在的，但是在异常情况下，缓存与数据都没有数据，但是用户不断发起请求，这样每次请求都会打到数据库上面去，这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;1.892925430210325&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/k5430ljpYPNic3ic6iaK8z8O1MpctWOYFLEiaZYfU1jKH8hJta1eXqzicJIYn0vfJObMF44txuXd1G3iaQ7306bM83iaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;523&quot;/&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.2 解决办法&lt;/span&gt;&lt;span/&gt;&lt;br/&gt;&lt;/h4&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.2.1 添加参数校验&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我刚入职的时候，我的老大就跟我说过，作为一名后端开发工程师，不要相信前端传来的东西，所以数据一定要在后端进行校验。我们可以在接口层添加校验，不合法的直接返回即可，没必要做后续的操作。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.2.2 缓存空值&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面我们也介绍了，之所以会发生穿透，就是因为缓存中没有存储这些空数据的key。从而导致每次查询都到数据库去了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么我们就可以为这些key 设置的值设置为null 丢到缓存里面去。后面再出现查询这个key 的请求的时候，直接返回null ,就不用在到 数据库中去走一圈了。但是别忘了设置过期时间。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.2.3 布隆过滤器&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;redis&lt;/code&gt;的一个高级用法就是使用布隆过滤器（Bloom Filter），BloomFilter 类似于一个hase set 用来判断某个元素（key）是否存在于某个集合中。这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;2.2065009560229445&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/k5430ljpYPNic3ic6iaK8z8O1MpctWOYFLEqgMKiabiaQXNcZWKdID7A9xAG93kjbyOvTfaXcVibce7tC3fI1oRj4IoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;523&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面介绍了三种方法，用哪种方法最好呢？下面我们来分析一下：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一种方法，添加参数校验，这里是必须要添加，不过只能过滤掉一些特殊值，比如传的&lt;code&gt;id&lt;/code&gt;为负数，如果传的正常&lt;code&gt;id&lt;/code&gt;，这里参数校验就不起作用了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二种方法，如果有一些恶意攻击，攻击会带来大量的ke y是不存在的，这样采用第二种方法就不合适了。所以针对这种key 异常多，请求重复率比较低的数据，我们就没有必要进行缓存，使用第三种方案直接过滤掉。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果对于空数据key有限的，重复率比较高的，我们则可以采用第二种方式进行缓存。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;3. 缓存击穿&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;3.1 什么是缓存击穿&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在平常高并发的系统中，大量的请求同时查询一个key时，假设此时，这个key正好失效了，就会导致大量的请求都打到数据库上面去，这种现象我们称为击穿。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这么看缓存击穿和缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是&lt;strong&gt;「缓存击穿」&lt;/strong&gt;是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缓存击穿带来的问题就是会造成某一时刻数据库请求量过大，压力剧增。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;3.2 解决办法&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3.2.1 不过期&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们简单粗暴点，直接让热点数据永远不过期，定时任务定期去刷新数据就可以了。不过这样设置需要区分场景，比如某宝首页可以这么做。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3.2.2 互斥锁&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了避免出现缓存击穿的情况，我们可以在第一个请求去查询数据库的时候对他加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，后面的线程进来发现已经有缓存了，就直接走缓存，从而保护数据库。但是也是由于它会阻塞其他的线程，此时系统吞吐量会下降。需要结合实际的业务去考虑是否要这么做。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;总结&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好啦，分析到这里就结束了，这一💋简单介绍了&lt;strong&gt;「Redis」&lt;/strong&gt;的&lt;strong&gt;「雪崩」&lt;/strong&gt;，&lt;strong&gt;「击穿」&lt;/strong&gt;，&lt;strong&gt;「穿透」&lt;/strong&gt;，三者其实都差不多，但是又有一些区别，在面试中其实这是问到缓存必问的，大家不要把三者搞混了，因为缓存雪崩、穿透和击穿，是缓存最大的问题，要么不出现，一旦出现就是致命性的问题，&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再次强调一下，上面这三个知识点真的很重要，因为我们在项目设计时，这些都是要考虑的，所以一定知其所以然。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后打一波预告吧，下一篇文章内容：《缓存更新的套路》；敬请期待。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「结尾给大家发一个小福利吧，最近我在看[微服务架构设计模式]这一本书，讲的很好，自己也收集了一本PDF，有需要的小伙可以到自行下载。获取方式：关注公众号：[Golang梦工厂]，后台回复：[微服务]，即可获取。」&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「我翻译了一份GIN中文文档，会定期进行维护，有需要的小伙伴后台回复[gin]即可下载。」&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「我是asong，一名普普通通的程序猿，让我一起慢慢变强吧。我自己建了一个&lt;code&gt;golang&lt;/code&gt;交流群，有需要的小伙伴加我&lt;code&gt;vx&lt;/code&gt;,我拉你入群。欢迎各位的关注，我们下期见~~~」&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/k5430ljpYPNic3ic6iaK8z8O1MpctWOYFLESN5Cj4H6rld3vVlTVvN84Q98Fn4JDzVm9Eo0nMhyZpflfbeLEBS3BQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;258&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;推荐往期文章：&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d57371e4e1fb4835ce1dec4639db21b1</guid>
<title>[推荐] 面试官：如何写出让 CPU 跑得更快的代码？</title>
<link>https://toutiao.io/k/l6chi61</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6356877323420075&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DU5g3I7vpskPKGc2AVN5icSasGiaxoa1NIJWILJqTibPeibIZv2jkj6ianZSw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1076&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;hr/&gt;&lt;h2&gt;&lt;span&gt;前言&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;代码都是由 CPU 跑起来的，我们代码写的好与坏就决定了 CPU 的执行效率，特别是在编写计算密集型的程序，更要注重 CPU 的执行效率，否则将会大大影响系统性能。&lt;/p&gt;&lt;p&gt;CPU 内部嵌入了 CPU Cache（高速缓存），它的存储容量很小，但是离 CPU 核心很近，所以缓存的读写速度是极快的，那么如果 CPU 运算时，直接从 CPU Cache 读取数据，而不是从内存的话，运算速度就会很快。&lt;/p&gt;&lt;p&gt;但是，大多数人不知道 CPU Cache 的运行机制，以至于不知道如何才能够写出能够配合 CPU Cache 工作机制的代码，一旦你掌握了它，你写代码的时候，就有新的优化思路了。&lt;/p&gt;&lt;p&gt;那么，接下来我们就来看看，CPU Cache 到底是什么样的，是如何工作的呢，又该写出让 CPU 执行更快的代码呢？&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.34772462077012833&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUqltTazYGAUDNlrTfuPx6rgBxLw3ynWVJIQSGAVlM7bc73W4znSPoZg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1714&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;hr/&gt;&lt;h2&gt;&lt;span&gt;正文&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;CPU Cache 有多快？&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;你可能会好奇为什么有了内存，还需要 CPU Cache？根据摩尔定律，CPU 的访问速度每 18 个月就会翻倍，相当于每年增长 60% 左右，内存的速度当然也会不断增长，但是增长的速度远小于 CPU，平均每年只增长 7% 左右。于是，CPU 与内存的访问性能的差距不断拉大。&lt;/p&gt;&lt;p&gt;到现在，一次内存访问所需时间是 &lt;code&gt;200~300&lt;/code&gt; 多个时钟周期，这意味着 CPU 和内存的访问速度已经相差 &lt;code&gt;200~300&lt;/code&gt; 多倍了。&lt;/p&gt;&lt;p&gt;为了弥补 CPU 与内存两者之间的性能差异，就在 CPU 内部引入了  CPU Cache，也称高速缓存。&lt;/p&gt;&lt;p&gt;CPU Cache 通常分为大小不等的三级缓存，分别是 &lt;strong&gt;L1 Cache、L2 Cache 和 L3 Cache&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;由于 CPU Cache 所使用的材料是 SRAM，价格比内存使用的 DRAM 高出很多，在当今每生产 1 MB 大小的 CPU Cache 需要 7 美金的成本，而内存只需要 0.015 美金的成本，成本方面相差了 466 倍，所以 CPU Cache 不像内存那样动辄以 GB 计算，它的大小是以 KB 或 MB 来计算的。&lt;/p&gt;&lt;p&gt;在 Linux 系统中，我们可以使用下图的方式来查看各级 CPU Cache 的大小，比如我这手上这台服务器，离 CPU 核心最近的 L1 Cache 是 32KB，其次是 L2 Cache 是 256KB，最大的 L3 Cache 则是 3MB。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.7211740041928721&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUiaYtfLibicW11HOurkPCxZ6WcY0JHr1oGpcRvyNKsozexRSR3iaUzpulVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;954&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;其中，&lt;strong&gt;L1 Cache 通常会分为「数据缓存」和「指令缓存」&lt;/strong&gt;，这意味着数据和指令在 L1 Cache 这一层是分开缓存的，上图中的 &lt;code&gt;index0&lt;/code&gt; 也就是数据缓存，而 &lt;code&gt;index1&lt;/code&gt; 则是指令缓存，它两的大小通常是一样的。&lt;/p&gt;&lt;p&gt;另外，你也会注意到，L3 Cache 比 L1 Cache 和 L2 Cache 大很多，这是因为 &lt;strong&gt;L1 Cache 和 L2 Cache 都是每个 CPU 核心独有的，而 L3 Cache 是多个 CPU 核心共享的。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;程序执行时，会先将内存中的数据加载到共享的 L3 Cache 中，再加载到每个核心独有的 L2 Cache，最后进入到最快的 L1 Cache，之后才会被 CPU 读取。它们之间的层级关系，如下图：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6649056603773585&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUZic96QWC2PPxCPP9HeOPgzcmfSj9I80u1W15JpyIUib3LbibMpjFTh0Rw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1325&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;越靠近 CPU 核心的缓存其访问速度越快，CPU 访问 L1 Cache 只需要 &lt;code&gt;2~4&lt;/code&gt; 个时钟周期，访问 L2 Cache 大约 &lt;code&gt;10~20&lt;/code&gt; 个时钟周期，访问 L3 Cache 大约 &lt;code&gt;20~60&lt;/code&gt; 个时钟周期，而访问内存速度大概在 &lt;code&gt;200~300&lt;/code&gt; 个 时钟周期之间。如下表格：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5965189873417721&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUwhcPrwJ0d1niaQBKwCcsIvXC5Bm5MibIsgRum9riaEg7z2WibopJGaQQug/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;632&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;所以，CPU 从 L1 Cache 读取数据的速度，相比从内存读取的速度，会快 &lt;code&gt;100&lt;/code&gt; 多倍。&lt;/strong&gt;&lt;/p&gt;&lt;hr/&gt;&lt;h3&gt;&lt;span&gt;CPU Cache 的数据结构和读取过程是什么样的？&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的，而不是按照单个数组元素来读取数据的，在 CPU Cache 中的，这样一小块一小块的数据，称为 &lt;strong&gt;Cache Line（缓存块）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;你可以在你的 Linux 系统，用下面这种方式来查看 CPU 的 Cache Line，你可以看我服务器的 L1 Cache Line 大小是 64 字节，也就意味着 &lt;strong&gt;L1 Cache 一次载入数据的大小是 64 字节&lt;/strong&gt;。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.20949263502454993&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUpgXIYYgic3eJ5SHJNKFVRnLPwCd2qNnEGEichslHoZLWt8GsyEu49Nqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1222&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;比如，有一个 &lt;code&gt;int array[100]&lt;/code&gt; 的数组，当载入 &lt;code&gt;array[0]&lt;/code&gt; 时，由于这个数组元素的大小在内存只占 4 字节，不足 64 字节，CPU 就会&lt;strong&gt;顺序加载&lt;/strong&gt;数组元素到 &lt;code&gt;array[15]&lt;/code&gt;，意味着 &lt;code&gt;array[0]~array[15]&lt;/code&gt; 数组元素都会被缓存在 CPU Cache 中了，因此当下次访问这些数组元素时，会直接从 CPU Cache 读取，而不用再从内存中读取，大大提高了 CPU 读取数据的性能。&lt;/p&gt;&lt;p&gt;事实上，CPU 读取数据的时候，无论数据是否存放到 Cache 中，CPU 都是先访问 Cache，只有当 Cache 中找不到数据时，才会去访问内存，并把内存中的数据读入到 Cache 中，CPU 再从 CPU Cache 读取数据。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5844875346260388&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUfV2liaq9Sm18DGvnOFhxAHpGX1U3GqBwNlyj3W2biaRLeWTsv6NBrdvA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;722&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这样的访问机制，跟我们使用「内存作为硬盘的缓存」的逻辑是一样的，如果内存有缓存的数据，则直接返回，否则要访问龟速一般的硬盘。&lt;/p&gt;&lt;p&gt;那 CPU 怎么知道要访问的内存数据，是否在 Cache 里？如果在的话，如何找到 Cache 对应的数据呢？我们从最简单、基础的&lt;strong&gt;直接映射 Cache（&lt;em&gt;Direct Mapped Cache&lt;/em&gt;）&lt;/strong&gt; 说起，来看看整个 CPU Cache 的数据结构和访问逻辑。&lt;/p&gt;&lt;p&gt;前面，我们提到 CPU 访问内存数据时，是一小块一小块数据读取的，具体这一小块数据的大小，取决于 &lt;code&gt;coherency_line_size&lt;/code&gt; 的值，一般 64 字节。在内存中，这一块的数据我们称为&lt;strong&gt;内存块（&lt;em&gt;Bock&lt;/em&gt;）&lt;/strong&gt;，读取的时候我们要拿到数据所在内存块的地址。&lt;/p&gt;&lt;p&gt;对于直接映射 Cache 采用的策略，就是把内存块的地址始终「映射」在一个 CPU Line（缓存块） 的地址，至于映射关系实现方式，则是使用「取模运算」，取模运算的结果就是内存块地址对应的 CPU Line（缓存块） 的地址。&lt;/p&gt;&lt;p&gt;举个例子，内存共被划分为 32 个内存块，CPU Cache 共有 8 个 CPU Line，假设 CPU 想要访问第 15 号内存块，如果 15 号内存块中的数据已经缓存在 CPU Line 中的话，则是一定映射在 7 号 CPU Line 中，因为 &lt;code&gt;15 % 8&lt;/code&gt; 的值是 7。&lt;/p&gt;&lt;p&gt;机智的你肯定发现了，使用取模方式映射的话，就会出现多个内存块对应同一个 CPU Line，比如上面的例子，除了 15 号内存块是映射在 7 号 CPU Line 中，还有 7 号、23 号、31 号内存块都是映射到 7 号 CPU Line 中。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;1.0351390922401171&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUwLEOS9ugA1Km1PvBQf6zJ9ffp8HzIFBo5AdqI87aUqO25SUUExafHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;683&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;因此，为了区别不同的内存块，在对应的 CPU Line 中我们还会存储一个&lt;strong&gt;组标记（Tag）&lt;/strong&gt;。这个组标记会记录当前 CPU Line 中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。&lt;/p&gt;&lt;p&gt;除了组标记信息外，CPU Line 还有两个信息：&lt;/p&gt;&lt;p&gt;CPU 在从 CPU Cache 读取数据的时候，并不是读取 CPU Line 中的整个数据块，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个&lt;strong&gt;字（&lt;em&gt;Word&lt;/em&gt;）&lt;/strong&gt;。那怎么在对应的 CPU Line 中数据块中找到所需的字呢？答案是，需要一个&lt;strong&gt;偏移量（Offset）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;因此，一个内存的访问地址，包括&lt;strong&gt;组标记、CPU Line 索引、偏移量&lt;/strong&gt;这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。而对于 CPU Cache 里的数据结构，则是由&lt;strong&gt;索引 + 有效位 + 组标记 + 数据块&lt;/strong&gt;组成。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6840363937138131&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUGmFpHBHryZfZCrS1CcXAAXwZq4la5afWIFtIfATQJpGGGBQkicIMcHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1209&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;如果内存中的数据已经在 CPU Cahe 中了，那 CPU 访问一个内存地址的时候，会经历这 4 个步骤：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;根据内存地址中索引信息，计算在 CPU Cahe 中的索引，也就是找出对应的 CPU Line 的地址；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;找到对应 CPU Line 后，判断 CPU Line 中的有效位，确认 CPU Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对比内存地址中组标记和 CPU Line 中的组标记，确认 CPU Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;根据内存地址中偏移量信息，从 CPU Line 的数据块中，读取对应的字。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;到这里，相信你对直接映射 Cache 有了一定认识，但其实除了直接映射 Cache 之外，还有其他通过内存地址找到 CPU Cache 中的数据的策略，比如全相连 Cache （&lt;em&gt;Fully Associative Cache&lt;/em&gt;）、组相连 Cache （&lt;em&gt;Set Associative Cache&lt;/em&gt;）等，这几种策策略的数据结构都比较相似，我们理解流直接映射 Cache 的工作方式，其他的策略如果你有兴趣去看，相信很快就能理解的了。&lt;/p&gt;&lt;hr/&gt;&lt;h3&gt;&lt;span&gt;如何写出让 CPU 跑得更快的代码？&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;我们知道 CPU 访问内存的速度，比访问 CPU Cache 的速度慢了 100 多倍，所以如果 CPU 所要操作的数据在 CPU Cache 中的话，这样将会带来很大的性能提升。访问的数据在 CPU Cache 中的话，意味着&lt;strong&gt;缓存命中&lt;/strong&gt;，缓存命中率越高的话，代码的性能就会越好，CPU 也就跑的越快。&lt;/p&gt;&lt;p&gt;于是，「如何写出让 CPU 跑得更快的代码？」这个问题，可以改成「如何写出 CPU 缓存命中率高的代码？」。&lt;/p&gt;&lt;p&gt;在前面我也提到， L1 Cache 通常分为「数据缓存」和「指令缓存」，这是因为 CPU 会别处理数据和指令，比如 &lt;code&gt;1+1=2&lt;/code&gt; 这个运算，&lt;code&gt;+&lt;/code&gt; 就是指令，会被放在「指令缓存」中，而输入数字 &lt;code&gt;1&lt;/code&gt; 则会被放在「数据缓存」里。&lt;/p&gt;&lt;p&gt;因此，&lt;strong&gt;我们要分开来看「数据缓存」和「指令缓存」的缓存命中率&lt;/strong&gt;。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;如何提升数据缓存的命中率？&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;假设要遍历二维数组，有以下两种形式，虽然代码执行结果是一样，但你觉得哪种形式效率最高呢？为什么高呢？&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;1.3868613138686132&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUaWq5KdzLgGiaTeUj6icIrEgVHbzteS2cMUQlbkEfiawYibpunTLQO08DBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;548&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;经过测试，形式一 &lt;code&gt;array[i][j]&lt;/code&gt;  执行时间比形式二 &lt;code&gt;array[j][i]&lt;/code&gt; 快好几倍。&lt;/p&gt;&lt;p&gt;之所以有这么大的差距，是因为二维数组 &lt;code&gt;array&lt;/code&gt; 所占用的内存是连续的，比如长度 &lt;code&gt;N&lt;/code&gt; 的指是 &lt;code&gt;2&lt;/code&gt; 的话，那么内存中的数组元素的布局顺序是这样的：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.2391304347826087&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DU1V6Raia4HWY3ZAUReO3jbvGHRib59hCUbpRZ612thav03UbGoujvSuSQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;920&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;形式一用 &lt;code&gt;array[i][j]&lt;/code&gt;  访问数组元素的顺序，正是和内存中数组元素存放的顺序一致。当 CPU 访问 &lt;code&gt;array[0][0]&lt;/code&gt; 时，由于该数据不在 Cache 中，于是会「顺序」把跟随其后的 3 个元素从内存中加载到 CPU Cache，这样当 CPU 访问后面的 3 个数组元素时，就能在 CPU Cache 中成功地找到数据，这意味着缓存命中率很高，缓存命中的数据不需要访问内存，这便大大提高了代码的性能。&lt;/p&gt;&lt;p&gt;而如果用形式二的 &lt;code&gt;array[j][i]&lt;/code&gt; 来访问，则访问的顺序就是：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.2391304347826087&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DULaIspIibUC6T3XxxOlc0YRmlI6Wa8nHf1qviaDzxBLoAEdk61tmW4jNg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;920&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;你可以看到，访问的方式跳跃式的，而不是顺序的，那么如果 N 的数值很大，那么操作 &lt;code&gt;array[j][i]&lt;/code&gt; 时，是没办法把 &lt;code&gt;array[j+1][i]&lt;/code&gt; 也读入到 CPU Cache 中的，既然 &lt;code&gt;array[j+1][i]&lt;/code&gt; 没有读取到 CPU Cache，那么就需要从内存读取该数据元素了。很明显，这种不连续性、跳跃式访问数据元素的方式，可能不能充分利用到了 CPU Cache 的特性，从而代码的性能不高。&lt;/p&gt;&lt;p&gt;那访问 &lt;code&gt;array[0][0]&lt;/code&gt; 元素时，CPU 具体会一次从内存中加载多少元素到 CPU Cache 呢？这个问题，在前面我们也提到过，这跟 CPU Cache Line 有关，它表示 &lt;strong&gt;CPU Cache 一次性能加载数据的大小&lt;/strong&gt;，可以在 Linux 里通过 &lt;code&gt;coherency_line_size&lt;/code&gt; 配置查看 它的大小，通常是 64 个字节。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.20949263502454993&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUpgXIYYgic3eJ5SHJNKFVRnLPwCd2qNnEGEichslHoZLWt8GsyEu49Nqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1222&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;也就是说，当 CPU 访问内存数据时，如果数据不在 CPU Cache 中，则会一次性会连续加载 64 字节大小的数据到 CPU Cache，那么当访问 &lt;code&gt;array[0][0]&lt;/code&gt; 时，由于该元素不足 64 字节，于是就会往后&lt;strong&gt;顺序&lt;/strong&gt;读取 &lt;code&gt;array[0][0]~array[0][15]&lt;/code&gt; 到 CPU Cache 中。顺序访问的 &lt;code&gt;array[i][j]&lt;/code&gt; 因为利用了这一特点，所以就会比跳跃式访问的 &lt;code&gt;array[j][i]&lt;/code&gt; 要快。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;因此，遇到这种遍历数组的情况时，按照内存布局顺序访问，将可以有效的利用 CPU Cache 带来的好处，这样我们代码的性能就会得到很大的提升，&lt;/strong&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;如何提升指令缓存的命中率？&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;提升数据的缓存命中率的方式，是按照内存布局顺序访问，那针对指令的缓存该如何提升呢？&lt;/p&gt;&lt;p&gt;我们以一个例子来看看，有一个元素为 0 到 100 之间随机数字组成的一维数组：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5985401459854015&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DU9LLoj74jOfcObSSxeWI3Rc3mgkbJ51n7jAKiajAjxTfSPJB4XrAJ5rg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;548&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;接下来，对这个数组做两个操作：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.927007299270073&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DULmPvhCfBh9RvNIa8TRCZasTczRGWsTVk75zwo76mAWeGwkaEndYn2A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;548&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;figure&gt;&lt;br/&gt;&lt;/figure&gt;&lt;p&gt;那么问题来了，你觉得先遍历再排序速度快，还是先排序再遍历速度快呢？&lt;/p&gt;&lt;p&gt;在回答这个问题之前，我们先了解 CPU 的&lt;strong&gt;分支预测器&lt;/strong&gt;。对于 if 条件语句，意味着此时至少可以选择跳转到两段不同的指令执行，也就是 if 还是 else 中的指令。那么，&lt;strong&gt;如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;当数组中的元素是随机的，分支预测就无法有效工作，而当数组元素都是顺序的，分支预测器会动态地根据历史命中数据对未来进行预测，这样命中率就会很高。&lt;/p&gt;&lt;p&gt;因此，先排序再遍历速度会更快，这是因为排序之后，数字是从小到大的，那么前几次循环命中 &lt;code&gt;if &amp;lt; 50&lt;/code&gt; 的次数会比较多，于是分支预测就会缓存 &lt;code&gt;if&lt;/code&gt; 里的 &lt;code&gt;array[i] = 0&lt;/code&gt; 指令到 Cache 中，后续 CPU 执行该指令就只需要从 Cache 读取就好了。&lt;/p&gt;&lt;p&gt;如果你肯定代码中的 &lt;code&gt;if&lt;/code&gt; 中的表达式判断为 &lt;code&gt;true&lt;/code&gt; 的概率比较高，我们可以使用显示分支预测工具，比如在 C/C++ 语言中编译器提供了 &lt;code&gt;likely&lt;/code&gt; 和 &lt;code&gt;unlikely&lt;/code&gt; 这两种宏，如果 &lt;code&gt;if&lt;/code&gt; 条件为 &lt;code&gt;ture&lt;/code&gt; 的概率大，则可以用 &lt;code&gt;likely&lt;/code&gt; 宏把 &lt;code&gt;if&lt;/code&gt; 里的表达式包裹起来，反之用 &lt;code&gt;unlikely&lt;/code&gt; 宏。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5539906103286385&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUzOCKyzJmM68G89T8hSbibBuEch9QQQF0IY59uUtfibN3Fn2rTt5whcJg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;852&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;实际上，CPU 自身的动态分支预测已经是比较准的了，所以只有当非常确信 CPU 预测的不准，且能够知道实际的概率情况时，才建议使用这两种宏。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;如果提升多核 CPU 的缓存命中率？&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;在单核 CPU，虽然只能执行一个进程，但是操作系统给每个进程分配了一个时间片，时间片用完了，就调度下一个进程，于是各个进程就按时间片交替地占用 CPU，从宏观上看起来各个进程同时在执行。&lt;/p&gt;&lt;p&gt;而现代 CPU 都是多核心的，进程可能在不同 CPU 核心来回切换执行，这对 CPU Cache 不是有利的，虽然 L3 Cache 是多核心之间共享的，但是 L1 和 L2 Cache 都是每个核心独有的，&lt;strong&gt;如果一个进程在不同核心来回切换，各个核心的缓存命中率就会受到影响&lt;/strong&gt;，相反如果进程都在同一个核心上执行，那么其数据的 L1 和 L2 Cache 的缓存命中率可以得到有效提高，缓存命中率高就意味着 CPU 可以减少访问 内存的频率。&lt;/p&gt;&lt;p&gt;当有多个同时执行「计算密集型」的线程，为了防止因为切换到不同的核心，而导致缓存命中率下降的问题，我们可以把&lt;strong&gt;线程绑定在某一个 CPU 核心上&lt;/strong&gt;，这样性能可以得到非常可观的提升。&lt;/p&gt;&lt;p&gt;在 Linux 上提供了 &lt;code&gt;sched_setaffinity&lt;/code&gt; 方法，来实现将线程绑定到某个 CPU 核心这一功能。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.23548387096774193&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUvZ5zh4RImou6azJ9KMevyTDPcTHLffjYgxyckdaggftIY6hJgiarkYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;hr/&gt;&lt;h3&gt;&lt;span&gt;总结&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;由于随着计算机技术的发展，CPU 与 内存的访问速度相差越来越多，如今差距已经高达好几百倍了，所以 CPU 内部嵌入了 CPU Cache 组件，作为内存与 CPU 之间的缓存层，CPU Cache 由于离 CPU 核心很近，所以访问速度也是非常快的，但由于所需材料成本比较高，它不像内存动辄几个 GB 大小，而是仅有几十 KB 到 MB 大小。&lt;/p&gt;&lt;p&gt;当 CPU 访问数据的时候，先是访问 CPU Cache，如果缓存命中的话，则直接返回数据，就不用每次都从内存读取速度了。因此，缓存命中率越高，代码的性能越好。&lt;/p&gt;&lt;p&gt;但需要注意的是，当 CPU 访问数据时，如果 CPU Cache 没有缓存该数据，则会从内存读取数据，但是并不是只读一个数据，而是一次性读取一块一块的数据存放到 CPU Cache 中，之后才会被 CPU 读取。&lt;/p&gt;&lt;p&gt;内存地址映射到 CPU Cache 地址里的策略有很多种，其中比较简单是直接映射 Cache，它巧妙的把内存地址拆分成「索引 + 组标记 + 偏移量」的方式，使得我们可以将很大的内存地址，映射到很小的 CPU Cache 地址里。&lt;/p&gt;&lt;p&gt;要想写出让 CPU 跑得更快的代码，就需要写出缓存命中率高的代码，CPU L1 Cache 分为数据缓存和指令缓存，因而需要分别提高它们的缓存命中率：&lt;/p&gt;&lt;p&gt;另外，对于多核 CPU 系统，线程可能在不同 CPU 核心来回切换，这样各个核心的缓存命中率就会受到影响，于是要想提高进程的缓存命中率，可以考虑把线程绑定 CPU 到某一个 CPU 核心。&lt;/p&gt;&lt;hr/&gt;&lt;h2&gt;&lt;span&gt;絮叨&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;分享个喜事，小林平日里忙着输出文章，今天收到一份特别的快递，是 CSDN 寄来的奖状。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6587360594795539&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/J0g14CUwaZcKapyUj66hkhTng5Zof8DUZ0IFb8hhbujk32TmfGFhf050tBp0Y99Z45Ee6v0PwhnjVq73FsDEVA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1345&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;骄傲的说，你们关注的是 CSDN 首届技术原创第一名的博主，以后简历又可以吹牛逼了&lt;/p&gt;&lt;p&gt;没有啦，其实主要还是&lt;strong&gt;谢谢你们不离不弃的支持&lt;/strong&gt;。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5902612826603325&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUVwlCFh1n6JlGk9YqHE2t6sNc4UfFw0Za60dcwsambuF9A16w06086A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;842&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;em&gt;哈喽，我是小林，就爱图解计算机基础，如果觉得文章对你有帮助，欢迎分享给你的朋友，也给小林点个「在看」，这对小林非常重要，谢谢你们，给各位小姐姐小哥哥们抱拳了，我们下次见！&lt;/em&gt;&lt;/p&gt;&lt;hr/&gt;&lt;h5&gt;&lt;span&gt;推荐阅读&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;这个星期不知不觉输出了 3 篇文章了，前面的 2 篇还没看过的同学，赶紧去看看呀！&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&amp;amp;mid=2247485960&amp;amp;idx=1&amp;amp;sn=476d40b3e272149ba6c7370340e9768f&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;天啦噜！知道硬盘很慢，但没想到比 CPU Cache 慢 10000000 倍&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&amp;amp;mid=2247485918&amp;amp;idx=1&amp;amp;sn=f7fa3aa2a7cc362eeebad09d4d6fa03a&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;CPU 执行程序的秘密，藏在了这 15 张图里&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>0623720fbc535d26e68350dc6389efd6</guid>
<title>[推荐] 时间轮在 Kafka 的实践</title>
<link>https://toutiao.io/k/441cqn5</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;562&quot; data-backw=&quot;562&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;562&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;562&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1wBZCGiaYqBG8fiaH5DpcXl4gX9dSJhFzF6ARFqaicYjickTxiaPM701eKEspL7tj7A4xonqVVkpDfA12KVmDDPE8icg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section data-darkmode-bgcolor-15906711670635=&quot;rgb(52, 52, 52)&quot; data-darkmode-original-bgcolor-15906711670635=&quot;rgb(239, 239, 239)&quot; data-style=&quot;padding: 10px; display: inline-block; width: 558px; border-width: 1px; border-style: solid; border-color: transparent; background-color: rgb(239, 239, 239); border-radius: 0px;&quot; class=&quot;js_darkmode__0&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot; data-darkmode-bgcolor-15906711670635=&quot;rgb(52, 52, 52)&quot; data-darkmode-original-bgcolor-15906711670635=&quot;rgb(239, 239, 239)&quot;&gt;&lt;section data-darkmode-bgcolor-15906711670635=&quot;rgb(52, 52, 52)&quot; data-darkmode-original-bgcolor-15906711670635=&quot;rgb(239, 239, 239)&quot;&gt;&lt;p data-darkmode-bgcolor-15906711670635=&quot;rgb(52, 52, 52)&quot; data-darkmode-original-bgcolor-15906711670635=&quot;rgb(239, 239, 239)&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;桔妹导读：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;时间轮是一个应用场景很广的组件，在很多高性能中间件中都有它的身影，如Netty、Quartz、Akka，当然也包括Kafka，本文主要介绍时间轮在kafka的应用和实战，从核心源码和设计的角度对时间轮进行深入的讲解 。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;1. &lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;引子&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.0734375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jE5bOw22iaBtFvdK9icOj3ibAXa8W3tqZ2lQDEaA5XcCDJ5cVIic2221PzXcw0oo69kvia8ojgPZnEV4jPxZURBln4A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot; data-backw=&quot;562&quot; data-backh=&quot;41&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;从2个面试题说起，第一个问题：&lt;strong&gt;如果一台机器上有10w个定时任务，如何做到高效触发？&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;具体场景是：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;有一个APP实时消息通道系统，对每个用户会维护一个APP到服务器的TCP连接，用来实时收发消息，对这个TCP连接，有这样一个需求：“如果连续30s没有请求包（例如登录，消息，keepalive包），服务端就要将这个用户的状态置为离线”。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt; 其中，单机TCP同时在线量约在10w级别，keepalive请求包较分散大概30s一次，吞吐量约在3000qps。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;怎么做？&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;常用方案使用time定时任务，每秒扫描一次所有连接的集合Map&amp;lt;uid, last_packet_time&amp;gt;，把连接时间（每次有新的请求更新对应连接的连接时间）比当前时间的差值大30s的连接找出来处理。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;另一种方案，使用环形队列法：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;382&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.6606498194945848&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1wBZCGiaYqBG8fiaH5DpcXl4gX9dSJhFzFyHiaiaWIPMkRLgqmsN5VzQsHuYdCHiadPl2dunDHicSlewT7ma4pWBNJBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1108&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;三个重要的数据结构：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;30s超时，就创建一个index从0到30的环形队列（本质是个数组）&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;环上每一个slot是一个Set&amp;lt;uid&amp;gt;，任务集合&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;同时还有一个Map&amp;lt;uid, index&amp;gt;，记录uid落在环上的哪个slot里&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这样当有某用户uid有请求包到达时：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;从Map结构中，查找出这个uid存储在哪一个slot里&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;从这个slot的Set结构中，删除这个uid&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;将uid重新加入到新的slot中，具体是哪一个slot呢 =&amp;gt; Current Index指针所指向的&lt;/span&gt;&lt;span&gt;上一个&lt;/span&gt;&lt;span&gt;slot，因为这个slot，会被timer在30s之后扫描到&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;更新Map，这个uid对应slot的index值&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;哪些元素会被超时掉呢？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Current Index每秒种移动一个slot，这个slot对应的Set&amp;lt;uid&amp;gt;中所有uid都应该被集体超时！如果最近30s有请求包来到，一定被放到Current Index的前一个slot了，Current Index所在的slot对应Set中所有元素，都是最近30s没有请求包来到的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;所以，当没有超时时，Current Index扫到的每一个slot的Set中应该都没有元素。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;两种方案对比：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;方案一每次都要轮询所有数据，而方案二使用环形队列只需要轮询这一刻需要过期的数据，如果没有数据过期则没有数据要处理，并且是批量超时，并且由于是环形结构更加节约空间，这很适合高性能场景。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;第二个问题：&lt;strong&gt;在开发过程中有延迟一定时间的任务要执行，怎么做？&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果不重复造轮子的话，我们的选择当然是延迟队列或者Timer。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;延迟队列和在Timer中增 加延时任务采用数组表示的最小堆的数据结构实现，每次放入新元素和移除队首元素时间复杂度为O(nlog(n))。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;2. &lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;时间轮&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.0734375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jE5bOw22iaBtFvdK9icOj3ibAXa8W3tqZ2lQDEaA5XcCDJ5cVIic2221PzXcw0oo69kvia8ojgPZnEV4jPxZURBln4A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot; data-backw=&quot;562&quot; data-backh=&quot;41&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;方案二所采用的环形队列，就是时间轮的底层数据结构，它能够让需要处理的数据（任务的抽象）集中，在Kafka中存在大量的延迟操作，比如延迟生产、延迟拉取以及延迟删除等。Kafka并没有使用JDK自带的Timer或者DelayQueue来实现延迟的功能，而是基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）。JDK的Timer和DelayQueue插入和删除操作的平均时间复杂度为O(nlog(n))，并不能满足Kafka的高性能要求，而基于时间轮可以将插入和删除操作的时间复杂度都降为O(1)。时间轮的应用并非Kafka独有，其应用场景还有很多，在Netty、Akka、Quartz、Zookeeper等组件中都存在时间轮的踪影。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;▍&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;2.1 时间轮的数据结构&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;参考下图，Kafka中的时间轮（TimingWheel）是一个存储定时任务的环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表（TimerTaskList）。TimerTaskList是一个环形的双向链表，链表中的每一项表示的都是定时任务项（TimerTaskEntry），其中封装了真正的定时任务TimerTask。在Kafka源码中对这个TimeTaskList是用一个名称为buckets的数组表示的，所以后面介绍中可能TimerTaskList也会被称为bucket。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;312&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.54&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1wBZCGiaYqBG8fiaH5DpcXl4gX9dSJhFzFpdDDKO9Iib8RQIRQ3JMaZoqNfC7VDYJZTtUy2UOaXVFtDicNGsC0Btqw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1600&quot;/&gt;&lt;span&gt;图二&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;针对上图的几个名词简单解释下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;tickMs：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;时间轮由多个时间格组成，每个时间格就是tickMs，它代表当前时间轮的基本时间跨度。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;wheelSize：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;代表每一层时间轮的格数&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;interval：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;当前时间轮的总体时间跨度，interval=tickMs × wheelSize&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;startMs：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;构造当层时间轮时候的当前时间，第一层的时间轮的startMs是TimeUnit.NANOSECONDS.toMillis(nanoseconds()),上层时间轮的startMs为下层时间轮的currentTime。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;currentTime：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;表示时间轮当前所处的时间，currentTime是tickMs的整数倍（通过currentTime=startMs - (startMs % tickMs来保正currentTime一定是tickMs的整数倍），这个运算类比钟表中分钟里65秒分钟指针指向的还是1分钟）。currentTime可以将整个时间轮划分为到期部分和未到期部分，currentTime当前指向的时间格也属于到期部分，表示刚好到期，需要处理此时间格所对应的TimerTaskList的所有任务。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;▍&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;2.2 时间轮中的任务存放&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;若时间轮的tickMs=1ms，wheelSize=20，那么可以计算得出interval为20ms。初始情况下表盘指针currentTime指向时间格0，此时有一个定时为2ms的任务插入进来会存放到时间格为2的TimerTaskList中。随着时间的不断推移，指针currentTime不断向前推进，过了2ms之后，当到达时间格2时，就需要将时间格2所对应的TimeTaskList中的任务做相应的到期操作。此时若又有一个定时为8ms的任务插入进来，则会存放到时间格10中，currentTime再过8ms后会指向时间格10。如果同时有一个定时为19ms的任务插入进来怎么办？新来的TimerTaskEntry会复用原来的TimerTaskList，所以它会插入到原本已经到期的时间格1中。总之，整个时间轮的总体跨度是不变的，随着指针currentTime的不断推进，当前时间轮所能处理的时间段也在不断后移，总体时间范围在currentTime和currentTime+interval之间。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt; &lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;▍&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;2.3 时间轮的升降级&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果此时有个定时为350ms的任务该如何处理？直接扩充wheelSize的大小么？Kafka中不乏几万甚至几十万毫秒的定时任务，这个wheelSize的扩充没有底线，就算将所有的定时任务的到期时间都设定一个上限，比如100万毫秒，那么这个wheelSize为100万毫秒的时间轮不仅占用很大的内存空间，而且效率也会拉低。Kafka为此引入了层级时间轮的概念，当任务的到期时间超过了当前时间轮所表示的时间范围时，就会尝试添加到上层时间轮中。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;513&quot; data-backw=&quot;562&quot; data-ratio=&quot;0.9129332206255283&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1wBZCGiaYqBG8fiaH5DpcXl4gX9dSJhFzFXzdeg3QUgdoJ26RtYQpibFsFK0IXhico9xicPsZDvRnYcicqul57P0tP0g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1183&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span/&gt;&lt;span&gt;图三&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;参考上图，复用之前的案例，第一层的时间轮tickMs=1ms, wheelSize=20, interval=20ms。第二层的时间轮的tickMs为第一层时间轮的interval，即为20ms。每一层时间轮的wheelSize是固定的，都是20，那么第二层的时间轮的总体时间跨度interval为400ms。以此类推，这个400ms也是第三层的tickMs的大小，第三层的时间轮的总体时间跨度为8000ms。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;刚才提到的350ms的任务，不会插入到第一层时间轮，会插入到interval=20*20的第二层时间轮中，具体插入到时间轮的哪个bucket呢？先用350/tickMs(20)=virtualId(17)，然后virtualId(17) %wheelSize (20) = 17，所以350会放在第17个bucket。如果此时有一个450ms后执行的任务，那么会放在第三层时间轮中，按照刚才的计算公式，会放在第0个bucket。第0个bucket里会包含&lt;/span&gt;&lt;span&gt;[400,800)ms&lt;/span&gt;&lt;span&gt;的任务。&lt;/span&gt;&lt;span&gt;随着时间流逝，当时间过去了400ms，那么450ms后就要执行的任务还剩下50ms的时间才能执行，此时有一个时间轮降级的操作，将50ms任务重新提交到层级时间轮中，那么此时50ms的任务根据公式会放入第二个时间轮的第2个bucket中，此bucket的时间范围为[40,60)ms，然后再经过40ms，这个50ms的任务又会被监控到，此时距离任务执行还有10ms，同样将10ms的任务提交到层级时间轮，此时会加入到第一层时间轮的第10个bucket，所以再经过10ms后，此任务到期，最终执行。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;整个时间轮的升级降级操作是不是很类似于我们的时钟？ 第一层时间轮tickMs=1s, wheelSize=60，interval=1min，此为秒钟；第二层tickMs=1min，wheelSize=60，interval=1hour，此为分钟；第三层tickMs=1hour，wheelSize为12，interval为12hours，此为时钟。而钟表的指针就对应程序中的currentTime，这个后面分析代码时候会讲到（对这个的理解也是时间轮理解的重点和难点）。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;▍&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;2.4 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;任务添加和驱动时间轮滚动核心流程图&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;322&quot; data-backw=&quot;562&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;562&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;409&quot; data-ratio=&quot;0.5736994219653179&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1wBZCGiaYqBG8fiaH5DpcXl4gX9dSJhFzFeEWic4vjFkWp5Sng55EQSXoSZIIA9yIlKezQgWkiaT7bRuAHrNWq1J6A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1384&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图四&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;▍&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;2.5 重点代码介绍&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这是往SystenTimer中添加一个任务。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;private&lt;/span&gt; def &lt;span class=&quot;code-snippet__title&quot;&gt;addTimerTaskEntry&lt;/span&gt;(&lt;span class=&quot;code-snippet__params&quot;&gt;timerTaskEntry: TimerTaskEntry&lt;/span&gt;): Unit&lt;/span&gt; = {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (!timingWheel.&lt;span class=&quot;code-snippet__keyword&quot;&gt;add&lt;/span&gt;(timerTaskEntry)) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (!timerTaskEntry.cancelled)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      taskExecutor.submit(timerTaskEntry.timerTask)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;timingWheel添加任务，递归添加直到添加该任务进合适的时间轮的bucket中&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;def &lt;span class=&quot;code-snippet__title&quot;&gt;add&lt;/span&gt;(&lt;span class=&quot;code-snippet__params&quot;&gt;timerTaskEntry: TimerTaskEntry&lt;/span&gt;): Boolean&lt;/span&gt; = {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  val expiration = timerTaskEntry.expirationMs&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (timerTaskEntry.cancelled) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__literal&quot;&gt;false&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  } &lt;span class=&quot;code-snippet__keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (expiration &amp;lt; currentTime + tickMs) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__literal&quot;&gt;false&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  } &lt;span class=&quot;code-snippet__keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (expiration &amp;lt; currentTime + interval) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    val virtualId = expiration / tickMs&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    val bucket = buckets((virtualId % wheelSize.toLong).toInt)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    bucket.&lt;span class=&quot;code-snippet__keyword&quot;&gt;add&lt;/span&gt;(timerTaskEntry)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (bucket.setExpiration(virtualId * tickMs)) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      queue.offer(bucket)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__literal&quot;&gt;true&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  } &lt;span class=&quot;code-snippet__keyword&quot;&gt;else&lt;/span&gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (overflowWheel == &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt;) addOverflowWheel()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    overflowWheel.&lt;span class=&quot;code-snippet__keyword&quot;&gt;add&lt;/span&gt;(timerTaskEntry)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在本层级时间轮里添加上一层时间轮里的过程，注意的是在下一层时间轮的interval为上一层时间轮的tickMs。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;java&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;private&lt;/span&gt;[&lt;span class=&quot;code-snippet__keyword&quot;&gt;this&lt;/span&gt;] &lt;span class=&quot;code-snippet__function&quot;&gt;def &lt;span class=&quot;code-snippet__title&quot;&gt;addOverflowWheel&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;()&lt;/span&gt;: Unit &lt;/span&gt;= {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;synchronized&lt;/span&gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (overflowWheel == &lt;span class=&quot;code-snippet__keyword&quot;&gt;null&lt;/span&gt;) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      overflowWheel = &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; TimingWheel(&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        tickMs = interval,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        wheelSize = wheelSize,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        startMs = currentTime,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        taskCounter = taskCounter,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        queue&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      )&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;驱动时间轮滚动过程：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;注意这里会存在一个递归，一直驱动时间轮的指针滚动直到时间不足于驱动上层的时间轮滚动。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;kotlin&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;def advanceClock(timeMs: &lt;span class=&quot;code-snippet__built_in&quot;&gt;Long&lt;/span&gt;): &lt;span class=&quot;code-snippet__built_in&quot;&gt;Unit&lt;/span&gt; = {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (timeMs &amp;gt;= currentTime + tickMs) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    currentTime = timeMs - (timeMs % tickMs)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (overflowWheel != &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt;) overflowWheel.advanceClock(currentTime)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;驱动源：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;kotlin&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;private&lt;/span&gt;[&lt;span class=&quot;code-snippet__keyword&quot;&gt;this&lt;/span&gt;] &lt;span class=&quot;code-snippet__keyword&quot;&gt;val&lt;/span&gt; reinsert = (timerTaskEntry: TimerTaskEntry) =&amp;gt; addTimerTaskEntry(timerTaskEntry)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;def advanceClock(timeoutMs: &lt;span class=&quot;code-snippet__built_in&quot;&gt;Long&lt;/span&gt;): &lt;span class=&quot;code-snippet__built_in&quot;&gt;Boolean&lt;/span&gt; = {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;var&lt;/span&gt; bucket = delayQueue.poll(timeoutMs, TimeUnit.MILLISECONDS)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (bucket != &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt;) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    writeLock.lock()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;try&lt;/span&gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__keyword&quot;&gt;while&lt;/span&gt; (bucket != &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt;) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        timingWheel.advanceClock(bucket.getExpiration())&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;       &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        bucket.flush(reinsert)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;       &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        bucket = delayQueue.poll()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    } &lt;span class=&quot;code-snippet__keyword&quot;&gt;finally&lt;/span&gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      writeLock.unlock()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__literal&quot;&gt;true&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  } &lt;span class=&quot;code-snippet__keyword&quot;&gt;else&lt;/span&gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__literal&quot;&gt;false&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;3. &lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;strong/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.0734375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jE5bOw22iaBtFvdK9icOj3ibAXa8W3tqZ2lQDEaA5XcCDJ5cVIic2221PzXcw0oo69kvia8ojgPZnEV4jPxZURBln4A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot; data-backw=&quot;562&quot; data-backh=&quot;41&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span data-shimo-docs=&quot;[[20,&amp;quot;通过以上工作，滴滴Presto逐渐接入公司各大数据平台，并成为了公司首选Ad-Hoc查询引擎及Hive SQL加速引擎，下图可以看到某产品接入后的性能提升：\n&amp;quot;]]&quot;&gt;&lt;span data-shimo-docs=&quot;[[20,&amp;quot;但是如果看最近一个月的CPU使用率会发现，平均CPU使用率比较低，且波峰在白天10~18点，晚上基本上没有查询，CPU使用率不到5%。如下图所示：&amp;quot;,&amp;quot;0:\&amp;quot;%23333333\&amp;quot;&amp;quot;]]&quot;&gt;kafka的延迟队列使用时间轮实现，能够支持大量任务的高效触发，但是在kafka延迟队列实现方案里还是看到了delayQueue的影子，使用delayQueue是对时间轮里面的bucket放入延迟队列，以此来推动时间轮滚动，但是基于将插入和删除操作则放入时间轮中，将这些操作的时间复杂度都降为O(1)，提升效率。Kafka对性能的极致追求让它把最合适的组件放在最适合的位置。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;本文作者&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;h3&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;▬&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/h3&gt;&lt;h3&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;106&quot; data-backw=&quot;562&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;562&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;106&quot; data-ratio=&quot;0.18946188340807174&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1wBZCGiaYqBG8fiaH5DpcXl4gX9dSJhFzFSfRy6bcPNkSCjLkT4a5KRa0Rh1n8icXoTBmxqDdEibibXiaK5vI6zfCliag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;892&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span data-shimo-docs=&quot;[[20,&amp;quot;通过以上工作，滴滴Presto逐渐接入公司各大数据平台，并成为了公司首选Ad-Hoc查询引擎及Hive SQL加速引擎，下图可以看到某产品接入后的性能提升：\n&amp;quot;]]&quot;&gt;&lt;span data-shimo-docs=&quot;[[20,&amp;quot;但是如果看最近一个月的CPU使用率会发现，平均CPU使用率比较低，且波峰在白天10~18点，晚上基本上没有查询，CPU使用率不到5%。如下图所示：&amp;quot;,&amp;quot;0:\&amp;quot;%23333333\&amp;quot;&amp;quot;]]&quot;&gt;&lt;span data-shimo-docs=&quot;[[20,&amp;quot;所以，解决晚上资源浪费问题是我们今后需要解决的难题。&amp;quot;,&amp;quot;0:\&amp;quot;%23333333\&amp;quot;&amp;quot;],[20,&amp;quot;\n同时，为了不与开源社区脱节，我们打算升级PrestoDB 0.215到PrestoSQL 340版本，届时会把我们的Presto on Druid代码开源出来，回馈社区。&amp;quot;]]&quot;&gt;滴滴车险团队架构师，负责车险核心系统的架构和设计，十年互联网研发架构经验，其中五年中间件与基础架构经验，对高并发，高可用以及分布式应用的架构设计有丰富的实战经验，尤其对分布式消息队列，分布式流程编排引擎、分布式数据库中间件有较深入的研究，热爱技术，崇尚开源，是Kafka、RocketMQ、Conductor等多个知名开源项目的源码贡献者。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/h3&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;团队招聘&lt;/strong&gt;&lt;strong/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;▬&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-shimo-docs=&quot;[[20,&amp;quot;对于低重要度的特征，最终做了删除，从而降低模型大小。例如我们发现方位角的重要度在实际模型训练中不如角变量。推测方位角本身的不连续性（0 = 2pi）可能对模型训练是一种干扰。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;对于异常值，做了基本的数据清洗，如无效的速度值，无效的方位角；对于不足的GPS序列长度，用0进行填充（但需要额外注意起点属性）等。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;3. 模型选择、训练与效果&amp;quot;,&amp;quot;8:1&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;DNN&amp;quot;,&amp;quot;8:1&amp;quot;],[20,&amp;quot;：只需要相对简单的算法实现，引入较小的模型库。然而GPS轨迹数据具有典型的时间序列特征，在4万样本下，应用利用DNN模型调参优化后，训练结果准确率最高达到91%。Bad case中存在大量时间不敏感的情形，最典型的情形就是——轨迹由差转优时，判定结果未能及时转变为高质量。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;CNN&amp;quot;,&amp;quot;8:1&amp;quot;],[20,&amp;quot;：这里可以尝试两种实现方式，一种是通过生成bitmap进行识别，然而GPS跨度不确定性较高，方向性不易表达，在实现上具有一定困难。第二种将序列化数据转化为二维数组，C模型能够识别出前后时间戳之间的变化特征，但并不能保留更长的时间的变化特征。最终训练出的准确率在93%左右。另外，CNN模型应用在移动端有一个明显的缺点，即模型尺寸一般较大。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;LSTM（&amp;quot;,&amp;quot;8:1&amp;quot;],[20,&amp;quot;长短期记忆网络&amp;quot;],[20,&amp;quot;）&amp;quot;,&amp;quot;8:1&amp;quot;],[20,&amp;quot;：一种特殊的RNN模型，相比前述模型对轨迹质量序列判定有明显优势。在轨迹质量由好转差，或由差转好的识别上具有非常高的灵敏度，使用128个unit能够达到97%的准确率。缺点是LSTM模型训练速度相对较慢，算法库实现相对复杂。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;最终我们选择了使用LSTM模型。使用LSTM的训练结果，准确率大幅提升。在剩余3%的错误样例中，很多轨迹在形态上表现出较高的真实性，但却无法同路网进行匹配。理论上通过引入路网属性能够上带来准确率的进一步提升，然而这种数据的耦合脱离了轨迹质量判定的初衷——服务于偏航引擎专家系统，而非直接用于偏航判定。对此我们将会在最后进行更详细的介绍。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3&amp;quot;],[20,&amp;quot;4. 移动端性能优化&amp;quot;,&amp;quot;8:1&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;模型推算性能对于移动端尤为重要。偏航场景下，GPS更新频繁，选择在必要的时候进行模型推算能够避免不必要的计算开销。通常我们会计算当前GPS点与规划路线的偏离度，只有偏离度大于阈值时才会进行轨迹质量判定。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;基于深度学习的专家系统探索&amp;quot;,&amp;quot;27:\&amp;quot;14\&amp;quot;|8:1&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;32:2&amp;quot;],[20,&amp;quot;轨迹质量模型作为偏航判定的重要依据，能够以较小的代价移植到移动端。如果不考虑前端性能及数据限制，我们完全可以定义整个偏航判定问题，训练相应的偏航模型。然而偏航场景种类繁多，过于复杂，训练出一套通用的偏航模型需要大量的数据，充足的路网信息，和较大的模型存储，这对于移动端而言不太现实。  &amp;quot;]]&quot;&gt;&lt;span&gt;滴滴车险团队基于滴滴近百万辆车和海量数据，通过线上化、科技化、数据化的手段，达到车险的降赔付、降发生，降保费，为乘客、司机、以及车队、合作伙伴提供方便快捷高效的车险金融服务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-shimo-docs=&quot;[[20,&amp;quot;对于低重要度的特征，最终做了删除，从而降低模型大小。例如我们发现方位角的重要度在实际模型训练中不如角变量。推测方位角本身的不连续性（0 = 2pi）可能对模型训练是一种干扰。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;对于异常值，做了基本的数据清洗，如无效的速度值，无效的方位角；对于不足的GPS序列长度，用0进行填充（但需要额外注意起点属性）等。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;3. 模型选择、训练与效果&amp;quot;,&amp;quot;8:1&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;DNN&amp;quot;,&amp;quot;8:1&amp;quot;],[20,&amp;quot;：只需要相对简单的算法实现，引入较小的模型库。然而GPS轨迹数据具有典型的时间序列特征，在4万样本下，应用利用DNN模型调参优化后，训练结果准确率最高达到91%。Bad case中存在大量时间不敏感的情形，最典型的情形就是——轨迹由差转优时，判定结果未能及时转变为高质量。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;CNN&amp;quot;,&amp;quot;8:1&amp;quot;],[20,&amp;quot;：这里可以尝试两种实现方式，一种是通过生成bitmap进行识别，然而GPS跨度不确定性较高，方向性不易表达，在实现上具有一定困难。第二种将序列化数据转化为二维数组，C模型能够识别出前后时间戳之间的变化特征，但并不能保留更长的时间的变化特征。最终训练出的准确率在93%左右。另外，CNN模型应用在移动端有一个明显的缺点，即模型尺寸一般较大。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;LSTM（&amp;quot;,&amp;quot;8:1&amp;quot;],[20,&amp;quot;长短期记忆网络&amp;quot;],[20,&amp;quot;）&amp;quot;,&amp;quot;8:1&amp;quot;],[20,&amp;quot;：一种特殊的RNN模型，相比前述模型对轨迹质量序列判定有明显优势。在轨迹质量由好转差，或由差转好的识别上具有非常高的灵敏度，使用128个unit能够达到97%的准确率。缺点是LSTM模型训练速度相对较慢，算法库实现相对复杂。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;最终我们选择了使用LSTM模型。使用LSTM的训练结果，准确率大幅提升。在剩余3%的错误样例中，很多轨迹在形态上表现出较高的真实性，但却无法同路网进行匹配。理论上通过引入路网属性能够上带来准确率的进一步提升，然而这种数据的耦合脱离了轨迹质量判定的初衷——服务于偏航引擎专家系统，而非直接用于偏航判定。对此我们将会在最后进行更详细的介绍。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3&amp;quot;],[20,&amp;quot;4. 移动端性能优化&amp;quot;,&amp;quot;8:1&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;模型推算性能对于移动端尤为重要。偏航场景下，GPS更新频繁，选择在必要的时候进行模型推算能够避免不必要的计算开销。通常我们会计算当前GPS点与规划路线的偏离度，只有偏离度大于阈值时才会进行轨迹质量判定。&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;7:3|text-indent:\&amp;quot;1\&amp;quot;&amp;quot;],[20,&amp;quot;基于深度学习的专家系统探索&amp;quot;,&amp;quot;27:\&amp;quot;14\&amp;quot;|8:1&amp;quot;],[20,&amp;quot;\n&amp;quot;,&amp;quot;32:2&amp;quot;],[20,&amp;quot;轨迹质量模型作为偏航判定的重要依据，能够以较小的代价移植到移动端。如果不考虑前端性能及数据限制，我们完全可以定义整个偏航判定问题，训练相应的偏航模型。然而偏航场景种类繁多，过于复杂，训练出一套通用的偏航模型需要大量的数据，充足的路网信息，和较大的模型存储，这对于移动端而言不太现实。  &amp;quot;]]&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;团队长期招聘&lt;span&gt;java高级工程师和技术专家，&lt;/span&gt;欢迎有兴趣的小伙伴加入，可投递简历至 diditech@didiglobal.com，邮件请邮件主题请命名为「姓名-应聘部门-应聘方向」。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;135&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;135&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1wBZCGiaYqBFBFcH3cDkw5qRpibVy97GUiaCUicPhRyTg6LpWp2CFHhKZSYuQnmhyZzBnnRxJ4EuWwvI3HTgqibQ7Mw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;256&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;扫码了解更多岗位&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;延伸阅读&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;▬&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1ODEzNjI2NA==&amp;amp;mid=2247512436&amp;amp;idx=1&amp;amp;sn=1fea750185b0ec4a5c5e000db7e773e1&amp;amp;chksm=fc29dfd3cb5e56c5e8d07d13a755a3434cfd61af38a161bfde4be7eaf28b56fda65644da6971&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;112&quot; data-backw=&quot;562&quot; data-ratio=&quot;0.2&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1wBZCGiaYqBG8fiaH5DpcXl4gX9dSJhFzFUvNyoeeVzZpUV1iao6ZywZNm1lvQfoWJiaYJF1rICaHKIACfRhLLoIeA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1ODEzNjI2NA==&amp;amp;mid=2247507588&amp;amp;idx=1&amp;amp;sn=a4cc88ed4a14007f5d39da9e7c0e6d02&amp;amp;chksm=fc29b023cb5e393522bc096473e6ff4a5b2045bb591dd62609a6cbae7a2727991c6d82d628e3&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;112&quot; data-backw=&quot;562&quot; data-ratio=&quot;0.2&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1wBZCGiaYqBHraEAV6GKpIj4dQOQNs9ggIppJ4Jhjb2ic2K75ZnPYjTCBicrmiaEgQtH17Ks8E8uk0QeojUDD9whibQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU1ODEzNjI2NA==&amp;amp;mid=2247493821&amp;amp;idx=1&amp;amp;sn=c3fa1e6733cf9f2b173793adeb0139b3&amp;amp;chksm=fc29861acb5e0f0c5bb5bf02d4e0cafc68cd19232643be1cb798a05bd4a60e65d8705281a0ac&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot; hasload=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.2&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1000&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1wBZCGiaYqBFPvfKQEIHKT8V3yZSGBZQtHgjI7CoApEqXV3uRhYFH383kdxwNSsfOUib2NViciaJeYHtJk1CvZdVGA/640?wx_fmt=png&quot; data-backw=&quot;562&quot; data-backh=&quot;112&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;内容编辑&lt;span&gt; | Charlotte&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;联系我们 | DiDiTech@didiglobal.com&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;pre ng-bind-html=&quot;message.MMActualContent&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;162&quot; data-backw=&quot;562&quot; data-ratio=&quot;0.28888888888888886&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1wBZCGiaYqBHCquJeOibVaFwqqC4iadSqFxSJRyP1G2V6ZB0tXzfDbHQmq5LXdiawGrVAfTs5INmjsvxOnH4dU8how/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/pre&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8a1133ac7a7a479ab4f433875ac1a95c</guid>
<title>[推荐] 工具 | 一个轻量级业务中台开发框架</title>
<link>https://toutiao.io/k/6qs3yvv</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;weui-dialog&quot;&gt;
      &lt;p class=&quot;weui-dialog__hd&quot;&gt;&lt;strong class=&quot;weui-dialog__title&quot;&gt;&quot;Top Stories&quot; is disabled&lt;/strong&gt;&lt;/p&gt;
      &lt;p class=&quot;weui-dialog__bd&quot;&gt;
        Enable &quot;Top Stories&quot; in &quot;Settings&quot; &amp;gt; &quot;General&quot; &amp;gt; &quot;Manage Discover&quot;      &lt;/p&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>