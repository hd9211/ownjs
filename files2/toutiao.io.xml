<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>877b0dad1990c530fd20070a9f7689a9</guid>
<title>80 行 Python 代码搞定全国区划代码</title>
<link>https://toutiao.io/k/a8212hf</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;GitHub源码分享&lt;span/&gt;&lt;/h3&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;微信搜索：码农StayUp&lt;/p&gt;&lt;p&gt;主页地址：https://gozhuyinglong.github.io&lt;/p&gt;&lt;p&gt;源码分享：https://github.com/gozhuyinglong/blog-demos&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1. 前言&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在网站建设中一般会用到全国行政区域划分，以便于做区域数据分析。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我们用 Python 来爬取行政区域数据，数据来源为比较权威的国家统计局。爬取的页面为2020年统计用区划代码和城乡划分代码。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;这里有个疑问，为啥统计局只提供了网页版呢？提供文件版岂不是更方便大众。欢迎了解的小伙伴给我留言。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2. 网站分析&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在爬取数据之前要做的便是网站分析，通过分析来判断使用何种方式来爬取。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.1 省份页面&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个静态页面，其二级页面使用的是相对地址，通过 class=provincetr 的&lt;code&gt;tr&lt;/code&gt;元素来定位&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.41854838709677417&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BVm2jk5Hyj7IibKLc8NURAqIwXVQxk9Bttmq0R5UgZ0z4Fp9icoltN5Eg4bxlqnLgABnnEkTjZBwfrA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;省份页面&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2 城市页面&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个静态页面，其二级页面使用的是相对地址，通过 class=citytr 的&lt;code&gt;tr&lt;/code&gt;元素来定位&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4411290322580645&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BVm2jk5Hyj7IibKLc8NURAqIxDeibgU9U2ZRF1CMJDd6pMZtVkBk1UfwKA6Y2NS497icCHc6fI8SJyUQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;城市页面&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3 区县页面&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个静态页面，其二级页面使用的是相对地址，通过 class=countytr 的&lt;code&gt;tr&lt;/code&gt;元素来定位&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4112903225806452&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BVm2jk5Hyj7IibKLc8NURAqIWVve40W6u4wn9gdTpoUwTLUky5CicHNZlINKn394J2vfLoE6niaUD0Jw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;区县页面&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.4 城镇页面&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个静态页面，其二级页面使用的是相对地址，通过 class=towntr 的&lt;code&gt;tr&lt;/code&gt;元素来定位&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.38064516129032255&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BVm2jk5Hyj7IibKLc8NURAqI7ichjlFLtJhBRlmVmeZB3NJviaGHQdWhljLf9bHiclAVQj8PoiaE4F7RZg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;城镇页面&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5 村庄页面&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个静态页面，没有二级页面，通过 class=villagetr 的&lt;code&gt;tr&lt;/code&gt;元素来定位&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.38306451612903225&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BVm2jk5Hyj7IibKLc8NURAqI76icS2sz57LZticjC92uAFiaCkCruAewxTlHFcIXywlJLCMeFBFyHycOA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot;/&gt;&lt;figcaption&gt;村庄页面&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3. 安装所需库&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过上面的分析，使用爬取静态网页的方式即可。下面是一些必要的库，需要提前安装好：Requests、BeautifulSoup、lxml。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.1 Requests&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Requests 是一个 Python 的 HTTP 客户端库，用于访问 URL 网络资源。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;安装Requests库：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;pip install requests&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2 BeautifulSoup&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Beautifu lSoup 是一个可以从 HTML 或 XML 文件中提取数据的 Python 库。它能够通过指定的转换器实现页面文档的导航、查找、修改等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;安装 BeautifulSoup 库：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;pip install beautifulsoup4&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.3 lxml&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;lxml 是一种使用 Python 编写的库，可以迅速、灵活地处理 XML 和 HTML。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;它支持 XML Path Language (XPath) 和 Extensible Stylesheet Language Transformation (XSLT)，并且实现了常见的 ElementTree API。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;安装lxml库：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;pip install lxml&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4. 代码实现&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;爬虫分以下几步：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;使用Requests库来获取网页。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用BeautifulSoup和lxml库解析网页。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用Python的File来存储数据。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输出文件为：当前py文件所在目录，文件名称：area-number-2020.txt&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输出结果为：级别、区划代码、名称，中间使用制表符分隔，便于存到Exce和数据库中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面看详细代码：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;# -*-coding:utf-8-*-&lt;/span&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; requests&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; bs4 &lt;span&gt;import&lt;/span&gt; BeautifulSoup&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 根据地址获取页面内容，并返回BeautifulSoup&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;get_html&lt;/span&gt;&lt;span&gt;(url)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;# 若页面打开失败，则无限重试，没有后退可言&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt; &lt;span&gt;True&lt;/span&gt;:&lt;br/&gt;        &lt;span&gt;try&lt;/span&gt;:&lt;br/&gt;            &lt;span&gt;# 超时时间为1秒&lt;/span&gt;&lt;br/&gt;            response = requests.get(url, timeout=&lt;span&gt;1&lt;/span&gt;)&lt;br/&gt;            response.encoding = &lt;span&gt;&quot;GBK&quot;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; response.status_code == &lt;span&gt;200&lt;/span&gt;:&lt;br/&gt;                &lt;span&gt;return&lt;/span&gt; BeautifulSoup(response.text, &lt;span&gt;&quot;lxml&quot;&lt;/span&gt;)&lt;br/&gt;            &lt;span&gt;else&lt;/span&gt;:&lt;br/&gt;                &lt;span&gt;continue&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;except&lt;/span&gt; Exception:&lt;br/&gt;            &lt;span&gt;continue&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 获取地址前缀（用于相对地址）&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;get_prefix&lt;/span&gt;&lt;span&gt;(url)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; url[&lt;span&gt;0&lt;/span&gt;:url.rindex(&lt;span&gt;&quot;/&quot;&lt;/span&gt;) + &lt;span&gt;1&lt;/span&gt;]&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 递归抓取下一页面&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;spider_next&lt;/span&gt;&lt;span&gt;(url, lev)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; lev == &lt;span&gt;2&lt;/span&gt;:&lt;br/&gt;        spider_class = &lt;span&gt;&quot;city&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;elif&lt;/span&gt; lev == &lt;span&gt;3&lt;/span&gt;:&lt;br/&gt;        spider_class = &lt;span&gt;&quot;county&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;elif&lt;/span&gt; lev == &lt;span&gt;4&lt;/span&gt;:&lt;br/&gt;        spider_class = &lt;span&gt;&quot;town&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;else&lt;/span&gt;:&lt;br/&gt;        spider_class = &lt;span&gt;&quot;village&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; item &lt;span&gt;in&lt;/span&gt; get_html(url).select(&lt;span&gt;&quot;tr.&quot;&lt;/span&gt; + spider_class + &lt;span&gt;&quot;tr&quot;&lt;/span&gt;):&lt;br/&gt;        item_td = item.select(&lt;span&gt;&quot;td&quot;&lt;/span&gt;)&lt;br/&gt;        item_td_code = item_td[&lt;span&gt;0&lt;/span&gt;].select_one(&lt;span&gt;&quot;a&quot;&lt;/span&gt;)&lt;br/&gt;        item_td_name = item_td[&lt;span&gt;1&lt;/span&gt;].select_one(&lt;span&gt;&quot;a&quot;&lt;/span&gt;)&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; item_td_code &lt;span&gt;is&lt;/span&gt; &lt;span&gt;None&lt;/span&gt;:&lt;br/&gt;            item_href = &lt;span&gt;None&lt;/span&gt;&lt;br/&gt;            item_code = item_td[&lt;span&gt;0&lt;/span&gt;].text&lt;br/&gt;            item_name = item_td[&lt;span&gt;1&lt;/span&gt;].text&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; lev == &lt;span&gt;5&lt;/span&gt;:&lt;br/&gt;                item_name = item_td[&lt;span&gt;2&lt;/span&gt;].text&lt;br/&gt;        &lt;span&gt;else&lt;/span&gt;:&lt;br/&gt;            item_href = item_td_code.get(&lt;span&gt;&quot;href&quot;&lt;/span&gt;)&lt;br/&gt;            item_code = item_td_code.text&lt;br/&gt;            item_name = item_td_name.text&lt;br/&gt;        &lt;span&gt;# 输出：级别、区划代码、名称&lt;/span&gt;&lt;br/&gt;        content2 = str(lev) + &lt;span&gt;&quot;\t&quot;&lt;/span&gt; + item_code + &lt;span&gt;&quot;\t&quot;&lt;/span&gt; + item_name&lt;br/&gt;        print(content2)&lt;br/&gt;        f.write(content2 + &lt;span&gt;&quot;\n&quot;&lt;/span&gt;)&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; item_href &lt;span&gt;is&lt;/span&gt; &lt;span&gt;not&lt;/span&gt; &lt;span&gt;None&lt;/span&gt;:&lt;br/&gt;            spider_next(get_prefix(url) + item_href, lev + &lt;span&gt;1&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 入口&lt;/span&gt;&lt;br/&gt;&lt;span&gt;if&lt;/span&gt; __name__ == &lt;span&gt;&#x27;__main__&#x27;&lt;/span&gt;:&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;# 抓取省份页面&lt;/span&gt;&lt;br/&gt;    province_url = &lt;span&gt;&quot;http://www.stats.gov.cn/tjsj/tjbz/tjyqhdmhcxhfdm/2020/index.html&quot;&lt;/span&gt;&lt;br/&gt;    province_list = get_html(province_url).select(&lt;span&gt;&#x27;tr.provincetr a&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;# 数据写入到当前文件夹下 area-number-2020.txt 中&lt;/span&gt;&lt;br/&gt;    f = open(&lt;span&gt;&quot;area-number-2020.txt&quot;&lt;/span&gt;, &lt;span&gt;&quot;w&quot;&lt;/span&gt;, encoding=&lt;span&gt;&quot;utf-8&quot;&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;try&lt;/span&gt;:&lt;br/&gt;        &lt;span&gt;for&lt;/span&gt; province &lt;span&gt;in&lt;/span&gt; province_list:&lt;br/&gt;            href = province.get(&lt;span&gt;&quot;href&quot;&lt;/span&gt;)&lt;br/&gt;            province_code = href[&lt;span&gt;0&lt;/span&gt;: &lt;span&gt;2&lt;/span&gt;] + &lt;span&gt;&quot;0000000000&quot;&lt;/span&gt;&lt;br/&gt;            province_name = province.text&lt;br/&gt;            &lt;span&gt;# 输出：级别、区划代码、名称&lt;/span&gt;&lt;br/&gt;            content = &lt;span&gt;&quot;1\t&quot;&lt;/span&gt; + province_code + &lt;span&gt;&quot;\t&quot;&lt;/span&gt; + province_name&lt;br/&gt;            print(content)&lt;br/&gt;            f.write(content + &lt;span&gt;&quot;\n&quot;&lt;/span&gt;)&lt;br/&gt;            spider_next(get_prefix(province_url) + href, &lt;span&gt;2&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;finally&lt;/span&gt;:&lt;br/&gt;        f.close()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5. 资源下载&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你只是需要行政区域数据，那么已经为你准备好了，从下面连接中下载即可。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;链接：https://pan.baidu.com/s/18MDdkczwJVuRZwsH0pFYwQ&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提取码：t2eg&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;6. 爬虫遵循的规则&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;引自：https://www.cnblogs.com/kongyijilafumi/p/13969361.html&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;遵守 Robots 协议，谨慎爬取&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;限制你的爬虫行为，禁止近乎 DDOS 的请求频率，一旦造成服务器瘫痪，约等于网络攻击&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;对于明显反爬，或者正常情况不能到达的页面不能强行突破，否则是 Hacker 行为&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果爬取到别人的隐私，立即删除，降低进局子的概率。另外要控制自己的欲望&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4488888888888889&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hXEWOsco2BVm2jk5Hyj7IibKLc8NURAqIdPiaL8god0Y85ULLx2WGRMn1iabW0iczAjnQvrDIyzoh42m6KHwBcRapg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>eca28cd18229bd9354d0f9908e4b3499</guid>
<title>测试小姐姐问我 gRPC 怎么用，我直接把这篇文章甩给了她</title>
<link>https://toutiao.io/k/w2l7bil</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;p&gt;上篇文章 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI3MjY1ODI2Ng==&amp;amp;mid=2247484210&amp;amp;idx=1&amp;amp;sn=7d26f0d5ecf68704b75fcad76f42a68f&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;gRPC，爆赞&lt;/a&gt; 直接爆了，内容主要包括：简单的 gRPC 服务，流处理模式，验证器，Token 认证和证书认证。&lt;/p&gt;&lt;p&gt;在多个平台的阅读量都创了新高，在 oschina 更是获得了首页推荐，阅读量到了 1w+，这已经是我单篇阅读的高峰了。&lt;/p&gt;&lt;p&gt;看来只要用心写还是有收获的。&lt;/p&gt;&lt;p&gt;这篇咱们还是从实战出发，主要介绍 gRPC 的发布订阅模式，REST 接口和超时控制。&lt;/p&gt;&lt;p&gt;相关代码我会都上传到 GitHub，感兴趣的小伙伴可以去查看或下载。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;发布和订阅模式&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;发布订阅是一个常见的设计模式，开源社区中已经存在很多该模式的实现。其中 docker 项目中提供了一个 pubsub 的极简实现，下面是基于 pubsub 包实现的本地发布订阅代码：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br/&gt;    &lt;span&gt;&quot;fmt&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;strings&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;time&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&quot;github.com/moby/moby/pkg/pubsub&quot;&lt;/span&gt;&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    p := pubsub.NewPublisher(&lt;span&gt;100&lt;/span&gt;*time.Millisecond, &lt;span&gt;10&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;    golang := p.SubscribeTopic(&lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;(v &lt;span&gt;interface&lt;/span&gt;{})&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; key, ok := v.(&lt;span&gt;string&lt;/span&gt;); ok {&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; strings.HasPrefix(key, &lt;span&gt;&quot;golang:&quot;&lt;/span&gt;) {&lt;br/&gt;                &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;br/&gt;    })&lt;br/&gt;    docker := p.SubscribeTopic(&lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;(v &lt;span&gt;interface&lt;/span&gt;{})&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; key, ok := v.(&lt;span&gt;string&lt;/span&gt;); ok {&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; strings.HasPrefix(key, &lt;span&gt;&quot;docker:&quot;&lt;/span&gt;) {&lt;br/&gt;                &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;br/&gt;    })&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;go&lt;/span&gt; p.Publish(&lt;span&gt;&quot;hi&quot;&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;go&lt;/span&gt; p.Publish(&lt;span&gt;&quot;golang: https://golang.org&quot;&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;go&lt;/span&gt; p.Publish(&lt;span&gt;&quot;docker: https://www.docker.com/&quot;&lt;/span&gt;)&lt;br/&gt;    time.Sleep(&lt;span&gt;1&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;go&lt;/span&gt; &lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;        fmt.Println(&lt;span&gt;&quot;golang topic:&quot;&lt;/span&gt;, &amp;lt;-golang)&lt;br/&gt;    }()&lt;br/&gt;    &lt;span&gt;go&lt;/span&gt; &lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;        fmt.Println(&lt;span&gt;&quot;docker topic:&quot;&lt;/span&gt;, &amp;lt;-docker)&lt;br/&gt;    }()&lt;br/&gt;&lt;br/&gt;    &amp;lt;-&lt;span&gt;make&lt;/span&gt;(&lt;span&gt;chan&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这段代码首先通过 &lt;code&gt;pubsub.NewPublisher&lt;/code&gt; 创建了一个对象，然后通过 &lt;code&gt;p.SubscribeTopic&lt;/code&gt; 实现订阅，&lt;code&gt;p.Publish&lt;/code&gt; 来发布消息。&lt;/p&gt;&lt;p&gt;执行效果如下：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;docker topic: docker: https:&lt;span&gt;//www.docker.com/&lt;/span&gt;&lt;br/&gt;golang topic: golang: https:&lt;span&gt;//golang.org&lt;/span&gt;&lt;br/&gt;fatal error: all goroutines are asleep - deadlock!&lt;br/&gt;&lt;br/&gt;goroutine &lt;span&gt;1&lt;/span&gt; [&lt;span&gt;chan&lt;/span&gt; receive]:&lt;br/&gt;main.main()&lt;br/&gt;    /Users/zhangyongxin/src/&lt;span&gt;go&lt;/span&gt;-example/grpc-example/pubsub/server/pubsub.&lt;span&gt;go&lt;/span&gt;:&lt;span&gt;43&lt;/span&gt; +&lt;span&gt;0x1e7&lt;/span&gt;&lt;br/&gt;exit status &lt;span&gt;2&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;订阅消息可以正常打印。&lt;/p&gt;&lt;p&gt;但有一个死锁报错，是因为这条语句 &lt;code&gt;&amp;lt;-make(chan bool)&lt;/code&gt; 引起的。但是如果没有这条语句就不能正常打印订阅消息。&lt;/p&gt;&lt;p&gt;这里就不是很懂了，有没有大佬知道，欢迎留言，求指导。&lt;/p&gt;&lt;p&gt;接下来就用 gRPC 和 pubsub 包实现发布订阅模式。&lt;/p&gt;&lt;p&gt;需要实现四个部分：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;proto&lt;/strong&gt; 文件；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;服务端：&lt;/strong&gt; 用于接收订阅请求，同时也接收发布请求，并将发布请求转发给订阅者；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;订阅客户端：&lt;/strong&gt; 用于从服务端订阅消息，处理消息；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;发布客户端：&lt;/strong&gt; 用于向服务端发送消息。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;&lt;span&gt;proto 文件&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;首先定义 proto 文件：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;syntax&lt;/span&gt; = &lt;span&gt;&quot;proto3&quot;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;package&lt;/span&gt; proto;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;message&lt;/span&gt; String {&lt;br/&gt;    &lt;span&gt;string&lt;/span&gt; value = &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;service&lt;/span&gt; PubsubService {&lt;br/&gt;    &lt;span&gt;rpc&lt;/span&gt; Publish (String) returns (String);&lt;br/&gt;    &lt;span&gt;rpc&lt;/span&gt; SubscribeTopic (String) returns (stream String);&lt;br/&gt;    &lt;span&gt;rpc&lt;/span&gt; Subscribe (String) returns (stream String);&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;定义三个方法，分别是一个发布 &lt;code&gt;Publish&lt;/code&gt; 和两个订阅 &lt;code&gt;Subscribe&lt;/code&gt; 和 &lt;code&gt;SubscribeTopic&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;code&gt;Subscribe&lt;/code&gt; 方法接收全部消息，而 &lt;code&gt;SubscribeTopic&lt;/code&gt; 根据特定的 &lt;code&gt;Topic&lt;/code&gt; 接收消息。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;服务端&lt;/span&gt;&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br/&gt;    &lt;span&gt;&quot;context&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;fmt&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;log&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;net&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;server/proto&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;strings&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;time&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&quot;github.com/moby/moby/pkg/pubsub&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc/reflection&quot;&lt;/span&gt;&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;type&lt;/span&gt; PubsubService &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt;    pub *pubsub.Publisher&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(p *PubsubService)&lt;/span&gt; &lt;span&gt;Publish&lt;/span&gt;&lt;span&gt;(ctx context.Context, arg *proto.String)&lt;/span&gt; &lt;span&gt;(*proto.String, error)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    p.pub.Publish(arg.GetValue())&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &amp;amp;proto.String{}, &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(p *PubsubService)&lt;/span&gt; &lt;span&gt;SubscribeTopic&lt;/span&gt;&lt;span&gt;(arg *proto.String, stream proto.PubsubService_SubscribeTopicServer)&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    ch := p.pub.SubscribeTopic(&lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;(v &lt;span&gt;interface&lt;/span&gt;{})&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; key, ok := v.(&lt;span&gt;string&lt;/span&gt;); ok {&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; strings.HasPrefix(key, arg.GetValue()) {&lt;br/&gt;                &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;br/&gt;    })&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; v := &lt;span&gt;range&lt;/span&gt; ch {&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; err := stream.Send(&amp;amp;proto.String{Value: v.(&lt;span&gt;string&lt;/span&gt;)}); &lt;span&gt;nil&lt;/span&gt; != err {&lt;br/&gt;            &lt;span&gt;return&lt;/span&gt; err&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(p *PubsubService)&lt;/span&gt; &lt;span&gt;Subscribe&lt;/span&gt;&lt;span&gt;(arg *proto.String, stream proto.PubsubService_SubscribeServer)&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    ch := p.pub.Subscribe()&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; v := &lt;span&gt;range&lt;/span&gt; ch {&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; err := stream.Send(&amp;amp;proto.String{Value: v.(&lt;span&gt;string&lt;/span&gt;)}); &lt;span&gt;nil&lt;/span&gt; != err {&lt;br/&gt;            &lt;span&gt;return&lt;/span&gt; err&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;NewPubsubService&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; *&lt;span&gt;PubsubService&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &amp;amp;PubsubService{pub: pubsub.NewPublisher(&lt;span&gt;100&lt;/span&gt;*time.Millisecond, &lt;span&gt;10&lt;/span&gt;)}&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    lis, err := net.Listen(&lt;span&gt;&quot;tcp&quot;&lt;/span&gt;, &lt;span&gt;&quot;:50051&quot;&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;        log.Fatalf(&lt;span&gt;&quot;failed to listen: %v&quot;&lt;/span&gt;, err)&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// 简单调用&lt;/span&gt;&lt;br/&gt;    server := grpc.NewServer()&lt;br/&gt;    &lt;span&gt;// 注册 grpcurl 所需的 reflection 服务&lt;/span&gt;&lt;br/&gt;    reflection.Register(server)&lt;br/&gt;    &lt;span&gt;// 注册业务服务&lt;/span&gt;&lt;br/&gt;    proto.RegisterPubsubServiceServer(server, NewPubsubService())&lt;br/&gt;&lt;br/&gt;    fmt.Println(&lt;span&gt;&quot;grpc server start ...&quot;&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; err := server.Serve(lis); err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;        log.Fatalf(&lt;span&gt;&quot;failed to serve: %v&quot;&lt;/span&gt;, err)&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;对比之前的发布订阅程序，其实这里是将 &lt;code&gt;*pubsub.Publisher&lt;/code&gt; 作为了 gRPC 的结构体 &lt;code&gt;PubsubService&lt;/code&gt; 的一个成员。&lt;/p&gt;&lt;p&gt;然后还是按照 gRPC 的开发流程，实现结构体对应的三个方法。&lt;/p&gt;&lt;p&gt;最后，在注册服务时，将 &lt;code&gt;NewPubsubService()&lt;/code&gt; 服务注入，实现本地发布订阅功能。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;订阅客户端&lt;/span&gt;&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br/&gt;    &lt;span&gt;&quot;client/proto&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;context&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;fmt&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;io&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;log&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc&quot;&lt;/span&gt;&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    conn, err := grpc.Dial(&lt;span&gt;&quot;localhost:50051&quot;&lt;/span&gt;, grpc.WithInsecure())&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;        log.Fatal(err)&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;defer&lt;/span&gt; conn.Close()&lt;br/&gt;&lt;br/&gt;    client := proto.NewPubsubServiceClient(conn)&lt;br/&gt;    stream, err := client.Subscribe(&lt;br/&gt;        context.Background(), &amp;amp;proto.String{Value: &lt;span&gt;&quot;golang:&quot;&lt;/span&gt;},&lt;br/&gt;    )&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; != err {&lt;br/&gt;        log.Fatal(err)&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;go&lt;/span&gt; &lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;for&lt;/span&gt; {&lt;br/&gt;            reply, err := stream.Recv()&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; != err {&lt;br/&gt;                &lt;span&gt;if&lt;/span&gt; io.EOF == err {&lt;br/&gt;                    &lt;span&gt;break&lt;/span&gt;&lt;br/&gt;                }&lt;br/&gt;                log.Fatal(err)&lt;br/&gt;            }&lt;br/&gt;            fmt.Println(&lt;span&gt;&quot;sub1: &quot;&lt;/span&gt;, reply.GetValue())&lt;br/&gt;        }&lt;br/&gt;    }()&lt;br/&gt;&lt;br/&gt;    streamTopic, err := client.SubscribeTopic(&lt;br/&gt;        context.Background(), &amp;amp;proto.String{Value: &lt;span&gt;&quot;golang:&quot;&lt;/span&gt;},&lt;br/&gt;    )&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; != err {&lt;br/&gt;        log.Fatal(err)&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;go&lt;/span&gt; &lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;for&lt;/span&gt; {&lt;br/&gt;            reply, err := streamTopic.Recv()&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; != err {&lt;br/&gt;                &lt;span&gt;if&lt;/span&gt; io.EOF == err {&lt;br/&gt;                    &lt;span&gt;break&lt;/span&gt;&lt;br/&gt;                }&lt;br/&gt;                log.Fatal(err)&lt;br/&gt;            }&lt;br/&gt;            fmt.Println(&lt;span&gt;&quot;subTopic: &quot;&lt;/span&gt;, reply.GetValue())&lt;br/&gt;        }&lt;br/&gt;    }()&lt;br/&gt;&lt;br/&gt;    &amp;lt;-&lt;span&gt;make&lt;/span&gt;(&lt;span&gt;chan&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;新建一个 &lt;code&gt;NewPubsubServiceClient&lt;/code&gt; 对象，然后分别实现 &lt;code&gt;client.Subscribe&lt;/code&gt; 和 &lt;code&gt;client.SubscribeTopic&lt;/code&gt; 方法，再通过 goroutine 不停接收消息。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;发布客户端&lt;/span&gt;&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br/&gt;    &lt;span&gt;&quot;client/proto&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;context&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;log&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc&quot;&lt;/span&gt;&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    conn, err := grpc.Dial(&lt;span&gt;&quot;localhost:50051&quot;&lt;/span&gt;, grpc.WithInsecure())&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;        log.Fatal(err)&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;defer&lt;/span&gt; conn.Close()&lt;br/&gt;    client := proto.NewPubsubServiceClient(conn)&lt;br/&gt;&lt;br/&gt;    _, err = client.Publish(&lt;br/&gt;        context.Background(), &amp;amp;proto.String{Value: &lt;span&gt;&quot;golang: hello Go&quot;&lt;/span&gt;},&lt;br/&gt;    )&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;        log.Fatal(err)&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    _, err = client.Publish(&lt;br/&gt;        context.Background(), &amp;amp;proto.String{Value: &lt;span&gt;&quot;docker: hello Docker&quot;&lt;/span&gt;},&lt;br/&gt;    )&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt; != err {&lt;br/&gt;        log.Fatal(err)&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;新建一个 &lt;code&gt;NewPubsubServiceClient&lt;/code&gt; 对象，然后通过 &lt;code&gt;client.Publish&lt;/code&gt; 方法发布消息。&lt;/p&gt;&lt;p&gt;当代码全部写好之后，我们开三个终端来测试一下：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;终端1&lt;/strong&gt; 上启动服务端：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;go&lt;/span&gt; run main.&lt;span&gt;go&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;终端2&lt;/strong&gt; 上启动订阅客户端：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;go&lt;/span&gt; run sub_client.&lt;span&gt;go&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;终端3&lt;/strong&gt; 上执行发布客户端：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;go&lt;/span&gt; run pub_client.&lt;span&gt;go&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样，在 &lt;strong&gt;终端2&lt;/strong&gt; 上就有对应的输出了：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;subTopic:  golang: hello Go&lt;/span&gt;&lt;br/&gt;&lt;span&gt;sub1:  golang: hello Go&lt;/span&gt;&lt;br/&gt;&lt;span&gt;sub1:  docker: hello Docker&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;也可以再多开几个订阅终端，那么每一个订阅终端上都会有相同的内容输出。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;源码地址：&lt;/strong&gt; https://github.com/yongxinz/go-example/tree/main/grpc-example/pubsub&lt;/p&gt;&lt;h3&gt;&lt;span&gt;REST 接口&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;gRPC 一般用于集群内部通信，如果需要对外提供服务，大部分都是通过 REST 接口的方式。开源项目 grpc-gateway 提供了将 gRPC 服务转换成 REST 服务的能力，通过这种方式，就可以直接访问 gRPC API 了。&lt;/p&gt;&lt;p&gt;但我觉得，实际上这么用的应该还是比较少的。如果提供 REST 接口的话，直接写一个 HTTP 服务会方便很多。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;proto 文件&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;第一步还是创建一个 proto 文件：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;syntax = &lt;span&gt;&quot;proto3&quot;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;package proto;&lt;br/&gt;&lt;br/&gt;import &lt;span&gt;&quot;google/api/annotations.proto&quot;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;message StringMessage {&lt;br/&gt;  &lt;span&gt;string&lt;/span&gt; &lt;span&gt;value&lt;/span&gt; = &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;service RestService {&lt;br/&gt;    &lt;span&gt;rpc &lt;span&gt;Get&lt;/span&gt;(&lt;span&gt;StringMessage&lt;/span&gt;) &lt;span&gt;returns&lt;/span&gt; (&lt;span&gt;StringMessage&lt;/span&gt;) &lt;/span&gt;{&lt;br/&gt;        option (google.api.http) = {&lt;br/&gt;            &lt;span&gt;get&lt;/span&gt;: &lt;span&gt;&quot;/get/{value}&quot;&lt;/span&gt;&lt;br/&gt;        };&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;rpc &lt;span&gt;Post&lt;/span&gt;(&lt;span&gt;StringMessage&lt;/span&gt;) &lt;span&gt;returns&lt;/span&gt; (&lt;span&gt;StringMessage&lt;/span&gt;) &lt;/span&gt;{&lt;br/&gt;        option (google.api.http) = {&lt;br/&gt;            post: &lt;span&gt;&quot;/post&quot;&lt;/span&gt;&lt;br/&gt;            body: &lt;span&gt;&quot;*&quot;&lt;/span&gt;&lt;br/&gt;        };&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;定义一个 REST 服务 &lt;code&gt;RestService&lt;/code&gt;，分别实现 &lt;code&gt;GET&lt;/code&gt; 和 &lt;code&gt;POST&lt;/code&gt; 方法。&lt;/p&gt;&lt;p&gt;安装插件：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;go &lt;span&gt;get&lt;/span&gt; -u github.com/grpc-ecosystem/grpc-gateway/protoc-gen-grpc-gateway&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;生成对应代码：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;protoc -I/usr/&lt;span&gt;local&lt;/span&gt;/include -I. \&lt;br/&gt;    -I$GOPATH/pkg/&lt;span&gt;mod&lt;/span&gt; \&lt;br/&gt;    -I$GOPATH/pkg/&lt;span&gt;mod&lt;/span&gt;/github.com/grpc-ecosystem/grpc-gateway@v1&lt;span&gt;.16&lt;/span&gt;&lt;span&gt;.0&lt;/span&gt;/third_party/googleapis \&lt;br/&gt;    &lt;span&gt;--grpc-gateway_out=. --go_out=plugins=grpc:.\&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;--swagger_out=. \&lt;/span&gt;&lt;br/&gt;    helloworld.proto&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;--grpc-gateway_out&lt;/code&gt; 参数可生成对应的 gw 文件，&lt;code&gt;--swagger_out&lt;/code&gt; 参数可生成对应的 API 文档。&lt;/p&gt;&lt;p&gt;在我这里生成的两个文件如下：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;helloworld&lt;/span&gt;&lt;span&gt;.pb&lt;/span&gt;&lt;span&gt;.gw&lt;/span&gt;&lt;span&gt;.go&lt;/span&gt;&lt;br/&gt;&lt;span&gt;helloworld&lt;/span&gt;&lt;span&gt;.swagger&lt;/span&gt;&lt;span&gt;.json&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;&lt;span&gt;REST 服务&lt;/span&gt;&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br/&gt;    &lt;span&gt;&quot;context&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;log&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;net/http&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&quot;rest/proto&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&quot;github.com/grpc-ecosystem/grpc-gateway/runtime&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc&quot;&lt;/span&gt;&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    ctx := context.Background()&lt;br/&gt;    ctx, cancel := context.WithCancel(ctx)&lt;br/&gt;    &lt;span&gt;defer&lt;/span&gt; cancel()&lt;br/&gt;&lt;br/&gt;    mux := runtime.NewServeMux()&lt;br/&gt;&lt;br/&gt;    err := proto.RegisterRestServiceHandlerFromEndpoint(&lt;br/&gt;        ctx, mux, &lt;span&gt;&quot;localhost:50051&quot;&lt;/span&gt;,&lt;br/&gt;        []grpc.DialOption{grpc.WithInsecure()},&lt;br/&gt;    )&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;        log.Fatal(err)&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    http.ListenAndServe(&lt;span&gt;&quot;:8080&quot;&lt;/span&gt;, mux)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里主要是通过实现 gw 文件中的 &lt;code&gt;RegisterRestServiceHandlerFromEndpoint&lt;/code&gt; 方法来连接 gRPC 服务。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;gRPC 服务&lt;/span&gt;&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br/&gt;    &lt;span&gt;&quot;context&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;net&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&quot;rest/proto&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc&quot;&lt;/span&gt;&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;type&lt;/span&gt; RestServiceImpl &lt;span&gt;struct&lt;/span&gt;{}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(r *RestServiceImpl)&lt;/span&gt; &lt;span&gt;Get&lt;/span&gt;&lt;span&gt;(ctx context.Context, message *proto.StringMessage)&lt;/span&gt; &lt;span&gt;(*proto.StringMessage, error)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &amp;amp;proto.StringMessage{Value: &lt;span&gt;&quot;Get hi:&quot;&lt;/span&gt; + message.Value + &lt;span&gt;&quot;#&quot;&lt;/span&gt;}, &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(r *RestServiceImpl)&lt;/span&gt; &lt;span&gt;Post&lt;/span&gt;&lt;span&gt;(ctx context.Context, message *proto.StringMessage)&lt;/span&gt; &lt;span&gt;(*proto.StringMessage, error)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &amp;amp;proto.StringMessage{Value: &lt;span&gt;&quot;Post hi:&quot;&lt;/span&gt; + message.Value + &lt;span&gt;&quot;@&quot;&lt;/span&gt;}, &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    grpcServer := grpc.NewServer()&lt;br/&gt;    proto.RegisterRestServiceServer(grpcServer, &lt;span&gt;new&lt;/span&gt;(RestServiceImpl))&lt;br/&gt;    lis, _ := net.Listen(&lt;span&gt;&quot;tcp&quot;&lt;/span&gt;, &lt;span&gt;&quot;:50051&quot;&lt;/span&gt;)&lt;br/&gt;    grpcServer.Serve(lis)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;gRPC 服务的实现方式还是和以前一样。&lt;/p&gt;&lt;p&gt;以上就是全部代码，现在来测试一下：&lt;/p&gt;&lt;p&gt;启动三个终端：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;终端1&lt;/strong&gt; 启动 gRPC 服务：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;go&lt;/span&gt; run grpc_service.&lt;span&gt;go&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;终端2&lt;/strong&gt; 启动 REST 服务：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;go&lt;/span&gt; run rest_service.&lt;span&gt;go&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;终端3&lt;/strong&gt; 来请求 REST 服务：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ curl localhost:&lt;span&gt;8080&lt;/span&gt;/get/gopher&lt;br/&gt;{&lt;span&gt;&quot;value&quot;&lt;/span&gt;:&lt;span&gt;&quot;Get hi:gopher&quot;&lt;/span&gt;}&lt;br/&gt;&lt;br/&gt;$ curl localhost:&lt;span&gt;8080&lt;/span&gt;/post -X POST --data &lt;span&gt;&#x27;{&quot;value&quot;:&quot;grpc&quot;}&#x27;&lt;/span&gt;&lt;br/&gt;{&lt;span&gt;&quot;value&quot;&lt;/span&gt;:&lt;span&gt;&quot;Post hi:grpc&quot;&lt;/span&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;源码地址：&lt;/strong&gt; https://github.com/yongxinz/go-example/tree/main/grpc-example/rest&lt;/p&gt;&lt;h3&gt;&lt;span&gt;超时控制&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;最后一部分介绍一下超时控制，这部分内容是非常重要的。&lt;/p&gt;&lt;p&gt;一般的 WEB 服务 API，或者是 Nginx 都会设置一个超时时间，超过这个时间，如果还没有数据返回，服务端可能直接返回一个超时错误，或者客户端也可能结束这个连接。&lt;/p&gt;&lt;p&gt;如果没有这个超时时间，那是相当危险的。所有请求都阻塞在服务端，会消耗大量资源，比如内存。如果资源耗尽的话，甚至可能会导致整个服务崩溃。&lt;/p&gt;&lt;p&gt;那么，在 gRPC 中怎么设置超时时间呢？主要是通过上下文 &lt;code&gt;context.Context&lt;/code&gt; 参数，具体来说就是 &lt;code&gt;context.WithDeadline&lt;/code&gt; 函数。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;proto 文件&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;创建最简单的 proto 文件，这个不多说。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;syntax = &lt;span&gt;&quot;proto3&quot;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;package proto;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// The greeting service definition.&lt;/span&gt;&lt;br/&gt;service Greeter {&lt;br/&gt;    &lt;span&gt;// Sends a greeting&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;rpc &lt;span&gt;SayHello&lt;/span&gt; &lt;span&gt;(HelloRequest)&lt;/span&gt; &lt;span&gt;returns&lt;/span&gt; &lt;span&gt;(HelloReply)&lt;/span&gt; &lt;/span&gt;{}&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// The request message containing the user&#x27;s name.&lt;/span&gt;&lt;br/&gt;message HelloRequest {&lt;br/&gt;    &lt;span&gt;string&lt;/span&gt; name = &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// The response message containing the greetings&lt;/span&gt;&lt;br/&gt;message HelloReply {&lt;br/&gt;    &lt;span&gt;string&lt;/span&gt; message = &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;&lt;span&gt;客户端&lt;/span&gt;&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br/&gt;    &lt;span&gt;&quot;client/proto&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;context&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;fmt&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;log&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;time&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc/codes&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc/status&quot;&lt;/span&gt;&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    &lt;span&gt;// 简单调用&lt;/span&gt;&lt;br/&gt;    conn, err := grpc.Dial(&lt;span&gt;&quot;localhost:50051&quot;&lt;/span&gt;, grpc.WithInsecure())&lt;br/&gt;    &lt;span&gt;defer&lt;/span&gt; conn.Close()&lt;br/&gt;&lt;br/&gt;    ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(time.Duration(&lt;span&gt;3&lt;/span&gt;*time.Second)))&lt;br/&gt;    &lt;span&gt;defer&lt;/span&gt; cancel()&lt;br/&gt;&lt;br/&gt;    client := proto.NewGreeterClient(conn)&lt;br/&gt;    &lt;span&gt;// 简单调用&lt;/span&gt;&lt;br/&gt;    reply, err := client.SayHello(ctx, &amp;amp;proto.HelloRequest{Name: &lt;span&gt;&quot;zzz&quot;&lt;/span&gt;})&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;        statusErr, ok := status.FromError(err)&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; ok {&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; statusErr.Code() == codes.DeadlineExceeded {&lt;br/&gt;                log.Fatalln(&lt;span&gt;&quot;client.SayHello err: deadline&quot;&lt;/span&gt;)&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;&lt;br/&gt;        log.Fatalf(&lt;span&gt;&quot;client.SayHello err: %v&quot;&lt;/span&gt;, err)&lt;br/&gt;    }&lt;br/&gt;    fmt.Println(reply.Message)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过下面的函数设置一个 3s 的超时时间：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(time.Duration(&lt;span&gt;3&lt;/span&gt;*time.Second)))&lt;br/&gt;&lt;span&gt;defer&lt;/span&gt; cancel()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后在响应错误中对超时错误进行检测。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;服务端&lt;/span&gt;&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br/&gt;    &lt;span&gt;&quot;context&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;fmt&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;log&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;net&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;runtime&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;server/proto&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;time&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc/codes&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc/reflection&quot;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&quot;google.golang.org/grpc/status&quot;&lt;/span&gt;&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;type&lt;/span&gt; greeter &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(*greeter)&lt;/span&gt; &lt;span&gt;SayHello&lt;/span&gt;&lt;span&gt;(ctx context.Context, req *proto.HelloRequest)&lt;/span&gt; &lt;span&gt;(*proto.HelloReply, error)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    data := &lt;span&gt;make&lt;/span&gt;(&lt;span&gt;chan&lt;/span&gt; *proto.HelloReply, &lt;span&gt;1&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;go&lt;/span&gt; handle(ctx, req, data)&lt;br/&gt;    &lt;span&gt;select&lt;/span&gt; {&lt;br/&gt;    &lt;span&gt;case&lt;/span&gt; res := &amp;lt;-data:&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; res, &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;case&lt;/span&gt; &amp;lt;-ctx.Done():&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;, status.Errorf(codes.Canceled, &lt;span&gt;&quot;Client cancelled, abandoning.&quot;&lt;/span&gt;)&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;handle&lt;/span&gt;&lt;span&gt;(ctx context.Context, req *proto.HelloRequest, data &lt;span&gt;chan&lt;/span&gt;&amp;lt;- *proto.HelloReply)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    &lt;span&gt;select&lt;/span&gt; {&lt;br/&gt;    &lt;span&gt;case&lt;/span&gt; &amp;lt;-ctx.Done():&lt;br/&gt;        log.Println(ctx.Err())&lt;br/&gt;        runtime.Goexit() &lt;span&gt;//超时后退出该Go协程&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;case&lt;/span&gt; &amp;lt;-time.After(&lt;span&gt;4&lt;/span&gt; * time.Second): &lt;span&gt;// 模拟耗时操作&lt;/span&gt;&lt;br/&gt;        res := proto.HelloReply{&lt;br/&gt;            Message: &lt;span&gt;&quot;hello &quot;&lt;/span&gt; + req.Name,&lt;br/&gt;        }&lt;br/&gt;        &lt;span&gt;// //修改数据库前进行超时判断&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// if ctx.Err() == context.Canceled{&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;//  ...&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;//  //如果已经超时，则退出&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// }&lt;/span&gt;&lt;br/&gt;        data &amp;lt;- &amp;amp;res&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    lis, err := net.Listen(&lt;span&gt;&quot;tcp&quot;&lt;/span&gt;, &lt;span&gt;&quot;:50051&quot;&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;        log.Fatalf(&lt;span&gt;&quot;failed to listen: %v&quot;&lt;/span&gt;, err)&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// 简单调用&lt;/span&gt;&lt;br/&gt;    server := grpc.NewServer()&lt;br/&gt;    &lt;span&gt;// 注册 grpcurl 所需的 reflection 服务&lt;/span&gt;&lt;br/&gt;    reflection.Register(server)&lt;br/&gt;    &lt;span&gt;// 注册业务服务&lt;/span&gt;&lt;br/&gt;    proto.RegisterGreeterServer(server, &amp;amp;greeter{})&lt;br/&gt;&lt;br/&gt;    fmt.Println(&lt;span&gt;&quot;grpc server start ...&quot;&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; err := server.Serve(lis); err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;        log.Fatalf(&lt;span&gt;&quot;failed to serve: %v&quot;&lt;/span&gt;, err)&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;服务端增加一个 &lt;code&gt;handle&lt;/code&gt; 函数，其中 &lt;code&gt;case &amp;lt;-time.After(4 * time.Second)&lt;/code&gt; 表示 4s 之后才会执行其对应代码，用来模拟超时请求。&lt;/p&gt;&lt;p&gt;如果客户端超时时间超过 4s 的话，就会产生超时报错。&lt;/p&gt;&lt;p&gt;下面来模拟一下：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;服务端：&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ go run main.go&lt;br/&gt;grpc server &lt;span&gt;start&lt;/span&gt; ...&lt;br/&gt;&lt;span&gt;2021&lt;/span&gt;/&lt;span&gt;10&lt;/span&gt;/&lt;span&gt;24&lt;/span&gt; &lt;span&gt;22&lt;/span&gt;:&lt;span&gt;57&lt;/span&gt;:&lt;span&gt;40&lt;/span&gt; &lt;span&gt;context&lt;/span&gt; deadline exceeded&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;客户端：&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ go run main.go&lt;br/&gt;&lt;span&gt;2021&lt;/span&gt;/&lt;span&gt;10&lt;/span&gt;/&lt;span&gt;24&lt;/span&gt; &lt;span&gt;22&lt;/span&gt;:&lt;span&gt;57&lt;/span&gt;:&lt;span&gt;40&lt;/span&gt; client.SayHello err: deadline&lt;br/&gt;&lt;span&gt;exit&lt;/span&gt; status &lt;span&gt;1&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;源码地址：&lt;/strong&gt; https://github.com/yongxinz/go-example/tree/main/grpc-example/deadline&lt;/p&gt;&lt;h3&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;本文主要介绍了 gRPC 的三部分实战内容，分别是：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;发布订阅模式&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;REST 接口&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;超时控制&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;个人感觉，超时控制还是最重要的，在平时的开发过程中需要多多注意。&lt;/p&gt;&lt;p&gt;结合上篇文章，gRPC 的实战内容就写完了，代码全部可以执行，也都上传到了 GitHub。&lt;/p&gt;&lt;p&gt;大家如果有任何疑问，欢迎给我留言，如果感觉不错的话，也欢迎关注和转发。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;题图：&lt;/strong&gt; 该图片由 Reytschl 在 Pixabay 上发布&lt;/p&gt;&lt;p&gt;&lt;strong&gt;源码地址：&lt;/strong&gt; &lt;/p&gt;&lt;p&gt;关注公众号 &lt;strong&gt;AlwaysBeta&lt;/strong&gt;，回复「&lt;strong&gt;goebook&lt;/strong&gt;」领取 Go 编程经典书籍。&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzI3MjY1ODI2Ng==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/YQLyg1D0dluejnibLk0SZTDAwxMeYugmNiakQIDLp6wqGCGxNkbIjHJYedmKLKaJeAmt2NMslI7COJwD44flibVmQ/0?wx_fmt=png&quot; data-nickname=&quot;AlwaysBeta&quot; data-alias=&quot;betasite&quot; data-signature=&quot;手艺人，写代码的&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;推荐阅读：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;参考：&lt;/strong&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;https://chai2010.cn/advanced-go-programming-book/ch4-rpc/readme.html&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://codeleading.com/article/94674952433/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://juejin.cn/post/6844904017017962504&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://www.cnblogs.com/FireworksEasyCool/p/12702959.html&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9fffb682fee7a6dd3ca9bab5191750fb</guid>
<title>你分库分表的姿势对么？：详谈水平分库分表</title>
<link>https://toutiao.io/k/oyacwl5</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;22&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;作者：vivo平台产品开发团队-Han Lei&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;一、背景&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;提起分库分表，对于大部分服务器开发来说，其实并不是一个新鲜的名词。随着业务的发展，我们表中的数据量会变的越来越大，字段也可能随着业务复杂度的升高而逐渐增多，我们为了解决单表的查询性能问题，一般会进行分表操作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同时我们业务的用户活跃度也会越来越高，并发量级不断加大，那么可能会达到单个数据库的处理能力上限。此时我们为了解决数据库的处理性能瓶颈，一般会进行分库操作。不管是分库操作还是分表操作，我们一般都有两种方式应对，一种是垂直拆分，一种是水平拆分。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;关于两种拆分方式的区别和特点，互联网上参考资料众多，很多人都写过相关内容，这里就不再进行详细赘述，有兴趣的读者可以自行检索。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此文主要详细聊一聊，我们最实用最常见的水平分库分表方式中的一些特殊细节，希望能帮助大家避免走弯路，找到最合适自身业务的分库分表设计。&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;87&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;p&gt;【注1】本文中的案例均基于Mysql数据库，下文中的分库分表统指水平分库分表。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;【注2】后文中提到到M库N表，均指共M个数据库，每个数据库共N个分表，即总表个数其实为M*N。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;二、什么是一个好的分库分表方案？&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;2.1 方案可持续性&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;前期业务数据量级不大，流量较低的时候，我们无需分库分表，也不建议分库分表。但是一旦我们要对业务进行分库分表设计时，就一定要考虑到分库分表方案的可持续性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;那何为可持续性？&lt;/strong&gt;其实就是：业务数据量级和业务流量未来进一步升高达到新的量级的时候，我们的分库分表方案可以持续使用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;一个通俗的案例，假定当前我们分库分表的方案为10库100表，那么未来某个时间点，若10个库仍然无法应对用户的流量压力，或者10个库的磁盘使用即将达到物理上限时，我们的方案能够进行平滑扩容。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在后文中我们将介绍下目前业界常用的翻倍扩容法和一致性Hash扩容法。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;2.2 数据偏斜问题&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;一个良好的分库分表方案，它的数据应该是需要比较均匀的分散在各个库表中的。如果我们进行一个拍脑袋式的分库分表设计，很容易会遇到以下类似问题：&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;135&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;p&gt;a、某个数据库实例中，部分表的数据很多，而其他表中的数据却寥寥无几，业务上的表现经常是延迟忽高忽低，飘忽不定。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;b、数据库集群中，部分集群的磁盘使用增长特别块，而部分集群的磁盘增长却很缓慢。每个库的增长步调不一致，这种情况会给后续的扩容带来步调不一致，无法统一操作的问题。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这边我们定义分库分表最大数据偏斜率为 ：（数据量最大样本 - 数据量最小样本）/ 数据量最小样本。一般来说，如果我们的最大数据偏斜率在5%以内是可以接受的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100008465&quot; data-ratio=&quot;0.5117773019271948&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt7ibSqqgkw7u8SC7X6Jv4YzZgAnfMNvQibZvq4LtEbZeoBN27oY1KicgZHAXDu0Fs8ax3HeUjQYh2pKg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;467&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;三、常见的分库分表方案&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;3.1 Range分库分表&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;顾名思义，该方案根据数据范围划分数据的存放位置。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;举个最简单例子，我们可以把订单表按照年份为单位，每年的数据存放在单独的库（或者表）中。如下图所示：&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;java&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__comment&quot;&gt; * &lt;span class=&quot;code-snippet__doctag&quot;&gt;@return&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__comment&quot;&gt; */&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;static&lt;/span&gt; String &lt;span class=&quot;code-snippet__title&quot;&gt;rangeShardByYear&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(String orderId)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; year = Integer.parseInt(orderId.substring(&lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;));&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;t_order_&quot;&lt;/span&gt; + year;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过数据的范围进行分库分表，该方案是最朴实的一种分库方案，它也可以和其他分库分表方案灵活结合使用。时下非常流行的分布式数据库：TiDB数据库，针对TiKV中数据的打散，也是基于Range的方式进行，将不同范围内的[StartKey,EndKey)分配到不同的Region上。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;下面我们看看该方案的缺点：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;39&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;这点非常容易被遗忘，尤其是稳定跑了几年没有迭代任务，或者人员又交替频繁的模块。&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里就需要注意了，因为是通过年份进行分库分表，那么元旦的那一天，你的定时任务很有可能会漏掉上一年的最后一天的数据扫描。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;3.2 Hash分库分表&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;虽然分库分表的方案众多，但是Hash分库分表是最大众最普遍的方案，也是本文花最大篇幅描述的部分。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;针对Hash分库分表的细节部分，相关的资料并不多。大部分都是阐述一下概念举几个示例，而细节部分并没有特别多的深入，如果未结合自身业务贸然参考引用，后期非常容易出现各种问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在正式介绍这种分库分表方式之前，我们先看几个常见的错误案例。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;常见错误案例一：非互质关系导致的数据偏斜问题&lt;/strong&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;static&lt;/span&gt; ShardCfg &lt;span class=&quot;code-snippet__title&quot;&gt;shard&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(String userId)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; hash = userId.hashCode();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__comment&quot;&gt;// 对库数量取余结果为库序号&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; dbIdx = Math.&lt;span class=&quot;code-snippet__built_in&quot;&gt;abs&lt;/span&gt;(hash % DB_CNT);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__comment&quot;&gt;// 对表数量取余结果为表序号&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; tblIdx = Math.&lt;span class=&quot;code-snippet__built_in&quot;&gt;abs&lt;/span&gt;(hash % TBL_CNT);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; ShardCfg(dbIdx, tblIdx);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;上述方案是初次使用者特别容易进入的误区，用&lt;span&gt;Hash&lt;/span&gt;值分别对分库数和分表数取余，得到库序号和表序号。其实稍微思索一下，我们就会发现，以10库100表为例，如果一个&lt;span&gt;Hash&lt;/span&gt;值对100取余为0，那么它对10取余也必然为0。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这就意味着只有0库里面的0表才可能有数据，而其他库中的0表永远为空！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;类似的我们还能推导到，0库里面的共100张表，只有10张表中(个位数为0的表序号)才可能有数据。这就带来了非常严重的数据偏斜问题，因为某些表中永远不可能有数据，最大数据偏斜率达到了无穷大。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那么很明显，该方案是一个未达到预期效果的错误方案。数据的散落情况大致示意图如下：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;303&quot; data-backw=&quot;578&quot; data-fileid=&quot;100008466&quot; data-ratio=&quot;0.5237449118046132&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt7ibSqqgkw7u8SC7X6Jv4YzZpIKzw3xB1jE6WvhrjwNfpRA2W6cPuvco1Lqm6bxgsmWChU7IegDqaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;737&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;事实上，只要库数量和表数量非互质关系，都会出现某些表中无数据的问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;证明如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100008467&quot; data-ratio=&quot;0.4548440065681445&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt7ibSqqgkw7u8SC7X6Jv4YzZJz6wCq1zwxLI062iahVEGn80PS0RcDfAdQ5hQWrB5kXPpwBcYyCrrKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;609&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;那么是不是只要库数量和表数量互质就可用用这种分库分表方案呢？比如我用11库100表的方案，是不是就合理了呢？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;答案是否定的，我们除了要考虑数据偏斜的问题，还需要考虑可持续性扩容的问题，一般这种&lt;span&gt;Hash&lt;/span&gt;分库分表的方案后期的扩容方式都是通过翻倍扩容法，那11库翻倍后，和100又不再互质。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当然，如果分库数和分表数不仅互质，而且分表数为奇数(例如10库101表)，则理论上可以使用该方案，但是我想大部分人可能都会觉得使用奇数的分表数比较奇怪吧。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;常见错误案例二：扩容难以持续&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;如果避开了上述案例一的陷阱，那么我们又很容易一头扎进另一个陷阱，大概思路如下；&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们把10库100表看成总共1000个逻辑表，将求得的Hash值对1000取余，得到一个介于[0，999)中的数，然后再将这个数二次均分到每个库和每个表中，大概逻辑代码如下：&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;static&lt;/span&gt; ShardCfg &lt;span class=&quot;code-snippet__title&quot;&gt;shard&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(String userId)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__comment&quot;&gt;// ① 算Hash&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; hash = userId.hashCode();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__comment&quot;&gt;// ② 总分片数&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; sumSlot = DB_CNT * TBL_CNT;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__comment&quot;&gt;// ③ 分片序号&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; slot = Math.&lt;span class=&quot;code-snippet__built_in&quot;&gt;abs&lt;/span&gt;(hash % sumSlot);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__comment&quot;&gt;// ④ 计算库序号和表序号的错误案例&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; dbIdx = slot % DB_CNT ;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; tblIdx = slot / DB_CNT ;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; ShardCfg(dbIdx, tblIdx);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该方案确实很巧妙的解决了数据偏斜的问题，只要&lt;span&gt;Hash&lt;/span&gt;值足够均匀，那么理论上分配序号也会足够平均，于是每个库和表中的数据量也能保持较均衡的状态。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100008468&quot; data-ratio=&quot;0.7772357723577236&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt7ibSqqgkw7u8SC7X6Jv4YzZiaBvZ7pLrTdsmfFPRC4FlJvHbqGNRXYHQ6JyA7WJhC4lJC08466l5ow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;615&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但是该方案有个比较大的问题，那就是在计算表序号的时候，依赖了总库的数量，那么后续翻倍扩容法进行扩容时，会出现扩容前后数据不在同一个表中，从而无法实施。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如上图中，例如扩容前&lt;span&gt;Hash&lt;/span&gt;为1986的数据应该存放在6库98表，但是翻倍扩容成20库100表后，它分配到了6库99表，表序号发生了偏移。这样的话，我们在后续在扩容的时候，不仅要基于库迁移数据，还要基于表迁移数据，非常麻烦且易错。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;看完了上面的几种典型的错误案例，那么我们有哪些比较正确的方案呢？下面将结合一些实际场景案例介绍几种Hash分库分表的方案。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;常用姿势一：标准的二次分片法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上述错误案例二中，整体思路完全正确，只是最后计算库序号和表序号的时候，使用了库数量作为影响表序号的因子，导致扩容时表序号偏移而无法进行。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;事实上，我们只需要换种写法，就能得出一个比较大众化的分库分表方案。&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;static&lt;/span&gt; ShardCfg &lt;span class=&quot;code-snippet__title&quot;&gt;shard2&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(String userId)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__comment&quot;&gt;// ① 算Hash&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; hash = userId.hashCode();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__comment&quot;&gt;// ② 总分片数&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; sumSlot = DB_CNT * TBL_CNT;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__comment&quot;&gt;// ③ 分片序号&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; slot = Math.&lt;span class=&quot;code-snippet__built_in&quot;&gt;abs&lt;/span&gt;(hash % sumSlot);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__comment&quot;&gt;// ④ 重新修改二次求值方案&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; dbIdx = slot / TBL_CNT ;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; tblIdx = slot % TBL_CNT ;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; ShardCfg(dbIdx, tblIdx);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;大家可以注意到，和错误案例二中的区别就是通过分配序号重新计算库序号和表序号的逻辑发生了变化。它的分配情况如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;426&quot; data-backw=&quot;568&quot; data-fileid=&quot;100008469&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt7ibSqqgkw7u8SC7X6Jv4YzZSdnFhxmkHZicZX7P3W6iceeraNwiaNibp2cexGiacNAmHNy1aMMEOVib60fQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;568&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那为何使用这种方案就能够有很好的扩展持久性呢？我们进行一个简短的证明：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100008470&quot; data-ratio=&quot;0.5790251107828656&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt7ibSqqgkw7u8SC7X6Jv4YzZG1Wg0sVFvdcAhJfwjfTgLpw0gtwLYbiaBiarNibLsAPLThFMHLIMj3r9Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;677&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过上面结论我们知道，通过翻倍扩容后，我们的表序号一定维持不变，库序号可能还是在原来库，也可能平移到了新库中(原库序号加上原分库数)，完全符合我们需要的扩容持久性方案。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100008471&quot; data-ratio=&quot;0.8562992125984252&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt7ibSqqgkw7u8SC7X6Jv4YzZII2eI7xAY7V3wxpXEO6LoU41HA0pQo1WpicEbq0UibFpqshjdp83B1RQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;508&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;【方案缺点】&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1、翻倍扩容法前期操作性高，但是后续如果分库数已经是大几十的时候，每次扩容都非常耗费资源。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2、连续的分片键&lt;span&gt;Hash&lt;/span&gt;值大概率会散落在相同的库中，某些业务可能容易存在库热点（例如新生成的用户&lt;span&gt;Hash&lt;/span&gt;相邻且递增，且新增用户又是高概率的活跃用户，那么一段时间内生成的新用户都会集中在相邻的几个库中）。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;常用姿势二：关系表冗余&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们可以将分片键对应库的关系通过关系表记录下来，我们把这张关系表称为&quot;路由关系表&quot;。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;static&lt;/span&gt; ShardCfg &lt;span class=&quot;code-snippet__title&quot;&gt;shard&lt;/span&gt;(&lt;span class=&quot;code-snippet__params&quot;&gt;String userId&lt;/span&gt;)&lt;/span&gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; tblIdx = Math.abs(userId.hashCode() % TBL_CNT);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__comment&quot;&gt;// 从缓存获取&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        Integer dbIdx = loadFromCache(userId);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; == dbIdx) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            &lt;span class=&quot;code-snippet__comment&quot;&gt;// 从路由表获取&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            dbIdx = loadFromRouteTable(userId);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; != dbIdx) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                &lt;span class=&quot;code-snippet__comment&quot;&gt;// 保存到缓存&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                saveRouteCache(userId, dbIdx);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; == dbIdx) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            &lt;span class=&quot;code-snippet__comment&quot;&gt;// 此处可以自由实现计算库的逻辑&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            dbIdx = selectRandomDbIdx();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            saveToRouteTable(userId, dbIdx);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            saveRouteCache(userId, dbIdx);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; ShardCfg(dbIdx, tblIdx);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;该方案还是通过常规的&lt;span&gt;Hash&lt;/span&gt;算法计算表序号，而计算库序号时，则从路由表读取数据。因为在每次数据查询时，都需要读取路由表，故我们需要将分片键和库序号的对应关系记录同时维护在缓存中以提升性能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上述实例中&lt;strong&gt;selectRandomDbIdx方法&lt;/strong&gt;作用为生成该分片键对应的存储库序号，这边可以非常灵活的动态配置。例如可以为每个库指定一个权重，权重大的被选中的概率更高，权重配置成0则可以将关闭某些库的分配。当发现数据存在偏斜时，也可以调整权重使得各个库的使用量调整趋向接近。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该方案还有个优点，就是理论上后续进行扩容的时候，仅需要挂载上新的数据库节点，将权重配置成较大值即可，无需进行任何的数据迁移即可完成。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如下图所示：最开始我们为4个数据库分配了相同的权重，理论上落在每个库的数据概率均等。但是由于用户也有高频低频之分，可能某些库的数据增长会比较快。当挂载新的数据库节点后，我们灵活的调整了每个库的新权重。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100008472&quot; data-ratio=&quot;0.44283121597096187&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/4g5IMGibSxt7ibSqqgkw7u8SC7X6Jv4YzZ9icic99AgSdJ8CpmiboWqb2Js9gMZw5qqfKn6icBRakKVlr3T0FbChF5Tw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;551&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;该方案似乎解决了很多问题，那么它有没有什么不适合的场景呢？当然有，该方案在很多场景下其实并不太适合，以下举例说明。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;a、每次读取数据需要访问路由表，虽然使用了缓存，但是还是有一定的性能损耗。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;b、路由关系表的存储方面，有些场景并不合适。例如上述案例中用户id的规模大概是在10亿以内，我们用单库百表存储该关系表即可。但如果例如要用文件MD5摘要值作为分片键，因为样本集过大，无法为每个md5值都去指定关系（当然我们也可以使用md5前N位来存储关系）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;c、&lt;strong&gt;饥饿占位问题，如下详叙&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们知道，该方案的特点是后续无需扩容，可以随时修改权重调整每个库的存储增长速度。但是这个愿景是比较缥缈，并且很难实施的，我们选取一个简单的业务场景考虑以下几个问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;【&lt;strong&gt;业务场景&lt;/strong&gt;】：以用户存放文件到云端的云盘业务为例，需要对用户的文件信息进行分库分表设计，有以下假定场景：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们使用路由表记录每个用户所在的库序号信息。那么该方案会有以下问题：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第一：&lt;/strong&gt;我们总共有2亿个用户，只有3000W个产生过事务的用户。若程序不加处理，用户发起任何请求则创建路由表数据，会导致为大量实际没有事务数据的用户提前创建路由表。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;笔者最初存储云盘用户数据的时候便遇到了这个问题，客户端app会在首页查询用户空间使用情况，这样导致几乎一开始就为每个使用者分配好了路由。随着时间的推移，这部分没有数据的&quot;静默&quot;的用户，随时可能开始他的云盘使用之旅而“复苏”，从而导致它所在的库迅速增长并超过单个库的空间容量极限，从而被迫拆分扩容。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;解决这个问题的方案，其实就是只针对事务操作(例如购买空间，上传数据，创建文件夹等等)才进行路由的分配，这样对代码层面便有了一些倾入。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二、&lt;/strong&gt;按照前面描述的业务场景，一个用户最终平均有2000条数据，假定每行大小为1K，为了保证B+数的层级在3层，我们限制每张表的数据量在2000W，分表数为100的话，可以得到理论上每个库的用户数不能超过100W个用户。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;也就是如果是3000W个产生过事务的用户，我们需要为其分配30个库，这样会在业务前期，用户平均数据量相对较少的时候，存在非常大的数据库资源的浪费。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;解决第二个问题，我们一般可以将很多数据库放在一个实例上，后续随着增长情况进行拆分。也可以后续针对将满的库，使用常规手段进行拆分和迁移。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;常用姿势三：基因法&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;还是由错误案例一启发，我们发现案例一不合理的主要原因，就是因为库序号和表序号的计算逻辑中，有公约数这个因子在影响库表的独立性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那么我们是否可以换一种思路呢？我们使用相对独立的&lt;span&gt;Hash&lt;/span&gt;值来计算库序号和表序号。&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;static&lt;/span&gt; ShardCfg &lt;span class=&quot;code-snippet__title&quot;&gt;shard&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(String userId)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; dbIdx = Math.&lt;span class=&quot;code-snippet__built_in&quot;&gt;abs&lt;/span&gt;(userId.substring(&lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;).hashCode() % DB_CNT );&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; tblIdx = Math.&lt;span class=&quot;code-snippet__built_in&quot;&gt;abs&lt;/span&gt;(userId.hashCode() % TBL_CNT);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; ShardCfg(dbIdx, tblIdx);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;如上所示，我们计算库序号的时候做了部分改动，我们使用分片键的前四位作为&lt;span&gt;Hash&lt;/span&gt;值来计算库序号。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这也是一种常用的方案，我们称为基因法，即使用原分片键中的某些基因（例如前四位）作为库的计算因子，而使用另外一些基因作为表的计算因子。该方案也是网上不少的实践方案或者是其变种，看起来非常巧妙的解决了问题，然而在实际生成过程中还是需要慎重。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;笔者曾在云盘的空间模块的分库分表实践中采用了该方案，使用16库100表拆分数据，上线初期数据正常。然而当数据量级增长起来后，发现每个库的用户数量严重不均等，故猜测该方案存在一定的数据偏斜。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了验证观点，进行如下测试，随机2亿个用户id（16位的随机字符串），针对不同的M库N表方案，重复若干次后求平均值得到结论如下：&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;makefile&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;8库100表&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;min=248305(dbIdx=2, tblIdx=64), max=251419(dbIdx=7, tblIdx=8), rate= 1.25%            √&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;16库100表&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;min=95560(dbIdx=8, tblIdx=42), max=154476(dbIdx=0, tblIdx=87), rate= 61.65%           ×&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;20库100表&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;min=98351(dbIdx=14, tblIdx=78), max=101228(dbIdx=6, tblIdx=71), rate= 2.93%&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们发现该方案中，分库数为16，分表数为100，数量最小行数仅为10W不到，但是最多的已经达到了15W+，最大数据偏斜率高达61%。按这个趋势发展下去，后期很可能出现一台数据库容量已经使用满，而另一台还剩下30%+的容量。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该方案并不是一定不行，而是我们在采用的时候，要综合分片键的样本规则，选取的分片键前缀位数，库数量，表数量，四个变量对最终的偏斜率都有影响。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;例如上述例子中，如果不是16库100表，而是8库100表，或者20库100表，数据偏斜率都能降低到了5%以下的可接受范围。所以该方案的隐藏的&quot;坑&quot;较多，我们不仅要估算上线初期的偏斜率，还需要测算若干次翻倍扩容后的数据偏斜率。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;例如你用着初期比较完美的8库100表的方案，后期扩容成16库100表的时候，麻烦就接踵而至。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;常用姿势四：剔除公因数法&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;还是基于错误案例一启发，在很多场景下我们还是希望相邻的&lt;span&gt;Hash&lt;/span&gt;能分到不同的库中。就像N库单表的时候，我们计算库序号一般直接用&lt;span&gt;Hash&lt;/span&gt;值对库数量取余。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那么我们是不是可以有办法去除掉公因数的影响呢？下面为一个可以考虑的实现案例：&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;static&lt;/span&gt; ShardCfg &lt;span class=&quot;code-snippet__title&quot;&gt;shard&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(String userId)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; dbIdx = Math.&lt;span class=&quot;code-snippet__built_in&quot;&gt;abs&lt;/span&gt;(userId.hashCode() % DB_CNT);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__comment&quot;&gt;// 计算表序号时先剔除掉公约数的影响&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; tblIdx = Math.&lt;span class=&quot;code-snippet__built_in&quot;&gt;abs&lt;/span&gt;((userId.hashCode() / TBL_CNT) % TBL_CNT);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; ShardCfg(dbIdx, tblIdx);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;经过测算，该方案的最大数据偏斜度也比较小，针对不少业务从N库1表升级到N库M表下，需要维护库序号不变的场景下可以考虑。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;常用姿势五：一致性Hash法&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;一致性Hash算法也是一种比较流行的集群数据分区算法，比如RedisCluster即是通过一致性Hash算法，使用16384个虚拟槽节点进行每个分片数据的管理。关于一致性Hash的具体原理这边不再重复描述，读者可以自行翻阅资料。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这边详细介绍如何使用一致性Hash进行分库分表的设计。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们通常会将每个实际节点的配置持久化在一个配置项或者是数据库中，应用启动时或者是进行切换操作的时候会去加载配置。配置一般包括一个[StartKey,Endkey)的左闭右开区间和一个数据库节点信息，例如：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;503&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;195&quot; data-fileid=&quot;100008473&quot; data-ratio=&quot;0.38911290322580644&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt7AWBMjESn4VYZibMW4Z0ScG0EwOmwf17qWyia5Y2OsNDia6qk0D8HZbY9vDVCsQwKD2Zvh88luLJJeg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;496&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;示例代码：&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;private&lt;/span&gt; TreeMap&amp;lt;Long, Integer&amp;gt; nodeTreeMap = &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; TreeMap&amp;lt;&amp;gt;();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;@&lt;span class=&quot;code-snippet__function&quot;&gt;Override&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;afterPropertiesSet&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__comment&quot;&gt;// 启动时加载分区配置&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    List&amp;lt;HashCfg&amp;gt; cfgList = fetchCfgFromDb();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;for&lt;/span&gt; (HashCfg cfg : cfgList) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        nodeTreeMap.put(cfg.endKey, cfg.nodeIdx);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; ShardCfg &lt;span class=&quot;code-snippet__title&quot;&gt;shard&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(String userId)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; hash = userId.hashCode();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; dbIdx = nodeTreeMap.tailMap((&lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt;) hash, &lt;span class=&quot;code-snippet__literal&quot;&gt;false&lt;/span&gt;).firstEntry().getValue();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; tblIdx = Math.&lt;span class=&quot;code-snippet__built_in&quot;&gt;abs&lt;/span&gt;(hash % &lt;span class=&quot;code-snippet__number&quot;&gt;100&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; ShardCfg(dbIdx, tblIdx);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们可以看到，这种形式和上文描述的Range分表非常相似，Range分库分表方式针对分片键本身划分范围，而一致性Hash是针对分片键的&lt;span&gt;Hash&lt;/span&gt;值进行范围配置。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;正规的一致性Hash算法会引入虚拟节点，每个虚拟节点会指向一个真实的物理节点。这样设计方案主要是能够在加入新节点后的时候，可以有方案保证每个节点迁移的数据量级和迁移后每个节点的压力保持几乎均等。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但是用在分库分表上，一般大部分都只用实际节点，引入虚拟节点的案例不多，主要有以下原因：&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;188&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;p&gt;a、应用程序需要花费额外的耗时和内存来加载虚拟节点的配置信息。如果虚拟节点较多，内存的占用也会有些不太乐观。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;b、由于mysql有非常完善的主从复制方案，与其通过从各个虚拟节点中筛选需要迁移的范围数据进行迁移，不如通过从库升级方式处理后再删除冗余数据简单可控。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;c、虚拟节点主要解决的痛点是节点数据搬迁过程中各个节点的负载不均衡问题，通过虚拟节点打散到各个节点中均摊压力进行处理。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而作为OLTP数据库，我们很少需要突然将某个数据库下线，新增节点后一般也不会从0开始从其他节点搬迁数据，而是前置准备好大部分数据的方式，故一般来说没有必要引入虚拟节点来增加复杂度。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;四、常见扩容方案&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.1 翻倍扩容法&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;翻倍扩容法的主要思维是每次扩容，库的数量均翻倍处理，而翻倍的数据源通常是由原数据源通过主从复制方式得到的从库升级成主库提供服务的方式。故有些文档将其称作&quot;&lt;strong&gt;从库升级法&lt;/strong&gt;&quot;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;理论上，经过翻倍扩容法后，我们会多一倍的数据库用来存储数据和应对流量，原先数据库的磁盘使用量也将得到一半空间的释放。如下图所示:&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100008475&quot; data-ratio=&quot;0.5273775216138329&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt7ibSqqgkw7u8SC7X6Jv4YzZwJlqfTzSZEDuiaibgRibNrqFj5CcibPicbBHlkvg3KO9tW4YDH1PnibrCPRw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;694&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;具体的流程大致如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;①、时间点t1：为每个节点都新增从库，开启主从同步进行数据同步。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;②、时间点t2：主从同步完成后，对主库进行禁写。&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;153&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;p&gt;此处禁写主要是为了保证数据的正确性。若不进行禁写操作，在以下两个时间窗口期内将出现数据不一致的问题：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;a、断开主从后，若主库不禁写，主库若还有数据写入，这部分数据将无法同步到从库中。&lt;/p&gt;&lt;p&gt; b、应用集群识别到分库数翻倍的时间点无法严格一致，在某个时间点可能两台应用使用不同的分库数，运算到不同的库序号，导致错误写入。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;③、时间点t3：同步完全完成后，断开主从关系，理论上此时从库和主库有着完全一样的数据集。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;④、时间点t4：从库升级为集群节点，业务应用识别到新的分库数后，将应用新的路由算法。&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;161&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;一般情况下，我们将分库数的配置放到配置中心中，当上述三个步骤完成后，我们修改分库数进行翻倍，应用生效后，应用服务将使用新的配置。这里需要注意的是，业务应用接收到新的配置的时间点不一定一致，所以必定存在一个时间窗口期，该期间部分机器使用原分库数，部分节点使用新分库数。这也正是我们的禁写操作一定要在此步完成后才能放开的原因。&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;⑤、时间点t5：确定所有的应用均接受到库总数的配置后，放开原主库的禁写操作，此时应用完全恢复服务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;⑥、启动离线的定时任务，清除各库中的约一半冗余数据。&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;65&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;为了节省磁盘的使用率，我们可以选择离线定时任务清除冗余的数据。也可以在业务初期表结构设计的时候，将索引键的Hash值存为一个字段。&lt;span/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;257&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;那么以上述常用姿势四为例，我们离线的清除任务可以简单的通过sql即可实现（需要防止锁住全表，可以拆分成若干个id范围的子sql执行）：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;delete from db0.tbl0 where hash_val mod 4 &amp;lt;&amp;gt; 0; &lt;/p&gt;&lt;p&gt;delete from db1.tbl0 where hash_val mod 4 &amp;lt;&amp;gt; 1;&lt;/p&gt;&lt;p&gt;delete from db2.tbl0 where hash_val mod 4 &amp;lt;&amp;gt; 2;&lt;/p&gt;&lt;p&gt;delete from db3.tbl0 where hash_val mod 4 &amp;lt;&amp;gt; 3;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;具体的扩容步骤可参考下图：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100008476&quot; data-ratio=&quot;1.0336&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/4g5IMGibSxt7ibSqqgkw7u8SC7X6Jv4YzZfaZ1SZUkySuiccD7xiayc6kOPvIcWnVB3MnuvTQocGOCTmhvfbpl2hTw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;625&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;：通过上述迁移方案可以看出，从时间点t2到t5时间窗口呢内，需要对数据库禁写，相当于是该时间范围内服务器是部分有损的，该阶段整体耗时差不多是在分钟级范围内。若业务可以接受，可以在业务低峰期进行该操作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当然也会有不少应用无法容忍分钟级写入不可用，例如写操作远远大于读操作的应用，此时可以结合canel开源框架进行窗口期内数据双写操作以保证数据的一致性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该方案主要借助于mysql强大完善的主从同步机制，能在事前提前准备好新的节点中大部分需要的数据，节省大量的人为数据迁移操作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但是缺点也很明显，一是过程中整个服务可能需要以有损为代价，二是每次扩容均需要对库数量进行翻倍，会提前浪费不少的数据库资源。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.2 一致性Hash扩容&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们主要还是看下不带虚拟槽的一致性Hash扩容方法，假如当前数据库节点DB0负载或磁盘使用过大需要扩容，我们通过扩容可以达到例如下图的效果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;下图中，扩容前配置了三个&lt;span&gt;Hash&lt;/span&gt;分段，发现[-Inf，-10000）范围内的的数据量过大或者压力过高时，需要对其进行扩容。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100008477&quot; data-ratio=&quot;0.548460661345496&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt7ibSqqgkw7u8SC7X6Jv4YzZVUcTNVh9jBUiaplWhveGiapBAxdNFVpicm6vyX77ylMziaqtryJv0Pia1vA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;877&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;主要步骤如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;①、&lt;strong&gt;时间点t1&lt;/strong&gt;：针对需要扩容的数据库节点增加从节点，开启主从同步进行数据同步。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;②、&lt;strong&gt;时间点t2&lt;/strong&gt;：完成主从同步后，对原主库进行禁写。&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;35&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt; 此处原因和翻倍扩容法类似，需要保证新的从库和原来主库中数据的一致性。&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;③、&lt;strong&gt;时间点t3&lt;/strong&gt;：同步完全完成后，断开主从关系，理论上此时从库和主库有着完全一样的数据集。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;④、&lt;strong&gt;时间点t4&lt;/strong&gt;：修改一致性Hash范围的配置，并使应用服务重新读取并生效。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;⑤、&lt;strong&gt;时间点t5&lt;/strong&gt;：确定所有的应用均接受到新的一致性Hash范围配置后，放开原主库的禁写操作，此时应用完全恢复服务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;⑥、&lt;strong&gt;启动离线的定时任务&lt;/strong&gt;，清除冗余数据。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;可以看到，该方案和翻倍扩容法的方案比较类似，但是它更加灵活，可以根据当前集群每个节点的压力情况选择性扩容，而无需整个集群同时翻倍进行扩容。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;五、小结&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;本文主要描述了我们进行水平分库分表设计时的一些常见方案。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们在进行分库分表设计时，可以选择例如范围分表，&lt;span&gt;Hash&lt;/span&gt;分表，路由表，或者一致性Hash分表等各种方案。进行选择时需要充分考虑到后续的扩容可持续性，最大数据偏斜率等因素。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;文中也列举了一些常见的错误示例，例如库表计算逻辑中公约数的影响，使用前若干位计算库序号常见的数据倾斜因素等等。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们在实际进行选择时，一定要考虑自身的业务特点，充分验证分片键在各个参数因子下的数据偏斜程度，并提前规划考虑好后续扩容的方案。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;END&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span title=&quot;&quot; opera-tn-ra-cell=&quot;_$.pages:0.layers:0.comps:94.title1&quot;&gt;&lt;p&gt;猜你喜欢&lt;/p&gt;&lt;/span&gt; &lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>093e1223e95f33b20b22f122b1a4e380</guid>
<title>数据服务基础能力之元数据管理</title>
<link>https://toutiao.io/k/y6dlq01</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p id=&quot;js_tags&quot; class=&quot;article-tag__list single-tag__wrp js_single&quot; data-len=&quot;1&quot; role=&quot;link&quot; aria-labelledby=&quot;js_article-tag-card__left&quot; aria-describedby=&quot;js_article-tag-card__right&quot;&gt;
                                            
                                                                                    &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__left&quot; class=&quot;article-tag-card__left&quot;&gt;
                                    &lt;span class=&quot;article-tag-card__title&quot;&gt;收录于话题&lt;/span&gt;
                                    &lt;span class=&quot;article-tag__item-wrp no-active js_tag&quot; data-url=&quot;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU4Njg0MzYwNw==&amp;amp;action=getalbum&amp;amp;album_id=1695231212027428866#wechat_redirect&quot; data-tag_id=&quot;&quot; data-album_id=&quot;1695231212027428866&quot; data-tag_source=&quot;4&quot;&gt;
                                        &lt;span class=&quot;article-tag__item&quot;&gt;#数据洞察与分析&lt;/span&gt;
                                    &lt;/span&gt;
                                &lt;/span&gt;
                                &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__right&quot; class=&quot;article-tag-card__right&quot;&gt;9个&lt;span class=&quot;weui-hidden_abs&quot;&gt;内容&lt;/span&gt;&lt;/span&gt;
                                                                                        &lt;/p&gt;

                
                                
                
                

                
                                                                

                
                                


                
                
                
                
                                                
                                                                
                                
                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;h1&gt;&lt;span&gt;一、业务背景&lt;/span&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;1、应用场景&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;在多变的数据服务场景中，应用中常见如下的业务需求，通过对多种数据结构的灵活组合，快速实现业务模型构建，整体示意图如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100001821&quot; data-ratio=&quot;0.54453125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvCyMRMjzse8cicBXM9Ly3HzoRpXP1m3w10IM9hh7sh01QUPY4lCY8J51Tfk3uib8mzbBCHRsD3stCtw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;像常用的画图工具，左边提供基础图形库，中间是画布，右边是组件的控制细节，对比到这里的逻辑如下：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;字段面板：提供业务数据结构的字段映射，和常规字段类型配置，用来支撑组合面板的表单配置。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;数据结构：对现有业务结构做映射，可能是文件、数据表、JSON等，生成相对标准的字段选项；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;拓补字段：维护一批基础的字段类型，用来做拓补操作，完善整个业务结构；&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;组合面板：承载字段的组合管理，生成新的数据结构，根据业务场景，完成底层数据的抽取存储或者API服务生成。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;业务主体：通过业务需求的判断，明确面板支撑的业务属性，通过基础结构组合新的业务主体；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;组合结构：面板上呈现的字段，是多个业务结构的抽取，即不同业务结构中的部分字段组合；&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;规则面板：对组合面板上字段进行规制设定，常见涉及：描述，类型，默认值等，对面板字段进行相对统一的标准化管理。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;描述信息：对于组合面板上的字段描述，也可以是原有映射的结果，作为新业务主体的属性说明；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;类型维护：复杂的环节，不同数据类型在不同的存储中处理方式不同，需要统一维护类型存储映射；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;业务规则：对于新的业务主体，设置属性的规则，可以是：唯一性，默认值，等等；&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;span&gt;2、构建服务&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;基于上述功能的实现，可以快速实现以下服务能力，通常应用在业务多变的场景中：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据主体构建：通过组合面板的结构生成，快速完成相关数据的抽取和存储，作为新的业务场景中的主体数据。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;服务API生成：在数据服务中，直接通过配置，生成API服务能力，并控制参数的响应结构，这种情况通常会以实时查询的方式处理。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据智能分析：在数据分析场景中，侧重统计的结果，基于字段和图表结构，生成相应的统计分析任务，灵活管理分析报表。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里是简述相对单一的应用服务，如果把这里的流程分段放大，在整个数据服务体系下，就是围绕元数据管理的复杂的基础系统：围绕数据结构映射，进行元数据标准化管理，在此基础上二次组织数据，快速响应业务需求。在这样的流程下，可以快速建立业务链路，提供高效的服务能力，降低试错的成本。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;二、元数据概念&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;1、基础描述&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;从定义上说，元数据(Metadata)即描述数据的数据，但是在实际使用的时候，还是存在很多细分的概念，看下面的案例：用户性别；&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100001822&quot; data-ratio=&quot;0.1306532663316583&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvCyMRMjzse8cicBXM9Ly3HzoNFs3qB0ibng3a9HgbLc3OY8icxWg0ELbytCRx1W0zwsOKMzzlpvu2icbQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1194&quot;/&gt;&lt;/p&gt;&lt;p&gt;从细分角度看，可以对上面数据进行两块划分，即业务层与技术层：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;业务层：名称.释义.说明.值类型;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;技术层：路由库.路由表.存储类型.值类型;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里的分层只是描述的侧重点，业务层偏向应用端，技术层偏向底层系统的交互和实现，在对性别的描述上都是核心维度。&lt;/p&gt;&lt;p&gt;所以从本质上看元数据，介于系统和业务中间，提供双方都能明白的语义和逻辑，可以更加高效的支撑数据的业务价值。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;2、血缘关系&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;上面是从单个指标看元数据的结构，如果从整个链路上看，就会形成层级线路，通常称为血缘关系：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100001823&quot; data-ratio=&quot;0.5582959641255605&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvCyMRMjzse8cicBXM9Ly3HzoPcehalricI6MrlXsjiboVcK5DYGTmjPUws2ezPq6IIdxsrqVKPSkHRVw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;892&quot;/&gt;&lt;/p&gt;&lt;p&gt;从上层业务侧追溯到底层结构，形成血缘关系的概念，概念本身并不重要的，背后的核心是链路的管理，链路上的节点（中间实体）是通过多种计算手段生成；&lt;/p&gt;&lt;p&gt;如果某个节点数据一旦出现质量问题，则需要根据这里的链路关系进行逐级向底层排查，完成问题修复后，还需要根据关系向上逐级修复清洗；如此通过血缘关系进行数据质量的分析和把控。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;3、业务价值&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;元数据管理是一个持续又漫长的过程的，任何系统的搭建都需要业务来衡量其存在的价值，其核心逻辑在于：统一标准化管理元数据信息，规范业务层的定义，并通过技术层面快速定位数据，自动化抽取数据，灵活支撑业务应用。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;围绕核心业务：通常在项目初期的时候，只围绕一些核心业务主体，使其在使用的时候灵活高效，后续在持续扩展其他能力。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据成本分析：基于元数据中链路，分析各个节点数据的生产维护管理等成本，为数据服务中商业定价提供参考，可能直接影响服务是否可提供的决策。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;配置可视化：在数据服务平台中，最忌讳的一点就是靠手动去维护各种作业，不管在什么场景下，都要考虑可配置化管理，保证动作可追溯。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;流程自动化：不管是元数据结构映射，还是配置后数据的抽取，要保证指令生成后可以自动完成该一系列动作，并完成流程监控分析。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;资产化分析：通常会把元数据视为数据资产体系，因此围绕元数据去统计数据的使用情况，产生的价值，以及热点数据识别和分布，业务主体关联度等，并输出相应分析结果。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果单从业务角度去看，元数据系统的存在，就是为了可以快速理解元数据，并且灵活的组织管理，以此降低服务能力的实现成本。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;三、架构设计&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;1、系统分层&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-fileid=&quot;100001824&quot; data-ratio=&quot;0.2748414376321353&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvCyMRMjzse8cicBXM9Ly3HzoRgboW9MicRWIfIoYvkviajNNuWDVTic85HC7XUkS4RA7JbZ01EAia4F9UQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;946&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;采集层：元数据系统中的基础节点，架构体系的底层，维护元数据获取通道和映射管理以及落地存储，并实现结构管理和数据处理过程；在数据源中可能存在多种情况：数仓环境、文件结构等，在特定情况中，还需要一定程度的手动维护进行结构拓补；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;管理层：对于元数据核心能力打造，和相应的标准化管理，或者二次加工，数据源层面直接采集的数据通常不具备标准的业务语义，更多偏向技术侧的说明和逻辑，在经过标准化维护之后，在放开给应用层之前，还需要经过质量检测：例如工作城市，如果缺乏相应的枚举字典，显然是不合格的，必须经过必要的处理才能放开；即管理层放开的数据需要标准化和整体维度完善；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;应用层：基于元数据能力的应用层开发，对于实际业务场景提供解决方案和功能入口，以及相应的系统中用户权限隔离等基本功能；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;从系统分层的角度理解流程并不复杂，但是实际的实现过程简直不堪回首，技术栈使用非常复杂，多个版本逻辑重构再重构，并且不断的改进优化，最终才能实现相对稳定的服务能力。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;2、元数据采集&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;在采集数据的时候，面对的最大问题就是多种类数据源解析适配，以及数据调度任务的抽象，必须开发对应的工具来实现各种场景的元数据解析能力：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;解析能力：适配解析各种数据源特点，文件格式，SQL脚本，抽象任务等，完成标准元数据的转换沉淀；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;类型识别：十分复杂的一个节点，类型在描述数据的时候至关重要，结构化存储可以直接读取，文件类结构通常需要类型转换标识，任务流程会直接统一管理，依次保证数据在不同环境中的合理存储；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;更新消息：业务的发展中，各种数据结构是频繁变动的，这就需要与元数据系统进行同步，通常要向消息服务（总线）发送通知，然后触发元数据更新动作；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;核心能力：结构与类型识别解析、获取初始化数据，并且通过消息通知线路，完成动态更新流程的触发。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;3、元数据管理&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;核心能力的打造，通常在系统初期都是围绕基本能力和业务需求的方向，以求快速落地实现，提供业务支撑能力；&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;基础能力：标准化元数据结构，进行结构存储和可搜索能力实现，这个节点进行统一维护，数据类型识别和转换是至关重要的；补充说一句，在数据平台中，都会存在类型服务系统，以提供相应的识别能力和规范不同场景下的转换；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;实体与关系：数据业务中两个核心概念，实体必然由属性构成这是常说的，实体之间维护的关系：关联、、绑定、输出、输入等，是构建血缘关系和数据链路的核心标识；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据抽取：基于对元数据的组织和实体的定义，生成数据抽取规则，进而完成数据的快速获取，后续就是对接具体的业务，例如数据存储方式，搬运方式，最终落地业务线使用；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;可视化分析：包括数据质量分析，链路与周期分析，血缘分析等，这类功能一般在核心业务能力完成之后，会按需求等级，逐步迭代实现；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过核心能力的建设，以求实现对数据的快速定位，高效管理，灵活应用的目标，提高数据服务能力的效率，适应业务发展的多变性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;同系列&lt;/strong&gt;：&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU4Njg0MzYwNw==&amp;amp;mid=2247485465&amp;amp;idx=1&amp;amp;sn=bf2da90dc26ceb5899209205143a2960&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;消息中间件改造&lt;/a&gt; ┃ &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU4Njg0MzYwNw==&amp;amp;mid=2247485218&amp;amp;idx=1&amp;amp;sn=fdce6722b571c35298f9d999b7df2395&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;数据服务系统设计&lt;/a&gt; ┃ &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU4Njg0MzYwNw==&amp;amp;mid=2247485392&amp;amp;idx=1&amp;amp;sn=6895452da3e827128f4b2ef6c9de46ca&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;业务数据清洗方案&lt;/a&gt; ┃ &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU4Njg0MzYwNw==&amp;amp;mid=2247485178&amp;amp;idx=1&amp;amp;sn=e7f42c9d54f6852556abfd01478f8d0b&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;数字营销概念&lt;/a&gt; ┃ &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU4Njg0MzYwNw==&amp;amp;mid=2247485157&amp;amp;idx=1&amp;amp;sn=37b30d99a6d8f3a78cdc79b81b552416&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;标签业务应用&lt;/a&gt; ┃&lt;/p&gt;&lt;h2&gt;&lt;span&gt;四、源代码地址&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;GitEE·地址&lt;br/&gt;https://gitee.com/cicadasmile&lt;br/&gt;Wiki·地址&lt;br/&gt;https://gitee.com/cicadasmile/butte-java-note/wikis&lt;/code&gt;&lt;/pre&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU4Njg0MzYwNw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBCuF3zfJnqPKpUia4wfn1FUtTHpxxkR5HvbicPgOjibPicX0goMOkny1NdkLAJvBaqrYh3UdwMjiaDQMA/0?wx_fmt=png&quot; data-nickname=&quot;知了一笑&quot; data-alias=&quot;cicada_smile&quot; data-signature=&quot;积累是一个孤独且枯燥的过程&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4fab7850993e303ccb01bfd4c9c1d541</guid>
<title>前端 100 万行代码是怎样的体验？</title>
<link>https://toutiao.io/k/nacz0xt</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText css-hnrfcf&quot; options=&quot;[object Object]&quot;&gt;&lt;p&gt;    近年来，阿里数据中台产品发展迅速。核心产品之 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.aliyun.com/page-source/common/yunqihao/quickbi_gartnerabi_2021&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Quick BI&lt;/a&gt; 连续 2 年成为国内唯一入选 Gartner 魔力象限的国产 BI。Quick BI 单一代码仓库源码突破了 100万行。整个开发过程涉及到的人员和模块都很多，因为下面分享的一些原则，产品能一直做到快速迭代。&lt;/p&gt;&lt;p&gt;先分享几个关键数据：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;代码：TypeScript 82万行，样式 Sass+Less+CSS 18万行。（cloc 统计，去除自动生成代码）&lt;/li&gt;&lt;li&gt;协同：Code Review 12000+次，Commit 53,000+次。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fbe77c8f70896e47238e5f66b383d354_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1502&quot; data-rawheight=&quot;386&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-fbe77c8f70896e47238e5f66b383d354_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1502&quot; data-rawheight=&quot;386&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-fbe77c8f70896e47238e5f66b383d354_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fbe77c8f70896e47238e5f66b383d354_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;很多人会问，这么多代码，为什么不切分代码库？还不赶快引入微前端、Serverless 框架？你们就不担心无法维护，启动龟速吗？ 实际情况是，从第一天开始，就预估到会有这么大的代码量。启动时间也从最初的几秒钟到后面越来越慢5～10分钟，再优化到近期的5秒钟。整个过程下来，团队更感受到 Monorepo（单一代码仓库）的优势。 ​ 这个实践想说明：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;大的 Codebase 可能是好事情，大道至简。用极其“简单”的架构更容易支持复杂灵活的业务&lt;/li&gt;&lt;li&gt;要做到简单的架构，内部需要更&lt;b&gt;明确&lt;/b&gt;的规范，更&lt;b&gt;密切&lt;/b&gt;的协同，更&lt;b&gt;高效&lt;/b&gt;的执行&lt;/li&gt;&lt;li&gt;能通过工程化解决的问题，就不要通过开发规范，能通过规范来解决的不要靠自由发挥&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;h_425616384_0&quot; data-into-catalog-status=&quot;&quot;&gt;开工&lt;/h2&gt;&lt;p&gt;2019年4月30号，晴朗的下午，刚好是喜迎五一的前一天，发挥集体智慧，投票选出满意的仓库名。最开始是做 Quick BI 的底座，后来底座越来越大，把上层业务代码也吸纳进来。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;commit 769bf68c1740631b39dca6931a19a5e1692be48d
Date:   Tue Apr 30 17:48:52 2019 +0800

    A New Era of BI Begins&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&quot;h_425616384_1&quot; data-into-catalog-status=&quot;&quot;&gt;Why Monorepo？&lt;/h2&gt;&lt;figure data-size=&quot;small&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d0940049756d5bb2f007a5a5c76e4830_b.png&quot; data-caption=&quot;&quot; data-size=&quot;small&quot; data-rawwidth=&quot;960&quot; data-rawheight=&quot;120&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-d0940049756d5bb2f007a5a5c76e4830_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;small&quot; data-rawwidth=&quot;960&quot; data-rawheight=&quot;120&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-d0940049756d5bb2f007a5a5c76e4830_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d0940049756d5bb2f007a5a5c76e4830_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在开工之前，对单一仓库（Monorepo）和多仓库（Polyrepo）团队内做了很多的讨论。&lt;/p&gt;&lt;p&gt;曾经我也很喜欢 Polyrepo，为每个组件建立独立 repo 独立 npm，比如2019年前，单是表单类的编辑器组件就有 43 个：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e1d4bcc63a367cd81a527a35fadcd0d5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1184&quot; data-rawheight=&quot;924&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-e1d4bcc63a367cd81a527a35fadcd0d5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1184&quot; data-rawheight=&quot;924&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-e1d4bcc63a367cd81a527a35fadcd0d5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e1d4bcc63a367cd81a527a35fadcd0d5_b.jpg&quot;/&gt;&lt;figcaption&gt;曾经拆分从43个npm&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p&gt;本以为这样可以做到 &lt;b&gt;完美的解耦、极致的复用&lt;/b&gt;？？ ​ 但实际上：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;每次 Babel、React 等依赖整体升级能让人脱层皮，所以自研了脚手架。造轮子都是被逼出来的，事情做了一点点，但写脚本能力直线上升&lt;/li&gt;&lt;li&gt;每次 调试组件，npm link 一下。后来组件跨级，可以做 3 层 npm link，使用过的都知道这是多么糟糕的体验&lt;/li&gt;&lt;li&gt;版本难对齐，每次主仓库发布前，组件间版本对齐更是考验眼力，稍有不慎触发线上故障&lt;/li&gt;&lt;li&gt;方便别人复用的优势呢？最终支持自己业务都捉襟见肘，哪还敢让别人复用&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;最终我们把所有这些组件都合并到一个仓库，其实像 Google/Facebook/Microsoft 这些公司内部都很推崇 Monorepo。​&lt;/p&gt;&lt;p&gt;但我们不是原教旨主义的 Monorepo，没必要把不相关的产品代码硬放到一起。在实线团队内部，单个产品可以使用 Monorepo，会极大降低协同成本。但开始的时候，团队内还是有很多疑问。&lt;/p&gt;&lt;h2 id=&quot;h_425616384_2&quot; data-into-catalog-status=&quot;&quot;&gt;关于 Monorepo 的几个核心疑问？&lt;/h2&gt;&lt;h3 id=&quot;h_425616384_3&quot; data-into-catalog-status=&quot;&quot;&gt;1. 单一仓库，体积会很大吧？&lt;/h3&gt;&lt;p&gt;&lt;code&gt;100 万行&lt;/code&gt;代码的体积有多大？ ​ 先来猜一下：1GB？10GB？还是更多？ ​ 首先，按照公式计算一下：&lt;/p&gt;&lt;blockquote&gt; 代码的体积 = 源码的体积 + .git 的体积 + 资源文件（音视频、图片、其他文件）&lt;/blockquote&gt;&lt;p&gt;i. 我们一起来算一下源码的体积：&lt;/p&gt;&lt;p&gt;一般建议每行小于 120 字符，我们取每行 100 个字符来算，100 万行就是：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;100 * 1000,000 = 100,000,000 B
转换之后就是 100 MB！&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;那我们的仓库实际多大呢？  只有 85 MB！也就是平均每行 85 个字符。&lt;/p&gt;&lt;p&gt;ii. 再来算一下 &lt;code&gt;.git&lt;/code&gt;的体积：&lt;/p&gt;&lt;p&gt;&lt;code&gt;.git&lt;/code&gt;里记录了所有代码的提交历史、branch 和 tag 信息。会很大体积吧？ 实际上 Git 底层做了很多的优化：1. 所有 branch 和 tag 都是引用；2. 对变更是增量存储；3. 变更对象存储的时候会使用 zlib 压缩。（对于重复出现的样板代码只会存储一次，对于规范化的代码压缩比例极高）。 按照我们的经验，&lt;code&gt;.git&lt;/code&gt;记录 &lt;code&gt;10,000&lt;/code&gt; 次 commit 提交只需要额外的 &lt;code&gt;1～3&lt;/code&gt; 个代码体积即可。&lt;/p&gt;&lt;p&gt;iii. 资源文件大小&lt;/p&gt;&lt;p&gt;Git 做了很多针对源码的优化，但视频和音频这类资源文件除外。我们最近使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//rtyley.github.io/bfg-repo-cleaner/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BFG&lt;/a&gt; 把另一个产品的仓库从 22GB 优化到 200MB，降低 99%！而且优化后代码的提交历史和分支都得到了保留（因为 BFG 会编辑 Git 提交记录，部分 commit id 会变化）。 以前 22 GB 是因为仓库里存放视频、发布的 build 文件和 sourcemap 文件，这些都不应该放到源码仓库。&lt;/p&gt;&lt;p&gt;小结一下，百万行代码体积一般在 200MB ～ 400MB 之间。那来估算下 &lt;code&gt;1000 万行&lt;/code&gt;代码占用体积是多少？ 乘以十也就是 &lt;code&gt;2GB ~ 4GB&lt;/code&gt; 之间。这对比 &lt;code&gt;node_modules&lt;/code&gt;随随便便几个 G 来说，并不算什么，很容易管理。 补充个案例，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Linux 内核&lt;/a&gt;有 2800 万行，使用 Monorepo，数千人协同。据说当时 Linus 就是为了管理 Linux 的源码而开发出 Git。&lt;/p&gt;&lt;h3 id=&quot;h_425616384_4&quot; data-into-catalog-status=&quot;&quot;&gt;2. 启动很慢吧？5分钟还是10分钟？&lt;/h3&gt;&lt;p&gt;听到有些团队讲，代码十几万行，启动 10+分钟，典型的“巨石”项目，已经很难维护了。赶紧拆包、或者改微前端。可能团队才 3 个人却拆了 5 个项目，协同起来非常麻烦。&lt;/p&gt;&lt;p&gt;我们做法有3个：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;按照页面来拆分多 Entry，每次只需启动一个 Entry&lt;/li&gt;&lt;li&gt;梳理子包间的依赖关系，追求极致的 Lazy loading，Tree-Shaking&lt;/li&gt;&lt;li&gt;Webpack 切换到 Vite&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;尤其是 Webpack 切换到 Vite 以后，最终项目冷启动时间由 2-5分钟 优化到 &lt;b&gt;5秒 &lt;/b&gt;内。 热编译时间由原来 5秒 优化到 1秒 内，Apple M1 电脑基本都是 500ms 以内。&lt;/p&gt;&lt;h3 id=&quot;h_425616384_5&quot; data-into-catalog-status=&quot;&quot;&gt;3. 代码复用怎么办？Monorepo 复用的时候是否要引入全部？&lt;/h3&gt;&lt;p&gt;传统的软件工程思想追求 DRY，但并不是越 DRY 越好。&lt;/p&gt;&lt;p&gt;每写一行代码，都产生了相应代价：&lt;b&gt;维护&lt;/b&gt;的成本。为了减少代码，我们有了可复用的模块。但是代码复用有一个问题：当你以后想要修改的时候它就会成为一个障碍。 对于像 Quick BI 这样长期迭代的产品，绝大部分需求都是对原有功能的扩展，所以写出易维护的代码最重要。因此，团队不鼓励使用 magic 的特技写法；不单纯追求代码复用率，而是追求更易于修改；鼓励在未来模块下线的时候易于删除的编码方式。 ​ 对于确实存在复用的场景，我们做了拆包。Monorepo 内部我们拆了多个 package（后面有截图），比如其他产品需要 BI 搭建，可以复用 &lt;code&gt;@alife/bi-designer&lt;/code&gt;，并借助于 Tree-Shaking 做到依赖引入的最小化。&lt;/p&gt;&lt;h2 id=&quot;h_425616384_6&quot; data-into-catalog-status=&quot;&quot;&gt;目前的开发体验&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;冷启动 5秒，热编译 1秒内&lt;/b&gt;。以前是 5~10分钟。&lt;/li&gt;&lt;li&gt;改一行代码能解决的问题，&lt;b&gt;真正改一行且发布一次&lt;/b&gt;。而不是改 10+ 个项目，按依赖发布 N 次。&lt;/li&gt;&lt;li&gt;&lt;b&gt;新人 10分钟 搭建好环境&lt;/b&gt;，上手开发&lt;/li&gt;&lt;li&gt;相比于以前每个组件一个 Repo，包赋权都要搞很久&lt;/li&gt;&lt;li&gt;避免了版本不对齐的问题&lt;/li&gt;&lt;li&gt;对于 2C 产品，不需要多版本多主干分支，但多个 npm 依赖对齐版本也不容易&lt;/li&gt;&lt;li&gt;对于 2B 产品，由于多环境、多版本，会更加复杂，复杂度极高。Monorepo 通过分支来统一内部依赖的版本&lt;/li&gt;&lt;li&gt;工程化升级只需要一次。目前是基于 Lerna 开发的 Pri Monorepo 方案。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这样的体验要保持并不容易，开发中还有很多问题要解决：&lt;/p&gt;&lt;h2 id=&quot;h_425616384_7&quot; data-into-catalog-status=&quot;&quot;&gt;真正需要解决的问题&lt;/h2&gt;&lt;p&gt;Monorepo 不是银弹，对于不成熟的团队反而可能是炸弹。因为每个人每次提交都有摧毁整个产品的风险。 ​ 要产生价值，需要团队在 协同、技术文化、工程化、质量保障等方面达到深度认可。 ​&lt;/p&gt;&lt;h3 id=&quot;h_425616384_8&quot; data-into-catalog-status=&quot;&quot;&gt;1. 包依赖管理&lt;/h3&gt;&lt;p&gt;拆包的主要原因有2个，给外部复用以及减少打包后的体积（Tree Shaking 做的不够）。对于小闭环的团队，直接使用子目录让业务快跑就够用了，架构上更简单。&lt;/p&gt;&lt;p&gt;内部拆分多个子包，每个子包对应一个子文件，可以单独发布 npm，见下图： &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-73b5b2b97e346a4dbc241b64fd912d52_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1500&quot; data-rawheight=&quot;970&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-73b5b2b97e346a4dbc241b64fd912d52_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1500&quot; data-rawheight=&quot;970&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-73b5b2b97e346a4dbc241b64fd912d52_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-73b5b2b97e346a4dbc241b64fd912d52_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt; 内部包管理的核心原则是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;从左向右单向依赖，只能右边引用左边，禁止循环依赖&lt;/li&gt;&lt;li&gt;开发单向依赖检测插件，如果左边依赖右边直接报错&lt;/li&gt;&lt;li&gt;增加新包需要架构组评审，减少包的数量&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于开源 npm 的引入，需要更慎重。大部分 npm 的维护时长不超过x年，即使像 Moment.js 这样曾经标配的工具库也会终止维护。可能有 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//blog.tidelift.com/up-to-20-percent-of-your-application-dependencies-may-be-unmaintained&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;20% 的 npm 是没人维护&lt;/a&gt;。但未来如果你的线上用户遇到问题，你就需要靠自己啃源码，陷入被动。所以我们的原则是，引入开源 npm 要架构组评审通过才行。&lt;/p&gt;&lt;h3 id=&quot;h_425616384_9&quot; data-into-catalog-status=&quot;&quot;&gt;2. Code Review 文化&lt;/h3&gt;&lt;p&gt;互相 Code Review 能帮助新人快速成长，同时也是打造团队技术文化的方式。 过去几年一直在团队内推行 100% CR，但这还不够。机械的执行很容易把 CR 流于形式，去年开始探索分场景来做。&lt;/p&gt;&lt;p&gt;目前我们的 Code Review 主要分为3个场景：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;线上 MR Code Review【1对1】&lt;/li&gt;&lt;li&gt;主题式 Code Review【3-5个人】&lt;/li&gt;&lt;li&gt;大版本发布前集体 Code Review【All】&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;过去几年，一万两千多次 Code Review 积累的经验有很多，主要是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;及时 Review，鼓励小颗粒度的 MR，不必等整个功能开发完成&lt;/li&gt;&lt;li&gt;代码是写给人看的，鼓励白话文一样的代码，而不是文言文&lt;/li&gt;&lt;li&gt;建立最佳实践（目录树结构、命名规范、数据流规范）。开发一个功能可以有 10 种方法，但团队需要选 1 种并推广&lt;/li&gt;&lt;li&gt;不鼓励炫技，为了未来可维护性。能用简单技术实现，不要用“高深”冷门的技术&lt;/li&gt;&lt;li&gt;强调开发洁癖，追求优雅代码的文化。（命名是否易于理解、注释是否完整、是否有性能隐患等）&lt;/li&gt;&lt;/ol&gt;&lt;h3 id=&quot;h_425616384_10&quot; data-into-catalog-status=&quot;&quot;&gt;3. 工程化建设&lt;/h3&gt;&lt;p&gt;这个过程首先要感谢阿里 Def 工程化团队的支持，代码的增加在不断挑战打包机性能和灵活性的边界，Def 都能快速支持。 ​ 一般团队都会有开发规范，但能做到自动化工具检查的规范才是好规范。 ​&lt;/p&gt;&lt;h3 id=&quot;h_425616384_11&quot; data-into-catalog-status=&quot;&quot;&gt;检查器：ESLint、TS 类型校验、Prettier&lt;/h3&gt;&lt;p&gt;语法检查器是推动规范落地的重要方法，ESLint 可以做增量，优化后 git commit 的 pre-hooks 依旧很快。但 TS type check 因为不支持增量就比较慢了，放到本地体验就不好，需要搭配 CI/CD 来使用。&lt;/p&gt;&lt;h3 id=&quot;h_425616384_12&quot; data-into-catalog-status=&quot;&quot;&gt;Webpack vs Vite&lt;/h3&gt;&lt;p&gt;Webpack 的优势是插件丰富，打包产物兼容性好，页面打开快速，但开发模式启动慢、极慢，而 Vite 恰恰切中了这个痛点，开发模式启动快、飞快。 最近，我们做到了 Webpack 和 Vite 混合的模式，使用了两者的优点。 开发环境使用 Vite 快速调试，生产环境依旧使用 Webpack 打包出稳定兼容性好的产物。 风险是开发和生产编译产物不一致，这一块需要上线前回归测试避免。 ​&lt;/p&gt;&lt;h3 id=&quot;h_425616384_13&quot; data-into-catalog-status=&quot;&quot;&gt;4. 性能优化&lt;/h3&gt;&lt;p&gt;对于数据类产品而言，性能的挑战除了来自于 Monorepo 后构建产物的变大，还有大数据量对渲染计算带来的挑战。&lt;/p&gt;&lt;p&gt;性能优化可以分为3个环节：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;资源加载：精细化 Tree Shaking，难在精细。Webpack 本身的 Tree-Shaking 做的并不好，不支持 Class method 做 Tree Shaking，所以有时候需要修改代码。Lazy Loading 模块做到按需加载，尤其是图表、SQL 编辑器这类大组件。合理的接口预加载，不要让网络闲下来。&lt;/li&gt;&lt;li&gt;视图渲染：让组件渲染次数降到最低，表格类组件虚拟滚动优化，闲时预加载预渲染。&lt;/li&gt;&lt;li&gt;取数请求：资源本地化缓冲方案，移动端使用 PWA 将 JS 等资源文件和数据缓存到本地。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;另外还有性能检测工具，定位性能卡点。计划做代码性能门闩，代码提交前如果发现包体积增大发出提醒。&lt;/p&gt;&lt;h3 id=&quot;h_425616384_14&quot; data-into-catalog-status=&quot;&quot;&gt;5. 数据化驱动架构优化&lt;/h3&gt;&lt;p&gt;身在数据中台，我对数据的业务价值深信不疑。但对于开发本身而言，很少深度使用过数据。 所以 S1 重点探索了开发体验的数字化。通过采集大家的开发环境和启动耗时数据来做分析【不统计其他数据避免内卷】。发现很多有意思的事情，比如有个同学热编译 3～5 分钟，他以为别人也是这样慢，严重影响了开发效率，当从报表发现数据异常后十分钟帮他解决。&lt;/p&gt;&lt;p&gt;另外一个例子，为了保持线上打包产物的一致性，推动团队做 Node.js 版本统一，以前都是靠钉，钉多少次都无法知道效果如何。有了报表以后就一目了然。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-93083114706aacd49e2b7ee2ae7b898e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2670&quot; data-rawheight=&quot;726&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-93083114706aacd49e2b7ee2ae7b898e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2670&quot; data-rawheight=&quot;726&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-93083114706aacd49e2b7ee2ae7b898e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-93083114706aacd49e2b7ee2ae7b898e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt; 目前整个数据化的流程跑通，初步尝到甜头。未来还有很多好玩的分析可以做。&lt;/p&gt;&lt;h2 id=&quot;h_425616384_15&quot; data-into-catalog-status=&quot;&quot;&gt;更深层的经验&lt;/h2&gt;&lt;h3 id=&quot;h_425616384_16&quot; data-into-catalog-status=&quot;&quot;&gt;效率最高的方式就是一次最好&lt;/h3&gt;&lt;p&gt;每行代码都会留下成本。长远考虑，效率最高的方法就是一次做好。 苏世民说“做大事和做小事的难度是一样的。 两者都会消耗你的时间和精力”。既然如此，不妨把代码一次写好。代码中如果遗留 “TODO” 可能就永远 TO DO。客观来讲，一次做好比较难，首先是每个人认为的“好”标准不同，背后是个人的技术能力、体验的追求、业务的理解。&lt;/p&gt;&lt;h3 id=&quot;h_425616384_17&quot; data-into-catalog-status=&quot;&quot;&gt;组织文化技术 相辅相成&lt;/h3&gt;&lt;p&gt;技术架构和组织结构有很大关系，选择适合组织的技术架构更重要。 如果一个组织是分散的，使用 Monorepo 会有很大的协同成本。组织如果是内聚的，Monorepo 用好能极大提效。 工程化和架构底座是团队的事情，靠个人很难去推动。 短期可以靠战役靠照搬，长期要形成文化才能持续迭代。 组织沟通成本高应该通过组织来解，通过技术来解的力量是渺小的。技术可以做的是充分发挥工具的优势，让变化快速发生。&lt;/p&gt;&lt;h3 id=&quot;h_425616384_18&quot; data-into-catalog-status=&quot;&quot;&gt;简单不先于复杂，而是在复杂之后&lt;/h3&gt;&lt;p&gt;这是借用Alan Perlis的一句话。 ​ 对于一个简单的架构，总会有人会想办法把它做复杂。踩了坑，下决心重构，成功则回归简单，失败就会被新的简单模式颠覆。架构就是这样不断的在做复杂和做简单中交替着螺旋式演进。 踩坑本身也是有价值的，不然新人总是按捺不住还会再踩一次。做复杂很容易，但保持简单需要远见和克制。没有经历过过程的磨练，别人的解药对你可能是毒药。 架构不会一成不变，Quick BI 的图表最开始直接使用 D3、ECharts 简单快速，后来非常多定制化的功能逐渐复杂到难以扩展，于是基于 G2 自研 bi-charts 后架构又一次变简单，每一次重构都是对架构中各个元素的重新思考和整合，能够以更简单高效的方式支持业务。&lt;/p&gt;&lt;h2 id=&quot;h_425616384_19&quot; data-into-catalog-status=&quot;&quot;&gt;总结与展望&lt;/h2&gt;&lt;p&gt;百万行代码没什么可怕，是一个正常的节点，仍然可以像几万行代码那样敏捷。 ​ 现在 Quick BI 已经向千万行迈进，向世界一流 BI 的目标迈进。需要考虑研发效率、质量管控、组织协同、工程化、体验性能多方面的优化。以上内容限于篇幅。BI 数据分析业务开发涉及的技术挑战非常多，因为数据分析天生就要与海量数据打交道，在大数据量渲染和导出上我们在不断的探索；洞察丰富异样的数据，可视化及复杂表格方面有极其多样的需求，可视化能力不仅是技术，还变成业务本身；手机平板电视等多端展示，跨端适配需要融入到每个功能点。未来还希望能够把数据分析打造成一个引擎，能够快速集成到技术产品和商业流程中。&lt;/p&gt;&lt;p&gt;目前的开发模式并不完美，你有任何方面的建议，欢迎交流。&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>