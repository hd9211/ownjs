<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>9a83a95e1e121f6fa2027ea234c3c2e7</guid>
<title>从零开始搭建公司微服务授权架构技术栈（3种模式），这架构稳的一批...</title>
<link>https://toutiao.io/k/4g58j8v</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;30&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;作者 | Graham Kaemmer  &lt;/span&gt;&lt;span&gt;译者 | Rayden  &lt;/span&gt;&lt;span&gt;审校 | 王强&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;section&gt;在过去的 5 个月里，我与 50 多家公司讨论了他们的授权系统。其中超过一半的公司以某种形式使用微服务，我对它们带来的授权挑战非常感兴趣。在面向服务的后端进行授权这一问题上，似乎没有公认的最佳实践。我与很多团队进行了交谈，有的团队将用户角色附加到身份验证令牌上，有的将所有内容存储在专门用于授权的图数据库中，还有的团队在 Kubernetes 边车（sidecars）中自动执行授权检查。这些解决方案中都沉淀了数月或数年的工程工作，每个团队都发明了自己的轮子。这是为什么?&lt;br/&gt;&lt;/section&gt;&lt;p&gt;当你有一个单体应用时，你通常只需要访问一个数据库来决定是否允许用户做某些事情。单体应用的授权策略本身不需要太关心在哪里找到数据（比如用户角色）——你可以假设所有数据都可用，如果需要加载额外数据，它也可以很容易地从单体应用数据库中获取。&lt;/p&gt;&lt;p&gt;但是这个问题在分布式架构中变得困难了许多。也许你正在将单体应用拆分为多个微服务，或者你正在开发一个新的计算密集型的服务，在运行作业之前需要检查用户权限。现在，决定谁可以做什么的数据可能不那么容易获取。你需要新的 api，以便你的服务能够相互谈论权限：“谁是这个组织的管理员？谁可以编辑这个文档？他们可以编辑哪些文档？”为了在服务 A 中做出决策，我们需要服务 B 中的数据，服务 A 的开发人员如何请求这些数据？服务 B 的开发人员如何使这些数据可用？&lt;/p&gt;&lt;p&gt;这些问题有很多答案，所以我试图将这些答案归纳为几个广泛的模式。这些模式不一定能覆盖所有解决方案（解决方案的世界很复杂），但我发现它们能帮助我与不同的人谈论他们所构建的东西。当我与一个新团队进行对话时，它们让我更容易对解决方案进行分类。&lt;/p&gt;&lt;p&gt;在构建微服务时，我看到了处理授权数据的三种主要模式。我将在这篇文章中讨论这三种方法：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;将数据留在原处，让服务直接请求它。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用网关将数据附加到所有请求，以使其随处可用。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;将授权数据集中到一个地方，并将所有决策转移到那个地方。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;
&lt;span&gt;1&lt;/span&gt; 为什么微服务中的授权更困难？&lt;/section&gt;&lt;p&gt;让我们以某个授权场景为例，这是一个用于编辑文档的应用程序。它很简单，但应该能说明问题：&lt;/p&gt;&lt;p&gt;在一个单体应用中，用一种清晰的方式表达这种逻辑并不太难。当你需要检查用户是否可以阅读文档时，你可以检查该文档属于哪个组织，加载该组织中用户的角色，并检查该角色是成员还是管理员。这些检查可能需要额外的一两行 SQL 语句，但数据都在一个地方。&lt;/p&gt;&lt;p&gt;当你将应用程序拆分为不同的服务时，会发生什么情况？也许你已经剥离了一个新的“文档服务”——现在，检查特定文档的读权限需要检查位于该服务数据库之外的用户角色。文档服务如何访问它所需要的角色数据？&lt;/p&gt;&lt;section&gt;&lt;span ql-global=&quot;true&quot; line-inline=&quot;db52&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6658851113716295&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPmDmQ7n4ELE6ppylMPPda6a1icp691ZR2xFYRr155EIAiaYQ8Ovr1tnFR2LbgJQ6AEibicbpCPfibdz3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1706&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;
&lt;span&gt;2&lt;/span&gt; 模式 1：将数据留在原处&lt;/section&gt;&lt;p&gt;通常，最简单的解决方案是将数据留在原处，并让服务在需要时请求它所需要的数据。对于上述问题，你可能认为这是最明显的解决方案。&lt;/p&gt;&lt;p&gt;你可以将数据模型和逻辑分开，这样文档服务就可以控制向哪个角色授予哪些文档相关的权限（管理员可以编辑，成员可以读取，等等），然后用户服务公开一个 API 来获取组织中用户的角色。有了这个 API，权限检查可以像这样进行:&lt;/p&gt;&lt;section&gt;&lt;span ql-global=&quot;true&quot; line-inline=&quot;ad51&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6359803232607167&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPmDmQ7n4ELE6ppylMPPda6qtLGhSyTCocpibWCyNexhrHEXBNibGeGicY8nDxbkDVk73Ifo1sXJHycw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1423&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;有一个合理的论点认为最简单的解决方案就是最好的方案，在这里它通常是没问题的。根据我的经验，这通常是当团队开始转向微服务并想让用户授权正常工作的情况下所使用的解决方案。它完成了工作，而且不需要任何额外的基础设施。&lt;/p&gt;&lt;p&gt;当服务或团队数量增加、授权逻辑变得更复杂或面临更严格的性能要求时，此模式开始出现问题。要让该模式正常工作，任何新服务的开发人员都需要知道如何从用户服务中获取角色数据，而用户服务本身必须扩展以满足这种需求。随着服务依赖关系的增加，该模式可能会增加不可预测的延迟和重复请求。也许引入一个单独的“文件夹”服务就会导致系统需要通过服务之间的相互调用来进行权限检查：&lt;/p&gt;&lt;section&gt;&lt;span ql-global=&quot;true&quot; line-inline=&quot;655f&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6256627783669141&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPmDmQ7n4ELE6ppylMPPda6b7ZxTIn2aVxzyoOKQDwsIwq57DV5iaqj0iaB61wSCqcxXNHavtlWp8ag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1886&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;尽管有变得混乱的风险，但这种模式可以让你走得很远。无需部署和维护额外的授权基础设施可能是一个巨大的优势，如果具有数据的服务能够处理来自需要数据的服务的负载，那么将它们串在一起就是一个很好的解决方案。&lt;/p&gt;&lt;p&gt;有一些团队遵循这种通用模式，但他们认为应该用某种专门的授权服务替换所有这些请求流，我和这些团队有过交谈。我总是问他们真正的问题是什么。如果问题是时延，也许在正确的位置添加缓存可以解决这个问题。如果授权逻辑在服务中变得越来越混乱，那么可能需要强制采用标准策略格式。（Oso 是一个解决方案；还有其他解决方案。）&lt;/p&gt;&lt;p&gt;但是，如果问题是你的数据模型变得过于复杂，或者你在重复实现相同的 api，或者权限检查需要与太多不同的服务通信，那么也许是时候重新考虑架构了。&lt;/p&gt;&lt;section&gt;
&lt;span&gt;3&lt;/span&gt; 模式 2：请求网关&lt;/section&gt;&lt;p&gt;解决授权数据问题的一个优雅的解决方案是将用户角色包含在对服务（这些服务可能需要做出授权决策）的请求中。如果文档服务在请求中获得有关于用户角色的信息，那么它可以基于这些信息做出自己的授权决策。&lt;/p&gt;&lt;section&gt;&lt;span ql-global=&quot;true&quot; line-inline=&quot;8e1b&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.748319641523525&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPmDmQ7n4ELE6ppylMPPda6toHBzSdLYaVkh4t9UlXHAKXfO82bicPc2cs3Y6xVIf0lrVBqVzKU4TQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1339&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;在这种模式中，“网关”位于 API 和其最终用户之间。网关可以访问用户信息和角色信息，它可以在将请求传递给 API 本身之前将这些信息附加到请求中。当 API 接收到请求时，它可以使用来自请求的角色数据（例如在请求头中）来检查用户行为是否被允许。&lt;/p&gt;&lt;p&gt;网关通常同时负责身份验证和授权。例如，网关可能使用 Authorization 头对特定用户进行身份验证，然后另外获取该用户的角色信息。然后网关将带有用户 ID 和角色信息的请求代理给下游服务（上面示例中的文档服务）。&lt;/p&gt;&lt;p&gt;&lt;span ql-global=&quot;true&quot; line-inline=&quot;8a35&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7072135785007072&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPmDmQ7n4ELE6ppylMPPda6ZExtOvNVVomgawJibBzuYNTV9J1kSlWib54BVu4Jbzdda0JY29MPoDvg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1414&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;网关模式的主要好处是其架构简单。它使下游服务（如文档服务）的开发人员不必关心角色数据来自哪里。授权数据在请求中始终是可用的，因此可以立即执行权限检查，而不需要任何额外的调用。&lt;/p&gt;&lt;p&gt;请注意，在这里使用明文头信息开辟了新的攻击途径——你需要确保恶意客户端不能注入它们自己的头信息。作为一种替代方法，用户角色或其他访问控制数据可以包含在他们的身份验证令牌中，通常表示为 JWT。&lt;/p&gt;&lt;p&gt;如果授权数据由少量角色组成（例如，每个用户在一个组织中只能有一个角色），网关模式的效果最好。当权限开始不仅仅依赖于用户在组织中的角色时，请求的规模就会激增。也许用户可以有不同的角色，这取决于他们试图访问的资源类型（特定事件的组织者，或特定文件夹的编辑器）。有时，这些数据太大以至于无法放入请求头中，而其他时候，一次获取所有数据效率很低。如果是这种情况，将所有相关的授权数据塞到令牌或请求头中并不能完全解决问题。&lt;/p&gt;&lt;section&gt;
&lt;span&gt;4&lt;/span&gt; 模式 3：集中存放所有授权数据&lt;/section&gt;&lt;p&gt;另一种解决方案是将所有授权数据和逻辑放在一个地方，与需要实施授权的所有服务分开。实现此模式的最常见方法是构建专用的“授权服务”。然后，当其他服务需要执行权限检查时，它们会转向询问授权服务：&lt;/p&gt;&lt;section&gt;&lt;span ql-global=&quot;true&quot; line-inline=&quot;caa4&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.611878453038674&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfPmDmQ7n4ELE6ppylMPPda6MxLAzZStpsFksYpp5QhicRicqEH95G4ibbco1Wicg6SS5P2ZnDsicJPuoiag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1448&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;在这个模型中，文档服务根本不关心用户的角色：它只需要询问授权服务，用户是否可以编辑文档，或者用户是否可以查看文档。授权服务本身包含做出该决策所需的所有内容（包括角色数据）。&lt;/p&gt;&lt;p&gt;这可能非常有吸引力：你现在有一个负责授权的系统，这符合微服务的哲学。以这种方式进行责任分离有一些好处：团队中的其他开发人员不需要关心授权是如何工作的。因为它是独立的，所以你对授权服务所做的任何优化都有助于加速整个系统的其余部分。&lt;/p&gt;&lt;p&gt;当然，这种责任分离是有代价的。现在，所有授权数据都必须保存在一个地方。决策中可能使用的所有内容都必须保存在一个集中式服务中，这些内容包括用户在组织中的身份、文档与其组织的关系。要么授权服务成为该数据的唯一真实来源，要么必须将数据从应用程序复制并同步到该中心（可能性更大）。授权系统必须理解作为所有权限基础的整个数据模型：组、共享、文件夹、来宾、项目。如果这些模型经常改变，授权系统可能成为新的开发任务的瓶颈。任意微服务中的任何更改都可能需要对授权服务进行更新，从而打破你在最初转向微服务时可能寻求的关注点分离效果。&lt;/p&gt;&lt;p&gt;还有其他因素会使授权服务变得棘手：部署这一负责保护每个请求的服务意味着你要负责实现高可用和低延迟。如果系统出现故障，则所有请求都会被拒绝。如果授权系统系统的响应很慢，那么每个请求都很慢。&lt;/p&gt;&lt;p&gt;谷歌的 Zanzibar 论文概述了这种模式的一种实现，但它也带来了挑战。你必须将所有数据以“元组”的形式插入到 Zanzibar 中（Alice 拥有这个文档，这个文件夹包含另一个文件夹，等等）。由于它限制了可以存储的数据，有些规则实际上不能仅用 Zanzibar 来表示，例如一些必须与时间、请求上下文有关的规则，或者依赖于某种计算的规则。有人将这些称之为“基于属性”的规则。例如，用户每周只允许创建 10 个文档，或者管理员可以将某些文件夹设置为“只读”，以防止对其中文档的编辑。在这些情况下，开发人员必须在 Zanzibar 之外编写自己的策略逻辑。&lt;/p&gt;&lt;p&gt;集中式授权存在的挑战往往会阻止大多数团队采用这种模式。采用该模式的应用往往有很多服务和足够复杂的数据模型，接受授权服务本身增加的复杂性对它们来说是有意义的。例如，为了从单体应用向微服务转型，Airbnb 建立了一个名为 Himeji 的授权服务以支持他们的授权模式。已经有一个专门的工程师团队为它工作了两年，而且可能会无限期地工作下去。&lt;/p&gt;&lt;p&gt;但是，如果你能够去除一些这类开销，那么对于许多使用微服务架构的团队来说，集中式授权服务可能是一个很有吸引力的选择。我的团队正在努力构建一个授权服务，力求避免集中所有授权数据的挑战。如果这是你所面临的问题，请联系我们。&lt;/p&gt;&lt;section&gt;&lt;span&gt;5&lt;/span&gt;你应该用哪一个?&lt;/section&gt;&lt;p&gt;当与工程师团队交谈时，我的指导意见总是“围绕应用程序构建授权，而不是反过来。”对于简单系统，维护大量额外基础设施代价高昂，最好将数据保存在其所在的位置，并将服务与专用 api 放在一起。某些应用程序可以通过基本用户角色（可使用 GWT）扩展到大规模，在这种情况下，授权网关可能是最佳的。一些拥有各种产品、授权模式和用户类型的公司可能更愿意将其数据集中到专用的授权服务中。&lt;/p&gt;&lt;p&gt;如果你对讨论你的授权系统感兴趣——例如你正在考虑进行一些重构，或者只是对它的工作方式不太满意，请与我们联系。你可以与 Oso 工程师安排 1x1 讨论，或者加入我们的 slack。我们喜欢讨论授权。&lt;/p&gt;&lt;p&gt;如果你曾经对混乱的授权系统感到沮丧，或者和我一样喜欢好的分布式系统问题，欢迎加入我们团队！我们正在招聘，来帮助我们推动进一步的思考。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;原文链接：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.osohq.com/post/microservices-authorization-patterns&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-recommend-type=&quot;list-title&quot; data-recommend-tid=&quot;6&quot; data-mpa-template=&quot;t&quot; data-mid=&quot;&quot; data-from=&quot;yb-recommend&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;往期推荐&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; data-recommend-article-type=&quot;list-title&quot; data-recomment-template-id=&quot;6&quot; data-recommend-article-id=&quot;2247510421_1&quot; data-recommend-article-time=&quot;1641221256&quot; data-recommend-article-cover=&quot;https://mmbiz.qlogo.cn/mmbiz_jpg/eukZ9J6BEiadQiaibIxZqj8Spo4leoBWFyIicFQa9N443ltClhQod0LB6QPE5q3dL7ar2xqeoTQS9bmBhyRPLiae9Pw/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;SpringBoot+ Dubbo + Mybatis + Nacos +Seata整合来实现Dubbo分布式事务，绝了！&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMjU5NjEwMA==&amp;amp;mid=2247510421&amp;amp;idx=1&amp;amp;sn=7f2ce87503531de812c16a5b7f3a6389&amp;amp;chksm=97414d7ea036c468294f673e102f0462d36c1e6672bd0fce219603791581dbabc44284446ac3#rd&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMjU5NjEwMA==&amp;amp;mid=2247510421&amp;amp;idx=1&amp;amp;sn=7f2ce87503531de812c16a5b7f3a6389&amp;amp;chksm=97414d7ea036c468294f673e102f0462d36c1e6672bd0fce219603791581dbabc44284446ac3&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot;&gt;&lt;section data-recommend-title=&quot;t&quot; data-recommend-content=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;SpringBoot+ Dubbo + Mybatis + Nacos +Seata整合来实现Dubbo分布式事务，绝了！&lt;/p&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; data-recommend-article-type=&quot;list-title&quot; data-recomment-template-id=&quot;6&quot; data-recommend-article-id=&quot;2247510400_1&quot; data-recommend-article-time=&quot;1641135457&quot; data-recommend-article-cover=&quot;https://mmbiz.qlogo.cn/mmbiz_jpg/eukZ9J6BEiaevubGOWkFYiaHWqiajpc27JYictWibuQrzMaO2K0o6BDd2V3HHickNvlWYxmksXaofyX08U4PhhibIWaNw/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;最详细的 Intellij IDEA 中使用 Debug 教程&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMjU5NjEwMA==&amp;amp;mid=2247510400&amp;amp;idx=1&amp;amp;sn=a86aac00994b87d2d9db45921df826a1&amp;amp;chksm=97414d6ba036c47de52a4dabd9f7732339def69de7939502f3efb6e869ef131940ab08817f90#rd&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMjU5NjEwMA==&amp;amp;mid=2247510400&amp;amp;idx=1&amp;amp;sn=a86aac00994b87d2d9db45921df826a1&amp;amp;chksm=97414d6ba036c47de52a4dabd9f7732339def69de7939502f3efb6e869ef131940ab08817f90&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot;&gt;&lt;section data-recommend-title=&quot;t&quot; data-recommend-content=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;最详细的 Intellij IDEA 中使用 Debug 教程&lt;/p&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; data-recommend-article-type=&quot;list-title&quot; data-recomment-template-id=&quot;6&quot; data-recommend-article-id=&quot;2247510380_1&quot; data-recommend-article-time=&quot;1641043620&quot; data-recommend-article-cover=&quot;https://mmbiz.qlogo.cn/mmbiz_jpg/eukZ9J6BEiacgs1CqydKhu4uDmiaic1icz9vYPibmeElsxLIQyaicNSdCiaXG7EiaoSN1yYBzzKeIeBzjF6iaCZNslmRRUg/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;SpringBoot 定时任务动态管理通用解决方案&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMjU5NjEwMA==&amp;amp;mid=2247510380&amp;amp;idx=1&amp;amp;sn=df895fe602313be66f16dfb6173a2dbf&amp;amp;chksm=97414d87a036c491ca17ea8ba40ded544400dbc781799d1419368b9e743c68a7d3218db190f2#rd&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMjU5NjEwMA==&amp;amp;mid=2247510380&amp;amp;idx=1&amp;amp;sn=df895fe602313be66f16dfb6173a2dbf&amp;amp;chksm=97414d87a036c491ca17ea8ba40ded544400dbc781799d1419368b9e743c68a7d3218db190f2&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot;&gt;&lt;section data-recommend-title=&quot;t&quot; data-recommend-content=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;SpringBoot 定时任务动态管理通用解决方案&lt;/p&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; data-recommend-article-type=&quot;list-title&quot; data-recomment-template-id=&quot;6&quot; data-recommend-article-id=&quot;2247510280_1&quot; data-recommend-article-time=&quot;1640179620&quot; data-recommend-article-cover=&quot;https://mmbiz.qlogo.cn/mmbiz_jpg/eukZ9J6BEiaevubGOWkFYiaHWqiajpc27JY9lgSj0wVozjvYibsMticxhSbfLibxmWfAgTFRNPtXz1njibnlSic0q1uL6Q/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;Spring Cloud与Dubbo优缺点详解&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMjU5NjEwMA==&amp;amp;mid=2247510280&amp;amp;idx=1&amp;amp;sn=8c0f22191c8803c833cfe24c9b1c9221&amp;amp;chksm=97414de3a036c4f551971b10150ee967fc019504f06088b561e86894c27a69c27aa81be39b5d#rd&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMjU5NjEwMA==&amp;amp;mid=2247510280&amp;amp;idx=1&amp;amp;sn=8c0f22191c8803c833cfe24c9b1c9221&amp;amp;chksm=97414de3a036c4f551971b10150ee967fc019504f06088b561e86894c27a69c27aa81be39b5d&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot;&gt;&lt;section data-recommend-title=&quot;t&quot; data-recommend-content=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;Spring Cloud与Dubbo优缺点详解&lt;/p&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; data-recommend-article-type=&quot;list-title&quot; data-recomment-template-id=&quot;6&quot; data-recommend-article-id=&quot;2247510304_1&quot; data-recommend-article-time=&quot;1640439837&quot; data-recommend-article-cover=&quot;https://mmbiz.qlogo.cn/mmbiz_jpg/eukZ9J6BEiad724QspawbpSEVBcjokzaul5r2asgZgjEiaGZcl0sLGYK5BHokpJRic4ZeUhIsian8aSvCpicYIJbXcA/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;12 个适合做外包项目的开源后台管理系统&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMjU5NjEwMA==&amp;amp;mid=2247510304&amp;amp;idx=1&amp;amp;sn=1839e50c4ba449139b921779baf1fa5e&amp;amp;chksm=97414dcba036c4ddc1be1da28e750afb56d9f2af5a52c8e1f04624f76aad6abcba3f012d5175#rd&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMjU5NjEwMA==&amp;amp;mid=2247510304&amp;amp;idx=1&amp;amp;sn=1839e50c4ba449139b921779baf1fa5e&amp;amp;chksm=97414dcba036c4ddc1be1da28e750afb56d9f2af5a52c8e1f04624f76aad6abcba3f012d5175&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot;&gt;&lt;section data-recommend-title=&quot;t&quot; data-recommend-content=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;12 个适合做外包项目的开源后台管理系统&lt;/p&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; data-recommend-article-type=&quot;list-title&quot; data-recomment-template-id=&quot;6&quot; data-recommend-article-id=&quot;2247510190_1&quot; data-recommend-article-time=&quot;1639837023&quot; data-recommend-article-cover=&quot;https://mmbiz.qlogo.cn/mmbiz_jpg/eukZ9J6BEiadD6YQ4DgZXzCB3gofcDPRZhccmdiaxbQSkUDCTj7Bv31MTXmWsCp027FRdY8XrllWvwQ5ibIcef7CA/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;整理了35个快速开发平台，前后端都有 ，接私活拿来即用，非常方便！&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMjU5NjEwMA==&amp;amp;mid=2247510190&amp;amp;idx=1&amp;amp;sn=d8d2b54fd85952664e9cd9bccd2d0a3b&amp;amp;chksm=97414c45a036c55308b1b883a559a30518da3a6e0eaaf7901bb4e17cefd27e5d8fca18a12a96#rd&quot;&gt;&lt;section data-recommend-title=&quot;t&quot; data-recommend-content=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMjU5NjEwMA==&amp;amp;mid=2247510190&amp;amp;idx=1&amp;amp;sn=d8d2b54fd85952664e9cd9bccd2d0a3b&amp;amp;chksm=97414c45a036c55308b1b883a559a30518da3a6e0eaaf7901bb4e17cefd27e5d8fca18a12a96&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot;&gt;整理了35个快速开发平台，前后端都有 ，接私活拿来即用，非常方便！&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre ng-bind-html=&quot;message.MMActualContent&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3648148148148148&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eukZ9J6BEiacKaQE1gbiaT0Jg9LQkMNm4ITSuEWopyzk7aFfnLIKRsxKf34O4fmAlWhNFnat2nPsOTRaPJyEXj2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>000ef6e4fb309ed33ffbf6789e022d38</guid>
<title>浅谈缓存最终一致性的解决方案</title>
<link>https://toutiao.io/k/mgym1lv</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1575&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/j3gficicyOvasIjZpiaTNIPReJVWEJf7UGpmokI3LL4NbQDb8fO48fYROmYPXUhXFN8IdDqPcI1gA6OfSLsQHxB4w/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作者：clareguo，腾讯 CSIG 后台开发工程师&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;46&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;p&gt;到底是更新缓存还是删除缓存? 到底是先更新数据库，再删除缓存，还是先删除缓存，再更新数据库?&lt;/p&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1 引言&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于互联网业务来说，传统的直接访问数据库方式，主要通过数据分片、一主多从等方式来扛住读写流量，但随着数据量的积累和流量的激增，仅依赖数据库来承接所有流量，不仅成本高、效率低、而且还伴随着稳定性降低的风险。鉴于大部分业务通常是读多写少（读取频率远远高于更新频率），甚至存在读操作数量高出写操作多个数量级的情况。因此，在架构设计中，常采用增加缓存层来提高系统的响应能力，提升数据读写性能、减少数据库访问压力，从而提升业务的稳定性和访问体验。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据 CAP 原理，分布式系统在可用性、一致性和分区容错性上无法兼得，通常由于分区容错无法避免，所以一致性和可用性难以同时成立。对于缓存系统来说，如何保证其数据一致性是一个在应用缓存的同时不得不解决的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;需要明确的是，缓存系统的数据一致性通常包括持久化层和缓存层的一致性、以及多级缓存之间的一致性，这里我们仅讨论前者。持久化层和缓存层的一致性问题也通常被称为双写一致性问题，“双写”意为数据既在数据库中保存一份，也在缓存中保存一份。对于一致性来说，包含强一致性和弱一致性，强一致性保证写入后立即可以读取，弱一致性则不保证立即可以读取写入后的值，而是尽可能的保证在经过一定时间后可以读取到，在弱一致性中应用最为广泛的模型则是最终一致性模型，即保证在一定时间之后写入和读取达到一致的状态。对于应用缓存的大部分场景来说，追求的则是最终一致性，少部分对数据一致性要求极高的场景则会追求强一致性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2 保证最终一致性的策略（ Cache Policy ）&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了达到最终一致性，针对不同的场景，业界逐步形成了下面这几种应用缓存的策略。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.1 Cache-Aside&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Cache-Aside 意为旁路缓存模式，是应用最为广泛的一种缓存策略。下面的图示展示了它的读写流程，来看看它是如何保证最终一致性的。在读请求中，首先请求缓存，若缓存命中（ cache hit ），则直接返回缓存中的数据；若缓存未命中（ cache miss ），则查询数据库并将查询结果更新至缓存，然后返回查询出的数据（ demand-filled look-aside ）。在写请求中，先更新数据库，再删除缓存（write-invalidate）。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5924050632911393&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEy8knbFcMB7NoiajEYjxo04ww5kmKIOyicbnpbMD0kz3N57EzT4H46xkQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1580&quot;/&gt;&lt;/figure&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1.1 为什么删除缓存，而不是更新缓存？&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 Cache-Aside 中，对于读请求的处理比较容易理解，但在写请求中，可能会有读者提出疑问，为什么要删除缓存，而不是更新缓存？站在符合直觉的角度来看，更新缓存是一个容易被理解的方案，但站在性能和安全的角度，更新缓存则可能会导致一些不好的后果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先是性能，当该缓存对应的结果需要消耗大量的计算过程才能得到时，比如需要访问多张数据库表并联合计算，那么在写操作中更新缓存的动作将会是一笔不小的开销。同时，当写操作较多时，可能也会存在刚更新的缓存还没有被读取到，又再次被更新的情况（这常被称为缓存扰动），显然，这样的更新是白白消耗机器性能的，会导致缓存利用率不高。而等到读请求未命中缓存时再去更新，也符合懒加载的思路，需要时再进行计算。删除缓存的操作不仅是幂等的，可以在发生异常时重试，而且写-删除和读-更新在语义上更加对称。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其次是安全，在并发场景下，在写请求中更新缓存可能会引发数据的不一致问题。参考下面的图示，若存在两个来自不同线程的写请求，首先来自线程 1 的写请求更新了数据库（ step 1 ），接着来自线程 2 的写请求再次更新了数据库（ step 3 ），但由于网络延迟等原因，线程 1 可能会晚于线程 2 更新缓存（ step 4 晚于 step 3 ），那么这样便会导致最终写入数据库的结果是来自线程 2 的新值，写入缓存的结果是来自线程 1 的旧值，即缓存落后于数据库，此时再有读请求命中缓存（ step 5 ），读取到的便是旧值。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5852130325814536&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwErd8vgtqGLMcj2zkhqt4sO4mwic32ZU0wrlRP2reBh4K48X5jEVBooEA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1596&quot;/&gt;&lt;figcaption&gt;&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1.2 为什么先更新数据库，而不是先删除缓存？&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，有读者也会对更新数据库和删除缓存的时序产生疑问，那么为什么不先删除缓存，再更新数据库呢？在单线程下，这种方案看似具有一定合理性，这种合理性体现在删除缓存成功，但更新数据库失败的场景下，尽管缓存被删除了，下次读操作时，仍能将正确的数据写回缓存，相对于 Cache-Aside 中更新数据库成功，删除缓存失败的场景来说，先删除缓存的方案似乎更合理一些。那么，先删除缓存有什么问题呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;问题仍然出现在并发场景下，首先来自线程 1 的写请求删除了缓存（ step 1 ），接着来自线程 2 的读请求由于缓存的删除导致缓存未命中，根据 Cache-Aside 模式，线程 2 继而查询数据库（ step 2 ），但由于写请求通常慢于读请求，线程 1 更新数据库的操作可能会晚于线程 2 查询数据库后更新缓存的操作（ step 4 晚于 step 3 ），那么这样便会导致最终写入缓存的结果是来自线程 2 中查询到的旧值，而写入数据库的结果是来自线程 1 的新值，即缓存落后于数据库，此时再有读请求命中缓存（ step 5 ），读取到的便是旧值。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3954659949622166&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEgctQjMRGQglE3wyEmDWxGefpPfdZmcsgz1El5qL5icCdroGYcSTrI5Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1588&quot;/&gt;&lt;figcaption&gt;&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，先删除缓存，由于缓存中数据缺失，加剧数据库的请求压力，可能会增大缓存穿透出现的概率。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1.3 如果选择先删除缓存，再更新数据库，那如何解决一致性问题呢？&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了避免“先删除缓存，再更新数据库”这一方案在读写并发时可能带来的缓存脏数据，业界又提出了延时双删的策略，即在更新数据库之后，延迟一段时间再次删除缓存，为了保证第二次删除缓存的时间点在读请求更新缓存之后，这个延迟时间的经验值通常应稍大于业务中读请求的耗时。延迟的实现可以在代码中 &lt;code&gt;sleep&lt;/code&gt; 或采用延迟队列。显而易见的是，无论这个值如何预估，都很难和读请求的完成时间点准确衔接，这也是延时双删被诟病的主要原因。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5082382762991128&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEtpFBnmv9rhKJULmmAIrGjcqnnXSInT1UMTntXVntpZWPuf8Oaicfb4w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1578&quot;/&gt;&lt;figcaption&gt;&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1.4 那么 Cache-Aside 存在数据不一致的可能吗？&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 Cache-Aside 中，也存在数据不一致的可能性。在下面的读写并发场景下，首先来自线程 1 的读请求在未命中缓存的情况下查询数据库（ step 1 ），接着来自线程 2 的写请求更新数据库（ step 2 ），但由于一些极端原因，线程 1 中读请求的更新缓存操作晚于线程 2 中写请求的删除缓存的操作（ step 4 晚于 step 3 ），那么这样便会导致最终写入缓存中的是来自线程 1 的旧值，而写入数据库中的是来自线程 2 的新值，即缓存落后于数据库，此时再有读请求命中缓存（ step 5 ），读取到的便是旧值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种场景的出现，不仅需要缓存失效且读写并发执行，而且还需要读请求查询数据库的执行早于写请求更新数据库，同时读请求的执行完成晚于写请求。足以见得，这种不一致场景产生的条件非常严格，在实际的生产中出现的可能性较小。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4068010075566751&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEy1XuQ2xxVFFdNZgibhhSJUnR0sViasGl6xzLgNMcP3wxC1bJJ59CZ0icQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1588&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除此之外，在并发环境下，Cache-Aside 中也存在读请求命中缓存的时间点在写请求更新数据库之后，删除缓存之前，这样也会导致读请求查询到的缓存落后于数据库的情况。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.38944723618090454&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEuKSPArRcuQPbIob0MBaBWgKYyrZBZuNUvBR7DYNeNm67EmAbOwsuKA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1592&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然在下一次读请求中，缓存会被更新，但如果业务层面对这种情况的容忍度较低，那么可以采用加锁在写请求中保证“更新数据库&amp;amp;删除缓存”的串行执行为原子性操作（同理也可对读请求中缓存的更新加锁）。加锁势必会导致吞吐量的下降，故采取加锁的方案应该对性能的损耗有所预期。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4292929292929293&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwExt0GUt5zySf0MYCib3Wbg3jibkIwvQNicERf8PKC2wFTJfAtLBjiaODpxg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1584&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6914212548015365&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEicojwkV1Uh0nDTWGFTd3ncLQbibB2eZiccTnm4BOjILRvawDvx4qqhsMw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1562&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2 补偿机制&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在上面提到了，在 Cache-Aside 中可能存在更新数据库成功，但删除缓存失败的场景，如果发生这种情况，那么便会导致缓存中的数据落后于数据库，产生数据的不一致的问题。其实，不仅 Cache-Aside 存在这样的问题，在延时双删等策略中也存在这样的问题。针对可能出现的删除失败问题，目前业界主要有以下几种补偿机制。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.2.1 删除重试机制&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于同步重试删除在性能上会影响吞吐量，所以常通过引入消息队列，将删除失败的缓存对应的 &lt;code&gt;key&lt;/code&gt; 放入消息队列中，在对应的消费者中获取删除失败的 &lt;code&gt;key&lt;/code&gt; ，异步重试删除。这种方法在实现上相对简单，但由于删除失败后的逻辑需要基于业务代码的 trigger 来触发 ，对业务代码具有一定入侵性。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45132743362831856&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEkNJlDa9w1r2icXT7YGQtpuZq66BIDuFaCe79Whl5gDeOu1EyqEibB03A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1582&quot;/&gt;&lt;/figure&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.2.2 基于数据库日志（ MySQL binlog ）增量解析、订阅和消费&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;鉴于上述方案对业务代码具有一定入侵性，所以需要一种更加优雅的解决方案，让缓存删除失败的补偿机制运行在背后，尽量少的耦合于业务代码。一个简单的思路是通过后台任务使用更新时间戳或者版本作为对比获取数据库的增量数据更新至缓存中，这种方式在小规模数据的场景可以起到一定作用，但其扩展性、稳定性都有所欠缺。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个相对成熟的方案是基于 MySQL 数据库增量日志进行解析和消费，这里较为流行的是阿里巴巴开源的作为 MySQL binlog 增量获取和解析的组件 canal （类似的开源组件还有 Maxwell、Databus 等）。canal sever 模拟 MySQL slave 的交互协议，伪装为 MySQL slave ，向 MySQL master 发送 dump 协议，MySQL master 收到 dump 请求，开始推送 binary log 给 slave （即 canal sever ），canal sever 解析 binary log 对象（原始为 byte 流），可由 canal client 拉取进行消费，同时 canal server 也默认支持将变更记录投递到 MQ 系统中，主动推送给其他系统进行消费。在 ack 机制的加持下，不管是推送还是拉取，都可以有效的保证数据按照预期被消费。当前版本的 canal 支持的 MQ 有 kafka 或者 RocketMQ 。另外， canal 依赖 zookeeper 作为分布式协调组件来实现 HA ，canal 的 HA 分为两个部分：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;为了减少对 MySQL dump 的请求压力，不同 canal server 上的 instance 要求同一时间只能有一个处于运行状态，其他的 instance 处于 standby 状态；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;为了保证有序性，对于一个 instance 在同一时间只能由一个 canal client 进行 get/ack 等动作；&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6923076923076923&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEByTHKnOZ2yJDa8ciamnK6GsqkWm8CMcViaPHXdvhtSPV2wunkXcnrP0A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1560&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么，针对缓存的删除操作便可以在 canal client 或 consumer 中编写相关业务代码来完成。这样，结合数据库日志增量解析消费的方案以及 Cache-Aside 模型，在读请求中未命中缓存时更新缓存（通常这里会涉及到复杂的业务逻辑），在写请求更新数据库后删除缓存，并基于日志增量解析来补偿数据库更新时可能的缓存删除失败问题，在绝大多数场景下，可以有效的保证缓存的最终一致性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外需要注意的是，还应该隔离事务与缓存，确保数据库入库后再进行缓存的删除操作。比如考虑到数据库的主从架构，主从同步及读从写主的场景下，可能会造成读取到从库的旧数据后便更新了缓存，导致缓存落后于数据库的问题，这就要求对缓存的删除应该确保在数据库操作完成之后。所以，基于 binlog 增量日志进行数据同步的方案，可以通过选择解析从节点的 binlog，来避免主从同步下删除缓存过早的问题。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.2.3 数据传输服务 DTS&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据传输服务（ Data Transmission Service，简称 DTS）是云服务商提供的一种支持 RDBMS（关系型数据库）、NoSQL、OLAP 等多种数据源之间进行数据交互的数据流服务。DTS 提供了包括数据迁移、数据订阅、数据同步等在内的多种数据传输能力，常用于不停服数据迁移、数据异地灾备、异地多活(单元化)、跨境数据同步、实时数据仓库、查询报表分流、缓存更新、异步消息通知等多种业务应用场景。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相对于上述基于 canal 等开源组件自建系统，DTS 的优势体现在对多种数据源的支持、对多种数据传输方式的支持，避免了部署维护的人力成本。目前，各家云服务商的 DTS 服务已 针对云数据库，云缓存等产品进行了适配，解决了 Binlog 日志回收，主备切换等场景下的订阅高可用问题。在大规模的缓存数据一致性场景下，优先推荐使用 DTS 服务。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3 Read-Through&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Read-Through 意为读穿透模式，它的流程和 Cache-Aside 类似，不同点在于 Read-Through 中多了一个访问控制层，读请求只和该访问控制层进行交互，而背后缓存命中与否的逻辑则由访问控制层与数据源进行交互，业务层的实现会更加简洁，并且对于缓存层及持久化层交互的封装程度更高，更易于移植。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7479224376731302&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEMibwZEPeCZE1icibze89CLf9h8aPkgcJ0NUWlvJjd0IcMa6Yib4ziamibic1w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1444&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.4 Write-Through&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Write-Through 意为直写模式，对于 Write-Through 直写模式来说，它也增加了访问控制层来提供更高程度的封装。不同于 Cache-Aside 的是，Write-Through 直写模式在写请求更新数据库之后，并不会删除缓存，而是更新缓存。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.49111675126903553&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEbcBG5HIc4pohTLg9sMgRNDlAR3xPmYHS2HlMbz3Gv57bTeRJsmicKAA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1576&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种方式的优势在于读请求过程简单，不需要查询数据库更新缓存等操作。但其劣势也非常明显，除了上面我们提到的更新数据库再更新缓存的弊端之外，这种方案还会造成更新效率低，并且两个写操作任何一次写失败都会造成数据不一致。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果要使用这种方案，最好可以将这两个操作作为事务处理，可以同时失败或者同时成功，支持回滚，并且防止并发环境下的不一致。另外，为了防止缓存扰动的频发，也可以给缓存增加 TTL 来缓解。站在可行性的角度，不管是 Write-Through 模式还是 Cache-Aside 模式，理想状况下都可以通过分布式事务保证缓存层数据与持久化层数据的一致性，但在实际项目中，大多都对一致性的要求存在一些宽容度，所以在方案上往往有所折衷。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Write-Through 直写模式适合写操作较多，并且对一致性要求较高的场景，在应用 Write-Through 模式时，也需要通过一定的补偿机制来解决它的问题。首先，在并发环境下，我们前面提到了先更新数据库，再更新缓存会导致缓存和数据库的不一致，那么先更新缓存，再更新数据库呢？这样的操作时序仍然会导致下面这样线程 1 先更新缓存，最后更新数据库的情况，即由于线程 1 和 线程 2 的执行不确定性导致数据库和缓存的不一致。这种由于线程竞争导致的缓存不一致，可以通过分布式锁解决，保证对缓存和数据库的操作仅能由同一个线程完成。对于没有拿到锁的线程，一是通过锁的 &lt;code&gt;timeout&lt;/code&gt; 时间进行控制，二是将请求暂存在消息队列中顺序消费。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.410941475826972&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEB0ibpwSfY0CJJgyibXEVJ6xCKUjvZ72PI39SQWDEUz3bjCYUGrJQhkUg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1572&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在下面这种并发执行场景下，来自线程 1 的写请求更新了数据库，接着来自线程 2 的读请求命中缓存，接着线程 1 才更新缓存，这样便会导致线程 2 读取到的缓存落后于数据库。同理，先更新缓存后更新数据库在写请求和读请求并发时，也会出现类似的问题。面对这种场景，我们也可以加锁解决。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3883984867591425&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEXvn8hXIzibTmpt4R8LEuwMUN0aLDJug0kGtXicPmTgfnNSic7XLbIn5Eg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1586&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另在，在 Write-Through 模式下，不管是先更新缓存还是先更新数据库，都存在更新缓存或者更新数据库失败的情况，上面提到的重试机制和补偿机制在这里也是奏效的。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5 Write-Behind&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Write behind 意为异步回写模式，它也具有类似 Read-Through/Write-Through 的访问控制层，不同的是，Write behind 在处理写请求时，只更新缓存而不更新数据库，对于数据库的更新，则是通过批量异步更新的方式进行的，批量写入的时间点可以选在数据库负载较低的时间进行。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.48984771573604063&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvaulG1WsztCXujT0qDxALxwEfl7FaXmIwmgNPoUOwib2tSWykFoZicIpiaxbHPIpLC51VKyFazLkKEaeQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1576&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 Write-Behind 模式下，写请求延迟较低，减轻了数据库的压力，具有较好的吞吐性。但数据库和缓存的一致性较弱，比如当更新的数据还未被写入数据库时，直接从数据库中查询数据是落后于缓存的。同时，缓存的负载较大，如果缓存宕机会导致数据丢失，所以需要做好缓存的高可用。显然，Write behind 模式下适合大量写操作的场景，常用于电商秒杀场景中库存的扣减。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.6 Write-Around&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果一些非核心业务，对一致性的要求较弱，可以选择在 cache aside 读模式下增加一个缓存过期时间，在写请求中仅仅更新数据库，不做任何删除或更新缓存的操作，这样，缓存仅能通过过期时间失效。这种方案实现简单，但缓存中的数据和数据库数据一致性较差，往往会造成用户的体验较差，应慎重选择。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;总结&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在解决缓存一致性的过程中，有多种途径可以保证缓存的最终一致性，应该根据场景来设计合适的方案，读多写少的场景下，可以选择采用“ Cache-Aside 结合消费数据库日志做补偿”的方案，写多的场景下，可以选择采用“ Write-Through 结合分布式锁”的方案 ，写多的极端场景下，可以选择采用“ Write-Behind ” 的方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;最近其他好文：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5ODYwMjI2MA==&amp;amp;mid=2649766734&amp;amp;idx=1&amp;amp;sn=b23d539c9daedbf8a6ab8993505e3641&amp;amp;chksm=becca83589bb2123c21a187be11e064ba5e5154ceded1eef0b95d3ba3e4f9e8140adadfff0de&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;最近大火的 NFT 数字藏品是什么？&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;最近大火的 NFT 数字藏品是什么？&lt;/a&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5ODYwMjI2MA==&amp;amp;mid=2649766668&amp;amp;idx=1&amp;amp;sn=bc8d55f637fe8b00ce5404cfcfb8b7fc&amp;amp;chksm=becca87789bb216125125fdb6f5d883048a6346937f0c6707ea527df429040b508a759362de9&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;2021 腾讯技术十大热门文章&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;2021 腾讯技术十大热门文章&lt;/a&gt;&lt;strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5ODYwMjI2MA==&amp;amp;mid=2649766668&amp;amp;idx=1&amp;amp;sn=bc8d55f637fe8b00ce5404cfcfb8b7fc&amp;amp;chksm=becca87789bb216125125fdb6f5d883048a6346937f0c6707ea527df429040b508a759362de9&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;2021 腾讯技术十大热门文章&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5ODYwMjI2MA==&amp;amp;mid=2649766638&amp;amp;idx=1&amp;amp;sn=031eaf1fdd40222568eb40a9b6a399fb&amp;amp;chksm=becca99589bb2083ae4a361707339fc343bfe2d604c7cbcb6de582e878bc275849e52d0b9f68&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;服务器开发设计之算法宝典&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;服务器开发设计之算法宝典&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;3.72125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvatkTw3ahJGNlXdrVzdl0yxFvsAzUia48cP7KRgP46ZoZHANttHd1ZXKgWia8wm4TdWcNsrib1oSwaiaMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;800&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;2.587962962962963&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvatPyBdU42Pibe0fLSj0H232CGFzpFGdr8BenFo7oRWoAaecicibla1KEFW6KPrRStATLSwQ1hGJOUeEg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_live_iframe&quot; data-pluginname=&quot;videosnap&quot; data-headimgurl=&quot;https://wx.qlogo.cn/finderhead/I7awtksbibjQe7RZAy84xESOBAfIZ8xQ9ApXt4uTe8po/0&quot; data-username=&quot;v2_060000231003b20faec8c6e08e1ac1d4cf06ea31b07760a16cba92d83444bd9a5d9d55ffaede@finder&quot; data-nickname=&quot;腾讯程序员&quot; data-desc=&quot;将在01月12日 19:30 直播&quot; data-intro=&quot;对谈CoDesign程序媛，听听“文艺女青年”的前端旅行&quot; data-noticeid=&quot;finderlivenotice-v2_060000231003b20faec8c6e08e1ac1d4cf06ea31b07760a16cba92d83444bd9a5d9d55ffaede@finder-1641525666664055-1293066808&quot; data-type=&quot;live&quot;/&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MjM5ODYwMjI2MA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvasvpPfMrktl2xvC9A325p8Qa9dFeEzxZmZ2O1XuFGsVXyQhG9Dia8J8nTXVtzNcHozr0umH3R4iboXg/0?wx_fmt=png&quot; data-nickname=&quot;腾讯技术工程&quot; data-alias=&quot;Tencent_TEG&quot; data-signature=&quot;腾讯技术官方号。腾讯技术创新、前沿领域发布解读平台。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>179b1c35855e61ed68c5286bac5c9f43</guid>
<title>知名开源库惊现666版本！神秘Bug影响超2万个项目，亚马逊云也躺枪</title>
<link>https://toutiao.io/k/ggyi1k2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;

                

                
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>96c79f82affdd8f904a3d3cbdb3485f6</guid>
<title>Flink 大规模作业调度性能优化</title>
<link>https://toutiao.io/k/r8koytk</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p id=&quot;js_tags&quot; class=&quot;article-tag__list single-tag__wrp js_single js_wx_tap_highlight wx_tap_card&quot; data-len=&quot;1&quot; role=&quot;link&quot; aria-labelledby=&quot;js_article-tag-card__left js_a11y_comma js_article-tag-card__right&quot;&gt;
                                            
                                                                                    &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__left&quot; class=&quot;article-tag-card__left&quot;&gt;
                                    &lt;span class=&quot;article-tag-card__title&quot;&gt;收录于话题&lt;/span&gt;
                                    &lt;span class=&quot;article-tag__item-wrp no-active js_tag&quot; data-url=&quot;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU3Mzg4OTMyNQ==&amp;amp;action=getalbum&amp;amp;album_id=1929701066745397252#wechat_redirect&quot; data-tag_id=&quot;&quot; data-album_id=&quot;1929701066745397252&quot; data-tag_source=&quot;4&quot;&gt;
                                        &lt;span class=&quot;article-tag__item&quot;&gt;#资料中心&lt;/span&gt;
                                    &lt;/span&gt;
                                &lt;/span&gt;
                                &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__right&quot; class=&quot;article-tag-card__right&quot;&gt;81个&lt;/span&gt;
                                                                                        &lt;/p&gt;

                
                                
                
                

                
                                                                

                
                                


                
                
                
                
                                                                
                                
                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;本文作者洪志龙（柏星）&amp;amp; 朱翥（长耕），分享了如何在 Flink 1.13 版本和 1.14 版本中对 Flink 调度大规模作业的性能进行了优化。主要内容包括：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;性能测评结果&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;基于拓扑结构的优化&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;优化任务部署&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;针对 Pipelined Region 构建的优化&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Tips：&lt;/strong&gt;点击&lt;/span&gt;&lt;span&gt;&lt;strong&gt;「阅读原&lt;/strong&gt;&lt;strong&gt;文」&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;查看 FFA 2021 视频回放～&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;随着 Flink 流批一体架构不断演进和升级，越来越多的用户开始选择用 Flink 来同时承载实时和离线的业务。&lt;/span&gt;&lt;span&gt;离线业务和实时业务有一定差异性，其中比较关键的一点是 —— 离线作业的规模通常都远远大于实时作业。&lt;/span&gt;&lt;span&gt;超大规模的流批作业对 Flink 的调度性能提出了新的挑战。&lt;/span&gt;&lt;span&gt;在基于 Flink 1.12 版本部署大规模流批作业时，用户可能会遇到以下瓶颈：&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;需要很长时间才能完成作业的调度和部署；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;需要大量内存来存储作业的执行拓扑图以及部署时所需的临时变量，并且在运行过程中会出现频繁的长时间 GC，影响集群稳定性；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;经测试，对于一个并发度为 10k 的 word count 作业，在其部署时 JobManager 需要 30 GiB 内存，并且从提交作业到所有任务节点部署完毕所需的总时间长达 4 分钟。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;此外，对于大规模作业，任务部署的过程可能会长时间阻塞 JobManager 的主线程。当主线程阻塞时，JobManager 无法响应任何来自 TaskManager 的请求。这会使得 TaskManager 心跳超时进而导致作业出错失败。在最坏的情况下，作业从故障恢复 (Failover) 并进行新一轮部署时又会出现心跳超时，从而导致作业一直卡在部署阶段无法正常运行。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;为了优化 Flink 调度大规模作业的性能，我们在 Flink 1.13 版本和 1.14 版本进行了以下优化：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;针对拓扑结构引入分组概念，优化与拓扑相关的计算逻辑，主要包括作业初始化、Task 调度以及故障恢复时计算需要重启的 Task 节点等等。与此同时，该优化降低了执行拓扑占用的内存空间；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;引入缓存机制优化任务部署，优化后部署速度更快且所需内存更少；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;基于逻辑拓扑和执行拓扑的特性进行优化以加快 Pipelined Region 的构建速度，从而降低作业初始化所需的时间。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n25&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;一、性能评测结果&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n25&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;为了评估优化的效果，我们对 Flink 1.12 (优化前) 和 Flink 1.14 (优化后) 进行了对比测试。测试作业包含两个节点，由全连接边相连，并发度均为 10k。为了通过 blob 服务器分发 ShuffleDescriptor，我们将配置项 blob.offload.minsize 的值修改为 100 KiB。该配置项指定了通过 blob 服务器传输数据的最小阈值，大小超过该阈值的数据将会通过 Blob 服务器进行传输。该配置项的默认值为 1 MiB，而测试作业中节点的 ShuffleDescriptor 大小约为 270 KiB。测试结果如表 1 所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;表 1 Flink 1.12 和 1.14 各流程时间对比&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;table interlaced=&quot;enabled&quot;&gt;&lt;tbody&gt;&lt;tr class=&quot;ue-table-interlace-color-single&quot;&gt;&lt;td valign=&quot;top&quot;&gt;&lt;br/&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;1.12&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;1.14&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;时间降低百分比(%)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-double&quot;&gt;&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;span&gt;作业初始化&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;11,431ms&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;627ms&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;94.51%&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-single&quot;&gt;&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;span&gt;任务部署&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;63,118ms&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;17,183ms&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;72.78%&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ue-table-interlace-color-double&quot;&gt;&lt;td valign=&quot;top&quot; colspan=&quot;1&quot; rowspan=&quot;1&quot;&gt;&lt;p&gt;&lt;span&gt;故障恢复时计算重启节点&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; colspan=&quot;1&quot; rowspan=&quot;1&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;37,195ms&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; colspan=&quot;1&quot; rowspan=&quot;1&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;170ms&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td valign=&quot;middle&quot; colspan=&quot;1&quot; rowspan=&quot;1&quot; align=&quot;center&quot;&gt;&lt;p&gt;&lt;span&gt;99.55%&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;除了时间大幅缩短以外，内存占用也明显降低。在 Flink 1.12 版本上运行测试作业时，JobManager 需要 30 GiB 内存才能保证作业稳定运行，而在 Flink 1.14 版本上只需要 2 GiB 即可。与此同时，GC 情况也得以改善。在 1.12 版本上，测试作业在初始化和 Task 部署的过程中都会出现超过 10 秒的长 GC，而在 1.14 版本上均未出现，这意味着心跳超时等问题出现的概率更低，作业运行更为稳定。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在 1.12 版本上，除去申请资源的时间，测试作业需要至少 4 分钟才能部署完成。而作为对比，在 1.14 版本上，除去申请资源的时间，测试作业在 30 秒内即可完成部署并开始运行。整体所需时间降低了 87%。鉴于此，对于需要部署运行大规模作业的用户，建议将 Flink 版本升级至 1.14 以提升作业调度和部署性能。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在接下来的部分中我们将进一步介绍各项优化的细节。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n57&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;二、基于拓扑结构的优化&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n57&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;在 Flink 中，分发模式 (Distribution Pattern) 描述了上游节点与下游节点连接的方式，上游节点计算的结果会按照连边分发到下游节点。目前 Flink 中有两种分发模式：点对点 (Pointwise) 和全连接 (All-to-all)。如图 1 所示，当分发模式为点对点时，遍历所有边的计算复杂度为 O(N)；当分发模式为全连接时，所有下游节点与上游节点都有连边，遍历所有边的计算复杂度为 O(N&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;)，所需时间会随着规模增大而迅速增长。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n60&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;209&quot; data-backw=&quot;572&quot; data-ratio=&quot;0.36436436436436437&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu4DgCnBq3xK78f3CerskWWO6Dh4ZsYwa3FkMKMuGqnStNuQIgNRnWIH66SJ21ibwluah31HnQO0o1Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1998&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n60&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n60&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;图 1 目前 Flink 的两种分发模式&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink 1.12 版本使用执行拓扑边 (ExecutionEdge) 存储任务节点间连接的信息。当分发模式为全连接模式时，节点间一共会有 O(N&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;) 条边相连，当作业规模较大时会占用大量内存。对于两个全连接边相连且并发度为 10k 的节点，其连边数量为 1 亿，总共需要超过 4 GiB 内存来存储这些连边。在生产作业中可能会有多个全连接边相连的节点，这也就意味着随着作业规模的增长，所需内存也会大幅增长。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;从图 1 可以看到，对于全连接边相连的任务节点，所有上游节点所产生的结果分区 (Result Partition) 都是同构的，也就是说这些结果分区所连接的下游任务节点都是完全相同的。全连接边相连的所有下游节点也都是同构的，因为其所消费的上游分区都是相同的。鉴于节点间的 JobEdge 只有一种分发模式，我们可以按照分发模式对上游分区以及下游节点进行分组。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;对于全连接边，由于其所有下游节点都是同构的，我们可以将这些下游节点划分为一组，称为节点组 (ConsumerVertexGroup)，全连接边相连的所有上游分区都与这个组连接。同样，所有同构的上游分区也被划分为同一组，称为分区组 (ConsumedPartitionGroup)，全连接边相连的所有下游节点都与这个组相连。优化方案的基本思路为：将所有消费相同结果分区的下游节点放入同一个节点组中，同时将所有与相同下游节点相连的结果分区放入同一个分区组中，如图 2 所示。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n69&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;194&quot; data-backw=&quot;572&quot; data-ratio=&quot;0.3402340234023402&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu4DgCnBq3xK78f3CerskWWOGyPHpfuibCSbrcaiadc8ydEpeN1IyDvZhYF3qTS6PD3QCibh94tBO20dw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2222&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图 2 两种分发模式下如何对结果分区和任务节点进行分组&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在调度任务节点时，Flink 需要遍历每一个上游分区和下游节点间的所有连边。在优化前，由于连边的总数量为 O(N&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;)，因此将所有边遍历一遍的总时间复杂度为 O(N&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;)。优化后，执行拓扑边被分组的概念所替代。鉴于所有同构的分区都连接到同一个下游节点组，当 Flink 需要遍历所有连边时，只需要将该节点组遍历一遍即可，不需要重复遍历所有节点，这样就使得计算复杂度从 O(N&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;) 降到 O(N)。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;对于点对点的分发模式，上游结果分区与下游节点逐一相连，因此分区组和节点组之间也是点对点相连，分组的数量级和执行拓扑边的数量级是一样的，也就是说，遍历所有连边的计算复杂度依旧是 O(N)。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;对于上文我们提到的 word count 作业，采用上述的分组方式取代执行拓扑边可以将执行拓扑的内存占用从 4 GiB 降至 12 MiB 左右。基于分组的概念，我们对作业初始化、任务调度以及故障恢复时计算需要重启的节点等耗时较长的计算逻辑进行了优化。这些计算逻辑都涉及到对上下游之间所有连边进行遍历的操作。在优化后，其计算复杂度都从 O(N&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;) 降为 O(N)。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n78&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;三、优化任务部署&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n78&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;对于 Flink 1.12 版本，当大规模作业内包含全连接边时，部署所有节点需要花费很长时间。此外，在部署过程中容易出现 TaskManager 心跳超时的情况，进而导致集群不稳定。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;目前任务部署包含以下几个阶段：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;JobManager 在主线程内为每一个 Task 创建任务部署描述符 (TaskDeploymentDescriptor，以下简称 TDD)；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;JobManager 在异步线程内将这些 TDD 进行序列化；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;JobManager 通过 RPC 通信将序列化后的 TDD 发送至 TaskManager；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;TaskManager 基于 TDD 创建任务并执行。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;TDD 包含了 TaskManager 创建任务 (Task) 时所需的所有信息。当任务部署开始时，JobManager 会在主线程内为所有任务节点创建 TDD。在创建过程中 JobManager 无法响应任何其他请求。对于大规模作业，这一过程可能会导致 JobManager 主线程长时间被阻塞，进一步导致心跳超时，从而触发作业故障。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;鉴于任务部署时所有 TDD 都是由 JobManager 负责发送至各 TaskManager，这导致 JobManager 可能会成为性能瓶颈。尤其是对于大规模作业，部署时产生的 TDD 会占用大量内存空间，导致频繁的长时间 GC，进一步加重 JobManager 的负担。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;因此，我们需要缩短创建 TDD 所需的时间，避免心跳超时的发生。此外，如果能够缩减 TDD 的大小，网络传输所需的时间也会缩短，这样可以进一步加快任务部署的速度。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n98&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1 为 ShuffleDescriptor 添加缓存机制&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;ShuffleDescriptor 用于描述任务在运行时需要消费的上游结果分区的所有信息。当作业规模较大时，ShuffleDescriptor 可能是 TDD 中所占空间最大的一部分。对于全连接边相连的节点，当上游节点和下游节点的并发度都是 N 时，每一个下游节点需要消费 N 个上游结果分区，此时 ShuffleDescriptor 的总数量是 N&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;。也就是说，计算所有节点的 ShuffleDescriptor 的时间复杂度为 O(N&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;)。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;然而，对于同构的下游节点来说，他们所消费的上游结果分区是完全一样的，因此部署时所需要的 ShuffleDescriptor 内容也是一样的。鉴于此，在部署时不需要为每一个下游节点重复计算 ShuffleDescriptor，只需要将计算好的 ShuffleDescriptor 放入缓存以供复用即可。这样计算 TDD 的时间复杂度就可以从 O(N&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;) 降至 O(N)。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了缩减 RPC 消息的大小，进而降低网络传输的开销，我们可以对 ShuffleDescriptor 进行压缩。对于上文我们提到的 word count 作业，当节点并发度为 10k 时，每一个下游节点都会有 10k 个 ShuffleDescriptor，在压缩后其序列化值的总大小降低了 72%。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n105&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;3.2 通过 Blob 服务器分发 ShuffleDescriptor&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;Blob (Binary Large Object) 以二进制数据的形式存储大型文件。Flink 通过 blob 服务器在 JobManager 和 TaskManager 之间传输体积较大的文件。当 JobManager 需要将大文件传输至 TaskManager 时，它可以将文件传输至 blob 服务器 (同时会将文件传输至分布式文件系统)，并且获得访问文件所需的 token。当 TaskManager 获取到 token 时，它们会从分布式文件系统 (Distributed File System，DFS) 下载文件。TaskManager 会同时将文件存储到本地 blob 缓存中方便之后重复读取。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在任务部署的过程中，JobManager 负责将 ShuffleDescriptor 通过 RPC 消息分发到对应的 TaskManager 中。在发送完成后，RPC 消息会被垃圾回收器回收处理。但当 JobManager 创建 RPC 消息的速度大于发送的速度时，RPC 消息会逐渐堆积在内存中并且对 GC 造成影响，频繁触发长时间的 GC。这些 GC 会导致 JobManager 停摆，进一步拖慢任务部署的速度。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了解决这个问题，Flink 可以通过 blob 服务器来分发大体积的 ShuffleDescriptor。首先 JobManager 将 ShuffleDescriptor 发送至 blob 服务器，而 blob 服务器会将 ShuffleDescriptor 存储至 DFS 中，TaskManager 在开始处理 TDD 时会从 DFS 下载数据。这样 JobManager 不需要将所有 ShuffleDescriptor 始终存储在内存中直至对应的 RPC 消息发出。经过优化后，在部署大规模作业时长时间 GC 的频率会明显降低。且鉴于 DFS 为 TaskManager 提供了多个分布式节点下载数据，JobManager 网络传输的压力也得以缓解，不再成为瓶颈，这样可以加快任务部署的速度。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n112&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;295&quot; data-backw=&quot;572&quot; data-ratio=&quot;0.5159763313609468&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu4DgCnBq3xK78f3CerskWWObsfqicRcLf7Ac0mmyqJ7sT5rb55pOhBRTfyqJnKJwtgCF6qTXZB6XYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1690&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图 3 JobManager 将 ShuffleDescriptor 分发至 TaskManager&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了避免缓存过多导致本地磁盘空间不足，当 ShuffleDescriptor 所对应的结果分区被释放时，在 blob 服务器上存储的对应缓存会被清理。此外我们为 TaskManager 上 ShuffleDescriptor 的缓存添加了总大小的限制。当缓存超过一定大小时，缓存会按照最近最少使用 (LRU) 的顺序移除。这样可以保证本地磁盘不会被缓存占满，特别是对于 session 模式运行的集群。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n117&quot; mdtype=&quot;heading&quot;&gt;四、针对 Pipelined Region 构建的优化&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;目前 Flink 中节点间有两种数据交换类型：pipelined 和 blocking。对于 blocking 的数据交换方式，结果分区会在上游全部计算完成后再交由下游进行消费，数据会持久化到本地，支持多次消费。对于 pipelined 数据交换，上游结果分区的产出和下游任务节点的消费是同时进行的，所有数据不会被持久化且只能读取一次。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;鉴于 pipelined 的数据流产出和消费同时发生，Flink 需要保证 pipelined 边相连的上下游节点同时运行。由 pipelined 边相连的节点构成了一个 region，被称为 Pipelined Region (以下简称 region)。在 Flink 中，region 是任务调度和 Failover 的基本单位。在调度的过程中，同一 region 内的所有 Task 节点都会被同时调度，而整个拓扑中所有 region 会按照拓扑顺序逐一进行调度。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;目前在 Flink 的调度层面有两种 region：逻辑层面的 Logical Pipelined Region 以及执行调度层面的 Scheduling Pipelined Region。逻辑 region 由逻辑拓扑 (JobGraph) 中的节点 JobVertex 构成，而执行 region 则由执行拓扑 (ExecutionGraph) 中的节点 ExecutionVertex 构成。类似于 ExecutionVertex 基于 JobVertex 计算产生，执行 region 是由逻辑 region 计算得到的，如图 4 所示。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n124&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;218&quot; data-backw=&quot;572&quot; data-ratio=&quot;0.38060309698451505&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu4DgCnBq3xK78f3CerskWWOCtmibl3wW9gPtlJO61YlDPQD3S0NiaMHchK3sGhp7yUQF9rg9781wVaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2454&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图 4 逻辑 region 以及执行 region&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在构建 region 的过程中会遇到一个问题：region 之间可能存在环形依赖。对于当前 region，当且仅当其所消费的上游 region 都产出全部数据后才能进行调度。如果两个&lt;span&gt; &lt;/span&gt;&lt;span&gt;region&lt;/span&gt;&lt;span&gt; &lt;/span&gt;之间存在环形依赖，那么就会出现调度死锁：两个&lt;span&gt; &lt;/span&gt;&lt;span&gt;region&lt;/span&gt;&lt;span&gt; &lt;/span&gt;都需要等对方完成才能调度，最终两个&lt;span&gt; &lt;/span&gt;&lt;span&gt;region&lt;/span&gt;&lt;span&gt; &lt;/span&gt;都无法被调度起来。因此，Flink 通过 Tarjan 强连通分量算法来发现环形依赖，并将具有环形依赖的&lt;span&gt; &lt;/span&gt;&lt;span&gt;region&lt;/span&gt;&lt;span&gt; &lt;/span&gt;合并成一个&lt;span&gt; &lt;/span&gt;&lt;span&gt;region&lt;/span&gt;，这样就能解决调度死锁的问题。Tarjan 强连通分量算法需要遍历拓扑内的所有边，而对于全连接的分发模式来说，其边的数量为 O(N&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;)，因此算法整体的计算复杂度为 O(N&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;)，随着规模变大会显著增长，从而影响大规模作业初始化的时间。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p cid=&quot;n128&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;230&quot; data-backw=&quot;572&quot; data-ratio=&quot;0.40285714285714286&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu4DgCnBq3xK78f3CerskWWOWuPK2zAXWB0ktc8X5cGia6JlUDyEx6mrECCNw20pB6ciaxjAKxbAd4Bw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2100&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图 5 具有调度死锁的拓扑&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了加快 region 的构建速度，我们可以基于逻辑拓扑和执行拓扑之间的关联进行优化。鉴于一个执行 region 只能由一个逻辑 region 中的节点派生，不会出现跨&lt;span&gt; &lt;/span&gt;&lt;span&gt;region&lt;/span&gt;&lt;span&gt; &lt;/span&gt;的情况，Flink 在初始化作业时只需要遍历所有逻辑 region 并逐一转换成执行 region 即可。转换的方式跟分发模式相关。如果逻辑 region 内的节点间有任何全连接边，则整个逻辑 region 可以直接转换成一个执行 region。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n133&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;569&quot; data-backw=&quot;572&quot; data-ratio=&quot;0.9947916666666666&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu4DgCnBq3xK78f3CerskWWOgoM4lMmQqNogRj6FudXia6soPiaS7fUa13ficujUljMulVtBE3RPPNjgQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图 6 如何将逻辑 region 转换成执行 region&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果全连接边采用的是 pipelined 数据交换，所有与之相连的上下游节点都必须同时运行，也就是说全连接边所连接的所有&lt;span&gt; &lt;/span&gt;&lt;span&gt;region&lt;/span&gt;&lt;span&gt; &lt;/span&gt;都要合并成一个&lt;span&gt; &lt;/span&gt;&lt;span&gt;region&lt;/span&gt;。如果全连接边采用的是 blocking 数据交换，则会引入环形依赖，如图 5 所示。在这种情况下所有与之相连的&lt;span&gt; &lt;/span&gt;&lt;span&gt;region&lt;/span&gt;&lt;span&gt; &lt;/span&gt;都必须合并以避免调度死锁，如图 6 所示。鉴于只要有全连接边就直接生成一整个执行 region，在这种情况下不需要用 Tarjan 算法，整体计算复杂度只需要 O(N) 即可。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果在逻辑 region 内，所有节点间都只有点对点的分发模式，那么 Flink 依旧直接用 Tarjan 算法来检测环形依赖，鉴于点对点的分发模式其边数为 O(N)，算法的时间复杂度也只有 O(N)。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在优化后，将逻辑 region 转换成执行 region 的整体计算复杂度从 O(N&lt;span&gt;&lt;sup&gt;&lt;span&gt;2&lt;/span&gt;&lt;/sup&gt;&lt;/span&gt;) 降为 O(N)。经测试，对于上文提到的 word count 作业，当两个节点间的连边为全连接边且数据交换方式为 blocking 时，构建 region 的总时间降低了 99%，从 8,257ms 降至 120ms。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;hr/&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;FFA 2021 视频回放 &amp;amp; 演讲 PDF 获取&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关注&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Apache Flink&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;，回复：FFA2021&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU3Mzg4OTMyNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6FJHxaI14AsXuzeg4SybT0hiaCSohrIY75oiaOMzhQU7RouiafjNa76k2CtD6xxB2JqnawqFqV3zg3A/0?wx_fmt=png&quot; data-nickname=&quot;Apache Flink&quot; data-alias=&quot;apacheflinkcc&quot; data-signature=&quot;Flink 中文社区官微，Flink PMC 维护&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;更多 Flink 相关技术问题，可扫码加入社区钉钉交流群～&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100010716&quot; data-ratio=&quot;1.2078189300411524&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6PUTQaA1BP3Fb8uViccQpspmTibIYEfM7Wv6VACia9CDQfcN8huMVCafZ5s36wThUmbYRTOzMu4hd8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;972&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt; &lt;img class=&quot;__bg_gif rich_pages wxw-img&quot; data-fileid=&quot;100010714&quot; data-ratio=&quot;1&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/Z6bicxIx5naLWBBEcl44aIic1Mthe1nZiaramW5s4e8WwyCYYbTzu6uPBpgI6sxNXNymEnOYKpJpcrItUia7lS64mA/640?wx_fmt=gif&quot;/&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;戳我，查看 FFA 2021 视频回放～&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>52ddaebfde3a67fd831c453a509f048f</guid>
<title>Web3.0是什么，为什么MetaVerse这么火？2022安全方向展望；腾讯开源的代码综合分析跟踪系统</title>
<link>https://toutiao.io/k/dwx3rx2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                              &lt;strong class=&quot;profile_nickname&quot;&gt;开发者头条&lt;/strong&gt;
                              &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                              &lt;p class=&quot;profile_meta&quot;&gt;
                              &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                              &lt;span class=&quot;profile_meta_value&quot;&gt;kaifazhetoutiao&lt;/span&gt;
                              &lt;/p&gt;

                              &lt;p class=&quot;profile_meta&quot;&gt;
                              &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                              &lt;span class=&quot;profile_meta_value&quot;&gt;程序员分享平台 | 官方应用下载地址：http://toutiao.io/download&lt;/span&gt;
                              &lt;/p&gt;
                              
                          &lt;/div&gt;
                          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>