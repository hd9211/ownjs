<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>73284fc8941ed16fcde4a5a0ec7a0586</guid>
<title>跟 Kafka 学技术系列之时间轮</title>
<link>https://toutiao.io/k/77iozz6</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;src-views-article-detail-main-module__content--2qOBd markdown-body&quot;&gt;&lt;h1&gt;写在前面&lt;/h1&gt;
&lt;p&gt;kafka是一个分布式消息中间件，其高可用高吞吐的特点是大数据领域首选的消息中间件，Kafka是分布式消息队列的顺序读写文件分段组织串联起来思想的鼻祖，包括RocketMq这些消息队列都是借鉴了Kafka早期的架构和设计思路改造而来，所以在架构设计层面，Kafka有非常多值得借鉴的地方。本文是作者介绍Kafka优秀架构设计文章中的一篇，文中的代码和流程图均是base on 0.10.2.0版本。&lt;/p&gt;
&lt;h1&gt;引出环形队列和延迟队列&lt;/h1&gt;
&lt;p&gt;从2个面试题说起，第1个问题，如果一台机器上有10w个定时任务，如何做到高效触发？&lt;/p&gt;
&lt;p&gt;具体场景是：&lt;/p&gt;
&lt;p&gt;有一个APP实时消息通道系统，对每个用户会维护一个APP到服务器的TCP连接，用来实时收发消息，对这个TCP连接，有这样一个需求：“如果连续30s没有请求包（例如登录，消息，keepalive包），服务端就要将这个用户的状态置为离线”。&lt;/p&gt;
&lt;p&gt;其中，单机TCP同时在线量约在10w级别，keepalive请求包较分散大概30s一次，吞吐量约在3000qps。&lt;/p&gt;
&lt;p&gt;怎么做？&lt;/p&gt;
&lt;p&gt;常用方案使用time定时任务，每秒扫描一次所有连接的集合Map&amp;lt;uid, last_packet_time&amp;gt;，把连接时间（每次有新的请求更新对应连接的连接时间）比当前时间的差值大30s的连接找出来处理。&lt;/p&gt;
&lt;p&gt;另一种方案，使用环形队列法：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200308202309477.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1poaVp1aUNodW5GZW5n,size_16,color_FFFFFF,t_70&quot; alt=&quot;小桔车服 &amp;gt; 跟Kafka学技术-时间轮 &amp;gt; image2020-1-17_16-20-37.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;三个重要的数据结构：&lt;/p&gt;
&lt;p&gt;1）30s超时，就创建一个index从0到30的环形队列（本质是个数组）&lt;/p&gt;
&lt;p&gt;2）环上每一个slot是一个Set&amp;lt;uid&amp;gt;，任务集合&lt;/p&gt;
&lt;p&gt;3）同时还有一个Map&amp;lt;uid, index&amp;gt;，记录uid落在环上的哪个slot里&lt;/p&gt;
&lt;p&gt;这样当有某用户uid有请求包到达时：&lt;/p&gt;
&lt;p&gt;1）从Map结构中，查找出这个uid存储在哪一个slot里&lt;/p&gt;
&lt;p&gt;2）从这个slot的Set结构中，删除这个uid&lt;/p&gt;
&lt;p&gt;3）将uid重新加入到新的slot中，具体是哪一个slot呢 =&amp;gt; Current Index指针所指向的上一个slot，因为这个slot，会被timer在30s之后扫描到&lt;/p&gt;
&lt;p&gt;4）更新Map，这个uid对应slot的index值&lt;/p&gt;
&lt;p&gt;哪些元素会被超时掉呢？&lt;/p&gt;
&lt;p&gt;Current Index每秒种移动一个slot，这个slot对应的Set&amp;lt;uid&amp;gt;中所有uid都应该被集体超时！如果最近30s有请求包来到，一定被放到Current Index的前一个slot了，Current Index所在的slot对应Set中所有元素，都是最近30s没有请求包来到的。&lt;/p&gt;
&lt;p&gt;所以，当没有超时时，Current Index扫到的每一个slot的Set中应该都没有元素。&lt;/p&gt;
&lt;p&gt;两种方案对比：&lt;/p&gt;
&lt;p&gt;方案一每次都要轮询所有数据，而方案二使用环形队列只需要轮询这一刻需要过期的数据，如果没有数据过期则没有数据要处理，并且是批量超时，并且由于是环形结构更加节约空间，这很适合高性能场景。&lt;/p&gt;
&lt;p&gt;第二个问题：在开发过程中有延迟一定时间的任务要执行，怎么做？&lt;/p&gt;
&lt;p&gt;如果不重复造轮子的话，我们的选择当然是延迟队列或者Timer。&lt;/p&gt;
&lt;p&gt;延迟队列和在Timer中增 加延时任务采用数组表示的最小堆的数据结构实现，每次放入新元素和移除队首元素时间复杂度为O(nlog(n))。&lt;/p&gt;
&lt;h1&gt;时间轮&lt;/h1&gt;
&lt;p&gt;方案二所采用的环形队列，就是时间轮的底层数据结构，它能够让需要处理的数据（任务的抽象）集中，在Kafka中存在大量的延迟操作，比如延迟生产、延迟拉取以及延迟删除等。Kafka并没有使用JDK自带的Timer或者DelayQueue来实现延迟的功能，而是基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）。JDK的Timer和DelayQueue插入和删除操作的平均时间复杂度为O(nlog(n))，并不能满足Kafka的高性能要求，而基于时间轮可以将插入和删除操作的时间复杂度都降为O(1)。时间轮的应用并非Kafka独有，其应用场景还有很多，在Netty、Akka、Quartz、Zookeeper等组件中都存在时间轮的踪影。&lt;/p&gt;
&lt;h2&gt;时间轮的数据结构&lt;/h2&gt;
&lt;p&gt;参考下图，Kafka中的时间轮（TimingWheel）是一个存储定时任务的环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表（TimerTaskList）。TimerTaskList是一个环形的双向链表，链表中的每一项表示的都是定时任务项（TimerTaskEntry），其中封装了真正的定时任务TimerTask。在Kafka源码中对这个TimeTaskList是用一个名称为buckets的数组表示的，所以后面介绍中可能TimerTaskList也会被称为bucket。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200308202645122.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1poaVp1aUNodW5GZW5n,size_16,color_FFFFFF,t_70&quot; alt=&quot;时间轮组成&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;时间轮相关名词解释&lt;/h2&gt;
&lt;p&gt;tickMs：时间轮由多个时间格组成，每个时间格就是tickMs，它代表当前时间轮的基本时间跨度。&lt;/p&gt;
&lt;p&gt;wheelSize：代表每一层时间轮的格数&lt;/p&gt;
&lt;p&gt;interval：当前时间轮的总体时间跨度，interval=tickMs × wheelSize&lt;/p&gt;
&lt;p&gt;startMs：构造当层时间轮时候的当前时间，第一层的时间轮的startMs是TimeUnit.NANOSECONDS.toMillis(nanoseconds()),上层时间轮的startMs为下层时间轮的currentTime。&lt;/p&gt;
&lt;p&gt;currentTime：表示时间轮当前所处的时间，currentTime是tickMs的整数倍（通过currentTime=startMs - (startMs % tickMs来保正currentTime一定是tickMs的整数倍），这个运算类比钟表中分钟里65秒分针指针指向的还是1分钟）。currentTime可以将整个时间轮划分为到期部分和未到期部分，currentTime当前指向的时间格也属于到期部分，表示刚好到期，需要处理此时间格所对应的TimerTaskList的所有任务。&lt;/p&gt;
&lt;h2&gt;时间轮中的任务存放&lt;/h2&gt;
&lt;p&gt;若时间轮的tickMs=1ms，wheelSize=20，那么可以计算得出interval为20ms。初始情况下表盘指针currentTime指向时间格0，此时有一个定时为2ms的任务插入进来会存放到时间格为2的TimerTaskList中。随着时间的不断推移，指针currentTime不断向前推进，过了2ms之后，当到达时间格2时，就需要将时间格2所对应的TimeTaskList中的任务做相应的到期操作。此时若又有一个定时为8ms的任务插入进来，则会存放到时间格10中，currentTime再过8ms后会指向时间格10。如果同时有一个定时为19ms的任务插入进来怎么办？新来的TimerTaskEntry会复用原来的TimerTaskList，所以它会插入到原本已经到期的时间格1中。总之，整个时间轮的总体跨度是不变的，随着指针currentTime的不断推进，当前时间轮所能处理的时间段也在不断后移，总体时间范围在currentTime和currentTime+interval之间。&lt;/p&gt;
&lt;h2&gt;时间轮的升降级&lt;/h2&gt;
&lt;p&gt;如果此时有个定时为350ms的任务该如何处理？直接扩充wheelSize的大小么？Kafka中不乏几万甚至几十万毫秒的定时任务，这个wheelSize的扩充没有底线，就算将所有的定时任务的到期时间都设定一个上限，比如100万毫秒，那么这个wheelSize为100万毫秒的时间轮不仅占用很大的内存空间，而且效率也会拉低。Kafka为此引入了层级时间轮的概念，当任务的到期时间超过了当前时间轮所表示的时间范围时，就会尝试添加到上层时间轮中&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200308202605415.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1poaVp1aUNodW5GZW5n,size_16,color_FFFFFF,t_70&quot; alt=&quot;时间轮升降级&quot;/&gt;&lt;/p&gt;
&lt;p&gt;参考上图，复用之前的案例，第一层的时间轮tickMs=1ms, wheelSize=20, interval=20ms。第二层的时间轮的tickMs为第一层时间轮的interval，即为20ms。每一层时间轮的wheelSize是固定的，都是20，那么第二层的时间轮的总体时间跨度interval为400ms。以此类推，这个400ms也是第三层的tickMs的大小，第三层的时间轮的总体时间跨度为8000ms。&lt;br/&gt;
刚才提到的350ms的任务，不会插入到第一层时间轮，会插入到interval=20*20的第二层时间轮中，具体插入到时间轮的哪个bucket呢？先用350/tickMs(20)=virtualId(17)，然后virtualId(17) %wheelSize (20) = 17，所以350会放在第17个bucket。如果此时有一个450ms后执行的任务，那么会放在第三层时间轮中，按照刚才的计算公式，会放在第0个bucket。第0个bucket里会包含&lt;/p&gt;
&lt;p&gt;[400,800)ms的任务。随着时间流逝，当时间过去了400ms，那么450ms后就要执行的任务还剩下50ms的时间才能执行，此时有一个时间轮降级的操作，将50ms任务重新提交到层级时间轮中，那么此时50ms的任务根据公式会放入第二个时间轮的第2个bucket中，此bucket的时间范围为[40,60)ms，然后再经过40ms，这个50ms的任务又会被监控到，此时距离任务执行还有10ms，同样将10ms的任务提交到层级时间轮，此时会加入到第一层时间轮的第10个bucket，所以再经过10ms后，此任务到期，最终执行。&lt;/p&gt;
&lt;p&gt;整个时间轮的升级降级操作是不是很类似于我们的时钟？ 第一层时间轮tickMs=1s, wheelSize=60，interval=1min，此为秒钟；第二层tickMs=1min，wheelSize=60，interval=1hour，此为分钟；第三层tickMs=1hour，wheelSize为12，interval为12hours，此为时钟。而钟表的指针就对应程序中的currentTime，这个后面分析代码时候会讲到（对这个的理解也是时间轮理解的重点和难点）。&lt;/p&gt;
&lt;p&gt;Kafka中任务添加和驱动时间轮滚动的核心流程：&lt;br/&gt;
&lt;img src=&quot;https://img-blog.csdnimg.cn/20200308202809831.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1poaVp1aUNodW5GZW5n,size_16,color_FFFFFF,t_70&quot; alt=&quot;任务添加和驱动时间轮滚动核心流程图&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;重点代码介绍&lt;/h2&gt;
&lt;p&gt;这是往SystenTimer中添加一个任务&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;&lt;span class=&quot;hljs-comment&quot;&gt;//在Systemtimer中添加一个任务，任务被包装为一个TimerTaskEntry&lt;/span&gt;
&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; def &lt;span class=&quot;hljs-title&quot;&gt;addTimerTaskEntry&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(timerTaskEntry: TimerTaskEntry)&lt;/span&gt;: Unit &lt;/span&gt;= {
&lt;span class=&quot;hljs-comment&quot;&gt;//先判断是否可以添加进时间轮中，如果不可以添加进去代表任务已经过期或者任务被取消，注意这里的timingWheel持有上一层时间轮的引用，所以可能存在递归调用&lt;/span&gt;
  &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (!timingWheel.add(timerTaskEntry)) {
    &lt;span class=&quot;hljs-comment&quot;&gt;// Already expired or cancelled&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (!timerTaskEntry.cancelled)
     &lt;span class=&quot;hljs-comment&quot;&gt;//过期任务直接线程池异步执行掉&lt;/span&gt;
      taskExecutor.submit(timerTaskEntry.timerTask)
  }
}
&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;p&gt;timingWheel添加任务，递归添加直到添加该任务进合适的时间轮的bucket中&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(timerTaskEntry: TimerTaskEntry)&lt;/span&gt;: Boolean &lt;/span&gt;= {
  val expiration = timerTaskEntry.expirationMs
  &lt;span class=&quot;hljs-comment&quot;&gt;//任务取消&lt;/span&gt;
  &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (timerTaskEntry.cancelled) {
    &lt;span class=&quot;hljs-comment&quot;&gt;// Cancelled&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;false&lt;/span&gt;
  } &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (expiration &amp;lt; currentTime + tickMs) {
    &lt;span class=&quot;hljs-comment&quot;&gt;// 任务过期后会被执行&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;false&lt;/span&gt;
  } &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (expiration &amp;lt; currentTime + interval) {&lt;span class=&quot;hljs-comment&quot;&gt;//任务过期时间比当前时间轮时间加周期小说明任务过期时间在本时间轮周期内&lt;/span&gt;
    val virtualId = expiration / tickMs
    &lt;span class=&quot;hljs-comment&quot;&gt;//找到任务对应本时间轮的bucket&lt;/span&gt;
    val bucket = buckets((virtualId % wheelSize.toLong).toInt)
    bucket.add(timerTaskEntry)
    &lt;span class=&quot;hljs-comment&quot;&gt;// Set the bucket expiration time&lt;/span&gt;
   &lt;span class=&quot;hljs-comment&quot;&gt;//只有本bucket内的任务都过期后才会bucket.setExpiration返回true此时将bucket放入延迟队列&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (bucket.setExpiration(virtualId * tickMs)) {
     &lt;span class=&quot;hljs-comment&quot;&gt;//bucket是一个TimerTaskList，它实现了java.util.concurrent.Delayed接口，里面是一个多任务组成的链表，图2有说明&lt;/span&gt;
      queue.offer(bucket)
    }
    &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;
  } &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {
    &lt;span class=&quot;hljs-comment&quot;&gt;// Out of the interval. Put it into the parent timer&lt;/span&gt;
    &lt;span class=&quot;hljs-comment&quot;&gt;//任务的过期时间不在本时间轮周期内说明需要升级时间轮，如果不存在则构造上一层时间轮，继续用上一层时间轮添加任务&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (overflowWheel == &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) addOverflowWheel()
    overflowWheel.add(timerTaskEntry)
  }
}

&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;p&gt;在本层级时间轮里添加上一层时间轮里的过程，注意的是在下一层时间轮的interval为上一层时间轮的tickMs&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt;[&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;] &lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;addOverflowWheel&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt;: Unit &lt;/span&gt;= {
  &lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {
    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (overflowWheel == &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {
      overflowWheel = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; TimingWheel(
        tickMs = interval,
        wheelSize = wheelSize,
        startMs = currentTime,
        taskCounter = taskCounter,
        queue
      )
    }
  }
}
&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;p&gt;驱动时间轮滚动过程：&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;&lt;span class=&quot;hljs-comment&quot;&gt;//注意这里会存在一个递归，一直驱动时间轮的指针滚动直到时间不足于驱动上层的时间轮滚动。&lt;/span&gt;
&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;advanceClock&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(timeMs: Long)&lt;/span&gt;: Unit &lt;/span&gt;= {
  &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (timeMs &amp;gt;= currentTime + tickMs) {
   &lt;span class=&quot;hljs-comment&quot;&gt;//把当前时间打平为时间轮tickMs的整数倍&lt;/span&gt;
    currentTime = timeMs - (timeMs % tickMs)
    &lt;span class=&quot;hljs-comment&quot;&gt;// Try to advance the clock of the overflow wheel if present&lt;/span&gt;
    &lt;span class=&quot;hljs-comment&quot;&gt;//驱动上层时间轮，这里的传给上层的currentTime时间是本层时间轮打平过的，但是在上层时间轮还是会继续打平&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (overflowWheel != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) overflowWheel.advanceClock(currentTime)
  }
}
&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;p&gt;这里是驱动源代码：&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;&lt;span class=&quot;hljs-comment&quot;&gt;//循环bucket里面的任务列表，一个个重新添加进时间轮，对符合条件的时间轮进行升降级或者执行任务&lt;/span&gt;
&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt;[&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;] val reinsert = (timerTaskEntry: TimerTaskEntry) =&amp;gt; addTimerTaskEntry(timerTaskEntry)
 
&lt;span class=&quot;hljs-comment&quot;&gt;/*
 * Advances the clock if there is an expired bucket. If there isn&#x27;t any expired bucket when called,
 * waits up to timeoutMs before giving up.
 */&lt;/span&gt;
&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;advanceClock&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(timeoutMs: Long)&lt;/span&gt;: Boolean &lt;/span&gt;= {
  &lt;span class=&quot;hljs-keyword&quot;&gt;var&lt;/span&gt; bucket = delayQueue.poll(timeoutMs, TimeUnit.MILLISECONDS)
  &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (bucket != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {
    writeLock.lock()
    &lt;span class=&quot;hljs-keyword&quot;&gt;try&lt;/span&gt; {
      &lt;span class=&quot;hljs-keyword&quot;&gt;while&lt;/span&gt; (bucket != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {
        &lt;span class=&quot;hljs-comment&quot;&gt;//驱动时间轮&lt;/span&gt;
        timingWheel.advanceClock(bucket.getExpiration())
       &lt;span class=&quot;hljs-comment&quot;&gt;//循环buckek也就是任务列表，任务列表一个个继续添加进时间轮以此来升级或者降级时间轮，把过期任务找出来执行&lt;/span&gt;
        bucket.flush(reinsert)
       &lt;span class=&quot;hljs-comment&quot;&gt;//循环&lt;/span&gt;
        &lt;span class=&quot;hljs-comment&quot;&gt;//这里就是从延迟队列取出bucket，bucket是有延迟时间的，取出代表该bucket过期，我们通过bucket能取到bucket包含的任务列表&lt;/span&gt;
        bucket = delayQueue.poll()
      }
    } &lt;span class=&quot;hljs-keyword&quot;&gt;finally&lt;/span&gt; {
      writeLock.unlock()
    }
    &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;
  } &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {
    &lt;span class=&quot;hljs-keyword&quot;&gt;false&lt;/span&gt;
  }
}
&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;h1&gt;总结&lt;/h1&gt;
&lt;p&gt;kafka的延迟队列使用时间轮实现，能够支持大量任务的高效触发，但是在kafka延迟队列实现方案里还是看到了delayQueue的影子，使用delayQueue是对时间轮里面的bucket放入延迟队列，以此来推动时间轮滚动，但是基于将插入和删除操作则放入时间轮中，将这些操作的时间复杂度都降为O(1)，提升效率。Kafka对性能的极致追求让它把最合适的组件放在最适合的位置。&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>35b847572daa0a8491692d02ce6fff69</guid>
<title>[推荐] 面试题：MySQL 一棵 B+ 树能存多少条数据？</title>
<link>https://toutiao.io/k/85kvlje</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;大家好，我是Tom哥~&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;今日寄语：充满活力的新人，能让身边的人都重回初心，真是不可思议。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;my&lt;/span&gt;&lt;span&gt;sql 的InnoDB存储引擎 一棵B+树可以存放多少行数据?&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.41114982578397213&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzpVLicRx4bhoYFC2IyEJGQichDkNPaf1ubltvu1LibkZTwU9dP5pyVJejA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;574&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;（答案在文章中！！）&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;要搞清楚这个问题，首先要从InnoDB索引数据结构、数据组织方式说起。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们都知道计算机有五大组成部分：控制器，运算器，存储器，输入设备，输出设备。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;其中很重要的，也跟今天这个题目有关系的是存储器。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们知道万事万物都有自己的单元体系，若干个小单体组成一个个大的个体。就像拼乐高一样，可以自由组合。所以说，如果能熟悉最小单元，就意味着我们抓住了事物的本事，再复杂的问题也会迎刃而解。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;存储单元&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;存储器范围比较大，但是数据具体怎么存储，有自己的最小存储单元。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1、数据持久化存储磁盘里，磁盘的最小单元是扇区，&lt;/span&gt;&lt;code&gt;&lt;span&gt;一个扇区的大小是 512个字节&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2、文件系统的最小单元是块，&lt;/span&gt;&lt;code&gt;&lt;span&gt;一个块的大小是 4K&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3、InnoDB存储引擎，有自己的最小单元，称之为页，&lt;/span&gt;&lt;code&gt;&lt;span&gt;一个页的大小是16K&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;扇区、块、页这三者的存储关系？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4234375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzlYj9YicSEnH5fHR3M2vhZXRAx5ziaicicGYF8ticfyhddjfoMDSsia5F2kzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;InnoDB引擎&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果mysql部署在本地，通过命令行方式连接mysql，默认的端口 &lt;/span&gt;&lt;code&gt;&lt;span&gt;3306&lt;/span&gt;&lt;/code&gt;&lt;span&gt; ，然后输入密码即可进入&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;mysql -u root -p&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;查看InnoDB的页大小&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;show variables like &lt;span&gt;&#x27;innodb_page_size&#x27;&lt;/span&gt;;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.3391304347826087&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzEFG2ibmpdO3d6tPLUeKoXj30aAaJKib31DbJrsucRC8RGAffyxIcNO6w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;690&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;mysql数据库中，table表中的记录都是存储在页中，那么一页可以存多少行数据？假如一行数据的大小约为1K字节，那么按 &lt;/span&gt;&lt;code&gt;&lt;span&gt;16K / 1K = 16&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，可以计算出一页大约能存放16条数据。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;mysql 的最小存储单元叫做“页”，这么多的页是如何构建一个庞大的数据组织，我们又如何知道数据存储在哪一个页中？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果逐条遍历，性能肯定很差。为了提升查找速度，我们引入了&lt;/span&gt;&lt;code&gt;&lt;span&gt;B+树&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，先来看下&lt;/span&gt;&lt;code&gt;&lt;span&gt;B+树&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的存储结构&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.7431972789115646&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzQoknttTWIrdxibtddSIiaXkNRwaa7nbLNhzAZic8jOx7ExBGFkDT5hZQg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1176&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;页除了可以存放&lt;/span&gt;&lt;code&gt;&lt;span&gt;数据&lt;/span&gt;&lt;/code&gt;&lt;span&gt;（叶子节点），还可以存放&lt;/span&gt;&lt;code&gt;&lt;span&gt;健值和指针&lt;/span&gt;&lt;/code&gt;&lt;span&gt;（非叶子节点），当然他们是有序的。这样的数据组织形式，我们称为索引组织表。&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如：上图中 page number=3的页，该页存放键值和指向数据页的指针，这样的页由N个键值+指针组成&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;B+ 树是如何检索记录？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;首先找到根页，你怎么知道一张表的根页在哪呢？&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;其实每张表的根页位置在表空间文件中是固定的，即page number=3的页&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;找到根页后通过二分查找法，定位到id=5的数据应该在指针P5指向的页中&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;然后再去page number=5的页中查找，同样通过二分查询法即可找到id=5的记录&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;如何计算B+树的高度？&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在&lt;/span&gt;&lt;code&gt;&lt;span&gt;InnoDB&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 的表空间文件中，约定&lt;/span&gt;&lt;code&gt;&lt;span&gt;page number = 3&lt;/span&gt;&lt;/code&gt;&lt;span&gt;表示主键索引的根页&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;SELECT&lt;br/&gt;b.name, a.name, index_id, &lt;span&gt;type&lt;/span&gt;, a.space, a.PAGE_NO&lt;br/&gt;FROM&lt;br/&gt;information_schema.INNODB_SYS_INDEXES a,&lt;br/&gt;information_schema.INNODB_SYS_TABLES b&lt;br/&gt;WHERE&lt;br/&gt;a.table_id = b.table_id AND a.space &amp;lt;&amp;gt; 0&lt;br/&gt;and b.name like &lt;span&gt;&#x27;%sp_job_log&#x27;&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4416326530612245&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzDYSy4C3FBQGVAicTia8eWaE0ibSbmR1nR0fQrxvPzpH314j8wwD7BQzJQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1225&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;从图中可以看出，每个表的主键索引的根页的page number都是3，而其他的二级索引page number为4&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在根页偏移量为&lt;/span&gt;&lt;code&gt;&lt;span&gt;64&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的地方存放了该B+树的&lt;/span&gt;&lt;code&gt;&lt;span&gt;page level&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。主键索引B+树的根页在整个表空间文件中的第3个页开始，所以算出它在文件中的偏移量：&lt;/span&gt;&lt;code&gt;&lt;span&gt;16384*3 + 64 = 49152 + 64 =49216&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，前2个字节中。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;首先，找到MySql数据库物理文件存放位置：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;show global variables like &lt;span&gt;&quot;%datadir%&quot;&lt;/span&gt; ;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.23905723905723905&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketznDFboCv74nXKOaM99gicGfGPWOX4iaV47GdCokFqSrlUv32h8z5mS6wA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;594&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;hexdump工具，查看表空间文件指定偏移量上的数据：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;hexdump -s 49216 -n 10  sp_job_log.ibd&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.09765625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzuZepNfX9ZfrDShVg5coaEoKmmZEe5jAxad1Te2Q5y8v5IcI09mzzpw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;page_level 值是 1，那么 B+树高度为 &lt;/span&gt;&lt;code&gt;&lt;span&gt;page level + 1 = 2&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;特别说明：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;查询数据库时，不论读一行，还是读多行，都是将这些行所在的整页数据加载，然后在内存中匹配过滤出最终结果。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;表的检索速度跟树的深度有直接关系，毕竟一次页加载就是一次IO，而磁盘IO又是比较费时间。&lt;/span&gt;&lt;code&gt;&lt;span&gt;对于一张千万级条数B+树高度为3的表与几十万级B+树高度也为3的表，其实查询效率相差不大。&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;一棵树可以存放多少行数据？&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;假设B+树的深度为2&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这棵B+树的存储总记录数 = &lt;/span&gt;&lt;code&gt;&lt;span&gt;根节点指针数 * 单个叶子节点记录条数&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;那么指针数如何计算？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;假设主键ID为&lt;/span&gt;&lt;code&gt;&lt;span&gt;bigint&lt;/span&gt;&lt;/code&gt;&lt;span&gt;类型，长度为&lt;/span&gt;&lt;code&gt;&lt;span&gt;8字节&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，而指针大小在InnoDB源码中设置为&lt;/span&gt;&lt;code&gt;&lt;span&gt;6字节&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，这样一共&lt;/span&gt;&lt;code&gt;&lt;span&gt;14字节&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;那么一个页中能存放多少这样的组合，就代表有多少指针，即 &lt;/span&gt;&lt;code&gt;&lt;span&gt;16384 / 14 = 1170&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。那么可以算出一棵高度为2 的B+树，能存放 &lt;/span&gt;&lt;code&gt;&lt;span&gt;1170 * 16 = 18720&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 条这样的数据记录。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;同理：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;高度为3的B+树可以存放的行数 =  &lt;/span&gt;&lt;code&gt;&lt;span&gt;1170 * 1170 * 16 = 21902400&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;千万级的数据存储只需要约3层B+树，查询数据时，每加载一页（page）代表一次IO。所以说，根据主键id索引查询约3次IO便可以找到目标结果。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;对于一些复杂的查询，可能需要走二级索引，那么通过二级索引查找记录最多需要花费多少次IO呢？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.66640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketz38TgsCyJTkFxDq7psbdsdsbYqoL9le40CKiaeaiaObAliaFWnOaGs48aA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;首先，从二级索引B+树中，根据&lt;/span&gt;&lt;code&gt;&lt;span&gt;name&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 找到对应的主键id&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.69296875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzk8Vt860QGV3uwh5GjeEgfwmRcYFpADH8hZNwV2ic5eTutzYPGhVEttQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;然后，再根据主键id 从 聚簇索引查找到对应的记录。如上图所示，二级索引有3层，聚簇索引有3层，那么最多花费的IO次数是：3+3 = 6&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;聚簇索引默认是主键，如果表中没有定义主键，InnoDB 会选择一个唯一的非空索引代替。如果没有这样的索引，InnoDB 会隐式定义一个主键来作为聚簇索引。&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;这也是为什么InnoDB表必须有主键，并且推荐使用整型的自增主键！！！&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;InnoDB使用的是聚簇索引，将主键组织到一棵B+树中，而行数据就储存在叶子节点上&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;举例说明：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1、若使用&lt;/span&gt;&lt;code&gt;&lt;span&gt;&quot;where id = 14&quot;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;这样的条件查找记录，则按照B+树的检索算法即可查找到对应的叶节点，之后获得行数据。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2、若对Name列进行条件搜索，则需要两个步骤：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键值。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二步使用主键值在主索引B+树中再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据。（重点在于通过其他键需要建立辅助索引）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;实战演示&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;实际项目中，每个表的结构设计都不一样，占用的存储空间大小也各不相等。如何计算不同的B+树深度下，一个表可以存储的记录条数？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们以业务日志表 &lt;/span&gt;&lt;code&gt;&lt;span&gt;sp_job_log&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 为例，讲解详细的计算过程：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1、查看表的状态信息&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;show table status like &lt;span&gt;&#x27;sp_job_log&#x27;&lt;/span&gt;\G&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.54140625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzPSO6icytqwXDU2rF2yy2CJKyc3V4462NyPbvuVroIicBhoz7Bk5TILDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;图中看到&lt;/span&gt;&lt;code&gt;&lt;span&gt;sp_job_log&lt;/span&gt;&lt;/code&gt;&lt;span&gt;表的行平均大小为&lt;/span&gt;&lt;code&gt;&lt;span&gt;153&lt;/span&gt;&lt;/code&gt;&lt;span&gt;个字节&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2、查看表结构&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;desc sp_job_log;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.2640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzlKOpFialibXWIiaZOIY26AZjhr2lTWicGTfOxAdq7xeZTzCZS0ib5ZQgVicQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3、计算B+树的行数&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;单个叶子节点（页）中的记录数 = 16K / 153 = 105&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;非叶子节点能存放多少指针， 16384 / 14 = 1170&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果树的高度为3，可以存放的记录行数 =  1170 * 1170 * 105 = 143,734,500&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;最后加餐&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;普通索引和唯一索引在查询效率上有什么不同？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;唯一索引就是在普通索引上增加了约束性，也就是关键字唯一，找到了关键字就停止检索。而普通索引，可能会存在用户记录中的关键字相同的情况，根据页结构的原理，当我们读取一条记录的时候，不是单独将这条记录从磁盘中读出去，而是将这个记录所在的页全部加载到内存中进行读取。InnoDB 存储引擎的页大小为 16KB，在一个页中可能存储着上千个记录，因此在普通索引的字段上进行查找也就是在内存中多几次&lt;/span&gt;&lt;code&gt;&lt;span&gt;判断下一条记录&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的操作，对于 CPU 来说，这些操作所消耗的时间是可以忽略不计的。所以对一个索引字段进行检索，采用普通索引还是唯一索引在检索效率上基本上没有差别。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;hr/&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;关于我：前阿里架构师，出过专利，竞赛拿过奖，CSDN博客专家，负责过电商交易、社区生鲜、营销、金融等业务，多年团队管理经验，爱思考，喜欢结交朋友&lt;/span&gt;&lt;/section&gt;&lt;h1 accuse=&quot;qTitle&quot;&gt;&lt;span&gt;&lt;span&gt;「长按2秒」↓↓&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;↓ 二维码，拉你进群，一线大厂技术交流&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.2021660649819494&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3Ohm6WHibeXLL4AVYEUeBKzcTZJd7mrk9XicnYiccg6n8YjsA4ibpRk6hkog7Qqx6cJNIF1rhicl992vID1IFUKWYuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;554&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推荐阅读&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&amp;amp;mid=2247484947&amp;amp;idx=1&amp;amp;sn=5a70f88fba83b435b8144bf1ddd3cc9f&amp;amp;chksm=ceb9fab8f9ce73ae97afc43f87314dd3bb61c966b9a40c12801cddc454dcf2845bbb605694e3&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;亿级系统的Redis缓存如何设计？？？&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&amp;amp;mid=2247484957&amp;amp;idx=1&amp;amp;sn=e50e0808cb6503ca7214bdd6fee4f134&amp;amp;chksm=ceb9fab6f9ce73a0c0725e381673fc7dc50c0594fb995b5f985b263143b34371e5e2936d7be0&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;【高并发、高性能、高可用】系统设计经验&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&amp;amp;mid=2247484929&amp;amp;idx=1&amp;amp;sn=d8cb3306dea9f1b92fd30d59da3f536a&amp;amp;chksm=ceb9faaaf9ce73bca59b46021a450fdc84aa0f85d6b49ff0e5578cc3abaa1433447f7dffc5e4&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;人人都是架构师？？？谈何容易！！&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&amp;amp;mid=2247484921&amp;amp;idx=1&amp;amp;sn=b429efe7e622759fc8f3bb24c2979a90&amp;amp;chksm=ceb9f952f9ce7044b001528ce8ae0ec89ed63727764081c21a8400e9f8f685345ec9cb0a54d7&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;【万级并发】电商库存扣减如何设计？不超卖！&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>bef9dab09790f19dfebfd8cc449c3076</guid>
<title>[推荐] 杭州某大厂：MySQL 连环问</title>
<link>https://toutiao.io/k/xjnx4kp</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，我是yes。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MySQL 面试题又更新啦！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请继续接招。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;说说分库分表？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随着用户量的激增和时间的堆砌，存在数据库里面的数据越来越多，此时的数据库就会产生瓶颈，出现资源报警、查询慢等场景。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先单机数据库所能承载的连接数、I/O及网络的吞吐等都是有限的，所以当并发量上来了之后，数据库就渐渐顶不住了。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.40814299900695133&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eSdk75TK4nEWAm9e6WibicVVnudWpTXSpbLKZHAvclSNUEknzcbZW02kVoUtBInLibrATW08HISruNjxULAicJSiakw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1007&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再则，如果单表的数据量过大，查询的性能也会下降。因为数据越多 B+ 树就越高，树越高则查询 I/O 的次数就越多，那么性能也就越差。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为上述的原因，不得已就得上分库分表了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;把以前存在一个数据库实例里的数据拆分成多个数据库实例，部署在不同的服务器中，&lt;span&gt;这是分库&lt;/span&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;把以前存在一张表里面的数据拆分成多张表，&lt;span&gt;这是分表&lt;/span&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般而言：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;分表：是为了解决由于单张表数据量多大，而导致查询慢的问题。大致三、四千万行数据就得拆分，不过具体还是得看每一行的数据量大小，有些字段都很小的可能支持更多行数，有些字段大的可能一千万就顶不住了。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;分库：是为了解决服务器资源受单机限制，顶不住高并发访问的问题，把请求分配到多台服务器上，降低服务器压力。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;你们一般怎么分库的？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般分库都是按照业务划分的，比如订单库、用户库等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有时候会针对一些特殊的库再作切分，比如一些活动相关的库都做了拆分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为做活动的时候并发可能会比较高，怕影响现有的核心业务，所以即使有关联，也会单独做拆分。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.7423971377459749&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eSdk75TK4nEWAm9e6WibicVVnudWpTXSpb6yoRNpHXmcfQqEqlOKaXxPqjotTEiaib2uCoXtWA3AebKEgiapcW6f3Aw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;559&quot;/&gt;&lt;/figure&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;那你觉得分库会带来什么问题呢？&lt;/span&gt;&lt;/h1&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;首先是&lt;span&gt;事务&lt;/span&gt;的问题。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们使用关系型数据库，有很大一点在于它保证事务完整性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而分库之后单机事务就用不上了，必须使用分布式事务来解决，而分布式事务基本的都是残缺的(我之前文章把分布式事务汇总了一波，后台搜索分布式事务就有了)。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是很重要的一点需要考虑。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;连表 JOIN 问题&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在一个库中的时候我们还可以利用 JOIN 来连表查询，而跨库了之后就无法使用 JOIN 了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时的解决方案就是&lt;span&gt;在业务代码中进行关联&lt;/span&gt;，也就是先把一个表的数据查出来，然后通过得到的结果再去查另一张表，然后利用代码来关联得到最终的结果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种方式实现起来稍微比较复杂，不过也是可以接受的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有可以&lt;span&gt;适当的冗余一些字段&lt;/span&gt;。比如以前的表就存储一个关联 ID，但是业务时常要求返回对应的 Name 或者其他字段。这时候就可以把这些字段冗余到当前表中，来去除需要关联的操作。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;那你们怎么分表的？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分表其实有两种：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;垂直分表，来看个图，很直观：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6628982528263104&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eSdk75TK4nEWAm9e6WibicVVnudWpTXSpb4eaOkdIoQsksMWPEyDJvonV78gfmqqelicN2FFfb7RZ7OJwFF6cSdEg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;973&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;垂直分表&lt;/span&gt;就是把一些不常用的大字段剥离出去。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;像上面的例子：用户名是很常见的搜索结果，性别和年龄占用的空间又不大，而地址和个人简介占用的空间相对而言就较大，我们都知道一个数据页的空间是有限的，把一些无用的数据拆分出去，一页就能存放更多行的数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内存存放更多有用的数据，就减少了磁盘的访问次数，性能就得到提升。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;水平分表&lt;/span&gt;，则是因为一张表内的数据太多了，上文也提到了数据越多 B+ 树就越高，访问的性能就差，所以进行水平拆分。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.39633638634471274&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eSdk75TK4nEWAm9e6WibicVVnudWpTXSpbC6sWOAAMlgwXMpYNlvgsf6FrWLQD1JFHqCe7bjjKFEOq3wFWj5RiabQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1201&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实不管这些，浅显的理解下，在一百个数据里面找一个数据快，还是在一万个数据里面找一个数据快？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;即使有索引，那厚的书目录多，翻目录也慢~&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;那分表会有什么问题？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;垂直分表还好，就是需要关联一下，而水平分表就有点麻烦了。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;排序、count、分页问题&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果一个用户的数据被拆分到多个表中，那查询结果分页就不像以前单张表那样直接就能查出来了，像 count 操作也是一样的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;只能由业务代码来实现或者用中间件将各表中的数据汇总、排序、分页然后返回。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;像 count 操作的结果其实可以缓存下来，然后每次数据增删都更新计数。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;路由问题&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分表的路由可以分：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Hash 路由&lt;/span&gt;，其实就是选择表中的某一列，然后进行 Hash 运算，将 Hash 运算得到的结果再对子表数进行取模，这样就能均匀的将数据分到不同的子表上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这跟 HashMap 选哪个桶是一样的原理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优点就是数据分布均匀。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缺点就是增加子表的时候麻烦，想想 HashMap的扩容，是不是得搬迁数据？这个分表也是一样的，我们可都知道，数据迁移一件麻烦事！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;范围路由&lt;/span&gt;，其实很简单，可以是时间，也可以是地址，表示一定的范围的即可。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如本来一张 User 表，我可以分 User_HZ、User_BJ、User_SH，按照地名来划分 User。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再比如 log 表，我可以将表分为 log_202103、 log_202104，把日志按照年月来划分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优点就是相对而言比较容易扩展，比如现在来个 GZ，那就加个 User_GZ。如果到了 5 月，那就建个 log_202105。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缺点就是数据可能分布不均匀，例如 BJ 的用户特别多或者某个月搞了促销，日志量特别大，等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;路由表&lt;/span&gt;，就是专门搞个表来记录路由信息，来看个图就很清楚了。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.653276955602537&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eSdk75TK4nEWAm9e6WibicVVnudWpTXSpblrE8Xmfc4av0iaHIDchGDc8lnyynXU6epNicRcyeE5W6amZqy3rLRzZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;473&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从图中我们就能得知，UserID 为 2 的用户数据在要去 User_3 这个用户表查询。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优点就是灵活咯，如果要迁移数据，直接迁移然后路由表一改就完事儿了~&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缺点就是得多查一次，每次查询都需要访问路由表，不过这个一般会做缓存的。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;全局主键问题&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以前单表的时候很简单，就是主键自增，现在分表了之后就有点尴尬了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以需要一些手段来保证全局主键唯一。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;还是自增，只不过自增步长设置一下。比如现在有三张表，步长设置为3，三张表 ID 初始值分别是1、2、3。这样第一张表的 ID 增长是 1、4、7。第二张表是2、5、8。第三张表是3、6、9，这样就不会重复了。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;UUID，这种最简单，但是不连续的主键插入会导致严重的页分裂，性能比较差。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;分布式 ID，比较出名的就是 Twitter 开源的 sonwflake 雪花算法，具体就不展开了，不然就又是一篇文章了，简单点利用 redis 来递增也行。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;那上面说的路由问题的 Sharding-Key 如何设计呢？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们分表是按照某个列来拆分的，那个列就是 Sharding-Key，查询的时候必须带上这个列才行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如上面提到的  log_202103，那表明查询条件一定得带上日期，这样才能找到正确的表。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以设计上得考虑查询的条件来作为 Sharding-Key。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;举个常常会被问的订单表 Sharding-Key 例子。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你想着查找订单的时候会通过订单号去找，所以应该利用订单 ID 来作为 Sharding-Key。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是你想想，你打开外卖软件想查找你的历史订单的时候，你是没有订单 ID 的，你只有你的 UserID，那此时只能把所有子表都通过 UserID 遍历一遍，这样效率就很低了！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以你想着那用 UserID 来作为 Sharding-Key 吧！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，商家呢？商家肯定关心自己今天卖了多少单，所以他也要查找订单，但他只有自己的商家 ID，所以如果要查询订单，只能把所有子表都通过商家 ID 遍历一遍，这样效率就很低了！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以 Sharding-Key 是满足不了所有查询需求的，只能曲线救国。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般做法就是&lt;span&gt;冗余数据&lt;/span&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;将订单同步到另一张表中给商家使用，这个表按商家 ID 来作为 Sharding-Key，也可以将数据同步到 ES 中。一般而言这里的数据同步都是异步处理，不会影响正常流程。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;最后&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天的面试题主要是分库分表相关的，基本上常问的都涵盖了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MySQL 面试题未完，持续更新~&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为分库分表会带来很多复杂性，所以能不分库分表，就不要分库分表。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个前提请牢记。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有，&lt;span&gt;面试题交流群&lt;/span&gt;持续开放，已经分享了近 50 个面经。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;加我微信: yes_oba，备注面试，拉你进群。&lt;/p&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我是 yes，从一点点到亿点点，我们下篇见~&lt;/p&gt;&lt;section data-recommend-type=&quot;list-title&quot; data-recommend-tid=&quot;8&quot; data-mpa-template=&quot;t&quot; data-mid=&quot;&quot; data-from=&quot;yb-recommend&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;往期推荐&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; data-recommend-article-type=&quot;list-title&quot; data-recomment-template-id=&quot;8&quot; data-recommend-article-id=&quot;2247489107_1&quot; data-recommend-article-time=&quot;1619081400&quot; data-recommend-article-cover=&quot;http://mmbiz.qpic.cn/mmbiz_jpg/eSdk75TK4nGygiam8LvNnHpvoNO012TInP3YB3cYuqicIzOJudn4Tu3Q0UYiab4KKBo8hx0LFxNsb1Ys1OtHzsVNA/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;我给总监打了包票，结果......我不想3.25&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzkxNTE3NjQ3MA==&amp;amp;mid=2247489107&amp;amp;idx=1&amp;amp;sn=12c449ae8afc6d1d6d89b8236854eede&amp;amp;chksm=c1627b2af615f23c55fe23b3686c6c95f0512f4ce2a7559f78e751283b159b81968a40644274#rd&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzkxNTE3NjQ3MA==&amp;amp;mid=2247489107&amp;amp;idx=1&amp;amp;sn=12c449ae8afc6d1d6d89b8236854eede&amp;amp;chksm=c1627b2af615f23c55fe23b3686c6c95f0512f4ce2a7559f78e751283b159b81968a40644274&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;&lt;section data-recommend-title=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;我给总监打了包票，结果......我不想3.25&lt;/p&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; data-recommend-article-type=&quot;list-title&quot; data-recomment-template-id=&quot;8&quot; data-recommend-article-id=&quot;2247489047_1&quot; data-recommend-article-time=&quot;1618878060&quot; data-recommend-article-cover=&quot;http://mmbiz.qpic.cn/mmbiz_jpg/eSdk75TK4nHQJOTMnuMpLPx77KCicwSYCRicy2RIibkVavVB9skjWIbOXNHEvicXibQfCu7BuXo02dxpjicLdhDg2ic2w/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;总监问我：Kafka为什么要抛弃ZooKeeper？| 文末送书&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzkxNTE3NjQ3MA==&amp;amp;mid=2247489047&amp;amp;idx=1&amp;amp;sn=ac16366e70fce619409360a972562f28&amp;amp;chksm=c1627b6ef615f278cee7ffe2a3d68111dbd2292d99a83e6cad15de7bd66af8ed54a4c11e784a#rd&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzkxNTE3NjQ3MA==&amp;amp;mid=2247489047&amp;amp;idx=1&amp;amp;sn=ac16366e70fce619409360a972562f28&amp;amp;chksm=c1627b6ef615f278cee7ffe2a3d68111dbd2292d99a83e6cad15de7bd66af8ed54a4c11e784a&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;&lt;section data-recommend-title=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;总监问我：Kafka为什么要抛弃ZooKeeper？| 文末送书&lt;/p&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8611c28ec86f3e7d7744721ceee9617c</guid>
<title>[推荐] Redis 存储对象信息是用 Hash 还是 String</title>
<link>https://toutiao.io/k/2rcud9q</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText&quot;&gt;&lt;p&gt;Redis 内部使用一个 RedisObject 对象来表示所有的 key 和 value，RedisObject 中的 type，则是代表一个 value 对象具体是何种数据类型，它包含字符串（String）、链表（List）、哈希结构（Hash）、集合（Set）、有序集合（Sorted set）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b188fc9df3bb28ffbbc456f00ee63233_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;671&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-b188fc9df3bb28ffbbc456f00ee63233_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;671&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-b188fc9df3bb28ffbbc456f00ee63233_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b188fc9df3bb28ffbbc456f00ee63233_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;日常工作中我们存储对象信息的时候，一般有两种做法，一种是用 Hash 存储，另一种是 String 存储。但好像并没有所谓的最佳实践，那么实际上到底用什么数据结构存储更好呢？&lt;/p&gt;&lt;p&gt;首先简单回顾下，Redis 的 Hash 和 String 结构。&lt;/p&gt;&lt;h2&gt;String&lt;/h2&gt;&lt;p&gt;String 数据结构是简单的 key-value 类型，value 其实不仅是 String，也可以是数字。Redis 中的 String 可以表示很多语义：&lt;/p&gt;&lt;p&gt;这三种类型，Redis 会根据具体的场景完成自动转换，并且根据需要选取底层的承载方式。String 在Redis 内部存储默认就是一个字符串，被 RedisObject 所引用，当遇到 incr、decr 等操作时会转成数值型进行计算，此时 RedisObject 的 encoding 字段为int。&lt;/p&gt;&lt;p&gt;在存储过程中，我们可以将用户信息使用 Json 序列化成字符串，然后将序列化后的字符串存入 Redis 进行缓存。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-27f8be534bfc97f96460328e94a72c8e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;964&quot; data-rawheight=&quot;402&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-27f8be534bfc97f96460328e94a72c8e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;964&quot; data-rawheight=&quot;402&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-27f8be534bfc97f96460328e94a72c8e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-27f8be534bfc97f96460328e94a72c8e_b.jpg&quot;/&gt;&lt;figcaption&gt;String 数据结构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;由于 Redis 的字符串是动态字符串，可以修改，内部结构类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配。如上图所示，内部为当前字符串实际分配的空间 capacity，一般高于实际字符串长度 len。&lt;/p&gt;&lt;p&gt;假设我们要存储的结构是：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;1 {
2   &quot;name&quot;: &quot;xiaowang&quot;,
3   &quot;age&quot;: &quot;35&quot;
4 }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果此时将此用户信息的 name 改为“xiaoli”，再存到 Redis 中，Redis 是不需要重新分配空间的。而且我们在读取和存储数据的时候只需要对做 Json 序列化与反序列化，比较方便。&lt;/p&gt;&lt;h2&gt;Hash&lt;/h2&gt;&lt;p&gt;Hash 在很多编程语言中都有着很广泛的应用，而在 Redis 中也是如此。在 Redis 中，Hash 常常用来缓存一些对象信息，如用户信息、商品信息、配置信息等，因此也被称为字典（dictionary），Redis 的字典使用 Hash table 作为底层实现， 一个 Hash table 里面可以有多个哈希表节点，而每个哈希表节点保存了字典中的一个键值对。实际上，Redis 数据库底层也是采用 Hash table 来存储键值对的。&lt;/p&gt;&lt;p&gt;Redis 的 Hash 相当于 Java 的 HashMap，内部结构实现与 HashMap 一致，即数组+链表结构。只是 reHash 方式不一样。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b4bc1aa71667b1b437671aad442daf0d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;370&quot; data-rawheight=&quot;244&quot; class=&quot;content_image&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;370&quot; data-rawheight=&quot;244&quot; class=&quot;content_image lazy&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b4bc1aa71667b1b437671aad442daf0d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;前面说到 String 适合存储用户信息，而 Hash 结构也可以存储用户信息，不过是对每个字段单独存储，因此可以在查询时获取部分字段的信息，节省网络流量。不过 Redis 的 Hash 的值只能是字符串，存储上面的那个例子还好，如果存储的用户信息变为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;1 {
2   &quot;name&quot;: &quot;xiaowang&quot;,
3   &quot;age&quot;: 25,
4   &quot;clothes&quot;: {
5     &quot;shirt&quot;: &quot;gray&quot;,
6     &quot;pants&quot;: &quot;read&quot;
7   }
8 }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;那么该如何存储&quot;clothes&quot;属性又变成了该用 String 还是 Hash 的问题。&lt;/p&gt;&lt;h2&gt;String 和 Hash 占用内存的比较&lt;/h2&gt;&lt;p&gt;既然两种数据结构都可以存储结构体信息。到底哪种更加合适呢？&lt;/p&gt;&lt;p&gt;首先我们用代码先插入 10000 条数据，然后用可视化工具来看看内存的占用情况。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;1  const Redis = require(&quot;ioRedis&quot;);
2  const Redis0 = new Redis({port: 6370});
3  const Redis1 = new Redis({port: 6371});
4
5
6  const user = {
7   name: &#x27;name12345&#x27;,
8   age: 16,
9   avatar: &#x27;https://dss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=256767015,24101428&amp;amp;fm=26&amp;amp;gp=0.jpg&#x27;,
10  phone: &#x27;13111111111&#x27;,
11  email: &#x27;1111111@11.email&#x27;,
12  lastLogon: &#x27;2021-04-28 10:00:00&#x27;,
13 }
14
15
16 async function main() {
17  for (let i = 0; i &amp;lt; 10000; i++) {
18     await Redis0.set(`String:user:${i}`, Json.Stringify(user));
19     await Redis1.hmset(`Hash:user:${i}`, user);
20   }
21 }
22
23 main().then(process.exit);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;先看 Redis0：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bb939848be9abcf4bd68095d4940f139_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;630&quot; data-rawheight=&quot;534&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-bb939848be9abcf4bd68095d4940f139_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;630&quot; data-rawheight=&quot;534&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-bb939848be9abcf4bd68095d4940f139_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bb939848be9abcf4bd68095d4940f139_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;再来看看 Redis1：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-32e8929036b707955e9337668c57eaf3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;652&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-32e8929036b707955e9337668c57eaf3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;652&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-32e8929036b707955e9337668c57eaf3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-32e8929036b707955e9337668c57eaf3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;可以看到还是有点差距的，但是差距并不明显。&lt;/p&gt;&lt;h2&gt;网友讨论&lt;/h2&gt;&lt;p&gt;网上的用户也有同样的疑问， 因为值的长度是不确定的，所以不知道采用 String 还是 Hash 存储更有效率。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2ec5a5fc745eecba2893edb5a6572f9d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;765&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-2ec5a5fc745eecba2893edb5a6572f9d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;765&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-2ec5a5fc745eecba2893edb5a6572f9d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2ec5a5fc745eecba2893edb5a6572f9d_b.jpg&quot;/&gt;&lt;figcaption&gt;△ 截图来源于 StackOverflow（Redis Strings vs Redis Hashes to represent Json: efficiency?）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这里我主要给大家翻译下该问题下优质的答案：&lt;/p&gt;&lt;p&gt;&lt;b&gt;适合用 String 存储的情况：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每次需要访问大量的字段&lt;/li&gt;&lt;li&gt;存储的结构具有多层嵌套的时候&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;适合用 Hash 存储的情况：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在大多数情况中只需要访问少量字段&lt;/li&gt;&lt;li&gt;自己始终知道哪些字段可用，防止使用 mget 时获取不到想要的数据&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文主要介绍了Redis 存储对象信息是用 Hash 还是 String，我的建议是大部分情况下使用 String 存储就好，毕竟在存储具有多层嵌套的对象时方便很多，占用的空间也比 Hash 小。当我们需要存储一个特别大的对象时，而且在大多数情况中只需要访问该对象少量的字段时，可以考虑使用 Hash。&lt;/p&gt;&lt;p&gt;&lt;b&gt;推荐阅读：&lt;/b&gt;&lt;/p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://link.zhihu.com/?target=https%3A//www.upyun.com/tech/article/563/%25E4%25B8%2589%25E5%2588%2586%25E9%2592%259F%25E4%25BA%2586%25E8%25A7%25A3%2520Python3%2520%25E7%259A%2584%25E5%25BC%2582%25E6%25AD%25A5%2520Web%2520%25E6%25A1%2586%25E6%259E%25B6%2520FastAPI.html&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic4.zhimg.com/v2-32db835da87060ffdd805ef17d07aec3_180x120.jpg&quot; data-image-width=&quot;957&quot; data-image-height=&quot;620&quot; class=&quot;LinkCard old LinkCard--hasImage&quot;&gt;&lt;span class=&quot;LinkCard-backdrop&quot;/&gt;&lt;span class=&quot;LinkCard-content&quot;&gt;&lt;span class=&quot;LinkCard-text&quot;&gt;&lt;span class=&quot;LinkCard-title&quot; data-text=&quot;true&quot;&gt;三分钟了解 Python3 的异步 Web 框架 FastAPI&lt;/span&gt;&lt;span class=&quot;LinkCard-meta&quot;&gt;&lt;span&gt;​&lt;svg class=&quot;Zi Zi--InsertLink&quot; fill=&quot;currentColor&quot; viewbox=&quot;0 0 24 24&quot;&gt;&lt;path d=&quot;M13.414 4.222a4.5 4.5 0 1 1 6.364 6.364l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005a2.5 2.5 0 1 0-3.536-3.536l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005zm-6.187 6.187a.5.5 0 0 1 .638-.058l.07.058.706.707a.5.5 0 0 1 .058.638l-.058.07-3.005 3.004a2.5 2.5 0 0 0 3.405 3.658l.13-.122 3.006-3.005a.5.5 0 0 1 .638-.058l.069.058.707.707a.5.5 0 0 1 .058.638l-.058.069-3.005 3.005a4.5 4.5 0 0 1-6.524-6.196l.16-.168 3.005-3.005zm8.132-3.182a.25.25 0 0 1 .353 0l1.061 1.06a.25.25 0 0 1 0 .354l-8.132 8.132a.25.25 0 0 1-.353 0l-1.061-1.06a.25.25 0 0 1 0-.354l8.132-8.132z&quot;/&gt;&lt;/svg&gt;&lt;/span&gt;www.upyun.com&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-imageCell&quot;&gt;&lt;img class=&quot;LinkCard-image LinkCard-image--horizontal&quot; alt=&quot;图标&quot; src=&quot;https://pic4.zhimg.com/v2-32db835da87060ffdd805ef17d07aec3_180x120.jpg&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://link.zhihu.com/?target=https%3A//www.upyun.com/tech/article/558/QUIC%252FHTTP3%2520%25E5%258D%258F%25E8%25AE%25AE%25E7%25AE%2580%25E6%259E%2590.html&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic1.zhimg.com/v2-7a88939758f822892186586001fb0d2c_180x120.jpg&quot; data-image-width=&quot;1080&quot; data-image-height=&quot;608&quot; class=&quot;LinkCard old LinkCard--hasImage&quot;&gt;&lt;span class=&quot;LinkCard-backdrop&quot;/&gt;&lt;span class=&quot;LinkCard-content&quot;&gt;&lt;span class=&quot;LinkCard-text&quot;&gt;&lt;span class=&quot;LinkCard-title&quot; data-text=&quot;true&quot;&gt;QUIC/HTTP3 协议简析&lt;/span&gt;&lt;span class=&quot;LinkCard-meta&quot;&gt;&lt;span&gt;​&lt;svg class=&quot;Zi Zi--InsertLink&quot; fill=&quot;currentColor&quot; viewbox=&quot;0 0 24 24&quot;&gt;&lt;path d=&quot;M13.414 4.222a4.5 4.5 0 1 1 6.364 6.364l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005a2.5 2.5 0 1 0-3.536-3.536l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005zm-6.187 6.187a.5.5 0 0 1 .638-.058l.07.058.706.707a.5.5 0 0 1 .058.638l-.058.07-3.005 3.004a2.5 2.5 0 0 0 3.405 3.658l.13-.122 3.006-3.005a.5.5 0 0 1 .638-.058l.069.058.707.707a.5.5 0 0 1 .058.638l-.058.069-3.005 3.005a4.5 4.5 0 0 1-6.524-6.196l.16-.168 3.005-3.005zm8.132-3.182a.25.25 0 0 1 .353 0l1.061 1.06a.25.25 0 0 1 0 .354l-8.132 8.132a.25.25 0 0 1-.353 0l-1.061-1.06a.25.25 0 0 1 0-.354l8.132-8.132z&quot;/&gt;&lt;/svg&gt;&lt;/span&gt;www.upyun.com&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-imageCell&quot;&gt;&lt;img class=&quot;LinkCard-image LinkCard-image--horizontal&quot; alt=&quot;图标&quot; src=&quot;https://pic1.zhimg.com/v2-7a88939758f822892186586001fb0d2c_180x120.jpg&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;p/&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>708505d3cd88587be98e4a30354d1380</guid>
<title>[推荐] 一文理解 Redis 底层数据结构</title>
<link>https://toutiao.io/k/a3gplbq</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-source-line=&quot;1&quot;&gt;Redis的5种常见数据结构：字符串(String)、列表(List)、散列(Hash)、集合(Set)、有序集合(Sorted Set)。这些都是Redis对外暴露的数据结构，本文将介绍这些数据结构的底层数据结构的实现。&lt;/p&gt;&lt;p data-source-line=&quot;3&quot;&gt;Redis底层数据结构有六种：&lt;/p&gt;&lt;ul data-source-line=&quot;4&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;简单动态字符串（SDS）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;列表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;字典&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;整数集合&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;跳跃表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;压缩列表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;快速列表&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-source-line=&quot;12&quot;&gt;简单动态字符串（SDS）&lt;/h2&gt;&lt;p data-source-line=&quot;14&quot;&gt;SDS是&quot;simple dynamic string&quot;的缩写。Redis中所有场景中出现的字符串，基本都是由SDS来实现的。&lt;/p&gt;&lt;p data-source-line=&quot;16&quot;&gt;使用场景：&lt;/p&gt;&lt;ul data-source-line=&quot;17&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;所有非数字的key。例如：&lt;code&gt;set msg &quot;hello world&quot;&lt;/code&gt;中的key msg.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;字符串数据类型的值。例如：&lt;code&gt;set msg &quot;hello world&quot;&lt;/code&gt;中的msg的值&lt;code&gt;&quot;hello wolrd&quot;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;非字符串数据类型中的“字符串值”。例如：&lt;code&gt;RPUSH fruits &quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;&lt;/code&gt;中的&lt;code&gt;&quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;21&quot;&gt;SDS结构图：&lt;/p&gt;&lt;p data-source-line=&quot;23&quot;&gt;&lt;img data-ratio=&quot;0.37174721189591076&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwQMQXH7jatA6qic7FxhOlD3lMxqC4iaGuE7grIlFJ6sicCCRbynhTicXRmA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;538&quot;/&gt;&lt;/p&gt;&lt;ul data-source-line=&quot;25&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;len：记录当前已使用的字节数（不包括&#x27;\0&#x27;），获取SDS长度的复杂度为O(1)（C 语言中获取字符串长度的时间复杂度为 O(N)）。此外，len值还避免了二进制安全与缓存区溢出的问题。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;alloc：记录当前字节数组总共分配的字节数量（不包括&#x27;\0&#x27;）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;flags：标记当前字节数组的属性，是sdshdr8还是sdshdr16等。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;buf：字节数组，用于保存字符串，包括结尾空白字符&#x27;\0&#x27;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-source-line=&quot;30&quot;&gt;&lt;code&gt;&lt;span&gt;// flags&lt;span&gt;值定义&lt;/span&gt;(&lt;span&gt;为了节约头部空间，在&lt;/span&gt;Redis3.2&lt;span&gt;开始，增加&lt;/span&gt;flag&lt;span&gt;字段。&lt;/span&gt;SDS&lt;span&gt;由一种数据结构变成了&lt;/span&gt;5&lt;span&gt;种数据结构，会根据&lt;/span&gt;SDS&lt;span&gt;存储的内容长度来选择不同的结构，以达到节省内存的效果&lt;/span&gt;)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_5  0&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_8  1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_16 2&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_32 3&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_64 4&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote data-source-line=&quot;39&quot;&gt;&lt;p&gt;注：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;二进制安全：通俗的讲，C语言中，用“\0”表示字符串的结束，如果字符串本身就有“\0”字符，字符串就会被截断，即非二进制安全；若通过某种机制，保证读写字符串时不损害其内容，这就是二进制安全。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;因为C字符串不记录自身的长度，所以strcat会假定用户在执行这个函数时，已经为dest分配足够多的内存了，可以容纳src字符串中的所有内容，而一旦这个假设不成立，就会产生缓存区溢出。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;h3 data-source-line=&quot;43&quot;&gt;频繁内存分配问题处理&lt;/h3&gt;&lt;p data-source-line=&quot;45&quot;&gt;每次增长或者缩短一个字符，程序都需要对保存这个字符串的数组进行一次内存重新分配操作。因为内存重分配涉及复杂的算法，并且可能需要执行系统调用，所以它通常是一个比较耗时的操作。&lt;/p&gt;&lt;p data-source-line=&quot;47&quot;&gt;为了避免C字符串的这种缺陷，SDS通过未使用空间解除了字符串长度和底层数组长度之间的关联。通过未使用空间，SDS实现了空间预分配和惰性空间释放两种优化策略。&lt;/p&gt;&lt;ol data-source-line=&quot;49&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;空间预分配&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;51&quot;&gt;空间预分配用于优化SDS的字符串增长操作。当SDS的API对一个SDS进行修改，并且需要对SDS进行空间扩展的时候，程序不仅会为SDS分配修改所必须要的空间，还会为SDS分配额外的未使用空间。其中，额外分配的未使用空间数量由以下公式决定：&lt;/p&gt;&lt;p data-source-line=&quot;57&quot;&gt;在扩展SDS空间之前，SDS API会先检查未使用空间是否足够，如果足够的话，API就会直接使用未使用空间，而无需执行内存重分配。通过空间预分配策略，Redis可以减少连续执行字符串增长操作所需的内存重分配次数。&lt;/p&gt;&lt;ol start=&quot;2&quot; data-source-line=&quot;59&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;惰性空间释放&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;61&quot;&gt;惰性空间释放用于优化SDS的字符串缩短操作。当SDS的API需要缩短SDS保存的字符串时，程序不会立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录下来，并等待将来使用。&lt;/p&gt;&lt;p data-source-line=&quot;63&quot;&gt;通过惰性空间释放策略，SDS避免了缩短字符串时所需的内存重分配操作，并为将来可能的增长操作提供了优化。&lt;/p&gt;&lt;p data-source-line=&quot;65&quot;&gt;与此同时，SDS也提供了响应的API可以在有需要时，真正的释放SDS里面的未使用空间，所以不用担心惰性空间释放策略会造成内存浪费。&lt;/p&gt;&lt;h2 data-source-line=&quot;67&quot;&gt;列表&lt;/h2&gt;&lt;p data-source-line=&quot;69&quot;&gt;列表在Redis中应用的非常广，列表的底层实现就是链表。此外，Redis的发布与订阅、慢查询、监视器等功能也用到了链表。&lt;/p&gt;&lt;p data-source-line=&quot;71&quot;&gt;列表特点：&lt;/p&gt;&lt;ul data-source-line=&quot;72&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;双端链表：带有指向前置节点和后置节点的指针，获取这两个节点的复杂度为O(1)。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无环：表头节点的prev和表尾节点的next都指向NULL，对链表的访问以NULL结束。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;链表长度计数器：带有len属性，获取链表长度的复杂度为O(1)。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多态：链表节点使用 void*指针保存节点值，可以保存不同类型的值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;77&quot;&gt;列表结构图：&lt;/p&gt;&lt;p data-source-line=&quot;79&quot;&gt;&lt;img data-ratio=&quot;0.5209471766848816&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwbJxwcmialX3lgnMv3gocSuvgic5bUDfNIpRiaicVXAEZTZ6icReicJMNBovQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;549&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;81&quot;&gt;列表的数据结构（adlist.h/listNode与adlist.h/list）：&lt;/p&gt;&lt;p data-source-line=&quot;83&quot;&gt;listNode：&lt;/p&gt;&lt;ul data-source-line=&quot;84&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;prev：前置节点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;next：后置节点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;value：节点值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;88&quot;&gt;list：&lt;/p&gt;&lt;h2 data-source-line=&quot;96&quot;&gt;字典&lt;/h2&gt;&lt;p data-source-line=&quot;98&quot;&gt;字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对的抽象数据结构。字典中的每一个键都是唯一的，可以通过键查找与之关联的值，并对其修改或删除。&lt;/p&gt;&lt;p data-source-line=&quot;100&quot;&gt;Redis的键值对存储就是用字典实现的，散列（Hash）的底层实现之一也是字典。&lt;/p&gt;&lt;p data-source-line=&quot;102&quot;&gt;字典的结构图（与JDk中的HashMap结构很相似）：&lt;/p&gt;&lt;p data-source-line=&quot;104&quot;&gt;&lt;img data-ratio=&quot;0.3811074918566775&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwc4KGUvAU6PYaLgaYHiaksQSZO0SHKErKibXVyWXHXTahl1UjGDr9W8xA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;921&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;106&quot;&gt;字典的数据结构（dict.h/dictht与dict.h/dict）：&lt;/p&gt;&lt;p data-source-line=&quot;108&quot;&gt;dict：&lt;/p&gt;&lt;ul data-source-line=&quot;109&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;type：针对不同类型的键值对，用于创建多类型的字典&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;privdata：针对不同类型的键值对，用于创建多类型的字典&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ht：两个元素的数组，包含两个dictht哈希表，一般字典只使用ht[0]哈希表，ht[1]哈希表会在对ht[0]哈希表进行rehash（重哈希）的时候使用，即当哈希表的键值对数量超过负载数量过多的时候，会将键值对迁移到ht[1]上&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;rehashidx：rehashidx也是跟rehash相关的，rehash的操作不是瞬间完成的，rehashidx记录着rehash的进度，图中没有进行rehash，它的值为-1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;114&quot;&gt;dictht：&lt;/p&gt;&lt;p data-source-line=&quot;120&quot;&gt;dictEntry：&lt;/p&gt;&lt;ul data-source-line=&quot;121&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;key：键&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;next：下一个dictEntry节点&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;value：union类型，支持不同类型的值&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-source-line=&quot;125&quot;&gt;渐进式hash&lt;/h3&gt;&lt;p data-source-line=&quot;127&quot;&gt;字典类型容量变化过程叫做rehash。需要满足一定的条件才能触发扩容机制：&lt;/p&gt;&lt;ol data-source-line=&quot;128&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;服务器当前没有进行BGWRITEAOF或者BGSAVE命令，且当前键值对个数超过一维数组的大小，才会触发扩容。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果当前键值对个数超过一维数组大小的五倍，无论是否在进行BGWRITEAOF或者BGSAVE命令，都会强制扩容。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果当前键值对个数少于一维数组大小的十分之一，则触发缩容过程。缩容不会考虑当前服务器是否在进行BGWRITEAOF或者BGSAVE命令。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;132&quot;&gt;渐进式hash的过程，简单来说类似数据库的迁移，读的时候先读ht[0]，读不到读ht[1]；写的时候只写ht[1]；ht[0]数据慢慢地往ht[1]上搬。&lt;/p&gt;&lt;p data-source-line=&quot;134&quot;&gt;当ht[0]的所有键值都迁至ht[1]之后，ht[0]变为空表，释放ht[0]。并将ht[1]设置为ht[0]，并在ht[1]新创建一个空白哈希表，将rehashidx属性的值设为-1，表示rehash操作已完成。&lt;/p&gt;&lt;p data-source-line=&quot;136&quot;&gt;具体步骤如下：&lt;/p&gt;&lt;ol data-source-line=&quot;138&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;为字典的备用哈希表分配空间：如果执行的是扩展操作，那么备用哈希表的大小为第一个大于等于(已用节点个数)*2的2n（2的n次方幂） 如果执行的是收缩操作，那么备用哈希表的大小为第一个大于等于(已用节点个数)的2n&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始（为-1时表示没有进行rehash）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当一次rehash工作完成之后，程序将rehashidx属性的值+1。同时在serverCron中调用rehash相关函数，在1ms的时间内，进行rehash处理，每次仅处理少量的转移任务(100个元素)。随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;145&quot;&gt;这里比较下Redis的渐进hash与JDk中HashMap的resize过程。如果对HashMap不了解，可以查看《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247483866&amp;amp;idx=1&amp;amp;sn=9ae4f9da57a198fdfc16265657e5efde&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;详解并发下的HashMap以及JDK8的优化&lt;/a&gt;》。&lt;/p&gt;&lt;h2 data-source-line=&quot;147&quot;&gt;整数集合&lt;/h2&gt;&lt;p data-source-line=&quot;149&quot;&gt;整数集合（intset）是Redis用于保存整数值的集合抽象数据结构，可以保存类型为int16_t、int32_t、int64_t的整数值，并且保证集合中不会出现重复元素 整数集合是集合（Set）的底层实现之一，如果一个集合只包含整数值元素，且元素数量不多时，会使用整数集合作为底层实现&lt;/p&gt;&lt;p data-source-line=&quot;152&quot;&gt;整数集合的结构图：&lt;/p&gt;&lt;p data-source-line=&quot;154&quot;&gt;&lt;img data-ratio=&quot;0.2747826086956522&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwnnOYZUcLPR1lvcM8ibLVFmXVJea0x7PDUGpPIxYdv5kytO6tUkt21Gw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;575&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;156&quot;&gt;整数集合的数据结构（inset.h/inset）：&lt;/p&gt;&lt;p data-source-line=&quot;158&quot;&gt;intset：&lt;/p&gt;&lt;ul data-source-line=&quot;159&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;encoding：决定contents数组的真正类型，如INTSET_ENC_INT16、INTSET_ENC_INT32、INTSET_ENC_INT64。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;length：记录整数集合的元素数量，即contents数组长度&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;contents：整数集合的每个元素在数组中按值的大小从小到大排序，且不包含重复项。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-source-line=&quot;163&quot;&gt;整数集合的升级&lt;/h3&gt;&lt;p data-source-line=&quot;165&quot;&gt;当想要添加一个新元素到整数集合中时，并且新元素的类型比整数集合现有的所有元素的类型都要长，整数集合需要先进行升级，才能将新元素添加到整数集合里面。每次想整数集合中添加新元素都有可能会引起升级，每次升级都需要对底层数组已有的所有元素进行类型转换。&lt;/p&gt;&lt;p data-source-line=&quot;167&quot;&gt;升级添加新元素：&lt;/p&gt;&lt;p data-source-line=&quot;173&quot;&gt;整数集合的升级策略可以提升整数集合的灵活性，并尽可能的节约内存。另外，整数集合不支持降级，一旦升级，编码就会一直保持升级后的状态。&lt;/p&gt;&lt;h2 data-source-line=&quot;175&quot;&gt;跳跃表&lt;/h2&gt;&lt;p data-source-line=&quot;177&quot;&gt;一个普通的单链表查询一个元素的时间复杂度为O(N)，即便该单链表是有序的。使用跳跃表（SkipList）是来解决查找问题的，它是一种有序的数据结构，不属于平衡树结构，也不属于Hash结构，它通过在每个节点维持多个指向其他节点的指针，而达到快速访问节点的目的 跳跃表是有序集合（Sorted Set）的底层实现之一，如果有序集合包含的元素比较多，或者元素的成员是比较长的字符串时，Redis会使用跳跃表做有序集合的底层实现。&lt;/p&gt;&lt;p data-source-line=&quot;180&quot;&gt;跳跃表其实可以把它理解为多层的链表，它有如下的性质：&lt;/p&gt;&lt;p data-source-line=&quot;187&quot;&gt;有关跳跃表的讲解，可以查看《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247483893&amp;amp;idx=1&amp;amp;sn=04e19d3f3a424bd53937c4bca78f3003&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;有关跳跃表的干货都在这里&lt;/a&gt;》&lt;/p&gt;&lt;p data-source-line=&quot;189&quot;&gt;跳跃表的结构图：&lt;/p&gt;&lt;p data-source-line=&quot;191&quot;&gt;&lt;img data-ratio=&quot;0.49741468459152016&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwLlkfia9Via47JDhg1U2I0CicnvaItUfkMosCsn0JkZJ9whEvMjXscSacQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;967&quot;/&gt;&lt;/p&gt;&lt;h2 data-source-line=&quot;197&quot;&gt;压缩列表&lt;/h2&gt;&lt;p data-source-line=&quot;199&quot;&gt;压缩列表（ziplist）是为了节约内存而设计的，是由一系列特殊编码的连续内存块组成的顺序性（sequential）数据结构，一个压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者一个整数值。&lt;/p&gt;&lt;p data-source-line=&quot;201&quot;&gt;压缩列表是列表（List）和散列（Hash）的底层实现之一，一个列表只包含少量列表项，并且每个列表项是小整数值或比较短的字符串，会使用压缩列表作为底层实现（在3.2版本之后是使用quicklist实现）。&lt;/p&gt;&lt;p data-source-line=&quot;203&quot;&gt;压缩列表的结构图：&lt;/p&gt;&lt;p data-source-line=&quot;205&quot;&gt;&lt;img data-ratio=&quot;0.07936507936507936&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZw1gyTUNkEoFVgRIia2VmIH6LlsYu7Yzu3IcPQJxG5tRZgAUhPSgibfrYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;693&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;207&quot;&gt;一个压缩列表可以包含多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。&lt;/p&gt;&lt;p data-source-line=&quot;209&quot;&gt;压缩列表的数据结构：&lt;/p&gt;&lt;ul data-source-line=&quot;211&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;zlbytes：记录整个压缩列表占用的内存字节数，在压缩列表内存重分配，或者计算zlend的位置时使用。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;zltail：记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，通过该偏移量，可以不用遍历整个压缩列表就可以确定表尾节点的地址。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;zllen：记录压缩列表包含的节点数量，但该属性值小于UINT16_MAX（65535）时，该值就是压缩列表的节点数量，否则需要遍历整个压缩列表才能计算出真实的节点数量。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;entryX：压缩列表的节点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;zlend：特殊值0xFF（十进制255），用于标记压缩列表的末端。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-source-line=&quot;217&quot;&gt;压缩列表节点的构成&lt;/h3&gt;&lt;p data-source-line=&quot;219&quot;&gt;&lt;img data-ratio=&quot;0.11711711711711711&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwfnGricWnnmBUw6Lw1ricMYmXzWBiagknicIVD6EfygeNC3ib19zN9EYo5rQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;444&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;221&quot;&gt;每个压缩列表节点可以保存一个字节数字或者一个整数值。压缩列表节点的数据结构：&lt;/p&gt;&lt;ul data-source-line=&quot;222&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;previous_entry_ength：记录压缩列表前一个字节的长度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;encoding：节点的encoding保存的是节点的content的内容类型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;content：content区域用于保存节点的内容，节点内容类型和长度由encoding决定。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-source-line=&quot;226&quot;&gt;快速列表&lt;/h2&gt;&lt;p data-source-line=&quot;228&quot;&gt;考虑到链表的附加空间相对太高，prev和next指针就要占去16个字节（64bit系统的指针是8个字节）。另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。因此Redis3.2版本开始对列表数据结构进行了改造，使用快速列表（quicklist）代替了压缩列表和列表。&lt;/p&gt;&lt;p data-source-line=&quot;230&quot;&gt;快速列表的结构图：&lt;/p&gt;&lt;p data-source-line=&quot;232&quot;&gt;&lt;img data-ratio=&quot;0.6107470511140236&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwibUXyMRzf0qFFCPM9NUtXwn45M69TWMdq15P4rcx9mKUZJdAKndU59w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;763&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;234&quot;&gt;快速列表的数据结构：&lt;/p&gt;&lt;p data-source-line=&quot;236&quot;&gt;quicklistNode：&lt;/p&gt;&lt;ul data-source-line=&quot;238&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;prev: 指向链表前一个节点的指针。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;next: 指向链表后一个节点的指针。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;zl: 数据指针。如果当前节点的数据没有压缩，那么它指向一个ziplist结构；否则，它指向一个quicklistLZF结构。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;sz: 表示zl指向的ziplist的总大小（包括zlbytes, zltail, zllen, zlend和各个数据项）。需要注意的是：如果ziplist被压缩了，那么这个sz的值仍然是压缩前的ziplist大小。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;count: 表示ziplist里面包含的数据项个数。这个字段只有16bit。稍后我们会一起计算一下这16bit是否够用。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;encoding: 表示ziplist是否压缩了（以及用了哪个压缩算法）。目前只有两种取值：2表示被压缩了（而且用的是LZF压缩算法），1表示没有压缩。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;container: 是一个预留字段。本来设计是用来表明一个quicklist节点下面是直接存数据，还是使用ziplist存数据，或者用其它的结构来存数据（用作一个数据容器，所以叫container）。但是，在目前的实现中，这个值是一个固定的值2，表示使用ziplist作为数据容器。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;recompress: 当我们使用类似lindex这样的命令查看了某一项本来压缩的数据时，需要把数据暂时解压，这时就设置recompress=1做一个标记，等有机会再把数据重新压缩。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;attempted_compress: 这个值只对Redis的自动化测试程序有用。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;extra: 其它扩展字段。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;249&quot;&gt;quickList：&lt;/p&gt;&lt;ul data-source-line=&quot;250&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;head: 指向头节点（左侧第一个节点）的指针。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;tail: 指向尾节点（右侧第一个节点）的指针。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;count: 所有ziplist数据项的个数总和。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;len: quicklist节点的个数。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;fill: 16bit，ziplist大小设置，存放list-max-ziplist-size参数的值。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;compress: 16bit，节点压缩深度设置，存放list-compress-depth参数的值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-source-line=&quot;257&quot;&gt;压缩深度&lt;/h3&gt;&lt;p data-source-line=&quot;259&quot;&gt;quicklist默认的压缩深度是0，也就是不压缩。压缩的实际深度由配置参数&lt;code&gt;list-compress-depth&lt;/code&gt;决定。为了支持快速的push/pop操作，quicklist的首尾两个ziplist不压缩，此时深度就是1；如果深度为2，就表示quicklist的首尾第一个 ziplist以及首尾第二个ziplist都不压缩。&lt;/p&gt;&lt;h3 data-source-line=&quot;261&quot;&gt;zipList长度&lt;/h3&gt;&lt;p data-source-line=&quot;262&quot;&gt;quicklist 内部默认单个ziplist长度为8k字节，超出了这个字节数，就会新起一个ziplist。ziplist的长度由配置参数&lt;code&gt;list-max-ziplist-size&lt;/code&gt;决定。&lt;/p&gt;&lt;h2 data-source-line=&quot;264&quot;&gt;编码&lt;/h2&gt;&lt;p data-source-line=&quot;266&quot;&gt;上面介绍了Redis的主要底层数据结构，包括简单动态字符串（SDS）、链表、字典、跳跃表、整数集合、压缩列表。但是Redis并没有直接使用这些数据结构来构建数据库，而是基于这些数据结构创建不同的编码，然后由不同条件下的不同编码来实现Redis的这些数据类型：字符串(String)、列表(List)、散列(Hash)、集合(Set)、有序集合(Sorted Set)。&lt;/p&gt;&lt;p data-source-line=&quot;268&quot;&gt;接下来就介绍Redis五种数据结构对应的编码。&lt;/p&gt;&lt;h3 data-source-line=&quot;270&quot;&gt;字符串对象的编码&lt;/h3&gt;&lt;p data-source-line=&quot;272&quot;&gt;上面介绍了SDS，但这只是字符串对象的其中一种实现。字符串对象的编码可能有三种：int、raw、embstr。&lt;/p&gt;&lt;ol data-source-line=&quot;274&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;int&lt;br/&gt;如果一个字符串对象，保存的值是一个整数值，并且这个整数值在long的范围内，那么Redis用整数值来保存这个信息，并且将字符串编码设置为 int。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;raw&lt;br/&gt;如果字符串对象保存的是一个字符串, 并且长度大于32个字节，它就会使用前面讲过的SDS（简单动态字符串）数据结构来保存这个字符串值，并且将字符串对象的编码设置为raw。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;embstr&lt;br/&gt;如果字符串对象保存的是一个字符串，但是长度小于32个字节，它就会使用embstr来保存了，embstr编码不是一个数据结构，而是对SDS的一个小优化，当使用SDS 的时候，程序需要调用两次内存分配，来给字符串对象和SDS各自分配一块空间，而embstr只需要一次内存分配，因为他需要的空间很少，所以采用连续的空间保存，即将SDS的值和字符串对象的值放在一块连续的内存空间上。这样能在短字符串的时候提高一些效率。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;283&quot;&gt;浮点数如何保存：&lt;/p&gt;&lt;p data-source-line=&quot;285&quot;&gt;Redis的字符串数据类型是支持保存浮点数，并且支持对浮点数进行加减操作，但是Redis在底层是把浮点数转换成字符串值，然后按照上述编码规则。对浮点数进行操作时，也是从字符串转换成浮点数进行计算，然后再转换成字符串进行保存的。&lt;/p&gt;&lt;p data-source-line=&quot;287&quot;&gt;编码转换条件：&lt;/p&gt;&lt;p data-source-line=&quot;289&quot;&gt;如果对一个int编码的字符串对象，修改它成非整数值，则对象就会使用raw编码。而Redis没有为embstr编码提供任何的修改操作，embstr编码的值是只读的，只要发生修改，立刻将编码转换成raw。&lt;/p&gt;&lt;table data-source-line=&quot;291&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码&lt;/th&gt;&lt;th&gt;使用条件&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;int&lt;/td&gt;&lt;td&gt;可以用long保存的整数&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;raw&lt;/td&gt;&lt;td&gt;长度大于32的字符串&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;embstr&lt;/td&gt;&lt;td&gt;字符串长度小于32字节（或者浮点数转换后满足）&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;297&quot;&gt;列表对象的编码&lt;/h3&gt;&lt;p data-source-line=&quot;299&quot;&gt;在 Redis 3.2 版本之前，列表对象底层由 压缩列表和双向链表配合实现，当元素数量较少的时候，使用压缩列表，当元素数量增多，就开始使用普通的双向链表保存数据。&lt;/p&gt;&lt;p data-source-line=&quot;301&quot;&gt;但是这种实现方式不够好，双向链表中的每个节点，都需要保存前后指针，这个内存的使用量 对于Redis这个内存数据库来说极其不友好。&lt;/p&gt;&lt;p data-source-line=&quot;303&quot;&gt;因此在 3.2 之后的版本，Redis新实现了一个数据结构，叫做快速列表（quicklist）。所有列表的底层实现都是这个数据结构了。它的底层实现基本上就是将 双向链表和压缩列表进行了结合，用双向的指针将压缩列表进行连接，这样不仅避免了压缩列表存储大量元素的性能压力，同时避免了双向链表连接指针占用空间过多的问题。&lt;/p&gt;&lt;h3 data-source-line=&quot;309&quot;&gt;集合对象的编码&lt;/h3&gt;&lt;p data-source-line=&quot;311&quot;&gt;集合对象的编码可以是intset或者hashtable。&lt;/p&gt;&lt;p data-source-line=&quot;313&quot;&gt;当集合中的所有元素都是整数，且元素的数量不大于512个的时候，使用intset编码。&lt;/p&gt;&lt;p data-source-line=&quot;315&quot;&gt;当元素不符合全部为整数值且元素个数小于512时，集合对象使用的编码方式为 hashtable。&lt;/p&gt;&lt;table data-source-line=&quot;317&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码&lt;/th&gt;&lt;th&gt;使用条件&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;intset&lt;/td&gt;&lt;td&gt;所有元素都是整数且元素个数小于 512&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;hashtable&lt;/td&gt;&lt;td&gt;其他数据&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;322&quot;&gt;有序集合对象的编码&lt;/h3&gt;&lt;p data-source-line=&quot;324&quot;&gt;有序集合对象的编码可以是ziplist以及skiplist。&lt;/p&gt;&lt;p data-source-line=&quot;326&quot;&gt;当使用ziplist编码时，有序集合对象的实现数据结构为压缩列表。当条件变化，ziplist编码会转换成skiplist编码。&lt;/p&gt;&lt;p data-source-line=&quot;328&quot;&gt;当使用skiplist编码的时候，内部使用zset 来实现数据的保存，zset的定义如下：&lt;/p&gt;&lt;pre data-source-line=&quot;329&quot;&gt;&lt;code&gt;typedef struct zset{&lt;br/&gt;  zskiplist *zsl&lt;span&gt;;&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;dict &lt;/span&gt;*&lt;span&gt;dict;&lt;br/&gt;&lt;/span&gt;}zset&lt;span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-source-line=&quot;335&quot;&gt;为什么需要同时使用跳跃表以及字典呢？&lt;/p&gt;&lt;p data-source-line=&quot;340&quot;&gt;因此，将字典和跳跃表结合进行使用，可以在O(1)的时间复杂度下完成查询分值操作，而对一些范围操作使用跳跃表可以达到O(logn)的时间复杂度。&lt;/p&gt;&lt;table data-source-line=&quot;342&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码&lt;/th&gt;&lt;th&gt;使用条件&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;ziplist&lt;/td&gt;&lt;td&gt;元素数量少于128且所有元素成员的长度小于64字节&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;skiplist&lt;/td&gt;&lt;td&gt;不满足上述条件的其他情况&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;347&quot;&gt;散列对象&lt;/h3&gt;&lt;p data-source-line=&quot;349&quot;&gt;散列对象的编码可以是ziplist或者hashtable.&lt;/p&gt;&lt;p data-source-line=&quot;351&quot;&gt;ziplist编码下的哈希对象，使用了压缩列表作为底层实现数据结构，用两个连续的压缩列表节点来表示哈希对象中的一个键值对。实现方式类似于上面的有序集合的场景。&lt;/p&gt;&lt;p data-source-line=&quot;353&quot;&gt;哈希结构本身在结构上和字典颇为相似，因此哈希对象中的每一个键值对都是字典中的一个键值对。&lt;/p&gt;&lt;table data-source-line=&quot;357&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码&lt;/th&gt;&lt;th&gt;使用条件&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;ziplist&lt;/td&gt;&lt;td&gt;键值对的键和值的长度都小于64字节，且键值对个数小于512&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;hastable&lt;/td&gt;&lt;td&gt;不满足上述条件的其他情况&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;362&quot;&gt;总结&lt;/h3&gt;&lt;table data-source-line=&quot;364&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;基础数据类型&lt;/th&gt;&lt;th&gt;可能的编码方式&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;字符串&lt;/td&gt;&lt;td&gt;int, raw, embstr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;列表&lt;/td&gt;&lt;td&gt;之前是 ziplist, linkedlist。3.2开始都是quicklist&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;集合&lt;/td&gt;&lt;td&gt;intset, hashtable&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;有序集合&lt;/td&gt;&lt;td&gt;ziplist, skiplist&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;散列&lt;/td&gt;&lt;td&gt;ziplist, hashtable&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p data-source-line=&quot;374&quot;&gt;参考文档：&lt;/p&gt;&lt;ol data-source-line=&quot;376&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;《Redis设计与实现》&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://github.com/redis/redis&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;《Redis 深度历险：核心原理和应用实践》&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>