<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>1e22e4414b07b7f0d29b33c0799106a1</guid>
<title>2022 年别再焦虑啦！加入我们！</title>
<link>https://toutiao.io/k/obimloc</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                              &lt;strong class=&quot;profile_nickname&quot;&gt;开发者头条&lt;/strong&gt;
                              &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                              &lt;p class=&quot;profile_meta&quot;&gt;
                              &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                              &lt;span class=&quot;profile_meta_value&quot;&gt;kaifazhetoutiao&lt;/span&gt;
                              &lt;/p&gt;

                              &lt;p class=&quot;profile_meta&quot;&gt;
                              &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                              &lt;span class=&quot;profile_meta_value&quot;&gt;程序员分享平台 | 官方应用下载地址：http://toutiao.io/download&lt;/span&gt;
                              &lt;/p&gt;
                              
                          &lt;/div&gt;
                          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>88e58c6dc96613c0d2fb57c74b13d5ed</guid>
<title>Redis 7.0 Multi Part AOF的设计和实现</title>
<link>https://toutiao.io/k/dtraf4e</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;article data-clipboard-cangjie=&quot;[&amp;quot;root&amp;quot;,{},[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;Redis 作为一种非常流行的内存数据&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:false,&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;库，通过将数据保存在内存中，Redis 得以拥有极高的读写性能。&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;但是一旦进程退出，Redis 的数据就会全部丢失。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;为了解决这个问题，Redis 提供了 RDB 和 AOF 两种持久化方案，将内存中的数据保存到磁盘中，避免数据丢失。本文将重点讨论AOF持久化方案，以及其存在的一些问题，并探讨在&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(0, 0, 0)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;Optima-Regular&amp;quot;},&amp;quot;spacing&amp;quot;:0.20400000000000001,&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;Redis 7.0 (已发布&amp;quot;]],[&amp;quot;a&amp;quot;,{&amp;quot;href&amp;quot;:&amp;quot;https://raw.githubusercontent.com/redis/redis/7.0/00-RELEASENOTES&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(0, 0, 0)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;Optima-Regular&amp;quot;},&amp;quot;spacing&amp;quot;:0.20400000000000001,&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;RC1&amp;quot;]]],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(0, 0, 0)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;Optima-Regular&amp;quot;},&amp;quot;spacing&amp;quot;:0.20400000000000001,&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;) 中&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:false,&amp;quot;color&amp;quot;:&amp;quot;rgb(0, 0, 0)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;Optima-Regular&amp;quot;},&amp;quot;spacing&amp;quot;:0.20400000000000001,&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;Multi Part AOF&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(0, 0, 0)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;Optima-Regular&amp;quot;},&amp;quot;spacing&amp;quot;:0.20400000000000001,&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;（下文简称为&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(0, 0, 0)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;Optima-Regular&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;Optima-Regular&amp;quot;},&amp;quot;spacing&amp;quot;:0.204,&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;MP-AOF）设计和实现细节。&amp;quot;]]],[&amp;quot;h1&amp;quot;,{&amp;quot;uuid&amp;quot;:&amp;quot;kyo2dj0xn514joqncg&amp;quot;,&amp;quot;spacing&amp;quot;:{&amp;quot;before&amp;quot;:14.666666666666668,&amp;quot;after&amp;quot;:14.666666666666668,&amp;quot;line&amp;quot;:0.8529411764705882}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;sz&amp;quot;:20,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;AOF&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;AOF( append only file )持久化以独立日志文件的方式记录每条写命令，并在 Redis 启动时回放 AOF 文件中的命令以达到恢复数据的目的。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;由于AOF会以追加的方式记录每一条redis的写命令，因此随着Redis处理的写命令增多，AOF文件也会变得越来越大，命令回放的时间也会增多，为了解决这个问题，Redis引入了AOF rewrite机制（下文称之为AOFRW）。AOFRW会移除AOF中冗余的写命令，以等效的方式重写、生成一个新的AOF文件，来达到减少AOF文件大小的目的。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;h1&amp;quot;,{&amp;quot;uuid&amp;quot;:&amp;quot;kytd9pe0fsmnb0u0bqp&amp;quot;,&amp;quot;spacing&amp;quot;:{&amp;quot;before&amp;quot;:14.666666666666668,&amp;quot;after&amp;quot;:14.666666666666668,&amp;quot;line&amp;quot;:0.8529411764705882}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:20,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;AOFRW&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;图1展示的是AOFRW的实现原理。当AOFRW被触发执行时，Redis首先会fork一个子进程进行后台重写操作，该操作会将执行fork那一刻Redis的数据快照全部重写到一个名为&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;temp-rewriteaof-bg-pid.aof&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;的临时AOF文件中。 &amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;由于重写操作为子进程后台执行，主进程在AOF重写期间依然可以正常响应用户命令。因此，为了让子进程最终也能获取重写期间主进程产生的增量变化，主进程除了会将执行的写命令写入aof_buf，还会写一份到aof_rewrite_buf中进行缓存。在子进程重写的后期阶段，主进程会将aof_rewrite_buf中累积的数据使用pipe发送给子进程，子进程会将这些数据追加到临时AOF文件中（详细原理可参考&amp;quot;]],[&amp;quot;a&amp;quot;,{&amp;quot;href&amp;quot;:&amp;quot;http://mysql.taobao.org/monthly/2018/12/06/&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;这里&amp;quot;]]],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;）。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;当主进程承接了较大的写入流量时，aof_rewrite_buf中可能会堆积非常多的数据，导致在重写期间子进程无法将aof_rewrite_buf中的数据全部消费完。此时，aof_rewrite_buf剩余的数据将在重写结束时由主进程进行处理。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;当子进程完成重写操作并退出后，主进程会在&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;inlineCode&amp;quot;:true,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;backgroundRewriteDoneHandler&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot; 中处理后续的事情。首先，将重写期间aof_rewrite_buf中未消费完的数据追加到临时AOF文件中。其次，当一切准备就绪时，Redis会使用&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;inlineCode&amp;quot;:true,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;rename&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot; 操作将临时AOF文件原子的重命名为server.aof_filename，&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;此时原来的AOF文件会被覆盖&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;。至此，整个AOFRW流程结束。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;jc&amp;quot;:&amp;quot;center&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]],[&amp;quot;img&amp;quot;,{&amp;quot;id&amp;quot;:&amp;quot;4pglcs&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;image.png&amp;quot;,&amp;quot;size&amp;quot;:269281,&amp;quot;width&amp;quot;:708,&amp;quot;height&amp;quot;:597,&amp;quot;rotation&amp;quot;:0,&amp;quot;src&amp;quot;:&amp;quot;https://ata2-img.oss-cn-zhangjiakou.aliyuncs.com/neweditor/2b8e1a16-69c8-47de-9706-d38b16ba4cff.png?Expires=1644479627&amp;amp;OSSAccessKeyId=5brTYsCF9kNTYdU5&amp;amp;Signature=ShYJ%2Fqlyh0GTFrvHb%2F3JNHctG7s%3D&amp;quot;,&amp;quot;extraData&amp;quot;:{&amp;quot;resourceId&amp;quot;:&amp;quot;a0b35013-251c-4faf-a3ff-9a5a3506392a&amp;quot;}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;jc&amp;quot;:&amp;quot;center&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;图1 AOFRW实现原理&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;h1&amp;quot;,{&amp;quot;uuid&amp;quot;:&amp;quot;kysntecv89423ksakf2&amp;quot;,&amp;quot;spacing&amp;quot;:{&amp;quot;before&amp;quot;:14.666666666666668,&amp;quot;after&amp;quot;:14.666666666666668,&amp;quot;line&amp;quot;:0.8529411764705882}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;color&amp;quot;:&amp;quot;rgb(51, 51, 51)&amp;quot;,&amp;quot;fonts&amp;quot;:{&amp;quot;ascii&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;hAnsi&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;cs&amp;quot;:&amp;quot;-apple-system&amp;quot;,&amp;quot;eastAsia&amp;quot;:&amp;quot;-apple-system&amp;quot;},&amp;quot;sz&amp;quot;:20,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;AOFRW存在的问题&amp;quot;]]],[&amp;quot;h2&amp;quot;,{&amp;quot;uuid&amp;quot;:&amp;quot;kyo2ed9f7q3f4w9avi6&amp;quot;,&amp;quot;spacing&amp;quot;:{&amp;quot;before&amp;quot;:14.666666666666668,&amp;quot;after&amp;quot;:14.666666666666668,&amp;quot;line&amp;quot;:0.8529411764705882}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;sz&amp;quot;:16,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;内存开销&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;由图1可以看到，在AOFRW期间，主进程会将fork之后的数据变化写进aof_rewrite_buf中，aof_rewrite_buf和aof_buf中的内容绝大部分都是重复的，因此这将带来额外的内存冗余开销。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;在Redis INFO中的aof_rewrite_buffer_length字段可以看到当前时刻aof_rewrite_buf占用的内存大小。如下面显示的，在高写入流量下aof_rewrite_buffer_length几乎和aof_buffer_length占用了同样大的内存空间，几乎浪费了一倍的内存。&amp;quot;]]],[&amp;quot;code&amp;quot;,{&amp;quot;syntax&amp;quot;:&amp;quot;plaintext&amp;quot;,&amp;quot;theme&amp;quot;:&amp;quot;dracula&amp;quot;,&amp;quot;height&amp;quot;:null,&amp;quot;id&amp;quot;:&amp;quot;i8yxwg&amp;quot;,&amp;quot;uuid&amp;quot;:&amp;quot;kytfkzddqcz9l7p2ltq&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;aof_pending_rewrite:0\naof_buffer_length:35500\naof_rewrite_buffer_length:34000\naof_pending_bio_fsync:0&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;当aof_rewrite_buf占用的内存大小超过一定阈值时，我们将在Redis日志中看到如下信息。可以看到，aof_rewrite_buf占用了100MB的内存空间且主进程和子进程之间传输了2135MB的数据（子进程在通过pipe读取这些数据时也会有内部读buffer的内存开销）。对于内存型数据库Redis而言，这是一笔不小的开销。&amp;quot;]]],[&amp;quot;code&amp;quot;,{&amp;quot;syntax&amp;quot;:&amp;quot;plaintext&amp;quot;,&amp;quot;theme&amp;quot;:&amp;quot;dracula&amp;quot;,&amp;quot;height&amp;quot;:null,&amp;quot;id&amp;quot;:&amp;quot;top5pg&amp;quot;,&amp;quot;uuid&amp;quot;:&amp;quot;kytgfq7vflruw8o67y4&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;3351:M 25 Jan 2022 09:55:39.655 * Background append only file rewriting started by pid 6817\n3351:M 25 Jan 2022 09:57:51.864 * AOF rewrite child asks to stop sending diffs.\n6817:C 25 Jan 2022 09:57:51.864 * Parent agreed to stop sending diffs. Finalizing AOF...\n6817:C 25 Jan 2022 09:57:51.864 * Concatenating 2135.60 MB of AOF diff received from parent.\n3351:M 25 Jan 2022 09:57:56.545 * Background AOF buffer size: 100 MB&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:false,&amp;quot;sz&amp;quot;:11,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;AOFRW带来的内存开销有可能导致Redis内存突然达到maxmemory限制，从而影响正常命令的写入，甚至会触发操作系统限制被OOM Killer杀死，导致Redis不可服务。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;h2&amp;quot;,{&amp;quot;uuid&amp;quot;:&amp;quot;kyo2i0xjmtesmcz7fn&amp;quot;,&amp;quot;spacing&amp;quot;:{&amp;quot;before&amp;quot;:14.666666666666668,&amp;quot;after&amp;quot;:14.666666666666668,&amp;quot;line&amp;quot;:0.8529411764705882}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;sz&amp;quot;:16,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;CPU开销&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;CPU的开销主要有三个地方，分别解释如下：&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;ind&amp;quot;:{&amp;quot;left&amp;quot;:0},&amp;quot;list&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;e1lxev2npmd&amp;quot;,&amp;quot;level&amp;quot;:0,&amp;quot;isOrdered&amp;quot;:true,&amp;quot;isTaskList&amp;quot;:false,&amp;quot;listStyleType&amp;quot;:&amp;quot;DEC_LEN_LROM_P&amp;quot;,&amp;quot;symbolStyle&amp;quot;:{},&amp;quot;listStyle&amp;quot;:{&amp;quot;format&amp;quot;:&amp;quot;decimal&amp;quot;,&amp;quot;text&amp;quot;:&amp;quot;%1.&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;left&amp;quot;},&amp;quot;hideSymbol&amp;quot;:false}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;在AOFRW期间，主进程需要花费CPU时间向aof_rewrite_buf写数据，并使用eventloop事件循环向子进程发送aof_rewrite_buf中的数据：&amp;quot;]]],[&amp;quot;code&amp;quot;,{&amp;quot;syntax&amp;quot;:&amp;quot;text/x-csrc&amp;quot;,&amp;quot;theme&amp;quot;:&amp;quot;dracula&amp;quot;,&amp;quot;height&amp;quot;:null,&amp;quot;id&amp;quot;:&amp;quot;0p34tg&amp;quot;,&amp;quot;uuid&amp;quot;:&amp;quot;kyth2f8ccybtdywfs&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;/* Append data to the AOF rewrite buffer, allocating new blocks if needed. */\nvoid aofRewriteBufferAppend(unsigned char *s, unsigned long len) {\n    // 此处省略其他细节...\n  \n    /* Install a file event to send data to the rewrite child if there is\n     * not one already. */\n    if (!server.aof_stop_sending_diff &amp;amp;&amp;amp;\n        aeGetFileEvents(server.el,server.aof_pipe_write_data_to_child) == 0)\n    {\n        aeCreateFileEvent(server.el, server.aof_pipe_write_data_to_child,\n            AE_WRITABLE, aofChildWriteDiffData, NULL);\n    } \n  \n  \t// 此处省略其他细节...\n}&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;ind&amp;quot;:{&amp;quot;left&amp;quot;:0},&amp;quot;list&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;e1lxev2npmd&amp;quot;,&amp;quot;level&amp;quot;:0,&amp;quot;isOrdered&amp;quot;:true,&amp;quot;isTaskList&amp;quot;:false,&amp;quot;listStyleType&amp;quot;:&amp;quot;DEC_LEN_LROM_P&amp;quot;,&amp;quot;symbolStyle&amp;quot;:{},&amp;quot;listStyle&amp;quot;:{&amp;quot;format&amp;quot;:&amp;quot;decimal&amp;quot;,&amp;quot;text&amp;quot;:&amp;quot;%1.&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;left&amp;quot;},&amp;quot;hideSymbol&amp;quot;:false}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;在子进程执行重写操作的后期，会循环读取pipe中主进程发送来的增量数据，然后追加写入到临时AOF文件：&amp;quot;]]],[&amp;quot;code&amp;quot;,{&amp;quot;syntax&amp;quot;:&amp;quot;text/x-csrc&amp;quot;,&amp;quot;theme&amp;quot;:&amp;quot;dracula&amp;quot;,&amp;quot;height&amp;quot;:null,&amp;quot;id&amp;quot;:&amp;quot;sf22zi&amp;quot;,&amp;quot;uuid&amp;quot;:&amp;quot;kyth2f8c84bdajos6lu&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;int rewriteAppendOnlyFile(char *filename) {\n \t  // 此处省略其他细节...\n  \n    /* Read again a few times to get more data from the parent.\n     * We can&#x27;t read forever (the server may receive data from clients\n     * faster than it is able to send data to the child), so we try to read\n     * some more data in a loop as soon as there is a good chance more data\n     * will come. If it looks like we are wasting time, we abort (this\n     * happens after 20 ms without new data). */\n    int nodata = 0;\n    mstime_t start = mstime();\n    while(mstime()-start &amp;lt; 1000 &amp;amp;&amp;amp; nodata &amp;lt; 20) {\n        if (aeWait(server.aof_pipe_read_data_from_parent, AE_READABLE, 1) &amp;lt;= 0)\n        {\n            nodata++;\n            continue;\n        }\n        nodata = 0; /* Start counting from zero, we stop on N *contiguous*\n                       timeouts. */\n        aofReadDiffFromParent();\n    }\n\n    // 此处省略其他细节...\n}&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;ind&amp;quot;:{&amp;quot;left&amp;quot;:0},&amp;quot;list&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;e1lxev2npmd&amp;quot;,&amp;quot;level&amp;quot;:0,&amp;quot;isOrdered&amp;quot;:true,&amp;quot;isTaskList&amp;quot;:false,&amp;quot;listStyleType&amp;quot;:&amp;quot;DEC_LEN_LROM_P&amp;quot;,&amp;quot;symbolStyle&amp;quot;:{},&amp;quot;listStyle&amp;quot;:{&amp;quot;format&amp;quot;:&amp;quot;decimal&amp;quot;,&amp;quot;text&amp;quot;:&amp;quot;%1.&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;left&amp;quot;},&amp;quot;hideSymbol&amp;quot;:false}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;在子进程完成重写操作后，主进程会在&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;inlineCode&amp;quot;:true,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;backgroundRewriteDoneHandler&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot; 中进行收尾工作。其中一个任务就是将在重写期间aof_rewrite_buf中没有消费完成的数据写入临时AOF文件。如果aof_rewrite_buf中遗留的数据很多，这里也将消耗CPU时间。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;code&amp;quot;,{&amp;quot;syntax&amp;quot;:&amp;quot;text/x-csrc&amp;quot;,&amp;quot;theme&amp;quot;:&amp;quot;dracula&amp;quot;,&amp;quot;height&amp;quot;:null,&amp;quot;id&amp;quot;:&amp;quot;c2vkig&amp;quot;,&amp;quot;uuid&amp;quot;:&amp;quot;kytccgz0w307g477gn&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;void backgroundRewriteDoneHandler(int exitcode, int bysignal) {\n    // 此处省略其他细节...\n  \n    /* Flush the differences accumulated by the parent to the rewritten AOF. */\n    if (aofRewriteBufferWrite(newfd) == -1) {\n        serverLog(LL_WARNING,\n                \&amp;quot;Error trying to flush the parent diff to the rewritten AOF: %s\&amp;quot;, strerror(errno));\n        close(newfd);\n        goto cleanup;\n     }\n  \t\n     // 此处省略其他细节...\n}&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:false,&amp;quot;sz&amp;quot;:11,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;AOFRW带来的CPU开销可能会造成Redis在执行命令时出现RT上的抖动，甚至造成客户端超时的问题。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:false,&amp;quot;sz&amp;quot;:11,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;h2&amp;quot;,{&amp;quot;uuid&amp;quot;:&amp;quot;kywm25r9s45dc5dz1gi&amp;quot;,&amp;quot;spacing&amp;quot;:{&amp;quot;before&amp;quot;:14.666666666666668,&amp;quot;after&amp;quot;:14.666666666666668,&amp;quot;line&amp;quot;:0.8529411764705882}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;sz&amp;quot;:16,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;磁盘IO开销&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;如前文所述，在AOFRW期间，主进程除了会将执行过的写命令写到aof_buf之外，还会写一份到aof_rewrite_buf中。aof_buf中的数据最终会被写入到当前使用的旧AOF文件中，产生磁盘IO。同时，aof_rewrite_buf中的数据也会被写入重写生成的新AOF文件中，产生磁盘IO。因此，同一份数据会产生两次磁盘IO。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;highlight&amp;quot;:&amp;quot;#FDBE3D&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;h2&amp;quot;,{&amp;quot;uuid&amp;quot;:&amp;quot;kytgzlktzco3maat32n&amp;quot;,&amp;quot;spacing&amp;quot;:{&amp;quot;before&amp;quot;:14.666666666666668,&amp;quot;after&amp;quot;:14.666666666666668,&amp;quot;line&amp;quot;:0.8529411764705882}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;sz&amp;quot;:16,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;代码复杂度&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;Redis使用下面所示的六个pipe进行主进程和子进程之间的数据传输和控制交互，这使得整个AOFRW逻辑变得更为复杂和难以理解。&amp;quot;]]],[&amp;quot;code&amp;quot;,{&amp;quot;syntax&amp;quot;:&amp;quot;text/x-csrc&amp;quot;,&amp;quot;theme&amp;quot;:&amp;quot;dracula&amp;quot;,&amp;quot;height&amp;quot;:null,&amp;quot;id&amp;quot;:&amp;quot;4ipxou&amp;quot;,&amp;quot;uuid&amp;quot;:&amp;quot;kytgzovc9lai0deyblo&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot; /* AOF pipes used to communicate between parent and child during rewrite. */\n int aof_pipe_write_data_to_child;\n int aof_pipe_read_data_from_parent;\n int aof_pipe_write_ack_to_parent;\n int aof_pipe_read_ack_from_child;\n int aof_pipe_write_ack_to_child;\n int aof_pipe_read_ack_from_parent;&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;h1&amp;quot;,{&amp;quot;uuid&amp;quot;:&amp;quot;kyo2mpefevqbms14o&amp;quot;,&amp;quot;spacing&amp;quot;:{&amp;quot;before&amp;quot;:14.666666666666668,&amp;quot;after&amp;quot;:14.666666666666668,&amp;quot;line&amp;quot;:0.8529411764705882}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;sz&amp;quot;:20,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;MP-AOF实现&amp;quot;]]],[&amp;quot;h2&amp;quot;,{&amp;quot;uuid&amp;quot;:&amp;quot;kyo2swqeqa6n53twfur&amp;quot;,&amp;quot;spacing&amp;quot;:{&amp;quot;before&amp;quot;:14.666666666666668,&amp;quot;after&amp;quot;:14.666666666666668,&amp;quot;line&amp;quot;:0.8529411764705882}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;sz&amp;quot;:16,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;方案概述&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;顾名思义，MP-AOF就是将原来的单个AOF文件拆分成多个AOF文件。在MP-AOF中，我们将AOF分为三种类型，分别为：&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;list&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;h9vqxr9nxan&amp;quot;,&amp;quot;level&amp;quot;:0,&amp;quot;isOrdered&amp;quot;:false,&amp;quot;isTaskList&amp;quot;:false,&amp;quot;listStyleType&amp;quot;:&amp;quot;SCIR_ECIR_SREC&amp;quot;,&amp;quot;symbolStyle&amp;quot;:{},&amp;quot;listStyle&amp;quot;:{&amp;quot;format&amp;quot;:&amp;quot;bullet&amp;quot;,&amp;quot;text&amp;quot;:&amp;quot;●&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;left&amp;quot;},&amp;quot;hideSymbol&amp;quot;:false},&amp;quot;ind&amp;quot;:{&amp;quot;left&amp;quot;:0}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;BASE&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;：表示基础AOF，它一般由子进程通过重写产生，该文件最多只有一个。&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;list&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;h9vqxr9nxan&amp;quot;,&amp;quot;level&amp;quot;:0,&amp;quot;isOrdered&amp;quot;:false,&amp;quot;isTaskList&amp;quot;:false,&amp;quot;isChecked&amp;quot;:false,&amp;quot;listStyleType&amp;quot;:&amp;quot;SCIR_ECIR_SREC&amp;quot;,&amp;quot;symbolStyle&amp;quot;:{},&amp;quot;listStyle&amp;quot;:{&amp;quot;format&amp;quot;:&amp;quot;bullet&amp;quot;,&amp;quot;text&amp;quot;:&amp;quot;●&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;left&amp;quot;},&amp;quot;hideSymbol&amp;quot;:false,&amp;quot;extraData&amp;quot;:{}},&amp;quot;ind&amp;quot;:{&amp;quot;left&amp;quot;:0}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;INCR：&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;表示增量AOF，它一般会在AOFRW开始执行时被创建，该文件可能存在多个。&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;list&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;h9vqxr9nxan&amp;quot;,&amp;quot;level&amp;quot;:0,&amp;quot;isOrdered&amp;quot;:false,&amp;quot;isTaskList&amp;quot;:false,&amp;quot;isChecked&amp;quot;:false,&amp;quot;listStyleType&amp;quot;:&amp;quot;SCIR_ECIR_SREC&amp;quot;,&amp;quot;symbolStyle&amp;quot;:{},&amp;quot;listStyle&amp;quot;:{&amp;quot;format&amp;quot;:&amp;quot;bullet&amp;quot;,&amp;quot;text&amp;quot;:&amp;quot;●&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;left&amp;quot;},&amp;quot;hideSymbol&amp;quot;:false,&amp;quot;extraData&amp;quot;:{}},&amp;quot;ind&amp;quot;:{&amp;quot;left&amp;quot;:0}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;HISTORY&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;：表示历史AOF，它由BASE和INCR AOF变化而来，每次AOFRW成功完成时，本次AOFRW之前对应的BASE和INCR AOF都将变为HISTORY，HISTORY类型的AOF会被Redis自动删除。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;为了管理这些AOF文件，我们引入了一个manifest（清单）文件来跟踪、管理这些AOF。同时，为了便于AOF备份和拷贝，我们将所有的AOF文件和manifest文件放入一个单独的文件目录中，目录名由appenddirname配置（Redis 7.0新增配置项）决定。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;jc&amp;quot;:&amp;quot;center&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]],[&amp;quot;img&amp;quot;,{&amp;quot;id&amp;quot;:&amp;quot;a51afg&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;image.png&amp;quot;,&amp;quot;size&amp;quot;:294309,&amp;quot;width&amp;quot;:735,&amp;quot;height&amp;quot;:536,&amp;quot;rotation&amp;quot;:0,&amp;quot;src&amp;quot;:&amp;quot;https://ata2-img.oss-cn-zhangjiakou.aliyuncs.com/neweditor/56ce29ce-0481-45fa-acc2-a368b9d16f1e.png?Expires=1644479627&amp;amp;OSSAccessKeyId=5brTYsCF9kNTYdU5&amp;amp;Signature=GKh0AZtwHcERl5nBhK8hxm2xF%2Bw%3D&amp;quot;,&amp;quot;extraData&amp;quot;:{&amp;quot;resourceId&amp;quot;:&amp;quot;25a9a49f-85fe-4c68-a278-8959b474811c&amp;quot;}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;jc&amp;quot;:&amp;quot;center&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;图2 MP-AOF Rewrite原理&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;jc&amp;quot;:&amp;quot;center&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;jc&amp;quot;:&amp;quot;center&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;jc&amp;quot;:&amp;quot;left&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;图2展示的是在MP-AOF中执行一次AOFRW的大致流程。在开始时我们依然会fork一个子进程进行重写操作，在主进程中，我们会同时打开一个新的INCR类型的AOF文件，在子进程重写操作期间，所有的数据变化都会被写入到这个新打开的INCR AOF中。子进程的重写操作完全是独立的，重写期间不会与主进程进行任何的数据和控制交互，最终重写操作会产生一个BASE AOF。新生成的BASE AOF和新打开的INCR AOF就代表了当前时刻Redis的全部数据。AOFRW结束时，主进程会负责更新manifest文件，将新生成的BASE AOF和INCR AOF信息加入进去，并将之前的BASE AOF和INCR  AOF标记为HISTORY（这些HISTORY AOF会被Redis异步删除）。一旦manifest文件更新完毕，就标志整个AOFRW流程结束。&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;jc&amp;quot;:&amp;quot;left&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;jc&amp;quot;:&amp;quot;left&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;由图2可以看到，我们在AOFRW期间不再需要aof_rewrite_buf，因此去掉了对应的内存消耗。同时，主进程和子进程之间也不再有数据传输和控制交互，因此对应的CPU开销也全部去掉。对应的，前文提及的六个pipe及其对应的代码也全部删除，使得AOFRW逻辑更加简单清晰。&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;&amp;quot;]]],[&amp;quot;h2&amp;quot;,{&amp;quot;uuid&amp;quot;:&amp;quot;kyo2t1tp3q78kh2g71y&amp;quot;,&amp;quot;spacing&amp;quot;:{&amp;quot;before&amp;quot;:14.666666666666668,&amp;quot;after&amp;quot;:14.666666666666668,&amp;quot;line&amp;quot;:0.8529411764705882}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;sz&amp;quot;:16,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;关键实现&amp;quot;]]],[&amp;quot;h3&amp;quot;,{&amp;quot;uuid&amp;quot;:&amp;quot;kyts1tvasif32v1bdd&amp;quot;,&amp;quot;spacing&amp;quot;:{&amp;quot;before&amp;quot;:12,&amp;quot;after&amp;quot;:12,&amp;quot;line&amp;quot;:0.8529411764705882}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;sz&amp;quot;:14,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;Manifest&amp;quot;]]],[&amp;quot;h4&amp;quot;,{&amp;quot;uuid&amp;quot;:&amp;quot;kyus2pzhw1d93fys0t9&amp;quot;,&amp;quot;spacing&amp;quot;:{&amp;quot;before&amp;quot;:10.666666666666666,&amp;quot;after&amp;quot;:10.666666666666666,&amp;quot;line&amp;quot;:0.8529411764705882}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;sz&amp;quot;:12,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;在内存中的表示&amp;quot;]]],[&amp;quot;p&amp;quot;,{},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;MP-AOF强依赖manifest文件，manifest在内存中表示为如下结构体，其中：&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;list&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;fny9nrh4i6&amp;quot;,&amp;quot;level&amp;quot;:0,&amp;quot;isOrdered&amp;quot;:false,&amp;quot;isTaskList&amp;quot;:false,&amp;quot;listStyleType&amp;quot;:&amp;quot;SCIR_ECIR_SREC&amp;quot;,&amp;quot;symbolStyle&amp;quot;:{},&amp;quot;listStyle&amp;quot;:{&amp;quot;format&amp;quot;:&amp;quot;bullet&amp;quot;,&amp;quot;text&amp;quot;:&amp;quot;●&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;left&amp;quot;},&amp;quot;hideSymbol&amp;quot;:false},&amp;quot;ind&amp;quot;:{&amp;quot;left&amp;quot;:0}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;aofInfo&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;：表示一个AOF文件信息，当前仅包括文件名、文件序号和文件类型&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;list&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;fny9nrh4i6&amp;quot;,&amp;quot;level&amp;quot;:0,&amp;quot;isOrdered&amp;quot;:false,&amp;quot;isTaskList&amp;quot;:false,&amp;quot;isChecked&amp;quot;:false,&amp;quot;listStyleType&amp;quot;:&amp;quot;SCIR_ECIR_SREC&amp;quot;,&amp;quot;symbolStyle&amp;quot;:{},&amp;quot;listStyle&amp;quot;:{&amp;quot;format&amp;quot;:&amp;quot;bullet&amp;quot;,&amp;quot;text&amp;quot;:&amp;quot;●&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;left&amp;quot;},&amp;quot;hideSymbol&amp;quot;:false,&amp;quot;extraData&amp;quot;:{}},&amp;quot;ind&amp;quot;:{&amp;quot;left&amp;quot;:0}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;base_aof_info&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;：表示BASE AOF信息，当不存在BASE AOF时，该字段为NULL&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;list&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;fny9nrh4i6&amp;quot;,&amp;quot;level&amp;quot;:0,&amp;quot;isOrdered&amp;quot;:false,&amp;quot;isTaskList&amp;quot;:false,&amp;quot;isChecked&amp;quot;:false,&amp;quot;listStyleType&amp;quot;:&amp;quot;SCIR_ECIR_SREC&amp;quot;,&amp;quot;symbolStyle&amp;quot;:{},&amp;quot;listStyle&amp;quot;:{&amp;quot;format&amp;quot;:&amp;quot;bullet&amp;quot;,&amp;quot;text&amp;quot;:&amp;quot;●&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;left&amp;quot;},&amp;quot;hideSymbol&amp;quot;:false,&amp;quot;extraData&amp;quot;:{}},&amp;quot;ind&amp;quot;:{&amp;quot;left&amp;quot;:0}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;sz&amp;quot;:11,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;incr_aof_list&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:false,&amp;quot;sz&amp;quot;:11,&amp;quot;szUnit&amp;quot;:&amp;quot;pt&amp;quot;,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;：用于存放所有INCR AOF文件的信息，所有的INCR AOF都会按照文件打开顺序排放&amp;quot;]]],[&amp;quot;p&amp;quot;,{&amp;quot;list&amp;quot;:{&amp;quot;listId&amp;quot;:&amp;quot;fny9nrh4i6&amp;quot;,&amp;quot;level&amp;quot;:0,&amp;quot;isOrdered&amp;quot;:false,&amp;quot;isTaskList&amp;quot;:false,&amp;quot;isChecked&amp;quot;:false,&amp;quot;listStyleType&amp;quot;:&amp;quot;SCIR_ECIR_SREC&amp;quot;,&amp;quot;symbolStyle&amp;quot;:{},&amp;quot;listStyle&amp;quot;:{&amp;quot;format&amp;quot;:&amp;quot;bullet&amp;quot;,&amp;quot;text&amp;quot;:&amp;quot;●&amp;quot;,&amp;quot;align&amp;quot;:&amp;quot;left&amp;quot;},&amp;quot;hideSymbol&amp;quot;:false,&amp;quot;extraData&amp;quot;:{}},&amp;quot;ind&amp;quot;:{&amp;quot;left&amp;quot;:0}},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;bold&amp;quot;:true,&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;history_aof_list&amp;quot;],[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;：用于存放HISTORY AOF信息，history_aof_list中的元素都是从base_aof_info和incr_aof_list中move过来的&amp;quot;]]],[&amp;quot;code&amp;quot;,{&amp;quot;syntax&amp;quot;:&amp;quot;text/x-csrc&amp;quot;,&amp;quot;theme&amp;quot;:&amp;quot;dracula&amp;quot;,&amp;quot;height&amp;quot;:null,&amp;quot;id&amp;quot;:&amp;quot;a134vb&amp;quot;,&amp;quot;uuid&amp;quot;:&amp;quot;kytr5bv4el8zuyqckl&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;text&amp;quot;},[&amp;quot;span&amp;quot;,{&amp;quot;data-type&amp;quot;:&amp;quot;leaf&amp;quot;},&amp;quot;typedef struct {\n    sds           file_name;  /* file name */\n    long long     file_seq;   /* file sequence */\n    aof_file_type file_type;  /* file type */\n} aofInfo;\n\ntypedef struct {\n    aofInfo     *base_aof_info;       /* BASE file information. NULL if there is no BASE file. */\n    list        *incr_aof_list;       /* INCR AOFs list. We may have multiple INCR AOF when rewrite fails. */\n    list        *history_aof_list;    /* HISTORY AOF list. When the AOFRW success, The aofInfo contained in\n                                         &quot; base_aof_info=&quot;base_aof_info&quot; and=&quot;and&quot; incr_aof_list=&quot;incr_aof_list&quot; will=&quot;will&quot; be=&quot;be&quot; moved=&quot;moved&quot; to=&quot;to&quot; this=&quot;this&quot; list=&quot;list&quot; we=&quot;we&quot; delete=&quot;delete&quot; these=&quot;these&quot; aof=&quot;aof&quot; files=&quot;files&quot; when=&quot;when&quot; aofrw=&quot;aofrw&quot; finish=&quot;finish&quot; n=&quot;n&quot; long=&quot;long&quot; curr_base_file_seq=&quot;curr_base_file_seq&quot; the=&quot;the&quot; sequence=&quot;sequence&quot; number=&quot;number&quot; used=&quot;used&quot; by=&quot;by&quot; current=&quot;current&quot; base=&quot;base&quot; file=&quot;file&quot; curr_incr_file_seq=&quot;curr_incr_file_seq&quot; incr=&quot;incr&quot; int=&quot;int&quot; dirty=&quot;dirty&quot; indicates=&quot;indicates&quot; that=&quot;that&quot; aofmanifest=&quot;aofmanifest&quot; in=&quot;in&quot; memory=&quot;memory&quot; is=&quot;is&quot; inconsistent=&quot;inconsistent&quot; with=&quot;with&quot; disk=&quot;disk&quot; need=&quot;need&quot; persist=&quot;persist&quot; it=&quot;it&quot; immediately=&quot;immediately&quot; redisserver=&quot;redisserver&quot; aof_manifest=&quot;aof_manifest&quot; track=&quot;track&quot; aofs=&quot;aofs&quot; appendonly=&quot;appendonly&quot; seq=&quot;seq&quot; type=&quot;type&quot; b=&quot;b&quot; i=&quot;i&quot; compatibility=&quot;compatibility&quot; newkey=&quot;newkey&quot; newvalue=&quot;newvalue&quot; annotations=&quot;annotations&quot; quot=&quot;quot&quot; preamble=&quot;preamble&quot; base_file_suffix=&quot;base_file_suffix&quot; incr_file_suffix=&quot;incr_file_suffix&quot; rdb_format_suffix=&quot;rdb_format_suffix&quot; aof_format_suffix=&quot;aof_format_suffix&quot; manifest_name_suffix=&quot;manifest_name_suffix&quot; rdb=&quot;rdb&quot; redis=&quot;redis&quot; manifest=&quot;manifest&quot; load=&quot;load&quot; according=&quot;according&quot; pointed=&quot;pointed&quot; am=&quot;am&quot; nint=&quot;nint&quot; loadappendonlyfiles=&quot;loadappendonlyfiles&quot; if=&quot;if&quot; server=&quot;server&quot; exists=&quot;exists&quot; dir=&quot;dir&quot; may=&quot;may&quot; starting=&quot;starting&quot; from=&quot;from&quot; an=&quot;an&quot; old=&quot;old&quot; version=&quot;version&quot; use=&quot;use&quot; enter=&quot;enter&quot; upgrade=&quot;upgrade&quot; mode=&quot;mode&quot; three=&quot;three&quot; situations=&quot;situations&quot; directory=&quot;directory&quot; not=&quot;not&quot; exist=&quot;exist&quot; but=&quot;but&quot; missing=&quot;missing&quot; contains=&quot;contains&quot; has=&quot;has&quot; record=&quot;record&quot; name=&quot;name&quot; of=&quot;of&quot; fileexist=&quot;fileexist&quot; direxists=&quot;direxists&quot; am-=&quot;=&quot; null=&quot;null&quot; amp=&quot;amp&quot; listlength=&quot;=&quot; strcmp=&quot;strcmp&quot; aoffileexist=&quot;aoffileexist&quot; aofupgradeprepare=&quot;aofupgradeprepare&quot; manually=&quot;manually&quot; construct=&quot;construct&quot; a=&quot;a&quot; aofinfo=&quot;aofinfo&quot; add=&quot;add&quot; aofinfofree=&quot;aofinfofree&quot; ai=&quot;aofInfoCreate();\n&quot; ai-=&quot;sdsnew(server.aof_filename);\n&quot; persistaofmanifest=&quot;persistaofmanifest&quot; c_ok=&quot;c_ok&quot; exit=&quot;exit&quot; move=&quot;move&quot; sds=&quot;sds&quot; aof_filepath=&quot;makePath(server.aof_dirname,&quot; rename=&quot;rename&quot; sdsfree=&quot;sdsfree&quot; t=&quot;t&quot; safety=&quot;safety&quot; info=&quot;info&quot; here=&quot;here&quot; calculate=&quot;calculate&quot; total=&quot;total&quot; size=&quot;size&quot; all=&quot;all&quot; advance=&quot;advance&quot; set=&quot;set&quot; total_size=&quot;getBaseAndIncrAppendOnlyFilesSize(am);\n&quot; startloading=&quot;startloading&quot; rdbflags_aof_preamble=&quot;rdbflags_aof_preamble&quot; needed=&quot;needed&quot; aof_name=&quot;(char*)am-&amp;gt;base_aof_info-&amp;gt;file_name;\n&quot; updateloadingfilename=&quot;updateloadingfilename&quot; loadsingleappendonlyfile=&quot;loadsingleappendonlyfile&quot; listnode=&quot;listnode&quot; ln=&quot;ln&quot; listiter=&quot;listiter&quot; li=&quot;li&quot; listrewind=&quot;listrewind&quot; while=&quot;while&quot; stoploading=&quot;stoploading&quot; crash=&quot;crash&quot; h=&quot;h&quot; exitcode=&quot;exitcode&quot; bysignal=&quot;bysignal&quot; snprintf=&quot;snprintf&quot; dup=&quot;dup&quot; temporary=&quot;temporary&quot; for=&quot;for&quot; subsequent=&quot;subsequent&quot; modifications=&quot;modifications&quot; temp_am=&quot;aofManifestDup(server.aof_manifest);\n\n&quot; get=&quot;get&quot; new=&quot;new&quot; mark=&quot;mark&quot; previous=&quot;previous&quot; have=&quot;have&quot; as=&quot;as&quot; history=&quot;history&quot; new_base_filename=&quot;getNewBaseFileNameAndMarkPreAsHistory(temp_am);\n\n&quot; aofmanifestfree=&quot;aofmanifestfree&quot; goto=&quot;goto&quot; cleanup=&quot;cleanup&quot; change=&quot;change&quot; aof_file_type_incr=&quot;aof_file_type_incr&quot; aof_file_type_hist=&quot;aof_file_type_hist&quot; them=&quot;them&quot; history_aof_list=&quot;history_aof_list&quot; markrewrittenincraofashistory=&quot;markrewrittenincraofashistory&quot; our=&quot;our&quot; c_err=&quot;c_err&quot; bg_unlink=&quot;bg_unlink&quot; can=&quot;can&quot; safely=&quot;safely&quot; let=&quot;let&quot; point=&quot;point&quot; free=&quot;free&quot; aofmanifestfreeandupdate=&quot;aofmanifestfreeandupdate&quot; don=&quot;don&quot; care=&quot;care&quot; about=&quot;about&quot; return=&quot;return&quot; value=&quot;value&quot; aofdelhistoryfiles=&quot;aofdelhistoryfiles&quot; because=&quot;because&quot; deletion=&quot;deletion&quot; failure=&quot;failure&quot; cause=&quot;cause&quot; any=&quot;any&quot; problems=&quot;problems&quot; truncate=&quot;truncate&quot; ftruncate=&quot;ftruncate&quot; aof_on=&quot;aof_on&quot; hasactivechildprocess=&quot;hasactivechildprocess&quot; aofrewritelimited=&quot;aofrewritelimited&quot; growth=&quot;(server.aof_current_size*100/base)&quot; rewriteappendonlyfilebackground=&quot;rewriteappendonlyfilebackground&quot; annotation=&quot;annotation&quot; recovery=&quot;recovery&quot;&gt;&lt;section&gt;&lt;span&gt;Redis 作为一种非常流行的内存数据库，通过将数据保存在内存中，Redis 得以拥有极高的读写性能。但是一旦进程退出，Redis 的数据就会全部丢失。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;为了解决这个问题，Redis 提供了 RDB 和 AOF 两种持久化方案，将内存中的数据保存到磁盘中，避免数据丢失。本文将重点讨论AOF持久化方案，以及其存在的一些问题，并探讨在Redis 7.0 (已发布RC1) 中Multi Part AOF（下文简称为MP-AOF，&lt;/span&gt;&lt;span&gt;本特性由阿里云数据库Tair团队贡献&lt;/span&gt;&lt;span&gt;）设计和实现细节。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;一  AOF&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;AOF( append only file )持久化以独立日志文件的方式记录每条写命令，并在 Redis 启动时回放 AOF 文件中的命令以达到恢复数据的目的。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;由于AOF会以追加的方式记录每一条redis的写命令，因此随着Redis处理的写命令增多，AOF文件也会变得越来越大，命令回放的时间也会增多，为了解决这个问题，Redis引入了AOF rewrite机制（下文称之为AOFRW）。AOFRW会移除AOF中冗余的写命令，以等效的方式重写、生成一个新的AOF文件，来达到减少AOF文件大小的目的。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;二  AOFRW&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图1展示的是AOFRW的实现原理。当AOFRW被触发执行时，Redis首先会fork一个子进程进行后台重写操作，该操作会将执行fork那一刻Redis的数据快照全部重写到一个名为temp-rewriteaof-bg-pid.aof的临时AOF文件中。 &lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;由于重写操作为子进程后台执行，主进程在AOF重写期间依然可以正常响应用户命令。因此，为了让子进程最终也能获取重写期间主进程产生的增量变化，主进程除了会将执行的写命令写入aof_buf，还会写一份到aof_rewrite_buf中进行缓存。在子进程重写的后期阶段，主进程会将aof_rewrite_buf中累积的数据使用pipe发送给子进程，子进程会将这些数据追加到临时AOF文件中（详细原理可参考[1]）。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;当主进程承接了较大的写入流量时，aof_rewrite_buf中可能会堆积非常多的数据，导致在重写期间子进程无法将aof_rewrite_buf中的数据全部消费完。此时，aof_rewrite_buf剩余的数据将在重写结束时由主进程进行处理。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;当子进程完成重写操作并退出后，主进程会在&lt;/span&gt;&lt;span&gt;backgroundRewriteDoneHandler&lt;/span&gt;&lt;span&gt; 中处理后续的事情。首先，将重写期间aof_rewrite_buf中未消费完的数据追加到临时AOF文件中。其次，当一切准备就绪时，Redis会使用&lt;/span&gt;&lt;span&gt;rename&lt;/span&gt;&lt;span&gt; 操作将临时AOF文件原子的重命名为server.aof_filename，此时原来的AOF文件会被覆盖。至此，整个AOFRW流程结束。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.84&quot; data-type=&quot;png&quot; data-w=&quot;2600&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naJh3PDPuwWCue0Uticd8qRIcUDr7YMJ4J3C8un11hncZ5xU0k2VMt1oPjc6Cco23vM6cFje6F13V7w/640?wx_fmt=png&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图1 AOFRW实现原理&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;三  AOFRW存在的问题&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;1  内存开销&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;由图1可以看到，在AOFRW期间，主进程会将fork之后的数据变化写进aof_rewrite_buf中，aof_rewrite_buf和aof_buf中的内容绝大部分都是重复的，因此这将带来额外的内存冗余开销。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在Redis INFO中的aof_rewrite_buffer_length字段可以看到当前时刻aof_rewrite_buf占用的内存大小。如下面显示的，在高写入流量下aof_rewrite_buffer_length几乎和aof_buffer_length占用了同样大的内存空间，几乎浪费了一倍的内存。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;css&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;aof_pending_rewrite&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:0&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;aof_buffer_length&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:35500&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;aof_rewrite_buffer_length&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:34000&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;aof_pending_bio_fsync&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:0&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;当aof_rewrite_buf占用的内存大小超过一定阈值时，我们将在Redis日志中看到如下信息。可以看到，aof_rewrite_buf占用了100MB的内存空间且主进程和子进程之间传输了2135MB的数据（子进程在通过pipe读取这些数据时也会有内部读buffer的内存开销）。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;对于内存型数据库Redis而言，这是一笔不小的开销。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;css&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;3351&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:M&lt;/span&gt; 25 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;Jan&lt;/span&gt; 2022 09&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:55&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:39.655&lt;/span&gt; * &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;Background&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;append&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;only&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;rewriting&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;started&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;pid&lt;/span&gt; 6817&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;3351&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:M&lt;/span&gt; 25 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;Jan&lt;/span&gt; 2022 09&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:57&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:51.864&lt;/span&gt; * &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;AOF&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;rewrite&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;child&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;asks&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;stop&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;sending&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;diffs&lt;/span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;6817&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:C&lt;/span&gt; 25 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;Jan&lt;/span&gt; 2022 09&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:57&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:51.864&lt;/span&gt; * &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;Parent&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;agreed&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;stop&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;sending&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;diffs&lt;/span&gt;. &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;Finalizing&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;AOF&lt;/span&gt;...&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;6817&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:C&lt;/span&gt; 25 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;Jan&lt;/span&gt; 2022 09&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:57&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:51.864&lt;/span&gt; * &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;Concatenating&lt;/span&gt; 2135&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.60&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;MB&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;AOF&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;diff&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;received&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;parent&lt;/span&gt;.&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;3351&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:M&lt;/span&gt; 25 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;Jan&lt;/span&gt; 2022 09&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:57&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:56.545&lt;/span&gt; * &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;Background&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;AOF&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;buffer&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;size&lt;/span&gt;: 100 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;MB&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;AOFRW带来的内存开销有可能导致Redis内存突然达到maxmemory限制，从而影响正常命令的写入，甚至会触发操作系统限制被OOM Killer杀死，导致Redis不可服务。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h2&gt;&lt;span&gt;2  CPU开销&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;CPU的开销主要有三个地方，分别解释如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在AOFRW期间，主进程需要花费CPU时间向aof_rewrite_buf写数据，并使用eventloop事件循环向子进程发送aof_rewrite_buf中的数据：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;aofRewriteBufferAppend&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(&lt;span class=&quot;code-snippet__keyword&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;char&lt;/span&gt; *s, &lt;span class=&quot;code-snippet__keyword&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt; len)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (!server.aof_stop_sending_diff &amp;amp;&amp;amp;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        aeGetFileEvents(server.el,server.aof_pipe_write_data_to_child) == &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        aeCreateFileEvent(server.el, server.aof_pipe_write_data_to_child,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            AE_WRITABLE, aofChildWriteDiffData, &lt;span class=&quot;code-snippet__literal&quot;&gt;NULL&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    } &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ol start=&quot;2&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在子进程执行重写操作的后期，会循环读取pipe中主进程发送来的增量数据，然后追加写入到临时AOF文件：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;rewriteAppendOnlyFile&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(&lt;span class=&quot;code-snippet__keyword&quot;&gt;char&lt;/span&gt; *filename)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; nodata = &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;mstime_t&lt;/span&gt; start = mstime();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;while&lt;/span&gt;(mstime()-start &amp;lt; &lt;span class=&quot;code-snippet__number&quot;&gt;1000&lt;/span&gt; &amp;amp;&amp;amp; nodata &amp;lt; &lt;span class=&quot;code-snippet__number&quot;&gt;20&lt;/span&gt;) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (aeWait(server.aof_pipe_read_data_from_parent, AE_READABLE, &lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;) &amp;lt;= &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            nodata++;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            &lt;span class=&quot;code-snippet__keyword&quot;&gt;continue&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        nodata = &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        aofReadDiffFromParent();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ol start=&quot;3&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在子进程完成重写操作后，主进程会在&lt;/span&gt;&lt;span&gt;backgroundRewriteDoneHandler&lt;/span&gt;&lt;span&gt; 中进行收尾工作。其中一个任务就是将在重写期间aof_rewrite_buf中没有消费完成的数据写入临时AOF文件。如果aof_rewrite_buf中遗留的数据很多，这里也将消耗CPU时间。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;backgroundRewriteDoneHandler&lt;/span&gt;(&lt;span class=&quot;code-snippet__params&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; exitcode, &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; bysignal&lt;/span&gt;)&lt;/span&gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (aofRewriteBufferWrite(newfd) == &lt;span class=&quot;code-snippet__number&quot;&gt;-1&lt;/span&gt;) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        serverLog(LL_WARNING,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;Error trying to flush the parent diff to the rewritten AOF: %s&quot;&lt;/span&gt;, strerror(errno));&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        close(newfd);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;goto&lt;/span&gt; cleanup;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;AOFRW带来的CPU开销可能会造成Redis在执行命令时出现RT上的抖动，甚至造成客户端超时的问题。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;3  磁盘IO开销&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;如前文所述，在AOFRW期间，主进程除了会将执行过的写命令写到aof_buf之外，还会写一份到aof_rewrite_buf中。aof_buf中的数据最终会被写入到当前使用的旧AOF文件中，产生磁盘IO。同时，aof_rewrite_buf中的数据也会被写入重写生成的新AOF文件中，产生磁盘IO。因此，同一份数据会产生两次磁盘IO。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;4  代码复杂度&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;Redis使用下面所示的六个pipe进行主进程和子进程之间的数据传输和控制交互，这使得整个AOFRW逻辑变得更为复杂和难以理解。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; aof_pipe_write_data_to_child;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; aof_pipe_read_data_from_parent;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; aof_pipe_write_ack_to_parent;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; aof_pipe_read_ack_from_child;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; aof_pipe_write_ack_to_child;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; aof_pipe_read_ack_from_parent;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;四  MP-AOF实现&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;1  方案概述&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;顾名思义，MP-AOF就是将原来的单个AOF文件拆分成多个AOF文件。在MP-AOF中，我们将AOF分为三种类型，分别为：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;BASE：表示基础AOF，它一般由子进程通过重写产生，该文件最多只有一个。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;INCR：表示增量AOF，它一般会在AOFRW开始执行时被创建，该文件可能存在多个。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;HISTORY：表示历史AOF，它由BASE和INCR AOF变化而来，每次AOFRW成功完成时，本次AOFRW之前对应的BASE和INCR AOF都将变为HISTORY，HISTORY类型的AOF会被Redis自动删除。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了管理这些AOF文件，我们引入了一个manifest（清单）文件来跟踪、管理这些AOF。同时，为了便于AOF备份和拷贝，我们将所有的AOF文件和manifest文件放入一个单独的文件目录中，目录名由appenddirname配置（Redis 7.0新增配置项）决定。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7278731836195509&quot; data-type=&quot;png&quot; data-w=&quot;3028&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naJh3PDPuwWCue0Uticd8qRIclYwToIWiadcYUEVMgL0xxLj3EOyHkfToZr3ywFM9ruormNrkz9PdkGA/640?wx_fmt=png&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图2 MP-AOF Rewrite原理&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图2展示的是在MP-AOF中执行一次AOFRW的大致流程。在开始时我们依然会fork一个子进程进行重写操作，在主进程中，我们会同时打开一个新的INCR类型的AOF文件，在子进程重写操作期间，所有的数据变化都会被写入到这个新打开的INCR AOF中。子进程的重写操作完全是独立的，重写期间不会与主进程进行任何的数据和控制交互，最终重写操作会产生一个BASE AOF。新生成的BASE AOF和新打开的INCR AOF就代表了当前时刻Redis的全部数据。AOFRW结束时，主进程会负责更新manifest文件，将新生成的BASE AOF和INCR AOF信息加入进去，并将之前的BASE AOF和INCR  AOF标记为HISTORY（这些HISTORY AOF会被Redis异步删除）。一旦manifest文件更新完毕，就标志整个AOFRW流程结束。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;由图2可以看到，我们在AOFRW期间不再需要aof_rewrite_buf，因此去掉了对应的内存消耗。同时，主进程和子进程之间也不再有数据传输和控制交互，因此对应的CPU开销也全部去掉。对应的，前文提及的六个pipe及其对应的代码也全部删除，使得AOFRW逻辑更加简单清晰。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h2&gt;&lt;span&gt;2  关键实现&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;Manifest&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;1）在内存中的表示&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;MP-AOF强依赖manifest文件，manifest在内存中表示为如下结构体，其中：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;aofInfo：表示一个AOF文件信息，当前仅包括文件名、文件序号和文件类型&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;base_aof_info：表示BASE AOF信息，当不存在BASE AOF时，该字段为NULL&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;incr_aof_list：用于存放所有INCR AOF文件的信息，所有的INCR AOF都会按照文件打开顺序排放&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;history_aof_list：用于存放HISTORY AOF信息，history_aof_list中的元素都是从base_aof_info和incr_aof_list中move过来的&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;typedef&lt;/span&gt; &lt;span class=&quot;code-snippet__class&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;struct&lt;/span&gt; {&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    sds           file_name;  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt;     file_seq;   &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    aof_file_type file_type;  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;} aofInfo;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;typedef&lt;/span&gt; &lt;span class=&quot;code-snippet__class&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;struct&lt;/span&gt; {&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    aofInfo     *base_aof_info;       &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__built_in&quot;&gt;list&lt;/span&gt;        *incr_aof_list;       &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__built_in&quot;&gt;list&lt;/span&gt;        *history_aof_list;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt;   curr_base_file_seq;   &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt;   curr_incr_file_seq;   &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt;         dirty;                &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;} aofManifest;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;为了便于原子性修改和回滚操作，我们在redisServer结构中使用指针的方式引用aofManifest。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__class&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;redisServer&lt;/span&gt; {&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    aofManifest *aof_manifest;       &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;h4&gt;&lt;span&gt;2）在磁盘上的表示&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;Manifest本质就是一个包含多行记录的文本文件，每一行记录对应一个AOF文件信息，这些信息通过key/value对的方式展示，便于Redis处理、易于阅读和修改。下面是一个可能的manifest文件内容：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;css&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.base&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.rdb&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 1 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.incr&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 1 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.2&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.incr&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 2 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;Manifest格式本身需要具有一定的扩展性，以便将来添加或支持其他的功能。比如可以方便的支持新增key/value和注解（类似AOF中的注解），这样可以保证较好的forward compatibility。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;css&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.base&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.rdb&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 1 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;newkey&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;newvalue&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.incr&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 1 &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;# &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;annotations&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 2 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.2&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.incr&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;文件命名规则&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;在MP-AOF之前，AOF的文件名为appendfilename参数的设置值（默认为appendonly.aof）。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;在MP-AOF中，我们使用basename.suffix的方式命名多个AOF文件。其中，appendfilename配置内容将作为basename部分，suffix则由三个部分组成，格式为seq.type.format ，其中：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;seq为文件的序号，由1开始单调递增，BASE和INCR拥有独立的文件序号&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;type为AOF的类型，表示这个AOF文件是BASE还是INCR&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;format用来表示这个AOF内部的编码方式，由于Redis支持RDB preamble机制，因此BASE AOF可能是RDB格式编码也可能是AOF格式编码：&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;#&lt;span class=&quot;code-snippet__meta-keyword&quot;&gt;define&lt;/span&gt; BASE_FILE_SUFFIX           &lt;span class=&quot;code-snippet__meta-string&quot;&gt;&quot;.base&quot;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;#&lt;span class=&quot;code-snippet__meta-keyword&quot;&gt;define&lt;/span&gt; INCR_FILE_SUFFIX           &lt;span class=&quot;code-snippet__meta-string&quot;&gt;&quot;.incr&quot;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;#&lt;span class=&quot;code-snippet__meta-keyword&quot;&gt;define&lt;/span&gt; RDB_FORMAT_SUFFIX          &lt;span class=&quot;code-snippet__meta-string&quot;&gt;&quot;.rdb&quot;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;#&lt;span class=&quot;code-snippet__meta-keyword&quot;&gt;define&lt;/span&gt; AOF_FORMAT_SUFFIX          &lt;span class=&quot;code-snippet__meta-string&quot;&gt;&quot;.aof&quot;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__meta&quot;&gt;#&lt;span class=&quot;code-snippet__meta-keyword&quot;&gt;define&lt;/span&gt; MANIFEST_NAME_SUFFIX       &lt;span class=&quot;code-snippet__meta-string&quot;&gt;&quot;.manifest&quot;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;因此，当使用appendfilename默认配置时，BASE、INCR和manifest文件的可能命名如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;appendonly.aof&lt;span class=&quot;code-snippet__number&quot;&gt;.1&lt;/span&gt;.&lt;span class=&quot;code-snippet__keyword&quot;&gt;base&lt;/span&gt;.rdb &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;appendonly.aof&lt;span class=&quot;code-snippet__number&quot;&gt;.1&lt;/span&gt;.&lt;span class=&quot;code-snippet__keyword&quot;&gt;base&lt;/span&gt;.aof &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;appendonly.aof&lt;span class=&quot;code-snippet__number&quot;&gt;.1&lt;/span&gt;.incr.aof&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;appendonly.aof&lt;span class=&quot;code-snippet__number&quot;&gt;.2&lt;/span&gt;.incr.aof&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;兼容老版本升级&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;由于MP-AOF强依赖manifest文件，Redis启动时会严格按照manifest的指示加载对应的AOF文件。但是在从老版本Redis（指Redis 7.0之前的版本）升级到Redis 7.0时，由于此时并无manifest文件，因此如何让Redis正确识别这是一个升级过程并正确、安全的加载旧AOF是一个必须支持的能力。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;识别能力是这一重要过程的首要环节，在真正加载AOF文件之前，我们会检查Redis工作目录下是否存在名为server.aof_filename的AOF文件。如果存在，那说明我们可能在从一个老版本Redis执行升级，接下来，我们会继续判断，当满足下面三种情况之一时我们会认为这是一个升级启动：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果appenddirname目录不存在&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;或者appenddirname目录存在，但是目录中没有对应的manifest清单文件&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果appenddirname目录存在且目录中存在manifest清单文件，且清单文件中只有BASE AOF相关信息，且这个BASE AOF的名字和server.aof_filename相同，且appenddirname目录中不存在名为server.aof_filename的文件&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;php&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;int loadAppendOnlyFiles(aofManifest *am) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (fileExist(server.aof_filename)) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (!dirExists(server.aof_dirname) ||&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            (am-&amp;gt;base_aof_info == &lt;span class=&quot;code-snippet__keyword&quot;&gt;NULL&lt;/span&gt; &amp;amp;&amp;amp; listLength(am-&amp;gt;incr_aof_list) == &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;) ||&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            (am-&amp;gt;base_aof_info != &lt;span class=&quot;code-snippet__keyword&quot;&gt;NULL&lt;/span&gt; &amp;amp;&amp;amp; listLength(am-&amp;gt;incr_aof_list) == &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt; &amp;amp;&amp;amp;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;             !strcmp(am-&amp;gt;base_aof_info-&amp;gt;file_name, server.aof_filename) &amp;amp;&amp;amp; !aofFileExist(server.aof_filename)))&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            aofUpgradePrepare(am);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  }&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;一旦被识别为这是一个升级启动，我们会使用&lt;/span&gt;&lt;span&gt;aofUpgradePrepare&lt;/span&gt;&lt;span&gt; 函数进行升级前的准备工作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;升级准备工作主要分为三个部分：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;使用server.aof_filename作为文件名来构造一个BASE AOF信息&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;将该BASE AOF信息持久化到manifest文件&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;使用&lt;/span&gt;&lt;span&gt;rename &lt;/span&gt;&lt;span&gt;将旧AOF文件移动到appenddirname目录中&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;php&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;void aofUpgradePrepare(aofManifest *am) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (am-&amp;gt;base_aof_info) aofInfoFree(am-&amp;gt;base_aof_info);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    aofInfo *ai = aofInfoCreate();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    ai-&amp;gt;file_name = sdsnew(server.aof_filename);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    ai-&amp;gt;file_seq = &lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    ai-&amp;gt;file_type = AOF_FILE_TYPE_BASE;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    am-&amp;gt;base_aof_info = ai;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    am-&amp;gt;curr_base_file_seq = &lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    am-&amp;gt;dirty = &lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (persistAofManifest(am) != C_OK) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;exit&lt;/span&gt;(&lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    sds aof_filepath = makePath(server.aof_dirname, server.aof_filename);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (rename(server.aof_filename, aof_filepath) == &lt;span class=&quot;code-snippet__number&quot;&gt;-1&lt;/span&gt;) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        sdsfree(aof_filepath);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;exit&lt;/span&gt;(&lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;);;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;升级准备操作是Crash Safety的，以上三步中任何一步发生Crash我们都能在下一次的启动中正确的识别并重试整个升级操作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;多文件加载及进度计算&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;Redis在加载AOF时会记录加载的进度，并通过Redis INFO的loading_loaded_perc字段展示出来。在MP-AOF中，&lt;/span&gt;&lt;span&gt;&lt;span&gt;loadAppendOnlyFiles&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;函数会根据传入的aofManifest进行AOF文件加载。在进行加载之前，我们需要提前计算所有待加载的AOF文件的总大小，并传给&lt;/span&gt;&lt;span&gt;startLoading&lt;/span&gt;&lt;span&gt; 函数，然后在&lt;/span&gt;&lt;span&gt;loadSingleAppendOnlyFile&lt;/span&gt;&lt;span&gt; 中不断的上报加载进度。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接下来，&lt;/span&gt;&lt;span&gt;loadAppendOnlyFiles&lt;/span&gt;&lt;span&gt; 会根据aofManifest依次加载BASE AOF和INCR AOF。当前加载完所有的AOF文件，会使用&lt;/span&gt;&lt;span&gt;stopLoading&lt;/span&gt;&lt;span&gt; 结束加载状态。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;php&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;int loadAppendOnlyFiles(aofManifest *am) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    total_size = getBaseAndIncrAppendOnlyFilesSize(am);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    startLoading(total_size, RDBFLAGS_AOF_PREAMBLE, &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (am-&amp;gt;base_aof_info) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        aof_name = (char*)am-&amp;gt;base_aof_info-&amp;gt;file_name;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        updateLoadingFileName(aof_name);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        loadSingleAppendOnlyFile(aof_name);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (listLength(am-&amp;gt;incr_aof_list)) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        listNode *ln;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        listIter li;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        listRewind(am-&amp;gt;incr_aof_list, &amp;amp;li);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;while&lt;/span&gt; ((ln = listNext(&amp;amp;li)) != &lt;span class=&quot;code-snippet__keyword&quot;&gt;NULL&lt;/span&gt;) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            aofInfo *ai = (aofInfo*)ln-&amp;gt;value;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            aof_name = (char*)ai-&amp;gt;file_name;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            updateLoadingFileName(aof_name);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            loadSingleAppendOnlyFile(aof_name);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    server.aof_current_size = total_size;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    server.aof_rewrite_base_size = server.aof_current_size;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    server.aof_fsync_offset = server.aof_current_size;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    stopLoading();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;AOFRW Crash Safety&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;当子进程完成重写操作，子进程会创建一个名为temp-rewriteaof-bg-pid.aof的临时AOF文件，此时这个文件对Redis而言还是不可见的，因为它还没有被加入到manifest文件中。要想使得它能被Redis识别并在Redis启动时正确加载，我们还需要将它按照前文提到的命名规则进行&lt;/span&gt;&lt;span&gt;rename &lt;/span&gt;&lt;span&gt;操作，并将其信息加入到manifest文件中。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;AOF文件&lt;/span&gt;&lt;span&gt;rename&lt;/span&gt;&lt;span&gt; 和manifest文件修改虽然是两个独立操作，但我们必须保证这两个操作的原子性，这样才能让Redis在启动时能正确的加载对应的AOF。MP-AOF使用两个设计来解决这个问题：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;BASE AOF的名字中包含文件序号，保证每次创建的BASE AOF不会和之前的BASE AOF冲突；&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;先执行AOF的&lt;/span&gt;&lt;span&gt;rename&lt;/span&gt;&lt;span&gt; 操作，再修改manifest文件；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了便于说明，我们假设在AOFRW开始之前，manifest文件内容如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;css&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.base&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.rdb&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 1 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.incr&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 1 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;则在AOFRW开始执行后manifest文件内容如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;css&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.base&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.rdb&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 1 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.incr&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 1 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.2&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.incr&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 2 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;子进程重写结束后，在主进程中，我们会将temp-rewriteaof-bg-pid.aof重命名为appendonly.aof.2.base.rdb，并将其加入manifest中，同时会将之前的BASE和INCR AOF标记为HISTORY。此时manifest文件内容如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;css&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.2&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.base&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.rdb&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 2 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.base&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.rdb&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 1 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.1&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.incr&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 1 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;h&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;appendonly&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.2&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.incr&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.aof&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;seq&lt;/span&gt; 2 &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;此时，本次AOFRW的结果对Redis可见，HISTORY AOF会被Redis异步清理。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;backgroundRewriteDoneHandler &lt;/span&gt;&lt;span&gt;函数通过七个步骤实现了上述逻辑：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在修改内存中的server.aof_manifest前，先dup一份临时的manifest结构，接下来的修改都将针对这个临时的manifest进行。这样做的好处是，一旦后面的步骤出现失败，我们可以简单的销毁临时manifest从而回滚整个操作，避免污染server.aof_manifest全局数据结构；&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;从临时manifest中获取新的BASE AOF文件名（记为new_base_filename），并将之前（如果有）的BASE AOF标记为HISTORY；&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;将子进程产生的temp-rewriteaof-bg-pid.aof临时文件重命名为new_base_filename；&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;将临时manifest结构中上一次的INCR  AOF全部标记为HISTORY类型；&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;将临时manifest对应的信息持久化到磁盘（persistAofManifest内部会保证manifest本身修改的原子性）；&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果上述步骤都成功了，我们可以放心的将内存中的server.aof_manifest指针指向临时的manifest结构（并释放之前的manifest结构），至此整个修改对Redis可见；&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;清理HISTORY类型的AOF，该步骤允许失败，因为它不会导致数据一致性问题。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;backgroundRewriteDoneHandler&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(&lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; exitcode, &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; bysignal)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__built_in&quot;&gt;snprintf&lt;/span&gt;(tmpfile, &lt;span class=&quot;code-snippet__number&quot;&gt;256&lt;/span&gt;, &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;temp-rewriteaof-bg-%d.aof&quot;&lt;/span&gt;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        (&lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt;)server.child_pid);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    temp_am = aofManifestDup(server.aof_manifest);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    new_base_filename = getNewBaseFileNameAndMarkPreAsHistory(temp_am);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (rename(tmpfile, new_base_filename) == &lt;span class=&quot;code-snippet__number&quot;&gt;-1&lt;/span&gt;) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        aofManifestFree(temp_am);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;goto&lt;/span&gt; cleanup;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    markRewrittenIncrAofAsHistory(temp_am);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (persistAofManifest(temp_am) == C_ERR) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        bg_unlink(new_base_filename);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        aofManifestFree(temp_am);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;goto&lt;/span&gt; cleanup;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    aofManifestFreeAndUpdate(temp_am);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    aofDelHistoryFiles();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;支持AOF truncate &lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;在进程出现Crash时AOF文件很可能出现写入不完整的问题，如一条事务里只写了MULTI，但是还没写EXEC时Redis就Crash。默认情况下，Redis无法加载这种不完整的AOF，但是Redis支持AOF truncate功能（通过&lt;/span&gt;&lt;span&gt;aof-load-truncated&lt;/span&gt;&lt;span&gt;配置打开）。其原理是使用server.aof_current_size跟踪AOF最后一个正确的文件偏移，然后使用&lt;/span&gt;&lt;span&gt;ftruncate&lt;/span&gt;&lt;span&gt; 函数将该偏移之后的文件内容全部删除，这样虽然可能会丢失部分数据，但可以保证AOF的完整性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在MP-AOF中，server.aof_current_size已经不再表示单个AOF文件的大小而是所有AOF文件的总大小。因为只有最后一个INCR AOF才有可能出现不完整写入的问题，因此我们引入了一个单独的字段server.aof_last_incr_size用于跟踪最后一个INCR AOF文件的大小。当最后一个INCR AOF出现不完整写入时，我们只需要将server.aof_last_incr_size之后的文件内容删除即可。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;javascript&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (ftruncate(server.aof_fd, server.aof_last_incr_size) == &lt;span class=&quot;code-snippet__number&quot;&gt;-1&lt;/span&gt;) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt; &lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;AOFRW限流&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;Redis在AOF大小超过一定阈值时支持自动执行AOFRW，当出现磁盘故障或者触发了代码bug导致AOFRW失败时，Redis将不停的重复执行AOFRW直到成功为止。在MP-AOF出现之前，这看似没有什么大问题（顶多就是消耗一些CPU时间和fork开销）。但是在MP-AOF中，因为每次AOFRW都会打开一个INCR AOF，并且只有在AOFRW成功时才会将上一个INCR和BASE转为HISTORY并删除。因此，连续的AOFRW失败势必会导致多个INCR AOF并存的问题。极端情况下，如果AOFRW重试频率很高我们将会看到成百上千个INCR AOF文件。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为此，我们引入了AOFRW限流机制。即当AOFRW已经连续失败三次时，下一次的AOFRW会被强行延迟1分钟执行，如果下一次AOFRW依然失败，则会延迟2分钟，依次类推延迟4、8、16...，当前最大延迟时间为1小时。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在AOFRW限流期间，我们依然可以使用bgrewriteaof命令立即执行一次AOFRW。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (server.aof_state == AOF_ON &amp;amp;&amp;amp;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    !hasActiveChildProcess() &amp;amp;&amp;amp;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    server.aof_rewrite_perc &amp;amp;&amp;amp;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    server.aof_current_size &amp;gt; server.aof_rewrite_min_size &amp;amp;&amp;amp;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    !aofRewriteLimited())&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;base&lt;/span&gt; = server.aof_rewrite_base_size ?&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        server.aof_rewrite_base_size : &lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt; growth = (server.aof_current_size*&lt;span class=&quot;code-snippet__number&quot;&gt;100&lt;/span&gt;/&lt;span class=&quot;code-snippet__keyword&quot;&gt;base&lt;/span&gt;) - &lt;span class=&quot;code-snippet__number&quot;&gt;100&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (growth &amp;gt;= server.aof_rewrite_perc) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        rewriteAppendOnlyFileBackground();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;AOFRW限流机制的引入，还可以有效的避免AOFRW高频重试带来的CPU和fork开销。Redis中很多的RT抖动都和fork有关系。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;五  总结&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;MP-AOF的引入，成功的解决了之前AOFRW存在的内存和CPU开销对Redis实例甚至业务访问带来的不利影响。同时，在解决这些问题的过程中，我们也遇到了很多未曾预料的挑战，这些挑战主要来自于Redis庞大的使用群体、多样化的使用场景，因此我们必须考虑用户在各种场景下使用MP-AOF可能遇到的问题。如兼容性、易用性以及对Redis代码尽可能的减少侵入性等。这都是Redis社区功能演进的重中之重。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;同时，MP-AOF的引入也为Redis的数据持久化带来了更多的想象空间。如在开启aof-use-rdb-preamble时，BASE AOF本质是一个RDB文件，因此我们在进行全量备份的时候无需在单独执行一次BGSAVE操作。直接备份BASE AOF即可。MP-AOF支持关闭自动清理HISTORY AOF的能力，因此那些历史的AOF有机会得以保留，并且目前Redis已经支持在AOF中加入timestamp annotation，因此基于这些我们甚至可以实现一个简单的PITR能力（ point-in-time recovery）。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;MP-AOF的设计原型来自于Tair for redis企业版[2]的binlog实现，这是一套在阿里云Tair服务上久经验证的核心功能，在这个核心功能上阿里云Tair成功构建了全球多活、PITR等企业级能力，使用户的更多业务场景需求得到满足。今天我们将这个核心能力贡献给Redis社区，希望社区用户也能享受这些企业级特性，并通过这些企业级特性更好的优化，创造自己的业务代码。有关MP-AOF的更多细节，请移步参考相关PR(#9788)，那里有更多的原始设计和完整代码。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[1]http://mysql.taobao.org/monthly/2018/12/06/&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[2]https://help.aliyun.com/document_detail/145956.html&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;hr/&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h2 data-spm-anchor-id=&quot;a2c6h.21258778.0.i0.c9e85b5dDxrhGF&quot;&gt;&lt;strong&gt;&lt;span&gt;搜索与推荐技术实战训练营&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;点击阅读原文查看详情&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/section&gt;&lt;/article&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>f7960d022211c8770f7335ed92414e61</guid>
<title>20000字详解大厂实时数仓建设</title>
<link>https://toutiao.io/k/gc9jet5</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;以下文章来源于zhisheng&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xqJ76ZLyAwBJqics7JOHibribibIVOr90dZmK4bGuA3O8r56TnJPereApbA73JOCNFOfouePBQrzr0YQShc1jTQFeQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;258&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.9444444444444444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/7QRTvkK2qC6jNJS1xw99aQZkRfiaXtVtDzxao4mIvdhHKL53TVBmhAx5OylXVXCBQm1RGRhjjYQYsWdelI1gr1Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;18&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;strong&gt;长按二维码关注&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;大数据领域必关注的公众号&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-type=&quot;jpeg&quot; data-w=&quot;800&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xqJ76ZLyAwBJqics7JOHibribibIVOr90dZm5FdKd7658Roicd4JibRwgU5xp64v17kBlcRSBubspF2IlxqeyE0rETAw/640?wx_fmt=jpeg&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一、实时数仓建设背景&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1. 实时需求日趋迫切&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目前各大公司的产品需求和内部决策对于数据实时性的要求越来越迫切，需要实时数仓的能力来赋能。传统离线数仓的数据时效性是 T+1，调度频率以天为单位，无法支撑实时场景的数据需求。即使能将调度频率设置成小时，也只能解决部分时效性要求不高的场景，对于实效性要求很高的场景还是无法优雅的支撑。因此实时使用数据的问题必须得到有效解决。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2. 实时技术日趋成熟&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时计算框架已经经历了三代发展，分别是：Storm、SparkStreaming、Flink，计算框架越来越成熟。一方面，实时任务的开发已经能通过编写 SQL 的方式来完成，在技术层面能很好地继承离线数仓的架构设计思想；另一方面，在线数据开发平台所提供的功能对实时任务开发、调试、运维的支持也日渐趋于成熟，开发成本逐步降低，有助于去做这件事。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;二、实时数仓建设目的&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1. 解决传统数仓的问题&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从目前数仓建设的现状来看，实时数仓是一个容易让人产生混淆的概念，根据传统经验分析，数仓有一个重要的功能，即能够记录历史。通常，数仓都是希望从业务上线的第一天开始有数据，然后一直记录到现在。但实时流处理技术，又是强调当前处理状态的一个技术，结合当前一线大厂的建设经验和滴滴在该领域的建设现状，我们尝试把公司内实时数仓建设的目的定位为，以数仓建设理论和实时技术，解决由于当前离线数仓数据时效性低解决不了的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现阶段我们要建设实时数仓的主要原因是：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;公司业务对于数据的实时性越来越迫切，需要有实时数据来辅助完成决策；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;实时数据建设没有规范，数据可用性较差，无法形成数仓体系，资源大量浪费；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据平台工具对整体实时开发的支持也日渐趋于成熟，开发成本降低。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2. 实时数仓的应用场景&lt;/span&gt;&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;实时 OLAP 分析；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;实时数据看板；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;实时业务监控；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;实时数据接口服务。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;三、实时数仓建设方案&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来我们分析下目前实时数仓建设比较好的几个案例，希望这些案例能够给大家带来一些启发。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1. 滴滴顺风车实时数仓案例&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;滴滴数据团队建设的实时数仓，基本满足了顺风车业务方在实时侧的各类业务需求，初步建立起顺风车实时数仓，完成了整体数据分层，包含明细数据和汇总数据，统一了 DWD 层，降低了大数据资源消耗，提高了数据复用性，可对外输出丰富的数据服务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数仓具体架构如下图所示：&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;amp;mid=2650247965&amp;amp;idx=1&amp;amp;sn=c4146fd59091d66eab755387ef1b94b1&amp;amp;chksm=8f5af941b82d705757b00aeafdcf64d00e2107d56d53b48ab6d2e1a8be168150fc60682bc501&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7675925925925926&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNiaFV99tyVLRfxWZS8nZoSX6KMGI3e4XgCvkYFfh1hLGq0Q0Nnv3Ghug/640?wx_fmt=jpeg&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从数据架构图来看，顺风车实时数仓和对应的离线数仓有很多类似的地方。例如分层结构；比如 ODS 层，明细层，汇总层，乃至应用层，他们命名的模式可能都是一样的。但仔细比较不难发现，两者有很多区别：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;与离线数仓相比，实时数仓的层次更少一些：&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;从目前建设离线数仓的经验来看，数仓的数据明细层内容会非常丰富，处理明细数据外一般还会包含轻度汇总层的概念，另外离线数仓中应用层数据在数仓内部，但实时数仓中，app 应用层数据已经落入应用系统的存储介质中，可以把该层与数仓的表分离；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;应用层少建设的好处：实时处理数据的时候，每建一个层次，数据必然会产生一定的延迟；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;汇总层少建的好处：在汇总统计的时候，往往为了容忍一部分数据的延迟，可能会人为的制造一些延迟来保证数据的准确。举例，在统计跨天相关的订单事件中的数据时，可能会等到 00:00:05 或者 00:00:10 再统计，确保 00:00 前的数据已经全部接受到位了，再进行统计。所以，汇总层的层次太多的话，就会更大的加重人为造成的数据延迟。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;与离线数仓相比，实时数仓的数据源存储不同：&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;在建设离线数仓的时候，目前滴滴内部整个离线数仓都是建立在 Hive 表之上。但是，在建设实时数仓的时候，同一份表，会使用不同的方式进行存储。比如常见的情况下，明细数据或者汇总数据都会存在 Kafka 里面，但是像城市、渠道等维度信息需要借助 Hbase，mysql 或者其他 KV 存储等数据库来进行存储。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来，根据顺风车实时数仓架构图，对每一层建设做具体展开：&lt;/p&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;1. ODS 贴源层建设&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据顺风车具体场景，目前顺风车数据源主要包括订单相关的 binlog 日志，冒泡和安全相关的 public 日志，流量相关的埋点日志等。这些数据部分已采集写入 kafka 或 ddmq 等数据通道中，部分数据需要借助内部自研同步工具完成采集，最终基于顺风车数仓 ods 层建设规范分主题统一写入 kafka 存储介质中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;命名规范：ODS 层实时数据源主要包括两种。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;一种是在离线采集时已经自动生产的 DDMQ 或者是 Kafka topic，这类型的数据命名方式为采集系统自动生成规范为：cn-binlog-数据库名-数据库名 eg：&lt;code&gt;cn-binlog-ihap_fangyuan-ihap_fangyuan&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一种是需要自己进行采集同步到 kafka topic 中，生产的 topic 命名规范同离线类似：ODS 层采用：&lt;code&gt;realtime_ods_binlog_{源系统库/表名}/ods_log_{日志名} eg: realtime_ods_binlog_ihap_fangyuan&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;2. DWD 明细层建设&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据顺风车业务过程作为建模驱动，基于每个具体的业务过程特点，构建最细粒度的明细层事实表；结合顺风车分析师在离线侧的数据使用特点，将明细事实表的某些重要维度属性字段做适当冗余，完成宽表化处理，之后基于当前顺风车业务方对实时数据的需求重点，重点建设交易、财务、体验、安全、流量等几大模块；该层的数据来源于 ODS 层，通过大数据架构提供的 Stream SQL 完成 ETL 工作，对于 binlog 日志的处理主要进行简单的数据清洗、处理数据漂移和数据乱序，以及可能对多个 ODS 表进行 Stream Join，对于流量日志主要是做通用的 ETL 处理和针对顺风车场景的数据过滤，完成非结构化数据的结构化处理和数据的分流；该层的数据除了存储在消息队列 Kafka 中，通常也会把数据实时写入 Druid 数据库中，供查询明细数据和作为简单汇总数据的加工数据源。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;命名规范：DWD 层的表命名使用英文小写字母，单词之间用下划线分开，总长度不能超过 40 个字符，并且应遵循下述规则：&lt;code&gt;realtime_dwd_{业务/pub}_{数据域缩写}_[{业务过程缩写}]_[{自定义表命名标签缩写}]&lt;/code&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;{业务/pub}：参考业务命名&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;{数据域缩写}：参考数据域划分部分&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;{自定义表命名标签缩写}：实体名称可以根据数据仓库转换整合后做一定的业务抽象的名称，该名称应该准确表述实体所代表的业务含义&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;样例：realtime_dwd_trip_trd_order_base&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;3. DIM 层&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;公共维度层，基于维度建模理念思想，建立整个业务过程的一致性维度，降低数据计算口径和算法不统一风险；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;DIM 层数据来源于两部分：一部分是 Flink 程序实时处理 ODS 层数据得到，另外一部分是通过离线任务出仓得到；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;DIM 层维度数据主要使用 MySQL、Hbase、fusion(滴滴自研 KV 存储) 三种存储引擎，对于维表数据比较少的情况可以使用 MySQL，对于单条数据大小比较小，查询 QPS 比较高的情况，可以使用 fusion 存储，降低机器内存资源占用，对于数据量比较大，对维表数据变化不是特别敏感的场景，可以使用 HBase 存储。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;命名规范：DIM 层的表命名使用英文小写字母，单词之间用下划线分开，总长度不能超过 30 个字符，并且应遵循下述规则：&lt;code&gt;dim_{业务/pub}_{维度定义}[_{自定义命名标签}]&lt;/code&gt;：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;{业务/pub}：参考业务命名&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;{维度定义}：参考维度命名&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;{自定义表命名标签缩写}：实体名称可以根据数据仓库转换整合后做一定的业务抽象的名称，该名称应该准确表述实体所代表的业务含义&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;样例：dim_trip_dri_base&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在建设顺风车实时数仓的汇总层的时候，跟顺风车离线数仓有很多一样的地方，但其具体技术实现会存在很大不同。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一：对于一些共性指标的加工，比如 pv，uv，订单业务过程指标等，我们会在汇总层进行统一的运算，确保关于指标的口径是统一在一个固定的模型中完成。对于一些个性指标，从指标复用性的角度出发，确定唯一的时间字段，同时该字段尽可能与其他指标在时间维度上完成拉齐，例如行中异常订单数需要与交易域指标在事件时间上做到拉齐。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二：在顺风车汇总层建设中，需要进行多维的主题汇总，因为实时数仓本身是面向主题的，可能每个主题会关心的维度都不一样，所以需要在不同的主题下，按照这个主题关心的维度对数据进行汇总，最后来算业务方需要的汇总指标。在具体操作中，对于 pv 类指标使用 Stream SQL 实现 1 分钟汇总指标作为最小汇总单位指标，在此基础上进行时间维度上的指标累加；对于 uv 类指标直接使用 druid 数据库作为指标汇总容器，根据业务方对汇总指标的及时性和准确性的要求，实现相应的精确去重和非精确去重。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第三：汇总层建设过程中，还会涉及到衍生维度的加工。在顺风车券相关的汇总指标加工中我们使用 Hbase 的版本机制来构建一个衍生维度的拉链表，通过事件流和 Hbase 维表关联的方式得到实时数据当时的准确维度&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;命名规范：DWM 层的表命名使用英文小写字母，单词之间用下划线分开，总长度不能超过 40 个字符，并且应遵循下述规则：&lt;code&gt;realtime_dwm_{业务/pub}_{数据域缩写}_{数据主粒度缩写}_[{自定义表命名标签缩写}]_{统计时间周期范围缩写}&lt;/code&gt;：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;{业务/pub}：参考业务命名&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;{数据域缩写}：参考数据域划分部分&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;{数据主粒度缩写}：指数据主要粒度或数据域的缩写，也是联合主键中的主要维度&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;{自定义表命名标签缩写}：实体名称可以根据数据仓库转换整合后做一定的业务抽象的名称，该名称应该准确表述实体所代表的业务含义&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;{统计时间周期范围缩写}：1d:天增量；td:天累计(全量)；1h:小时增量；th:小时累计(全量)；1min:分钟增量；tmin:分钟累计(全量)&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;样例：&lt;code&gt;realtime_dwm_trip_trd_pas_bus_accum_1min&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;ol start=&quot;5&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;APP 应用层&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该层主要的工作是把实时汇总数据写入应用系统的数据库中，包括用于大屏显示和实时 OLAP 的 Druid 数据库(该数据库除了写入应用数据，也可以写入明细数据完成汇总指标的计算)中，用于实时数据接口服务的 Hbase 数据库，用于实时数据产品的 mysql 或者 redis 数据库中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;命名规范：基于实时数仓的特殊性不做硬性要求。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2. 快手实时数仓场景化案例&lt;/span&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;1) 目标及难点&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNbzngMUuIqVgvtxmBOtmsxMVoYAF1mvZCwB02XWlbKwT2w2iaHrnBwkA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;目标&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先由于是做数仓，因此希望所有的实时指标都有离线指标去对应，要求实时指标和离线指标整体的数据差异在 1% 以内，这是最低标准。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其次是数据延迟，其 SLA 标准是活动期间所有核心报表场景的数据延迟不能超过 5 分钟，这 5 分钟包括作业挂掉之后和恢复时间，如果超过则意味着 SLA 不达标。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后是稳定性，针对一些场景，比如作业重启后，我们的曲线是正常的，不会因为作业重启导致指标产出一些明显的异常。&lt;/p&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;难点&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一个难点是数据量大。每天整体的入口流量数据量级大概在万亿级。在活动如春晚的场景，QPS 峰值能达到亿 / 秒。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二个难点是组件依赖比较复杂。可能这条链路里有的依赖于 Kafka，有的依赖 Flink，还有一些依赖 KV 存储、RPC 接口、OLAP 引擎等，我们需要思考在这条链路里如何分布，才能让这些组件都能正常工作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第三个难点是链路复杂。目前我们有 200+ 核心业务作业，50+ 核心数据源，整体作业超过 1000。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;2) 实时数仓 - 分层模型&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于上面三个难点，来看一下数仓架构：&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;amp;mid=2650247940&amp;amp;idx=1&amp;amp;sn=616e435f6ccba7f305f724b6bcc8bbf5&amp;amp;chksm=8f5af958b82d704e6610a9f097196a03cc8b8d40b842ae6d3bf0d40d9dca46cbf348afa3ec2f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNe6jS5nnH2wZWIjep0ZUDO7eQRBUldvgkLGuSfx2hopEDgwaYWouGeg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如上所示：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最下层有三个不同的数据源，分别是客户端日志、服务端日志以及 Binlog 日志；在公共基础层分为两个不同的层次，一个是 DWD 层，做明细数据，另一个是 DWS 层，做公共聚合数据，DIM 是我们常说的维度。我们有一个基于离线数仓的主题预分层，这个主题预分层可能包括流量、用户、设备、视频的生产消费、风控、社交等。DWD 层的核心工作是标准化的清洗；DWS 层是把维度的数据和 DWD 层进行关联，关联之后生成一些通用粒度的聚合层次。再往上是应用层，包括一些大盘的数据，多维分析的模型以及业务专题数据；最上面是场景。整体过程可以分为三步：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一步是做业务数据化，相当于把业务的数据接进来；第二步是数据资产化，意思是对数据做很多的清洗，然后形成一些规则有序的数据；第三步是数据业务化，可以理解数据在实时数据层面可以反哺业务，为业务数据价值建设提供一些赋能。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;3) 实时数仓 - 保障措施&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于上面的分层模型，来看一下整体的保障措施：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNZhozq4X4UaKRibdtText8ImafufdwM8L2evHUK7qxo5mn3xFOtt7nnw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;保障层面分为三个不同的部分，分别是质量保障，时效保障以及稳定保障。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们先看蓝色部分的质量保障。针对质量保障，可以看到在数据源阶段，做了如数据源的乱序监控，这是我们基于自己的 SDK 的采集做的，以及数据源和离线的一致性校准。研发阶段的计算过程有三个阶段，分别是研发阶段、上线阶段和服务阶段。研发阶段可能会提供一个标准化的模型，基于这个模型会有一些 Benchmark，并且做离线的比对验证，保证质量是一致的；上线阶段更多的是服务监控和指标监控；在服务阶段，如果出现一些异常情况，先做 Flink 状态拉起，如果出现了一些不符合预期的场景，我们会做离线的整体数据修复。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二个是时效性保障。针对数据源，我们把数据源的延迟情况也纳入监控。在研发阶段其实还有两个事情：首先是压测，常规的任务会拿最近 7 天或者最近 14 天的峰值流量去看它是否存在任务延迟的情况；通过压测之后，会有一些任务上线和重启性能评估，相当于按照 CP 恢复之后，重启的性能是什么样子。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后一个是稳定保障，这在大型活动中会做得比较多，比如切换演练和分级保障。我们会基于之前的压测结果做限流，目的是保障作业在超过极限的情况下，仍然是稳定的，不会出现很多的不稳定或者 CP 失败的情况。之后我们会有两种不同的标准，一种是冷备双机房，另外一种是热备双机房。冷备双机房是：当一个单机房挂掉，我们会从另一个机房去拉起；热备双机房：相当于同样一份逻辑在两个机房各部署一次。以上就是我们整体的保障措施。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;3) 快手场景问题及解决方案&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1. PV/UV 标准化&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.1 场景&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一个问题是 PV/UV 标准化，这里有三个截图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNwtvY1PDgaFGeNY2UltDicZVgic6CsWXsVpYfGW42ibg4HC590JFialnoTA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一张图是春晚活动的预热场景，相当于是一种玩法，第二和第三张图是春晚当天的发红包活动和直播间截图。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在活动进行过程中，我们发现 60~70% 的需求是计算页面里的信息，如：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;这个页面来了多少人，或者有多少人点击进入这个页面；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;活动一共来了多少人；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;页面里的某一个挂件，获得了多少点击、产生了多少曝光。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1.2 方案&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;抽象一下这个场景就是下面这种 SQL：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNQxdicu2CqosZyytqL9oL8KfJDLpNicMsYU0CXhKoS0qh2C1hredYD0Xg/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单来说，就是从一张表做筛选条件，然后按照维度层面做聚合，接着产生一些 Count 或者 Sum 操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于这种场景，我们最开始的解决方案如上图右边所示。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们用到了 Flink SQL 的 Early Fire 机制，从 Source 数据源取数据，之后做了 DID 的分桶。比如最开始紫色的部分按这个做分桶，先做分桶的原因是防止某一个 DID 存在热点的问题。分桶之后会有一个叫做 Local Window Agg 的东西，相当于数据分完桶之后把相同类型的数据相加。Local Window Agg 之后再按照维度进行 Global Window Agg 的合桶，合桶的概念相当于按照维度计算出最终的结果。Early Fire 机制相当于在 Local Window Agg 开一个天级的窗口，然后每分钟去对外输出一次。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个过程中我们遇到了一些问题，如上图左下角所示。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在代码正常运行的情况下是没有问题的，但如果整体数据存在延迟或者追溯历史数据的情况，比如一分钟 Early Fire 一次，因为追溯历史的时候数据量会比较大，所以可能导致 14:00 追溯历史，直接读到了 14:02 的数据，而 14:01 的那个点就被丢掉了，丢掉了以后会发生什么？&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNWShOs4xWKQBuDLEupCWtF7A31fQkVibX8fdibwoasrmMLYWbFHGzsU4w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这种场景下，图中上方的曲线为 Early Fire 回溯历史数据的结果。横坐标是分钟，纵坐标是截止到当前时刻的页面 UV，我们发现有些点是横着的，意味着没有数据结果，然后一个陡增，然后又横着的，接着又一个陡增，而这个曲线的预期结果其实是图中下方那种平滑的曲线。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了解决这个问题，我们用到了 Cumulate Window 的解决方案，这个解决方案在 Flink 1.13 版本里也有涉及，其原理是一样的。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNevgvLQEXcKqr3icbY1cdj3oicNDfBPjj08p3cO6oaI4kaOvQZLdeTRTw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据开一个大的天级窗口，大窗口下又开了一个小的分钟级窗口，数据按数据本身的 Row Time 落到分钟级窗口。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Watermark 推进过了窗口的 event_time，它会进行一次下发的触发，通过这种方式可以解决回溯的问题，数据本身落在真实的窗口， Watermark 推进，在窗口结束后触发。此外，这种方式在一定程度上能够解决乱序的问题。比如它的乱序数据本身是一个不丢弃的状态，会记录到最新的累计数据。最后是语义一致性，它会基于事件时间，在乱序不严重的情况下，和离线计算出来的结果一致性是相当高的。以上是 PV/UV 一个标准化的解决方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2. DAU 计算&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.1 背景介绍&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面介绍一下 DAU 计算：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNkjapxkPvicTjuSXibiacyHSuL09Cz4XULvXS5ia7OgLbQ3rOX9skxwlECw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们对于整个大盘的活跃设备、新增设备和回流设备有比较多的监控。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;活跃设备指的是当天来过的设备；新增设备指的是当天来过且历史没有来过的设备；回流设备指的是当天来过且 N 天内没有来过的设备。但是我们计算过程之中可能需要 5~8 个这样不同的 Topic 去计算这几个指标。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们看一下离线过程中，逻辑应该怎么算。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先我们先算活跃设备，把这些合并到一起，然后做一个维度下的天级别去重，接着再去关联维度表，这个维度表包括设备的首末次时间，就是截止到昨天设备首次访问和末次访问的时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;得到这个信息之后，我们就可以进行逻辑计算，然后我们会发现新增和回流的设备其实是活跃设备里打的一个子标签。新增设备就是做了一个逻辑处理，回流设备是做了 30 天的逻辑处理，基于这样的解决方案，我们能否简单地写一个 SQL 去解决这个问题？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实我们最开始是这么做的，但遇到了一些问题：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一个问题是：数据源是 6~8 个，而且我们大盘的口径经常会做微调，如果是单作业的话，每次微调的过程之中都要改，单作业的稳定性会非常差；第二个问题是：数据量是万亿级，这会导致两个情况，首先是这个量级的单作业稳定性非常差，其次是实时关联维表的时候用的 KV 存储，任何一个这样的 RPC 服务接口，都不可能在万亿级数据量的场景下保证服务稳定性；第三个问题是：我们对于时延要求比较高，要求时延小于一分钟。整个链路要避免批处理，如果出现了一些任务性能的单点问题，我们还要保证高性能和可扩容。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.2 技术方案&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对以上问题，介绍一下我们是怎么做的：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHN7lNxLW0ciczwsuXuYnQgtXJEUvickqlvvicV11XLCOpJYNzD4FrBzj8kg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如上图的例子，第一步是对 A B C 这三个数据源，先按照维度和 DID 做分钟级别去重，分别去重之后得到三个分钟级别去重的数据源，接着把它们 Union 到一起，然后再进行同样的逻辑操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这相当于我们数据源的入口从万亿变到了百亿的级别，分钟级别去重之后再进行一个天级别的去重，产生的数据源就可以从百亿变成了几十亿的级别。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在几十亿级别数据量的情况下，我们再去关联数据服务化，这就是一种比较可行的状态，相当于去关联用户画像的 RPC 接口，得到 RPC 接口之后，最终写入到了目标 Topic。这个目标 Topic 会导入到 OLAP 引擎，供给多个不同的服务，包括移动版服务，大屏服务，指标看板服务等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个方案有三个方面的优势，分别是稳定性、时效性和准确性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先是稳定性。松耦合可以简单理解为当数据源 A 的逻辑和数据源 B 的逻辑需要修改时，可以单独修改。第二是任务可扩容，因为我们把所有逻辑拆分得非常细粒度，当一些地方出现了如流量问题，不会影响后面的部分，所以它扩容比较简单，除此之外还有服务化后置和状态可控。其次是时效性，我们做到毫秒延迟，并且维度丰富，整体上有 20+ 的维度做多维聚合。最后是准确性，我们支持数据验证、实时监控、模型出口统一等。此时我们遇到了另外一个问题 - 乱序。对于上方三个不同的作业，每一个作业重启至少会有两分钟左右的延迟，延迟会导致下游的数据源 Union 到一起就会有乱序。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.3 延迟计算方案&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;遇到上面这种有乱序的情况下，我们要怎么处理？&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNPHJ0ib7QOLxAACngyxWzvq9O2VFouKKJ1YWLqG6BPkIFYEvibHK8Lb1g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们总共有三种处理方案：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一种解决方案是用 “did + 维度 + 分钟” 进行去重，Value 设为 “是否来过”。比如同一个 did，04:01 来了一条，它会进行结果输出。同样的，04:02 和 04:04 也会进行结果输出。但如果 04：01 再来，它就会丢弃，但如果 04:00 来，依旧会进行结果输出。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个解决方案存在一些问题，因为我们按分钟存，存 20 分钟的状态大小是存 10 分钟的两倍，到后面这个状态大小有点不太可控，因此我们又换了解决方案 2。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二种解决方案，我们的做法会涉及到一个假设前提，就是假设不存在数据源乱序的情况。在这种情况下，key 存的是 “did + 维度”，Value 为 “时间戳”，它的更新方式如上图所示。04:01 来了一条数据，进行结果输出。04:02 来了一条数据，如果是同一个 did，那么它会更新时间戳，然后仍然做结果输出。04：04 也是同样的逻辑，然后将时间戳更新到 04：04，如果后面来了一条 04：01 的数据，它发现时间戳已经更新到 04:04，它会丢弃这条数据。这样的做法大幅度减少了本身所需要的一些状态，但是对乱序是零容忍，不允许发生任何乱序的情况，由于我们不好解决这个问题，因此我们又想出了解决方案 3。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;方案 3 是在方案 2 时间戳的基础之上，加了一个类似于环形缓冲区，在缓冲区之内允许乱序。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如 04:01 来了一条数据，进行结果输出；04:02 来了一条数据，它会把时间戳更新到 04:02，并且会记录同一个设备在 04:01 也来过。如果 04:04 再来了一条数据，就按照相应的时间差做一个位移，最后通过这样的逻辑去保障它能够容忍一定的乱序。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综合来看这三个方案：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;方案 1 在容忍 16 分钟乱序的情况下，单作业的状态大小在 480G 左右。这种情况虽然保证了准确性，但是作业的恢复和稳定性是完全不可控的状态，因此我们还是放弃了这个方案；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;方案 2 是 30G 左右的状态大小，对于乱序 0 容忍，但是数据不准确，由于我们对准确性的要求非常高，因此也放弃了这个方案；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;方案 3 的状态跟方案 1 相比，它的状态虽然变化了但是增加的不多，而且整体能达到跟方案 1 同样的效果。方案 3 容忍乱序的时间是 16 分钟，我们正常更新一个作业的话，10 分钟完全足够重启，因此最终选择了方案 3。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;3. 运营场景&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.1 背景介绍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNsFCIFF1mrFLSh3IR855WWJicnzscQURJNfjO5w8Qp0ET3ozsyZvDyeA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运营场景可分为四个部分：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一个是数据大屏支持，包括单直播间的分析数据和大盘的分析数据，需要做到分钟级延迟，更新要求比较高；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二个是直播看板支持，直播看板的数据会有特定维度的分析，特定人群支持，对维度丰富性要求比较高；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第三个是数据策略榜单，这个榜单主要是预测热门作品、爆款，要求的是小时级别的数据，更新要求比较低；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第四个是 C 端实时指标展示，查询量比较大，但是查询模式比较固定。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面进行分析这 4 种不同的状态产生的一些不同的场景。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNm6ukIeyLmMeK4DY11fgmND9c55JIHckofXWSTcDe24aokzjfCVHNnQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前 3 种基本没有什么差别，只是在查询模式上，有的是特定业务场景，有的是通用业务场景。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对第 3 种和第 4 种，它对于更新的要求比较低，对于吞吐的要求比较高，过程之中的曲线也不要求有一致性。第 4 种查询模式更多的是单实体的一些查询，比如去查询内容，会有哪些指标，而且对 QPS 要求比较高。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.2 技术方案&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对上方 4 种不同的场景，我们是如何去做的？&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;amp;mid=2650247940&amp;amp;idx=1&amp;amp;sn=616e435f6ccba7f305f724b6bcc8bbf5&amp;amp;chksm=8f5af958b82d704e6610a9f097196a03cc8b8d40b842ae6d3bf0d40d9dca46cbf348afa3ec2f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNvhsZdgUBQ13CEdKPpyuFj37lx9mDQ9yv1iaicickg1RgM4R9I2R8lLxag/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先看一下基础明细层 (图中左方)，数据源有两条链路，其中一条链路是消费的流，比如直播的消费信息，还有观看 / 点赞 / 评论。经过一轮基础清洗，然后做维度管理。上游的这些维度信息来源于 Kafka，Kafka 写入了一些内容的维度，放到了 KV 存储里边，包括一些用户的维度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这些维度关联了之后，最终写入 Kafka 的 DWD 事实层，这里为了做性能的提升，我们做了二级缓存的操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如图中上方，我们读取 DWD 层的数据然后做基础汇总，核心是窗口维度聚合生成 4 种不同粒度的数据，分别是大盘多维汇总 topic、直播间多维汇总 topic、作者多维汇总 topic、用户多维汇总 topic，这些都是通用维度的数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如图中下方，基于这些通用维度数据，我们再去加工个性化维度的数据，也就是 ADS 层。拿到了这些数据之后会有维度扩展，包括内容扩展和运营维度的拓展，然后再去做聚合，比如会有电商实时 topic，机构服务实时 topic 和大 V 直播实时 topic。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分成这样的两个链路会有一个好处：一个地方处理的是通用维度，另一个地方处理的是个性化的维度。通用维度保障的要求会比较高一些，个性化维度则会做很多个性化的逻辑。如果这两个耦合在一起的话，会发现任务经常出问题，并且分不清楚哪个任务的职责是什么，构建不出这样的一个稳定层。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如图中右方，最终我们用到了三种不同的引擎。简单来说就是 Redis 查询用到了 C 端的场景，OLAP 查询用到了大屏、业务看板的场景。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3. 腾讯看点实时数仓案例&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;腾讯看点业务为什么要构建实时数仓，因为原始的上报数据量非常大，一天上报峰值就有上万亿条。而且上报格式混乱。缺乏内容维度信息、用户画像信息，下游没办法直接使用。而我们提供的实时数仓，是根据腾讯看点信息流的业务场景，进行了内容维度的关联，用户画像的关联，各种粒度的聚合，下游可以非常方便的使用实时数据。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;1) 方案选型&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5078125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNicYBxniceexgeJvsrcWw7rGRs7FSuK39FXGibsakoibUSbzZtvJVKZ6hXA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那就看下我们多维实时数据分析系统的方案选型，选型我们对比了行业内的领先方案，选择了最符合我们业务场景的方案。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;第一块是实时数仓的选型，我们选择的是业界比较成熟的 Lambda 架构，他的优点是灵活性高、容错性高、成熟度高和迁移成本低；缺点是实时、离线数据用两套代码，可能会存在一个口径修改了，另一个没改的问题，我们每天都有做数据对账的工作，如果有异常会进行告警。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;第二块是实时计算引擎选型，因为 Flink 设计之初就是为了流处理，SparkStreaming 严格来说还是微批处理，Strom 用的已经不多了。再看 Flink 具有 Exactly-once 的准确性、轻量级 Checkpoint 容错机制、低延时高吞吐和易用性高的特点，我们选择了 Flink 作为实时计算引擎。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;第三块是实时存储引擎，我们的要求就是需要有维度索引、支持高并发、预聚合、高性能实时多维 OLAP 查询。可以看到，Hbase、Tdsql 和 ES 都不能满足要求，Druid 有一个缺陷，它是按照时序划分 Segment，无法将同一个内容，存放在同一个 Segment 上，计算全局 TopN 只能是近似值，所以我们选择了最近两年大火的 MPP 数据库引擎 ClickHouse。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;2) 设计目标与设计难点&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4578125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNTKAkeuELficRH6l32zDlibrVwYq8EdSyibrj9T5aGdEyXcjLl0UQvDpwQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们多维实时数据分析系统分为三大模块&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;实时计算引擎&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;实时存储引擎&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;App 层&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;难点主要在前两个模块：实时计算引擎和实时存储引擎。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;千万级/s 的海量数据如何实时接入，并且进行极低延迟维表关联。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;实时存储引擎如何支持高并发写入、高可用分布式和高性能索引查询，是比较难的。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这几个模块的具体实现，看一下我们系统的架构设计。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;3) 架构设计&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.50625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNbXTmJ30yibCfApBHSr86iaYzldueYkBoyCWuLlxpxsLNbQadInueX5icQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前端采用的是开源组件 Ant Design，利用了 Nginx 服务器，部署静态页面，并反向代理了浏览器的请求到后台服务器上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后台服务是基于腾讯自研的 RPC 后台服务框架写的，并且会进行一些二级缓存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时数仓部分，分为了接入层、实时计算层和实时数仓存储层。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;接入层主要是从千万级/s 的原始消息队列中，拆分出不同行为数据的微队列，拿看点的视频来说，拆分过后，数据就只有百万级/s 了；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;实时计算层主要负责，多行行为流水数据进行行转列，实时关联用户画像数据和内容维度数据；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;实时数仓存储层主要是设计出符合看点业务的，下游好用的实时消息队列。我们暂时提供了两个消息队列，作为实时数仓的两层。一层 DWM 层是内容 ID-用户 ID 粒度聚合的，就是一条数据包含内容 ID-用户 ID 还有 B 侧内容数据、C 侧用户数据和用户画像数据；另一层是 DWS 层，是内容 ID 粒度聚合的，一条数据包含内容 ID，B 侧数据和 C 侧数据。可以看到内容 ID-用户 ID 粒度的消息队列流量进一步减小到十万级/s，内容 ID 粒度的更是万级/s，并且格式更加清晰，维度信息更加丰富。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时存储部分分为实时写入层、OLAP 存储层和后台接口层。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;实时写入层主要是负责 Hash 路由将数据写入；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;OLAP 存储层利用 MPP 存储引擎，设计符合业务的索引和物化视图，高效存储海量数据；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;后台接口层提供高效的多维实时查询接口。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;4) 实时计算&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个系统最复杂的两块，实时计算和实时存储。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先介绍实时计算部分：分为实时关联和实时数仓。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1. 实时高性能维表关联&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4890625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNDSuSFpeqJRchBRCnboicQGNTbtQs2NrnKE5k3H85fsroa72QBKw8WrA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时维表关联这一块难度在于 &lt;strong&gt;百万级/s&lt;/strong&gt; 的实时数据流，如果直接去关联 HBase，1 分钟的数据，关联完 HBase 耗时是小时级的，会导致数据延迟严重。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们提出了几个解决方案：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;第一个是&lt;/strong&gt;，在 Flink 实时计算环节，先按照 1 分钟进行了窗口聚合，将窗口内多行行为数据转一行多列的数据格式，经过这一步操作，原本小时级的关联耗时下降到了十几分钟，但是还是不够的。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;第二个是&lt;/strong&gt;，在访问 HBase 内容之前设置一层 Redis 缓存，因为 1000 条数据访问 HBase 是秒级的，而访问 Redis 是毫秒级的，访问 Redis 的速度基本是访问 HBase 的 1000 倍。为了防止过期的数据浪费缓存，缓存过期时间设置成 24 小时，同时通过监听写 HBase Proxy 来保证缓存的一致性。这样将访问时间从十几分钟变成了秒级。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;第三个是&lt;/strong&gt;，上报过程中会上报不少非常规内容 ID，这些内容 ID 在内容 HBase 中是不存储的，会造成缓存穿透的问题。所以在实时计算的时候，我们直接过滤掉这些内容 ID，防止缓存穿透，又减少一些时间。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;第四个是&lt;/strong&gt;，因为设置了定时缓存，会引入一个缓存雪崩的问题。为了防止雪崩，我们在实时计算中，进行了削峰填谷的操作，错开设置缓存的时间。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到，优化前后，数据量从百亿级减少到了十亿级，耗时从小时级减少到了数十秒，减少 99%。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2. 下游提供服务&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.50625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHN14wqwiasMicQoVwOjt0Qb2n14u6hfpg5XjueXxnXl6BsxVFiar79neXow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时数仓的难度在于：它处于比较新的领域，并且各个公司各个业务差距比较大，怎么能设计出方便，好用，符合看点业务场景的实时数仓是有难度的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先看一下实时数仓做了什么，实时数仓对外就是几个消息队列，不同的消息队列里面存放的就是不同聚合粒度的实时数据，包括内容 ID、用户 ID、C 侧行为数据、B 侧内容维度数据和用户画像数据等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们是怎么搭建实时数仓的，就是上面介绍的实时计算引擎的输出，放到消息队列中保存，可以提供给下游多用户复用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以看下，在我们建设实时数据仓库前后，开发一个实时应用的区别。没有数仓的时候，我们需要消费千万级/s 的原始队列，进行复杂的数据清洗，然后再进行用户画像关联、内容维度关联，才能拿到符合要求格式的实时数据，开发和扩展的成本都会比较高，如果想开发一个新的应用，又要走一遍这个流程。有了数仓之后，如果想开发内容 ID 粒度的实时应用，就直接申请 TPS 万级/s 的 DWS 层的消息队列。开发成本变低很多，资源消耗小很多，可扩展性也强很多。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看个实际例子，开发我们系统的实时数据大屏，原本需要进行如上所有操作，才能拿到数据。现在只需要消费 DWS 层消息队列，写一条 Flink SQL 即可，仅消耗 2 个 CPU 核心，1G 内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到，以 50 个消费者为例，建立实时数仓前后，下游开发一个实时应用，可以减少 98%的资源消耗。包括计算资源，存储资源，人力成本和开发人员学习接入成本等等。并且消费者越多，节省越多。就拿 Redis 存储这一部分来说，一个月就能省下上百万人民币。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;5) 实时存储&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;介绍完实时计算，再来介绍实时存储。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这块分为三个部分来介绍&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;第一是 分布式-高可用&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第二是 海量数据-写入&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第三是 高性能-查询&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1. 分布式-高可用&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.378125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNVtXs59ypZCnU27Z4eBA15oPnOIeSmYJoLnS4kADNibMMMhuQt2UBc5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们这里听取的是 Clickhouse 官方的建议，借助 ZK 实现高可用的方案。数据写入一个分片，仅写入一个副本，然后再写 ZK，通过 ZK 告诉同一个分片的其他副本，其他副本再过来拉取数据，保证数据一致性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里没有选用消息队列进行数据同步，是因为 ZK 更加轻量级。而且写的时候，任意写一个副本，其它副本都能够通过 ZK 获得一致的数据。而且就算其它节点第一次来获取数据失败了，后面只要发现它跟 ZK 上记录的数据不一致，就会再次尝试获取数据，保证一致性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2. 海量数据-写入&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5078125&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNLuUW3Vmgsic6XfsDWEg0Gm03pR96wyZfHZ7rkYia7E3iavMgibiaTlYA87g/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据写入遇到的第一个问题是，海量数据直接写入 Clickhouse 的话，会导致 ZK 的 QPS 太高，解决方案是改用 Batch 方式写入。Batch 设置多大呢，Batch 太小的话缓解不了 ZK 的压力，Batch 也不能太大，不然上游内存压力太大，通过实验，最终我们选用了大小几十万的 Batch。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二个问题是，随着数据量的增长，单 QQ 看点的视频内容每天可能写入百亿级的数据，默认方案是写一张分布式表，这就会造成单台机器出现磁盘的瓶颈，尤其是 Clickhouse 底层运用的是 Mergetree，原理类似于 HBase、RocketsDB 的底层 LSM-Tree。在合并的过程中会存在写放大的问题，加重磁盘压力。峰值每分钟几千万条数据，写完耗时几十秒，如果正在做 Merge，就会阻塞写入请求，查询也会非常慢。我们做的两个优化方案：一是对磁盘做 Raid，提升磁盘的 IO；二是在写入之前进行分表，直接分开写入到不同的分片上，磁盘压力直接变为 1/N。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第三个问题是，虽然我们写入按照分片进行了划分，但是这里引入了一个分布式系统常见的问题，就是局部的 Top 并非全局 Top 的问题。比如同一个内容 ID 的数据落在了不同的分片上，计算全局 Top100 阅读的内容 ID，有一个内容 ID 在分片 1 上是 Top100，但是在其它分片上不是 Top100，导致汇总的时候，会丢失一部分数据，影响最终结果。我们做的优化是在写入之前加上一层路由，将同一个内容 ID 的记录，全部路由到同一个分片上，解决了该问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;介绍完写入，下一步介绍 Clickhouse 的高性能存储和查询。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;3. 高性能-存储-查询&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Clickhouse 高性能查询的一个关键点是稀疏索引。稀疏索引这个设计就很有讲究，设计得好可以加速查询，设计不好反而会影响查询效率。我根据我们的业务场景，因为我们的查询大部分都是时间和内容 ID 相关的，比如说，某个内容，过去 N 分钟在各个人群表现如何？我按照日期，分钟粒度时间和内容 ID 建立了稀疏索引。针对某个内容的查询，建立稀疏索引之后，可以减少 99%的文件扫描。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有一个问题就是，我们现在数据量太大，维度太多。拿 QQ 看点的视频内容来说，一天流水有上百亿条，有些维度有几百个类别。如果一次性把所有维度进行预聚合，数据量会指数膨胀，查询反而变慢，并且会占用大量内存空间。我们的优化，针对不同的维度，建立对应的预聚合物化视图，用空间换时间，这样可以缩短查询的时间。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3859375&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNcou54djSYLJQt0MBe7x1zRN4SFvMsdx9iasNL9VRDgQLQEkazOiahbpw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分布式表查询还会有一个问题，查询单个内容 ID 的信息，分布式表会将查询下发到所有的分片上，然后再返回查询结果进行汇总。实际上，因为做过路由，一个内容 ID 只存在于一个分片上，剩下的分片都在空跑。针对这类查询，我们的优化是后台按照同样的规则先进行路由，直接查询目标分片，这样减少了 N-1/N 的负载，可以大量缩短查询时间。而且由于我们是提供的 OLAP 查询，数据满足最终一致性即可，通过主从副本读写分离，可以进一步提升性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在后台还做了一个 1 分钟的数据缓存，针对相同条件查询，后台就直接返回了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;4. 扩容&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里再介绍一下我们的扩容的方案，调研了业内的一些常见方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如 HBase，原始数据都存放在 HDFS 上，扩容只是 Region Server 扩容，不涉及原始数据的迁移。但是 Clickhouse 的每个分片数据都是在本地，是一个比较底层存储引擎，不能像 HBase 那样方便扩容。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 是哈希槽这种类似一致性哈希的方式，是比较经典分布式缓存的方案。Redis slot 在 Rehash 的过程中虽然存在短暂的 ask 读不可用，但是总体来说迁移是比较方便的，从原 h[0]迁移到 h[1]，最后再删除 h[0]。但是 Clickhouse 大部分都是 OLAP 批量查询，不是点查，而且由于列式存储，不支持删除的特性，一致性哈希的方案不是很适合。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目前扩容的方案是，另外消费一份数据，写入新 Clickhouse 集群，两个集群一起跑一段时间，因为实时数据就保存 3 天，等 3 天之后，后台服务直接访问新集群。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4. 有赞实时数仓案例&lt;/span&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;1) 分层设计&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;传统离线数仓的分层设计大家都很熟悉，为了规范的组织和管理数据，层级划分会比较多，在一些复杂逻辑处理场景还会引入临时层落地中间结果以方便下游加工处理。实时数仓考虑到时效性问题，分层设计需要尽量精简，降低中间流程出错的可能性，不过总体而言，实时数仓还是会参考离线数仓的分层思想来设计。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时数仓分层架构如下图所示 ：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6682464454976303&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNnpxTTDHTNnhEN29nAxUM2aRNhzHKxK0C5hEIZfvw8KZAfYUnwN50kA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;844&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;- ODS（实时数据接入层）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ODS 层，即实时数据接入层，通过数据采集工具收集各个业务系统的实时数据，对非结构化的数据进行结构化处理，保存原始数据，几乎不过滤数据；该层数据的主要来源有三个部分：第一部分是业务方创建的 NSQ 消息，第二部分是业务数据库的 Binlog 日志，第三部分是埋点日志和应用程序日志，以上三部分的实时数据最终统一写入 Kafka 存储介质中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ODS 层表命名规范：部门名称.应用名称.数仓层级&lt;span&gt;主题域前缀&lt;/span&gt;数据库名/消息名&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：接入业务库的 Binlog&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时数仓表命名：&lt;code&gt;deptname.appname.ods_subjectname_tablename&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：接入业务方的 NSQ 消息&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时数仓表命名：&lt;code&gt;deptname.appname.ods_subjectname_msgname&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;- DWS（实时明细中间层）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DWS 层，即实时明细中间层，该层以业务过程作为建模驱动，基于每个具体的业务过程事件来构建最细粒度的明细层事实表；比如交易过程，有下单事件、支付事件、发货事件等，我们会基于这些独立的事件来进行明细层的构建。在这层，事实明细数据同样是按照离线数仓的主题域来进行划分，也会采用维度建模的方式组织数据，对于一些重要的维度字段，会做适当冗余。基于有赞实时需求的场景，重点建设交易、营销、客户、店铺、商品等主题域的数据。该层的数据来源于 ODS 层，通过 FlinkSQL 进行 ETL 处理，主要工作有规范命名、数据清洗、维度补全、多流关联，最终统一写入 Kafka 存储介质中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DWS 层表命名规范：&lt;code&gt;部门名称.应用名称.数仓层级_主题域前缀_数仓表命名&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：实时事件 A 的中间层&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时数仓表命名：&lt;code&gt;deptname.appname.dws_subjectname_tablename_eventnameA&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：实时事件 B 的中间层&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时数仓表命名：&lt;code&gt;deptname.appname.dws_subjectname_tablename_eventnameB&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;- DIM（实时维表层）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DIM 层，即实时维表层，用来存放维度数据，主要用于实时明细中间层宽化处理时补全维度使用，目前该层的数据主要存储于 HBase 中，后续会基于 QPS 和数据量大小提供更多合适类型的存储介质。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DIM 层表命名规范：&lt;code&gt;应用名称_数仓层级_主题域前缀_数仓表命名&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：HBase 存储，实时维度表&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时数仓表命名：&lt;code&gt;appname_dim_tablename&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;- DWA（实时汇总层）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DWA 层，即实时汇总层，该层通过 DWS 层数据进行多维汇总，提供给下游业务方使用，在实际应用过程中，不同业务方使用维度汇总的方式不太一样，根据不同的需求采用不同的技术方案去实现。第一种方式，采用 FlinkSQL 进行实时汇总，将结果指标存入 HBase、MySQL 等数据库，该种方式是我们早期采用的方案，优点是实现业务逻辑比较灵活，缺点是聚合粒度固化，不易扩展；第二种方式，采用实时 OLAP 工具进行汇总，该种方式是我们目前常用的方案，优点是聚合粒度易扩展，缺点是业务逻辑需要在中间层预处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DWA 层表命名规范：&lt;code&gt;应用名称_数仓层级_主题域前缀_聚合粒度_数据范围&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：HBase 存储，某域当日某粒度实时汇总表&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时数仓表命名：&lt;code&gt;appname_dwa_subjectname_aggname_daily&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;- APP（实时应用层）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;APP 层，即实时应用层，该层数据已经写入应用系统的存储中，例如写入 Druid 作为 BI 看板的实时数据集；写入 HBase、MySQL 用于提供统一数据服务接口；写入 ClickHouse 用于提供实时 OLAP 服务。因为该层非常贴近业务，在命名规范上实时数仓不做统一要求。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;2) 实时 ETL&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时数仓 ETL 处理过程所涉及的组件比较多，接下来盘点构建实时数仓所需要的组件以及每个组件的应用场景。如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.49907407407407406&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNOcejkx1jfE5iaL3T6fABQ83SwiaMhQia7GBpCaOtQXsiciaaEicuianMynibaA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体实时 ETL 处理流程如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9022316684378321&quot; data-type=&quot;png&quot; data-w=&quot;941&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNFgiaiayaPfBNsNsg6PMAFRRZVTMwRqiaxDRQvEKMuCxwDRwSBTiaHRgoQg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1. 维度补全&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;创建调用 Duboo 接口的 UDF 函数在实时流里补全维度是最便捷的使用方式，但如果请求量过大，对 Duboo 接口压力会过大。在实际应用场景补全维度首选还是关联维度表，但关联也存在一定概率的丢失问题，为了弥补这种丢失，可以采用 Duboo 接口调用兜底的方式来补全。伪代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;create&lt;/span&gt; &lt;span&gt;function&lt;/span&gt; call_dubbo &lt;span&gt;as&lt;/span&gt; &lt;span&gt;&#x27;XXXXXXX&#x27;&lt;/span&gt;;&lt;br/&gt;&lt;span&gt;create&lt;/span&gt; &lt;span&gt;function&lt;/span&gt; get_json_object &lt;span&gt;as&lt;/span&gt; &lt;span&gt;&#x27;XXXXXXX&#x27;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;case&lt;br/&gt;    when cast( b.column as bigint) is not null&lt;br/&gt;        then cast( b.column as bigint)&lt;br/&gt;            else cast(coalesce(cast(get_json_object(call_dubbo(&#x27;clusterUrl&#x27;&lt;br/&gt;                                                              ,&#x27;serviceName&#x27;&lt;br/&gt;                                                              ,&#x27;methodName&#x27;&lt;br/&gt;                                                              ,cast(concat(&#x27;[&#x27;,cast(a.column as varchar),&#x27;]&#x27;) as varchar)&lt;br/&gt;                                                              ,&#x27;key&#x27;&lt;br/&gt;                                                              )&lt;br/&gt;                                             ,&#x27;rootId&#x27;)&lt;br/&gt;                                         as bigint)&lt;br/&gt;                                   ,a.column)&lt;br/&gt;                            as bigint)  &lt;span&gt;end&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2. 幂等处理&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时任务在运行过程中难免会遇到执行异常的情况，当任务异常重启的时候会导致部分消息重新发送和消费，从而引发下游实时统计数据不准确，为了有效避免这种情况，可以选择对实时消息流做幂等处理，当消费完一条消息，将这条消息的 Key 存入 KV，如果任务异常重启导致消息重新发送的时候，先从 KV 判断该消息是否已被消费，如果已消费就不再往下发送。伪代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;create&lt;/span&gt; &lt;span&gt;function&lt;/span&gt; idempotenc &lt;span&gt;as&lt;/span&gt; &lt;span&gt;&#x27;XXXXXXX&#x27;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;insert&lt;/span&gt; &lt;span&gt;into&lt;/span&gt; &lt;span&gt;table&lt;/span&gt;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt;&lt;br/&gt;    order_no&lt;br/&gt;&lt;span&gt;from&lt;/span&gt;&lt;br/&gt;    (&lt;br/&gt;        &lt;span&gt;select&lt;/span&gt;&lt;br/&gt;            a.orderNo                                        &lt;span&gt;as&lt;/span&gt;  order_no&lt;br/&gt;          , idempotenc(&lt;span&gt;&#x27;XXXXXXX&#x27;&lt;/span&gt;, &lt;span&gt;coalesce&lt;/span&gt;( order_no, &lt;span&gt;&#x27;&#x27;&lt;/span&gt;) )  &lt;span&gt;as&lt;/span&gt;  rid&lt;br/&gt;        &lt;span&gt;from&lt;/span&gt;&lt;br/&gt;            table1&lt;br/&gt;    ) t&lt;br/&gt;&lt;span&gt;where&lt;/span&gt;&lt;br/&gt;    t.rid = &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;3. 数据验证&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于实时数仓的数据是无边界的流，相比于离线数仓固定不变的数据更难验收。基于不同的场景，我们提供了 2 种验证方式，分别是：抽样验证与全量验证。如图 3.3 所示&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该方案主要应用在数据准确性验证上，实时汇总结果是基于存储在 Kafka 的实时明细中间层计算而来，但 Kafka 本身不支持按照特定条件检索，不支持写查询语句，再加上消息的无边界性，统计结果是在不断变化的，很难寻找参照物进行比对。鉴于此，我们采用了持久化消息的方法，将消息落盘到 TiDB 存储，基于 TiDB 的能力对落盘的消息进行检索、查询、汇总。编写固定时间边界的测试用例与相同时间边界的业务库数据或者离线数仓数据进行比对。通过以上方式，抽样核心店铺的数据进行指标准确性验证，确保测试用例全部通过。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该方案主要应用在数据完整性和一致性验证上，在实时维度表验证的场景使用最多。大体思路：将存储实时维度表的在线 HBase 集群中的数据同步到离线 HBase 集群中，再将离线 HBase 集群中的数据导入到 Hive 中，在限定实时维度表的时间边界后，通过数据平台提供的数据校验功能，比对实时维度表与离线维度表是否存在差异，最终确保两张表的数据完全一致。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.23355576739752146&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1049&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNylBuhADw8W1O6UhSCd3siaCXhA4W3k0z0fibNNfq1ibPYdOZSicd1oPqNQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;4. 数据恢复&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时任务一旦上线就要求持续不断的提供准确、稳定的服务。区别于离线任务按天调度，如果离线任务出现 Bug，会有充足的时间去修复。如果实时任务出现 Bug，必须按照提前制定好的流程，严格按照步骤执行，否则极易出现问题。造成 Bug 的情况有非常多，比如代码 Bug、异常数据 Bug、实时集群 Bug，如下图展示了修复实时任务 Bug 并恢复数据的流程。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3961290322580645&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;775&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNPOMCKd87Kxas4c7JsIlRjx1UVXKnnDhongIB7O5gPF5WvSok5eFOyw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5. 腾讯全场景实时数仓建设案例&lt;/span&gt;&lt;br/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在数仓体系中会有各种各样的大数据组件，譬如 Hive/HBase/HDFS/S3，计算引擎如 MapReduce、Spark、Flink，根据不同的需求，用户会构建大数据存储和处理平台，数据在平台经过处理和分析，结果数据会保存到 MySQL、Elasticsearch 等支持快速查询的关系型、非关系型数据库中，接下来应用层就可以基于这些数据进行 BI 报表开发、用户画像，或基于 Presto 这种 OLAP 工具进行交互式查询等。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5287958115183246&quot; data-type=&quot;png&quot; data-w=&quot;764&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHN4ruh0TibCsnkQStRv0fQnVG2R2ibibDECaJSy4xu0wbPCGgiakPiaTRv7XQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;1) Lambda 架构的痛点&lt;br/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在整个过程中我们常常会用一些离线的调度系统，定期的（T+1 或者每隔几小时）去执行一些 Spark 分析任务，做一些数据的输入、输出或是 ETL 工作。离线数据处理的整个过程中必然存在数据延迟的现象，不管是数据接入还是中间的分析，数据的延迟都是比较大的，可能是小时级也有可能是天级别的。另外一些场景中我们也常常会为了一些实时性的需求去构建一个实时处理过程，比如借助 Flink+Kafka 去构建实时的流处理系统。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整体上，数仓架构中有非常多的组件，大大增加了整个架构的复杂性和运维的成本。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下图，这是很多公司之前或者现在正在采用的 Lambda 架构，Lambda 架构将数仓分为离线层和实时层，相应的就有批处理和流处理两个相互独立的数据处理流程，同一份数据会被处理两次以上，同一套业务逻辑代码需要适配性的开发两次。Lambda 架构大家应该已经非常熟悉了，下面我就着重介绍一下我们采用 Lambda 架构在数仓建设过程中遇到的一些痛点问题。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5157068062827225&quot; data-type=&quot;png&quot; data-w=&quot;764&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNwSGxxicClorE98FzXPy6wrmIOmpWoh5gl42gsldibjkwKKDuk7GiciaIEA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如在实时计算一些用户相关指标的实时场景下，我们想看到当前 pv、uv 时，我们会将这些数据放到实时层去做一些计算，这些指标的值就会实时呈现出来，但同时想了解用户的一个增长趋势，需要把过去一天的数据计算出来。这样就需要通过批处理的调度任务来实现，比如凌晨两三点的时候在调度系统上起一个 Spark 调度任务把当天所有的数据重新跑一遍。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很显然在这个过程中，由于两个过程运行的时间是不一样的，跑的数据却相同，因此可能造成数据的不一致。因为某一条或几条数据的更新，需要重新跑一遍整个离线分析的链路，数据更新成本很大，同时需要维护离线和实时分析两套计算平台，整个上下两层的开发流程和运维成本其实都是非常高的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了解决 Lambda 架构带来的各种问题，就诞生了 Kappa 架构，这个架构大家应该也非常的熟悉。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;2) Kappa 架构的痛点&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们来讲一下 Kappa 架构，如下图，它中间其实用的是消息队列，通过用 Flink 将整个链路串联起来。Kappa 架构解决了 Lambda 架构中离线处理层和实时处理层之间由于引擎不一样，导致的运维成本和开发成本高昂的问题，但 Kappa 架构也有其痛点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，在构建实时业务场景时，会用到 Kappa 去构建一个近实时的场景，但如果想对数仓中间层例如 ODS 层做一些简单的 OLAP 分析或者进一步的数据处理时，如将数据写到 DWD 层的 Kafka，则需要另外接入 Flink。同时，当需要从 DWD 层的 Kafka 把数据再导入到 Clickhouse，Elasticsearch，MySQL 或者是 Hive 里面做进一步的分析时，显然就增加了整个架构的复杂性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其次，Kappa 架构是强烈依赖消息队列的，我们知道消息队列本身在整个链路上数据计算的准确性是严格依赖它上游数据的顺序，消息队列接的越多，发生乱序的可能性就越大。ODS 层数据一般是绝对准确的，把 ODS 层的数据发送到下一个 kafka 的时候就有可能发生乱序，DWD 层再发到 DWS 的时候可能又乱序了，这样数据不一致性就会变得很严重。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第三，Kafka 由于它是一个顺序存储的系统，顺序存储系统是没有办法直接在其上面利用 OLAP 分析的一些优化策略，例如谓词下推这类的优化策略，在顺序存储的 Kafka 上来实现是比较困难的事情。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么有没有这样一个架构，既能够满足实时性的需求，又能够满足离线计算的要求，而且还能够减轻运维开发的成本，解决通过消息队列构建 Kappa 架构过程中遇到的一些痛点？答案是肯定的，后面的篇幅会详细论述。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.520891364902507&quot; data-type=&quot;png&quot; data-w=&quot;718&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNq6MqcU4DhaUMv5EBoWvdyTTp7HgTLibbpIWSkoSxQAPiaprGwBgxGIGg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;3) 痛点总结&lt;br/&gt;&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5436046511627907&quot; data-type=&quot;png&quot; data-w=&quot;688&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNEF8PFj6EKzicN8Ea750IkbLyxwUP7GicjWBObOibxezP4K6KunMtdLLQA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;4) Flink+Iceberg 构建实时数仓&lt;br/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1. 近实时的数据接入&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面介绍了 Iceberg 既支持读写分离，又支持并发读、增量读、小文件合并，还可以支持秒级到分钟级的延迟，基于这些优势我们尝试采用 Iceberg 这些功能来构建基于 Flink 的实时全链路批流一体化的实时数仓架构。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下图所示，Iceberg 每次的 commit 操作，都是对数据的可见性的改变，比如说让数据从不可见变成可见，在这个过程中，就可以实现近实时的数据记录。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.55&quot; data-type=&quot;png&quot; data-w=&quot;680&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHN99AwBehFx804DABqUoepKtWeqEG1ynL1DWE6wjhFXxokL256VhL6lQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2. 实时数仓 - 数据湖分析系统&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此前需要先进行数据接入，比如用 Spark 的离线调度任务去跑一些数据，拉取，抽取最后再写入到 Hive 表里面，这个过程的延时比较大。有了 Iceberg 的表结构，可以中间使用 Flink，或者 spark streaming，完成近实时的数据接入。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于以上功能，我们再来回顾一下前面讨论的 Kappa 架构，Kappa 架构的痛点上面已经描述过，Iceberg 既然能够作为一个优秀的表格式，既支持 Streaming reader，又可以支持 Streaming sink，是否可以考虑将 Kafka 替换成 Iceberg？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Iceberg 底层依赖的存储是像 HDFS 或 S3 这样的廉价存储，而且 Iceberg 是支持 parquet、orc、Avro 这样的列式存储。有列式存储的支持，就可以对 OLAP 分析进行基本的优化，在中间层直接进行计算。例如谓词下推最基本的 OLAP 优化策略，基于 Iceberg snapshot 的 Streaming reader 功能，可以把离线任务天级别到小时级别的延迟大大的降低，改造成一个近实时的数据湖分析系统。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5267605633802817&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHN8hXmkelgHB0N4upmmw4Nsx9R2d2HC3MJQb0OicCuNibf2sQE1p2Tlbeg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;710&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在中间处理层，可以用 presto 进行一些简单的查询，因为 Iceberg 支持 Streaming read，所以在系统的中间层也可以直接接入 Flink，直接在中间层用 Flink 做一些批处理或者流式计算的任务，把中间结果做进一步计算后输出到下游。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;替换 Kafka 的优劣势：&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;总的来说，Iceberg 替换 Kafka 的优势主要包括：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;实现存储层的流批统一&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;中间层支持 OLAP 分析&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;完美支持高效回溯&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;存储成本降低&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;当然，也存在一定的缺陷，如：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据延迟从实时变成近实时&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;对接其他数据系统需要额外开发工作&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5358166189111748&quot; data-type=&quot;png&quot; data-w=&quot;698&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNneicxaH3y6Vr8blCjXYIa4g1Je7o8rPG7VEjD5aEMpnc9XIFuckfF1w/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;秒级分析 - 数据湖加速&lt;/strong&gt;：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于 Iceberg 本身是将数据文件全部存储在 HDFS 上的，HDFS 读写这块对于秒级分析的场景，还是不能够完全满足我们的需求，所以接下去我们会在 Iceberg 底层支持 Alluxio 这样一个缓存，借助于缓存的能力可以实现数据湖的加速。这块的架构也在我们未来的一个规划和建设中。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5582089552238806&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBd8F47zvRC39bsBk2kBRicHNM4ryeuYSpHbbCjTrYjLL4xGqfGia7rX2icVxE1WxS8riaFbjKZaw7vDrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;670&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;92798&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;欢迎点赞 + 收藏 + 在看 &lt;span&gt; 素质三连 &lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;89428&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;完&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br data-filtered=&quot;filtered&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;92886&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;▼&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;往期精彩回顾&lt;/section&gt;&lt;section&gt;▼&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247489160&amp;amp;idx=1&amp;amp;sn=ae48de203f212768735e387f45bf5591&amp;amp;chksm=ec1c7048db6bf95efd02cff03950ea092b883b691d697440b745ac59a24f599b334a5e9103e4&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;程序员，如何避免内卷&lt;/a&gt;&lt;br data-filtered=&quot;filtered&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247492316&amp;amp;idx=1&amp;amp;sn=eeb7c8ae98b2532f4414463c298fec00&amp;amp;chksm=ec1f841cdb680d0af054e53e32d022a00a49cdb6ae573e79dc30d1e054c313c270232263525b&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;2021年大数据开发发展趋势&lt;/a&gt;&lt;br data-filtered=&quot;filtered&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247483999&amp;amp;idx=1&amp;amp;sn=016e4c4d0ba7bd96e9f2d2d5f8cbe0de&amp;amp;chksm=ec1c649fdb6bed89e74984c28859557f577cdfedcdcee3f67ad50a5097daaff0e67718c50121&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;【全网首发】Hadoop 3.0分布式集群安装&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247494141&amp;amp;idx=1&amp;amp;sn=c6d501c903d385d9cbfc160ae31a25bb&amp;amp;chksm=ec1f8f3ddb68062b312c15cfc5f871c42ca7e4f6621e908717dc509486d6ce9851489c730780&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;大数据运维工程师经典面试题汇总(附带答案)&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;大数据运维工程师经典面试题汇总(附带答案)&lt;/a&gt;&lt;br data-filtered=&quot;filtered&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247485085&amp;amp;idx=1&amp;amp;sn=5ea5585ebe9a101e3287b934f11a9532&amp;amp;chksm=ec1c605ddb6be94b3d13c7f329e45037b2fbdcbe7e8cedb7ad79f8f275054d0f2435668d64e0&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;【2020最新整理】大数据面试130题&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;大数据面试130题&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247488101&amp;amp;idx=1&amp;amp;sn=0327c492f0f30cbfe3043bd274ccaae5&amp;amp;chksm=ec1c74a5db6bfdb3d609ec19a70fec0415931aa860de02ec854f3a01f8dfe169c7d6080ed793&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;某集团大数据平台整体架构及实施方案完整目录&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247489171&amp;amp;idx=1&amp;amp;sn=4ae22d71dd2b390f80041378a36e1d68&amp;amp;chksm=ec1c7053db6bf9457c4bc087fb872e55c4d2db060c963f9fccebc5a0ba4e9f28964dc4b36a59&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;大数据凉凉了？Apache将一众大数据开源项目束之高阁！&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247488568&amp;amp;idx=1&amp;amp;sn=7d37a9c703e2ff4cec5d93a342dd54d3&amp;amp;chksm=ec1c72f8db6bfbeee1da9a4174e22afa3846e0f66cc18dde13dd7ab13cac33d15e28266c7e30&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;实战企业数据湖，抢先数仓新玩法&lt;/a&gt;&lt;br data-filtered=&quot;filtered&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247489329&amp;amp;idx=1&amp;amp;sn=d2b475f1236971db561cf9b526ccb7a0&amp;amp;chksm=ec1c71f1db6bf8e716211d53c935f466c73b4241f418dae5b79ee54489c570cc48a01473c5e6&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;Superset制作智慧数据大屏，看它就够了&lt;/a&gt;&lt;br data-filtered=&quot;filtered&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247487980&amp;amp;idx=1&amp;amp;sn=f91bae73e1b5372feffa25d98f07ba51&amp;amp;chksm=ec1c772cdb6bfe3add9728dda65556aa609e27d95ae7d2d9e29def9c364b525516282d614528&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;Apache Flink 在快手的过去、现在和未来&lt;/a&gt;&lt;br data-filtered=&quot;filtered&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247491729&amp;amp;idx=1&amp;amp;sn=2b5420bb957dd536767c76b6bb07df33&amp;amp;chksm=ec1f8651db680f47377f96d2e3d588761f216d31527bb0c38be5d753c902e246195c6cca68e8&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;华为云-基于Ambari构建大数据平台（上）&lt;/a&gt;&lt;br data-filtered=&quot;filtered&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247491843&amp;amp;idx=1&amp;amp;sn=32e14594500b7371c1e3d7d9b30159a9&amp;amp;chksm=ec1f87c3db680ed525311d5c413307a270e3035b5ae682842560f3fbd7348a793151e2cc30e9&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;华为云-基于Ambari构建大数据平台（下）&lt;/a&gt;&lt;br data-filtered=&quot;filtered&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247483936&amp;amp;idx=1&amp;amp;sn=51948ae9478f8fbd0e16135b477fc030&amp;amp;chksm=ec1c64e0db6bedf6f70f4e90358513e376f9b56bb39c9b86bd929b2b931ce8ff80c10f647285&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;【HBase调优】Hbase万亿级存储性能优化总结&lt;/a&gt;&lt;br data-filtered=&quot;filtered&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247483800&amp;amp;idx=1&amp;amp;sn=c6d159dc2d90aa1da1631bf2e95c4e7e&amp;amp;chksm=ec1c6758db6bee4e3f10f442be9b16b63fd9a15ccdf849dd045a5ee4fadef6368689fb428b4b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;【Python精华】100个Python练手小程序&lt;/a&gt;&lt;br data-filtered=&quot;filtered&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247483794&amp;amp;idx=1&amp;amp;sn=02c9d959bce88520d833f8b10d63c997&amp;amp;chksm=ec1c6752db6bee44c37842eca5cc6f7973e99675eedeedbfcec5a84bd508f776cecc72d4fbe2&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;【HBase企业应用开发】工作中自己总结的Hbase笔记，非常全面！&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI5MDYxNjIzOQ==&amp;amp;mid=2247483767&amp;amp;idx=1&amp;amp;sn=ac3bb74985c13b3a5e92089d8b0510ba&amp;amp;chksm=ec1c67b7db6beea168b5d10f8c8d2cbb8071254149c24869f58fe615e378109bf5ef3f27fe35&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;【剑指Offer】近50个常见算法面试题的Java实现代码&lt;/a&gt;&lt;br data-filtered=&quot;filtered&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;95677&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100009663&quot; data-ratio=&quot;1&quot; data-type=&quot;jpeg&quot; data-w=&quot;258&quot; data-width=&quot;100%&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xqJ76ZLyAwCZa1fpodUQy3Ncs5WsagqvxHHUfHsMShpm77L6HVCoIVhibOEOdFefFLejMjQXyxOoDrWLzycr8pg/640?wx_fmt=jpeg&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;长按识别左侧二维码&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;    关注领福利    &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  &lt;/span&gt;&lt;span&gt;&lt;strong&gt;领10本经典大数据书&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>cce970ed4a3fe88da6d54567b17c714a</guid>
<title>从0到1剖析并编码实现短链系统</title>
<link>https://toutiao.io/k/n9hfkus</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section&gt;&lt;span&gt;短链很常见，在互联网营销场景以及移动端信息传播等场景下起着重要的作用。同时，也是经常被来拿考察选手系统设计水平的一个场景。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;对于服务端研发，关于前端访问时的长短转换，其实只要知道有&lt;code&gt;30X&lt;/code&gt;重定向基本也就可以了。&lt;/section&gt;&lt;section&gt;相较于重定向，我更关注的，是&lt;strong&gt;短链生成方式选型&lt;/strong&gt;、&lt;strong&gt;存储选型&lt;/strong&gt;、&lt;strong&gt;系统性能应对&lt;/strong&gt;等方面的方案和设计。&lt;/section&gt;&lt;h2&gt;Part one 短链系统分析&lt;/h2&gt;&lt;section&gt;短链系统的最根本能力:&lt;/section&gt;&lt;section&gt;&lt;strong&gt;是可以根据长链计算得到短链，以方便外部访问&lt;/strong&gt;:&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;也可以根据短链映射到长链，寻找真实服务地址提供服务&lt;/strong&gt;&lt;span&gt;:&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.590032154340836&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/xE6oscyT5326VR2HevoPUiczjSfOibKDkRwIvJJrSKZhH1fVHUcCnb8I0p2u1CHwXV7nvEcMtphhQe4o6wGVVY1Q/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;622&quot; title=&quot;null&quot;/&gt;&lt;/figure&gt;&lt;p&gt;条条大路通罗马，系统方案有很多，但采取哪种最合适，还需要和存储策略以及访问性能联合起来一起看~&lt;/p&gt;&lt;h2&gt;Part two 实现方案分析&lt;/h2&gt;&lt;section&gt;Hash是最容易想到的实现策略之一，那么，Hash方式有哪些优缺点，我们又该怎么改进呢？&lt;/section&gt;&lt;h3&gt;Hash策略关键点解析&lt;/h3&gt;&lt;section&gt;&lt;strong&gt;首先&lt;/strong&gt;，如果用hash方式来生成短链，那么短链是没法通过hash码反解出长链的，因此，必须存储短链和长链的关联关系；&lt;/section&gt;&lt;section&gt;&lt;strong&gt;其次&lt;/strong&gt;，长链的长度一般又很长，不便于索引的构建，需要再生成一个长链的固定唯一短串来辅助存储和查询。( 如32位MD5压缩，加密算法一般不利于压缩，而压缩算法一般不可逆)；&lt;/section&gt;&lt;section&gt;&lt;strong&gt;再次&lt;/strong&gt;，hash难免会有冲突，需要对原始长链尾部拼接一个或多个固定串来消除冲突，因此，在访问长链时同样需要裁剪固定串。&lt;/section&gt;&lt;h3&gt;Hash策略的存储设计&lt;/h3&gt;&lt;section&gt;如果用&lt;code&gt;mysql&lt;/code&gt;进行结构化存储比较简单:&lt;br/&gt;&lt;code&gt;id&lt;/code&gt; | &lt;code&gt;短链&lt;/code&gt; | &lt;code&gt;长链MD5&lt;/code&gt; | &lt;code&gt;长链&lt;/code&gt; | &lt;code&gt;时间戳&lt;/code&gt;&lt;br/&gt;并且需要给 &lt;code&gt;短链&lt;/code&gt; 和 &lt;code&gt;长链MD5&lt;/code&gt; 构建索引，供查询时使用。&lt;/section&gt;&lt;section&gt;如果用&lt;code&gt;redis&lt;/code&gt;等非结构化kv存储，则需要存储多个关系用于查询:&lt;br/&gt;&lt;code&gt;长链MD5&lt;/code&gt; &lt;code&gt;-&amp;gt;&lt;/code&gt; &lt;code&gt;短链&lt;/code&gt; |&lt;br/&gt;&lt;code&gt;短链&lt;/code&gt; &lt;code&gt;-&amp;gt;&lt;/code&gt; &lt;code&gt;长链MD5&lt;/code&gt; |&lt;br/&gt;&lt;code&gt;长链MD5&lt;/code&gt; &lt;code&gt;-&amp;gt;&lt;/code&gt; &lt;code&gt;长链&lt;/code&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;优点是查询性能高，可以抗量，且自带过期机制；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;缺点是需要维护多个KV关系，稍显繁琐。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;改进-- 自增ID+高位进制法&lt;/h3&gt;&lt;section&gt;如果说&lt;span&gt;长链的MD5标识&lt;/span&gt;的生成和存储是不可缺少的，那么，可优化的点，就只能从&lt;code&gt;短链&lt;/code&gt; &lt;code&gt;-&amp;gt;&lt;/code&gt; &lt;code&gt;长链MD5&lt;/code&gt;的转化这里来下手了。&lt;/section&gt;&lt;section&gt;有没有办法既可以省掉&lt;code&gt;短链&lt;/code&gt; &lt;code&gt;-&amp;gt;&lt;/code&gt; &lt;code&gt;长链MD5&lt;/code&gt;的存储呢？&lt;/section&gt;&lt;section&gt;如果我们让唯一标识和短链之间可以通过计算相互编码解码，是不是就可以了！？既省了一部分存储，而且也省掉了查询存储的时间耗时，本地简单计算总归要比查询外部存储要快的多。&lt;/section&gt;&lt;section&gt;经常使用&lt;code&gt;进制转换&lt;/code&gt;，可以知道，进制越高所占位数越少。&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6005665722379604&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/xE6oscyT5326VR2HevoPUiczjSfOibKDkR4xTfWP2J8ibAENb4thP2C7ZNFxodFicPKVGZr9d1nHLLQhZgvUTgs7Rw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;706&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;span&gt;16进制转换示例&lt;br/&gt;&lt;/span&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;这个时候，用&lt;code&gt;MD5&lt;/code&gt;应该就不太合适了，不好参与计算，因此，我们改用纯数字的&lt;code&gt;分布式ID&lt;/code&gt;来代替&lt;code&gt;MD5&lt;/code&gt;串(一般公司应该都有现成的分布式ID生成服务吧)。&lt;/section&gt;&lt;section&gt;利用进制转换虽然可以很方便编码成短链，但有时候，我们不希望出现 短链被轻松解码，导致服务端可被遍历，因此，需要考虑对进制转换进行&lt;code&gt;加密处理&lt;/code&gt;。&lt;/section&gt;&lt;h3&gt;编码实现带加密的进制转换&lt;/h3&gt;&lt;section&gt;首先，需要选择高位进制：我们启用 0-9 a-z A-Z 全部的数字和字母，一共62位，即支持62进制转换&lt;/section&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;String&lt;/span&gt; &lt;span&gt;DIGITAL_STRING&lt;/span&gt; = &lt;span&gt;&quot;0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;&lt;/span&gt;;&lt;br/&gt;&lt;span&gt;//byte数组 &lt;/span&gt;&lt;br/&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;byte&lt;/span&gt;[] DIGITAL;&lt;br/&gt;&lt;span&gt;static&lt;/span&gt; {&lt;br/&gt;    DIGITAL = DIGITAL_STRING.getBytes(StandardCharsets.US_ASCII);&lt;br/&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;section&gt;从10进制向62进制转换的编码实现：&lt;/section&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; String &lt;span&gt;encode&lt;/span&gt;(&lt;span&gt;long&lt;/span&gt; 分布式id) {&lt;br/&gt;    &lt;span&gt;//内部复制&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;long&lt;/span&gt; &lt;span&gt;value&lt;/span&gt; = id; &lt;br/&gt;    &lt;span&gt;//创建短链所需长度的空间，这里可以限制短链长度为最多12位，最少6位 &lt;/span&gt;&lt;br/&gt;    &lt;span&gt;ByteBuffer&lt;/span&gt; &lt;span&gt;buf&lt;/span&gt; = ByteBuffer.allocate(&lt;span&gt;12&lt;/span&gt;);&lt;br/&gt;    &lt;span&gt;//最多执行12次转换&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;12&lt;/span&gt;; i++) {&lt;br/&gt;        &lt;span&gt;//分布式ID对62取模&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;int&lt;/span&gt; &lt;span&gt;mod&lt;/span&gt; = (&lt;span&gt;int&lt;/span&gt;) (value % &lt;span&gt;62&lt;/span&gt;);&lt;br/&gt;        &lt;span&gt;//加密， 再取模&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;int&lt;/span&gt; &lt;span&gt;pos&lt;/span&gt; = (mod + (OFFSET &amp;lt;&amp;lt; i)) % &lt;span&gt;62&lt;/span&gt;;&lt;br/&gt;        &lt;span&gt;//根据模值从数组中获取对应的值，加入结果集中&lt;/span&gt;&lt;br/&gt;        buf.put(DIGITAL[pos]);&lt;br/&gt;        &lt;span&gt;//求余数，用余数继续参加后续模操作，直到余数为0 或 短链长度达到要求&lt;/span&gt;&lt;br/&gt;        value = value / &lt;span&gt;62&lt;/span&gt;;&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (value==&lt;span&gt;0&lt;/span&gt; &amp;amp;&amp;amp; i &amp;gt;= &lt;span&gt;6&lt;/span&gt;) {&lt;br/&gt;            &lt;span&gt;break&lt;/span&gt;;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;//从ByteBuffer中获取结果集合&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;byte&lt;/span&gt;[] result=&lt;span&gt;new&lt;/span&gt; &lt;span&gt;byte&lt;/span&gt;[buf.position()];&lt;br/&gt;    buf.rewind();&lt;br/&gt;    buf.get(result);&lt;br/&gt;    &lt;span&gt;//反转顺序&lt;/span&gt;&lt;br/&gt;    ArrayUtils.reverse(result);&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;String&lt;/span&gt;(result);&lt;br/&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;section&gt;重点关注&lt;code&gt;(mod + (OFFSET &amp;lt;&amp;lt; i)) % 62&lt;/code&gt; 这个操作，其目的是在模值上加上一个偏移量(偏移大小和所处位置有关，非固定偏移) ，用来防止被直接解码。&lt;/section&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;//将短链串解码为分布式ID&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; &lt;span&gt;decode&lt;/span&gt;(String code) {&lt;br/&gt;    &lt;span&gt;long&lt;/span&gt; &lt;span&gt;value&lt;/span&gt; = &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;byte&lt;/span&gt;[] buf = code.getBytes();&lt;br/&gt;    &lt;span&gt;int&lt;/span&gt; &lt;span&gt;length&lt;/span&gt; = buf.length;&lt;br/&gt;    &lt;span&gt;//循环次数为短链字符串长度&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; length; i++) {&lt;br/&gt;        &lt;span&gt;byte&lt;/span&gt; &lt;span&gt;digital&lt;/span&gt; = buf[i];&lt;br/&gt;        &lt;span&gt;//当前字符对应的下标&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;int&lt;/span&gt; &lt;span&gt;index&lt;/span&gt; = Arrays.binarySearch(DIGITAL, digital);&lt;br/&gt;        &lt;span&gt;//当前下标需要减掉加密时增加的部分(同样和所处位置有关)&lt;/span&gt;&lt;br/&gt;        index = index - (OFFSET &amp;lt;&amp;lt; (length - i - &lt;span&gt;1&lt;/span&gt;));&lt;br/&gt;        &lt;span&gt;//因为减掉的有可能是一个非常大的值，再把index对62取余，如果任然小于0 ，就加上62(62进制内负变正)&lt;/span&gt;&lt;br/&gt;        index = index % &lt;span&gt;62&lt;/span&gt;;&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (index &amp;lt; &lt;span&gt;0&lt;/span&gt;) {&lt;br/&gt;            index = index + &lt;span&gt;62&lt;/span&gt;;&lt;br/&gt;        }&lt;br/&gt;        &lt;span&gt;//10进制复原原值&lt;/span&gt;&lt;br/&gt;        value = value * &lt;span&gt;62&lt;/span&gt; + index;&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; value;&lt;br/&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;Part three 总结&lt;/h2&gt;&lt;section&gt;每一种技术方案，都是通过不断论证和尝试才可以最终决定的。我们在学习一个技术架构时，最好可以从它的发展历程，每个瓶颈点的解决来进行整体把握，会对我们处理问题时候的入手角度和思考方式的锻炼起到很好的作用。&lt;/section&gt;&lt;h4&gt;推荐阅读&lt;/h4&gt;&lt;section&gt;&lt;span&gt;•    &lt;/span&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4ODUzMDg5NQ==&amp;amp;mid=2650001658&amp;amp;idx=1&amp;amp;sn=d4660d396dc407e06f30b79699c854aa&amp;amp;scene=21#wechat_redirect&quot; title=&quot;高并发整体可用性：一文详解降级、限流和熔断&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;高并发整体可用性：一文详解降级、限流和熔断&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4ODUzMDg5NQ==&amp;amp;mid=2650001643&amp;amp;idx=1&amp;amp;sn=9745c8d6b24f06cfea08c1fd9e5b84b2&amp;amp;scene=21#wechat_redirect&quot; title=&quot;高并发整体可用性：大规模集群下的分片管理&quot; data-linktype=&quot;2&quot;&gt;•    &lt;span&gt;高并发整体可用性：大规模集群下的分片管理&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4ODUzMDg5NQ==&amp;amp;mid=2650001616&amp;amp;idx=1&amp;amp;sn=e85c4e8e1f08d3dac8f53e8f80c39499&amp;amp;scene=21#wechat_redirect&quot; title=&quot;高并发整体可用性：历经磨难的注册中心选型&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;&lt;span&gt;•    &lt;/span&gt;高并发整体可用性：历经磨难的注册中心选型&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4ODUzMDg5NQ==&amp;amp;mid=2650001219&amp;amp;idx=1&amp;amp;sn=6c41849dbfa9f7078d455014aa8781c0&amp;amp;scene=21#wechat_redirect&quot; title=&quot;高并发存储优化篇：诸多策略，缓存为王&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;    高并发存储优化篇：诸多策略，缓存为王&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;hr/&gt;&lt;section&gt;欢迎关注我的公众号“&lt;strong&gt;Coder的技术之路&lt;/strong&gt;”，欢迎转发分享，原创技术文章第一时间推送。&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>f917035ee9b7c7c8491720c193e103a4</guid>
<title>冰墩墩官方NFT盲盒开售；蚂蚁高P何昌华离职；极狐正式发布GitLabSaaS｜开发者头条</title>
<link>https://toutiao.io/k/vysw00t</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section&gt;&lt;p&gt;&lt;span&gt;我爱程序员！欢迎来撩！&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;我的微信号：&lt;/span&gt;&lt;span&gt;toutiaoio007&lt;/span&gt;&lt;span&gt; ，欢迎加我，拉你入群！&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;冰墩墩官方NFT盲盒开售，单价99美元&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;近日，nWayPlay在社交平台上表示，由国际奥委会官方授权的冰墩墩数字盲盒将于北京时间2月12日凌晨1:00发售。此次冰墩墩数字盲盒总数为500个，每个99美元（约626元人民币），每人限购5个。&lt;br/&gt;据官网介绍，史诗级盲盒（Epic Box）内将包含3个官方授权的数字胸针：1个史诗款（Epic）和2个珍稀款（Rare）。其中包含有15个版本的官方授权吉祥物（冰墩墩）表演各种冬季运动，如滑雪、俯式雪橇、单板滑雪等，还有5个版本的北京2022年冬奥会官方会徽和1个版本的海报。&lt;br/&gt;不过，该平台目前不支持中国地区用户购买。&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;工信部：工业和信息化领域数据处理者境内收集和产生的重要数据向境外提供应进行数据出境安全评估&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;36氪获悉，工信部再次公开征求对《工业和信息化领域数据安全管理办法（试行）》的意见。意见提出，工业和信息化领域数据处理者在中华人民共和国境内收集和产生的重要数据和核心数据，法律、行政法规有境内存储要求的，应当在境内存储，确需向境外提供的，应当依法依规进行数据出境安全评估。&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;中国灵活就业者已达2亿人&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;国家统计局相关负责人日前表示，截至2021年底，中国灵活就业人员已经达到2亿人，其中从事主播及相关从业人员160多万人，较2020年增加近3倍。&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;B站、完美世界、TapTap等多家游戏公司裁员，大扩张后迎调整&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;日前，据澎湃新闻报道，包括B站、完美世界、心动网络等多家游戏公司在2021年底至2022年初期间，均有不同规模的裁员。&lt;br/&gt;根据完美世界在今年1月份披露的投资者关系活动记录表显示，2021年公司对游戏团队进行精简和调优，调整部分跟公司未来大方向和调性不契合的团队。去年第四季度已经优化了几百人。完美世界表示，截至今年1月份，公司研发团队有四千人左右，后续有可能会进一步下降。按照最高1000人的计算，意味着公司研发团队裁员规模最高达25%。&lt;br/&gt;据B站内部员工透露，去年年底到今年年初之间，B站有人员调整，其中游戏部门裁员比例接近20%，研发团队裁员人数较多。B站游戏部门部分员工年终奖仅有半个月工资。此外1月底有市场传言称，TapTap母公司心动网络正在裁员，幅度接近团队的三分之一。此消息得到心动CEO黄一孟的正式回应。他在推特上坦言确实有团队调整，根据实际业务需求进行增减，但“并没有所谓的一刀切”。&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;脉脉：六成职场人愿意为了好工作放弃年终奖&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;脉脉人才智库的2022春招求职风向标调研显示，超过六成受访职场人愿意放弃年终奖；三成职场人表示，如果有好的工作机会，可以接受降薪跳槽。这一现象或许和公司普遍拖延年终奖有关，仅半数受访人表示，年终奖会在春节之前发放。15%左右的受访者表示春节后两个月或更长时间以后才能发年终奖，年终奖拖成了“年中”奖；超过两成受访者对公司年终奖的发放日期表示“不知道、不好说”。&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;蚂蚁高P何昌华离职，又一技术大牛出走&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;据新言财经报道，蚂蚁集团计算存储首席架构师何昌华已于近日离职，他在蚂蚁集团的职级为P10，其离职后的去向暂时未知。据公开资料显示，何昌华毕业于斯坦福大学，在谷歌有7年的工作经验，后在Airbnb负责后台系统的应用架构。此后加入蚂蚁，担任蚂蚁计算存储首席架构师。&lt;br/&gt;近一年时间内，互联网大厂中有着多位技术大牛出走。去年8月，字节跳动人工智能实验室总监李磊离职，入职加州大学圣巴巴拉分校；同年，曾任视觉技术负责人王长虎博士离职后，加入房地产公司龙湖；在早些时，字节跳动副总裁、人工智能实验室主任的马维英离职，加入清华大学智能产业研究院。前不久，阿里巴巴副总裁、达摩院自动驾驶实验室负责人王刚离职，去年蚂蚁集团原副总裁、AI团队负责人漆远，则选择重返学术界。&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;苏富比拍卖行将举办 CryptoPunks 特别拍卖会&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;由 Larva Labs 团队开发的 CryptoPunks 是 NFT 领域的头部项目之一，如今每一个市价都已突破天际。&lt;br/&gt;2 月 9 日，苏富比拍卖行宣布将在本月 23 日举办 CryptoPunks 拍卖活动，主题名为「Punk It! 104 CryptoPunks. 1 Lot.」。&lt;br/&gt;这 104 个 CryptoPunks 目前被匿名买家 0x650d 持有，将作为一个 NFT 集合进行拍卖，预计成交价在 2000-3000 万美元之间。&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;苹果推送 iOS / iPadOS 15.4 公测版 Beta 2&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;苹果推送了 iOS 15.4 和 iPadOS 15.4 公测版 beta 2。&lt;br/&gt;这个版本带来了 iPhone 支持戴口罩解锁 Face ID 功能，也带来了新公布的 Tap to Pay 功能，支持 iPhone 用户可在不依赖外部硬件的情况下使用 Apple Pay 收款。&lt;br/&gt;而 iPadOS 15.4 则带来了通用控制。配合搭载 macOS Monterey 12.3 的 Mac 使用时，Mac 和 iPad 可用同一套键盘鼠标控制。&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Android 12 L Beta 3 版本发布：专为大屏优化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;北京时间 2 月 10 日，谷歌宣布，Android 12 L Beta 3 版本发布，首次支持了 Pixel 6 和 Pixel 6 Pro，以及更新的测试环境、修复和优化了一些 bug。&lt;br/&gt;Android 12 L Beta 3 的版本号为 S2B3.220205.007.A1，支持 Pixel 3a、4、4a、5、5a、6 系列设备。自 Beta 2 开始，系统行为和 API 已最终确定。开发者已可面向 Android 12 L 进行 App 适配。&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;极狐正式发布GitLabSaaS&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;36氪获悉，极狐（GitLab）正式宣布推出极狐GitLab SaaS （JihuLab.com），为中国用户提供从源代码托管到开发运维的全栈式一体化DevOpsSaaS平台与企业级专家咨询服务。&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;马斯克、方岱宁院士入选2021年美国国家工程院院士&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;2月9日，美国国家工程院公布2021年度国家工程院增补院士名单，含111位院士及22位外籍院士。其中包括SpaceX创始人马斯克，LG能源解决方案密歇根公司总裁Denise Gray，通用电气智能电网业务发展负责人John McDonald，中国科学院院士、北京理工大学教授方岱宁。目前美国国家工程院院士总数2388位，外籍院士310位。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;加入「码农周刊VIP会员」，成为更好的开发者！&lt;br/&gt;↓↓↓&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5493333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/AjN1jquNavicibroqCN98y5SNT9NbfA3oHYQiaicFScHFfppgek7ZGicJiaHK45qc2zoccBibfEzIvzTsI4AB2xO2IaOw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>