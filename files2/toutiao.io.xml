<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>492648e91b5b0f73105be2abc7dbcc42</guid>
<title>2022 年升职加薪就靠它了！抓紧时间！</title>
<link>https://toutiao.io/k/fitvcz1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                              &lt;strong class=&quot;profile_nickname&quot;&gt;开发者头条&lt;/strong&gt;
                              &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                              &lt;p class=&quot;profile_meta&quot;&gt;
                              &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                              &lt;span class=&quot;profile_meta_value&quot;&gt;kaifazhetoutiao&lt;/span&gt;
                              &lt;/p&gt;

                              &lt;p class=&quot;profile_meta&quot;&gt;
                              &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                              &lt;span class=&quot;profile_meta_value&quot;&gt;程序员分享平台 | 官方应用下载地址：http://toutiao.io/download&lt;/span&gt;
                              &lt;/p&gt;
                              
                          &lt;/div&gt;
                          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>619e2cf4171d05d15f06105e47ce7315</guid>
<title>元数据性能大比拼：HDFS vs OSS vs JuiceFS</title>
<link>https://toutiao.io/k/kdd5k5y</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;post_content markdown&quot;&gt;&lt;h1 id=&quot;背景&quot;&gt;背景&lt;/h1&gt;&lt;p&gt;存储是大数据的基石，存储系统的元数据又是它的核心大脑，元数据的性能对整个大数据平台的性能和扩展能力非常关键。本文选取了大数据平台中 3 个典型的存储方案来压测元数据的性能，来个大比拼。&lt;/p&gt;&lt;p&gt;其中 HDFS 是被广为使用的大数据存储方案，已经经过十几年的沉淀和积累，是最合适的参考标杆。&lt;/p&gt;&lt;p&gt;以 Amazon S3 和 Aliyun OSS 为代表的对象存储也是云上大数据平台的候选方案，但它只有 HDFS 的部分功能和语义，性能也差不少，实际使用并不广泛。在这个测试中对象存储以 Aliyun OSS 为代表，其他对象存储类似。&lt;/p&gt;&lt;p&gt;JuiceFS 是大数据圈的新秀，专为云上大数据打造，是符合云原生特征的大数据存储方案。JuiceFS 使用云上对象存储保存客户数据内容，通过 JuiceFS 元数据服务和 Java SDK 来实现 HDFS 的完整兼容，不需要对数据分析组件做任何修改就可以得到跟 HDFS 一样的体验。&lt;/p&gt;&lt;h1 id=&quot;测试方法&quot;&gt;测试方法&lt;/h1&gt;&lt;p&gt;Hadoop 中有一个专门压测文件系统元数据性能的组件叫 NNBench，本文就是使用它来做压测的。&lt;/p&gt;&lt;p&gt;原版的 NNBench 有一些局限性，我们做了调整：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;原版 NNBench 的单个测试任务是单线程的，资源利用率低，我们将它改成多线程，便于增加并发压力。&lt;/li&gt;&lt;li&gt;原版 NNBench 使用 hostname 作为路径名的一部分，没有考虑同一个主机里多个并发任务的冲突问题，会导致多个测试任务重复创建和删除文件，不太符合大数据工作负载的实际情况，我们改成使用 Map 的顺序号来生成路径名，避免的一个主机上多个测试任务的产生冲突。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们使用了 3 台阿里云 4核 16G 的虚拟机来做压力测试。CDH 5 是目前被广泛使用的发行版，我们选用 CDH 5 作为测试环境，其中的 HDFS 是 2.6 版本。
HDFS 是使用 3 个 JournalNode 的高可用配置，JuiceFS 是 3 个节点的 Raft 组。HDFS 使用内网 IP，JuiceFS 使用的是弹性 IP，HDFS 的网络性能会好一些。OSS 是使用内网接口访问。&lt;/p&gt;&lt;h1 id=&quot;数据分析&quot;&gt;数据分析&lt;/h1&gt;&lt;p&gt;先来看看大家都熟悉的 HDFS 的性能表现：&lt;/p&gt;&lt;p&gt;此图描述的是 HDFS 每秒处理的请求数（TPS）随着并发数增长的曲线，有两个发现：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;其中 Open/Read 和 Delete 操作的性能要远高于 Create 和 Rename。&lt;/li&gt;&lt;li&gt;在 20 个并发前，TPS 随着并发数线性增长，之后就增长缓慢了，到 60 个并发已经能压到 TPS 的极限（满负载）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;再来看看 OSS 的性能情况：&lt;/p&gt;&lt;p&gt;OSS 速度比 HDFS 慢了一个数量级，但它的各种操作的速度基本保持稳定，总的 TPS 随着并发数的增长而增长，在 80 个并发下还没遇到瓶颈。受测试资源所限，未能进一步加大压测知道它的上限。&lt;/p&gt;&lt;p&gt;最后看下 JuiceFS 的表现：&lt;/p&gt;&lt;p&gt;从图中可以看出，整体趋势和 HDFS 类似，Open/Read 和 Delete 操作明显比 Create/Rename 快很多。JuiceFS 的 TPS 也是在 20 个并发以内基本保持线程增长，之后增长放缓，在 60 个并发左右达到上线。&lt;strong&gt;但 JuiceFS 增幅更快，上限更高&lt;/strong&gt;。&lt;/p&gt;&lt;h1 id=&quot;详细性能对比&quot;&gt;详细性能对比&lt;/h1&gt;&lt;p&gt;为了更直观的看出这三者的性能差异，我们直接把 HDFS、Aliyun OSS 和 JuiceFS 放在一起比较：&lt;/p&gt;&lt;p&gt;可见无论是哪种元数据操作，&lt;strong&gt;JuiceFS 的 TPS 增长更快，上限也更高&lt;/strong&gt;，明显优于 HDFS 和 OSS。&lt;/p&gt;&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;&lt;p&gt;一般我们在看一个系统的性能时，主要关注它的操作时延（单个操作所消耗的时间）和吞吐量（满负载下的处理能力），我们把这两个指标再汇总一下：&lt;/p&gt;&lt;p&gt;上图是 20 个并发下的各操作的时延（未跑满负载），可以发现：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;OSS 非常慢，尤其是 Rename 操作，因为它是通过 Copy + Delete 实现的。本文测试的还只是单个文件的 Rename，而大数据场景常用的是对整个目录的 Rename，差距会更大。&lt;/li&gt;&lt;li&gt;JuiceFS 的速度比 HDFS 更快，快一倍多。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;上图是 80 个并发时的吞吐量对比，可以发现：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;OSS 的吞吐量非常低，和其它两个产品有一到两个数量级的差距，意味着它需要使用更多的计算资源，产生更高的并发，才能获得同等的处理能力。&lt;/li&gt;&lt;li&gt;JuiceFS 比 HDFS 的处理能力高 50-200%，同样的资源能够支撑更大规模的计算。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;从以上两个核心性能指标来看，对象存储不适合要求性能的大数据分析场景。JuiceFS 作为后来者已经全面超越 HDFS，能够以更快的性能支撑更大规模的计算处理&lt;/strong&gt;。&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>70dbc83aaf1b9953ee80e4289edb0531</guid>
<title>AliExpress基于Flink的广告实时数仓建设</title>
<link>https://toutiao.io/k/filrcil</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p class=&quot;original_area_primary&quot;&gt;
                                                                                                &lt;/p&gt;

                    
                                            &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span&gt;点击上方&lt;/span&gt;&lt;strong&gt;&lt;span&gt;蓝色字体&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，选择“设为星标”&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;回复&quot;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;面试&quot;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;获取更多惊喜&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247510434&amp;amp;idx=1&amp;amp;sn=0130fa0497d91e2b2adaca76cbee4f71&amp;amp;chksm=fd3eef37ca496621e07370f33e58129d744860cb2effe7ca0635b522cfe7c958f71b3da3b6bb&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;大数据面试提升私教训练营上线&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;大数据面试提升私教训练营上线&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.0625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sq2uE6cicHYxoldXibjHyWbvjJfI6ibEm5Kw715uVJTBLdX1gkVpExwlFh22TMnLIpBq96wT1ibdccSSd3LVdSE3LQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;Hi，我是王知无，一个大数据领域的原创作者。 &lt;/section&gt;&lt;section&gt;放心关注我，获取更多行业的一手消息。&lt;/section&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;section&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;&lt;strong&gt;摘要&lt;/strong&gt;：实时数仓以提供低延时数据指标为目的供业务实时决策，本文主要介绍基于Flink的广告实时数仓建设，主要包括以下内容：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;1. 建设背景&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;2. 技术架构&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;3. 数仓架构&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;4. 实时OLAP&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;5. 实时保障&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;6. 未来规划&lt;/span&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section label=&quot;Powered by xmyeditor.com&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-role=&quot;outer&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-id=&quot;93744&quot; data-custom=&quot;#c3ebb5&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p mpa-is-content=&quot;t&quot;&gt;&lt;strong&gt;建设背景&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;广告是目前互联网流量变现的一种重要手段，广告投放的优化很大程度上依赖于广告效果数据，依托于广告曝光、点击、消耗、订单等指标调整广告投放策略，以达到最优投放效果。前期主要提供T+1效果数据，投放策略往往需要第二天才能做出调整，不能及时做出投放优化，特别在一些大促场景，实时优化显得尤为重要，需要及时调整例如人群、地域、出价等策略，以此为背景建设实时数据链路。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.9876543209876543&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/S7tIvo5xYM6LaJXxcTXHgpUfJkywIXFCYmtYK1iaAQ9Zp4q5IChibaR6CQNyibWqOyVp0zh8KD527BrYLicqfpw6WA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;648&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;目前实时数据的场景主要有以下几种：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;实时大屏&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：提供给运营、产品使用，展示核心的业务指标：曝光、点击、消耗等数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;实时特征&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：提供给算法使用，统计用户维度的行为数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;商家看板&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：提供给商家使用，展示商家的在不同维度的曝光、点击、消耗等数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;多维分析&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：提供给运营、分析师使用，实时分析广告数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-role=&quot;outer&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-id=&quot;93744&quot; data-custom=&quot;#c3ebb5&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p mpa-is-content=&quot;t&quot;&gt;&lt;strong&gt;技术架构&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;依托新一代实时计算引擎Flink的兴起，在超高性能、数据一致性保障、SQL化编程方式等特点下推动了实时数仓的发展。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当前的整体技术架构图如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3370577281191806&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/S7tIvo5xYM6SHRdDkVficwEq0ov9tNf02W5ibdkw2X2jptTR0u0tibFGrxflURkIHYH3MTKLAXKkWWqZDe7WUtK2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2148&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;在数据源侧&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，&lt;span&gt;一方面服务器日志数据与MySQL变更数据作为数仓的数据源，会被采集消息队列Kafka中；另外一方面MySQL 中的数据会通过DataX离线方式同步到HBASE中，通常是在维度建设初始化使用；&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;在数据加工侧&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，&lt;span&gt;使用Flink作为计算引擎，HBASE作为维表存储数据库，Flink任务在处理的过程中会做一些数据解析、规范化、打宽、聚合等操作；&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;在数据服务侧&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，&lt;span&gt;使用两种不同的存储引擎HBASE与Hologres，HBASE提供KV查询，应用于实时大屏、商家看板等固化查询场景， &lt;span&gt;Hologres&lt;/span&gt;用于在线分析，应用于多维分析等场景，提供多维分析能力。二者由统一数据接口服务封装，对外提供查询。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-role=&quot;outer&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-id=&quot;93744&quot; data-custom=&quot;#c3ebb5&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p mpa-is-content=&quot;t&quot;&gt;&lt;strong&gt;数仓架构&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;数仓的分层搭建需要从复用、成本、质量、扩展性等方面去考虑，实时数仓的搭建，包括层次划分、命名、主题域划分、数据域划分与离线相差不大，目前划分层次如下：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7792642140468228&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/S7tIvo5xYM6LaJXxcTXHgpUfJkywIXFCmCgx3c7J4ongQ2ystEkBeGU0hq7tajibbPvqnibJR0vAR9rTGq6CoBUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1196&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;数据源层&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：&lt;span&gt;DB日志与服务器日志，DB日志数据主要是广告商家、投放计划等物料数据；服务器日志是广告引擎曝光日志、广告点击日志、用户真实曝光日志；按照不同的业务属于又可以分为搜索广告日志、推荐广告日志。&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;中间层&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：&lt;span&gt;分为DIM层与DWD层，DIM层即维度层，其数据来源于DB日志，通过离线全量+实时增量方式完整同步操作；明细层DWD建设很重要的一个要求就是能够被复用，因此将搜索、推荐广告日志做了水平合并供下游多方使用，另外一个是维度扩充，提前做维表信息关联，避免下游多次join操作。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;应用层&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：&lt;span&gt;按照应用场景划分为实时大屏、商家后台实时指标、实时特征、实时多维分析，提供了不同维度的曝光、点击、消耗等数据。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;从当前分层架构来说，可以说与离线分层上有两个差异：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-role=&quot;outer&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-id=&quot;93744&quot; data-custom=&quot;#c3ebb5&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p mpa-is-content=&quot;t&quot;&gt;实时OLAP&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当前使用OLAP主要解决两方面的问题：&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;运营对数据的需求变化性常常是大于广告商家看数的需求，如果都是使用Flink进行预计算完成的指标，那么其开发、运维成本是非常高的；&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;mysql中的数据是可变的，经常会执行一些update操作，例如广告预算数据，预算是可实时变更的，需要知道每小时整的预算额。使用Flink去处理这类问题成本比较高、并且也不可复用。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;基于以上问题，提出了实时OLAP的架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.49586776859504134&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/S7tIvo5xYM6LaJXxcTXHgpUfJkywIXFCibvAic1iaBc9SxOBDJia1X7yLr9icAqnb0soQwU4sXcMhyiazjeO8tp7lvYw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1452&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将明细数据通过Flink处理写入OLAP中，基于OLAP一方面完成在线数据查询，另外一方面通过离线调度处理OLAP中数据，进行一个简单的分层处理，最终提供给上层查询服务使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-role=&quot;outer&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-id=&quot;93744&quot; data-custom=&quot;#c3ebb5&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p mpa-is-content=&quot;t&quot;&gt;实时保障&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整个实时数据体系保障，可分为稳定性保障、数据质量保障两个方面。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;h2 mpa-is-content=&quot;t&quot;&gt;&lt;span&gt;稳定性保障&lt;/span&gt;&lt;/h2&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;稳定性保障目前主要从压测、任务等级划分、 监控三方面实施：&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;提前压测&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，应对流量高峰期，特别是大促场景下，提前做好资源保障、任务优化等措施。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;制定保障等级&lt;/strong&gt;，从任务影响面大小、数据使用方来划分，一般情况公司层面优先于部门层面，外部使用优先于内部使用，  高优先级任务需要优先/及时响应、必要情况下做双链路保障机制；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;指标监控&lt;/strong&gt;，监控任务failover情况、checkpoint指标、GC情况、作业反压等，出现异常告警。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;h2 mpa-is-content=&quot;t&quot;&gt;&lt;span&gt;数据质量保障&lt;/span&gt;&lt;/h2&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;质量保障主要是保障数据正确性与时效性。&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;正确性&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;实时计算端到端的一致性，对数据正确性的影响，常用手段就是通过输出幂等方式保障，这种方式要求输出使用存储介质支持重写，对于不支持幂等的存储，比较常用的就是DWD层的kafka， 可能会产生重复的数据，那么在下游使用的时候可以使用row_number() 语法进行去重，保证相同的key不会被多次计算；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;离线与实时的一致性，需要保证使用数据源一致、加工业务逻辑一致。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;时效性&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;保障实时指标的时效性，常用的手段就是提前压测与监控。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;提前压测：提前发现可能会影响任务处理速度的瓶颈，常见的就是数据倾斜、大状态的算子操作(join)；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;监控：监控任务当前的消费进度，在数据源处通过使用数据时间与当前系统时间对比判断其消费进度。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-role=&quot;outer&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-id=&quot;93744&quot; data-custom=&quot;#c3ebb5&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p mpa-is-content=&quot;t&quot;&gt;未来规划&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;h2 mpa-is-content=&quot;t&quot;&gt;&lt;span&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;实时DWS层建设&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当前虽然做了统一DWD层的建设，但是在应用层商家看板、实时特征等的场景应用中，仍然存在重复建设的工作，例如小时维度的商品曝光指标被多个链路重复计算，这种存在数据一致性的风险，另外也会造成资源浪费，可以将公共的汇总指标抽象出来统一计算，建设DWS层。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;h2 mpa-is-content=&quot;t&quot;&gt;&lt;span&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;实时OLAP 的深度应用&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当前OLAP的应用场景主要是运营侧使用，但是对于商家侧看板数据也可以做进一步的应用。目前商家看板数据使用HBASE作为存储，然而实际的看数需求是需要排序、分页等操作，这个功能的实现大多数是通过将数据查询出来，然后基于内存去处理，这种方式开发成本高、不易维护，可通过OLAP天然支持排序、分页去解决这些问题。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;h2 mpa-is-content=&quot;t&quot;&gt;&lt;span&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;基于Hologres的HASP架构简化数仓架构&lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Hologres &lt;/span&gt;是阿里巴巴自主研发的一款交互式分析产品，其重要的理念就是&lt;span&gt;HASP, &lt;/span&gt;即&lt;span&gt;hybrid serving/analytical processing&lt;/span&gt;，服务分析一体化，通过其行存结构提供高频&lt;span&gt;kv&lt;/span&gt;查询，列存结构提供多维分析能力。可使用&lt;span&gt;Hologres&lt;/span&gt;替换&lt;span&gt;HBASE, &lt;/span&gt;简化整个技术架构链路。&lt;/span&gt;&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果这个文章对你有帮助，不要忘记 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;「在看」&lt;/strong&gt; &lt;strong&gt;「点赞」&lt;/strong&gt; &lt;strong&gt;「收藏」&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; 三连啊喂！&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4662576687116564&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2MPL7m13Yrluz8WJicNiaVRsiaCqArkyO99exPDGicFIH6AF7ZWRpT7huEHTT4z45Jibay1ZebmsSSqiaeA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;978&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;98469&quot;&gt;&lt;section hm_fix=&quot;349:393&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.10979228486646884&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/BSBqCXrZtzAicMToibKuIysLrB62M5A5YaLhZg6z86tI7ZeEZqTLLYyNrmlzrkyKUN5kNeUFicVC3bMP1GEqKz1OQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1011&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;98469&quot;&gt;&lt;section hm_fix=&quot;349:393&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247504680&amp;amp;idx=1&amp;amp;sn=9f2547b40316b8dc8a748bbc8b6b6015&amp;amp;chksm=fd3e95bdca491cab9e0badbd7a1144f7511638ae80db684fd5383c771129a16bb08ba5e72515&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247510040&amp;amp;idx=1&amp;amp;sn=aa335f25965975731173916f012d56f4&amp;amp;chksm=fd3eee8dca49679b82f632048fb64d21fac01497d1a0fe33917edb01e194caf0f9a1930a55ce&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;2022年全网首发|大数据专家级技能模型与学习指南(胜天半子篇)&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;2022年全网首发|大数据专家级技能模型与学习指南(胜天半子篇)&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247508317&amp;amp;idx=1&amp;amp;sn=0bcb7fb6997b42306994b890eaa0d47f&amp;amp;chksm=fd3ee7c8ca496ede347a2971002c6ea68dcfd70abeeb90b43c8b02a2a60ebc7cec3a87ef7d52&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;互联网最坏的时代可能真的来了&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;互联网最坏的时代可能真的来了&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247507860&amp;amp;idx=1&amp;amp;sn=807ac5003762f29c127bc4071dcebe33&amp;amp;chksm=fd3e9901ca4910178cfc816043ea86c29f881f70cd943d252de9ae2e21cb7e8ba80bff162e1b&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;我在B站读大学，大数据专业&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;我在B站读大学，大数据专业&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247499604&amp;amp;idx=1&amp;amp;sn=d938dfb30d221774704982d2938b30c1&amp;amp;chksm=fd3eb9c1ca4930d76a391241333de461ca22d2aa27472eab3cffab1564872ae37f1b48fe2d3c&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;我们在学习Flink的时候，到底在学习什么？&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247504856&amp;amp;idx=2&amp;amp;sn=6f62e2a0c756ce56773eed253d2f41ee&amp;amp;chksm=fd3e954dca491c5b732b7e2aa46db32efbc3f690e528522098659bb3c6e78e1582ab4529b5dc&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;193篇文章暴揍Flink，这个合集你需要关注一下&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247504742&amp;amp;idx=1&amp;amp;sn=8765c198d8ad66219a7bcabb221e4a23&amp;amp;chksm=fd3e95f3ca491ce52d0724b9e4154a47af0f5ea349e1e184c8fbc65aa17c0000242aa9b58429&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Flink生产环境TOP难题与优化，阿里巴巴藏经阁YYDS&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247504813&amp;amp;idx=1&amp;amp;sn=f5cd6ae2aa2b1e30f87a5ae55971c514&amp;amp;chksm=fd3e9538ca491c2eb191677d070f2c7e4f1098eece00e256d6205b8a5d21b21c1e74f875f16f&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;Flink CDC我吃定了耶稣也留不住他！| Flink CDC线上问题小盘点&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI0NjU2NDkzMQ==&amp;amp;mid=2247492567&amp;amp;idx=1&amp;amp;sn=1f693e549f76622725b936041ff8896e&amp;amp;chksm=e9bff2fbdec87bedecbdeed4547d7d612c72fc8d4918614a26a4e31666cf0128fd57b537f347&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;我们在学习Spark的时候，到底在学习什么？&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247504834&amp;amp;idx=1&amp;amp;sn=46ca1a3924b8fdb89ac1c2acb0319d6c&amp;amp;chksm=fd3e9557ca491c41d837b917639ea62007ea16d3c2cc6c0c02d1f8a8c6e44318f5183b787c46&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;在所有Spark模块中，我愿称SparkSQL为最强！&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247502750&amp;amp;idx=1&amp;amp;sn=bd9a9173d060dc4e4ebd49c8efc6acfe&amp;amp;chksm=fd3e8d0bca49041dea84da93910e5efdc4935e520525c09887c986691377aeb48e5cf7fb5667&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;硬刚Hive | 4万字基础调优面试小总结&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247504382&amp;amp;idx=2&amp;amp;sn=550b78802acfe727e0e77cd9195f8784&amp;amp;chksm=fd3e976bca491e7db2b8b2446d231736df01bbf13653804d680ac4390597ec17fa466ad4ae83&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;数据治理方法论和实践小百科全书&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247503741&amp;amp;idx=1&amp;amp;sn=e5039be93123f2e337013756a818bfc3&amp;amp;chksm=fd3e89e8ca4900fe603b63c5722a6fb8a32bd63d6ba23e0028851948a71b877eb1f742d95087&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;标签体系下的用户画像建设小指南&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247503675&amp;amp;idx=1&amp;amp;sn=3ee6af64d0126c78b48cad219308f81e&amp;amp;chksm=fd3e89aeca4900b8b8954e9569ee3c0877881fac8c792bfafc22e7e9d3e8524da8eb860d33d8&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;4万字长文 | ClickHouse基础&amp;amp;实践&amp;amp;调优全视角解析&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI0NjU2NDkzMQ==&amp;amp;mid=2247492567&amp;amp;idx=2&amp;amp;sn=57ecc77718f1b6f2f262d62e8318dcc9&amp;amp;chksm=e9bff2fbdec87bedb1986765bfae7dbabb9aece45b0b2af147bbad1ac5d79ebc934c64df40ea&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;【面试&amp;amp;个人成长】2021年过半，社招和校招的经验之谈&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247504478&amp;amp;idx=1&amp;amp;sn=14efef3868ba42bd044f9618745a7fdc&amp;amp;chksm=fd3e94cbca491dddb961b7b8b93105b2869c5bcf4c03f9f0dc83ad62be0dce4c124b52ed0ba3&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;大数据方向另一个十年开启 |《硬刚系列》第一版完结&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247504410&amp;amp;idx=1&amp;amp;sn=7e81ab5a324395eb0f12397c40247ca1&amp;amp;chksm=fd3e948fca491d9946456acbd93b2d651ae4d7a7d0127a211981e08f50f377e60d1b7c0d7b3a&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;我写过的关于成长/面试/职场进阶的文章&lt;/a&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;98469&quot;&gt;&lt;section hm_fix=&quot;349:393&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247504783&amp;amp;idx=1&amp;amp;sn=72aed147a459368ed934a007a2df3bc9&amp;amp;chksm=fd3e951aca491c0cade212390011eca7d8a68951fee6aa2844b8f4d14bcbd5b3ed26305d69dc&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;当我们在学习Hive的时候在学习什么？「硬刚Hive续集」&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>cf4cf5c4c47ca5111083c56833e051e8</guid>
<title>多功能猫咪爬架，点击链接立即购买！</title>
<link>https://toutiao.io/k/2qh6etz</link>
<content:encoded>&lt;div&gt;&lt;body id=&quot;readabilityBody&quot;&gt;


&lt;/body&gt;
&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b1bb9857fcd62f08402deec07ba514a5</guid>
<title>使用 Flink Hudi 构建流式数据湖平台</title>
<link>https://toutiao.io/k/wded8mj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p id=&quot;js_tags&quot; class=&quot;article-tag__list single-tag__wrp js_single js_wx_tap_highlight wx_tap_card&quot; data-len=&quot;1&quot; role=&quot;link&quot; aria-labelledby=&quot;js_article-tag-card__left js_a11y_comma js_article-tag-card__right&quot;&gt;
                                            
                                                                                    &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__left&quot; class=&quot;article-tag-card__left&quot;&gt;
                                    &lt;span class=&quot;article-tag-card__title&quot;&gt;收录于话题&lt;/span&gt;
                                    &lt;span class=&quot;article-tag__item-wrp no-active js_tag&quot; data-url=&quot;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU3Mzg4OTMyNQ==&amp;amp;action=getalbum&amp;amp;album_id=2216860909833109508#wechat_redirect&quot; data-tag_id=&quot;&quot; data-album_id=&quot;2216860909833109508&quot; data-tag_source=&quot;4&quot;&gt;
                                        &lt;span class=&quot;article-tag__item&quot;&gt;#FFA2021&lt;/span&gt;
                                    &lt;/span&gt;
                                &lt;/span&gt;
                                &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__right&quot; class=&quot;article-tag-card__right&quot;&gt;12个&lt;/span&gt;
                                                                                        &lt;/p&gt;

                
                                
                
                

                
                                                                

                
                                


                
                
                
                
                                                
                                                                
                                
                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;&lt;span&gt;▼ 关注「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;ApacheFlink&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，看更多大咖 &lt;span&gt;▼&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_iframe&quot; data-pluginname=&quot;videosnap&quot; data-id=&quot;export/UzFfAgtgekIEAQAAAAAAeL0gajhnQwAAAAstQy6ubaLX4KHWvLEZgBPEzoIcKX1BQNr8zNPgMIsqbqUjF9_AtHqJ6X6fKkrA&quot; data-url=&quot;https://findermp.video.qq.com/251/20304/stodownload?encfilekey=rjD5jyTuFrIpZ2ibE8T7YmwgiahniaXswqzrUOk33AGVzwTCX1xXbtNH4L736QomxjiaprZX4j8ucdF5X48zeKa6oqseJMzMSswia3jKgt9mCtGujAfp5eZwaBQ&amp;amp;adaptivelytrans=0&amp;amp;bizid=1023&amp;amp;dotrans=0&amp;amp;hy=SH&amp;amp;idx=1&amp;amp;m=&amp;amp;scene=0&amp;amp;token=AxricY7RBHdUIAgyzcKpVnfFoTibv3px4URrpNaPQxrDqqMibQPR2PIt7wGDQIOicb9yia9YjE9TKbXE&quot; data-headimgurl=&quot;http://wx.qlogo.cn/finderhead/XxT9TiaJ1ibf3rFKHtt2yXrJpCDia37R3rjlyd6wzzicd55QmIWDrKHqRA/0&quot; data-username=&quot;v2_060000231003b20faec8c7e7881dc1dccd00ea35b077960b9c6a44e8a5c5efa3651fa144024c@finder&quot; data-nickname=&quot;ApacheFlink&quot; data-desc=&quot;Apache Hudi Committer，阿里巴巴技术专家陈玉兆 (玉兆)，介绍如何使用 Flink Hudi 构建流式数据湖平台#Flink#大数据#数据湖#实时计算&amp;#10;&quot; data-nonceid=&quot;11178154759566799656&quot; data-type=&quot;video&quot;/&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;本文整理自阿里巴巴技术专家陈玉兆 (玉兆)、阿里巴巴开发工程师刘大龙 (风离) 在 Flink Forward Asia 2021 实时数据湖专场的演讲。主要内容包括：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Apache Hudi 101&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Flink Hudi Integration&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Flink Hudi Use Case&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Apache Hudi Roadmap&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Tips：&lt;/strong&gt;点击&lt;/span&gt;&lt;span&gt;&lt;strong&gt;「阅读原&lt;/strong&gt;&lt;strong&gt;文」&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;查看原文视频 &amp;amp; 演讲PDF～&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;一、Apache Hudi 101&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;提到数据湖，大家都会有这样的疑问，什么是数据湖？为什么数据湖近两年热度很高？数据湖其实不是一个新的概念，最早的数据湖概念在 80 年代就已经提出，当时对数据湖的定义是原始数据层，可以存放各种结构化、半结构化甚至非结构化的数据。像机器学习、实时分析等很多场景都是在查询的时候确定数据的 Schema。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n17&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxtVC2zXY6m8iaHQ0F5h0OMmYhukaVkupbmo2hDnrugW2NvF6c8QL2EJg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;湖存储成本低、灵活性高的特性，非常适用于做查询场景的中心化存储。伴随着近年来云服务的兴起，尤其是对象存储的成熟，越来越多的企业选择在云上构建存储服务。数据湖的存算分离架构非常适合当前的云服务架构，通过快照隔离的方式，提供基础的 acid 事务，同时支持对接多种分析引擎适配不同的查询场景，可以说湖存储在成本和开放性上占了极大优势。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n21&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxdOGBFK51O8JDvktPlTUJSoGPQyFIZWyT7aOIaTpbIH0r2kbuhho2wQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当前的湖存储已经开始承担数仓的功能，通过和计算引擎对接实现湖仓一体的架构。湖存储是一种 table format，在原有的 data format 基础上封装了 table 的高级语义。Hudi 从 2016 年开始将数据湖投入实践，当时是为了解决大数据场景下文件系统上的数据更新问题，Hudi 类 LSM 的 table format 当前在湖格式中是独树一帜的，对近实时更新比较友好，语义也相对完善。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Table format 是当前流行的三种数据湖格式的基础属性，而 Hudi 从项目之初就一直朝着平台方向去演化，拥有比较完善的数据治理和 table service，比如用户在写入的时候可以并发地优化文件的布局，metadata table 可以大幅优化写入时查询端的文件查找效率。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面介绍一些 Hudi 的基础概念。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n29&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxgSBptmr2LiaDOm9UPWGXg4IICE0htkesnZJ5uNibw0LG9eTlopbwheaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Timeline service 是 Hudi 事务层的核心抽象，Hudi 所有数据操作都是围绕着 timeline service 来展开的，每次操作通过 instant 抽象绑定一个特定的时间戳，一连串的 instant 构成了 timeline service，每一个 instance 记录了对应的 action 和状态。通过 timeline service，Hudi 可以知道当前表操作的状态，通过一套文件系统视图的抽象结合 timeline service，可以对 table 当前的 reader 和 writer 暴露特定时间戳下的文件布局视图。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n33&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxFkYw0yAaKq71SFCtqJD2x7qXkQnPWPeQ7tnTX8Hw3JWsIcibZo6VvEg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;file group 是 Hudi 在文件布局层的核心抽象，每一个 file group 相当于一个 bucket，通过文件大小来来划分，它的每次写入行为都会产生一个新的版本，一个版本被抽象为一个 file slice，file slice 内部维护了相应版本的数据文件。当一个 file group 写入到规定的文件大小的时候，就会切换一个新的 file group。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Hudi 在 file slice 的写入行为可以抽象成两种语义， copy on write 和 merge on read。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n39&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxSGjBdRZG8Fc0SX2jUGhUYoibb0lzI70QQuoAhibjeGFsNbgicib4ibnQx6A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;copy on write 每次都会写全量数据，新数据会和上一个 file slice 的数据 merge，然后再写一个新的 file slice，产生一个新的 bucket 的文件。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n43&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3Wxoyl60jtlcicickY8V77jTLhHoVmOYHSn4biaiaMk0D9LFnLaf9JNRZTOHg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;而 merge on read 则比较复杂一些，它的语义是追加写入，即每次只写增量数据，所以不会写新的 file slice。它首先会尝试追加之前的 file slice，只有当该写入的 file slice 被纳入压缩计划之后，才会切新的 file slice。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n47&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;二、Flink Hudi Integration&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n47&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p cid=&quot;n48&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3Wx5c2tQSLT0e5cicC3Db5QKVYc9ic545NbRhlxZR80jPMlxeWlMO7SzyrA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink Hudi 的写入 pipeline 由几个算子构成。第一个算子负责将 table 层的 rowdata 转换成 Hudi 的消息格式 HudiRecord。接着经过一个 Bucket Assigner，它主要负责将已经转好的 HudiRecord 分配到特定的 file group 中，接着分好 file group 的 record 会流入 Writer 算子执行真正的文件写入。最后还有一个 coordinator，负责 Hudi table 层的 table service 调度以及新事务的发起和提交。此外，还有一些后台的清理角色负责清理老版本的数据。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n52&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3Wx1fjGqgC5sAa8SSQjRBPmGWPAibN86ibh54FdDeb3VEYKniaOTfI3gz7icA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当前的设计中，每一个 bucket assign task 都会持有一个 bucket assigner，它独立维护自己的一组 file group。在写入新数据或非更新 insert 数据的时候，bucket assign task 会扫描文件视图，优先将这一批新的数据写入到被判定为小 bucket 的 file group 里。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;比如上图， file group 默认大小是 120M，那么左图的 task1 会优先写到 file group1和 file group2，注意这里不会写到 file group3，这是因为 file group3 已经有 100M 数据，对于比较接近目标阈值的 bucket 不再写入可以避免过度写放大。而右图中的 task2 会直接写一个新的 file group，不会去追加那些已经写的比较大的 file group 了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n58&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxhmfSLA5fgia3jEe15QbBqmS8ByYzmic2a9axicRflbM6pr16jBUcJPThQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接下来介绍 Flink Hudi 写流程的状态切换机制。作业刚启动时，coordinator 会先尝试去文件系统上新建这张表，如果当前表不存在，它就会去文件目录上写一些 meta 信息，也就是构建一个表。收到所有 task 的初始化 meta 信息后，coordinator 会开启一个新的 transaction，write task 看到 transaction 的发起后，就会解锁当前数据的 flush 行为。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Write Task 会先积攒一批数据，这里有两种 flush 策略，一种是当前的数据 buffer 达到了指定的大小，就会把内存中的数据 flush 出去；另一种是当上游的 checkpoint barrier 到达需要做快照的时候，会把所有内存中的数据 flush 到磁盘。每次 flush 数据之后都会把 meta 信息发送给 coordinator。coordinator 收到 checkpoint 的 success 事件后，会提交对应的事务，并且发起下一个新的事务。writer task 看到新事务后，又会解锁下一轮事务的写入。这样，整个写入流程就串起来了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n64&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3Wx7IGBlntbzPdrBEiatFBVSbDHz3cErNUFPwIQBibrPVtCYpEXqKZOoB7g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink Hudi Write 提供了非常丰富的写入场景。当前支持对 log 数据类型的写入，即非更新的数据类型，同时支持小文件合并。另外对于 Hudi 的核心写入场景比如更新流、CDC 数据也都是 Hudi 重点支持的。同时，Flink Hudi 还支持历史数据的高效率批量导入，bucket insert 模式可以一次性将比如 Hive 中的离线数据或者数据库中的离线数据，通过批量查询的方式，高效导入 Hudi 格式中。另外，Flink Hudi 还提供了全量和增量的索引加载，用户可以一次性将批量数据高效导入湖格式，再通过对接流的写入程序，实现全量接增量的数据导入。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3Wxu1TDhDjLuvwCLiaaTAZKibUicXSXkEiaWk6nia2nM64TyEzLgXU2OD5oudA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink Hudi read 端也支持了非常丰富的查询视图，目前主要支持的有全量读取、历史时间 range 的增量读取以及流式读取。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n72&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3Wx6AJ9eoFjaapppm1zyckwIhayq2Q2zFohDGStqiaQHS9HLFxYeFfPwEQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上图是一段通过 Flink sql 写 Hudi 的例子，Hudi 支持的 use case 非常丰富，也尽量简化了用户需要配置的参数。通过简单配置表 path、 并发以及 operation type，用户可以非常方便地将上游的数据写入到 Hudi 格式中。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n76&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;三、Flink Hudi Use Case&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n76&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;下面介绍 Flink Hudi 的经典应用场景。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n79&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxtqD5ApSWY0ESDl0RYem5mluCaoGX983ZVCN3f2LHAGTlO6zABjTXQg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;第一个经典场景是 DB 导入数据湖。目前 DB 数据导入数据湖有两种方式：可以通过 CDC connector 一次性将全量和增量数据导入到 Hudi 格式中；也可以通过消费 Kafka 上的 CDC changelog，通过 Flink 的 CDC format 将数据导入到 Hudi 格式。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n83&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxLTeAo5pEdH7voTlNWxDa0TESibicPlsuVxFBuRyVnWm4tibVAz8mFkhaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;第二个经典场景是流计算的 ETL (近实时的 olap 分析)。通过对接上游流计算简单的一些 ETL，比如双流 join 或双流 join 接一个 agg，直接将变更流写入到 Hudi 格式中，然后下游的 read 端可以对接传统经典的 olap 引擎比如 presto、spark 来做端到端的近实时查询。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n87&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxdJWOmmricutpGwYcRofzf5DEotM9IObQVhroib3cibbPKN3cTgaM1DXZQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;第三个经典场景和第二个有些类似， Hudi 支持原生的 changelog，也就是支持保存 Flink 计算中行级别的变更。基于这个能力，通过流读消费变更的方式，可以实现端到端的近实时的 ETL 生产。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n91&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxQZz4rHGut8tN96BYPDD6u3josBXw5ssCzzmwu90pNAMkjCUBxggatg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;未来，社区两个大版本主要的精力还是放在流读和流写方向，并且会加强流读的语义；另外在 catalog 和 metadata 方面会做自管理；我们还会在近期推出一个 trino 原生的 connector 支持，取代当前读 Hive 的方式，提高效率。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n95&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;四、Apache Hudi Roadmap&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n95&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;下面是一个 MySql 到 Hudi 千表入湖的演示。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section/&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;首先数据源这里我们准备了两个库，benchmark1 和 benchmark2，benchmark1 下面有 100 张表，benchmark2 下面有 1000 张表。因为千表入湖强依赖于 catalog，所以我们首先要创建 catalog，对于数据源我们要创建 MySql catalog，对于目标我们要创建 Hudi catalog。MySql catalog 用于获取所有源表相关的信息，包括表结构、表的数据等。Hudi catalog 用于创建目标。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n101&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6186252771618626&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxyXU7kMfvdd4u4LD5VsArwqYibbMia5dzGicnVRTlspK8V6S3ylLnAcicwg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;902&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;执行两条 sql 语句以后，两条 catalog 就创建成功了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n105&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4866962305986696&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxMJJmJiaIH46kZpqnmRSLLxSDqhrDDzrqMPnNXxeGor9biaKUFYhAqorQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;902&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接下来到作业开发页面创建一个千表入湖的作业。只需要简单的 9 行 SQL，第一种语法是 create database as database，它的作用是把 MySql benchmark1 库下所有的表结构和表数据一键同步到 Hudi CDS demo 库，表的关系是一对一映射。第二条语法是 create table as table，它的作用是把 MySql benchmark2 库下所有匹配 sbtest. 正则表达式的表同步到 Hudi 的 DB1 下的 ctas_dema 表里面，是多对一的映射关系，会做分库分表的合并。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接着我们运行并上线，然后到作业运维的页面去启动作业，可以看到配置信息已经更新了，说明已经重新上线过。接着点击启动按钮，启动作业。然后就可以到作业总览页面查看作业相关的状态信息。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n111&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5565410199556541&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu45oR8sxcKulPxrMcaaib3Wx0gNMmK2pGnQtiaqncNcJPWofpF1kicDHgtVib2yeBdz6CSPZJsrnuHSAQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;902&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上图是作业的拓扑，非常复杂，有 1100 张源表和 101 张目标表。这里我们做了一些优化 —— source merge，把所有的表合并到一个节点里，可以在增量 binlog 拉取阶段只拉取一次，减轻对 MySql 的压力。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n115&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5421286031042128&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxMEic48icIkoeYDluVibT4d03U8lOosWtKgWU9FBDLaS9h4QkXydLRsYgA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;902&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接下来刷新 oss 页面，可以看到已经多了一个 cdas_demo 路径，进入 subtest1 路径，可以看到已经有元数据在写入，表明数据其实在写入过程中。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n119&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5631929046563193&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu45oR8sxcKulPxrMcaaib3Wxg0nfLKKIjlBodpmzt1SksoCB6R6VE0SWLibYVTx1y081bDA0EbIuV8g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;902&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;再到作业开发页面写一个简单的 SQL 查询某张表，来验证一下数据是否真的在写入。执行上图 SQL 语句，可以看到数据已经可以查询到，这些数据与插入的数据是一致的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们利用 catalog 提供的元数据能力，结合 CDS 和 CTS 语法，通过几行简单的 SQL，就能轻松实现几千张表的数据入湖，极大简化了数据入湖的流程，降低了开发运维的工作量。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;往期精选&lt;/p&gt;&lt;/section&gt;&lt;img data-ratio=&quot;2&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu45oR8sxcKulPxrMcaaib3Wx128yAwxu3FRYPKbcibaoicoRUZKN6dPias3kt22jhwGDZztreO1zq2aRg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;50&quot;/&gt; &lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247495687&amp;amp;idx=1&amp;amp;sn=239cce428d8fa45f74b017c5671c3fb4&amp;amp;chksm=fd387e45ca4ff753ad6d4d321737bf6eee7744ddbb1a90cef38a85c68c738248ec6c46fa67fd&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4255556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxGWkQWo82SamV0WLLVgu0qVJNpFPxVNZP7B65lzB2Gc8ic5dYcmhicdJw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247495624&amp;amp;idx=1&amp;amp;sn=9ce5ad1aac58f5fc85a9ea317deb5ad2&amp;amp;chksm=fd38618aca4fe89c55c952af13d35a15a4445077106681f7e3a150c1587049dd204267f39b34&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4255556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3WxYPZAFWz6LomEZn4ib3pbphIyBDEdGrFmTGicDlccMibrtlekaicN55IBzQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247495570&amp;amp;idx=1&amp;amp;sn=0438c235ae2cb766fe5959e3f7151290&amp;amp;chksm=fd3861d0ca4fe8c6b167cf58f8917ae859ba25db5f49e4c142b8a32afbfd5e8b51c739e647fe&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4255556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu45oR8sxcKulPxrMcaaib3Wx6Tb3icoOqic2P8BV1pjw12XnpQickKLyZAib6umpO2WPWCF7z2xjqwPH2w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;▼ 关注「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Apache Flink&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，获取更多技术干货 &lt;span&gt;▼&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU3Mzg4OTMyNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6FJHxaI14AsXuzeg4SybT0hiaCSohrIY75oiaOMzhQU7RouiafjNa76k2CtD6xxB2JqnawqFqV3zg3A/0?wx_fmt=png&quot; data-nickname=&quot;Apache Flink&quot; data-alias=&quot;apacheflinkcc&quot; data-signature=&quot;Flink 中文社区官微，Flink PMC 维护&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;更多 Flink 相关技术问题，可扫码加入社区钉钉交流群～&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100010716&quot; data-ratio=&quot;1.2078189300411524&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6PUTQaA1BP3Fb8uViccQpspmTibIYEfM7Wv6VACia9CDQfcN8huMVCafZ5s36wThUmbYRTOzMu4hd8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;972&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;img class=&quot;__bg_gif rich_pages wxw-img&quot; data-fileid=&quot;100010714&quot; data-ratio=&quot;1&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/Z6bicxIx5naLWBBEcl44aIic1Mthe1nZiaramW5s4e8WwyCYYbTzu6uPBpgI6sxNXNymEnOYKpJpcrItUia7lS64mA/640?wx_fmt=gif&quot;/&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;戳我，查看原文视频&amp;amp;演讲PDF～&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>