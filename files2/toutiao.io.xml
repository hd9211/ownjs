<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>12e25819a9f9a8900a28feee83ff66ca</guid>
<title>流量复制方案对比：TCPCopy vs Goreplay</title>
<link>https://toutiao.io/k/cpf8p4q</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;「流量复制」常常应用在准生产环境的测试中，将线上的流量复制到一个准生产环境服务中，测试新功能和服务的承压能力。流量复制可以完全模拟线上的流量，对复杂的业务场景进行真实的服务测试，又不会对生产服务产生任何副作用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于复杂的流量复制应用场景和需求，完全可以立项开发一套完整的复制架构，可参考字节团队自研的 &lt;span&gt;ByteCopy&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt; 项目。而对于一些简单的需求，开源的工具基本可以搞定。开源的流量复制工具有很多，常用的有 goreplay、tcpreplay、tcpcopy 等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文主要来探讨下 tcpcopy 和 goreplay 的方案实现，废话不多说开整。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.57&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sM0hH9BhiaDcSWIdf6OZ7OWfWvYuQcJLx8CvnL8kFib9awH0CHQiaJSLt4FmAVnbCb6icYL6js1iatjyDLdCia3hu9qA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1200&quot;/&gt;&lt;figcaption&gt;目录&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;tcpcopy 方案实现&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;tcpcopy 简介&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;tcpcopy 由网易技术部&lt;span&gt;王斌&lt;/span&gt;&lt;sup&gt;[2]&lt;/sup&gt;等开发，并于 2011 年 9 月开源的。tcpcopy 最新架构如下（来自作者王斌博客：https://blog.csdn.net/wangbin579/article/details/8949315）：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.9359165424739195&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sM0hH9BhiaDcSWIdf6OZ7OWfWvYuQcJLxhf6Faic1pY8lx4YDbtxv0m21yCYmotlDHNs3IuwYcSwicWB2AxFNAPMg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;671&quot;/&gt;&lt;figcaption&gt;架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;tcpcopy 主要有两个组件构成 tcpcopy client 和 intercept 。client 端负责复制流量和转发，intercept 负责对回应流量的拦截和 tcpcopy 的链接处理。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;tcpcopy 搭建&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实例环境如下，下面来阐述下整个架构的搭建过程：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;192.168.33.11 生产服务器，部署 tcpcopy client&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;192.168.33.12 辅助服务器，部署 intercept&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;192.168.33.13 测试服务器&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;各组件可直接从 github 下载源码包，编译安装：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;# 起压机部署 tcpcopy client 192.168.33.11&lt;/span&gt;&lt;br/&gt;wget https://github.com/session-replay-tools/tcpcopy/archive/1.0.0.tar.gz&lt;br/&gt;tar xvf 1.0.0.tar.gz&lt;br/&gt;&lt;span&gt;cd&lt;/span&gt; tcpcopy-1.0.0&lt;br/&gt;./configure --prefix=/opt/tcpcopy&lt;br/&gt;make&lt;br/&gt;make install&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 辅助机部署 intercept 192.168.33.12 , 截获包需要依赖 libpcap 抓包函数库&lt;/span&gt;&lt;br/&gt;yum -y install libpcap-devel&lt;br/&gt;&lt;span&gt;# ubuntu&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# apt install -y libpcap-dev&lt;/span&gt;&lt;br/&gt;https://github.com/session-replay-tools/intercept/archive/1.0.0.tar.gz&lt;br/&gt;tar xvf 1.0.0.tar.gz&lt;br/&gt;&lt;span&gt;cd&lt;/span&gt; intercept-1.0.0&lt;br/&gt;./configure --prefix=/opt/tcpcopy/&lt;br/&gt;make&lt;br/&gt;make install&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;安装完之后，先启动 intercept，运行如下命令：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;/opt/tcpcopy/sbin/intercept -i enp0s8 -F &lt;span&gt;&#x27;tcp and src port 8000&#x27;&lt;/span&gt; -d&lt;br/&gt;&lt;span&gt;# -i，指定网卡 enp0s8&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# -F，过滤，语法和pcap抓包工具一直，如tcpdump&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# -d，以domain的形式启动。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# 其他参数可 -h 查看。&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;启动 intercept 之后，再启动 tcpcopy client 。tcpcopy 启动依赖 intercept ，启动时确保 intercept 启动成功。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;/opt/tcpcopy/sbin/tcpcopy -x 8000-192.168.33.13:8000 -s 192.168.33.12 -c 192.168.1.x -n 2 -d&lt;br/&gt;&lt;span&gt;# -x，复制本地8000端口的流量，转发到192.168.33.13机器的8000端口&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# -s，辅助服务器intercept 地址&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# -c，修改转发包的原地址为该地址段的地址，这里也可以是明确的ip。这个ip端用来伪装数据包，方便intercept做路由劫持。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# -n，流量倍数&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# -d，以domain的形式运行&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在测试服务器添加拦截路由，如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;# 测试机 192.168.33.13&lt;/span&gt;&lt;br/&gt;route add -net 192.168.1.0 netmask 255.255.255.0 gw 192.168.33.12&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该路由相当于把到 192.168.1.0 网段的包都走网关 192.168.33.12，对测试服务器的回包做伪地址拦截。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这便是 tcpcopy 的整个架构部署了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;包流向分析&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我们抓包看看这个过程中包是如何流动的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我在 tcpcopy client 机器 192.168.33.11 和测试机器 192.168.33.13 使用 &lt;code&gt;python -m SimpleHTTPServer&lt;/code&gt; 分别起了一个 8000 端口的服务用来测试，从我本机 192.168.33.1 发送请求，在三台机器上抓包。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;tcpcopy client 机器 192.168.33.11 包信息如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3251231527093596&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sM0hH9BhiaDcSWIdf6OZ7OWfWvYuQcJLxzTB8hE02CLOhqYsJCG2bToEArPXUuFcn8lK9MwDrD2ibwf9WiaPfMicicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1827&quot;/&gt;&lt;figcaption&gt;tcpcopy&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;红色标注块为我本机（192.168.33.1）和 tcpcopy client 机器（192.168.33.11）的正常请求交换，从三次握手，到 http 请求，到最后的断链。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;蓝色标注块则为 tcpcopy 复制的流量，可以看到为了让 intercepter 拦截回包流量，tcpcopy 已将包源 ip 地址替换为我们指定的伪网段（192.168.1.0）的地址，这样在回包时，就会根据测试服务器上的路由将回包指向辅助服务器 intercept，避免对生产流量造成影响。这也是为什么复制流量三次握手和 http 都没有回包的原因。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看测试服务器 192.168.33.13 的包：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.1618685497012493&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sM0hH9BhiaDcSWIdf6OZ7OWfWvYuQcJLx9wt7w3pZWKVZjeFuqbr4gQLCpCcWRn6uKcHSmLUYHPI3QM33dlFEZg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1841&quot;/&gt;&lt;figcaption&gt;test server&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;测试服务器的包和正常流量包一样，三次握手到 http 请求，最后断连。这里和测试服务器 192.168.33.13 交互的源地址 ip 已经被 tcpcopy 替换为伪 ip 192.168.1.1 。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看 intercept 192.168.33.12 的包：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.23268698060941828&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sM0hH9BhiaDcSWIdf6OZ7OWfWvYuQcJLxgTGadLOqQHMs6cSpdcB7FoVCOhdkbYyytKmfMr5KCIGQEGO0A2eiapg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1805&quot;/&gt;&lt;figcaption&gt;image&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到辅助服务器拦截下来的请求，标注块 1 为复制流量三次握手时的回包，标注块 2 为 http 请求的回包，这便是 intercept 的拦截功能。可以看到在标注块 1、2 之后，辅助服务器（192.168.33.12）和 tcpcopy 服务器（192.168.33.11）进行了数据交换，这部分便是 intercept 的 tcp 处理功能，它把有用的信息返回给 tcpcopy 以便能使 tcpcopy 和测试机的 tcp 链接完成。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据上边抓包，我们得到了和架构图一样的包流动过程，总结如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;生产流量正常请求，服务正常回应。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;tcpcopy 服务在生产机器上复制流量，并修改流量包的源 ip 地址为我们指定的伪网络段(-c 参数指定)，之后将流量转发到测试服务器。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;测试服务器，接受到流量，但包的源地址为伪网络段的地址，回包时根据提前配置好的伪路由，将回包导流到辅助服务器。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;辅助服务器接收测试服务器的回包，但是并不转发。而是解包，只返回部分必要的信息给 tcpcopy，以便完成 tcpcopy 和测试服务器之间的 tcp 交互。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据官方文档，我们还需要注意几个问题：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;辅助服务器不做包的转发，需要关闭内核参数 &lt;code&gt;ip_forward&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在做测试时，注意上行流量的过滤和测试数据源的隔离，防止对生产数据造成多次操作的影响。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;上边为在线实时的复制模式，tcpcopy 还支持离线方式，具体可查阅&lt;span&gt;文档&lt;/span&gt;&lt;sup&gt;[3]&lt;/sup&gt;。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;辅助机需要和测试机在一个网段，以便辅助机作为伪网段的网关使用。这里可以加一次代理，解除这个限制。如使用 nginx 作为测试中转机，将伪路由添加到 nginx 服务器上，测试机只需要向 nginx 注册即可，无需做其他配置。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;goreplay 方案实现&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;goreplay 简介&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Goreplay 是另一个比较常用的流量复制开源工具。与 tcpcopy 相比它的架构更简单，只有一个 gor 组件，如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5818363273453094&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sM0hH9BhiaDcSWIdf6OZ7OWfWvYuQcJLx87DlSNEEbqgdMv15OiaQRKZZxPTNunvEfx8o1d9S6PFsTNnMy6Kbusg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1002&quot;/&gt;&lt;figcaption&gt;image&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;只需要在生产服务器上启动一个 gor 进程，它负责所有的工作包括监听、过滤和转发。它的设计遵循 Unix 设计哲学：&lt;em&gt;一切都是由管道组成的，各种输入将数据复用为输出&lt;/em&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输入输出通常被成为插件，常见的有下面几种。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可用输入：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;--input-raw 用于捕获 HTTP 流量，您应该指定 IP 地址或接口和应用程序端口。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;--input-file 接受流量输出的文件（--output-file），用来离线流量重放。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;--input-tcp 如果您决定将来自多个转发器 Gor 实例的流量转发给它，则由 Gor 聚合实例使用。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可用输出：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;--output-http 重放 HTTP 流量到给定的端点，接受基础 URL。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;--output-file 记录传入的流量到文件。更多关于保存和从文件重播&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;--output-tcp 将传入数据转发给另一个 Gor 实例，并与其一起使用--input-tcp。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;--output-stdout 用于调试，输出所有数据到 stdout。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你可以对数据进行限速、过滤、重新，还可以重用中间件实现一些自定义逻辑处理，如私有数据的过滤、认证等个性需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其他常用参数：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;--output-http &quot;http://staging.com|10&quot; 输出流量的 10%&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;--http-allow-method 根据请求方式过滤。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;--http-allow-url url 白名单，其他请求将会被丢弃。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;--http-disallow-url 遇上一个 url 相反，黑名单，其他的请求会被捕获到。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文不对中间件做过多描述，仅讨论常用功能，对中间件有需求的可参考&lt;span&gt;中间件文档&lt;/span&gt;&lt;sup&gt;[4]&lt;/sup&gt;。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;goreplay 搭建&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Goreplay 是使用 golang 开发的，我们可以直接使用编译好的对应各系统的二进制文件，也可以自己编译，我们这里直接使用二进制文件。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;wget https://github.com/buger/goreplay/releases/download/v1.3.0_RC1/gor_1.3_RC1_x64.tar.gz&lt;br/&gt;tar zxvf gor_1.3_RC1_x64.tar.gz&lt;br/&gt;&lt;span&gt;# 解压出二进制文件 gor&lt;/span&gt;&lt;br/&gt;gor&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来，直接启动 gor 即可复制流量和转发。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;sudo ./gor --input-raw :8000 --output-http=&lt;span&gt;&quot;http://192.168.33.13:8001&quot;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;复制本地 8000 端口的流量到 http 远端服务&lt;code&gt;http://192.168.33.13:8001&lt;/code&gt;。(复制同端口的流量时，流量会重复。这是 gor 的一个 bug，截止目前 1.3 版本仍可复现，可见&lt;span&gt;issue292&lt;/span&gt;&lt;sup&gt;[5]&lt;/sup&gt;)&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;goreplay 的流量转发，并不是直接 tcp 包的转发，而是重新组织 http 协议级别的请求，发送到测试服务器。所以它是新的 gor 线程和测试服务器的交互，和监听线程无关，所以无需对流量进行拦截。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;包流向分析&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我们来看下 gor 复制的流量包的流向过程：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4105720492396814&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sM0hH9BhiaDcSWIdf6OZ7OWfWvYuQcJLxRibWGGxK3ibHs1cy68hGAgv6sKmyft3iaMEibHO3eqwCYRADHCV7utFcgg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2762&quot;/&gt;&lt;figcaption&gt;gor&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;红色标注块为正常流量，蓝色标注块为复制的流量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到此处，你可能会有疑问，为什么 gor 不用拦截流量？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家仔细看 tcpcopy 和 gor 复制流量的端口，在生产机和测试机建立连接时，tcpcopy 虽然修改了 tcp 包的源 ip，但端口还是用的请求客户端的端口，是 tcp 数据链路层级别的流量复制。而 gor 这里严格来说并不是复制，而是重新构建了 http 请求。使用新端口来和测试机建连，相对的测试机在回包时，即使包是回到了生产机，但由于是和客户端不同的端口，也不会对生产流量造成影响。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;对比总结&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到此，我们对流量复制有了些基本的概念和应用了，也对 tcpcopy 和 goreplay 两款开源工具有了一定的认知。两款开源工具各有优缺点，我们来一块总结下。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;tcpcopy 部署架构相对复杂，goreplay 相对简单只需启动一个进程。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;tcpcopy 支持的协议比较丰富，goreplay 根据架构特点仅支持 http。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;tcpcopy 和 goreplay 都支持离线和在线录制回放。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;goreplay 有个中间件模块，可自定义部分过滤逻辑。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单 http 复制 goreplay 完全可以胜任，稍复杂点或应用场景更复杂，那么推荐 tcpcopy。更复杂，要求更高的流量复制，那只能我们自己定制了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，本篇到这结束了，欢迎留言讨论，你觉着最佳流量复制方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我是DeanWu，一个努力成为真正SRE的人。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;关注公众号「码农吴先生」, 可第一时间获取最新文章。回复关键字「go」「python」获取我收集的学习资料，也可回复关键字「小二」，加我wx拉你进技术交流群，聊技术聊人生~&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3287037037037037&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/sM0hH9BhiaDcSWIdf6OZ7OWfWvYuQcJLxC0wYGQ9FOT7AlslkQTMzHKEYKeVjLHMW3rzldm0pRsiayvt4gPgvSmg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2592&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;ByteCopy: &lt;em&gt;https://juejin.cn/post/6857688805835866126&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;p&gt;王斌: &lt;em&gt;https://github.com/wangbin579&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;p&gt;文档: &lt;em&gt;https://github.com/session-replay-tools/tcpcopy&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[4]&lt;/span&gt;&lt;p&gt;中间件文档: &lt;em&gt;https://github.com/buger/goreplay/tree/master/middleware&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[5]&lt;/span&gt;&lt;p&gt;issue292: &lt;em&gt;https://github.com/buger/goreplay/issues/292&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c90e18eece329cadc8e734178b931ae4</guid>
<title>Flink 在又拍云日志批处理中的实践</title>
<link>https://toutiao.io/k/upxcdey</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText&quot;&gt;&lt;p&gt;大家好，我是来自又拍云的张召，今天主要分享又拍云多数据源日志处理选型 Flink 的考量，以及 Flink 落地过程中遇到的问题和解决方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;为什么用 Flink 做批处理&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在选用 Flink 前，我们对日志批处理的整个业务需求分为三步：数据源采集、日志处理、结果的保存。我们的日志量在 100G/h，单机服务处理速度慢、扩容不方便，一些相似的需求都是以编码形式完成的。另外，数据处理流程复杂，需要在多个服务间流转，迫切需要一个方案来解决问题。&lt;/p&gt;&lt;p&gt;前期我们调研了数据库，发现数据库里没有多维度的反复总结和挖掘的功能，所以我们放弃了选用数据库的方案，选用 MapReduce 里的 hadoop 这条组件。实际生产中发现它经常在写入的时候出现一些错误，导致无法做一些聚合的操作。接着我们选择了 Spark，新的问题又出现了：提交任务时，Restful API 接口的支持不全面；web 控制台中虚拟 IP 无法访问内部。&lt;/p&gt;&lt;p&gt;基于以上原因，我们需要一个更好的解决方案。通过比较之后，我们发现了 Flink。Flink 规避了前面所有的问题，后面还提供一套完整的 Restful API。不仅能够渲染出这个页面，还可以通过 Submit NewJob 直接提交任务。同时，我们对老服务升级的过程中，逐渐明白了我们日志数据的特点，以及当前我们需要挖掘日志数据的哪些方面。&lt;b&gt;在盘点了手头上可调用的资源后，我们希望部署的服务整个系统是可观测、可维护的，所以基于以上各种原因，最终我们放弃 Spark 方案，选择了 Flink 。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Flink 基础知识&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Flink 组件栈&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如下图所示，这是一个分布式系统，整体也比较简单。最左边的 Flink Client 支持客户端现在的提交方式，后面会谈到它支持提交 Restful API 接口以及通过命令行等 5 种手段向这个 Job Manager 提交任务。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-df43a5857e0f485359ddbff80cf4e9d6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;711&quot; data-rawheight=&quot;378&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-df43a5857e0f485359ddbff80cf4e9d6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;711&quot; data-rawheight=&quot;378&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-df43a5857e0f485359ddbff80cf4e9d6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-df43a5857e0f485359ddbff80cf4e9d6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Job Manager 是分布式系统里的 master 节点，master 节点拿到数据之后会对架包进行分析，而后把相关其他信息给传送到对应的 TaskManager 节点。TaskManager 节点拿到信息后才真正执行Job，Job Manager 最主要的作用就是解析这个图以及维持整个集群，比如心跳、资源调度、HA 高可用、文件存储等，这是 Flink 提交任务 runtime 的过程。&lt;/p&gt;&lt;p&gt;接着看 Flink 静态的整体设计，底层是部署部分，稍后展开讲。中间的核心部分是 Runtime，分别封装了两个不同的 API：DataStream 是流处理，是现在 Flink 用的最多的场景；DataSet 是我们用到的批处理方式。虽然现在 Flink 号称支持流批一体处理，但是它目前版本两个接口是分开的，今年 12 月发的 1.12 版本已经不鼓励用 DataSet 相关的 API，这部分功能合到了 DataStream 里。但由于我们部署的版本还在 1.1，没有升级，所以我们还没有把这些 Job 迁到 DataStream 上去。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4dce7c28e166e3004b769016926d090f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;755&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-4dce7c28e166e3004b769016926d090f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;755&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-4dce7c28e166e3004b769016926d090f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4dce7c28e166e3004b769016926d090f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;接下来我们探索最上层的 tabl circle，但使用的最终效果并不好，因为无论是文档里，还是代码里写的支持限度是比较有限的。比如去执行 circle，但 circle 想把最终结果输出到 PG 里面的时候，它就出现了一个 bug，它 PG 的数据库最终拼出来的地址是错的，它的 host 和 pot 少了一个反斜线。这个 bug 非常简单，但是现在都没有修复。所以我认为最上层这部分可能测试的还不完善，也不是很稳定。所以我们最终代码的实现和业务集中编写也是放在调用的 DataSet API 这部分来做的。&lt;/p&gt;&lt;p&gt;另外我们还做了些小的工作，我们基于又拍云存储系统，扩展了它的相关功能，能够支持 Flink 的处理结果直接输出到云存储上，对整体代码起到简化作用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;JobManager 和TaskManager&lt;/b&gt;&lt;/p&gt;&lt;p&gt;JobManager 的作用主要体现在里面的组件。比如 DataflowGraph 可以把 Flink 客户端提交的架包分析成一个可以执行的 graph，分发到下面的 TaskManager 节点里面去。另外一个我们比较关注的组件是 Actor System，它是由 ScadAKKA 异步网络组件实现的。我们后期部署时发现有很多 AKKA time out 这类问题，这意味着 JobManager 组件和 TaskManager 组件进行通信的时候出现了问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fca6b8f8434d02d934488020d090514c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;519&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-fca6b8f8434d02d934488020d090514c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;519&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-fca6b8f8434d02d934488020d090514c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fca6b8f8434d02d934488020d090514c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;再看 TaskManager 主要关注的概念，当 TaskManager 和外界系统发生交互时，它用的不是 actor 模型，actor 模型主要是异步通信，强调的是快。它和外部通信时，TaskManager 用的是 Netty，输入数据更加的稳定。&lt;/p&gt;&lt;p&gt;这里要着重关注一下 Task Slot 概念，一些分享的最佳实践案例提到 TaskManager 里的 slot 最好和当前机器 CPU 核数保持 1：1 的设置。我们最初按照1：1 设计跑一些小的 job 的时候很好，但数据量上升时经常会出现一些 time out 的问题。原因在于 Kubernetes 提供的 CPU 只是一个 CPU 的实践片，不能等同物理机上的 CPU，当在 TaskManager 下部署多个的时候，虽然它们的内存会被分摊掉，但 CPU 却是共享的。在这种状况下，整个 TaskManager 就不是特别稳定。所以我们最终设置大概在 1：4 或 1：8。具体数据应该是从当前环境内的网络状况和经验值来确定的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Flink 部署&lt;/b&gt;&lt;/p&gt;&lt;p&gt;刚开始部署 Flink 时，我们是比较懵的，因为 Flink 部署文档里介绍了很多模式，比如部署在 standalone，Kubernetes、YARN 或者是 Mesos，还有一些应用实践都比较少的模式。虽然我们在云平台上搞一个 Kubernetes 的操作，但我们做不到直接使用 Kubernetes托管式的服务，所以最终采用的是 Standalone on Docker 模式，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-639a9b9617c79c83a941cb0910c689fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;539&quot; data-rawheight=&quot;440&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-639a9b9617c79c83a941cb0910c689fd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;539&quot; data-rawheight=&quot;440&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-639a9b9617c79c83a941cb0910c689fd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-639a9b9617c79c83a941cb0910c689fd_b.jpg&quot;/&gt;&lt;figcaption&gt;△ Standalone on Docker 模式&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;Standalone 模式下，Master 和 TaskManager 可以运行在同一台机器或者不同的机器上；&lt;/li&gt;&lt;li&gt;Master 进程中，Standalone ResourceManager 的作用是对资源进行管理。当用户通过 Flink Cluster Client 将 JobGraph 提交给 Master 时，JobGraph 先经过 Dispatcher；&lt;/li&gt;&lt;li&gt;当 Dispatcher 收到请求，生成 JobManager。接着 JobManager 进程向 Standalone ResourceManager 申请资源，最终再启动 TaskManager；&lt;/li&gt;&lt;li&gt;TaskManager 启动后，经历注册后 JobManager 将具体的 Task 任务分发给 TaskManager 去执行。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Flink 提交任务&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Flink 提供丰富的客户端操作提交任务和与任务进行交互，包括 Flink 命令行、Scala Shell、SQL Client、Restful API 和 Web。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e7c24b194c137db5c73fdda69d4a0154_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;413&quot; data-rawheight=&quot;353&quot; class=&quot;content_image&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;413&quot; data-rawheight=&quot;353&quot; class=&quot;content_image lazy&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e7c24b194c137db5c73fdda69d4a0154_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;最重要的是命令行，其次是 SQL Client 用于提交 SQL 任务的运行，以及 Scala Shell 提交 Table API 的任务，还提供可以通过 http 方式进行调用的 Restful 服务，此外还有 Web 的方式可以提交任务。对我们非常实用的是 Restful API 功能。目前的服务里，除了拉取原始日志这块代码没有动，其他一些 go 自研组件的统计、排序等后续的操作现在统统不用了，直接调用 Flink 相关的接口。&lt;/p&gt;&lt;p&gt;Flink 是一个异步执行的过程。调用接口传递任务后，紧接着会把 taster 的ID 返还给你，后续的操作里面可以通过这个接口不断去轮循，发现当前任务的执行情况再进行下一步决策。综合来看，Flink 的 Restful API 接口，对于我们这种异构的、非 JAVA 系的团队来说还是非常方便的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;使用批处理时遇到的问题&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;网络问题&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-05888a9e248f1a8b7d748cc8811cf714_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1032&quot; data-rawheight=&quot;397&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-05888a9e248f1a8b7d748cc8811cf714_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1032&quot; data-rawheight=&quot;397&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-05888a9e248f1a8b7d748cc8811cf714_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-05888a9e248f1a8b7d748cc8811cf714_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;当我们逐步迁移日志服务时，开始日志量比较小，Flink运行的非常好；当发现它负载不了，出现 GVM 堆错误之类的问题时也只需要把相关参数调大就可以了，毕竟云平台上资源还是比较富裕的，操作也很方便。&lt;/p&gt;&lt;p&gt;但当我们越来越信任它，一个 job 上百 G 流量时，整个 tap 图就变成一条线，网络问题就出现了。此前有心跳超时或者任务重试之类的问题，我们并不是特别在意，因为失败后Flink 支持重试，我们通过 restful 接口也能够感知到，所以失败就再试一次。但是随着后面的任务量加大，每运行一次代价就越来越大了，导致提交的越多当前整个集群就会越来越恶化。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-07af3d6249262eea71811be0c220d50e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;298&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-07af3d6249262eea71811be0c220d50e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;298&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-07af3d6249262eea71811be0c220d50e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-07af3d6249262eea71811be0c220d50e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;当这种上百 G 的日志批处理任务放进去后经常会出现三类错误：最上面红线画出的akkaTimeout 问题是前面讲的 JobManager 和 TaskManager 相互通信出现的问题；像心跳超时或链接被重置的问题也非常多。&lt;/p&gt;&lt;p&gt;为什么我们没有完全把这个问题处理掉呢？是因为我们看了一些阿里的 Flink on K8S 的经验总结。大家有兴趣也可以看一下。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-55e6cdb000864ffa9e1200b5f8beaad9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;360&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-55e6cdb000864ffa9e1200b5f8beaad9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;360&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-55e6cdb000864ffa9e1200b5f8beaad9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-55e6cdb000864ffa9e1200b5f8beaad9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这篇文章中面对同样的问题，阿里团队提出将网络放到 K8S 网络虚拟化会实现一定的性能，我们参考了这种解决方案。具体来说，需要对 Flink 配置进行一些调整，另外有一些涉及 connection reset by peer 的操作：&lt;/p&gt;&lt;p&gt;&lt;b&gt;调整 Flink 配置参数&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调大网络容错性, 也就是配置参数中 timeout 相关的部分。比如心跳 5 秒一次超时了就调成 20 秒或者 30 秒，注意不可以完全禁掉或者调到很大；&lt;/li&gt;&lt;li&gt;开启压缩。如果是以纯文本的形式或者不是压缩包的形式上传，Flink     会并行读取文件加快处理速度，所以前期倾向上传解压后的文本；当网络开销变大后，我们就选择开启文件压缩，希望通过 CPU 的压力大一点，尽量减少网络开销。此外，TaskManager 或者是 JobManager 和 TaskManager 之间进行通信也可以开启压缩；&lt;/li&gt;&lt;li&gt;利用缓存, 如`taskmanager.memory.network.fraction` 等，参数配置比较灵活；&lt;/li&gt;&lt;li&gt;减少单个 task manager 下 task slots 的数量。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Connection reset by peer&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;不要有异构网络环境（尽量不要跨机房访问）&lt;/li&gt;&lt;li&gt;云服务商的机器配置网卡多队列 (将实例中的网络中断分散给不同的CPU处理，从而提升性能)&lt;/li&gt;&lt;li&gt;选取云服务商提供的高性能网络插件：例如阿里云的 Terway&lt;/li&gt;&lt;li&gt;Host network，绕开 K8s 的虚拟化网络（需要一定的开发量）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;由于 Connection reset bypeer 的方案涉及到跨部门协调，实施起来比较麻烦，所以我们目前能够缓解网络问题的方案是对 Flink 配置进行一些调整，通过这种手段，当前集群的网络问题有了很大程度的缓解。&lt;/p&gt;&lt;p&gt;&lt;b&gt;资源浪费&lt;/b&gt;&lt;/p&gt;&lt;p&gt;standlone 模式下，整个集群配置资源的总额取决于当前所有 job 里最大的 job 需要的容量。如下图所示，最下面不同任务步骤之间拷贝的数据已经达到了 150G+，能够缓解这种问题的办法是不断配置更大的参数。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9429eb3cfe2f85acd5247f1d4ec94bf3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1060&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-9429eb3cfe2f85acd5247f1d4ec94bf3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1060&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-9429eb3cfe2f85acd5247f1d4ec94bf3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9429eb3cfe2f85acd5247f1d4ec94bf3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;但由于 Flink 这一套后面有一个JVM 的虚拟机，JVM 虚拟机经常申请资源后并没有及时释放掉，所以一个容器一旦跑过一个任务后，内存就会飙上去。当不断拉大配置，且配置数量还那么多的情况下，如果我们的任务只是做一个小时级的日志处理，导致真正用到的资源量很少，最终的效果也不是很好，造成资源浪费。&lt;/p&gt;&lt;p&gt;&lt;b&gt;job 卡死&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在容量比较大后，我们发现会出现 job 卡死，经常会出现量大的 job 加载进行到一半的时候就卡住了。如下图所示（浅蓝色是已经完成的，鲜绿色表示正在进行的），我们试过不干预它，那么这个任务就会三五个小时甚至是八个小时的长久运行下去，直到它因为心跳超时这类的原因整体 cross 掉。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b88154bc138893d84f6a4a5845af7313_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1015&quot; data-rawheight=&quot;369&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-b88154bc138893d84f6a4a5845af7313_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1015&quot; data-rawheight=&quot;369&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-b88154bc138893d84f6a4a5845af7313_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b88154bc138893d84f6a4a5845af7313_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这个问题目前没有完全定位出来，所以现在能采取的措施也只是通过 restful 接口检查任务的时候，给它设置一个最大的阈值。当超过这个阈值就认为这个任务已经完全坏掉了，再通过接口把它取消掉。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Flink 带来的收益&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;下图所示是日志处理的某一环节，每一个小方块代表一个服务，整个服务的链路比较长。当有多个数据源加载一个数据时，它会先 transfer porter 放到又拍云的云存储里，由 log-merge 服务进行转换，再根据当前服务的具体业务需求，最终才会存到云存储或者存到 redis。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5e06faedb552d043b40d7105635e7348_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;619&quot; data-rawheight=&quot;509&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-5e06faedb552d043b40d7105635e7348_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;619&quot; data-rawheight=&quot;509&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-5e06faedb552d043b40d7105635e7348_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5e06faedb552d043b40d7105635e7348_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;任务和任务之间的衔接是通过两种方式：一种是人为之间进行约定，比如我是你的下游组件，我们约定延迟 3 个小时，默认 3 个小时后你已经数据处理好，我就去运行一次；第二种是用 ASQ，我处理结束后推送消息，至于你消费不消费、消费是否成功，上游不需要关心。&lt;b&gt;虽然原本正常的情况下服务运行也很稳定，但一旦出现问题再想定位、操纵整个系统，追捕一些日志或重跑一些数据的时候就比较痛苦。这一点在我们引入到 Flink 后，整体上有非常大的改进。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;small&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bf19eb6d346280028a3a265a2c8344e3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;small&quot; data-rawwidth=&quot;876&quot; data-rawheight=&quot;719&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-bf19eb6d346280028a3a265a2c8344e3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;small&quot; data-rawwidth=&quot;876&quot; data-rawheight=&quot;719&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-bf19eb6d346280028a3a265a2c8344e3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bf19eb6d346280028a3a265a2c8344e3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;目前只有任务管理部分是复用了之前的代码，相当于采集板块。采集好数据直接向 Flink 提交当前的 job，Flink 处理好后直接存进云存储。我们的任务管理主要分两类功能，一个是采集，另一个是动态监控当前任务的进行结果。总的来看，重构后相当于形成了一个闭环，无论是 Flink 处理出现问题，亦或是存储有问题，任务管理系统都会去重跑，相当于减少一些后期的运维工作。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;选择 standalone 系统部署一套Flink 系统，又要它处理不是太擅长的批处理，且量还比较大，这是非常有挑战性的。充满挑战的原因在于这不是 Flink 典型的应用场景，很多配置都做不到开箱即用，虽说号称支持批处理，但相关配置默认都是关闭的。这就需要调优，不过很多文档里大多会写如果遇到某类问题就去调大某类值，至于调大多少完全靠经验。&lt;/p&gt;&lt;p&gt;尽管如此，但由于当前 Flink 主推的也是流批一体化开发，我们对 Flink 后续的发展还是比较有信心的。前面也讲了 Flink1.1 版本中，dateset 批处理的 API 和 stream的 API 还是分开的，而在最新版本 1.12 中已经开始融合在一起了，并且 dateset 部分已经不建议使用了。我们相信沿着这个方向发展，跟上社区的节奏，未来可期。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;演讲视频观看及PPT下载：&lt;/b&gt;&lt;/p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://link.zhihu.com/?target=https%3A//www.upyun.com/opentalk/457.html&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic4.zhimg.com/v2-11121468cdfd0a5f2a0b5aebe4703c37_180x120.jpg&quot; data-image-width=&quot;960&quot; data-image-height=&quot;540&quot; class=&quot;LinkCard LinkCard--hasImage&quot;&gt;&lt;span class=&quot;LinkCard-backdrop&quot;/&gt;&lt;span class=&quot;LinkCard-content&quot;&gt;&lt;span class=&quot;LinkCard-text&quot;&gt;&lt;span class=&quot;LinkCard-title&quot; data-text=&quot;true&quot;&gt;Flink 在又拍云日志批处理中的实践&lt;/span&gt;&lt;span class=&quot;LinkCard-meta&quot;&gt;&lt;span&gt;​&lt;svg class=&quot;Zi Zi--InsertLink&quot; fill=&quot;currentColor&quot; viewbox=&quot;0 0 24 24&quot;&gt;&lt;path d=&quot;M13.414 4.222a4.5 4.5 0 1 1 6.364 6.364l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005a2.5 2.5 0 1 0-3.536-3.536l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005zm-6.187 6.187a.5.5 0 0 1 .638-.058l.07.058.706.707a.5.5 0 0 1 .058.638l-.058.07-3.005 3.004a2.5 2.5 0 0 0 3.405 3.658l.13-.122 3.006-3.005a.5.5 0 0 1 .638-.058l.069.058.707.707a.5.5 0 0 1 .058.638l-.058.069-3.005 3.005a4.5 4.5 0 0 1-6.524-6.196l.16-.168 3.005-3.005zm8.132-3.182a.25.25 0 0 1 .353 0l1.061 1.06a.25.25 0 0 1 0 .354l-8.132 8.132a.25.25 0 0 1-.353 0l-1.061-1.06a.25.25 0 0 1 0-.354l8.132-8.132z&quot;/&gt;&lt;/svg&gt;&lt;/span&gt;www.upyun.com&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-imageCell&quot;&gt;&lt;img class=&quot;LinkCard-image LinkCard-image--horizontal&quot; alt=&quot;图标&quot; src=&quot;https://pic4.zhimg.com/v2-11121468cdfd0a5f2a0b5aebe4703c37_180x120.jpg&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;p/&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b55773682bd457a6ac202de731ebbc54</guid>
<title>关于构建数据仓库的几个问题</title>
<link>https://toutiao.io/k/8894fk1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;92356&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section&gt;&lt;section data-width=&quot;97%&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-ratio=&quot;1.3246753246753247&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uN1LIav7oJibnXRTwzul99YfpqjjVFWoFABPTfAIWeODwwzprdQd6xO6w5PTntPoJBicOa9kS1N0jqL5dkXJAwhQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;77&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;strong&gt;元宵节快乐&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-bgless=&quot;spin&quot; data-bglessp=&quot;120&quot;&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section&gt;&lt;p&gt;如果本文对你有所帮助，请分享、点赞、在看，想要获得更多信息，请关注我。&lt;/p&gt;&lt;p&gt;欢迎扫描文末二维码加我微信，回复【进群】，可以加入大数据技术交流群，期待与你一起交流&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;102462&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.5283018867924528&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FIBZec7ucCjv9me2lz9aUeUY91fHaIhIODzyCn62XtvA8ictTjkd5ym0o2hmxRTy2K38hcANQmK9qHyic4L7ohNA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;53&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;写在前面&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库（Data Warehouse）是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策(Decision Making Support)。近年来，随着大数据的应用不断深入，构建企业级数据仓库成为了企业进行精细化运营的一种趋势。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从管理者的视角来看，数据仓库是赋能业务并辅助决策的一种工具，从开发者的视角来看，数据仓库是一堆数据模型的集合。数仓开发是一个系统工程，涉及数据集成、数据建模、数据开发、数据服务、任务调度、元数据管理、数据质量管理(DQC)等一系列的流程。另外，由于数据跟业务是息息相关的，所以在构建数仓的时候，需要对业务有一个非常深刻的理解。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;值得注意的是，数仓的建设不是一蹴而就的，也没有毕其功于一役的方法，业务的不断变化决定了数仓是在不断迭代中进行完善的。从这个层面上来讲，或许永远没有完美的数仓。由于人员的流动、业务的变化以及前期的系统性建设不足，数仓总会存在这样或那样的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;或许我们可以用&quot;&lt;strong&gt;是否成熟&lt;/strong&gt;&quot;描述数仓的建设，那么什么是成熟的数仓呢，我们不妨换个角度思考一下：&lt;strong&gt;什么是一个不成熟的数据仓库&lt;/strong&gt;？此时你的脑海里是否会蹦出一个词，那就是&lt;strong&gt;混乱&lt;/strong&gt;。是的，一个不成熟的数仓虽然具备了部分数仓规范，但在具体的落地实施过程中，并未能完全按照规范操作， 导致数据仓库建设比较混乱，比如数据域划分不清楚、数仓分层不明确、数据任务随意依赖、数据重复开发等等问题。迫于业务快速变化以及日常数据开发需求的压力，造成了数据开发没有太多的时间和精力去顾及这些问题，最终形成了一个不成熟的数仓。一旦出现了这些问题，后续就需要有专门的数据治理团队去规划并规范数仓的建设。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，假设你接手了一个不成熟的数仓项目，或者你觉得目前的数仓建设还不够成熟，那么不妨思考一下几个问题：&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;定目标&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数仓设计目标包括数仓分层清晰，字段与模型命名规范，具备较高可复用性与可维护性，能够快速响应产品运营层面的数据分析需求，以数据驱动产品迭代与业务增长。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数仓设计的过程中，坚持用户驱动与数据驱动相结合的设计理念，即一方面根据当前的业务数据的基础和质量情况，以数据源分析为出发点构建数据仓库；另一方面根据业务的方向性需求，从业务需要解决的具体问题出发，确定系统范围和需求框架。&lt;img data-ratio=&quot;0.5317919075144508&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PL10rfzHicsiaIkI19RdaNMz4TrUCPEoFl7OzFZ7iaEh4rYthJxxaAuBhIHwd15rhpnIITluAVFYSoxZPbYicrs0JQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;692&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;选技术&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库是一个复杂系统，会涉及到一系列的流程，由此不可避免的会使用很多的技术框架。目前，行业中使用的常见工具主要包括：数据同步工具、数据处理工具、任务调度工具、报表工具、元数据管理工具、质量管理平台(DQC)以及大数据基础平台等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果是自建的大数据平台，或者是没有一个大数据开发平台，这种情况下需要数仓开发人员具备丰富的技术栈，既要兼顾技术的集成使用，又要兼顾数仓的建设与业务需求的开发。如果使用的是已经集成好的开发套件，比如阿里云的dataworks，这样数仓的开发人员会更加聚焦数仓的建设，而不是在各种技术的集成过程中踩坑而分散过多的精力。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;找问题&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前文已经提到没有完美的数仓，其实数仓的建设并没有对与错之分，只有好与坏之差。我们不能一味的使用拿来主义的方式去构建数据仓库，数据仓库建设能否成功会涉及很多的因素，数仓建设的方法论是指引我们的一个方向，万万不可迷失其中。一言以蔽之，合适就好。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在接手不成熟的数仓时，需要梳理存在的一些问题，而这些问题一般情况下都大同小异，常见的一些问题主要包括：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;数仓分层不清晰&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据域划分不明确&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;模型设计不合理&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;代码不规范&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;命名不统一&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;划主题&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主题域是业务过程的抽象集合，是在较高层次上对数据进行分类聚集的抽象，这是一个逻辑概念，主要方便数据的分类管理。业务过程就是企业经营过程中一个个不可拆分的行为事件，比如仓储管理里面有入库、出库、发货、签收，都是业务过程，抽象出来的主题域就是仓储域。主题域划分要尽量涵盖所有业务需求，保持相对稳定性，还具备一定的扩展性，新加入一个主题域，不影响已经划分的主题域的表。有了主题域之后，每个数据模型也就有了一个归属，这样数据组织会更加的清晰，同时也比较方便维护。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;识分层&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数仓为什么要分层&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;合理的数据仓库分层一方面能够降低耦合性，提高重用性，可读性可维护性，另一方面也能提高运算的效率，影响到数据需求迭代的速度，近而影响到产品决策的及时性。建立数据分层可以提炼公共层，避免烟囱式开发，可见一个合适且合理的数仓分层是极其重要。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;通用分层设计思路&lt;span/&gt;&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;ODS&lt;/strong&gt;:操作型数据(Operational Data Store)，指结构与源系统基本保持一致的增量或者全量数据。作为DW数据的一个数据准备区，同时又承担基础数据记录历史变化，之所以保留原始数据和线上原始数据保持一致，方便后期数据核对需要。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;CDM&lt;/strong&gt;：通用数据模型，又称为数据中间层(Common Data Model)，包含DWD、DWS、DIM层。&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;DWD&lt;/strong&gt;：数据仓库明细层数据(Data Warehouse Detail)。对ODS层数据进行清洗转化，以业务过程作为建模驱动，基于每个具体的业务过程特点，构建最细粒度的明细事实表。可以结合企业的数据使用特点，基于维度建模思想，将明细事实表的某些重要属性字段做适当冗余，也即宽表化处理，构建明细宽表。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;DWS&lt;/strong&gt;：数据仓库汇总层数据(Data Warehouse Summary)，基于指标需求，构建初步汇总事实表，一般是宽表。基于上层的应用和产品的指标需求，构建公共粒度的汇总指标表。以宽表化手段物理化模型，构建命名规范、口径一致的统计指标，为上层提供公共指标。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;DIM&lt;/strong&gt;：建立一致数据分析维表，可以降低数据计算口径不统一的风险，同时可以方便进行交叉探查。以维度作为建模驱动，基于每个维度的业务含义，通过添加维度属性、关联维度等定义计算逻辑，完成属性定义的过程并建立一致的数据分析维表。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;ADS&lt;/strong&gt;：面向应用的数据服务层(Application Data Service)。整合汇总成分析某一个主题域的服务数据，面向应用逻辑的数据加工。该层主要存放数据产品个性化的统计指标数据，这一层的数据直接对接数据的消费者，是产品、运营等角色可以直接感知理解的一层，大多数这一层的表都可以直接在BI上通过图表的形式直接透出。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;分层辨析&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;ODS层&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ODS层的概念主要体现在两个方面：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;操作型系统的集成，用于当前、历史以及其它细节查询(业务系统的一部分)&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;为决策支持提供当前细节数据(数据仓库的一部分)&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ODS是用于支持企业日常的全局应用的数据集合，ODS的数据具有&lt;strong&gt;面向主题、集成的、可变的以及数据是当前的或是接近当前的&lt;/strong&gt;特点。同样也可以看出ODS是介于DB和DW之间的一种过渡存储。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;值得注意的是，Kimball所说的ODS是物理落地关系型数据库中，但是在实际生产应用中，ODS往往是物理落地在数据仓库中，比如Hive。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通常来说ODS是在数据仓库中存储业务系统源数据，所以从数据粒度、数据结构、数据关系等各个方面都与业务系统的数据源保持一致。但是，也不能仅仅将ODS层看做是业务系统数据源的一个简单备份，ODS和业务系统数据源的差异主要是由于两者之间面向业务需求是不同的，业务系统是面向多并发读写同时有需要满足数据的一致性，而ODS数据通常是面向数据报表等批量数据查询需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于ODS层与业务系统DB的主要区别，体现在一下几个方面：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;数据存储方式方面。由于性能压力，业务DB需要对同一个逻辑表进行分表分库操作，而ODS会将业务系统中同一个逻辑表统一到一个物理实体中存储&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据存储介质方面。业务系统通常用oralce、MySQL、DB2等以事务性处理见长关系型数据库系统，ODS通常存储在以Hadoop为代表的分布式系统中，比如Hive等等。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据组织形式方面。业务系统表通常需要遵循三范式，并且需要创建复杂的索引结构来提升查询效率，但是ODS层的表通常没有索引。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ODS层的数据同步通常会使用数据库直连抽取或者数据库日志抽取的方式，在设计ODS物理表时，在表命名、数据存储等方面都需要遵循一定的准则。比如：不管是表命名还是字段命名尽量和业务系统保持一致，但是需要通过额外的标识来区分增量和全量表，”_delta”来标识该表为增量表。另外，为了满足历史数据分析需求，我们需要在ODS表中加一个时间维度，这个维度通常在ODS表中作为分区字段。如果是&lt;strong&gt;增量存储&lt;/strong&gt;，则可以按天为单位使用业务日期作为分区，每个分区存放日增量的业务数据。如果是&lt;strong&gt;全量存储&lt;/strong&gt;，只可以按天为单位使用业务日期作为分区，每个分区存储截止到当前业务时间的全量快照数据。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;DWD层&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DWD层的数据一般存放明细事实表，为了提升访问便利性和访问性能，在维度模型的事实表基础上，将部分常用维度冗余到事实表，从而形成宽表模型。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;明细事实表的设计有五个步骤：&lt;strong&gt;选择业务过程---&amp;gt;确定粒度---&amp;gt;选择维度---&amp;gt;确定事实(度量)---&amp;gt;冗余维度&lt;/strong&gt;。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;DWS层&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以分析的主题对象作为建模驱动，基于上层的应用和产品的指标需求，构建公共粒度的汇总指标表。以宽表化手段物理化模型，构建命名规范、口径一致的统计指标，为上层提供公共指标，建立汇总宽表。如：形成日，周，月粒度汇总明细，或者基于某一个维度，如商品类目粒度的汇总日表，统计便于下一步报表数据结构的组织。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于汇总层的表建模应遵循以下的原则：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;数据公用性&lt;/strong&gt;比如，汇总的聚集表能否与他人公用？基于某个维度的聚集是否是数据分析或者报表中经常使用的？如果满足这些情况，我们就有必要把明细数据沉淀到汇总表中。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;不跨数据域&lt;/strong&gt;数据域是在较高层次上对数据进行分类聚集的抽象，如交易统一划到交易域下，商品的新增、修改放到商品域下。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;区分统计周期&lt;/strong&gt;表命名上要能说明数据的统计周期，如_1d 表示最近1天，_td 截止到当天，_nd 表示最近N天。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;避免多个层级的数据&lt;/strong&gt;应该避免将不同层级的数据放在一起，比如，如果存在7天和30天的事实，我们可以选择用两列存放7天和30天的事实，但是需要在列名和字段注释上说明清楚。同时我们也可以使用两张表分别存储不同统计周期的数据加以区分。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;聚集是不跨越事实的&lt;/strong&gt;聚集是针对原始星型模型进行的汇总，为了获取和查询原始模型一致的结果，聚集的维度和度量必须与原始模型保持一致，因此聚集是不跨事实的。横向钻取(交叉探查)是针对多个事实基于一致性维度进行的分析，很多时候采用融合事实表，预先存放横向钻取的结果，从而提高查询性能。因此融合事实表是一种导出模式而不是聚集。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;DIM层&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该层主要存储一致性维度数据，数据仓库总线架构重要基石之一就是一致性维度。通过构建一致性维度我们可以轻松实现数据的交叉探查。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;维度是维度建模的基础和灵魂。维度建模中，将度量称为“事实”，将环境描述为“维度”，维度是用于分析事实所需要的多样环境。例如，在分析交易过程时，可以通过买家、卖家、商品和时间等维度描述交易发生的环境。维度所包含的表示维度的列，称为维度属性。维度属性是查询约束条件、分组和报表标签生成的基本来源，是数据易用性的关键。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;ADS层&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;个性化指标加工，主要存储不具有公用性的复杂指标，比如针对某张数据报表设计的底层数据存储模型。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;分层注意点&lt;span/&gt;&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;ODS不可以被应用层调用&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;CDM层任务的深度不宜过大&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;DWS优先调用DWD及DIM&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;避免ADS过渡引用明细层&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;理建模&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前文介绍了数据分层的概念，而数据建模更多的着眼于数据公共层处理。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;好的数据建模有哪些特点&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据模型就是数据组织和存储方法，强调从业务、数据存储和数据使用角度合理存储数据。好的数据建模一般具备如下特点：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;性能：能够帮助使用者快速查询所需要的数据，减少数据的I/O吞吐，提高使用数据的效率。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;成本：减少不必要的数据冗余与重复计算，实现计算结果的良好复用，从而降低存储和计算成本。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;质量：减少数据统计口径不一致性，减少数据计算错误的可能性。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数据模型设计原则&lt;span/&gt;&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;高内聚和低耦合
一个逻辑和物理模型由哪些记录和字段组成，应该遵循最基本的软件设计方法论的高内聚和低耦合原则。主要从数据业务特性和访问特性两个角度来考虑：将业务相近或者相关的数据、粒度相同数据设计为一个逻辑或者物理模型；将高概率同时访问的数据放一起，将低概率同时访问的数据分开存储。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;核心模型与扩展模型分离
建立核心模型与扩展模型体系，核心模型包括的字段支持常用核心的业务，扩展模型包括的字段支持个性化或是少量应用的需要，不能让扩展字段过度侵入核心模型，破坏了核心模型的架构简洁性与可维护性。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;公共处理逻辑下沉及单一
越是底层公用的处理逻辑更应该在数据调度依赖的底层进行封装与实现，不要让公共的处理逻辑暴露给应用层实现，不要让公共逻辑在多处同时存在。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;成本与性能平衡
适当的数据冗余换取查询和刷新性能，不宜过度冗余与数据复制。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据可回滚
处理逻辑不变，在不同时间多次运行数据结果确定不变。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一致性
相同的字段含义在不同表中字段命名必须相同，必须使用规范定义中的名称。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;命名清晰可理解
表命名需清晰、一致，表名需易于消费者理解和使用。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;典型的数据仓库建模方法&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数仓建模的典型方法有：实体建模(ER模型)、维度建模法、Data Vault 模型、Anchor 模型。目前使用较多的当属维度建模，而维度建模中，又分为星型模型和雪花模型两大类，一般星型模型使用较多。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;星型模型：维度建模非常直观，紧紧围绕着业务模型，可以直观的反映出业务模型中的业务问题。不需要经过复杂的表关联，就能够拿到业务分析想要的全部数据，能够极大的提升数据仓库的处理能力，缺点则是数据冗余较多。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;雪花模型：在星型的基础上，分解维度，雪花模型的维度表可以拥有其他维度表的，虽然这种模型相比星型模型更规范一些，但是由于这种模型不太容易理解，维护成本比较高，而且性能方面需要关联多层维表，性能也比星型模型要低，普遍用的少一些。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于维度建模，主要是将数据分为了维表和事实表。维度建模中，将度量称为“事实”，将环境描述为“维度”，维度是用于分析事实所需要的多样环境。例如，在分析交易过程时，可以通过买家、卖家、商品和时间等维度描述交易发生的环境。维度所包含的表示维度的列，称为维度属性。维度属性是查询约束条件、分组和报表标签生成的基本来源，是数据易用性的关键。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;事实表&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事实表作为数据仓库维度建模的核心，紧紧围绕着业务过程来设计，通过获取描述业务过程的度量来表达业务过程，包含了引用的维度和与业务过程有关的度量。事实表中一条记录所表达的业务细节程度被称为粒度。粒度通常可以通过两种方式来表述：一种是维度属性组合所表示的细节程度，一种是所表示的具体业务含义。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相对维度表来说，通常事实表要细长的多，行的增加速度也比维度表快很多。维度属性也可以存储到事实表中，这种存储到事实表中的维度列被称为退化维度。与其他存储在维度表中的维度一样，退化维度也可以用来作为事实表的过滤查询、实现聚合操作等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事实表有三种类型：事务事实表、周期快照事实表、累积快照事实表。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;维表&lt;span/&gt;&lt;/h4&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;注意问题&lt;span/&gt;&lt;/h5&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;尽可能包含丰富的维度属性
丰富的维度属性可以为数据分析统计提供更多的分析角度&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;编码与文字描述共存
尽可能多给出包括一些富有意义的文字性描述，除此之外，为了保持扩展性，需要将编码code与文字描述同时保留，方便以后新增加属性时导致错误的计算。比如商品维度中的商品ID和商品标题，类目ID和类目名称等。ID一般用于不同表之前的关联，而名称一般用于报表标签。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;区分数值型的维度属性
数值型字段是作为事实还是维度属性，取决于该字段的作用。如果通常是用于查询约束条件或分组统计，则是作为维度属性；如果通常是用于参与度量的计算，则是作为事实。比如商品价格，可以用于查询约束条件或统计价格区间的商品数量，此时是作为维度属性使用；也可以用于统计某类目下商品的平均价格，此时是作为事实使用。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;尽量沉淀出通用的维度属性
有些维度属性获取需要进行比较复杂的逻辑处理，有需要通过多表关联得到，也有单表的不同字段混合处理得到，或者对单表的某个字段进行解析得到。此时，需要将尽可能多的通用的维度属性进行沉淀。一方面，可以提高下游使用的方便性，减少复杂度；另一方面，避免下游使用解析时由于各自逻辑不同而导致的口径不一致。比如有些字段存储在JSON字符串中，则需要解析出来。再比如有时候无法直接获取某个维度属性，这个时候就需要进行加工判断，将其作为一个单独的属性字段。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;维度表一般是很不规范化的。实际应用中，几乎总是使用维度表的空间来换取简明性和查询性能。&lt;/p&gt;&lt;/blockquote&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;缓慢变化维&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库的重要特点之一是反应历史变化，所以如何处理维度的变化是维度设计的重要工作之一。缓慢变化维的提出是因为在现实世界中，维度的属性并不是静态的，它会随着时间的变化而发生缓慢的变化，这一现象称为缓慢变化的维度，简称缓慢变化维。与数据增长较为快速的事实表相比，维度变化相对缓慢。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在Kimball的理论中，有三种缓慢变化的处理方式，分别是：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;type1：重写维度值。采用此种方式，不保留历史，始终取最新数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;type2：插入新的维度行。采用此种方式，保留历史，维度值变化前的事实和过去的维度值关联，维度值变化后的事实和当前的维度值关联。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;type3：添加维度列&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;在Kimball的理论中，必须使用代理键作为每个维度表的主键，用于处理缓慢变化维度，这种方式在实际的操作中非常复杂，使用起来也不方便，所以一般情况下不使用代理键。&lt;/p&gt;&lt;/blockquote&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;常用缓慢变化维的处理方式&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;常见的方式是使用快照来处理缓慢变化维。离线数仓按T+1计算，处理维度变化的方式就是每天一份全量快照。比如商品维度，每天保留一份全量商品快照数据。任意一天的事实均可以取到当天的商品信息，也可以取到最新的商品信息，通过限定日期，采用自然键进行关联即可。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此方式的优势是简单而有效，开发和维护成本低，另外使用方便，理解性好。数据使用方只需要限定日期即可取到当天的快照数据。任意一天的事实快照和任意一天的维度快照通过维度的自然键进行关联即可。主要的缺点就是会造成存储资源的浪费，由于存储成本远低于CPU、内存等成本，此方法总体来说弊大于利。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;制规范&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;达成共识&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于数仓开发规范，务必要执行到位，确保大家能够达成一致的理解与认可。只有按照规范操作，才不至于使数仓最终变得越来越臃肿，越来越低效。关于规范的制定，需要经过团队人员的一致认可，具有可操作性，切不可畏手畏脚地被规范束缚，影响开发效率。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;表命名规范&lt;span/&gt;&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;ODS层表命名规范
比如全量表：ods.s{源系统表名}
比如增量表：ods.s{源系统表名}_delta&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;DIM/DWD层表命名规范
比如全量表：dwd_{数据域缩写}{自定义表命名}&lt;em&gt;df
比如增量表：dwd&lt;/em&gt;{数据域缩写}{自定义表命名}_di
比如维表：dim[{业务域缩写}]{自定义表命名}&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;DWS层表命名规范
dws_{数据域缩写}{维度缩写}{自定义表命名}{数字}_{d/m/y，分别表示天、月、年}&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;最近一天      1d
最近N天      （N）d  ---N代表是一个数字
最近30天      1m
最近7天       1w
最近365天     1y
周累计至今     wtd   ----周报周（周六至周五）
月初累计至今   mtd
累计至今      td&lt;/p&gt;&lt;/blockquote&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;ADS层表命名
比如：ads_{数据域}&lt;em&gt;{统计粒度}[&lt;/em&gt;{业务限定}][&lt;em&gt;{自定义命名标签}]&lt;/em&gt;{统计周期}&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;关于表的命名需要根据具体团队的约定，一般见名知意即可，一旦规定了具体的格式，就尽量统一风格&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;开发规范&lt;span/&gt;&lt;/h4&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;总结&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文主要介绍了构建数仓的过程中或者在接手一个不成熟的数仓之后需要注意的一些问题，主要包括7个方面，分别是定目标、选技术、找问题、划主题、识分层、理建模、制规范。这些方面只是数仓构建中的一部分，由于篇幅限制，不能一一详述，希望本文对你有所帮助。&lt;/p&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;93573&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;往期精彩回顾&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-autoskip=&quot;1&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2ODQ3NjYyMA==&amp;amp;mid=2247484561&amp;amp;idx=1&amp;amp;sn=70af9e747e7b1ec121dbd430b4309c5d&amp;amp;chksm=fc8c1232cbfb9b24ddc803d85f940f7a4acb5b00cdcc079599f026a212da56ccf9810e713213&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;数仓开发应避免的10个陷阱&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2ODQ3NjYyMA==&amp;amp;mid=2247485606&amp;amp;idx=1&amp;amp;sn=1dfd0fba7c2c903cc887a88cd25b8211&amp;amp;chksm=fc8c1e05cbfb97134879d36808cfbcb5439feb468585d751d1e016a6c8fb2981d01585725a6f&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;数仓|几种SQL隐藏的错误，你遇到过吗？&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2ODQ3NjYyMA==&amp;amp;mid=2247484865&amp;amp;idx=1&amp;amp;sn=ffcb7f1f56aa8d5df61386778491677a&amp;amp;chksm=fc8c1362cbfb9a7480c5c5a1cfa07d3d586cca75c15e4ab95eb1bf750972d87c34875a7b8eb2&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;数仓面试|四个在工作后才知道的SQL密技&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2ODQ3NjYyMA==&amp;amp;mid=2247484633&amp;amp;idx=1&amp;amp;sn=4318c44a7ba10c8f98ae17f1a13bf20f&amp;amp;chksm=fc8c127acbfb9b6cd38eb4f12e1598beb47779d8ab2085d2f100f09766fbb3cd6c05f2560e0d&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;数仓|大数据时代,维度建模过时了吗?&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2ODQ3NjYyMA==&amp;amp;mid=2247484622&amp;amp;idx=1&amp;amp;sn=09a652b7ee8d03cd5581cc57931420bf&amp;amp;chksm=fc8c126dcbfb9b7b7d74d4cd7716c86d27592ac42c3e6a676880ededfff1d7f72df2dec0b4b8&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;数仓规范|使SQL更易于阅读的几个小技巧&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;1.2952127659574468&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/PL10rfzHicsgSwyuFAHrIHib40RYaGkyQxVn7629suCCWxJO5heFibm2q46Uz3thXuFDNciaunNiaXSdoiaPC3lFPlRw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;752&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;99939&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;98929&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;98929&quot;&gt;&lt;section hm_fix=&quot;300:334&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.958904109589041&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PL10rfzHicshOumLmWmKppdib5dNhEeg7drFgtcqoI4kRvrW1e753UOYicDoR0WlSMwcesOE0IJw0E4MPqReicsyyg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;点分享&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.9594594594594594&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PL10rfzHicshOumLmWmKppdib5dNhEeg7dJuIHmg5JR3WFRpxMhg813xnsbPpI91VI6MIuZIbYHJvwiauIVgNictBA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;74&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;点收藏&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.958904109589041&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PL10rfzHicshOumLmWmKppdib5dNhEeg7dviaDhs0VOZzUVIAibLK5WmhfpGHpkgp3M4JjJRdDaYia0tlwmyO3cQnxQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;73&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;点点赞&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.9594594594594594&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PL10rfzHicshOumLmWmKppdib5dNhEeg7dkCQhtZPOXw5NMlqCX0qHXiauoWdKx0nsaFGibu03yrURic1P8YlC1tQCQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;74&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;点在看&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8c6e08aaceef48bafc1ef8e61c7abfc3</guid>
<title>帮助阅读源码的 8 个技巧</title>
<link>https://toutiao.io/k/9v93x32</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;strong&gt;&lt;span&gt;这里是Z哥的个人公众号&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;每周五11：45 按时送达&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;当然了，也会时不时加个餐～&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我的第「181」篇原创敬上&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;大家好，我是Z哥。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;之前写了一篇关于阅读源码到底有多少价值的文章《&lt;/span&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2NzEwMDc4OQ==&amp;amp;mid=2247485621&amp;amp;idx=1&amp;amp;sn=40c0a8d28928692bcbe2cc9729744c61&amp;amp;chksm=fca31cafcbd495b93abdb1471e6834ce9c72752b18d7cbf330f98a005b2bff183c690ecbcb7f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;阅读源码的真正价值&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;阅读源码的真正价值&lt;/a&gt;&lt;/span&gt;&lt;span&gt;》，反响还不错。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在文中我向你阐明了阅读源码5个价值。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;面试&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在工作中更快地上手新项目&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;给自己创造用新技术的机会&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;完善知识体系&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;学习别人的设计思路&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;那么今天我就和你来聊聊如何更好地阅读源码，毕竟阅读源码这件事做起来还是有一定难度的，特别是刚起步的时候。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;而且有些巨型源码库，如果你不掌握一些高效的方式，那你阅读起来会让你绝望。就像往大海里投个石子，虽能掀起一丝涟漪，但海面很快就归于平静。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;其实从整个程序员群体来看，很少有人去学习这些项目的源码，大部分人都仅仅停留在 API 使用阶段。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;很多人对某个框架、项目的了解，最多停留在其它人对源码的解读之上。的确，在搜索引擎如此成熟、信息如此多的时代，如果要快速了解信息，以便解决眼前的问题，这的确是高效的方式。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;相信有不少人肯定也尝试过去github上阅读那些开源框架的源码，但是坚持不下去。在我看来原因主要是以下几种，&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;花了好几个小时，甚至好几天，才看懂了1、2个文件里的代码。但是毕竟还得工作呢，按这个进度的话，实在没办法拿出太多的时间放在源码的阅读上，还是算了吧。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第一个选择阅读的项目规模就比较大。一般这种大型项目，必然是经历了多年的迭代而形成的。所以，不管从复杂度还是代码量上都是“困难”级别的。当一次次遇到无法理解而放弃，换一个切入点但困难依旧的时候，你会觉得自己根本无法驾驭它，挫败感会促使你放弃阅读源码这件事情。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;有时我们阅读源码会配合着调试。但是有些源码的环境依赖比较多，一旦我们在部署环境的时候遇到了各种诡异的问题，但是查了很多资料依旧未能解决的时候，就会失去耐心，促使我们放弃。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;看了一段时间的源码，但是感受不到自己获得了什么，没有成就感。渐渐地，阅读源码的热情逐渐消失殆尽，感觉还是打游戏、刷短视频更香。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;不知道上面有你的影子吗？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;之所以出现这样的情况，在我看来是因为没有找到明确的方向或者目标太大，阅读源码是为了什么？为了提升自己，但是这个目标太大了，大到你还没有接收到正反馈就坚持不下去了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;所以我觉得有效地阅读源码的步骤分为以下两步，when和how，正好对应上一篇《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2NzEwMDc4OQ==&amp;amp;mid=2247485621&amp;amp;idx=1&amp;amp;sn=40c0a8d28928692bcbe2cc9729744c61&amp;amp;chksm=fca31cafcbd495b93abdb1471e6834ce9c72752b18d7cbf330f98a005b2bff183c690ecbcb7f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;阅读源码的真正价值&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;阅读源码的真正价值&lt;/a&gt;&lt;/span&gt;&lt;span&gt;》的why。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;/01  阅读源码的时机/&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;很多人看源码之所以看不下去，间接说明了一个问题，并不是任何时候都适合阅读源码。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;所以，我们的第一个问题就是要搞清楚“什么时候适合阅读源码”。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我亲测有效的方法是，带着问题去阅读源码，哪怕是一个个看似很小的问题。慢慢庖丁解牛，逐渐吃透整个项目。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;举个例子，比如你看到网上很多文章都在说redis单线程的性能表现在某些场景下甚至比多线程的memcached还要好。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;那么你可以带着这个问题去找到对应的源码去学习，这比你漫无目的的在大量的源码中乱逛，效果好得多。因为当你阅读完源码后你会获得一个正反馈，就是你知道了问题的答案，这种收获与成就感也会大大加深这次学习的效果。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;所以，一定要有一个问题或者说目的，没有目的就不要去阅读源码，还不如打游戏刷短视频。因为你大概率没几天就会全部忘记你看过的东西。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果你只是想学习一下，实在想不到什么问题作为切入点，那么不妨从git仓库里的issue里找一个开始吧。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;/02  怎么读/&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;01&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;准备工作&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;阅读源码之前首先你得掌握相关的基础知识。比如，你要去读Linux内核的源码，但是对C语言并不熟悉，这个事情自然没法继续下去。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在具备起码的基础知识后，先去官网看看是否有什么文档，通过阅读文档可以对项目设计思路和演进思路有一个大致的了解，这对你在实际阅读源码的时候可以起到事半功倍的效果。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;还可以了解一下，是否有其他项目是该项目的衍生品。因为当你后续觉得阅读该项目的源码举步维艰的时候，那么不妨试试从封装它的上层入手。多一种选择。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;02&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;从最早的稳定版本开始看&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;coding和造房子一样，结构（架构）在最开始一但确定好，后续几乎无法推翻重改，所以建议你从第一个版本开始看，可以通过阅读最少的代码就能了解到整个项目大部分的内容，包括它的核心设计思路。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;后期追加的很多代码其实有不少都在完善最初设计没考虑周全的地方以及异常处理，代码量虽然增加了，但是重要性完全不同。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;03&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;在IDE阅读&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;很多高手直接在git上看源码，效果如何我不清楚，反正我是觉得不太靠谱。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Z哥建议你一定要把代码放到IDE里阅读，毕竟IDE里可以方便跳转，查看定义，而且只要环境搭好还可以调试，比起在网页上看效率高得多。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果你实在要在git上直接阅读，好吧，我也帮你一把，推荐你一个chrome插件：SourceGraph。为你提供接近IDE般的操作体验。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;04&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;尽量调试一下&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;尽可能编译调试一下。因为在Z哥觉得能调试的代码，几乎没有看不懂的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;很多人在工作中修bug为什么喜欢直连生产环境调试？除了修bug效率高之外，还有一个原因就是它直观的体现了一个完整的流程在代码中是如何体现的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果一份代码你只能看不能调试，那可能读到一些地方你只能猜这个地方的数据值和跳转结构是怎么样的，而且很有可能你猜的是错的。但如果你能编译运行，那在需要的时候你可以修改，加日志等等来更好地观察和验证你的想法，得到正确的理解。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;05&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;先从宏观再到微观&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在看具体的代码之前，建议你先大致过一下整个项目的分层，知道解决方案里每一个项目的作用是什么。比如，这个专门存放全局工具类的项目，这个是数据访问层，等等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这样当你在后续经过多次代码跳转之后，不至于晕头转向的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;同样的，在你深入代码细节之前，先从“宏观”入手。先捋清楚与这相关的上下游完整的流程是如何映射在代码里的，然后再开始深入其中的具体环节的实现。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;另外，interface也是获取宏观信息很好的入口，当然前提是方法的命名比较规范或者有注释。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;06&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;适当跳过一些代码&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;一个项目的源码规模越大，里面的能跳过不读的代码也越多。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;哪些是可以跳过的？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;比如，针对数据的处理，json的序列化和反序列化、xml数据的读取和写入等代码，这些代码往往还特别冗长。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;07&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;看一遍无法理解的代码就画图&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当你看一遍甚至好几遍都无法完全明白的代码，说明它具有一定的复杂性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;此时，你不要偷懒，老老实实地画流程图、时序图等来帮助你梳理和记忆。它们最终为你省下的时间大概率比你花的时间多得多。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;而且画图是把代码具像化了，当你对着一张流程图读源码，就好像拿着地图走迷宫一般，确保自己走在预期的道路上。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;08&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;做笔记&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我相信每个人都出现过这样的情况：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这个问题我之前解决过，怎么解决来着？好像想不起来了……&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这个问题我之前研究过，是怎么回事来着？好像想不起来了……&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更甚之的情况是，早上觉得弄懂了数据流向，中午吃个饭就忘了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;……&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果你当时做了笔记，就不会出现这种情况了。而且，做笔记不仅仅可以用做后续的查阅，还可以帮助你更快地进入前一天的阅读状态。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这里建议用纸和笔就好。如果要用软件的话，最好弄个双屏，这样可以避免频繁地在查看源码的应用和记录笔记的应用之间的切换。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我建议你弄明白一个问题或者收获一个新的信息就记录一下。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;然后每天工作结束，稍做整理，并且将当前遗留的未知问题记录好，这样你第二天很容易进入到昨天的状态中继续进行。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果你打算将阅读源码作为一个长期习惯去做，那么你平时储备的通用知识多少又变得很重要，因为它们可以在阅读源码的时候大大提升效率。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;比如，设计模型、常用的算法等。当你看到什么XXXbuilder、XXXfactory，你就心领神会了，自然能大大提高阅读效率。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当然，如果遇到你之前不懂的设计模式、算法，那么应该停下来花点时间，将他们消化掉，这样你的通用知识库就又扩大了一些。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;总之，阅读源码还是一个比较费神的事情，要有耐心，遇到困难的时候更是如此。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我有时看代码，也会反复好几遍看不明白，感觉真是觉得搞不定了，然而，这意味着要么是你基础知识没准备好，要么是你找错了入口，要知道，任何一份代码，都有一条隐形的线串着，耐心点，总会找到。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;好了，总结一下。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这篇呢，Z哥和你分享了我在阅读源码这件事上的一些经验。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;首先，一定要带着问题或者目的去读源码，否则就别读了，读源码光“看”是没意义的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;其次在读的时候可以做以下8件事：&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;准备工作&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从最早的稳定版本开始看&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在IDE阅读&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;尽量调试一下&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;先从宏观再到微观&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;适当跳过一些代码&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;看一遍无法理解的代码就画图&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;做笔记&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;希望对你有所帮助。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;源码一开始读不懂是正常的，读不懂才要读，想不明白才要想，这是进步和成长的开始。那些阻挡你的蹂躏你的而又杀不死你的，终将帮助你成长让你变得更强大。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;推荐阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;原创不易，如果你觉得这篇文章还不错，就「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;在看&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」或者「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;分享&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」一下吧。鼓励我的创作 ：）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4428822495606327&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/oB5bd6W6hI1Xrkr3iaFRP5fErfmjHqlBw160icnia8yicWBlicnPEfqGE80alzGl9FLj6FxyuibIuliceoH9zicibj95loQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1138&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你有关于软件架构、分布式系统、产品、运营的困惑&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以试试点击「&lt;strong&gt;阅读原文&lt;/strong&gt;」&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>93ea39b57e1e04ee2a115b4c40b5a59c</guid>
<title>Spring Boot 异步调用</title>
<link>https://toutiao.io/k/xxk05uj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;@&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;2.1、无返回值的异步方法&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2.1、有返回值的异步方法&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;3.1、方法级别重写Executor&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;3.2、应用级别重写Executor&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;3.3、自定义线程池配置&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;“异步调用”对应的是“同步调用”，&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在实际开发中，有时候为了及时处理请求和进行响应，我们可能使用异步调用，&lt;strong&gt;同步调用指程序按照定义顺序依次执行，每一行程序都必须等待上一行程序执行完成之后才能执行；异步调用指程序在顺序执行时，不等待异步调用的语句返回结果就执行后面的程序。&lt;/strong&gt;异步调用的实现有很多，例如多线程、定时任务、消息队列等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里学习使用@Async注解来实现异步调用。&lt;/p&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1、@EnableAsync&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，我们需要在启动类上添加  @EnableAsync 注解来声明开启异步方法。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@SpringBootApplication&lt;/span&gt;&lt;br/&gt;&lt;span&gt;@EnableAsync&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;SpringbootAsyncApplication&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        SpringApplication.run(SpringbootAsyncApplication&lt;span&gt;.&lt;span&gt;class&lt;/span&gt;, &lt;span&gt;args&lt;/span&gt;)&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2、@Async&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;需要注意的，@Async在使用上有一些限制：&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;它只能应用于public修饰的方法&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;自调用–从同一个类中调用async方法，将不起作用&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;原因很简单：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;只有公共方法，才可以被代理。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;自调用不起作用，因为它越过了代理直接调用了方法。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1、无返回值的异步方法&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是一个异步运行的无返回值方法：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;    &lt;span&gt;@Async&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;asyncMethodWithVoidReturnType&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;异步无返回值方法 &quot;&lt;/span&gt;&lt;br/&gt;                + Thread.currentThread().getName());&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;big&gt;实例：&lt;/big&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;AsyncTask:异步式任务类，定义了三个异步式方法。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;/**&lt;br/&gt; * &lt;span&gt;@Author&lt;/span&gt; 三分恶&lt;br/&gt; * &lt;span&gt;@Date&lt;/span&gt; 2020/7/15&lt;br/&gt; * &lt;span&gt;@Description&lt;/span&gt; 异步式任务&lt;br/&gt; */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;@Component&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;AsyncTask&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;   Logger log= LoggerFactory.getLogger(AsyncTask&lt;span&gt;.&lt;span&gt;class&lt;/span&gt;)&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; Random random = &lt;span&gt;new&lt;/span&gt; Random();&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;/**&lt;br/&gt;     * 定义三个异步式方法&lt;br/&gt;     * &lt;span&gt;@throws&lt;/span&gt; InterruptedException&lt;br/&gt;     */&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Async&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;taskOne&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; InterruptedException &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;long&lt;/span&gt; start = System.currentTimeMillis();&lt;br/&gt;        &lt;span&gt;//随机休眠若干毫秒&lt;/span&gt;&lt;br/&gt;        Thread.sleep(random.nextInt(&lt;span&gt;10000&lt;/span&gt;));&lt;br/&gt;        &lt;span&gt;long&lt;/span&gt; end = System.currentTimeMillis();&lt;br/&gt;        log.info(&lt;span&gt;&quot;任务一执行完成耗时{}秒&quot;&lt;/span&gt;, (end - start)/&lt;span&gt;1000f&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Async&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;taskTwo&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; InterruptedException &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;long&lt;/span&gt; start = System.currentTimeMillis();&lt;br/&gt;        Thread.sleep(random.nextInt(&lt;span&gt;10000&lt;/span&gt;));&lt;br/&gt;        &lt;span&gt;long&lt;/span&gt; end = System.currentTimeMillis();&lt;br/&gt;        log.info(&lt;span&gt;&quot;任务二执行完成耗时{}秒&quot;&lt;/span&gt;, (end - start)/&lt;span&gt;1000f&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Async&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;taskThree&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; InterruptedException &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;long&lt;/span&gt; start = System.currentTimeMillis();&lt;br/&gt;        Thread.sleep(random.nextInt(&lt;span&gt;10000&lt;/span&gt;));&lt;br/&gt;        &lt;span&gt;long&lt;/span&gt; end = System.currentTimeMillis();&lt;br/&gt;        log.info(&lt;span&gt;&quot;任务三执行完成耗时{}秒&quot;&lt;/span&gt;, (end - start)/&lt;span&gt;1000f&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;/**&lt;br/&gt; * &lt;span&gt;@Author&lt;/span&gt; 三分恶&lt;br/&gt; * &lt;span&gt;@Date&lt;/span&gt; 2020/7/15&lt;br/&gt; * &lt;span&gt;@Description&lt;/span&gt;&lt;br/&gt; */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;@SpringBootTest&lt;/span&gt;&lt;br/&gt;&lt;span&gt;@RunWith&lt;/span&gt;(SpringRunner&lt;span&gt;.&lt;span&gt;class&lt;/span&gt;)&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; &lt;span&gt;AsyncTaskTest&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; AsyncTask asyncTask;&lt;br/&gt;&lt;br/&gt;    Logger log= LoggerFactory.getLogger(AsyncTaskTest&lt;span&gt;.&lt;span&gt;class&lt;/span&gt;)&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Test&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;doAsyncTasks&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;            &lt;span&gt;long&lt;/span&gt; start = System.currentTimeMillis();&lt;br/&gt;            &lt;span&gt;//调用三个异步式方法&lt;/span&gt;&lt;br/&gt;            asyncTask.taskOne();&lt;br/&gt;            asyncTask.taskTwo();&lt;br/&gt;            asyncTask.taskThree();&lt;br/&gt;            Thread.sleep(&lt;span&gt;5000&lt;/span&gt;);&lt;br/&gt;            &lt;span&gt;long&lt;/span&gt; end = System.currentTimeMillis();&lt;br/&gt;            log.info(&lt;span&gt;&quot;主程序执行完成耗时{}秒&quot;&lt;/span&gt;, (end - start)/&lt;span&gt;1000f&lt;/span&gt;);&lt;br/&gt;        } &lt;span&gt;catch&lt;/span&gt; (InterruptedException e) {&lt;br/&gt;            e.printStackTrace();&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行结果：可以看到三个方法没有顺序执行，这个复执行单元测试，您可能会遇到各种不同的结果，比如：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.1570048309178744&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PMZOEonJxWf6Ow2vqaaH7vmQwx1J3XPf2qicBREaC2hvY5IoR3ZoiaWjn1N02QfW7A3ibzuIOsMQznFZeP0QM5USA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1242&quot;/&gt;&lt;figcaption&gt;&lt;span/&gt;在这里插入图片描述&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.1495480690221857&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PMZOEonJxWf6Ow2vqaaH7vmQwx1J3XPfrJ6Wia9tliagqxMHqGXIAbusrT3YnxIEXibgtta291lJC9ZCHAnNH5H7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1217&quot;/&gt;&lt;figcaption&gt;&lt;span/&gt;在这里插入图片描述&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;原因是目前doTaskOne、doTaskTwo、doTaskThree三个函数的时候已经是异步执行了。&lt;strong&gt;主程序在异步调用之后，主程序并不会理会这三个函数是否执行完成了，由于没有其他需要执行的内容，所以程序就自动结束了，&lt;/strong&gt;导致了不完整或是没有输出任务相关内容的情况。&lt;/p&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1、有返回值的异步方法&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;@Async也可以应用有返回值的方法–通过在Future中包装实际的返回值：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;   &lt;span&gt;/**&lt;br/&gt;     * 有返回值的异步方法&lt;br/&gt;     * &lt;span&gt;@return&lt;/span&gt;&lt;br/&gt;     */&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Async&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; Future&amp;lt;String&amp;gt; &lt;span&gt;asyncMethodWithReturnType&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;执行有返回值的异步方法 &quot;&lt;/span&gt;&lt;br/&gt;                + Thread.currentThread().getName());&lt;br/&gt;        &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;            Thread.sleep(&lt;span&gt;5000&lt;/span&gt;);&lt;br/&gt;            &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; AsyncResult&amp;lt;String&amp;gt;(&lt;span&gt;&quot;hello world !!!!&quot;&lt;/span&gt;);&lt;br/&gt;        } &lt;span&gt;catch&lt;/span&gt; (InterruptedException e) {&lt;br/&gt;            &lt;span&gt;//&lt;/span&gt;&lt;br/&gt;        }&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Spring还提供了一个实现Future的AsyncResult类。这个类可用于跟踪异步方法执行的结果。&lt;/p&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;big&gt;实例：&lt;/big&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;    &lt;span&gt;@Async&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; Future&amp;lt;String&amp;gt; &lt;span&gt;taskOne&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; InterruptedException &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;long&lt;/span&gt; start = System.currentTimeMillis();&lt;br/&gt;        &lt;span&gt;//随机休眠若干毫秒&lt;/span&gt;&lt;br/&gt;        Thread.sleep(random.nextInt(&lt;span&gt;10000&lt;/span&gt;));&lt;br/&gt;        &lt;span&gt;long&lt;/span&gt; end = System.currentTimeMillis();&lt;br/&gt;        log.info(&lt;span&gt;&quot;任务一执行完成耗时{}秒&quot;&lt;/span&gt;, (end - start)/&lt;span&gt;1000f&lt;/span&gt;);&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; AsyncResult&amp;lt;&amp;gt;(&lt;span&gt;&quot;任务一完事了&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;taskTwo、taskThree方法做同样的改造。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;   &lt;span&gt;@Test&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;doFutureTask&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;            &lt;span&gt;long&lt;/span&gt; start=System.currentTimeMillis();&lt;br/&gt;            Future&amp;lt;String&amp;gt; future1=asyncTask.taskOne();&lt;br/&gt;            Future &amp;lt;String&amp;gt; future2 = asyncTask.taskTwo();&lt;br/&gt;            Future &amp;lt;String&amp;gt; future3 = asyncTask.taskThree();&lt;br/&gt;            &lt;span&gt;//三个任务执行完再执行主程序&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;do&lt;/span&gt; {&lt;br/&gt;                Thread.sleep(&lt;span&gt;100&lt;/span&gt;);&lt;br/&gt;            } &lt;span&gt;while&lt;/span&gt; (future1.isDone() &amp;amp;&amp;amp; future2.isDone() &amp;amp;&amp;amp; future3.isDone());&lt;br/&gt;            log.info(&lt;span&gt;&quot;获取异步方法的返回值:{}&quot;&lt;/span&gt;, future1.get());&lt;br/&gt;            Thread.sleep(&lt;span&gt;5000&lt;/span&gt;);&lt;br/&gt;            &lt;span&gt;long&lt;/span&gt; end = System.currentTimeMillis();&lt;br/&gt;            log.info(&lt;span&gt;&quot;主程序执行完成耗时{}秒&quot;&lt;/span&gt;, (end - start)/&lt;span&gt;1000f&lt;/span&gt;);&lt;br/&gt;        } &lt;span&gt;catch&lt;/span&gt; (InterruptedException e) {&lt;br/&gt;            e.printStackTrace();&lt;br/&gt;        } &lt;span&gt;catch&lt;/span&gt; (ExecutionException e) {&lt;br/&gt;            e.printStackTrace();&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行结果：可以看到三个任务完成后才执行主程序，还输出了异步方法的返回值。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.18764478764478765&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PMZOEonJxWf6Ow2vqaaH7vmQwx1J3XPfonwKlHw1nt6Bmhcmich6hia9Reb9KnJvRMYXAUcpXbboo3BxLIaYLPyw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1295&quot;/&gt;&lt;figcaption&gt;&lt;span/&gt;在这里插入图片描述&lt;/figcaption&gt;&lt;/figure&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3、 Executor&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;默认情况下，Spring使用SimpleAsyncTaskExecutor异步运行这些方法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以在两个级别上重写默认线程池——应用程序级别或方法级别。&lt;/p&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3.1、方法级别重写Executor&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所需的执行程序需要在配置类中声明 Executor：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;/**&lt;br/&gt; * &lt;span&gt;@Author&lt;/span&gt; 三分恶&lt;br/&gt; * &lt;span&gt;@Date&lt;/span&gt; 2020/7/15&lt;br/&gt; * &lt;span&gt;@Description&lt;/span&gt; 方法级别重写线程池&lt;br/&gt; */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;@Configuration&lt;/span&gt;&lt;br/&gt;&lt;span&gt;@EnableAsync&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;SpringAsyncConfig&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Bean&lt;/span&gt;(name = &lt;span&gt;&quot;threadPoolTaskExecutor&quot;&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; Executor &lt;span&gt;threadPoolTaskExecutor&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; ThreadPoolTaskExecutor();&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后，在@Async中的属性提供Executor名称：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;    &lt;span&gt;@Async&lt;/span&gt;(&lt;span&gt;&quot;threadPoolTaskExecutor&quot;&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;asyncMethodWithConfiguredExecutor&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;Execute method with configured executor - &quot;&lt;/span&gt;&lt;br/&gt;                + Thread.currentThread().getName());&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3.2、应用级别重写Executor&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;配置类应实现AsyncConfigurer接口，重写getAsyncExecutor()方法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这里，我们将返回整个应用程序的Executor，这样一来，它就成为运行以@Async注释的方法的默认Executor：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;/**&lt;br/&gt; * &lt;span&gt;@Author&lt;/span&gt; 三分恶&lt;br/&gt; * &lt;span&gt;@Date&lt;/span&gt; 2020/7/15&lt;br/&gt; * &lt;span&gt;@Description&lt;/span&gt; 应用级别重写 Excutor&lt;br/&gt; */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;@Configuration&lt;/span&gt;&lt;br/&gt;&lt;span&gt;@EnableAsync&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;SpringApplicationAsyncConfig&lt;/span&gt; &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;AsyncConfigurer&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; Executor &lt;span&gt;getAsyncExecutor&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; ThreadPoolTaskExecutor();&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3.3、自定义线程池配置&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上面，自定义线程池只是简单地返回了一个线程池：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; ThreadPoolTaskExecutor();&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实际上，还可以对线程池做一些配置：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;/**&lt;br/&gt; * &lt;span&gt;@Author&lt;/span&gt; 三分恶&lt;br/&gt; * &lt;span&gt;@Date&lt;/span&gt; 2020/7/15&lt;br/&gt; * &lt;span&gt;@Description&lt;/span&gt;&lt;br/&gt; */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;@Configuration&lt;/span&gt;&lt;br/&gt;&lt;span&gt;@EnableAsync&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;SpringPropertiesAsyncConfig&lt;/span&gt; &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;AsyncConfigurer&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;/**&lt;br/&gt;     * 对线程池进行配置&lt;br/&gt;     * &lt;span&gt;@return&lt;/span&gt;&lt;br/&gt;     */&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; Executor &lt;span&gt;getAsyncExecutor&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        ThreadPoolTaskExecutor taskExecutor = &lt;span&gt;new&lt;/span&gt; ThreadPoolTaskExecutor();&lt;br/&gt;        taskExecutor.setCorePoolSize(&lt;span&gt;20&lt;/span&gt;);&lt;br/&gt;        taskExecutor.setMaxPoolSize(&lt;span&gt;200&lt;/span&gt;);&lt;br/&gt;        taskExecutor.setQueueCapacity(&lt;span&gt;25&lt;/span&gt;);&lt;br/&gt;        taskExecutor.setKeepAliveSeconds(&lt;span&gt;200&lt;/span&gt;);&lt;br/&gt;        taskExecutor.setThreadNamePrefix(&lt;span&gt;&quot;oKong-&quot;&lt;/span&gt;);&lt;br/&gt;        &lt;span&gt;// 线程池对拒绝任务（无线程可用）的处理策略，目前只支持AbortPolicy、CallerRunsPolicy；默认为后者&lt;/span&gt;&lt;br/&gt;        taskExecutor.setRejectedExecutionHandler(&lt;span&gt;new&lt;/span&gt; ThreadPoolExecutor.CallerRunsPolicy());&lt;br/&gt;        taskExecutor.initialize();&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; taskExecutor;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ThreadPoolTaskExecutor配置参数的简单说明：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;corePoolSize：线程池维护线程的最少数量&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;keepAliveSeconds：允许的空闲时间,当超过了核心线程出之外的线程在空闲时间到达之后会被销毁&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;maxPoolSize：线程池维护线程的最大数量,只有在缓冲队列满了之后才会申请超过核心线程数的线程&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;queueCapacity：缓存队列&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;rejectedExecutionHandler：线程池对拒绝任务（无线程可用）的处理策略。这里采用了CallerRunsPolicy策略，当线程池没有处理能力的时候，该策略会直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务。还有一个是AbortPolicy策略：处理程序遭到拒绝将抛出运行时RejectedExecutionException。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4、异常处理&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当方法返回类型为Future时，异常处理很容易– Future.get()方法将抛出异常。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是如果是无返回值的异步方法，&lt;strong&gt;异常不会传播到调用线程。&lt;/strong&gt;因此，我们需要添加额外的配置来处理异常。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们将通过实现AsyncUncaughtExceptionHandler接口来创建自定义异步异常处理程序。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当存在任何未捕获的异步异常时，将调用handleUncaughtException()方法：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;/**&lt;br/&gt; * &lt;span&gt;@Author&lt;/span&gt; 三分恶&lt;br/&gt; * &lt;span&gt;@Date&lt;/span&gt; 2020/7/15&lt;br/&gt; * &lt;span&gt;@Description&lt;/span&gt;&lt;br/&gt; */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;CustomAsyncExceptionHandler&lt;/span&gt; &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;AsyncUncaughtExceptionHandler&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;handleUncaughtException&lt;/span&gt;&lt;span&gt;(Throwable throwable, Method method, Object... objects)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;Exception message - &quot;&lt;/span&gt; + throwable.getMessage());&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;Method name - &quot;&lt;/span&gt; + method.getName());&lt;br/&gt;        &lt;span&gt;for&lt;/span&gt; (Object param : objects) {&lt;br/&gt;            System.out.println(&lt;span&gt;&quot;Parameter value - &quot;&lt;/span&gt; + param);&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面，我们使用配置类实现了AsyncConfigurer接口。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作为其中的一部分，我们还需要重写getAsyncUncaughtExceptionHandler()方法以返回我们的自定义异步异常处理：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;    &lt;span&gt;/**&lt;br/&gt;     * 返回自定义异常处理&lt;br/&gt;     * &lt;span&gt;@return&lt;/span&gt;&lt;br/&gt;     */&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; AsyncUncaughtExceptionHandler &lt;span&gt;getAsyncUncaughtExceptionHandler&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;         &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; CustomAsyncExceptionHandler();&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5、总结&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里异步请求的使用及相关配置，如超时，异常等处理。在剥离一些和业务无关的操作时，就可以考虑使用异步调用进行其他无关业务操作，以此提供业务的处理效率。或者一些业务场景下可拆分出多个方法进行同步执行又互不影响时，也可以考虑使用异步调用方式提供执行效率。&lt;/p&gt;&lt;br data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;本文为学习笔记类博客，学习资料来源见参考！&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;big&gt;&lt;strong&gt;参考：&lt;/strong&gt;&lt;/big&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;【1】：《深入浅出SpringBoot 2.x》
【2】：Spring Boot中使用@Async实现异步调用【3】：SpringBoot 中异步执行任务的 2 种方式【4】：How To Do @Async in Spring【5】：SpringBoot系列：Spring Boot异步调用@Async【6】：SpringBoot | 第二十一章：异步开发之异步调用【7】：实战Spring Boot 2.0系列(三) - 使用@Async进行异步调用详解&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>