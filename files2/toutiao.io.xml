<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>f51b8bfcd26e79563274022b552b94ea</guid>
<title>五一没地方去？来这里吧！</title>
<link>https://toutiao.io/k/m70wnkv</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                  &lt;strong class=&quot;profile_nickname&quot;&gt;我爱程序员&lt;/strong&gt;
                  &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;developerWorks&lt;/span&gt;
                  &lt;/p&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;我们的产品：《码农周刊》 http://manong.io/ 、《开发者头条》 http://toutiao.io/&lt;/span&gt;
                  &lt;/p&gt;
                &lt;/div&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a9c50de2c98dc9ad5ab552fee94187af</guid>
<title>引入『客户端缓存』，Redis6算是把缓存玩明白了…</title>
<link>https://toutiao.io/k/txajf8j</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;哈喽大家好啊，我是没更新就是在家忙着带娃的Hydra。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在前面介绍两级缓存的文章中，我们总共给出了4种实现方案，在项目中整合了本地缓存&lt;code&gt;Caffeine&lt;/code&gt;和远程缓存&lt;code&gt;Redis&lt;/code&gt;，将应用的性能从仅适用单独远程缓存的基础上，再次提高了一个层次。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而今天Hydra要和大家分享的技术，在思想上和上面两级缓存有些类似，不过不需要借助其他本地缓存中间件，只使用&lt;code&gt;Redis&lt;/code&gt;自身服务端和客户端就可以实现。这就是&lt;code&gt;Redis6&lt;/code&gt;中的客户端缓存&lt;code&gt;Client-side caching&lt;/code&gt;这一项新特性，它允许将数据缓存在&lt;strong&gt;应用服务端&lt;/strong&gt;以及&lt;strong&gt;远程缓存&lt;/strong&gt;两个位置。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;简介&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;客户端缓存是Redis6众多新特性中比较实用的一项新功能，我们看看官方文档，了解一下它的作用：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;客户端缓存是一种用于创建高性能服务的技术，它可以利用&lt;strong&gt;应用服务器&lt;/strong&gt;上的可用内存（这些服务器通常是一些不同于数据库服务器的节点），在这些应用服务端来直接存储数据库中的一些信息。&lt;/p&gt;&lt;p&gt;与访问数据库等网络服务相比，访问本地内存所需要的时间消耗要少得多，因此这个模式可以大大缩短应用程序获取数据的延迟，同时也能减轻数据库的负载压力。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到这，我心想这不是和其他本地缓存Guava、Caffeine啥的一样吗，换汤不换药，都是使用的应用服务的内存罢了。要说有什么好处，可能就是我在项目中能少引入一个中间件了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不过，我这点浅薄的猜想，在看完客户端缓存的具体应用模式后，彻底被颠覆了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;两种模式&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在了解了客户端缓存的基本功能后，我们来看看它的两种基本应用模式。Redis的客户端缓存支持被称为&lt;code&gt;tracking&lt;/code&gt;，个人感觉翻译为对key的&lt;strong&gt;追踪&lt;/strong&gt;就很好理解，它具有两种模式：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;默认模式，服务端会记录某个客户端具体访问过哪一些&lt;code&gt;key&lt;/code&gt;，当这些&lt;code&gt;key&lt;/code&gt;对应的值发生变化时，会发送失效消息给这些客户端。这个模式会在服务端消耗一些内存，但是发送失效消息的范围，被限制在了客户端存储了的&lt;code&gt;key&lt;/code&gt;的集合范围内&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;广播模式，服务端不会再记录某个客户端访问了哪些&lt;code&gt;key&lt;/code&gt;，因此这个模式不消耗服务端的内存。取而代之的是，客户端需要订阅&lt;code&gt;key&lt;/code&gt;的特定前缀，每当符合这个前缀的&lt;code&gt;key&lt;/code&gt;对应的值发生改变时，客户端都会收到通知消息&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到这里，它和我们之前使用的两级缓存之间差异，是不是已经初露端倪了呢？如果还不熟悉两级缓存的架构，那么可以先来看看下面的这张图：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4039158810732415&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicbdISYMMsL8iaw6JWTYeElpIfwWIbTXwKx9bO6IQnWHgQ8wJ5GeFicia4uTa60PXcB7R0X2poXJ76PsQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1379&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种架构在理论上看起来不错，但是实际使用起来需要注意的点不少，尤其是在分布式模式下，需要保证各个主机下的一级缓存的一致性问题，回想一下我们原先的解决方案，可以使用redis本身的&lt;strong&gt;发布/订阅&lt;/strong&gt;功能来实现：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4524053224155578&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicbdISYMMsL8iaw6JWTYeElpIJxlOVudq9zMusjqV8y0EaUjWCu7fIXbhm1GYibvGdfP8PgHiaPHZAmpA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;977&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而客户端缓存的出现，大大简化了这一过程。我们以&lt;strong&gt;默认模式&lt;/strong&gt;为例，看一下使用了客户端缓存后的操作过程：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5650406504065041&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicbdISYMMsL8iaw6JWTYeElpIuavKHIuHUsqicwelYcT9ovvmgOyDfQ0w9icEVFlZORSLzLTsKA1GADfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;984&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相比原先的发布/订阅模式，我们可以看到明显的优势，使用客户端缓存功能后，我们只需要单纯的修改redis中的数据就可以了，手动处理发布/订阅消息的这一过程可以完全被省略。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;优势&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到这里，在了解了客户端缓存的基本功能与两种模式后，我们来对比一下，和传统的只使用redis做远程缓存、以及使用整合后的两级缓存相比较，客户端缓存具有什么样的优势。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;当应用的服务端存在缓存时，会直接读取本地缓存，能够减少网络访问上造成的延迟，从而加快访问速度&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;同时也能减少访问redis服务端的次数，降低redis的负载压力&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在分布式环境下，不再需要通过发布订阅来通知其他主机更新本地缓存，来保证数据的一致性。使用客户端缓存后，它所具有的原生的消息通知功能，能很好地支持作废本地缓存，保证之后访问时能取到更新后的新数据&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;误区&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在开始演示客户端缓存的使用之前，我们先来纠正一个误区。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然这个新特性被称为&lt;strong&gt;客户端缓存&lt;/strong&gt;，但是redis本身不提供在应用服务端缓存数据的功能，这个功能要由&lt;strong&gt;访问redis的客户端&lt;/strong&gt;自己去实现。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说白了，也就是redis服务端只负责通知你，你缓存在应用服务本地的这个key已经作废了，至于你本地如何缓存的这些数据，redis并不关心，也不负责。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;功能演示&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面将通过一些实例来进行演示，本文代码的运行前提条件是你已经装好了&lt;code&gt;Redis6.x&lt;/code&gt;版本，linux环境下可以直接从官网下载后编译安装，windows环境下的安装可以参考 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzIwMTgzOTQ0Ng==&amp;amp;mid=2247488620&amp;amp;idx=1&amp;amp;sn=0065c23e5055adddbe9ead318a49c9c6&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;手摸手教你在Windows环境下运行Redis6.x&lt;/a&gt; 这篇文章。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;概念上的东西我们也大体了解了，下面我们分别来看一下客户端缓存具体实现的三种模式（至于为什么多了一种，后面再来细说）。在正式开始前，强烈建议大家先花个十几分钟了解一下 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzIwMTgzOTQ0Ng==&amp;amp;mid=2247489005&amp;amp;idx=1&amp;amp;sn=ef5ceda185c92758e98b36888d53d34d&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;Redis6底层的通信协议RESP3&lt;/a&gt;，否则在看到具体的通信内容时可能会存在一些疑问。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先做一下准备工作，通过&lt;code&gt;telnet&lt;/code&gt;连接redis服务，并切换到&lt;code&gt;resp3&lt;/code&gt;协议模式：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;telnet 127.0.0.1 6379&lt;br/&gt;hello 3&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;1、默认模式&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在使用客户端连接到redis服务后，需要先通过指令开启&lt;code&gt;tracking&lt;/code&gt;模式的功能，因为在客户端连接后这个选项是默认关闭的，会无法收到失效类型的&lt;code&gt;push&lt;/code&gt;消息：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;开启&lt;/span&gt;&lt;br/&gt;client tracking on&lt;br/&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;关闭&lt;/span&gt;&lt;br/&gt;client tracking off&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当开启&lt;code&gt;tracking&lt;/code&gt;后的默认模式下，redis服务端会记录每个客户端请求过的key，当key对应的值发生变化时，会发送失效信息给客户端。简单总结一下，也就是说这个模式能够生效的&lt;strong&gt;必要前提条件&lt;/strong&gt;有两个：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我们还是在&lt;code&gt;telnet&lt;/code&gt;中来模拟一下这个过程，分别启动两个redis客户端，在client1中先执行&lt;code&gt;get&lt;/code&gt;命令后，再在client2对相同的key执行&lt;code&gt;set&lt;/code&gt;操作修改它的值，之后就会在client1中收到&lt;code&gt;push&lt;/code&gt;类型的消息。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9079563182527302&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicbdISYMMsL8iaw6JWTYeElpIBy8dicdc0qhE2HicicW5lmxoLhojOibBaNrjGd06MGsnjoJV6zsHWm5tYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;641&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;push&lt;/code&gt;类型的消息我们在RESP3中介绍过了，这里简单再唠叨两句：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;br/&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;&lt;br/&gt;invalidate&lt;br/&gt;*1&lt;br/&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;&lt;br/&gt;user&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;起始的第一字节&lt;code&gt;&amp;gt;&lt;/code&gt;表示该消息为&lt;code&gt;push&lt;/code&gt;类型，后面消息体中包含了两部分内容，第一部分表示收到的消息类型为&lt;code&gt;invalidate&lt;/code&gt;，也就是作废类型的信息，第二部分则是需要作废的key是&lt;code&gt;user&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除此之外，当一个缓存的key到达失效时间导致过期，或是因为到达最大内存，要使用驱逐策略进行驱逐时，也会对客户端发送&lt;code&gt;PUSH&lt;/code&gt;的消息。下面以缓存的key过期为例：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.9145299145299146&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicbdISYMMsL8iaw6JWTYeElpI7zK86c5B5Cp4UGaxy9dULWtAav83AnuYtVLkichLkjTuicQiagHGDcQUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;351&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，对于单个key来说，这个&lt;code&gt;tracking&lt;/code&gt;消息只会对客户端发送一次，当第二次修改该key所对应的值后，客户端不会再收到&lt;code&gt;tracking&lt;/code&gt;的消息。只有对这个key再执行一次&lt;code&gt;get&lt;/code&gt;命令，之后才会再次收到&lt;code&gt;tracking&lt;/code&gt;消息。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8611544461778471&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicbdISYMMsL8iaw6JWTYeElpImbfxhg4gz6OBUhI48weyQTPicGLHyINMY3BhD2zgDqWyGKNDyOAQNSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;641&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;默认模式虽然使用起来简单，但是需要在服务端存储客户端的访问数据，记录哪些key被哪些客户端访问过。如果访问的不是少量的热点数据的话，可能会占用大量redis服务端的内存空间。应对这种情况，可以试一试下面要介绍的广播模式。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;2、广播模式&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在广播模式&lt;code&gt;BCAST&lt;/code&gt;下，redis服务端不再记录key的访问情况，而是无差别地向所有开启&lt;code&gt;tracking&lt;/code&gt;广播的客户端发送消息。这样一来，好处就是不需要浪费redis服务端的内存进行记录，但是坏处就是客户端可能会收到过多的消息，其中可能还会包含自己不需要的一些key。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在使用前，需要先通过命令开启广播模式：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;client tracking on bcast&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面，我们通过一个例子来进行广播模式的使用演示：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.06396255850234&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicbdISYMMsL8iaw6JWTYeElpIXcUMZBcx6nar5oclMBx9G77jVF5JUbvU63jNrvGMLmciak5kSLOYLCA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;641&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到在开启广播模式后，只要在client2中修改了key对应的值，在client1中都会收到作废消息，而不管client1之前在本地是否进行过缓存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;并且，另外一点和默认模式不同的是，广播模式是能够重复多次收到一个key的失效消息的，因为服务端没有记录，所以只要有key发生了修改，客户端就会收到失效消息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时候，有的小伙伴可能就要问了，如果我不想收到这么多没用的冗余消息，有没有什么办法进行一下过滤或精简呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答案是可以的，在广播模式下，客户端可以只关注一些&lt;strong&gt;特定前缀&lt;/strong&gt;的key，表示我只需要接收这些前缀的key，其他的就不要发给我了。命令格式如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;client tracking on bcast prefix myprefix&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再来看一下使用过程的示例：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9547581903276131&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicbdISYMMsL8iaw6JWTYeElpIkB3wc37bHabT5VvXTshZHJWziaAbAvPapfXf5ILlpdPIQKxPwOSiaegw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;641&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到，在设置了只关注以&lt;code&gt;order:&lt;/code&gt;作为前缀的key后，成功过滤掉了&lt;code&gt;user&lt;/code&gt;的失效消息。从这个角度来看，也要求了我们在缓存一个类型的数据时，都以相同的单词作为前缀，规范了我们在使用缓存中对key的命名规则。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至于在业务中具体要使用哪种模式，可能更多的需要进行一下权衡。看一下你究竟是能忍受占用更多redis服务端的内存，还是能够忍受收到大量不需要的失效消息。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;3、转发模式&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;默认模式和广播模式的生效，都要在开启&lt;code&gt;RESP3&lt;/code&gt;协议的前提下，具体原因看过上面的例子大家应该也都清楚了，因为要使用&lt;code&gt;tracking&lt;/code&gt;的话，就必须要借助到&lt;code&gt;RESP3&lt;/code&gt;协议中的新的&lt;code&gt;push&lt;/code&gt;消息类型。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么如果客户端还是使用的旧版本&lt;code&gt;RESP V2&lt;/code&gt;的话，也想要体验这一功能，应该如何进行改造呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不得不说redis6的开发者想的还是蛮全面的，为了适配&lt;code&gt;RESP V2&lt;/code&gt;，专门设计了一种新的&lt;strong&gt;转发模式&lt;/strong&gt;，允许使用旧版本协议的客户端通过&lt;code&gt;Pub/Sub&lt;/code&gt;发布订阅功能来接收key的失效信息。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.444794952681388&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicbdISYMMsL8iaw6JWTYeElpIdfRS9Jnu0OPqzpeFN3Tqh8L6iaOuLSj3duic243oZxTVvopEFUFpB23A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;951&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从上面这张图可以看到，转发模式的核心就是redis服务端会将原先&lt;code&gt;push&lt;/code&gt;类型的&lt;code&gt;tracking&lt;/code&gt;信息，转发到订阅了&lt;code&gt;_redis_:invalidate&lt;/code&gt;这一信道的被指定的客户端上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们来梳理一下上面的流程，首先在client1需要使用指令开启转发模式：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;client tracking on bcast redirect [client-id]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相对广播模式，多了两个参数，&lt;code&gt;redirect&lt;/code&gt;表示为转发模式，后面的&lt;code&gt;client-id&lt;/code&gt;表示消息要发送给哪一个客户端，客户端的id可以在client2上通过&lt;code&gt;client id&lt;/code&gt;指令获取。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在client2中，则需要订阅指定的信道：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;subscribe _redis_:invalidate&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实说白了，转发模式还是使用的发布订阅功能罢了，只不过redis帮我们解放了双手，把发送消息的工作由自己完成了。整个操作的流程如下图所示：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8621997471554994&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicbdISYMMsL8iaw6JWTYeElpI0V1QIuzTVQYDBfPq6CZQRqTiaSk1Kpiay83IuDQA8wIqFoEUibWqKsC9A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;791&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到，client2中收到的消息格式与之前的&lt;code&gt;push&lt;/code&gt;类型消息不同，是一条RESP V2中多条批量回复格式的消息，表示的含义同样是收到的key已经作废掉了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;需要注意的是，虽然说开启转发模式的指令中也带了一个&lt;code&gt;bcast&lt;/code&gt;，但是它和广播模式有着非常大的区别。在转发模式下，&lt;code&gt;key&lt;/code&gt;的作废消息只能被转发到一个客户端上，如果先后执行两条指定转发指令，那么后执行的指令会覆盖前一指令中转发的&lt;code&gt;client-id&lt;/code&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8060965283657917&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zpom4BeZSicbdISYMMsL8iaw6JWTYeElpI3ia7QMXQg1ib5YWibVv4OL6iaaX5VQiaeSYS0uLq05o0ickiabMe4gRHZ4gdw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1181&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到这里是不是多少感觉这个转发模式有点鸡肋，毕竟实际的业务场景中很有可能会有多个客户端的存在，只能转发一个实在是有点说不过去了。不过，也有可能作者就是这么设计，留点缺陷，好让大家更快地拥抱&lt;code&gt;RESP3&lt;/code&gt;……&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;总结&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好啦，到这里客户端缓存的基本理论和使用就介绍的差不多了，不得不说，Redis6的这个新特性确实给了我们眼前一亮的感觉。从这个新特性也可以看出，Redis大有把缓存从服务端的局限中挣脱出来，染指向客户端，一统缓存江湖的意味。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不过这个过程应该并不简单，就像我们前面说的，毕竟只有Redis服务端还不够，还需要优秀的客户端进行支持才行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么下一篇文章，我们就来从实战角度，看看如何改造客户端，让&lt;code&gt;client-side caching&lt;/code&gt;能在项目中落地开花。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这次的分享就到这里，我是Hydra，下篇文章再见。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;官方文档：&lt;/p&gt;&lt;p&gt;https://redis.io/docs/manual/client-side-caching/&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>31be310e12f5148c6efbd2ea28b28bc4</guid>
<title>Golang用proto文件同时生成gRPC和HTTP</title>
<link>https://toutiao.io/k/t6bq5xo</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;p&gt;&lt;strong&gt;&lt;span&gt;这里是Z哥的个人公众号&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;每周五11：45 按时送达&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;当然了，也会时不时加个餐～&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;我的第「224」篇原创敬上&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;大家好，我是Z哥。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;做技术的都知道，程序之间的通讯，常用的方式有两种，RPC 和 HTTP。普遍的共识是系统内部的各个子系统之间的通讯用 RPC，与外部系统之间的通讯用 HTTP。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了避免需要分别编写两套契约文件来生成两套 API（.proto 和 .api），如果能够根据同一份契约文件生成两套 API 的代码就太棒了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Z哥目前所在的公司，rpc 使用的框架是 gRPC，所以自然先想得是，是否能够根据一份 proto 文件，同时生成 gRPC 和 HTTP 的 stub 代码呢。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;网上很快就找到了一个符合要求的框架。相信不少 gopher 们应该也听说过或者正在使用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;46&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;https://github.com/grpc-ecosystem/grpc-gateway&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;框架的原理用一张图即可表达。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6785714285714286&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/oB5bd6W6hI3YVXf0Zbucyv7GAQTfuVjCp8knSDvjvU1dKFAWCicc48BNHNtLeH8NJJOIU30l0cibCsyXZ3ZWqgEA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1120&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;通过一份 proto 文件，在生成 gRPC 代码的同时生成一个基于 HTTP1.1 + JSON 的反向代理 gateway，如此一来，既可以通过 gRPC 的方式直接调用实际的 server ，也可以通过反向代理中转一次来访问 server。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;具体的使用方式看 github 上的官方教程即可，Z 哥和你主要聊一下其中可能会遇到的卡点。毕竟国内的网络情况你懂的，有些操作可能会遇到一些困难。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;/01  不会科学上网不要用buf/&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;教程里提供了两种来操作，一种是通过基础工具 protoc 来操作，另一种是通过一个基于 protoc 封装的工具 buf 来操作。protoc 可以基于 go mod 来安装，鉴于 go mod 还有国内的镜像站点可以解决访问的困难，建议不会科学上网的小伙伴通过 protoc 来操作，因为你没办法成功安装 buf。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;/02  手动下载 googleapis 的repo/&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;然后，当你定义 gateway 的时候，需要引入一些 google 的 packages，怎么办呢？直接去 github 上下载，具体地址是：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;40&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;https://github.com/googleapis/googleapis&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;如果可以的话，建议把整个仓库都下载下来，否则就单独下载教程里提到的4个文件即可。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;特别要注意的是，在 googleapis/google/目录下缺少的 protobuf 相关文件需要到下面的 repo 里去下载，并且放到 googleapis/google/目录下。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;73&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;https://github.com/protocolbuffers/protobuf/tree/main/src/google/protobuf&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;/03  protoc -I 指定查找目录/&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;官方教程里的 protoc -I . 只会查找当前命令执行所在目录的范围，所以如果你下载的 googlesapi 不存放在当前目录下，则需要增加额外信息指定一下查找目录。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;指定的方式是再增加一个 -I，命令如下（其中第二行就是新增的用于查找 google packages 的目录）：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;properties&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;protoc&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;-I ./ \&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    -I $GOPATH/src/googleapis\&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    --grpc-gateway_out ./gen/go \&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    --grpc-gateway_opt logtostderr=true \&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    --grpc-gateway_opt paths=source_relative \&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    --grpc-gateway_opt generate_unbound_methods=true \&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    your/service/v1/your_service.proto&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果还有其它目录需要查找，那么继续增加 -I 即可。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;好了需要注意的点就是以上3个，官方教程中提到的三个命令可以一起执行，这样便可同时生成 gRPC server、gateway 和 swagger.json ：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;properties&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;protoc&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;-I ./ \&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    -I $GOPATH/src/googleapis\&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    --go_out ./gen/go/ --go_opt paths=source_relative \&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    --go-grpc_out ./gen/go/ --go-grpc_opt paths=source_relative \&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    --grpc-gateway_out ./gen/go/  \&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    --grpc-gateway_opt logtostderr=true \&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    --grpc-gateway_opt paths=source_relative \&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    --grpc-gateway_opt generate_unbound_methods=true \&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    --openapiv2_out . --openapiv2_opt logtostderr=true \&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    your/service/v1/your_service.proto&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;关于一些gRPC-Gateway的其它用法可以参考：&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;46&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;https://grpc-ecosystem.github.io/grpc-gateway/&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;好了，这篇呢，Z哥和你分享了如何用一份 proto 文件同时生成 gRPC 和 HTTP 的 Stub 代码以及 Swagger 文档。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如此不但可以提高效率，还可以避免维护两份不同的契约文件所带来不一致风险，希望对你有所帮助。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推荐阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;原创不易，如果你觉得这篇文章还不错，就「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;点赞&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」或者「&lt;span&gt;&lt;strong&gt;在看&lt;/strong&gt;&lt;/span&gt;」一下吧，鼓励我的创作 ：）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也可以分享我的公众号名片给有需要的朋友们。&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU2NzEwMDc4OQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/oB5bd6W6hI1ENbrFbGjEucl1Az92hEuwmUSdaNXxibiaWuO9sLTPHokw00p8ZxAYdIJJJ7FXj77Ts0YoV5KwEKCA/0?wx_fmt=png&quot; data-nickname=&quot;跨界架构师&quot; data-alias=&quot;Zachary_ZF&quot; data-signature=&quot;坚持原创。专注大型互联网技术，涉猎产品、运营。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;如果你有关于软件架构、分布式系统、产品、运营的困惑&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以试试点击「&lt;strong&gt;阅读原文&lt;/strong&gt;」&lt;/span&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b6d238db2ffef7af11adecef42a899c2</guid>
<title>一种优雅的Golang的库插件注册加载机制</title>
<link>https://toutiao.io/k/sywhmm4</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;最近看到一个项目的插件加载机制，非常赞。&lt;/span&gt;&lt;span&gt;当然这里说的插件并不是指的golang&lt;/span&gt;&lt;span&gt;原生的可以在buildmode中加载指定so文件的那种加载机制。&lt;/span&gt;&lt;span&gt;而是软件设计上的「插件」。&lt;/span&gt;&lt;span&gt;如果你的软件是一个框架，或者一个平台性产品，想要提升扩展性，即可以让第三方进行第三方库开发，最终能像搭积木一样将这些库组装起来。&lt;/span&gt;&lt;span&gt;那么就可能需要这种库加载机制。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们的目标是什么？对第三方库进行某种库规范，只要按照这种库规范进行开发，这个库就可以被加载到框架中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们先定义一个插件的数据结构，这里肯定是需要使用接口来规范，这个可以根据你的项目自由发挥，比如我希望插件有一个Setup方法来在启动的时候加载即可。然后我就定义如下的Plugin结构。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; Plugin &lt;span&gt;interface&lt;/span&gt;{&lt;br/&gt;  Name() &lt;span&gt;string&lt;/span&gt;&lt;br/&gt;  Setup(config &lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;string&lt;/span&gt;) error&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而在框架启动的时候，我启动了一个如下的全局变量：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;var&lt;/span&gt; plugins &lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]Plugin&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;注册&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有人可能会问，这里有了加载函数setup，但是为什么没有注册逻辑呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答案是注册的逻辑放在库的init函数中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;即框架还提供了一个注册函数。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;// package plugin&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;Register(plugin Plugin)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个register就是实现了将第三方plugin放到plugins全局变量中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以第三方的plugin库大致实现如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;package MyPlugin&lt;br/&gt;&lt;br/&gt;&lt;span&gt;type&lt;/span&gt; MyPlugin struct{&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;func (m *MyPlugin) Setup(config map[string]string) error {&lt;br/&gt; // TODO&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;func (m *MyPlugin) Name() string {&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;&quot;myPlugin&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;func &lt;span&gt;&lt;span&gt;init&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt; plugin.Register(&amp;amp;MyPlugin)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样注册的逻辑就变成了，如果你要加载一个插件，那么你在main.go中直接以 _ import的形式引入即可。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;package main&lt;br/&gt;&lt;br/&gt;_ import &lt;span&gt;&quot;github.com/foo/myplugin&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;func &lt;span&gt;&lt;span&gt;main&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整体的感觉，这样子插件的注册就被“隐藏”到import中了。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;加载&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;注册的逻辑其实看起来也平平无奇，但是加载的逻辑就考验细节了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先插件的加载其实有两点需要考虑：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;配置指的是插件一定是有某种配置的，这些配置以配置文件yaml中plugins.myplugin的路径存在。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;plugins:&lt;br/&gt; myplugin:&lt;br/&gt;  foo: bar&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实我对这种实现持保留意见。配置文件以一个文件中配置项的形式存在，好像不如以配置文件的形式存在，即以config/plugins/myplugin.yaml 的文件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样不会出现一个大配置文件的问题。毕竟每个配置文件本身就是一门DSL语言。如果你将配置文件的逻辑变复杂，一定会有很多附带的bug是由于配置文件错误导致的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二个说的是依赖。插件A依赖于插件B，那么这里就有加载函数Setup的先后顺序了。这种先后顺序如果纯依赖用户的“经验”，将某个插件的Setup调用放在某个插件的Setup调用之前，是非常痛苦的。（虽然一定是有办法可以做到）。更好的办法是依赖于框架自身的加载机制来进行加载。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先我们在plugin包中定义一个接口：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; Depend &lt;span&gt;interface&lt;/span&gt;{&lt;br/&gt; DependOn() []&lt;span&gt;string&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果我的插件依赖一个名字为 “fooPlugin” 的插件，那么我的插件 MyPlugin就会实现这个接口。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;package MyPlugin&lt;br/&gt;&lt;br/&gt;&lt;span&gt;type&lt;/span&gt; MyPlugin struct{&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;func (m *MyPlugin) Setup(config map[string]string) error {&lt;br/&gt; // TODO&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;func (m *MyPlugin) Name() string {&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;&quot;myPlugin&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;func &lt;span&gt;&lt;span&gt;init&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt; plugin.Register(&amp;amp;MyPlugin)&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;func (m *MyPlugin) DependOn() []string {&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; []string{&lt;span&gt;&quot;fooPlugin&quot;&lt;/span&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在最终加载所有插件的时候，我们并不是简单地将所有插件调用Setup，而是使用一个channel，将所有插件放在channel中，然后一个个调用Setup，遇到有Depend其他插件的，且依赖插件还未被加载，则将当前插件放在队列最后（重新塞入channel）。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;var setupStatus map[string]bool&lt;br/&gt;&lt;br/&gt;// 获取所有注册插件&lt;br/&gt;func loadPlugins() (plugin chan Plugin, setupStatus map[string]bool) {&lt;br/&gt; // 这里定义一个长度为10的队列&lt;br/&gt; var sortPlugin = make(chan Plugin, 10)&lt;br/&gt; var setupStatus = make[string]bool&lt;br/&gt; &lt;br/&gt; // 所有的插件&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; name, plugin := range plugins {&lt;br/&gt;  sortPlugin &amp;lt;- plugin&lt;br/&gt;  setupStatus[name] = &lt;span&gt;false&lt;/span&gt;&lt;br/&gt; }&lt;br/&gt; &lt;br/&gt; &lt;span&gt;return&lt;/span&gt; sortPlugin, setupStatus&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// 加载所有插件&lt;br/&gt;func SetupPlugins(pluginChan chan Plugin, setupStatus map[string]bool) error {&lt;br/&gt; num := len(pluginChan)&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; num &amp;gt; 0 {&lt;br/&gt;  plugin &amp;lt;- pluginChan&lt;br/&gt;  &lt;br/&gt;  canSetup := &lt;span&gt;true&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; deps, ok := p.(Depend); ok {&lt;br/&gt;   depends := deps.DependOn()&lt;br/&gt;   &lt;span&gt;for&lt;/span&gt; _, dependName := range depends{&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; _, setuped := setupStatus[dependName]; !setup {&lt;br/&gt;      // 有未加载的插件&lt;br/&gt;      canSetup = &lt;span&gt;false&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;break&lt;/span&gt;&lt;br/&gt;    }&lt;br/&gt;   }&lt;br/&gt;  }&lt;br/&gt;  &lt;br/&gt;  // 如果这个插件能被setup&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; canSetup {&lt;br/&gt;   plugin.Setup(xxx)&lt;br/&gt;   setupStatus[p.Name()] = &lt;span&gt;true&lt;/span&gt;&lt;br/&gt;  } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;   // 如果插件不能被setup, 这个plugin就塞入到最后一个队列&lt;br/&gt;   pluginChan &amp;lt;- plugin&lt;br/&gt;  }&lt;br/&gt; }&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; nil&lt;br/&gt;} &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面这段代码最精妙的就是使用了一个有buffer的channel作为一个队列，消费队列一方SetupPlugins，除了消费队列，也有可能生产数据到队列，这样就保证了队列中所有plugin都是被按照标记的依赖被顺序加载的。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种插件的注册和加载机制是非常优雅的。注册方面，巧妙使用隐式import来做插件的注册。而加载方面，巧妙使用有buffer的channel作为加载队列。&lt;/p&gt; &lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>65fadeac3f79be26212bb9458eb084f5</guid>
<title>万字长文详解携程酒店订单缓存 &amp;amp; 存储系统升级实践</title>
<link>https://toutiao.io/k/h7w6rt4</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span title=&quot;&quot; opera-tn-ra-cell=&quot;_$.pages:0.layers:0.comps:0.title1&quot;&gt;&lt;p&gt;&lt;strong&gt;作者简介&lt;/strong&gt;&lt;/p&gt;&lt;/span&gt; &lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;荣&lt;/span&gt;&lt;span&gt;华&lt;/span&gt;&lt;span&gt;，携&lt;/span&gt;&lt;span&gt;程&lt;/span&gt;&lt;span&gt;高&lt;/span&gt;&lt;span&gt;级研发经理，专注于后&lt;/span&gt;&lt;span&gt;端技术项目研发&lt;/span&gt;&lt;span&gt;管理&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;军威，携程&lt;/span&gt;&lt;span&gt;软件技&lt;/span&gt;&lt;span&gt;术&lt;/span&gt;&lt;span&gt;专家，&lt;/span&gt;&lt;span&gt;负责分布式缓存系&lt;/span&gt;&lt;span&gt;统开发 &amp;amp; 存储架构迁移项目。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;金永，携程资深软件工程师，专注于实时计算，数据分析工程。&lt;/p&gt;&lt;p&gt;俊强，携程高级后端开发工程师，拥有丰富SQLServer使用经验&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;前&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;言&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;携程酒店订单系统的存储设计从1999年收录第一单以来，已经完成了从单一SQLServer数据库到多IDC容灾、完成分库分表等多个阶段，在见证了大量业务奇迹的同时，也开始逐渐暴露出老骥伏枥的心有余而力不足之态。基于更高稳定性与高效成本控制而设计的订单存储系统，已经是携程在疫情后恢复业务的必然诉求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前携程酒店订单系统正面临着在业务高增长的同时信息读写管理能力受制于数据库自身性能与稳定性的窘境。综合分析，一则为携程服役了十多年的SQLServer服务器集群的磁盘容量设计，已经跟不上时下新增订单量的空间诉求；二则在系统能力提升上造成了各大业务系统巨大的底层瓶颈与风险，同时又相比业界主流已基于MySQL架构设计存储系统而言，我们的订单存储系统仍基于SQLServer构建也整体推高了运营成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了支撑未来每日千万级订单的业务增长目标，同时满足高可用、高性能、高可扩展的高效成本控制期望，我们为酒店部门的订单DB所有访问开发并落地了一套稳定且可靠的统一中间件封装方案，对现状收敛并提供了全局统一的热点缓存系统，彻底解决了当下订单上层应用与数据库间直连的方案缺陷。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新系统由中间件服务统一实现了对上层应用提供数据链服务，并达成了为现有依赖订单库的应用以及其他直接或间接的数据应用无感的实现存储底层由SQLServer向MySQL技术架构迁移的目标。&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;一、架构综述&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过对现有系统瓶颈的分析，我们发现核心缺陷集中在订单数据缓存分散导致数据各端不一致，各订单应用则与数据库直连又造成可扩展性差。通过实践我们编写中间件抽象并统一了数据访问层，以及基于数据库部署架构镜像构建了订单缓存统一管理热点数据，解决了各端差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.41875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1eq3axNnoFTPLWbhRyhKWFib2NCR8EmEgl2aXJT8syHLiap3c5Mv4KeBefGF4XgpgE2uTXX7ibXytygg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;480&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图1.1  存储系统架构图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;二、应用场景&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;h2&gt;&lt;br/&gt;&lt;/h2&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;2.1  新单秒级各端同步&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从订单的提交到各端可见的速度为存储服务的核心指标之一，我们对数据链的主要环节进行了优化，覆盖了新单同步、消息实时推送、查询索引构建以及数据平台离线归档等主要环节，使大系统内数据到达速度在3秒以内，即用户刚下完单即可跳转我携列表可见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;当新用户创单时，同步服务作为数据链入口将用户订单数据通过中间件写入订单库，此时中间件同时完成订单缓存的构建；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;当订单完成入库行为和热点数据构建后抛订单消息，实时输出给各子系统；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;当新单入库完毕即刻构建订单明细信息的ES索引，为第三方提供检索支持；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最后数据平台T+1实施当日数据的归档供BI等各类离线业务使用；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5074626865671642&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1eq3axNnoFTPLWbhRyhKWFibFQa7bcFiczYgic1WILp1gzunRUt7ucZQDwapa7ybSiaj49ib3eClKvWibBg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;737&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2.1 数据链&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;2.2  自动发单与工作台&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对客、商、员工工作台三端的支持是订单存储系统的基本角色，图2.1数据链在新单提交后为自动发单与工作台起到的衔接作用功不可没。自动发单即在客人提交订单后，以最快的响应速度向商户发送订单明细信息进行核实货位、确认订单等流程。工作台则协助员工介入流程及时获取订单处理人工事件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6992574257425742&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1eq3axNnoFTPLWbhRyhKWFibTpVOw3BiceYiafhWN1VxRt8qoynXZRQXOJP0lNx335Z76GW1KJ1IYSeA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;808&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2.2 基于存储系统的发单与工作台关系（缩略细节）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;2.3  查询与数据分析&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于订单数据为核心的主要分为在线查询和数据分析两条业务线，以对详情查询为例，访问QPS终年保持在高位，每逢假期高峰则容易造成查询瓶颈，根因复盘后在本次架构升级中我们做了调整来优化相关场景的高可用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如此以上，我们将订单主库的访问保护在订单缓存、实时消息、Hive数仓三架马车之后，与业务尽最大可能的解耦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;三、系统升级实践&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在对携程核心存储系统进行更新换代的过程中，贯穿全程需要做到的是热迁移，并达成所有操作对数据链路上的各应用透明无损的目标。我们的设计通盘分析了集团数据链路的特性，由订单缓存系统提供数据库镜像降低应用与数据库的直连耦合，继而再通过中间件对应用透明掉数据源于SQLServer / MySQL的物理关系，提供底层热迁移的操作空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结合无损迁移的工艺设计，注重对每一笔数据库流量的可见及可控，支持全库、Shard级、表级、CRUD操作级的流量分配策略，提供了底层数据迁移足够的实施手段。数仓衔接设计则侧重于解决数据平台百亿级离线数据与双库在线期间的同步问题，以及解决全量接入MySQL期间产生的数据问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以下将分三个部分分享我们在这一过程中学到的经验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;3.1  分布式订单缓存&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;随着业务发展，用户数和访问量越来越大，订单系统应用和服务器的压力也与日俱增。在没有引入订单缓存之前，每个应用独立连接数据库，造成查询出来的数据无法在应用间共享，并且DB每秒查询量和连接数都有上限，而酒店核心交易链路基于DB存储，存在单点故障风险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过埋点数据分析，订单系统是典型的读多写少，为了共享热点查询数据以及降低DB负载，一个有效的办法就是引入缓存，如图3.1，用户的请求过来时，优先查询缓存，如果存在缓存数据，则直接返回结果；缓存没有命中，则去查询DB，根据配置策略校验DB结果数据，校验通过则将DB数据写入缓存留作后续查询使用，否则不写入缓存，最后返回DB查询结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.8543307086614174&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1eq3axNnoFTPLWbhRyhKWFibtyjHbTt862QGzs2nWVOsxn9CG24Byq8icJHRYgWK53yGsokstibAy91w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1016&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图3.1 订单缓存基本设计&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于引入新的缓存组件后的硬件开销，可通过收敛原来各应用分散的硬件资源来降低总成本，但还会因为中心化管理带来可用性挑战以及数据一致性等问题，故需要充分对现有系统进行容量评估、流量估算和缓存表价值分析&lt;/span&gt;&lt;span&gt;。只缓存访问量&lt;/span&gt;&lt;span&gt;高的热点数据表，通过恰当的缓存结构设计、数据压缩和缓存淘汰策略，最大程度提高缓存命中率，在缓存容量、硬件成本和可用性之间做好权衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;传统的缓存设计，是一条数据库表记录对应一条缓存数据。而在订单系统中，一个订单查询多表的场景很常见，如果采用传统设计，在一次用户查询中，Redis的访问次数是随着表数量增加的，这种设计网络IO较大并且耗时较长。在盘点表维度流量数据时，我们发现有些表经常一起查询，不到30%的表其查询流量超过90%，在业务上完全可以划分为同一个抽象领域模型，然后基于hash结构进行存储，如图3.2，以订单号作为key，领域名称作为field，领域数据作为value。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样无论是单表还是多表查询，每个订单都只需要访问一次Redis，即减少了key，又减少了多表查询次数，提升了性能。同时value基于protostuff进行压缩，还减少了Redis的存储空间，以及随之而来的网络流量开销。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7232227488151659&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1eq3axNnoFTPLWbhRyhKWFib2iaAhwk4kiaYXwf0scTGjOqGuPAPiaSyrvt8UdY92NSqXStxbS8Wo4Tlg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1055&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图3.2 基于domain的存储结构简述&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;3.2  无损迁移工艺&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如何做到无损热迁移是整个项目最具挑战性的地方。在工艺设计之前我们的前置工作首先完成了中间件的开发，通过中间件将数据库与业务层应用一分为二。其次抽&lt;/span&gt;&lt;span&gt;象Dao层实现领域化，&lt;/span&gt;&lt;span&gt;并由数据领域层向应用提供数据服务，领域之下适配SQLServer和MySQL两种数据库并统一封装&lt;/span&gt;&lt;span&gt;。以此为基础才能委以&lt;/span&gt;&lt;span&gt;下述工艺设计实施无损热迁移。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SQLServer和MySQL双库在线，实施双写，主写SQLServer，同步副写MySQL，如果SQLServer操作失败则整体失败，回滚双写事务。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SQLServer和MySQL之间增加一路同步Job，实时查询SQLServer最近时间窗口变更的数据进行一致性校验MySQL中的条目，差异点追齐，可以确保双写期间不可预期的两边不一致，特别是&lt;/span&gt;&lt;span&gt;还残有直连写&lt;/span&gt;&lt;span&gt;SQLServer应用的阶段特别有用。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;中间件设计有配置系统，支持任一主要查询维度可按配置精准的将数据源定向到SQLServer或MySQL，并可控制是否读取后加载到订单缓存。初期设定只加载SQLServer数据源，避免因双库间的数据不一致而造成缓存数据跳跃&lt;/span&gt;&lt;span&gt;。并在初期可设&lt;/span&gt;&lt;span&gt;置灰度，将小批量非核心表直连MySQL验证可靠性。后期数据一致性达成预期后，订单缓存也可自由按指定数据库加载缓存。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;解决了查询场景下的数据一致性问题后，流量策略支持图3.2中任一可调控维度进行数据库单写。实际项目中以表维度实施单写为主，当指定表被配置单写MySQL后，所有涉及该表的CRUD行为全部定向MySQL，包括缓存加载源。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最后通过中间件统一收口对外发送的订单消息，所有消息基于中间件的CUD操作发送与物理数据库无关，这样实现消息的数据源透明，且可联动以上所有工艺操作，数据链保持一致。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5613660618996799&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1eq3axNnoFTPLWbhRyhKWFibN5k3PiayFKDQ2ibKLzT88bBJAe97yXZWqKYK3T3QP8Aubq5exyO5Aa7g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;937&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图3.2  操作工艺简介&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;3.3  数仓衔接&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了方便理解生产数据到数据仓库ODS层数据的迁移，做到对下游透明，这里简单介绍一下常规数据仓库的分层体系。通常数据仓库主要分为五层：ODS(原始数据层)、DIM(维度)、EDW(企业数仓)、CDM(通用模型层)、ADM(应用模型层)，如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.8161350844277674&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1eq3axNnoFTPLWbhRyhKWFibYrPDEzd5PibMHQ9ELFNKSxJt9rTVtQMPFIeYhSso6s5Sticd3hrryVxg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;533&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图3.3.1  数据仓库分层结构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从图3.3.1上可以看出，数据仓库各层都依赖ODS层的数据，为了不影响数据平台所有应用，我们只需要将原来订单库ODS层数据源从SQLServer迁移到MySQL库即可。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从图上很直观的看出，迁移只需换个数据源不是很麻烦，但是为了保证数据质量，我们做了很多的前置工作，比如：DBA预先将生产数据同步到生产MySQL库、MySQL数据实时同步、生产两侧数据一致性校验、MySQL侧数据同步到ODS层、ODS层数据一致性校验及原有ODS层同步Job数据源切换等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中，生产两侧数据一致性校验和数据仓库ODS层数据一致性校验最为复杂，耗时也最长，要确保每张表、每个字段都要一致时才能切换数据源。但是，从实际操作过程中，却做不到完全一致。根据实际情况，适当处理时间类型、浮点值精度及小数位等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面介绍一下整体流程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，对于线上数据一致校验，我们开发了在线同步Job，将SQLServer的数据和MySQL数据进行比较，发现不一致时，就将MySQL的数据以SQLServer数据为基准更新掉，确保两边数据的一致性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，对于离线数据一致性校验，我们和数据仓库同事合作把MySQL侧数据同步到ODS层(以库名区分是SQLServer还是MySQL的表)，并且将定时跑的任务和SQLServer侧任务在时间上尽量一致。两侧数据都准备好后，我们开发了离线数据校验脚本生成器，根据数据仓库元数据，为每张表生成一个同步Job，将其部署到调度平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同步任务会依赖两侧ODS层同步数据，T+1数据同步完成后，执行一致性校验，将不一致的订单号记录到不一致明细表中，并统计不一致的数据量，将结果保存到统计表中。然后在自助报表平台制作一个报表，将每天统计的不一致的表及不一致量发送到邮箱，我们每天对不一致的表进行排查找出问题，调整比较策略，更新比较Job。大致流程如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.12753858651502845&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1eq3axNnoFTPLWbhRyhKWFibnW2BUwzV3I0ZCBS5ibc0SwP2JT8sDqHVmYdaAwbzNJZBia0xX9M6terw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1231&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图3.3.2  一致性校验整体流程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，随着线上和离线数据逐步趋于一致后，我们将原先SQLServer同步到ODS层Job的数据源切换到MySQL。这里可能有同学会有疑问：为什么不直接使用MySQL侧ODS层的表呢？&lt;/span&gt;&lt;span&gt;原因是，经过统计，依赖原先ODS层表的Job有上千个之多，如果让依赖Job切换到MySQL侧ODS表，修改工作量非常大，所以我们直接将原来的ODS层同步数据源直接切换成MySQL。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;实际操作中，切数据源并不能一次全部切完，我们分三批进行，先找十几个不那么重要的表作为第一批，切完后运行两周，并收集下游数据问题的反馈。&lt;/span&gt;&lt;span&gt;第一批表顺利切完两周后，我们没收到下游报数据问题，说明数据质量没问题。&lt;/span&gt;&lt;span&gt;然后再将剩余的几百张表按重要程度分两批继续切，直到切完。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;至此，我们完成了订单库从SQLServer迁移到MySQL在数据仓库层的迁移工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;四、核心问题精编&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上再周密的分析与设计，总是难免遇到执行过程中的各种挑战。我们总结了一些经典问题，虽然通过技术手段最终解决了这些大大小小问题并达成了目标，但是相信各位看官必定还有更好的解决方案，我们乐见共同学习与进步。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;br/&gt;&lt;/h2&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;4.1  SQLServer &amp;amp; MySQL 流量迁移如何细粒度监控&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;订单系统涉及到的应用和表数量众多，一个应用对应1到n张表，一张表又对应1到n个应用，是典型的多对多关系。如图4.1，对于上层应用来说，从一个SQLServer数据库，切换到另一个MySQL数据库，其基本流程参照操作工艺章节至少分为以下几步：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4984375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1eq3axNnoFTPLWbhRyhKWFibL4nWotqNn4Iy0CNPyvLFlePJm5O7NJkygLlyKAK1kXOKNgc6TvGDIA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图4.1 应用和数据库以及表的关系图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在生产环境更换数据库系统，就像在高速公路上不停车换轮胎，需要维持原有的车速不变，且对用户无感，否则后果不敢设想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在切换工艺中双写、单读和单写流程，环环相扣，步步相依，作为配套设计监控手段必须确认上一个操作达到预期效果才能进行下一个。如果跳过或者没有切换干净就贸然进行下一步，比如还没有双写完全一致，就开始读MySQL数据，可能造成查无此数据或者查到脏数据！那么就需要对每一个CRUD操作的读写进行监控，在迁移过程中做到360度无死角可视化流量细分控制，所见即所得。具体的做法如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;所有应用接入中间件，CRUD由中间件根据配置控制读写哪个DB的哪张表；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每一个读写操作的详细信息均写入ES，在Kibana和Grafana上可视化展示，并且通过DBTrace，可以知道每条SQL是在哪个DB上执行；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;按照应用级别逐步配置双写DB，通过同步Job实时比对、修复和记录两侧DB差异，再通过离线T+1校验双写中出现的最终不一致，如此往复直到双写一致；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;双写一致之后，就开始逐步将读SQLServer切换到读MySQL，通过ES监控和DBTrace确认完全没有SQLServer读，则表明单读MySQL完成，考虑到自增主键情况，我们采取按照表维度，按批次断写SQLServer，直至所有表都单写MySQL。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综上所述，基本方案为通过中间件为管道为所有接入的应用统一埋点，通过实时展示应用层的行为观察流量分布，并结合公司数据库侧Trace的可视化工具核实应用的流量切换行为与数据库实际QPS及负载浮动保持一致来监督迁移任务。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;br/&gt;&lt;/h2&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;4.2  如何解决双写期间DB一致性问题&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;  &lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;酒店的订单库有着二十年左右历史，经年累积，跨部门和酒店内部多个团队直接或间接依赖订单库SQLServer，要想切换到MySQL，就得先解决双写DB一致性问题，不一致主要体现在以下两点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于双写数据一致性的保证，我们基于同步Job将SQLServer数据为准线，根据最后更新时间，拉取两侧DB数据进行比对，如果不一致则修复MySQL的数据并将不一致信息写入ES，供后续排查根因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但也因为引入了额外的Job操作MySQL数据，带来了新的问题，那就是多表双写时，因为耗时翻倍，Job发现SQLServer有数据而MySQL没有，就立即修复了MySQL数据，造成双写失败。所以双写部分失败又加上了Failover机制，通过抛送消息，触发新一轮的比对和修复工作，直到两侧DB数据完全一致。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同步Job和Failover消息机制虽然可以让数据最终一致，但毕竟有秒级的间隔，两侧数据是不一致的，并且对于众多应用的各种场景，难免会有遗漏时单写SQLServer。对于这些漏写MySQL的地方，通过DBTrace是无法找到的，因为无法确定一个CUD操作只写入SQLServer，而未写入MySQL。那么有没有办法事前就能找出漏写MySQL的场景呢，确实被我们找出来一点，那就是更换数据库连接串，接入中间件的应用使用新连接串，然后找出所有使用旧连接串操作SQLServer的SQL，就能准确定位出漏写MySQL的流量了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最终，我们将双写DB不一致率从十万分之二逐步降低到了几乎为0，为什么是几乎呢，因为DB的一些特性差异问题，会天然的导致数据无法完全一致，这个在后续内容会有详细的论述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;4.3  引入订单缓存后导致的数据不同步问题处理&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;引入缓存之后，就涉及到对缓存进行写入或者更新，业界常见的做法分为以下几种：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;先写DB再写缓存&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;先写缓存再写DB&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;先删缓存再写DB&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;先写DB再删缓存&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在具体实施上还会进行双删缓存或者延迟双删缓存，此处不再比较各种做法的优劣。我们采用的是先写DB再删缓存方案，对于数据敏感表，会进行延迟双删，后台的同步Job定时比对、修复和记录数据库数据与Redis数据的差异，虽然设计上已经能保证最终一致性，但是在前期还是出现过大量的数据不一致。主要体现在以下几个方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;应用有场景未接入中间件，对DB进行CUD操作之后，漏删除缓存；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;写DB后删除缓存延迟导致读取到缓存脏数据，比如不可靠网络、GC等造成删缓存延迟；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;写DB后删除缓存失败导致读取到缓存脏数据，比如Redis主从切换期间，只能读不可写；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而为了解决缓存一致性问题，如图4.3，我们在原有的缓存和DB基础上，增加了乐观锁和CUD施工标记，来限制并发情况下同时存在加载数据到缓存相互覆盖的行为，以及对当前被查数据正在进行CUD操作的感知。在此两种场景未结束期间可以做到Query流量直连DB，通过基于乐观锁的最后写入者获胜机制解决竞争问题。最终我们的缓存不一致率从百万分之二控制到了千万分之三。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.86484375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1eq3axNnoFTPLWbhRyhKWFibPFI7gtia2I6B9CLelbVvbAo6DArPVHIys7wRB5sSib32GR49BF2F1ejw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图4.3 缓存一致性解决&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：图4.3当查询未命中缓存，或当前存在该数据的乐观锁或施工标记时，当次查询直连DB，直至相关事务完成后放开缓存数据自动加载功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;4.4  存量订单数据如何一次性校准&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;项目启动初期我们对MySQL进行了最近N年数据的一次性铺底，这就产生了在双写阶段无法校准的如下两个场景的数据：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对第一点，我们开发了MySQL数据专项清理Job，由于订单数据库是多Shard的，Job内部根据实际Shard数设置核心线程总量，每个线程分别负责对应Shard中的指定表进行清理，并行开多台服务器分发任务进行清理，通过速度控制既保证&lt;/span&gt;&lt;span&gt;了效率又&lt;/span&gt;&lt;span&gt;不影响生产上数据库的负载。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对第二点，在所有应用接中间件和所&lt;/span&gt;&lt;span&gt;有表实现双写后，通过调&lt;/span&gt;&lt;span&gt;整线上同步Job扫描的开始时间戳，对存量订单数据进行修复。修复时特别注意的是，扫描数据要按时间段分片处理，防止加载数据太多导致订单库服务器CPU太高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;4.5  一些数据库特性差异问题&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在如此庞大的系统下进行数据库热迁移，我们就必须了解不同数据库之间的差异与不同，做到知己知彼，对症下药。MySQL与SQLServer虽同为时下流行的关系型数据库，均支持标准化SQL查询，但在细枝末节上还是有些许差异。下面我们通过迁移中所面临的问题来具体分析一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自增键问题&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，为保证数据自增序号一致，不能让两个数据库各自去进行自增，否则一旦不一致就要面临修数据甚至更大风险。因此，在数据双写时，我们将SQLServer写入后生成的自增id，回写入MySQL自增列，在数据单写MySQL时直接使用MySQL生成自增id值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;日期精度问题&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，双写后为了保证数据一致性，要对两侧数据进行一致性校验，类型为Date、DateTime、Timestamp的字段，由于保存精度不一致，在对比时就需要做特殊处理，截取到秒进行比较。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;XML字段问题&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，SQLServer中支持XML数据类型，而MySQL 5.7不支持XML类型。在使用varchar(4000)代替后，遇到MySQL数据写入失败，但同步Job将SQLServer数据回写MySQL时又能正常写入的案例。经过分析，程序在写入时会将未压缩的XML字符串写入，SQLServer XML类型会自动压缩并存储，但MySQL并不会，导致长度超过4000的写入操作失败，SQLServer压缩后长度小于4000，又能够正常回写MySQL。为此我们提出应对措施，写入前压缩并校验长度，非重要字段截取后再存储，重要字段优化存储结构或更换字段类型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面列举一些迁移过程中常见的注意点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;table cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;SQLServer&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;对应MySQL&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;使用IDENTITY自增&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;使用AUTO_INCREMENT自增&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;MONEY、SMALL MONEY类型&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;DECIMAL(19,4)、DECIMAL(10,4)类型&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;UNIQUEIDENTIFIER类型&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;BINARY(16)类型&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;串联运算符+或||&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;CONCAT(&#x27;string1&#x27;, &#x27;string2&#x27;)函数&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;日期函数GETDATE()&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;NOW()、CURRENT_TIMESTAMP()&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;日期函数DATEADD()&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;ADDDATE()&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;Top子句&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;使用Limit&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;VARCHAR(n)可存储n/2个汉字&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;VARCHAR(n)可存储n个汉字&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;strong&gt;五、预警实践&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的预警实践并不局限于项目推进期间的监控诉求，如何在百亿级数据中周期扫描数据写入的异常，完成项目期间双写数据一致率的复核，如何实时监控与预警订单库每个分片上订单写入量的正常趋势，如何定期验收/核验整套系统的高可用性将在以下篇幅中描述。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;5.1  百亿级数据差异校验预警&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;   &lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;要满足订单数据SQLServer迁移到MySQL库，数据质量是迁移的必要条件，数据一致性达不到要求就无法透明迁移，所以设计合理的校验方案，关乎迁移的进度。针对数据校验，我们分为线上和线下两种：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;线上数据校验和预警&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：迁移期间我们通过同步Job，在计算出不一致数据后，将不一致的表及字段写入ElasticSearch，再用Kibana制作出不一致数据量及不一致表所占比例的监控看板，通过监控看板，我们就可以实时监控哪些表数据不一致量比较高，再根据表名称通过DBA工具排查出哪些应用对表进行了CUD操作，进一步定位漏接中间件的应用和代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实际操作中，我们确实找出了大量未接中间的应用并对其改造，随着接入中间件的应用越来越多，数据一致性逐渐提高，从监控看板上看到不一致的量也慢慢降低。但是一致性始终没有降低到零，原因是应用和同步Job并发导致的，这个也是最令人头疼的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;或许有同学会疑问，既然双写了为什么不停止掉同步Job呢？原因是双写以SQLServer为主写，以受中间件覆盖的CUD范围为基准，除了不能保证写入MySQL的数据百分百成功外也不能保证两库的数据量相等，所以需要一致性Job兜底。由于并发的存在，虽然做不到数据百分百一致，但是可以进一步降低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的做法是，一致性Job比较时设置一个5秒的稳定线（即距离当前时间5秒内的数据视为不稳定数据），订单数据时间戳在稳定线内的不进行比较，稳定线外的比较时，会再一次计算订单数据是否在稳定线内，如果确认全部数据在稳定线外，就进行比较操作，否则放弃本次比较，由下一次调度执行一致性校验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;离线数据校验和预警&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：订单库迁移涉及到几百张表，离线数据比较多，一年的订单相关数据就有上百亿了，对于离线数据校验比较有挑战。我们编写了数据一致性脚本生成器，为每张表生成一个比较脚本并部署到调度平台，比较脚本依赖上游SQLServer和MySQL两侧的同步Job，上游Job执行完毕后自动执行数据比较，将不一致数据的订单号写到明细表中，并根据明细表统计出不一致量，以日报的形式发出，每天对数据不一致比较高的表排查并解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常一是能修复对比脚本的瑕疵，二是发现离线数据问题，就这样反复摸排解决不一致问题。对于离线数据每张表每个字段的校验是非常复杂的，我们编写UDF函数进行比较，UDF函数功能也很简单，就是将每张表的非主键字段进行拼接生成一个新字段，两侧表进行全外连接，主键或者逻辑主键相等的记录，生成新字段也应该一样，只要不一样就视为不一致数据。这里要注意日期字段截取、数据精度及末尾为零的小数处理问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过三个多月的努力，我们排查出所有未接中间件的应用，并将其CUD操作全部接入中间件，开启双写后线上线下数据一致性逐步提高，达到了迁移数据的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;5.2 ALL Shard 实时订单总量监控  &lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个公司对于订单量的监控是不可或缺的，携程有一个统一预警平台Sitemon，它主要监控各类订单告警，包括酒店，机票，无线，高铁，度假。并能按照online/offline，国内/国际，或者支付方式单独搜索和展现，并对各类订单做了告警。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;订单数据从SQLServer迁移到MySQL期间，我们梳理出来依赖订单库的预警策略近两百个，负责监控的相关同事对SQL Server数据源的预警策略原样复制一份连接MySQL数据源。以MySQL为数据源监控告警都添加完成后，开启报警策略，一旦订单量异常报警，NOC会收到两条通知，一条来源于SQLServer数据告警，一条来源于MySQL告警，如果两边一致，说明灰度验证通过。否则，不通过，需排查MySQL 监控问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过一段时间的灰度验证，两边报警数据一致，随着SQLServer数据表下线（即单写MySQL数据），以SQLServer为数据源的预警策略也跟着及时下线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.3  “流浪地球”实操&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h2&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了做好系统安全保障工作，提高应对突发事件的能力，必要的演练压测等是少不了的。为此，我们制定了完备的应急预案并定期组织开展应急演练——流浪地球。演练项目包括核心/非核心应用熔断、DB熔断、Redis熔断、核心防火墙、交换机应急切换等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以缓存为例，为了保证缓存服务的高可用，我们在演练时会下线部分节点或机器甚至切断整个Redis服务，模拟缓存雪崩、缓存击穿等场景。按照计划，在熔断前我们会先切断应用的Redis访问，一步步降低Redis负载，然后熔断Redis，以此检验在无Redis的情况下各应用系统是否能够正常运转。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但在首次演练中，熔断Redis后应用报错量就急剧上升，果断停止演练回退并查找原因。经过分析，部分应用Redis操作未统一收口，不受中间件统一控制，Redis熔断后应用随即出现异常。针对这一情况，我们分析后一方面将报错应用的订单缓存访问收口接入中间件，另一方面强化了中间件与Redis的弱依赖关系，支持一键断开Redis操作，并完善了各项指标监控。最终在第二次演练中顺利完成Redis熔断，各业务系统在全流量打入MySQL的状态下的正常运行。在最近一次的流浪地球演练中，机房网络阻断、非核心应用阻断等一轮轮故障注入后，我们的系统更是取得了很好的预期效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就这样，在一次次的演练中，我们发现问题，总结经验，优化系统，完善应急预案，一步步提升系统应对突发故障的能力，保证业务的连续性以及数据的完整性。做好底层数据支撑，为整个酒店订单系统保驾护航。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;六、未来规划&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h1&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;  &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;6.1  订单缓存手工调控台&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然我们有完善的监控看板与预警系统，但对于像熔断演练、自动化故障演练、硬件故障和维护以及不可提前预知的问题，若刚好核心开发人员未能及时在现场响应操作，系统尚不能完全自主降级可能导致部分性能有所下降，比如响应耗时增加等。在将来计划增加手工调控看板，授权后可以让NOC或者TS进行针对性操作，比如Redis全部或者部分集群宕机，可以一键切割故障Redis分片，或者根据Redis已计划中的不可用时间段来提前设置切割时间，可以最大程度保证系统的可控性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;6.2  中间件自动降级&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然可以手工进行调控，那么我们也考虑后续可以通过一些核心指标的监控，比如Redis主从切换期间，正常情况是秒级，但是我们也出现过部分Redis 10秒以上不可写的情况，此时可以监控缓存与数据库不一致的脏数据量，也可以在Redis发生故障时通过监控响应耗时异常的阀值来应用一些策略，让中间件自动降级切割掉这些故障主机保证服务的基本稳定，然后在探测到集群指标稳定后再逐步尝试恢复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;6.3  中间件接&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;入Service Mesh&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当前订单团队内部是以JAR的方式使用中间件，由中间件来屏蔽数据库底层差异和操作Redis以实现更复杂的功能，天然具备接&lt;/span&gt;&lt;span&gt;入Service Mesh能力&lt;/span&gt;&lt;span&gt;，接入后底层升级更加快速和无感、调用更加轻量化、更好与框架进行网格化集成以及上云更加方便，能够更好的支撑携程的国际化战略目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;【推荐阅读】&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/kEeDgfCVf1e6A9vSrEj2brdswgl1bNg2ahAemw7dmvib0LzoF8VdGoLzGQPYypibSfMyTwibGibnvqZic7XJS0icpIHA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt; “携程技术”公众号&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;  分享，交流，成长&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>