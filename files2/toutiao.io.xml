<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>57d39ca628414539c593820d83acd902</guid>
<title>猫咪招财喜庆铃铛项圈，点击链接立即领取10元红包礼券！</title>
<link>https://toutiao.io/k/doqqn4l</link>
<content:encoded>&lt;div&gt;&lt;body data-spm=&quot;10720394/n&quot; id=&quot;readabilityBody&quot;&gt;
    
    
    
    
    
    
      
      
    
    
    
    
    
  &lt;/body&gt;
&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>57d39ca628414539c593820d83acd902</guid>
<title>猫咪招财喜庆铃铛项圈，点击链接立即领取10元红包礼券！</title>
<link>https://toutiao.io/k/kln056s</link>
<content:encoded>&lt;div&gt;&lt;body data-spm=&quot;10720394/n&quot; id=&quot;readabilityBody&quot;&gt;
    
    
    
    
    
    
      
      
    
    
    
    
    
  &lt;/body&gt;
&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>7741dff969960664aecfa95530f9c2fb</guid>
<title>[推荐] 非常哇塞的 ES读场景、写场景 性能优化指南！你值得拥有！</title>
<link>https://toutiao.io/k/5pjb28q</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;174&quot; data-backw=&quot;365&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4767123287671233&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/cvQbJDZsKLp6wejHtKTRbqqQyt0wMk9K1wNtuwRqQTJAPOJ1KiaqSeSRbIJRTicVicKpDKRndBodY2DBNN20tvWwA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;365&quot;/&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;原创：小姐姐味道（微信公众号ID：xjjdog），欢迎分享，转载请保留出处。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ES作为NoSQL数据库里非常重要的一员，使用越来越广泛。虽然它因为索引延迟的原因，数据在时效性上有一些缺陷，但其大容量、分布式的优秀设计，使得它在时效性要求并不是特别高的类实时搜索领域，能够大展身手。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据使用场景和用途，ES可以分为写入和读取两种典型的应用方式。比如ELKB，我们就需要额外关注它的&lt;code&gt;写优化&lt;/code&gt;；再比如从MySQL中同步数据到ES的宽表，我们就需要额外关注它的&lt;code&gt;读优化&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;废话不多说，我们直接show一下优化方法。如果你对ES的一些概念还不是很清楚，建议收藏本文慢慢看。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.写入优化&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;日志属于写多读少的业务场景，对写入速度要求很高。拿我们其中一个集群来说，单集群日志量达到百TB，每秒钟日志写入量达到10W条。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据写入，主要有三个动作：flush、refresh和merge。通过调整它们的行为，即可在性能和数据可靠性之间进行权衡。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.1 translog异步化&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，ES需要写一份translog，它类似于MySQL中的redolog，为的是避免在断电的时候数据丢失。ES默认每次请求都进行一次flush，但对于日志来说，这没有必要，可以将这个过程改为异步的，刷盘间隔为60秒。参数如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;curl-H&lt;span&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt;-XPUT&lt;span&gt;&#x27;http://localhost:9200/_all/_settings?preserve_existing=true&#x27;&lt;/span&gt;-d&lt;span&gt;&#x27;{&lt;br/&gt;  &quot;index.translog.durability&quot; : &quot;async&quot;,&lt;br/&gt;  &quot;index.translog.flush_threshold_size&quot; : &quot;512mb&quot;,&lt;br/&gt;  &quot;index.translog.sync_interval&quot; : &quot;60s&quot;&lt;br/&gt;}&#x27;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这可以说是最重要的一步优化了，对性能的影响最大，但在极端情况下会有丢失部分数据的可能。对于日志系统来说，是可以忍受的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.2 增加refresh间隔&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了写translog，ES还会将数据写入到一个缓冲区中。但是注意了！此时，缓冲区的内容是无法被搜索到的，它还需要写入到segment里面才可以，也就是刷新到lucence索引里面。这就是refresh动作，默认1秒。也就是你写入的数据，大概率1秒之后才会被搜索到。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这也是为什么ES不是实时搜索系统的原因，它从数据写入到数据读出，一般是有一个合并过程的，有一定的时间差。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过index.refresh_interval可以修改这个刷新间隔。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于日志系统来说，当然要把它调大一点啦。xjjdog这里调整到了120s，减少了这些落到segment的频率，I/O的压力自然会小，写入速度自然会快。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;curl-H&lt;span&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt;-XPUT&lt;span&gt;&#x27;http://localhost:9200/_all/_settings?preserve_existing=true&#x27;&lt;/span&gt;-d&lt;span&gt;&#x27;{&lt;br/&gt;  &quot;index.refresh_interval&quot; : &quot;120s&quot;&lt;br/&gt;}&#x27;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.3 merge&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;merge其实是lucene的机制，它主要是合并小的segment块，生成更大的segment，来提高检索的速度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;原因就是refresh过程会生成一大堆小segment文件，数据删除也会产生空间碎片。所以merge，通俗来讲就像是碎片整理进程。像postgresql等，也有vaccum进程在干同样的事。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;显而易见，这种整理操作，既浪费I/O，又浪费CPU。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你的系统merge非常频繁，那么调整merge的块大小和频率，是一个比较好的方法。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.读取优化&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.1 指定路由&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你向ES里写数据，那么它会为你设置一个离散的隐藏ID，落到哪个分片，是不一定的。如果你根据一个查询条件查询数据，你设置了6个shards的话，它要查询6次才行。如果能够在路由的时候就知道数据在哪个分片上，查询速度自然会上升，这就要求我们在构造数据的时候，人工指定路由规则。它的实际运行规则如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;shard = &lt;span&gt;hash&lt;/span&gt;(routing) % number_of_primary_shards&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如，一个查询会变成这样。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;GET my-index-000001/_search&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;query&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;terms&quot;&lt;/span&gt;: {&lt;br/&gt;      &lt;span&gt;&quot;_routing&quot;&lt;/span&gt;: [ &lt;span&gt;&quot;user1&quot;&lt;/span&gt; ] &lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，如果你的查询维度较多，又对数据的查询速度有非常高的有求，根据routing存放多份数据是一个比较好的选择。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2 rollover冷热分离&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;rollover根据索引大小，文档数或使用期限自动过渡到新索引。当rollover触发后，将创建新索引，写别名将更新为指向新索引，所有后续更新都将写入新索引，比如&lt;code&gt;indexname-000001.&lt;/code&gt;这种模式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从rollover这个名字可以看出来，它和Java的log日志有一定的相似之处，比如Log4j的RollingFileAppender。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当索引变的非常大，通常是几十GB，那它的查询效率将变的非常的低，索引重建的成本也较大。实际上，很多索引的数据在时间维度上有较为明显的规律，一些冷数据将很少被用到。这个时候，建立滚动索引将是一个比较好的办法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;滚动索引一般可以与索引模板结合使用，实现按一定条件自动创建索引，ES的官方文档有具体的_rollover建立方法。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3 使用BoolQuery替代TermQuery&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Bool查询现在包括四种子句，must、filter、should和must_not。Bool查询是true、false对比，而TermQuery是精确的字符串比对，所以如果需求相似，BoolQuery自然会快于TermQuery。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.4 将大查询拆成分段查询&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有些业务的查询比较复杂，我们不得不拼接一张非常大的宽表放在ES中，这有两个比较明显的问题。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;宽表的数据往往需要从其他数据源中回查拼接而成，数据更新时对源库或者ES本身都有较大的压力&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;业务的查询JSON需要书写的非常复杂，查询效率未知，一次查询锁定的内存过高，无法进行深入优化&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实，宽表不论在RDBMS中还是ES中，都会与复杂的查询语句有关，其锁定时间都较长，业务也不够灵活。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;应对这种场景的策略，通常将复杂的数据查询，转移到业务代码的拼接上来。比如，将一段非常冗长的单条查询，拆分成循环遍历的100条小查询。所有的数据库都对较小的查询请求有较好的响应，其整体性能整体上将优于复杂的单条查询。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这对我们的ES索引建模能力和编码能力提出了挑战。毕竟，在ES层面，互不相关的几个索引，将作为整体为其他服务提供所谓的数据中台接口。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5 增加第一次索引的速度&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很多业务的索引数据往往来自于MySQL等传统数据库，第一次索引往往是全量索引，后面才是增量索引。必要的时候，也会进行索引的重建，大量的数据灌入造成了ES的索引速度建立缓慢。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了缓解这种情况，建议在创建索引的时候，把副本数量设置成1，即没有从副本。等所有数据索引完毕，再将副本数量增加到正常水平。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样，数据能够快速索引，副本会在后台慢慢复制。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.通用优化&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，我们还可以针对ES做一些通用的优化。比如，使用监控接口或者trace工具，发现线程池有明显的瓶颈，则需要调整线程池的大小。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体的优化项如下。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.1 线程池优化&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;新版本对线程池的配置进行了优化，不需要配置复杂的search、bulk、index线程池。有需要配置下面几个就行了：thread_pool.get.size, thread_pool.write.size, thread_pool.listener.size, thread_pool.analyze.size。具体可观测_cat/thread_pool接口暴露的数据进行调整。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2 物理冷热分离&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的rollover接口，我们可以实现索引滚动。但是如何将冷数据存放在比较慢但是便宜的节点上？如何将某些索引移动过去？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ES支持给节点打标签，具体方式是在elasticsearch.yml文件中增加一些属性。比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;//热节点&lt;/span&gt;&lt;br/&gt;node.attr.temperature: hot &lt;br/&gt;&lt;span&gt;//冷节点&lt;/span&gt;&lt;br/&gt;node.attr.temperature: cold &lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;节点有了冷热属性后，接下来就是指定数据的冷热属性，来设置和调整数据分布。ES提供了index shard filtering功能来实现索引的迁移。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，可以对索引也设置冷热属性。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;PUT hot_data_index/_settings&lt;br/&gt;{&lt;br/&gt;    &lt;span&gt;&quot;index.routing.allocation.require.temperature&quot;&lt;/span&gt;: &lt;span&gt;&quot;hot&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这些索引将自动转移到冷设备上。我们可以写一些定时任务，通过_cat接口的数据，自动的完成这个转移过程。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2 多磁盘分散I/O&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实，可以通过配置多块磁盘的方式，来分散I/O的压力，但容易会造成数据热点集中在单块磁盘上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ES支持在一台机器上配置多块磁盘，所以在存储规模上有更大的伸缩性。在配置文件中，配置path.data属性，即可挂载多块磁盘。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;path.data : /data1, /data2, /data3&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;值得注意的是，如果你是在扩容，那么就需要配合reroute接口进行索引的重新分配。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.3 减少单条记录的大小&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Lucene的索引建立过程，非常耗费CPU，可以减少倒排索引的数量来减少CPU的损耗。第一个优化就是减少字段的数量；第二个优化就是减少索引字段的数量。具体的操作，是将不需要搜索的字段，index属性设置为not_analyzed或者no。至于_source和_all，在实际调试中效果不大，不再赘述。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;End&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ES的使用越来越广泛，从ELKB到APM，从NoSQL到搜索引擎，ES在企业中的地位也越来越重要。本文通过分析ES写入和读取场景的优化，力求从原理到实践层面，助你为ES加速。希望你在使用ES时能够更加得心应手。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通常，一个ES集群对配置的要求是较高的，尤其是APM等场景，甚至会占到PaaS平台的1/3资源甚至更多。ES提供了较多的配置选项，我们可以根据应用场景，调整ES的表现，使其更好的为我们服务。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;作者简介：&lt;strong&gt;小姐姐味道&lt;/strong&gt;  (xjjdog)，一个不允许程序员走弯路的公众号。聚焦基础架构和Linux。十年架构，日百亿流量，与你探讨高并发世界，给你不一样的味道。我的个人微信xjjdog0，欢迎添加好友，进一步交流。&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>22078a270e10d8be092b2d89a9842187</guid>
<title>[推荐] 2022新年伊始，送你百篇干货文章</title>
<link>https://toutiao.io/k/kchudkd</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;weui-dialog&quot;&gt;
      &lt;p class=&quot;weui-dialog__hd&quot;&gt;&lt;strong class=&quot;weui-dialog__title&quot;&gt;&quot;Top Stories&quot; is disabled&lt;/strong&gt;&lt;/p&gt;
      &lt;p class=&quot;weui-dialog__bd&quot;&gt;
        Enable &quot;Top Stories&quot; in &quot;Settings&quot; &amp;gt; &quot;General&quot; &amp;gt; &quot;Manage Discover&quot;      &lt;/p&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>ed3d9fa7bba99675b1043635ce0d67d2</guid>
<title>[推荐] 网络编程怎么做才算是优雅？</title>
<link>https://toutiao.io/k/zylzzpi</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;174&quot; data-backw=&quot;365&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4767123287671233&quot; data-type=&quot;gif&quot; data-w=&quot;365&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/cvQbJDZsKLp6wejHtKTRbqqQyt0wMk9K1wNtuwRqQTJAPOJ1KiaqSeSRbIJRTicVicKpDKRndBodY2DBNN20tvWwA/640?wx_fmt=gif&quot;/&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;原创：小姐姐味道（微信公众号ID：xjjdog），欢迎分享，转载请保留出处。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;据说，web2.0的魅力在于由静态资源变成交互性资源，web3.0的魅力在于其去中心化的资源，大家都可以参与其中得享时代的福利。但是，无论上层概念玩的再花哨，最下层的通信还是基于web1.0所形成的技术。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们的终极目标，其实就是打着去中心化的名义，做实际上的中心化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当流量增加到一定程度，网络编程会发生各种怪异的场景。下面将以十几个实际的案例，来说明xjjdog平常在工作中遇到的与网络相关的高频问题，希望能够助你一臂之力。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1. 大量客户端上线注意躲避&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;无论你的服务器能力多强，在大批量连接到来，进行业务服务的时候，都会产生瞬时的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;举个例子，如果你的MQTT服务器连接了几十万台设备。当你的MQTT服务器宕机重启的时候，就要接受几十万的并发，这几乎没有任何服务能够受得了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在xjjdog以往的经验中，因为服务端重启问题而造成的阻塞事故，数不胜数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个场景，其实和缓存的击穿概念非常的相似。当缓存中的热点数据集中失效的时候，请求就会全部击穿到数据库层面，造成问题。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4798807749627422&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1342&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/cvQbJDZsKLr2VuKPZxnONlCFrhAIg0Agc6t3LlnbibUrKk6UCDUnCzAfqntNh0mz60QcMVpNHaDPMFfyDp0aj5A/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如上图，解决缓存击穿问题就是给每个key加个失效时间的随机值，让它们不要在同一时间失效。类似的，我们可以在客户端重连服务端的时候，加上一个随机的时间。随机数是个好东西，它能让我们的海量连接在随机时间窗口内保持类线性的增长。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2. 多网卡队列&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在类似openstack等虚拟平台上假设的虚拟机，往往因为网卡能力不强而造成流量在达到一定程度之后，服务发生卡顿。这是因为单个cpu在处理中断时，产生了瓶颈。通过dstat或者iftop命令，可以看到当前的网络流量。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4381551362683438&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;954&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/cvQbJDZsKLraeg3qV1NqYqicNYpXMukH2HSibZc6bRbZyvIKzHKsczuuwpRuviamELTCT78oUQaUkmZzLnvPXricYQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如，Kafka新机器上线之后，会进行大规模的数据拷贝，这个时候如果你去ping相关的机器，会发现ping值变的非常大。同时，&lt;code&gt;Recv-Q&lt;/code&gt;和&lt;code&gt;Send-Q&lt;/code&gt;的值也会增大。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个时候，就需要开启网卡多队列模式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用&lt;code&gt;ethtool&lt;/code&gt;可以看到网卡的队列信息。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;ethtool -l eth0 | grep &lt;span&gt;&#x27;Combined&#x27;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;Combined: 1&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，通过下面的命令，可以增加网卡的队列。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;ethtool -L eth0 combined 2&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;建议同时开启中断平衡服务。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;systemctl start irqbalance&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3. 不定时的切断一下长连接&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果客户端和服务端连接上了，并一直保持连接不关闭对方，那么它就是一条长连接。长连接可以避免频繁的连接创建所产生的开销。从HTTP1到HTTP2再到HTTP3，一直在向减少连接，复用连接方面去努力。通常情况下，长连接是第一选择。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但有一些特殊情况，我们希望长连接并不要一直在那里保持着，需要给它增加TTL。这种情况通常发生在负载均衡场景里。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如LVS、HAProxy等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果后端有A、B、C三台机器，经过LVS负载之后，90条连接被分散到三台机器。但某个时刻，A宕机了，它所持有的30个连接就会被重新负载到B、C上，这时候它们都持有45条连接。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当A重启之后，它却再也拿不到新的连接。如果LVS运算一次再平衡的话，产生的影响也比较大。所以我们希望创建的长连接能够有一个生存时长的属性，在某个时间间隔内达到渐进式的再平衡。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4. k8s端口范围&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了k8s和别的程序不起冲突，默认端口的范围是 30000-32767。如果你在使用k8s平台，配置了nodeport但是无法访问到，要注意是不是设置的端口号太小了。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5. TIME_WAIT&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;TIME_WAIT是主动关闭连接的一方保持的状态，像nginx、爬虫服务器，经常发生大量处于time_wait状态的连接。TCP一般在主动关闭连接后，会等待2MS，然后彻底关闭连接。由于HTTP使用了TCP协议，所以在这些频繁开关连接的服务器上，就积压了非常多的TIME_WAIT状态连接。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;某些系统通过dmesg可以看到以下信息。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;__ratelimit: 2170 callbacks suppressed&lt;br/&gt;TCP: time &lt;span&gt;wait&lt;/span&gt; bucket table overflow&lt;br/&gt;TCP: time &lt;span&gt;wait&lt;/span&gt; bucket table overflow&lt;br/&gt;TCP: time &lt;span&gt;wait&lt;/span&gt; bucket table overflow&lt;br/&gt;TCP: time &lt;span&gt;wait&lt;/span&gt; bucket table overflow&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;sysctl命令可以设置这些参数，如果想要重启生效的话，加入/etc/sysctl.conf文件中。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;# 修改阈值&lt;/span&gt;&lt;br/&gt;net.ipv4.tcp_max_tw_buckets = 50000 &lt;br/&gt;&lt;span&gt;# 表示开启TCP连接中TIME-WAIT sockets的快速回收&lt;/span&gt;&lt;br/&gt;net.ipv4.tcp_tw_reuse = 1&lt;br/&gt;&lt;span&gt;#启用timewait 快速回收。这个一定要开启，默认是关闭的。&lt;/span&gt;&lt;br/&gt;net.ipv4.tcp_tw_recycle= 1   &lt;br/&gt;&lt;span&gt;# 修改系統默认的TIMEOUT时间,默认是60s&lt;/span&gt;&lt;br/&gt;net.ipv4.tcp_fin_timeout = 10&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;测试参数的话，可以使用 sysctl -w net.ipv4.tcp_tw_reuse = 1 这样的命令。如果是写入进文件的，则使用sysctl -p生效。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;6. CLOSE_WAIT&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CLOSE_WAIT一般是由于对端主动关闭，而我方没有正确处理的原因引起的。说白了，就是程序写的有问题，属于危害比较大的一种。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家都知道TCP的连接是三次握手四次挥手，这是由于TCP连接允许单向关闭。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.0374707259953162&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;427&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/cvQbJDZsKLraeg3qV1NqYqicNYpXMukH2Hic8Rj6p5VFicDO6n01u1CNMWO3db3SdCibKMqOz8u3yv9wOicoWyS5sPQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如图，当一个连接发起主动关闭之后，它将进入fin_wait_1状态。同时，收到fin报文的被动关闭方，进入close_wait状态，然后回复ack后，主动关闭方进入fin_wait_2状态。这就是单向的关闭。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时，如果被动关闭方因为某些原因，没有发送fin报文给主动关闭方，那么它就会一直处于close_wait状态。比如，收到了EOF但没有发起close操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;显然，这多数是一种编程bug，只能通过代码review来解决。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;7. 一个进程能够打开的网络连接&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4233576642335766&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;685&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/cvQbJDZsKLraeg3qV1NqYqicNYpXMukH2hIibPMZfiaXutYUhHiaqpYdg2bKY24g6Nj96l0KpdV7JUC1041pEO0Aiag/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Linux即使放开一个端口，能够接受的连接也是海量的。这些连接的上限，受到单进程文件句柄数量和操作系统文件句柄数量的限制，也就是ulimit和file-max。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了能够将参数修改持久化，我们倾向于将改动写入到文件里。进程的文件句柄限制，可以放在&lt;code&gt;/etc/security/limits.conf&lt;/code&gt;中，它的上限受到&lt;code&gt;fs.nr_open&lt;/code&gt;的制约；操作系统的文件句柄限制，可以放到&lt;code&gt;/etc/sysctl.conf&lt;/code&gt;文件中。最后，别忘了在&lt;code&gt;/proc/$id/limits&lt;/code&gt;文件中，确认修改是否对进程生效了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;/etc/security/limits.conf配置案例：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;root soft nofile 1000000&lt;br/&gt;root hard nofile 1000000&lt;br/&gt;* soft nofile 1000000&lt;br/&gt;* hard nofile 1000000&lt;br/&gt;es  -  nofile  65535&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;8. SO_KEEPALIVE&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果将这个Socket选项打开，客户端Socket每隔段的时间（大约两个小时）就会利用空闲的连接向服务器发送一个数据包。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个数据包并没有其它的作用，只是为了检测一下服务器是否仍处于活动状态。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果服务器未响应这个数据包，在大约11分钟后，客户端Socket再发送一个数据包，如果在12分钟内，服务器还没响应，那么客户端Socket将关闭。如果将Socket选项关闭，客户端Socket在服务器无效的情况下可能会长时间不会关闭。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;9. SO_REUSEADDR是为了解决什么问题&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当我们在网络开发时，时常会碰到&lt;code&gt;address already in use&lt;/code&gt;的异常，这是由于关闭应用程序时，还有对应端口的网络连接处于&lt;code&gt;TIME_WAIT&lt;/code&gt;状态而造成的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;TIME_WAIT状态通常会持续一段时间（2ML），设置SO_REUSEADDR可以支持快速端口复用，支持应用的快速重启。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;10. 健康检查采用应用心跳&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;tcp自身的keepalived机制非常的鸡肋，它静悄悄的在底层运行，无法产生应用层的语义。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我们的想象里，连接就应该是一条线。但其实，它只是2个点，而且每次走的路径都可能不一样。一个点，需要在发出心跳包然后收到回复之后，才能知道对方是否存活。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;tcp自带的心跳机制，仅仅能知道对方是否存活，对于服务是否可用，健康状况这些东西一概不知，而且超时配置常常与超时重传机制相冲突。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，有确切含义的应用层心跳是必要的。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;11. SO_LINGER&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个Socket选项可以影响close方法的行为。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在默认情况下，当调用close方法后，将立即返回；如果这时仍然有未被送出的数据包，那么这些数据包将被丢弃。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果将linger参数设为一个正整数n时（n的值最大是65，535），在调用close方法后，将最多被阻塞n秒。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这n秒内，系统将尽量将未送出的数据包发送出去；如果超过了n秒，如果还有未发送的数据包，这些数据包将全部被丢弃；而close方法会立即返回。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果将linger设为0，和关闭SO_LINGER选项的作用是一样的。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;12. SO_TIMEOUT&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以通过这个选项来设置读取数据超时。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当输入流的read方法被阻塞时，如果设置timeout（timeout的单位是毫秒），那么系统在等待了timeout毫秒后会抛出一个InterruptedIOException例外。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在抛出例外后，输入流并未关闭，你可以继续通过read方法读取数据。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;13. SO_SNDBUF，SO_RCVBUF&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在默认情况下，输出流的发送缓冲区是8096个字节（8K）。这个值是Java所建议的输出缓冲区的大小。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果这个默认值不能满足要求，可以用setSendBufferSize方法来重新设置缓冲区的大小。但最好不要将输出缓冲区设得太小，否则会导致传输数据过于频繁，从而降低网络传输的效率。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;14. SO_OOBINLINE&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果这个Socket选项打开，可以通过Socket类的sendUrgentData方法向服务器发送一个单字节的数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个单字节数据并不经过输出缓冲区，而是立即发出。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然在客户端并不是使用OutputStream向服务器发送数据，但在服务端程序中这个单字节的数据是和其它的普通数据混在一起的。因此，在服务端程序中并不知道由客户端发过来的数据是由OutputStream还是由sendUrgentData发过来的。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;End&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我非常惊讶的发现，现在有些网络环境，依然还是千兆网卡，包括一些比较专业的测试环境。当在这些环境上进行实际的压测时，当流量突破了网卡的限制，应用响应将会变的异常缓慢。计算机系统是一个整体，CPU、内存、网络、IO，任何一环出现瓶颈，都会造成问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在分布式系统中，网络是一个非常重要的因素。但由于它相对来说比较底层，所以大多数开发对其了解较少。加上现在各种云原生组件的流行，接触这些底层设施的机会就越来越少。但如果系统真的发生了问题，在排除掉其他最可能出问题的组件后，千万别忘了--&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有网络这一摊子等着你。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;作者简介：&lt;strong&gt;小姐姐味道&lt;/strong&gt;  (xjjdog)，一个不允许程序员走弯路的公众号。聚焦基础架构和Linux。十年架构，日百亿流量，与你探讨高并发世界，给你不一样的味道。我的个人微信xjjdog0，欢迎添加好友，进一步交流。&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>