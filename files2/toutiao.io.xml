<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>f8028b4fcba6fdffdceecadd411cf538</guid>
<title>欢迎加入读者圈子，一起交流！</title>
<link>https://toutiao.io/k/mv211dm</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;p&gt;&lt;span&gt;&lt;strong&gt;欢迎加入读者圈子，一起交流！&lt;br/&gt;↓↓↓&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;307&quot; data-ratio=&quot;0.5493333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/AjN1jquNavich3VaNkKeiaAwUhz7TQbQmic4fFsr58X9PAYleYzxqc1K1vZjeBoZDMUsmia0xH67EQYINGRvNOtLmA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;圈子剧透&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、600+圈子成员，以中高级程序员为主，更有架构师、CTO坐镇交流；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、1000+优质主题，数十G独家资料，每日分享，精挑细选；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、全年52期专属邮件周报，让你轻松掌握业界资讯、技术干货，提升认知水平；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、全年52本好书共读，让你花最少的时间，获取更好的知识；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;心动不如行动，赶快加入吧！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>cb624d60a8edc9041b7f01f90f7d8e33</guid>
<title>阿里10年沉淀｜那些技术实战中的架构设计方法</title>
<link>https://toutiao.io/k/e9vlh55</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                  &lt;strong class=&quot;profile_nickname&quot;&gt;阿里开发者&lt;/strong&gt;
                  &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;ali_tech&lt;/span&gt;
                  &lt;/p&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;阿里巴巴官方技术号，关于阿里的技术创新均呈现于此。&lt;/span&gt;
                  &lt;/p&gt;
                &lt;/div&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a10f85b611244f1535306ebd3010be46</guid>
<title>自动发现 Go 项目 Bug 的神器</title>
<link>https://toutiao.io/k/tkj5eox</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Go1.18 新特性中有一&lt;/span&gt;&lt;span&gt;个神器：&lt;/span&gt;&lt;span&gt;Fuzzing，对于发现 Go 项目中的 Bug 很有帮助。&lt;/span&gt;&lt;span&gt;本文通过一个具体的例子来介绍它的基本使用，希望你能掌握并应用。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以下这个函数，你能找到几个 bug？它的功能看起来很简单——对于一个字符串，用一个新的用户定义字符覆盖它的第一个字符 &lt;code&gt;n&lt;/code&gt; 次。例如，如果我们运行&lt;code&gt;OverwriteString(&quot;Hello, World!&quot;, &quot;A&quot;, 5)&lt;/code&gt;，正确的输出是：&lt;code&gt;&quot;AAAAA, World!&quot;&lt;/code&gt;。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;// overwrite_string.go&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// OverwriteString overwrites the first &#x27;n&#x27; characters in a string with&lt;/span&gt;&lt;br/&gt;&lt;span&gt;// the rune &#x27;value&#x27;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;OverwriteString&lt;/span&gt;&lt;span&gt;(str &lt;span&gt;string&lt;/span&gt;, value &lt;span&gt;rune&lt;/span&gt;, n &lt;span&gt;int&lt;/span&gt;)&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;// If asked to overwrite more than the entire string then no need to loop,&lt;/span&gt;&lt;br/&gt; &lt;span&gt;// just return string length * the rune&lt;/span&gt;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; n &amp;gt; &lt;span&gt;len&lt;/span&gt;(str) {&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; strings.Repeat(&lt;span&gt;string&lt;/span&gt;(value), &lt;span&gt;len&lt;/span&gt;(str))&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt; result := []&lt;span&gt;rune&lt;/span&gt;(str)&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt;= n; i++ {&lt;br/&gt;  result[i] = value&lt;br/&gt; }&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;(result)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在为代码提供一次快速可视化所需的时间内，Go 的新模糊测试工具可以通过该函数运行超过 500 万个程序生成的输入，并在这种情况下在&lt;em&gt;一秒钟&lt;/em&gt;内找到导致越界数组访问的输入。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如，使用这组参数运行函数：&lt;code&gt;OverwriteString(&quot;0000&quot;, rune(&#x27;A&#x27;), 4)&lt;/code&gt;会导致 panic：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;--- FAIL: FuzzBasicOverwriteString (0.05s)&lt;br/&gt;    --- FAIL: FuzzBasicOverwriteString (0.00s)&lt;br/&gt;        testing.go:1349: panic: runtime error: index out of range [4] with length 4&lt;br/&gt;            goroutine 96 [running]:&lt;br/&gt;            runtime/debug.Stack()&lt;br/&gt;             /home/everest/sdk/gotip/src/runtime/debug/stack.go:24 +0x90&lt;br/&gt;            testing.tRunner.func1()&lt;br/&gt;           ...&amp;lt;snip&amp;gt; &lt;br/&gt;    &lt;br/&gt;    Failing input written to testdata/fuzz/FuzzBasicOverwriteString/2bac7bdf139ad0b2de37275db2a606ecb335bd344500173b451e9dfc3658c12f&lt;br/&gt;    To re-run:&lt;br/&gt;    go &lt;span&gt;test&lt;/span&gt; -run=FuzzBasicOverwriteString/2bac7bdf139ad0b2de37275db2a606ecb335bd344500173b451e9dfc3658c12f&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;模糊测试（Fuzzing）是一种强大的测试技术，它非常擅长发现开发人员通常会遗漏的 Bug 和漏洞，并且在发现开源 Go 代码中的数百个关键错误方面有着良好的记录。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;将我们的小示例问题扩展到关键应用程序中的千行代码路径，通过数十亿输入的模糊器只需几分钟即可发现细微的错误，否则这些错误在生产中需要数天才能解决。下面首先介绍如何使用 Go 的最新测试工具并尽快开始发现自己的错误。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;入门&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是 Go 1.18 的新特性：模糊测试功能，因此在开始之前，请确保您&lt;code&gt;$ go version&lt;/code&gt;的版本至少为 1.18。如果你的版本低于 1.18，请升级。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果想跟着代码做，可以在 github.com/fuzzbuzz/go-fuzzing-tutorial 找到这篇文章的代码。对于本教程的其余部分，所有命令都是从&lt;code&gt;introduction&lt;/code&gt;目录中运行的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是模糊测试的基本写法：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;// overwrite_string_test.go&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;FuzzBasicOverwriteString&lt;/span&gt;&lt;span&gt;(f *testing.F)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; f.Fuzz(&lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;(t *testing.T, str &lt;span&gt;string&lt;/span&gt;, value &lt;span&gt;rune&lt;/span&gt;, n &lt;span&gt;int&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;  OverwriteString(str, value, n)&lt;br/&gt; })&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;与期望来自固定输入的特定行为的单元测试相反，模糊测试通过其测试的功能运行数千个程序生成的输入，而无需开发人员手动提供输入。在这种特定情况下，我们希望将测试的函数传递给&lt;code&gt;f.Fuzz&lt;/code&gt;，因此模糊器将生成一个新&lt;code&gt;string&lt;/code&gt;、&lt;code&gt;rune&lt;/code&gt; 和 &lt;code&gt;int&lt;/code&gt; 来填充每次测试迭代的参数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;默认情况下，模糊测试将检测崩溃、挂起和极端内存使用情况，因此即使不编写任何断言，我们也已经为我们的函数构建了一个有用的健壮性测试。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要运行此测试，执行如下命令：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;go test -fuzz FuzzBasicOverwriteString&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在大约一秒钟内，你应该会看到带有类似于以下错误信息的测试退出：（你的运行结果不会完全一样）&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;--- FAIL: FuzzBasicOverwriteString (0.05s)&lt;br/&gt;    --- FAIL: FuzzBasicOverwriteString (0.00s)&lt;br/&gt;        testing.go:1349: panic: runtime error: index out of range [4] with length 4&lt;br/&gt;...SNIP&lt;br/&gt;    Failing input written to testdata/fuzz/FuzzBasicOverwriteString/2bac7bdf139ad0b2de37275db2a606ecb335bd344500173b451e9dfc3658c12f&lt;br/&gt;    To re-run:&lt;br/&gt;    go &lt;span&gt;test&lt;/span&gt; -run=FuzzBasicOverwriteString/2bac7bdf139ad0b2de37275db2a606ecb335bd344500173b451e9dfc3658c12f&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;模糊器在 &lt;code&gt;testdata/fuzz/FuzzBasicOverwriteString&lt;/code&gt;目录内存放导致问题的特定输入的文件。打开这个文件，你可以看到导致我们的函数 panic 的实际值：（你的值可能不一样）&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;go &lt;span&gt;test&lt;/span&gt; fuzz v1&lt;br/&gt;string(&lt;span&gt;&quot;00&quot;&lt;/span&gt;)&lt;br/&gt;rune(&lt;span&gt;&#x27;A&#x27;&lt;/span&gt;)&lt;br/&gt;int(2)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在我们已经发现了一个错误，可以进入我们的代码修复问题。查看实际导致 panic ( &lt;code&gt;overwrite_string.go:16&lt;/code&gt;) 的代码行，该代码似乎试图访问长度为 4 的字符串的索引 4，这导致了数组索引越界错误。你可以通过更改检查 &lt;code&gt;if n &amp;gt; len(str)&lt;/code&gt; 以测试大于或等于来修复错误：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;// overwrite_string.go&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// OverwriteString overwrites the first &#x27;n&#x27; characters in a string with&lt;/span&gt;&lt;br/&gt;&lt;span&gt;// the rune &#x27;value&#x27;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;OverwriteString&lt;/span&gt;&lt;span&gt;(str &lt;span&gt;string&lt;/span&gt;, value &lt;span&gt;rune&lt;/span&gt;, n &lt;span&gt;int&lt;/span&gt;)&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;// If asked to overwrite more than the entire string then no need to loop,&lt;/span&gt;&lt;br/&gt; &lt;span&gt;// just return string length * the rune&lt;/span&gt;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; n &amp;gt;= &lt;span&gt;len&lt;/span&gt;(str) {&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; strings.Repeat(&lt;span&gt;string&lt;/span&gt;(value), &lt;span&gt;len&lt;/span&gt;(str))&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt; result := []&lt;span&gt;rune&lt;/span&gt;(str)&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt;= n; i++ {&lt;br/&gt;  result[i] = value&lt;br/&gt; }&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;(result)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这将确保仅当 &lt;code&gt;n&lt;/code&gt; 至少小于字符串长度 1 时才输入循环。我们也可以修复 for 循环的边界，但这隐藏了一个更有趣的错误，所以现在我们忽略它。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过使用输出中提供的 fuzzer 命令重新运行崩溃的测试用例，确认修复了 Bug：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ go &lt;span&gt;test&lt;/span&gt; -v -count=1 -run=FuzzBasicOverwriteString/2bac7bdf139ad0b2de37275db2a606ecb335bd344500173b451e9dfc3658c12f&lt;br/&gt;&lt;br/&gt;=== RUN   FuzzBasicOverwriteString&lt;br/&gt;=== RUN   FuzzBasicOverwriteString/2bac7bdf139ad0b2de37275db2a606ecb335bd344500173b451e9dfc3658c12f&lt;br/&gt;--- PASS: FuzzBasicOverwriteString (0.00s)&lt;br/&gt;    --- PASS: FuzzBasicOverwriteString/2bac7bdf139ad0b2de37275db2a606ecb335bd344500173b451e9dfc3658c12f (0.00s)&lt;br/&gt;PASS&lt;br/&gt;ok   github.com/fuzzbuzz/go-fuzzing-tutorial/introduction 0.001s&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;任何时候执行 &lt;code&gt;go test&lt;/code&gt;（这些输入统称为“种子”），Go 的 fuzzer 将自动运行 &lt;code&gt;testdata&lt;/code&gt; 目录中的每个输入作为单元测试。将目录 testdata 提交 到版本控制会将此输入保存为永久回归测试，以确保永远不会重新引入该错误。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;一次意外之旅&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在，我完全承认，在我写这篇文章的时候，我希望这个改变能够满足基本的模糊测试，但是如果你在这个改变之后重新运行模糊器，你会注意到一个全新的错误出现：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ go &lt;span&gt;test&lt;/span&gt; -fuzz FuzzBasicOverwriteString&lt;br/&gt;fuzz: elapsed: 0s, gathering baseline coverage: 0/17 completed&lt;br/&gt;fuzz: elapsed: 0s, gathering baseline coverage: 17/17 completed, now fuzzing with 8 workers&lt;br/&gt;fuzz: minimizing 177-byte failing input file&lt;br/&gt;fuzz: elapsed: 0s, minimizing&lt;br/&gt;--- FAIL: FuzzBasicOverwriteString (0.17s)&lt;br/&gt;    --- FAIL: FuzzBasicOverwriteString (0.00s)&lt;br/&gt;        testing.go:1349: panic: runtime error: index out of range [60] with length 60&lt;br/&gt;            goroutine 2911 [running]:&lt;br/&gt;            runtime/debug.Stack()&lt;br/&gt;             /home/everest/sdk/gotip/src/runtime/debug/stack.go:24 +0x90&lt;br/&gt;            testing.tRunner.func1()&lt;br/&gt;             /home/everest/sdk/gotip/src/testing/testing.go:1349 +0x1f2&lt;br/&gt;            panic({0x5b3700, 0xc00289c798})&lt;br/&gt;             /home/everest/sdk/gotip/src/runtime/panic.go:838 +0x207&lt;br/&gt;            github.com/fuzzbuzz/go-fuzzing-tutorial/introduction.OverwriteString({0xc00288ef00, 0x3d}, 0x83, 0x3c)&lt;br/&gt;             /home/everest/src/fuzzbuzz/go-fuzzing-tutorial/introduction/overwrite_string.go:20 +0x270&lt;br/&gt;            github.com/fuzzbuzz/go-fuzzing-tutorial/introduction.FuzzBasicOverwriteString.func1(0x5?, {0xc00288ef00?, 0x0?}, 0x0?, 0x0?)&lt;br/&gt;             /home/everest/src/fuzzbuzz/go-fuzzing-tutorial/introduction/overwrite_string_test.go:24 +0x38&lt;br/&gt;            reflect.Value.call({0x598d60?, 0x5cfb58?, 0x13?}, {0x5c179f, 0x4}, {0xc0028c2de0, 0x4, 0x4?})&lt;br/&gt;             /home/everest/sdk/gotip/src/reflect/value.go:556 +0x845&lt;br/&gt;            reflect.Value.Call({0x598d60?, 0x5cfb58?, 0x514?}, {0xc0028c2de0, 0x4, 0x4})&lt;br/&gt;             /home/everest/sdk/gotip/src/reflect/value.go:339 +0xbf&lt;br/&gt;            testing.(*F).Fuzz.func1.1(0x0?)&lt;br/&gt;             /home/everest/sdk/gotip/src/testing/fuzz.go:337 +0x231&lt;br/&gt;            testing.tRunner(0xc0028e7380, 0xc0028ec5a0)&lt;br/&gt;             /home/everest/sdk/gotip/src/testing/testing.go:1439 +0x102&lt;br/&gt;            created by testing.(*F).Fuzz.func1&lt;br/&gt;             /home/everest/sdk/gotip/src/testing/fuzz.go:324 +0x5b8&lt;br/&gt;            &lt;br/&gt;    &lt;br/&gt;    Failing input written to testdata/fuzz/FuzzBasicOverwriteString/2ee896e38866e089811eeece13f9919795072e6cc05ee9f782d68d1663d204c7&lt;br/&gt;    To re-run:&lt;br/&gt;    go &lt;span&gt;test&lt;/span&gt; -run=FuzzBasicOverwriteString/2ee896e38866e089811eeece13f9919795072e6cc05ee9f782d68d1663d204c7&lt;br/&gt;FAIL&lt;br/&gt;&lt;span&gt;exit&lt;/span&gt; status 1&lt;br/&gt;FAIL github.com/fuzzbuzz/go-fuzzing-tutorial/introduction 0.174s&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你看到的情况下，模糊器生成的实际输入可能看起来不同，以下是我看到的测试用例：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;go&lt;/span&gt; test fuzz v1&lt;br/&gt;&lt;span&gt;string&lt;/span&gt;(&lt;span&gt;&quot;000000000000000000000000000000Ö00000000000000000000000000000&quot;&lt;/span&gt;)&lt;br/&gt;&lt;span&gt;rune&lt;/span&gt;(&lt;span&gt;&#x27;\u0083&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;span&gt;int&lt;/span&gt;(&lt;span&gt;60&lt;/span&gt;)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;乍一看，这个错误看起来几乎与你刚刚修复的错误一模一样。尝试访问 60 个字符长字符串的索引 60 应该是不可能的，因为该函数将在初始 if 语句处返回。但是这就是模糊测试的力量——它揭示了开发人员没有考虑过的边缘情况，这实际上是一个完全独立的错误。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你检查 panic 的输入，你可能会像我一样注意到其中一个字符是 Unicode 字符。也就是说，它由一个以上的字节表示。在我的情况下，它是 &lt;code&gt;Ö&lt;/code&gt;。当然，这个输入字符串有 60 个字符长，但它有&lt;em&gt;61 个字节长&lt;/em&gt;。在 Go 中，通过 &lt;code&gt;len&lt;/code&gt; 是获取字符串中的字节数，而不是字符数（或 rune）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这很容易自己检查。如果你运行以下 Go 代码片段：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;str := &lt;span&gt;&quot;Ö&quot;&lt;/span&gt;&lt;br/&gt;runeArray := []&lt;span&gt;rune&lt;/span&gt;(str)&lt;br/&gt;fmt.Println(&lt;span&gt;&quot;Str len:&quot;&lt;/span&gt;, &lt;span&gt;len&lt;/span&gt;(str), &lt;span&gt;&quot;Rune array len:&quot;&lt;/span&gt;, &lt;span&gt;len&lt;/span&gt;(runeArray))&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;将看到以下输出：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Str len: 2 Rune array len: 1&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有了关于 Go 的字符串实现的重要信息，再次重写 if 语句，从 &lt;code&gt;if n &amp;gt;= len(str)&lt;/code&gt; 改为 &lt;code&gt;if n &amp;gt;= utf8.RuneCountInString(str)&lt;/code&gt;。因此我们想要比较的是字符数而不是字节数：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;// overwrite_string.go&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// OverwriteString overwrites the first &#x27;n&#x27; characters in a string with&lt;/span&gt;&lt;br/&gt;&lt;span&gt;// the rune &#x27;value&#x27;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;OverwriteString&lt;/span&gt;&lt;span&gt;(str &lt;span&gt;string&lt;/span&gt;, value &lt;span&gt;rune&lt;/span&gt;, n &lt;span&gt;int&lt;/span&gt;)&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;// If asked to overwrite more than the entire string then no need to loop,&lt;/span&gt;&lt;br/&gt; &lt;span&gt;// just return string length * the rune&lt;/span&gt;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; n &amp;gt;= utf8.RuneCountInString(str) {&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; strings.Repeat(&lt;span&gt;string&lt;/span&gt;(value), &lt;span&gt;len&lt;/span&gt;(str))&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt; result := []&lt;span&gt;rune&lt;/span&gt;(str)&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt;= n; i++ {&lt;br/&gt;  result[i] = value&lt;br/&gt; }&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;(result)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再次运行 fuzz 测试，观察它的变化，试图找到另一个输入来使我们的函数 panic：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;go test -fuzz FuzzBasicOverwriteString&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你&lt;em&gt;应该&lt;/em&gt;让它运行一段时间以确保没有任何其他错误潜伏的错误，至少可以确信该函数不会在最基本的输入上崩溃。你可以按&lt;code&gt;ctrl/cmmand-C&lt;/code&gt;停止模糊器。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;功能性 Bug&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到目前为止，我们已经发现了导致崩溃的错误。拒绝服务是一件大事，但我们所知道的是，这个函数不会因意外输入而崩溃。但测试函数的&lt;em&gt;正确性&lt;/em&gt;也很重要。有很多方法可以解决这个问题，但是通过模糊测试，最好尝试考虑一个始终适用于你的代码&lt;em&gt;的不变量（或属性） 。&lt;/em&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;OverwriteString&lt;/code&gt; 不变量的一个例子是，该函数永远不应填充比它被要求的数字&lt;em&gt;更多的字符&lt;/em&gt;。更具体地说，如果被要求覆盖“Hello, world!” 使用 5 个 “A” 字符，应该可以检查字符串中剩余的字符是否仍然是“, world!”。（通常成为语料或种子）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这可以通过以下测试进行一般化：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;// overwrite_string_test.go&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;FuzzOverwriteStringSuffix&lt;/span&gt;&lt;span&gt;(f *testing.F)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; f.Add(&lt;span&gt;&quot;Hello, world!&quot;&lt;/span&gt;, &lt;span&gt;&#x27;A&#x27;&lt;/span&gt;, &lt;span&gt;15&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt; f.Fuzz(&lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;(t *testing.T, str &lt;span&gt;string&lt;/span&gt;, value &lt;span&gt;rune&lt;/span&gt;, n &lt;span&gt;int&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;  result := OverwriteString(str, value, n)&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; n &amp;gt; &lt;span&gt;0&lt;/span&gt; &amp;amp;&amp;amp; n &amp;lt; utf8.RuneCountInString(str) {&lt;br/&gt;   &lt;span&gt;// If we modified characters [0:n], then characters [n:] should stay the same&lt;/span&gt;&lt;br/&gt;   resultSuffix := &lt;span&gt;string&lt;/span&gt;([]&lt;span&gt;rune&lt;/span&gt;(result)[n:])&lt;br/&gt;   strSuffix := &lt;span&gt;string&lt;/span&gt;([]&lt;span&gt;rune&lt;/span&gt;(str)[:])&lt;br/&gt;   &lt;span&gt;if&lt;/span&gt; resultSuffix != strSuffix {&lt;br/&gt;    t.Fatalf(&lt;span&gt;&quot;OverwriteString modified too many characters! Expected %s, got %s.&quot;&lt;/span&gt;, strSuffix, resultSuffix)&lt;br/&gt;   }&lt;br/&gt;  }&lt;br/&gt; })&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行测试会发现另一个 Bug：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$ go &lt;span&gt;test&lt;/span&gt; -fuzz FuzzOverwriteStringSuffix&lt;br/&gt;&lt;br/&gt;fuzz: elapsed: 0s, gathering baseline coverage: 0/54 completed&lt;br/&gt;fuzz: minimizing 66-byte failing input file&lt;br/&gt;fuzz: elapsed: 0s, gathering baseline coverage: 8/54 completed&lt;br/&gt;--- FAIL: FuzzOverwriteStringSuffix (0.03s)&lt;br/&gt;    --- FAIL: FuzzOverwriteStringSuffix (0.00s)&lt;br/&gt;        overwrite_string_test.go:38: OverwriteString modified too many characters! Expected 0, got A.&lt;br/&gt;    &lt;br/&gt;    Failing input written to testdata/fuzz/FuzzOverwriteStringSuffix/148139e8febb077401421c031a9bd3c3315179c5a66c90349102d223b451ec02&lt;br/&gt;    To re-run:&lt;br/&gt;    go &lt;span&gt;test&lt;/span&gt; -run=FuzzOverwriteStringSuffix/148139e8febb077401421c031a9bd3c3315179c5a66c90349102d223b451ec02&lt;br/&gt;FAIL&lt;br/&gt;&lt;span&gt;exit&lt;/span&gt; status 1&lt;br/&gt;FAIL github.com/fuzzbuzz/go-fuzzing-tutorial/introduction 0.031s&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请注意，这一次不是 panic，而是一条看起来非常类似于单元测试失败的消息。实际上，这段代码一直存在一个功能性错误。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在第 20 行它检查循环索引用的是 &lt;code&gt;&amp;lt;=&lt;/code&gt;，所以它一直填充多余的字符。将循环条件从 &lt;code&gt;i &amp;lt;= n&lt;/code&gt; 更改为 &lt;code&gt;i &amp;lt; n&lt;/code&gt; 解决此问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最终&lt;code&gt;OverwriteString&lt;/code&gt;函数应该如下所示：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;// overwrite_string.go&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// OverwriteString overwrites the first &#x27;n&#x27; characters in a string with&lt;/span&gt;&lt;br/&gt;&lt;span&gt;// the rune &#x27;value&#x27;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;OverwriteString&lt;/span&gt;&lt;span&gt;(str &lt;span&gt;string&lt;/span&gt;, value &lt;span&gt;rune&lt;/span&gt;, n &lt;span&gt;int&lt;/span&gt;)&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;// If asked for more no need to loop, just return&lt;/span&gt;&lt;br/&gt; &lt;span&gt;// string length * the rune&lt;/span&gt;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; n &amp;gt;= utf8.RuneCountInString(str) {&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; strings.Repeat(&lt;span&gt;string&lt;/span&gt;(value), &lt;span&gt;len&lt;/span&gt;(str))&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt; result := []&lt;span&gt;rune&lt;/span&gt;(str)&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; n; i++ {&lt;br/&gt;  result[i] = value&lt;br/&gt; }&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;(result)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果再次运行 fuzzer，你应该会看到 fuzzer 每秒可靠地运行数千个输入，同时没有发现其他错误。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;理想情况下，应该让这个模糊测试运行至少几分钟，以增加对该代码正确性的信心（特别是如果它正在测试超过 10 行的函数）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这篇文章中的错误是在几秒钟内发现的，但有些错误可能需要数小时或数天的时间来进行模糊测试，因为模糊器需要时间来探索被测软件的整个状态空间。后续文章将介绍大规模连续模糊测试的艺术。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;结语&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这只是对 Go 模糊测试的简要介绍。今天讨论的示例是你开始向自己的项目添加模糊测试所需的全部内容。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后续文章将深入研究你可以找到的错误类型，调查一些真实世界的模糊测试错误，并讨论如何自动化你的模糊测试，以便 CI 在你睡着时发现错误。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;作者：Everest Munro-Zeisberger，原文链接：https://blog.fuzzbuzz.io/go-fuzzing-basics&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d6a05d2120e65aded46f4e448e2e30af</guid>
<title>ClickHouse使用实践与规范</title>
<link>https://toutiao.io/k/3xcqu8e</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;hr data-mpa-powered-by=&quot;yiban.io&quot;/&gt;&lt;section label=&quot;Copyright Reserved by PLAYHUDONG.&quot; donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot;&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;导读：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ClickHouse作为一款开源列式数据库管理系统（DBMS）近年来备受关注，主要用于数据分析（OLAP）领域。作者根据以往经验和遇到的问题，总结出一些基本的开发和使用规范，以供使用者参考。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着公司业务数据量日益增长，数据处理场景日趋复杂，急需一种具有高可用性和高性能的数据库来支持业务发展，ClickHouse是俄罗斯的搜索公司Yandex开源的MPP架构的分析引擎，号称比事务数据库快100-1000倍，最大的特色是高性能的向量化执行引擎，而且功能丰富、可靠性高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在过去的一年中，杭研DBA团队已经支撑网易集团内部多个事业部上线使用，集群规模共计十几套，CPU近3000核，每日近千亿数据入库，千亿级别表查询可在秒级完成，大大提升了业务原有OLAP架构的效能，覆盖的业务场景包括：用户行为日志分析，进行PV、UV、留存、转化漏斗和操作，包括游戏反外挂数据统计分析；用户画像，人群圈定和问卷投放；AB实验数据的实时计算与分析；机器和业务日志的分析、监控、查询等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86134&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-original-title=&quot;&quot; title=&quot;&quot;&gt;1&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-width=&quot;20%&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p hm_fix=&quot;360:461&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-brushtype=&quot;text&quot;&gt;ClickHouse应用场景&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 写在前面&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）如果你的业务预算或机器资源有限，强烈不推荐使用clickhouse，因为这套架构成本比较高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）最小集群部署所需机器：ck节点需要2台256G内存/40c cpu物理机，磁盘使用SSD，加上3台zookeeper和2台chproxy应用主机或者云主机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）Clickhouse自带了丰富的功能来应对复杂的业务场景和大数据量，所以在使用期间需要运维和开发侧都投入人力对这些功能(表引擎类型)学习和掌握。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 业务在数据层的表现&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）业务大多数是读请求，存储宽表，无大字段，较少的并发(单台100-200qps左右)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）数据批写入（1000条以上，线上业务建议5w-10w），不修改或少修改已添加的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）无事务要求，对数据一致性要求低。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（4）对于简单查询，允许延迟大约50毫秒，每一个查询除了一个大表外都很小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（5）处理单个查询时需要高吞吐量（每个服务器每秒高达数十亿行）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3.具体业务场景&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）用户行为分析，精细化运营分析：日活，留存率分析，路径分析，有序漏斗转化率分析，Session分析等；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）实时日志分析，监控分析；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）实时数仓。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86134&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-original-title=&quot;&quot; title=&quot;&quot;&gt;2&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-width=&quot;20%&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p hm_fix=&quot;360:461&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-brushtype=&quot;text&quot;&gt;表引擎选择&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ClickHouse表引擎一共分为四个系列，分别是Log、MergeTree、Integration、Special。其中包含了两种特殊的表引擎Replicated、Distributed，功能上与其他表引擎正交，目前业务上主要使用MergeTree系列，配合使用Mview和Distributed引擎。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/cv9Nw4dcXR4TAYDsZafHPjlHl5ObG0Y4FekI2ia2CibpWmyYXJKPU36RhywZ5ueMTQVPqBCPeIThKNHic6NEFpNew/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ClickHouse 包含以下几种常用的引擎类型：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;MergeTree 引擎：该系列引擎是执行高负载任务的最通用和最强大的表引擎，它们的特点是可以快速插入数据以及进行后续的数据处理。该系列引擎还同时支持数据复制（使用Replicated的引擎版本），分区 (partition) 以及一些其它引擎不支持的额外功能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Log 引擎：该系列引擎是具有最小功能的轻量级引擎。当你需要快速写入许多小表（最多约有100万行）并在后续任务中整体读取它们时使用该系列引擎是最有效的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;集成引擎：该系列引擎是与其它数据存储以及处理系统集成的引擎，如 Kafka，MySQL 以及 HDFS 等，使用该系列引擎可以直接与其它系统进行交互，但也会有一定的限制，如确有需要，可以尝试一下。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;特殊引擎：该系列引擎主要用于一些特定的功能，如 Distributed 用于分布式查询，MaterializedView 用来聚合数据，以及 Dictionary 用来查询字典数据等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在所有的表引擎中，最为核心的当属MergeTree系列表引擎，这些表引擎拥有最为强大的性能和最广泛的使用场合。对于非MergeTree系列的其他引擎而言，主要用于特殊用途，场景相对有限。而MergeTree系列表引擎是官方主推的存储引擎，支持几乎所有ClickHouse核心功能，下面主要介绍MergeTree系列表引擎：&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;mpcps frameborder=&quot;0&quot; class=&quot;js_editor_cps&quot; data-datakey=&quot;1649771597725_0.2648553759843819&quot; data-uid=&quot;1649771597629&quot; data-type=&quot;1&quot; data-product=&quot;&quot; data-templateid=&quot;list&quot; data-pid=&quot;29347487&quot; data-categoryid=&quot;3&quot; data-appuin=&quot;3084391334&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. MergeTree表引擎&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MergeTree在写入一批数据时，数据总会以数据片段的形式写入磁盘，且数据片段不可修改。为了避免片段过多，ClickHouse会通过后台线程，定期合并这些数据片段，属于相同分区的数据片段会被合成一个新的片段。这种数据片段往复合并的特点，也正是合并树名称的由来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; MergeTree作为家族系列最基础的表引擎，主要有以下特点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 建表语法：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;(   name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1] [TTL expr1],&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2] [TTL expr2],&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    ...&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    INDEX index_name1 expr1 TYPE type1(...) GRANULARITY value1,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    INDEX index_name2 expr2 TYPE type2(...) GRANULARITY value2&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;) ENGINE = MergeTree()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;ORDER BY expr&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[PARTITION BY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[PRIMARY KEY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[SAMPLE BY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[TTL expr [DELETE|TO DISK &#x27;xxx&#x27;|TO VOLUME &#x27;xxx&#x27;], ...]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[SETTINGS name=value, ...]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ENGINE：ENGINE = MergeTree()，MergeTree引擎没有参数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ORDER BY：排序字段。比如ORDER BY (Col1, Col2)，值得注意的是，如果没有指定主键，默认情况下 sorting key(排序字段)即为主键。如果不需要排序，则可以使用ORDER BY tuple()语法，这样的话，创建的表也就不包含主键。这种情况下，ClickHouse会按照插入的顺序存储数据。&lt;/span&gt;&lt;span&gt;必选。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PARTITION BY：分区字段，&lt;/span&gt;&lt;span&gt;强烈建议指定。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PRIMARY KEY：指定主键，如果排序字段与主键不一致，可以单独指定主键字段。否则默认主键是排序字段。可选。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SAMPLE BY：采样字段，如果指定了该字段，那么主键中也必须包含该字段。比如SAMPLE BY intHash32(UserID) ORDER BY (CounterID, EventDate, intHash32(UserID))。可选。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;TTL：数据的存活时间。在MergeTree中，可以为某个列字段或整张表设置TTL。当时间到达时，如果是列字段级别的TTL，则会删除这一列的数据；如果是表级别的TTL，则会删除整张表的数据。&lt;/span&gt;&lt;span&gt;大表强烈建议指定。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SETTINGS：额外的参数配置。一般设置index_granularity=8192 ，可选。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. ReplicatedMergeTree表引&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ReplicatedMergeTree使得以上 MergeTree 家族拥有副本机制，保证高可用，用于生产环境，对于大数据量的表来说不推荐使用，因为副本是基于zk做数据同步的，大数据量会对zk造成巨大压力，成为整个ck整个集群瓶颈。业务可以根据数据重要程度在性能和数据副本之间做选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;建表示例：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;TABLE&lt;/span&gt; [&lt;span class=&quot;code-snippet__keyword&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;EXISTS&lt;/span&gt;] [db.]table_name [&lt;span class=&quot;code-snippet__keyword&quot;&gt;ON&lt;/span&gt; CLUSTER cluster]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;(&lt;span class=&quot;code-snippet__string&quot;&gt;`id`&lt;/span&gt; Int64, &lt;span class=&quot;code-snippet__string&quot;&gt;`ymd`&lt;/span&gt; Int64)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;ENGINE&lt;/span&gt; = ReplicatedMergeTree(&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;/clickhouse/tables/replicated/{shard}/test&#x27;&lt;/span&gt;, &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;{replica}&#x27;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;BY&lt;/span&gt; ymd&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;id&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;/clickhouse/tables/ 这一部分指定的是在ZK上创建的路径地址，可随意变换只要记得即可&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;{shard} 指的是分片的标志，同一个分片内的所有机器应该保持相同。建议使用使用的是集群名+分片名的配置也就是{layer}-{shard}，这里的数据就是在macros中配置的属性&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;test 建议使用表名称&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;{replica} 参数建议在macros配置成机器的hostname，因为每台机器的hostname都是不一样的，因此就能确保每个表的识别符都是唯一的了&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. ReplacingMergeTree表引&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上文提到MergeTree表引擎无法对相同主键的数据进行去重，ClickHouse提供了ReplacingMergeTree引擎，可以针对相同主键的数据进行去重，它能够在合并分区时删除重复的数据。值得注意的是，ReplacingMergeTree只是在一定程度上解决了数据重复问题，但是并不能完全保障数据不重复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;建表语法：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;(   name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    ...&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;) ENGINE = ReplacingMergeTree([ver])&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[PARTITION BY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[ORDER BY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[PRIMARY KEY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[SAMPLE BY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[SETTINGS name=value, ...]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[ver]：可选参数，列的版本，可以是UInt、Date或者DateTime类型的字段作为版本号。该参数决定了数据去重的方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当没有指定[ver]参数时，保留最新的数据；如果指定了具体的值，保留最大的版本数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）去重规则&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ReplacingMergeTree是支持对数据去重的，去除重复数据时，是以ORDERBY排序键为基准的，而不是PRIMARY KEY。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）何时删除重复数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在执行分区合并时，会触发删除重复数据。optimize的合并操作是在后台执行的，无法预测具体执行时间点，除非是手动执行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）不同分区的重复数据不会被去重&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ReplacingMergeTree是以分区为单位删除重复数据的。只有在相同的数据分区内重复的数据才可以被删除，而不同数据分区之间的重复数据依然不能被剔除。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4. SummingMergeTree表引&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该引擎继承了MergeTree引擎，当合并 SummingMergeTree 表的数据片段时，ClickHouse 会把所有具有相同主键的行合并为一行，该行包含了被合并的行中具有数值数据类型的列的汇总值，即如果存在重复的数据，会对对这些重复的数据进行合并成一条数据，类似于group by的效果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推荐将该引擎和 MergeTree 一起使用。例如，将完整的数据存储在 MergeTree 表中，并且使用 SummingMergeTree 来存储聚合数据。这种方法可以避免因为使用不正确的主键组合方式而丢失数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果用户只需要查询数据的汇总结果，不关心明细数据，并且数据的汇总条件是预先明确的，即GROUP BY的分组字段是确定的，可以使用该表引擎。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;建表语法：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;(   name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    ...&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;) &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;ENGINE = SummingMergeTree([columns]) -- 指定合并汇总字段&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[PARTITION BY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[ORDER BY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[SAMPLE BY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[SETTINGS name=value, ...]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 注意点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 要保证PRIMARY KEY expr指定的主键是ORDER BY expr 指定字段的前缀，比如&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; -- 如下情况是允许的：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;properties&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;ORDER BY (A,B,C)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;KEY A&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;-- 如下情况会报错：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;http&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attribute&quot;&gt;DB::Exception: Primary key must be a prefix of the sorting key&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;ORDER BY (A,B,C)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;PRIMARY KEY B&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种强制约束保障了即便在两者定义不同的情况下，主键仍然是排序键的前缀，不会出现索引与数据顺序混乱的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SummingMergeTree是根据什么对两条数据进行合并的用ORBER BY排序键作为聚合数据的条件Key。即如果排序key是相同的，则会合并成一条数据，并对指定的合并字段进行聚合。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;仅对分区内的相同排序key的数据行进行合并以数据分区为单位来聚合数据。当分区合并时，同一数据分区内聚合Key相同的数据会被合并汇总，而不同分区之间的数据则不会被汇总。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果没有指定聚合字段，会怎么聚合如果没有指定聚合字段，则会按照非主键的数值类型字段进行聚合&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于非汇总字段的数据，该保留哪一条如果两行数据除了排序字段相同，其他的非聚合字段不相同，那么在聚合发生时，会保留最初的那条数据，新插入的数据对应的那个字段值会被舍弃。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5. Aggregatingmergetree表引&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该表引擎继承自MergeTree，可以使用 AggregatingMergeTree 表来做增量数据统计聚合。如果要按一组规则来合并减少行数，则使用 AggregatingMergeTree 是合适的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AggregatingMergeTree是通过预先定义的聚合函数计算数据并通过二进制的格式存入表内。与SummingMergeTree的区别在于：SummingMergeTree对非主键列进行sum聚合，而AggregatingMergeTree则可以指定各种聚合函数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;建表语法：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;(    name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2],    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     ...&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;) &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;ENGINE = AggregatingMergeTree()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[PARTITION BY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[ORDER BY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[SAMPLE BY expr]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[SETTINGS name=value, ...]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; 6. 其他特殊的表引&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Distributed表引擎&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Distributed表引擎是分布式表的代名词，它自身不存储任何数据，数据都分散存储在某一个分片上，能够自动路由数据至集群中的各个节点，所以Distributed表引擎需要和其他数据表引擎一起协同工作。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;mpcps frameborder=&quot;0&quot; class=&quot;js_editor_cps&quot; data-datakey=&quot;1649771597724_0.035689978665933264&quot; data-uid=&quot;1649771597628&quot; data-type=&quot;1&quot; data-product=&quot;&quot; data-templateid=&quot;list&quot; data-pid=&quot;29347487&quot; data-categoryid=&quot;3&quot; data-appuin=&quot;3084391334&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;所以，一张分布式表底层会对应多个本地分片数据表，由具体的分片表存储数据，分布式表与本地分片数据表是一对多的关系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Distributed表引擎的定义形式如下所示：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;css&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;Distributed&lt;/span&gt;(&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;cluster_name&lt;/span&gt;, &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;database_name&lt;/span&gt;, &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;table_name&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-attr&quot;&gt;[, sharding_key]&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;各个参数的含义分别如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;创建分布式表是读时检查的机制，也就是说对创建分布式表和本地表的顺序并没有强制要求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同样值得注意的是，在上面的语句中使用了ON CLUSTER分布式DDL，这意味着在集群的每个分片节点上，都会创建一张Distributed表，这样便可以从其中任意一端发起对所有分片的读、写请求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86134&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-original-title=&quot;&quot; title=&quot;&quot;&gt;3&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-width=&quot;20%&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p hm_fix=&quot;360:461&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-brushtype=&quot;text&quot;&gt;开发规范&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt; 1. 查询sql编写规范&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）当多表联查时，查询的数据仅从其中一张表出时，可考虑使用IN操作而不是JOIN。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）多表查询性能较差，多表Join时要满足小表在右的原则，右表关联时被加载到内存中与左表进行比较，ClickHouse中无论是Left Join 、Right Join还是Inner Join永远都是拿着右表中的每一条记录到左表中查找该记录是否存在，所以右表必须是小表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）将一些需要关联分析的业务创建成字典表进行join操作，前提是字典表不宜太大，因为字典表会常驻内存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（4）禁⽌业务select * ，列存数据,每减少一个字段会减少大量的数据扫描,提升查询效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（5）建议使用 limit 限制返回数据条数使用limit返回指定的结果集数量，不会进行向下扫描，大大提升了查询效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（&lt;/span&gt;&lt;span&gt;6）查询时如果可以建议带上分区键查询,可以有效减少数据扫描量,提升查询效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（7）CK的稀疏索引使得点查询(即kv类型的查询)性能不佳，千万不要把它简单当做关系型数据库进行查询。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（8）使用Global优化分布式子查询，避免出现查询指数级放大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（9）使用 uniqCombined 替代 distinctuniqCombined 对去重进行了优化，通过近似去重提升十倍查询性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（10）尽量不去使用字符串类型，时间类型最终会转换成数值类型进行处理，数值类型在执行效率和存储上远好过字符串。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（11）ClickHouse的分布式表性能性价比不如物理表高，建表分区字段值不宜过多，防止数据导入过程磁盘可能会被打满。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（12）不要在唯一列或大基数列上进行分组或去重操作，基数太大会消耗过多的io和内存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（13）CPU一般在50%左右会出现查询波动，达到70%会出现大范围的查询超时，CPU是最关键的指标，要非常关注。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; 2. 数据写入注意事项&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）不适合高并发写入，最好还是从异步化队列写入，batch insert 5w-10w 起步，尽量不要执行单条或插入操作，会产生大量小分区文件，给后台merge任务带来巨大压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）几乎完全不支持update/delete，也不支持事务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）建议表要指定分区键,尤其是数据量大的表，插入/查询/合并都是以分区为单位，合理的分区可以提升整体性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（4）分区不建议太多，如果分区太多，会因需要打开的文件描述符过多导致查询效率不佳。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（5）数据在写入ClickHouse前预先的对数据进行分组，避免一次插入的数据属于多个分区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（6）注意MerTree 主键允许存在重复数据(ReplacingMergeTree可以在分区内去重)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; 3. 建表规范&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）本地表命名格式：{tab_name}_local，分布式表命名格式：{tab_name}_shard 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）物化视图命名规范：&lt;/span&gt;&lt;span&gt;{tabl_name_xxx}_mv 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）尽量不要使用Nullable类型,该类型对性能有一定影响,且不能包含在索引中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（4）合理设置分区，所有本地表使用order by关键字指定分区字段，建议采用日期作为一级分区。&lt;/span&gt;&lt;span&gt;默认 order by 字段作为主键。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（&lt;/span&gt;&lt;span&gt;5）如果表中不是必须保留全量历史数据，建议指定TTL，可以免去手动过期历史数据的麻烦。&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（6）所有复制引擎表建表指定 use_minimalistic_part_header_in_zookeeper=1。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 本地ReplicatedMergeTree表建表模板如下所示：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;CREATE TABLE IF NOT EXISTS ads. ads_af_city_complaint_1d _local ON cluster ycdata_3shards_3replicas&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;(`id` UInt64 COMMENT &#x27;序号&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;`order_id` UInt64 COMMENT &#x27;订单号&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;`gross_weight` UInt64  COMMENT &#x27;权重&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;`create_time` Date COMMENT &#x27;创建时间&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;`event` String COMMENT &#x27;事件&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;ENGINE = ReplicatedMergeTree(&#x27;/clickhouse/table/{shared}/ads_af_city_complaint_1d _local&#x27;, &#x27;{replica}&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;PARTITION BY create_time&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;ORDER BY id&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;TTL create_time + toIntervalDay(90)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;SETTINGS index_granularity = 8192, use_minimalistic_part_header_in_zookeeper = 1;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解释：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86134&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-original-title=&quot;&quot; title=&quot;&quot;&gt;4&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-width=&quot;20%&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p hm_fix=&quot;360:461&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-brushtype=&quot;text&quot;&gt;集群架构&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt; 1. 常用架构&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为简化业务使用方式，降低业务使用成本。对clickhouse集群的使用做一些约束，能够提升交付速度，提高标准化程度，降低使用成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以4台机器为例，集群模式固定为2分片2副本模式，若数据量较大4台机器不够时，可以增加2台机器，集群模式未3分片每个分片2副本形式，另外需要3台zookeeper和2台chproxy应用主机或者云主机，两台chproxy使用NLB管理，程序直连NLB IP。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于单表数据量超过100亿数据的表不建议使用副本表，建议采用4分片0副本架构。(具体架构可以和DBA沟通后确定)&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总体上讲，一句话总结：业务访问统一入口，读分布式表，写本地表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7942028985507247&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/cv9Nw4dcXR4TAYDsZafHPjlHl5ObG0Y4SibibsaCho84sZvlZwZSgEH1r3bcDRYH4LfSRvibm27nypoGruZlPwMwQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;690&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 优势：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;限制：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）业务写入本地表(以_local结尾),读分布式表(以_shard结尾表)&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;业务表名为musci_bi_t1,则写入musci_bi_t1_local 通过proxy代理轮询写入底层节点保证数据分布均衡；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;读musci_bi_t1_shard表,同样可以通过proxy将shard表路由压力分散到底层节点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;（2）业务写入时需要批量写入,需要业务去保证每批次数据量大小尽量一致,以保证数据尽量均匀分布。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）业务每批次写入时都要重新获取连接,禁止使用长连接否则无法使用负载均衡能力,会导致数据分布不均衡。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（4）不支持跨集群访问&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因业务每批次写入数据量的不同，会导致数据分布的不均匀。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;mpcps frameborder=&quot;0&quot; class=&quot;js_editor_cps&quot; data-datakey=&quot;1649771597723_0.6089120526137164&quot; data-uid=&quot;1649771597627&quot; data-type=&quot;1&quot; data-product=&quot;&quot; data-templateid=&quot;list&quot; data-pid=&quot;29347487&quot; data-categoryid=&quot;3&quot; data-appuin=&quot;3084391334&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;运维注意点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对业务不透明，insert需要指定local结尾表,查询需要查sharded表,需要与业务确认；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;副本同步使用底层ReplicatedMergeTree引擎,提升副本同步性能以及数据一致性（&lt;/span&gt;&lt;span&gt;需要手动创建底层表,保证主备关系正确）；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;使用on cluster 语法在每个节点中创建分布式表,提升建表效率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. zookeeper的关键作用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ClickHouse中依赖Zookeeper解决的问题可以分为两大类：分布式DDL执行、ReplicatedMergeTree表主备节点之间的状态同步。zk的性能会影响整个集群的性能表现。使用复制表之后，随着数据量的增加，zookeeper可能成为集群瓶颈，zk集群建议机器配置如下：3台32G/4c机器，万兆网卡，磁盘80G-200G。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看作ck把zookeeper用成了目录服务，日志服务和协调服务，当znode达到几百万后，zk出现异常，常见是连接失败，此时有些表会出现readonly模式。头条对这个问题的处理方式是改写源码调整ck对zk的使用方式，为zk减重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果业务上单表数据量较大并且希望使用复制表，务必在建表时指定use_minimalistic_part_header_in_zookeeper参数为1，达到压缩zk数据的目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.8554817275747508&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/cv9Nw4dcXR4TAYDsZafHPjlHl5ObG0Y4ciaQt6F2l3cibZiaOp8HjdiaMuwvZEUPwztUcZJMluyNrM9922FfT0vqMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1204&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. chproxy&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;chproxy官方推荐的是专用于ClickHouse数据库的HTTP代理和负载均衡器，使用go语言实现，目前仅支持http协议。在Clickhouse集群中，每一台机器都是单独的实例，我们可以使用其中的一台作为查询机器。此时如何更好的完成负载均衡是我们所关注的，&lt;/span&gt;&lt;span/&gt;&lt;span&gt;chproxy即是这么一个工具。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;特性:&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;用户路由和响应缓存。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;灵活的限制。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;自动SSL证书续订。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;chroxy连接测试：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;echo &#x27;&lt;span class=&quot;code-snippet__keyword&quot;&gt;show&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;databases&lt;/span&gt;;&#x27; | curl &#x27;http://10.200.161.49:9009/?user=writeuser&amp;amp;password=xxxx&#x27; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于chroxy参数配置可参照如下文档：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/ContentSquare/chproxy&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86134&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-original-title=&quot;&quot; title=&quot;&quot;&gt;5&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-width=&quot;20%&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p hm_fix=&quot;360:461&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-brushtype=&quot;text&quot;&gt;客户端工具选择&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. DBeave&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DBeaver是免费和开源（GPL）为开发人员和数据库管理员通用数据库工具。易用性是该项目的主要目标，是经过精心设计和开发的数据库管理工具。免费、跨平台、基于开源框架和允许各种扩展写作（插件）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. Superse&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Superset 是一款由 Airbnb 开源的“现代化的企业级 BI（商业智能） Web 应用程序”，其通过创建和分享 dashboard，为数据分析提供了轻量级的数据查询和可视化方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. Tabi&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;功能和部署方式与Superset相似，可参考如下文档：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://github.com/smi2/tabix.ui/releases&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86134&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-original-title=&quot;&quot; title=&quot;&quot;&gt;6&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-width=&quot;20%&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p hm_fix=&quot;360:461&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-brushtype=&quot;text&quot;&gt;可用性说明&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据选择的集群架构不同， clickhouse集群表现出的可用性也不同。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）数据的读写高可用就是依赖复制表引擎创建多副本机制保证。如果Clickhouse集群使用是多分片多副本架构，当一个副本所在的机器宕机后，chproxy层会自动路由到可用的副本读写数据；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）如果Clickhouse集群只用了sharding分片，没有用到复制表作为数据副本，那么单台机器宕机只会影响到单个数据分片的读写；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）当zk集群不可用时，整个集群的写入会都会受影响，不管有没有使用复制表。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;mpcps frameborder=&quot;0&quot; class=&quot;js_editor_cps&quot; data-datakey=&quot;1649771597722_0.9054545886780196&quot; data-uid=&quot;1649771597626&quot; data-type=&quot;1&quot; data-product=&quot;&quot; data-templateid=&quot;list&quot; data-pid=&quot;29347487&quot; data-categoryid=&quot;3&quot; data-appuin=&quot;3084391334&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;总结：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据可用性要求越高，意味着投入更多的资源，单台机器的资源利用率越低，业务可根据数据重要程度灵活选择，不过Clickhouse的定位是在线分析olap系统，建议业务方将ck里的数据也定义为二级数据，数据丢失后是可以再生成的，从而控制整体架构的成本，提高单台机器的资源利用率。同时强烈建议业务不要强依赖Clickhouse，要有一定的兜底和熔断机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86134&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-original-title=&quot;&quot; title=&quot;&quot;&gt;7&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-width=&quot;20%&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p hm_fix=&quot;360:461&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-brushtype=&quot;text&quot;&gt;&lt;span&gt;集群配置参数调&lt;/span&gt;优&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. max_concurrent_querie&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最大并发处理的请求数(包含select,insert等)，默认值100，推荐150(不够再加)，在我们的集群中出现过”max concurrent queries”的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. max_bytes_before_external_sor&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当order by已使用max_bytes_before_external_sort内存就进行溢写磁盘(基于磁盘排序)，如果不设置该值，那么当内存不够时直接抛错，设置了该值order by可以正常完成，但是速度相对内存来说肯定要慢点(实测慢的非常多，无法接受)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. background_pool_size&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后台线程池的大小，merge线程就是在该线程池中执行，当然该线程池不仅仅是给merge线程用的，默认值16，推荐32提升merge的速度(CPU允许的前提下)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4. max_memory_usag&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单个SQL在单台机器最大内存使用量，该值可以设置的比较大，这样可以提升集群查询的上限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5. max_memory_usage_for_all_querie&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单机最大的内存使用量可以设置略小于机器的物理内存(留一点内操作系统)。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;6. max_bytes_before_external_group_b&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在进行group by的时候，内存使用量已经达到了max_bytes_before_external_group_by的时候就进行写磁盘(基于磁盘的group by相对于基于磁盘的order by性能损耗要好很多的)，一般max_bytes_before_external_group_by设置为max_memory_usage / 2，原因是在clickhouse中聚合分两个阶段：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些内存参数强烈推荐配置上，增强集群的稳定性避免在使用过程中出现莫名其妙的异常。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;学习资料：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;101582&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;作者简介&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-autoskip=&quot;1&quot;&gt;&lt;p hm_fix=&quot;322:369&quot;&gt;&lt;span&gt;刘彦鹏，网易杭州研究院数据库工程师。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; hm_fix=&quot;317:401&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7190426638917794&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/cv9Nw4dcXR65pDCEB2JUwoIWChTdxXzyhszKpAtx48WuJTmyMHOj86s3Lj4fKjvIGZbwQssloLtyGdK2iaJNnBA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;961&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;《&lt;span&gt;数据中台研习社&lt;/span&gt;》微信群，请添加微信：&lt;/span&gt;&lt;span&gt;laowang5244,备注【进群】&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;                                                         🧐&lt;/span&gt;&lt;span&gt;&lt;strong&gt;分享、点赞、在看&lt;/strong&gt;，给个&lt;strong&gt;三连击&lt;/strong&gt;呗！&lt;/span&gt;&lt;span&gt;&lt;strong&gt;👇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>0c8b5e66e10f483c6ca9aa706171b4d5</guid>
<title>Flink SQL 优化实战 - 维表 JOIN 优化</title>
<link>https://toutiao.io/k/91w40f2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;h2 cid=&quot;n2&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;作者：龙逸尘，腾讯 CSIG 高级工程师&lt;/span&gt;&lt;/h2&gt;&lt;h2 cid=&quot;n2&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;背景介绍&lt;/span&gt;&lt;/h2&gt;&lt;p cid=&quot;n3&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;维表（Dimension Table）是来自数仓建模的概念。在数仓模型中，事实表（Fact Table）是指存储有事实记录的表，如系统日志、销售记录等，而维表是与事实表相对应的一种表，它保存了事实表中指定属性的相关详细信息，可以跟事实表做关联；相当于将事实表上经常重复出现的属性抽取、规范出来用一张表进行管理。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n4&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在实际生产中，我们经常会有这样的需求，以原始数据流作为基础，关联大量的外部表来补充一些属性。例如，在订单数据中希望能获取订单收货人所在市区的名称。一般来说订单中会记录所在市区的 ID，需要根据 ID 去查询外部的表补充市区名称属性。这种查询操作就是典型的维表 JOIN。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n5&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;使用维度表有许多好处，例如：&lt;/span&gt;&lt;/p&gt;&lt;h2 cid=&quot;n13&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;Flink SQL 维表 JOIN 的用法&lt;/span&gt;&lt;/h2&gt;&lt;p cid=&quot;n14&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在实时数仓中，同样也有维表与事实表的概念，其中事实表通常为实时流数据，维表通常存储在外部设备中（如 MySQL、HBase 等）。对于每条流式数据，可以关联外部数据源，查询并补充维度属性。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n15&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;由于维表是一张不断变化的表（静态表视为动态表的一种特例），因此在维表 JOIN 时，需指明这条记录关联维表快照的对应时刻。Flink SQL 的维表 JOIN 语法引入了 &lt;span md-inline=&quot;plain&quot;&gt;Temporal Table&lt;/span&gt; 的标准语法，用于声明流数据关联的是维表哪个时刻的快照。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n16&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;需要注意是，目前原生 Flink SQL 的维表 JOIN 仅支持事实表对当前时刻维表快照的关联（处理时间语义），而不支持事实表 rowtime 所对应的维表快照的关联（事件时间语义）。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n17&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;语法说明&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n18&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Flink SQL 中使用 &lt;code&gt;for SYSTEM_TIME as of PROC_TIME()&lt;/code&gt; 的语法来标识维表 JOIN，仅支持 &lt;code&gt;INNER JOIN&lt;/code&gt; 与 &lt;code&gt;LEFT JOIN&lt;/code&gt;。&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;SELECT column-names&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;FROM table1 [AS &amp;lt;alias1&amp;gt;]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[LEFT] JOIN table2 FOR SYSTEM_TIME AS OF table1.proctime [AS &amp;lt;alias2&amp;gt;]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;ON table1.column-name1 = table2.key-name1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p cid=&quot;n18&quot; mdtype=&quot;paragraph&quot;&gt;注意：&lt;code&gt;table1.proctime&lt;/code&gt; 表示 &lt;code&gt;table1&lt;/code&gt; 的 &lt;code&gt;proctime&lt;/code&gt; 属性（可使用计算列）。&lt;/p&gt;&lt;h3 cid=&quot;n21&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;使用示例&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n22&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;下面用一个简单的示例来展示维表 JOIN 语法。假设我们有一个 Orders 订单数据流，希望根据用户 ID 补全订单中的用户信息，因此需要跟 Customer 维度表进行关联。&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;CREATE TABLE Orders (&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  id   INT,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  price   DOUBLE,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  quantity   INT,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  proc_time AS PROCTIME(),&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  PRIMARY KEY(id) NOT ENFORCED&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;) WITH (&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &#x27;connector&#x27; = &#x27;datagen&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &#x27;fields.id.kind&#x27; = &#x27;sequence&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &#x27;rows-per-second&#x27; = &#x27;10&#x27;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;CREATE TABLE Customers (&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;id   INT,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;name   STRING,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;country   STRING,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;zip   STRING,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;PRIMARY KEY(id) NOT ENFORCED&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;) WITH (&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&#x27;connector&#x27; = &#x27;jdbc&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&#x27;url&#x27; = &#x27;jdbc:mysql://mysqlhost:3306/customerdb&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&#x27;table-name&#x27; = &#x27;customers&#x27;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;CREATE TABLE OrderDetails (&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;id   INT,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;total_price   DOUBLE,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;country   STRING,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;zip   STRING,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;PRIMARY KEY(id) NOT ENFORCED&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;) WITH (&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&#x27;connector&#x27; = &#x27;jdbc&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&#x27;url&#x27; = &#x27;jdbc:mysql://mysqlhost:3306/orderdb&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&#x27;table-name&#x27; = &#x27;orderdetails&#x27;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;-- enrich each order with customer information&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;INSERT INTO OrderDetails SELECT o.id, o.price*o.quantity, c.country, c.zip&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;FROM Orders AS o&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;JOIN Customers FOR SYSTEM_TIME AS OF o.proc_time AS c&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  ON o.id = c.id;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p cid=&quot;n22&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;Flink SQL 维表 JOIN 的原理&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n25&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;Flink SQL 执行流程&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n26&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Apache Calcite 是一款开源的 SQL 解析工具，被广泛使用于各个大数据项目中，主要用于解析 SQL 语句。SQL 的执行流程一般分为四个主要阶段：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot; cid=&quot;n27&quot; mdtype=&quot;list&quot; data-mark=&quot;-&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n29&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Parse：语法解析，把 SQL 语句转换成抽象语法树（AST），在 Calcite 中用 SqlNode 来表示；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n31&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Validate：语法校验，根据元数据信息进行验证，例如查询的表、使用的函数是否存在等，校验之后仍然是 SqlNode 构成的语法树；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n33&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Optimize：查询计划优化，包含两个阶段，1）将 SqlNode 语法树转换成关系表达式 RelNode 构成的逻辑树，2）使用优化器基于规则进行等价变换，例如谓词下推、列裁剪等，经过优化器优化后得到最优的查询计划；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n35&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Execute：将逻辑查询计划翻译成物理执行计划，生成对应的可执行代码，提交运行。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.14375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/o2eWePa4j5BpUW2Lg5mrf9PLADZHgia3IzHUtqOW86tL73EWs6YmEIMBuvFGibqLmOALX4S6ZQ0ia5zHzO2mJ8rGQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n37&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Flink SQL 的执行基本上遵循上述处理流程，主要依赖于 Calcite 来完成。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n38&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;当在 Flink SQL 作业中显式执行 &lt;code&gt;tEnv.executeSql()&lt;/code&gt; 方法时，就会真正开始运行 Flink SQL 程序。代码入口可以参考 &lt;code&gt;TableEnvironmentImpl.executeSql()&lt;/code&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n39&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;接下来我们详细分析一下 Flink SQL 的执行流程。&lt;/span&gt;&lt;/p&gt;&lt;h4 cid=&quot;n40&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;SQL 解析&lt;/span&gt;&lt;/h4&gt;&lt;p cid=&quot;n41&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;SQL 的解析在 &lt;code&gt;PlannerImpl.parse()&lt;/code&gt; 中实现，主要分为 4 个阶段：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot; start=&quot;&quot; cid=&quot;n42&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n44&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;首先使用 Calcite parser 解析出抽象语法树 SqlNode；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n46&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;结合元数据验证 SQL 语句的合法性；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n48&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;将 SqlNode 转换为 RelNode；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n50&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;将 RelNode 封装为 Flink 内部对查询操作的抽象 PlannerQueryOperation。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4 cid=&quot;n51&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;SQL 转换&lt;/span&gt;&lt;/h4&gt;&lt;p cid=&quot;n52&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在将 SQL 语句解析成 Operation 后，为了得到 Flink 运行时的具体操作算子，需要进一步将 Operation 转换为 Transformation。需要注意的是，只有 ModifyOperation 才能进行转换，而 ModifyOperation 对应的是 DML 的操作，在将 SQL 查询结果插入到一张结果表或者调用 toDataStream 方法转化为 DataStream 时，才会得到 ModifyOperation。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n53&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;SQL 的转换在 &lt;code&gt;PlannerBase.translate()&lt;/code&gt; 中实现，主要流程分为四个阶段：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot; start=&quot;&quot; cid=&quot;n54&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n56&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;将 Operation 转换为 RelNode；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n58&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;优化 RelNode，最终得到 FlinkPhysicalRel；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n60&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;优化后的 FlinkPhysicalRelNode 转换成 ExecNode；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n62&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;ExecNode 转换为底层的 Transformation 算子。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4 cid=&quot;n63&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;SQL 优化&lt;/span&gt;&lt;/h4&gt;&lt;p cid=&quot;n64&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;得到 RelNode 后，Flink 使用 Calcite 对 RelNode 进行了一系列优化流程。这些优化流程在 &lt;code&gt;PlannerBase.optimize()&lt;/code&gt; 中实现。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n65&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Caclite 对逻辑计划的优化是一套基于规则的框架，用户可以通过添加规则进行扩展，Flink 基于自定义规则来实现整个的优化过程。Flink 构造了一个链式的优化流程，可以按顺序使用多套规则集合完成 RelNode 的优化过程。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n66&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Flink Table Planner 在 FlinkStreamProgram 中定义了一系列扩展规则，用于构造逻辑计划的优化器，应用在 SQL 优化的各个阶段，将 SQL 从 原始的 RelNode 转化为 FlinkLogicRel，最后转化为 FlinkPhysicalRel。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n67&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;维表 JOIN 涉及的主要优化阶段包含 &lt;code&gt;temporal_join_rewrite&lt;/code&gt;、&lt;code&gt;logical&lt;/code&gt;、&lt;code&gt;physical&lt;/code&gt; 等。不同阶段生成的逻辑树如下所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.48515625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/o2eWePa4j5BpUW2Lg5mrf9PLADZHgia3I9Eqt42CicZiaT7Xj3kgPVJGoljxZ22IJc46t7icMUscB1m7ibJI8RbicsNQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n69&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;经过优化器处理后，得到的逻辑树中的所有节点都是 FlinkPhysicRel。首先调用 &lt;code&gt;PlannerBase.translateToExecNodeGraph(optimizedRelNodes)&lt;/code&gt; 将 FlinkPhysicalRel 构成的 DAG 转换成 ExecNode 构成的 DAG；随后调用 &lt;code&gt;PlannerBase.translateToPlan(execGraph)&lt;/code&gt; 将 ExecNode 节点转换为 Flink 内部的 Transformation 算子。不同的 ExecNode 按照各自的需求生成不同的 Transformation，基于这些 Transformation 构建 Flink 的 StreamGraph。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n70&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;梳理过后，我们可以得出，维表 JOIN 算子对应的 ExecNode 为 &lt;code&gt;StreamExecLookupJoin&lt;/code&gt;，最终转化成的 JOIN Operator 是 &lt;code&gt;LookupJoinRunner&lt;/code&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h4 cid=&quot;n71&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;SQL 执行&lt;/span&gt;&lt;/h4&gt;&lt;p cid=&quot;n72&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;经过 SQL 优化步骤，得到 Transformation 后，利用 Transformation 生成 StreamGraph 后就可以提交 Flink 任务了。根据 Transformation 列表生成 StreamGraph 的实现比较简单，依次将算子添加到 StreamExecutionEnvironment 中即可。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n73&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;CommonExecLookupJoin&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n74&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;现在让我们详细看下 LookupJoin 对应的 Operator 是如何进行维表关联的。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n75&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;前往 &lt;code&gt;CommonExecLookupJoin.translateToPlanInternal()&lt;/code&gt; 方法[1]，可以看到这个 Operator 的 operatorFactory 由 createAsyncLookupJoin 或者 createSyncLookupJoin 生成，最终生成的 LookupJoinRunner 算子使用用户定义的 LookupFunction 来作为最终访问外部维表的函数。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n76&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;Lookup JOIN 算子的调用链如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7859375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/o2eWePa4j5BpUW2Lg5mrf9PLADZHgia3ImMeorE7aDOR1pGc4PebicdW7icNcdzHNUlPWPNlickeHfOPzKib09JGZaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h3 cid=&quot;n78&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;LookupTableSource 和 LookupFunction&lt;/span&gt;&lt;br/&gt;&lt;/h3&gt;&lt;p cid=&quot;n79&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;通过上面的分析，我们知道维表 JOIN 实际上基于 Flink SQL 的 LookupTableSource 实现。LookupTableSource 的 scan 逻辑基于 UDF LookupFunction，当事实表的数据到来时，调用 LookupFunction 的 eval 方法，前往外部数据源进行关联查询。代码详情请关注 &lt;span md-inline=&quot;plain&quot;&gt;LookupTableSource.java&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n80&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;LookupFunction 的实现通常分为以下几个部分：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot; start=&quot;&quot; cid=&quot;n81&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n83&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在 open() 方法中建立并维护与外部系统的连接；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n85&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;eval() 方法实现与外部系统的关联逻辑。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 cid=&quot;n86&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;Flink SQL 维表 JOIN 的优化&lt;/span&gt;&lt;/h2&gt;&lt;h3 cid=&quot;n87&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;维表 JOIN 的常见问题&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n88&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;维表 Join 的默认策略是实时、同步查询维表，每条流数据到来时，在 Flink 算子中直接访问维表数据源来进行关联。这种方式可以保证维表数据是最新的，但是当数据流量过大时，频繁的维表实时查询会对外部系统带来巨大的压力，可能导致连接失败、处理线程打满等情况，出现线程阻塞、数据返回缓慢等后果，影响任务整体的吞吐量。而且这种方案对外部系统能承受的 QPS 要求较高，在大数据实时计算场景下，QPS 远高于普通的后台系统，峰值高达百万甚至千万，导致整体作业处理瓶颈转移到外部系统。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n89&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;此外，维表并不是永远不变的，而维表的变化可能导致无法关联。例如维表有新增维度，而 JOIN 操作发生在维度新增之前，由于维表 JOIN 只能关联处理时间的快照，就会导致事实数据关联不上。这也是很多用户的使用痛点。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n90&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;优化点 1：Async I/O&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n91&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;维表 JOIN 默认为同步访问方式，上游每输入一条数据就会前往外部表中查询一次，等待返回后输出关联结果，期间的网络耗时与外部表的查询延迟极大地阻碍了流作业的吞吐，加大了数据处理延迟。为了解决同步访问外部数据源的问题，可以引入异步模式处理查询请求，使得连续的关联请求之间不需要阻塞等待。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n92&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;同步请求和异步请求外部维表，对比图如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6659877800407332&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/o2eWePa4j5BpUW2Lg5mrf9PLADZHgia3INEZ6sf1OQjrLR8zfKf8sdoPR5tLVrHFMZHZdzibPFSRfgS0wzAq43Mw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;491&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n94&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;基于 Flink Async I/O 和异步客户端，我们可以实现维表 JOIN 的异步化，极大地提高维表 JOIN 的吞吐率。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n95&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在 Flink SQL 中，通过继承 AsyncTableFunction，实现异步的 eval() 方法，即可完成异步维表 JOIN。以 HBaseAsyncLookupFunction [2] 为例，简单分析异步化维表 JOIN 的实现：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;java&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__class&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;HBaseRowDataAsyncLookupFunction&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;AsyncTableFunction&lt;/span&gt;&amp;lt;&lt;span class=&quot;code-snippet__title&quot;&gt;RowData&lt;/span&gt;&amp;gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__meta&quot;&gt;@Override&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(FunctionContext context)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__keyword&quot;&gt;final&lt;/span&gt; ExecutorService threadPool =&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;              Executors.newFixedThreadPool(&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                      THREAD_POOL_SIZE,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                      &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; ExecutorThreadFactory(&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                              &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;hbase-async-lookup-worker&quot;&lt;/span&gt;, Threads.LOGGING_EXCEPTION_HANDLER));&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      Configuration config = prepareRuntimeConfiguration();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;       &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      CompletableFuture&amp;lt;AsyncConnection&amp;gt; asyncConnectionFuture =&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;              ConnectionFactory.createAsyncConnection(config);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      asyncConnection = asyncConnectionFuture.get();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      table = asyncConnection.getTable(TableName.valueOf(hTableName), threadPool);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__keyword&quot;&gt;this&lt;/span&gt;.serde = &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; HBaseSerde(hbaseTableSchema, nullStringLiteral);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(CompletableFuture&amp;lt;Collection&amp;lt;RowData&amp;gt;&amp;gt; future, Object rowKey)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      Get get = serde.createGet(rowKey);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      CompletableFuture&amp;lt;Result&amp;gt; responseFuture = table.get(get);        &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      responseFuture.whenCompleteAsync(&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;          (result, throwable) -&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;              &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (throwable != &lt;span class=&quot;code-snippet__keyword&quot;&gt;null&lt;/span&gt;) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;              &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;              resultFuture.completeExceptionally(&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                      &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; RuntimeException(&lt;span class=&quot;code-snippet__string&quot;&gt;&quot;HBase table &#x27;&quot;&lt;/span&gt; + hTableName + &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;&#x27; not found.&quot;&lt;/span&gt;,throwable));&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;              } &lt;span class=&quot;code-snippet__keyword&quot;&gt;else&lt;/span&gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                  RowData rowData = serde.convertToNewRow(result);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                  resultFuture.complete(Collections.singletonList(rowData));&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;              }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;          }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      )&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p cid=&quot;n95&quot; mdtype=&quot;paragraph&quot;&gt;从代码中可以看出，维表 JOIN 异步化的关键点在于：&lt;span md-inline=&quot;plain&quot;/&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot; start=&quot;&quot; cid=&quot;n98&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n100&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;需要支持异步查询的外部数据源客户端；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n102&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;eval 方法中使用 CompletableFuture 处理异步请求的结果。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 cid=&quot;n103&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;优化点 2：维表缓存&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n104&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;除了将同步查询改为异步，我们还可以缓存维表中的数据，保存到 Flink 作业 TaskManager 的内存中，流数据到来时，只需要查询本地缓存中的数据，无需与远程数据源进行交互，可以极大提升数据处理的吞吐量。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n105&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;维表缓存的实现有多种方式，可以用一张表格进行总结：&lt;/span&gt;&lt;/p&gt;&lt;figure cid=&quot;n106&quot; mdtype=&quot;table&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr cid=&quot;n107&quot; mdtype=&quot;table_row&quot;&gt;&lt;th&gt;&lt;span cid=&quot;n108&quot; mdtype=&quot;table_cell&quot;&gt;缓存类型&lt;/span&gt;&lt;/th&gt;&lt;th&gt;&lt;span cid=&quot;n109&quot; mdtype=&quot;table_cell&quot;&gt;实现细节&lt;/span&gt;&lt;/th&gt;&lt;th&gt;&lt;span cid=&quot;n110&quot; mdtype=&quot;table_cell&quot;&gt;优点&lt;/span&gt;&lt;/th&gt;&lt;th&gt;&lt;span cid=&quot;n111&quot; mdtype=&quot;table_cell&quot;&gt;缺点&lt;/span&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr cid=&quot;n112&quot; mdtype=&quot;table_row&quot;&gt;&lt;td&gt;&lt;span cid=&quot;n113&quot; mdtype=&quot;table_cell&quot;&gt;全量缓存&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span cid=&quot;n114&quot; mdtype=&quot;table_cell&quot;&gt;LookupFunction 的 open() 方法中预加载维表全量数据，并保存到本地缓存中。eval() 方法先查询缓存，无法找到再查询维表外部数据源。&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span cid=&quot;n115&quot; mdtype=&quot;table_cell&quot;&gt;1.实现简单；2.有效提高维表 JOIN 的吞吐。&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span cid=&quot;n116&quot; mdtype=&quot;table_cell&quot;&gt;1.数据全量保存，无法应对超大维表；2.维表数据更新比较困难。&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr cid=&quot;n117&quot; mdtype=&quot;table_row&quot;&gt;&lt;td&gt;&lt;span cid=&quot;n118&quot; mdtype=&quot;table_cell&quot;&gt;LRU 缓存&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span cid=&quot;n119&quot; mdtype=&quot;table_cell&quot;&gt;LookupFunction 的 open() 方法中初始化 LRU 缓存。eval() 方法先查询缓存，无法找到再查询维表外部数据源，返回的结果存入缓存以备下次查询。需要设置缓存 TTL 和缓存 Size 来控制缓存数据的失效时间和缓存大小。&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span cid=&quot;n120&quot; mdtype=&quot;table_cell&quot;&gt;1.降低数据库的查询压力；2.降低内存消耗。&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span cid=&quot;n121&quot; mdtype=&quot;table_cell&quot;&gt;1.QPS 很高的情况下缓存命中率较低；2.需要合理设置 TTL 和缓存大小。&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr cid=&quot;n122&quot; mdtype=&quot;table_row&quot;&gt;&lt;td&gt;&lt;span cid=&quot;n123&quot; mdtype=&quot;table_cell&quot;&gt;Partitioned 缓存&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span cid=&quot;n124&quot; mdtype=&quot;table_cell&quot;&gt;LookupFunction 的 open() 方法中初始化 LRU/全量 缓存。事实数据关联维表前，先按照 JOIN Key 进行 Hash 操作。&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span cid=&quot;n125&quot; mdtype=&quot;table_cell&quot;&gt;每个 Subtask 加载所需的维表数据到缓存，降低内存消耗，提高吞吐。&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span cid=&quot;n126&quot; mdtype=&quot;table_cell&quot;&gt;Hash 操作消耗额外的网络和CPU资源。&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p cid=&quot;n127&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;全量缓存和 LRU 缓存的实现都比较简单，只需调整 LookupFunction 即可，而 Partitioned 缓存的实现涉及的改动点很多，下面进行详细分析。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n128&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;通过观察作业拓扑和执行计划，我们发现 Cacl 算子和 LookupJoin 算子是 Chain 在一起的。维表 JOIN 是一种等值 JOIN，天然具有 Hash 属性，如果能在 Cacl 算子和 LookupJoin 算子之间生成 Hash 算子，即可实现 Partitioned cache。&lt;/span&gt;&lt;/p&gt;&lt;h4 cid=&quot;n129&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;方案 1&lt;/span&gt;&lt;/h4&gt;&lt;p cid=&quot;n130&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;方案1：在 ExecNodeGraph 生成 Transformation 时进行调整。考虑在 CaclTransformation 和 LookupJoin Transformation 之间添加 PartitionTransformation。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n131&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;修改 LookupJoin 对应的 ExecNode &lt;code&gt;CommonExecLookupJoin&lt;/code&gt;，调整 &lt;code&gt;translateToPlanInternal()&lt;/code&gt;方法，在生成的 outputTransformation 和上游的 inputTransformation 之间添加 PartitionTransformation，根据 JOIN Key 进行 Hash。&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;java&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; Transformation&amp;lt;RowData&amp;gt; &lt;span class=&quot;code-snippet__title&quot;&gt;translateToPlanInternal&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(PlannerBase planner)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  Transformation&amp;lt;RowData&amp;gt; inputTransformation =&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            (Transformation&amp;lt;RowData&amp;gt;) inputEdge.translateToPlan(planner);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt;[] hashKeys = lookupKeys.keySet().stream().mapToInt(key -&amp;gt; key).toArray();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;final&lt;/span&gt; RowDataKeySelector keySelector =&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        KeySelectorUtil.getRowDataSelector(hashKeys, InternalTypeInfo.of(inputRowType));&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;final&lt;/span&gt; StreamPartitioner&amp;lt;RowData&amp;gt; partitioner =&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; KeyGroupStreamPartitioner&amp;lt;&amp;gt;(&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            keySelector, DEFAULT_LOWER_BOUND_MAX_PARALLELISM);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;final&lt;/span&gt; Transformation&amp;lt;RowData&amp;gt; partitionTransformation =&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; PartitionTransformation&amp;lt;&amp;gt;(inputTransformation, partitioner);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    partitionTransformation.setParallelism(inputTransformation.getParallelism());&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    OneInputTransformation&amp;lt;RowData, RowData&amp;gt; inputTransform = &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; OneInputTransformation&amp;lt;&amp;gt;(&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        partitionTransformation,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        getDescription(),&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        operatorFactory,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        InternalTypeInfo.of(resultRowType),&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        partitionTransformation.getParallelism());&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    inputTransform.setParallelism(partitionTransformation.getParallelism());&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    inputTransform.setOutputType(InternalTypeInfo.of(resultRowType));&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; inputTransform;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p cid=&quot;n131&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;方案 2&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n134&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;方案 2：在 Logical 优化阶段为节点添加 Hash FlinkRelDistribution Trait，在 Physical 优化阶段该 Trait 会生成 StreamPhysicalExchange Node。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n135&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;在 &lt;code&gt;StreamPhysicalLookupJoinRule.doTransform()&lt;/code&gt; 中将 FlinkLogicalRel 中的默认 FlinkRelDistribution Trait 替换成 Hash。&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;properties&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;def doTransform(&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;join&lt;/span&gt;: &lt;span class=&quot;code-snippet__string&quot;&gt;FlinkLogicalJoin,&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;input&lt;/span&gt;: &lt;span class=&quot;code-snippet__string&quot;&gt;FlinkLogicalRel,&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;temporalTable&lt;/span&gt;: &lt;span class=&quot;code-snippet__string&quot;&gt;RelOptTable,&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;calcProgram&lt;/span&gt;: &lt;span class=&quot;code-snippet__string&quot;&gt;Option[RexProgram]): StreamPhysicalLookupJoin = {&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;joinInfo = join.analyzeCondition&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;cluster = join.getCluster&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;providedTrait = join.getTraitSet.replace(FlinkConventions.STREAM_PHYSICAL)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;requiredTrait = input.getTraitSet.replace(FlinkConventions.STREAM_PHYSICAL)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;options = temporalTable.asInstanceOf[TableSourceTable].catalogTable.getOptions&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__meta&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;获取维表配置&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;enablePartitionedCache = options.getOrDefault(&quot;lookup.enable-partitioned-cache&quot;, &quot;false&quot;).toBoolean&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;(enablePartitionedCache) {&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__attr&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;requiredDistribution = FlinkRelDistribution.hash(joinInfo.leftKeys, true)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__attr&quot;&gt;requiredTrait&lt;/span&gt; = &lt;span class=&quot;code-snippet__string&quot;&gt;input.getTraitSet&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__meta&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;替换 FlinkRelDistributionTraitDef&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__attr&quot;&gt;.replace(requiredDistribution)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__attr&quot;&gt;.replace(FlinkConventions.STREAM_PHYSICAL)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;convInput = RelOptRule.convert(input, requiredTrait)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__attr&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;StreamPhysicalLookupJoin(&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__attr&quot;&gt;cluster,&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__attr&quot;&gt;providedTrait,&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__attr&quot;&gt;convInput,&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__attr&quot;&gt;temporalTable,&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__attr&quot;&gt;calcProgram,&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__attr&quot;&gt;joinInfo,&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__attr&quot;&gt;join.getJoinType)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p cid=&quot;n135&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;优化点 3：批量关联&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n138&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;维表 JOIN 时，攒一批数据以后调用维表的批量查询接口，进行批量关联，可以减少 RPC 的调用次数，提高吞吐量。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n139&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;批量关联的实现可以分为以下步骤：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot; start=&quot;&quot; cid=&quot;n140&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n142&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;添加是否开启 Batch JOIN 对应的配置，设置 Batch Size 和 Batch 触发 TTL；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n144&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;CommonExecLookupJoin 构造 ProcessFunction 时，根据是否开启 Batch JOIN 配置分别构造 LookupJoinRunner 或 BatchLookupJoinRunner；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n146&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;BatchLookupJoinRunner 的 processElement() 方法中实现攒批逻辑，使用 ListState 攒批，通过 timer 触发 批量关联操作；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n148&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;调整 CodeGen 相关类，为 BatchLookupJoinRunner 对应的 generatedFetcher、generatedCollector 和 generatedCalc 赋予正确的输入和输出：&lt;code&gt;List&amp;lt;RowData&amp;gt;&lt;/code&gt;；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n150&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;LookupFunction 的 eval 方法调用批量查询接口。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 cid=&quot;n151&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;优化点 4：延迟关联&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n152&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;由于维表 JOIN 只能关联处理时间的快照，可能导致事实数据无法关联更新后的维度，造成关联失败。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n153&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;对于这种场景，我们可以实现延迟关联功能。如果 Join 没有命中，数据无法关联，可以暂时将事实数据缓存在 Flink State 中，等待一段时间后进行重试，并且可以控制等待时间与重试次数。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n154&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;延迟关联的实现可以分为以下步骤：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot; start=&quot;&quot; cid=&quot;n155&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n157&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;添加是否开启 Delay JOIN 对应的配置，设置 Delay Join Intervals 和 RetryTimes；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n159&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;CommonExecLookupJoin 构造 ProcessFunction 时，根据是否开启 Delay JOIN 配置分别构造 LookupJoinRunner 或 DelayedLookupJoinRunner；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n161&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;DelayedLookupJoinRunner 的 processElement() 方法中实现延迟 JOIN 逻辑，如果无法关联则将事实数据保存在 ListState 中，通过设置 timer 和重试次数，延时触发关联操作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 cid=&quot;n163&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p cid=&quot;n164&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;本文简述了 Flink SQL 维表 JOIN 的用法与原理，分析了维表 JOIN 遇到的主要问题，并提供了多种维表 JOIN 的优化思路与具体实现方案。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n165&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;流计算 Oceanus 是大数据产品生态体系的实时化分析利器，是基于 Apache Flink 构建的具备一站开发、无缝连接、亚秒延时、低廉成本、安全稳定等特点的企业级实时大数据分析平台。流计算 Oceanus 针对常见的 JOIN 场景也有自己独特的性能优化，欢迎大家体验 1 元试用[3]，也欢迎阅读流计算 Oceanus 的专栏文章[4] 。&lt;/span&gt;&lt;/p&gt;&lt;h2 cid=&quot;n166&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;附录&lt;/span&gt;&lt;/h2&gt;&lt;p cid=&quot;n167&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;[1] CommonExecLookupJoin.java 源码。链接：&lt;/span&gt;&lt;span md-inline=&quot;url&quot; spellcheck=&quot;false&quot;&gt;https://github.com/apache/flink/blob/1f3324071a36ef78719e631fbac61c55b1ee3600/flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/common/CommonExecLookupJoin.java#L214&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n168&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;[2] HBaseRowDataAsyncLookupFunction.java 源码。链接：&lt;/span&gt;&lt;span md-inline=&quot;url&quot; spellcheck=&quot;false&quot;&gt;https://github.com/apache/flink/blob/master/flink-connectors/flink-connector-hbase-2.2/src/main/java/org/apache/flink/connector/hbase2/source/HBaseRowDataAsyncLookupFunction.java&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n169&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;[3] 流计算 Oceanus 一元试用活动。链接：&lt;/span&gt;&lt;span md-inline=&quot;url&quot; spellcheck=&quot;false&quot;&gt;https://cloud.tencent.com/developer/article/1885095&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n170&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;[4] 流计算 Oceanus 专栏。链接：&lt;/span&gt;&lt;span md-inline=&quot;url&quot; spellcheck=&quot;false&quot;&gt;https://cloud.tencent.com/developer/tag/10509&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n165&quot; mdtype=&quot;paragraph&quot;&gt;&lt;em&gt;&lt;strong&gt;扫码加入 流计算 Oceanus 产品交流群👇&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.544&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/o2eWePa4j5BpUW2Lg5mrf9PLADZHgia3IWtE048MNaSRdVRaT1UNo7KO5xP39jDrjegqSno4EHicmO0aTM80A5Aw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;500&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzNTc0NTcyMw==&amp;amp;mid=2247486172&amp;amp;idx=1&amp;amp;sn=9e07440d545ecd090c87734445aaed9d&amp;amp;chksm=fa818f08cdf6061e553f8fe283dc29ae5b870fac1c1daeed39bb2d1785379ce7d076c9c6390f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;流计算 Oceanus 限量秒杀专享活动火爆进行中↓↓&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;流计算 Oceanus &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;限量秒杀专享活动火爆进行中↓↓&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;2.424074074074074&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/o2eWePa4j5C6NlicUVzE4iasrmERfbyiam9eWJjyUvkZMmskXpLm4btib91a3O7IR5eRngjB8ib0dOtJD9TJwmJAyOw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;扫码关注&lt;/span&gt;&lt;/span&gt;&lt;span&gt;「腾讯云大数据」&lt;/span&gt;&lt;span&gt;，了解腾讯云流计算 Oceanus 更多信息&lt;/span&gt;&lt;/em&gt;&lt;em&gt;&lt;span&gt;~&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section label=&quot;Copyright © 2016 playhudong All Rights Reserved.&quot; donone=&quot;shifuMouseDownPayStyle(&#x27;shifu_sig_022&#x27;)&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;腾讯云大数据&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100002699&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/o2eWePa4j5DaCQzdVZibTicwrQId09Q0DzibuXlpp9fRibyulbDiafDHDk1ImSnbiaJ7PUHiajfOQLQlnLiczls7BVJFqQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; title=&quot;https://image.ipaiban.com/upload-ueditor-image-20200619-1592556685554099336.jpg&quot;/&gt;&lt;/section&gt;&lt;section data-remoteid=&quot;c1653633225119&quot;&gt;&lt;p&gt;&lt;span&gt;长按二维码&lt;br/&gt;关注我们&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>