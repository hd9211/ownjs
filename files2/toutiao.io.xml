<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>3ef105562296968c1b917a3e0f0b0b36</guid>
<title>建木持续集成平台 v1.0.0 发布</title>
<link>https://toutiao.io/k/5q2gy9v</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;container app-preview post-body&quot;&gt;
  &lt;div class=&quot;preview&quot;&gt;&lt;p&gt;建木持续集成平台是基于建木自动化平台提供的国产开源CI/CD产品，致力于为国内开发者提供简单易用、方便快捷的开发体验，推广DevOps的最佳实践，填补国内开源软件供应链中缺失的一环。&lt;/p&gt;

&lt;p&gt;建木持续集成平台v1.0.0现已发布&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;主要功能：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;事件桥接器：提供外部系统触发流程执行的事件桥接转换机制，当前只支持Webhook方式调用。&lt;/li&gt;
&lt;li&gt;配置即代码：提供两种不同的DSL语法来描述配置CI/CD流程。同时支持本地创建和远程Git导入两种方式来创建项目，可以支持GitOps的最佳实践。&lt;/li&gt;
&lt;li&gt;流程可视化：提供CI/CD流程的可视化展示，流程节点编排依赖与执行情况一目了然&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://ci.jianmu.dev&quot;&gt;详见官方项目示例&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.jianmu.dev/guide/quick-start.html&quot;&gt;快速开始&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://jianmu.dev&quot;&gt;官网首页&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>3837321b75fc204900015fb80dd2ecc5</guid>
<title>ElasticSearch 基础之分布式查询的执行</title>
<link>https://toutiao.io/k/quxpiua</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;entry-inner&quot;&gt;
                                                    
&lt;p&gt;我们在之前的《&lt;a href=&quot;https://donggeitnote.com/2021/08/25/elasticsearch-distribute-storage/&quot;&gt;ElasticSearch基础之分布式存储&lt;/a&gt;》中详细介绍了ElasticSearch是如何进行分布式的读写（CRUD）。那我们在发送查找请求之后，ElasticSearch是如何进行分布式执行的呢？它其实要比我们前面提到的CRUD操作复杂一些，本文就来详细介绍一下这一方面的知识。&lt;/p&gt;



&lt;p&gt;前面的CRUD操作其实只是针对某一个shard的，也就是说我们其实是知道我们的操作最终会指向哪一个shard的， 而search相对来说复杂的地方就在于我们根本不知道要查找的内容是存储在哪一个shard上，这就必然导致我们需要去访问每一个shard，或者说至少是我们感兴趣的shard。然后访问不同（所有）shard得到的数据其实只完成了一部分的工作，你还需要把各个shard返回的内容进行整合，排序或者筛选出最终返回给用户的那一部分数据并把它们从各个shard提取出来。因此我们可以简单认为search其实包含了两个部分的操作，一个是查询一个是提取。&lt;/p&gt;



&lt;h1&gt;查询&lt;/h1&gt;



&lt;p&gt;查询过程其实说白了也很简单，它在开始的时候会把你的query发送到index上所有的shard（有可能是primary也可能是replica的shard），然后在各个shard上执行查询，并根据相匹配的文档生成一个priority queue。具体可以参见下面的流程图：&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://donggeitnote.com/wp-content/uploads/2021/09/image-20.png&quot; alt=&quot;&quot; class=&quot;wp-image-943&quot; srcset=&quot;https://donggeitnote.com/wp-content/uploads/2021/09/image-20.png 624w, https://donggeitnote.com/wp-content/uploads/2021/09/image-20-300x141.png 300w, https://donggeitnote.com/wp-content/uploads/2021/09/image-20-520x245.png 520w&quot; sizes=&quot;(max-width: 624px) 100vw, 624px&quot;/&gt;&lt;/figure&gt;



&lt;ol type=&quot;1&quot;&gt;&lt;li&gt;首先假设client端会把search的request发送到node3，这里首先会create一个空的priority queue，大小就是from+size。这里from就是页码，比如说我们每页返回10条记录，我想看第三页的，那么from这里就设为20，size就是10。&lt;/li&gt;&lt;li&gt;Node3会把这个request转发给cluster中所有的相关shard，可能是primary也可能是replica，每个shard会在本地执行相关的request，并把它们的结果加入到本地的priority queue中，每个priority queue的大小也是from+size。&lt;/li&gt;&lt;li&gt;每个shard都会把它们的结果返回给node3，node3这里会进行merge的操作，同样取最前面的from+size放到全局的priority queue中。&lt;/li&gt;&lt;/ol&gt;



&lt;p&gt;整个流程还是蛮清晰的，node3负责接收request和返回response，它也负责分发request到各个shard，并merge最终得到的结果。这里假如你仔细观察会发现其实from这个值对我们需要查询的内容有很大的影响，同样是查询10条数据，假如from==0，也就是第一页，你就只要查询10条，但是假如from是9，也就是第10页，它就需要查询100条数据，这在分散到各个shard上，查询的数据就更大了。这也是为什么有些查询不支持太多的页，一方面是因为排序在后面的内容其实意义也不是很大，另一方面也是考虑这个查询的效率问题。&lt;/p&gt;



&lt;h1&gt;提取&lt;/h1&gt;



&lt;p&gt;上面查询就是确定哪些文本是符合最终的需求的，在有了这些信息之后，下一步要做的就是把这些文本提取出来，这就是提取这一步要做的事情，大体的流程见下图：&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://donggeitnote.com/wp-content/uploads/2021/09/image-21.png&quot; alt=&quot;&quot; class=&quot;wp-image-944&quot; srcset=&quot;https://donggeitnote.com/wp-content/uploads/2021/09/image-21.png 624w, https://donggeitnote.com/wp-content/uploads/2021/09/image-21-300x137.png 300w&quot; sizes=&quot;(max-width: 624px) 100vw, 624px&quot;/&gt;&lt;/figure&gt;



&lt;ol type=&quot;1&quot;&gt;&lt;li&gt;Node3从查询阶段得到了符合要求的文本列表，它会根据这个列表发送Get请求到各个shard来获取相关的文本内容。&lt;/li&gt;&lt;li&gt;每一个shard都加载相关的文本，并有可能附加一些额外的信息（metadata或者高亮文本之类的），然后返回给node3.&lt;/li&gt;&lt;li&gt;Node3接收到所有的文本内容，返回给client端。&lt;/li&gt;&lt;/ol&gt;



&lt;p&gt;Node3在第一步会计算一下哪些文本真正的需要提取，比如说像我们上面提到的例子，from是9，那么其实前面的90条记录是不需要去进行提取的，只需要提取91到100这一范围的文本就可以了。&lt;/p&gt;



&lt;h1&gt;查询的选项&lt;/h1&gt;



&lt;p&gt;上面提到的整个流程其实是一个通用情况的流程，其实有很多查询参数也会影响这个流程：&lt;/p&gt;



&lt;h2&gt;Preference&lt;/h2&gt;



&lt;p&gt;假如你仔细阅读上面的流程，你会发现我们在查询的时候并不一定是要去访问所有的shard，这里其实是可以控制的，甚至哪些node需要访问都是可以通过preference来设置的。&lt;/p&gt;



&lt;p&gt;你可以设置这个参数为_primary, _primary_first, _local, _only_node:xyz,_prefer_node:xyz或者_shards:2,3等等，不需要我详细介绍各个设置的意义应该还是蛮明显的。&lt;/p&gt;



&lt;h2&gt;Timeout&lt;/h2&gt;



&lt;p&gt;这个也比较好理解，我们毕竟要访问很多不同的shard，这个过程中什么都有可能发生，不可能无限制的等待下去，所以会有一个超时的机制，当超过了这段时间我们就不再等待相应shard的返回了，这个结果会显示在最终的返回结果中，如下所示：&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://donggeitnote.com/wp-content/uploads/2021/09/image-22.png&quot; alt=&quot;&quot; class=&quot;wp-image-945&quot; srcset=&quot;https://donggeitnote.com/wp-content/uploads/2021/09/image-22.png 624w, https://donggeitnote.com/wp-content/uploads/2021/09/image-22-300x102.png 300w&quot; sizes=&quot;(max-width: 624px) 100vw, 624px&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;这里就是有超时发生，总共有5个shard，其中有一个没有在规定时间内返回结果。我们也可以通过这个域来判断是不是所有的shard都出现了问题。&lt;/p&gt;



&lt;h2&gt;Routing&lt;/h2&gt;



&lt;p&gt;我们在index的时候可以根据routing来把相关的文档都放在同样的shard中，那么显然在查询的时候我们也可以通过设置这个参数来控制查询所涉及的shard。比如说下面这个request就只touch user1和user2所在的shard。&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://donggeitnote.com/wp-content/uploads/2021/09/image-23.png&quot; alt=&quot;&quot; class=&quot;wp-image-946&quot; srcset=&quot;https://donggeitnote.com/wp-content/uploads/2021/09/image-23.png 624w, https://donggeitnote.com/wp-content/uploads/2021/09/image-23-300x24.png 300w&quot; sizes=&quot;(max-width: 624px) 100vw, 624px&quot;/&gt;&lt;/figure&gt;



&lt;h2&gt;Search_type&lt;/h2&gt;



&lt;p&gt;其实我们上面提到的查询-提取只是一个默认的操作，我们是可以通过search_type来控制的，它可以设置为下面这些值：&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;Count：这个就只有查询的步骤，不会去进行提取。一般用在我们不需要知道具体文档的情况下，比如有多少个查询结果之类的。&lt;/li&gt;&lt;li&gt;Query_and_fetch：这个就是我们上面提到的查询和提取。&lt;/li&gt;&lt;li&gt;Dfs_query_then_fetch/dfs_quey_and_fetchg：这个设置中有一个预查询的步骤，他们会从所有相关的shard中获取term的frequency来决定一个global的term frequency。这个主要是用来防止relevance计算出问题。我们在《&lt;a href=&quot;https://donggeitnote.com/2021/09/19/elasticsearch-tfidf/&quot;&gt;Elasticsearch基础之相关性介绍&lt;/a&gt;》中详细介绍了relevance的计算，这里有一个概念，就是相关性其实和term出现的频率有关系，假如term在某一个shard中出现的频率太高或者太低，那么就会影响它在那个shard中分数的计算，从而在我们合并多个shard进行比较的时候不公平，所以这里我们会通过这个设置来得到一个全局的频率从而减小这个误差。当然在数据量很大的系统中，没有必要这么做，这个在一些比较小数据量的测试系统中会常常遇到。&lt;/li&gt;&lt;li&gt;Scan：这个主要是和scroll来配合的，主要是用来高效查询大数据量的结果，它不会进行各个shard之间的排序。主要是用来快速返回大量数据的情况下。&lt;/li&gt;&lt;/ul&gt;



&lt;h1&gt;总结&lt;/h1&gt;



&lt;p&gt;至此本文就详细介绍了ElasticSearch是如何进行分布式查询的，并介绍了几个常见的参数。&lt;/p&gt;
                                                    &lt;nav class=&quot;pagination group&quot;&gt;
                      &lt;/nav&gt;
        &lt;/div&gt;

        
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9fac77494d69828fa995f8b5f3dbca14</guid>
<title>用 Python 快速做一个国庆头像</title>
<link>https://toutiao.io/k/3wnq8j3</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;又到了一年一度的国庆假期七天乐，互联网公司的 IT 小能手们，终于又回到久违的家中，立即变身父母的&lt;em&gt;乖宝&lt;/em&gt;、另一半的&lt;em&gt;臭宝&lt;/em&gt;，或是&lt;em&gt;小宝&lt;/em&gt;们的超级奶妈奶爸；现代社会的节奏就是这样快，彷佛头一天还忙忙碌碌的对需求、过排期、写代码的生活已经恍若隔世一般了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大部分的人的假期安排其实也不复杂，就是那句能瞬间激活小孩和狗的魔法口令 -- &lt;strong&gt;出去玩！&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不管是惬意的郊游、热闹的街头，还是人头攒动的景区，掏出手机咔咔一通的自拍合影是必不可少的了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时家里的老人可能会提出一个需求 -- &lt;strong&gt;把自拍或家庭合影的手机照片做成微信头像&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随着智能手机和微信在中老年群体中的普及，这样的需求往往是大概率甚至高频的，一个好的微信头像，既能彰显家庭的和睦幸福，也能在国画班、广场舞天团中收获艳羡的目光。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但一个小问题随之产生 -- 微信默认的头像处理界面，只能截取手机照片的一个正方形区域，而无法保留全部图片，这可能造成&lt;strong&gt;家庭合影无法完整呈现&lt;/strong&gt;的问题。&lt;img data-ratio=&quot;1.7870967741935484&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/aqicFmRvjIbhj6sFGu02BY9ia17kknicCbdZJcYGToQibOZK2gcTzKLWyIicqI1HuibUkVqOeTCYlqZibgal0NVAcIBQg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;620&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;微信默认的头像处理&lt;/figcaption&gt;&lt;p&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;要是能将手机照片自动放置到一个正方形区域中，并且用颜色相近的模糊效果填充背景，那就好了～&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如下面的照片：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.5&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/aqicFmRvjIbhj6sFGu02BY9ia17kknicCbd3tZ3YD2HDP1OwaaqnUcaePJVrXcx0Un5qPcJ6ibkGlkZ9loibBLyXVvA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;500&quot;/&gt;&lt;figcaption&gt;原图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果做成我们期望的效果，再加个圆形小效果，多好！&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/aqicFmRvjIbhj6sFGu02BY9ia17kknicCbdXVUEo1DtfxqFK4iaBsaymqzmThYeiaOI0hia5QsBRE7Sw6v851GycicrzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;figcaption&gt;期望的效果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果用 PS 一张张处理图片，一来太麻烦，二来大部分人也搞不来。还好这年头互联网公司中，无论是专业的程序员还是产品经理、运营、测试的同学，好像人人都会写点 SQL 或 Python 啥的，这不就成了嘛～&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说干就干，请出懒人小助手 Python 君，用不了几行代码就能达到我们的效果！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;新建一个 circle.py 文件：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; os&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; re&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; sys&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; PIL &lt;span&gt;import&lt;/span&gt; Image, ImageFilter, ImageDraw, ImageOps&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先引入了一些系统库和 PIL，这是 Python 平台最常用的图片处理工具集，算得上事实上的图像处理标准库了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但由于 PIL 本身仅支持到 Python 2.7，我们可以直接安装叫做 pillow 的兼容版本，既支持最新的 Python 3.x，又加入了许多新特性，用下面的命令就可以安装了：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;pip3 install pillow&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后来声明一个函数：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;make_circle&lt;/span&gt;&lt;span&gt;(path, maxS = &lt;span&gt;600&lt;/span&gt;)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;    foreImg = Image.open(path)&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; foreImg.mode &lt;span&gt;in&lt;/span&gt; (&lt;span&gt;&quot;RGBA&quot;&lt;/span&gt;, &lt;span&gt;&quot;P&quot;&lt;/span&gt;):&lt;br/&gt;        foreImg = foreImg.convert(&lt;span&gt;&#x27;RGB&#x27;&lt;/span&gt;)&lt;br/&gt;    &lt;br/&gt;    h,w = foreImg.size&lt;br/&gt;    maxSize = max(h, w)&lt;br/&gt;    imgPosi = (int((maxSize - h) / &lt;span&gt;2&lt;/span&gt;), int((maxSize - w) / &lt;span&gt;2&lt;/span&gt;))&lt;br/&gt;    bgBlur = ImageFilter.GaussianBlur(radius=&lt;span&gt;6.18&lt;/span&gt;)&lt;br/&gt;    bgSize = (maxSize, maxSize)&lt;br/&gt;    &lt;br/&gt;    backImg = foreImg.copy()&lt;br/&gt;    backImg = backImg.resize(bgSize)&lt;br/&gt;    backImg = backImg.filter(bgBlur)&lt;br/&gt;    backImg.paste(foreImg, imgPosi)&lt;br/&gt;    &lt;br/&gt;    mask = Image.new(&lt;span&gt;&#x27;L&#x27;&lt;/span&gt;, bgSize, &lt;span&gt;0&lt;/span&gt;)&lt;br/&gt;    draw = ImageDraw.Draw(mask) &lt;br/&gt;    draw.ellipse((&lt;span&gt;0&lt;/span&gt;, &lt;span&gt;0&lt;/span&gt;) + bgSize, fill=&lt;span&gt;255&lt;/span&gt;)&lt;br/&gt;    &lt;br/&gt;    backImg = ImageOps.fit(backImg, mask.size, centering=(&lt;span&gt;0.5&lt;/span&gt;, &lt;span&gt;0.5&lt;/span&gt;))&lt;br/&gt;    backImg.putalpha(mask)&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; maxSize &amp;gt; maxS:&lt;br/&gt;        backImg = backImg.resize((maxS, maxS))&lt;br/&gt;    &lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; backImg&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这几行简短的代码比较清晰，基本就是按我们期望的顺序处理了目标路径的图片，相关的 API 查询 pillow 的文档即可，就不过多赘述了。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;file_name = sys.argv[&lt;span&gt;1&lt;/span&gt;]&lt;br/&gt;save_name = re.sub(&lt;span&gt;r&#x27;(jpg|jpeg)$&#x27;&lt;/span&gt;, &lt;span&gt;&#x27;png&#x27;&lt;/span&gt;, file_name.lower())&lt;br/&gt;img = make_circle(&lt;span&gt;&#x27;./&#x27;&lt;/span&gt; + file_name)&lt;br/&gt;img.save(&lt;span&gt;&#x27;./circle_&#x27;&lt;/span&gt; + save_name)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后几行是让程序接收命令行传入的文件名参数并执行处理函数的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;只需在终端中执行这样一条命令：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;python3 circle.py 1.jpg&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就能立即得到一张处理好的头像图片啦，方便又实用！&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5885416666666666&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/aqicFmRvjIbhj6sFGu02BY9ia17kknicCbdl0kUeBkRR1vFN9m0LBNSmXk2tjj7bOmL38xiceAhgZObZoxoBDGuQoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1152&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_iframe&quot; data-pluginname=&quot;videosnap&quot; data-id=&quot;export/UzFfAgtgekIEAQAAAAAA8DIGCKAwNgAAAAstQy6ubaLX4KHWvLEZgBPE5aNsBiYQUOr9zNPgMIvrHGcMGYXhOf-c4ZIVNoF7&quot; data-url=&quot;https://findermp.video.qq.com/251/20304/stodownload?encfilekey=S7s6ianIic0ia4PicKJSfB8EjyjpQibPUAXol5BJjoPRIREoChcjdjzctghzfSZuHWJv7erc2gJedLgp6L64icPia9ArNeicYZJ5Kw9a13JRJiahK5Ow&amp;amp;adaptivelytrans=0&amp;amp;bizid=1023&amp;amp;dotrans=0&amp;amp;hy=SZ&amp;amp;idx=1&amp;amp;m=&amp;amp;token=x5Y29zUxcibAU8R65MyqUGDvRIJSDS1MsFB8r3ctGKf25ePngsBFKm6Kce7TRCvQsaiaosg25WmFU&quot; data-headimgurl=&quot;http://wx.qlogo.cn/finderhead/liaxPQVRbzuNvpytkm8YoPG9oPzWh2IFWliccibUibTjVHQ/0&quot; data-username=&quot;v2_060000231003b20faec8c7e78b19c6d0cd0ceb30b0770919b36f1cce88d020d48d7c8f9f2385@finder&quot; data-nickname=&quot;云前端&quot; data-desc=&quot;#编程 术语古典史-8.维纳斯的诞生&quot; data-nonceid=&quot;11607277723412974211&quot; data-type=&quot;video&quot;/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，在视频号“云前端”的系列视频&lt;strong&gt;“编程术语古典史”&lt;/strong&gt;中，涉及希腊神话中众神的头像，也是用这个 Python 函数一键生成的哦，欢迎大家围观转发！&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6531901452937461&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/aqicFmRvjIbhj6sFGu02BY9ia17kknicCbd7X40Gs7wu4zfqqkicIE6ibEFic0nHZXgu7X0UxuT2RXRaqRWRibrEeiadQw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1583&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>ddf916061ce9d99f3f0eed30b17a6577</guid>
<title>开源｜一款本地优先的个人知识管理系统</title>
<link>https://toutiao.io/k/mksehc8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;一款本地优先的个人知识管理系统，支持细粒度块级引用和 Markdown 所见即所得。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.6133333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/t8lpVibticjQ40yO6oWpG0FibQH7RwiaE55zn5RjbSzxsAyzX8xFJO9IWdTQETrgdLE0V1MtuiazoaVXb0ibic6Wk1npg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;以上内容选自「码农周刊 VIP 会员」圈子，每日更新，精彩不断&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;码农周刊是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;码农周刊是一份专为广大程序员、编程爱好者们打造的 IT 技术周刊。每周发送。&lt;br/&gt;2013 年 9 月 12 日创刊至今，已发送 300 多期，订阅用户超 20 万。&lt;br/&gt;&lt;/span&gt;&lt;span&gt;专业、简单、有用&lt;/span&gt;&lt;span&gt;，是我们一直坚持的办刊宗旨。一路走来，我们见证了不少订阅用户从编程新手进阶成了高级程序员、架构师、CTO……&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;2020 年 4 月，为了给用户提供更优质的服务，我们推出了「&lt;/span&gt;&lt;span&gt;码农周刊VIP会员&lt;/span&gt;&lt;span&gt;」服务。&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;你与 BAT 技术大牛，只差一份「码农周刊VIP会员」的距离！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;VIP会员特权&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 52 期码农周刊VIP会员&lt;span&gt;专属邮件周报&lt;/span&gt;，让你及时掌握技术动向；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 只限VIP会员加入的&lt;span&gt;交流圈子&lt;/span&gt;，让你与技术大牛切磋学习；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. VIP会员独享的&lt;span&gt;工作机会&lt;/span&gt;，为你介绍好公司的好机会；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 更多会员特权，持续更新……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;如何加入「码农周刊VIP会员」？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1. 微信扫描下方二维码，加入码农周刊VIP会员知识星球。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;促销期间，一年仅需 108 元！平均一天花费不到 3 毛！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-cropselx1=&quot;34&quot; data-cropselx2=&quot;356&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;425&quot; data-ratio=&quot;1.0857487922705313&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/t8lpVibticjQ6h6x4EnYInRLic6PibFNWw4zSv28rAxcJu9dumVJF03PwHGOWxOzeJKIsydVa7UJuTo4jOjrct9NZw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;828&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 加入码农周刊VIP会员知识星球后，客服会联系您，请留意知识星球内的私信。&lt;br/&gt;3. 客服向您发送码农周刊VIP会员欢迎邮件，开启您的码农周刊VIP会员之旅。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;心动不如心动，赶快订阅吧！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>cb19d95e0277309a87eacb680bdf11d5</guid>
<title>Minerva：Airbnb 的大规模数据指标系统（三）</title>
<link>https://toutiao.io/k/jsdma77</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;blockquote&gt;&lt;p&gt;&lt;em&gt;这是Airbnb Minerva系列文章的第三篇，主要介绍Minerva如何为不同用户量身定制多功能的数据消费体验。原文：How Airbnb Enables Consistent Data Consumption at Scale&lt;span&gt;[1]&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2MTgxODgwNA==&amp;amp;mid=2247483890&amp;amp;idx=1&amp;amp;sn=b91ffef8a8c32fe24439afa367b0205a&amp;amp;chksm=fc73bc29cb04353f2de39edcd82c90e5300d1374b3a0806603bf8cb6b894d54043eb04ae0366&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Minerva -- Airbnb的大规模数据指标系统 Part 1&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Minerva -- Airbnb的大规模数据指标系统 Part 1&lt;br/&gt;&lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2MTgxODgwNA==&amp;amp;mid=2247483909&amp;amp;idx=1&amp;amp;sn=03c33e563c9edf8c92778e8f155d2557&amp;amp;chksm=fc73bfdecb0436c80078f63579f783a19df434b64ee79fcbc520e9c546df3ac940f0fd61638b&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Minerva -- Airbnb的大规模数据指标系统 Part 2&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Minerva -- Airbnb的大规模数据指标系统 Part 2&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.6666666666666666&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0VVcUKEa0ClxT4hXADLJuAwfQEsAtYD8KP1NGlcA6QwFbYZrS8qOFeEDgNsPl60l0OqPHzGBDgOmg/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1050&quot;/&gt;&lt;/p&gt;&lt;h3/&gt;&lt;h3&gt;简介&lt;/h3&gt;&lt;p&gt;在本系列的&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2MTgxODgwNA==&amp;amp;mid=2247483890&amp;amp;idx=1&amp;amp;sn=b91ffef8a8c32fe24439afa367b0205a&amp;amp;chksm=fc73bc29cb04353f2de39edcd82c90e5300d1374b3a0806603bf8cb6b894d54043eb04ae0366&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;第一篇文章&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;第一篇文章&lt;/a&gt;中，我们介绍了Minerva在改善Airbnb数据分析工作方面所起的作用。在&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2MTgxODgwNA==&amp;amp;mid=2247483909&amp;amp;idx=1&amp;amp;sn=03c33e563c9edf8c92778e8f155d2557&amp;amp;chksm=fc73bfdecb0436c80078f63579f783a19df434b64ee79fcbc520e9c546df3ac940f0fd61638b&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;第二篇文章&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;第二篇文章&lt;/a&gt;中，我们深入探讨了Minerva的核心计算基础设施，并介绍了我们如何保证数据集和团队数据的一致性。在第三篇也是最后一篇文章中，我们将重点讲述Minerva如何极大的简化和改善用户的数据消费体验。具体来说，我们将展示统一指标层（我们称之为Minerva API）如何帮助我们构建为具有广泛背景和不同级别数据专业知识的用户量身定制的多功能数据消费体验。&lt;/p&gt;&lt;h3&gt;以指标为中心的方法（A Metric-Centric Approach）&lt;/h3&gt;&lt;p&gt;当用户采用数据来探索业务问题时，通常会考虑不同的指标和维度。例如，业务负责人可能想知道长期住宿（维度）占预订（指标）的百分比是多少。要回答这个问题，首先要找到正确的表单（where），通过必要的联合（joins）或过滤（filters）（how），最终聚合数据（how）以得到正确的答案。&lt;/p&gt;&lt;p&gt;虽然许多传统BI工具试图代表用户把这些工作抽象出来，但大多数数据服务逻辑仍然严重依赖用户来确定“where”和“how”。在Airbnb，我们希望提供更好的用户体验——用户只要简单的请求获取指标和维度，就可以直接得到答案，而不必担心“where”或“how”的问题。我们将这一愿景称之为“以指标为中心的方法”，最终发现这是一个艰巨的工程挑战。&lt;/p&gt;&lt;h3&gt;挑战一：“Where”&lt;/h3&gt;&lt;p&gt;在大多数传统数据仓库中，数据以表的形式组织。这意味着要响应某个查询，BI工具需要将相关的指标和维度与包含相关答案的物理表关联起来。然而，对于给定的指标和维度的组合，也许有许多数据集包含有相关答案。这些表通常具有不同程度的数据质量和正确性保证，因此选择正确的表来服务数据并非易事。&lt;/p&gt;&lt;h3&gt;挑战二：“How”&lt;/h3&gt;&lt;p&gt;除了“where”之外，负责“how”的数据服务逻辑也有许多细微差别。首先，有不同的指标类型：由单个物理事件（例如：预定量）组成的&lt;em&gt;简单指标（simple metrics）&lt;/em&gt;；基于维度过滤产生的一组简单指标组成的&lt;em&gt;过滤指标（filtered metrics）&lt;/em&gt;（例如：中国的预订量）；由一个或多个非派生指标组成的&lt;em&gt;派生指标（derived metrics）&lt;/em&gt;（例如：图书搜索匹配率)。此外，虽然有许多指标是递增的（例如：预订量），但也有许多指标不是：计数差、百分比和基于时间的快照等，不能简单的通过汇总单个事件来计算。始终如一的在所有场景中正确的计算这些不同类型的指标是一个巨大的挑战。&lt;/p&gt;&lt;h3&gt;挑战三：与下游应用程序集成&lt;/h3&gt;&lt;p&gt;最后，只有在各种上下文环境、应用程序和工具中使用数据，才能做出基于数据的决策。指标越通用、越重要，就越有可能被广泛应用于各种场合。例如，总预订价值（Gross Booking Value，GBV）、预订夜数（nights booked）和收入（revenue）是Airbnb最常用的指标，被广泛应用于跟踪业务表现、作为随机控制实验的基准比较指标，并用于比较机器学习模型。在不同用例中基于这些指标提供服务，同时为用户提供上下文信息从而可以以正确的方式使用它们，是我们面临的另一个核心挑战。&lt;/p&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;我们通过构建Minerva API来解决这些挑战，这是一个指标服务层（metric-serving layer），充当上游数据模型和下游应用程序之间的接口。有了Minerva API，任何下游应用程序都能够以一致和正确的方式消费数据，而不用知道数据存储在哪里，也不用知道应该如何计算指标。本质上，Minerva API通过连接“what”和“where”来充当“how”。&lt;/p&gt;&lt;h1&gt;Minerva API&lt;/h1&gt;&lt;p&gt;Minerva API由API web服务、元数据获取应用以及客户端（与Apache Superset&lt;span&gt;[2]&lt;/span&gt;、Tableau&lt;span&gt;[3]&lt;/span&gt;、Python&lt;span&gt;[4]&lt;/span&gt;和R&lt;span&gt;[5]&lt;/span&gt;集成）组成。这些组件为下游应用程序提供本地NoSQL和SQL指标查询。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5238095238095238&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0VVcUKEa0ClxT4hXADLJuAwFnHQFmtZKaC7oHCA6NOKX3Vp3MiajTG0ySWZ5VJ1vzV0qhMs8Dcybww/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1050&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Minerva API充当消费者和底层数据集之间的接口&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;元数据获取器：抽象“Where”&lt;/h3&gt;&lt;p&gt;我们前面提到过，用户只需要向Minerva提供指标和规格参数，而不需要指定“where”。当发出数据请求时，Minerva会花费大量精力来确定应该使用哪个数据集来响应该请求。&lt;/p&gt;&lt;p&gt;Minerva在幕后选择最佳数据源之前需要综合考虑多个因素，其中最重要的因素之一是数据完整性。这意味着选择用于查询的任何数据源都应该包含给定用户查询请求所需的所有列，并且必须涵盖查询请求所需的时间范围。&lt;/p&gt;&lt;p&gt;为此，我们构建了一个名为元数据获取器（Metadata Fetcher）的服务，该服务每15分钟定期从数据源获取元数据，并将其缓存到MySQL数据库中。具体来说，我们定期从S3获取Minerva配置的最新副本（存储在Thrift二进制文件中），从而获取Druid中每个有效Minerva数据源的列表。对于每个数据源，我们查询Druid代理以读取它的名称以及相关的指标和维度列表。此外，我们还可以从代理获取最小日期、最大日期以及日期计数，以确定是否有任何丢失的数据。每次获取新信息时，我们都会更新MySQL数据库，以维护真实数据源。通过元数据获取器，我们能够在任何给定的时间使用最好的数据源来服务数据请求。&lt;/p&gt;&lt;h3&gt;数据API：抽象“How”&lt;/h3&gt;&lt;p&gt;假设用户希望了解2021年8月的4周时间内，除私人房间外，各目的地地区的日均价格（average daily price，ADR）下降趋势。示例查询的完整规格定义如下所示：&lt;/p&gt;&lt;p&gt;&lt;span aria-label=&quot;icon: copy&quot;&gt;&lt;svg viewbox=&quot;64 64 896 896&quot; focusable=&quot;false&quot; data-icon=&quot;copy&quot; fill=&quot;currentColor&quot; aria-hidden=&quot;true&quot;&gt;&lt;path d=&quot;M832 64H296c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h496v688c0 4.4 3.6 8 8 8h56c4.4 0 8-3.6 8-8V96c0-17.7-14.3-32-32-32zM704 192H192c-17.7 0-32 14.3-32 32v530.7c0 8.5 3.4 16.6 9.4 22.6l173.3 173.3c2.2 2.2 4.7 4 7.4 5.5v1.9h4.2c3.5 1.3 7.2 2 11 2H704c17.7 0 32-14.3 32-32V224c0-17.7-14.3-32-32-32zM350 856.2L263.9 770H350v86.2zM664 888H414V746c0-22.1-17.9-40-40-40H232V264h432v624z&quot;/&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;{&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;metric&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; ‘price_per_night’&lt;span&gt;,&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;groupby_dimension&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; ‘destination_region’&lt;span&gt;,&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;global_filter&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; ‘dim_room_type!=”private-room”’&lt;span&gt;,&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;aggregation_granularity&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; ‘W-SAT’&lt;span&gt;,&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;start_date&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; ‘2021–08–01’&lt;span&gt;,&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;end_date&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; ‘2021–09–01’&lt;span&gt;,&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;truncate_incomplete_leading_data&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; ‘true’&lt;span&gt;,&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;truncate_incomplete_trailing_data&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; ‘true’&lt;span&gt;,&lt;/span&gt;&lt;br/&gt;&lt;span&gt;}&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;当Minerva接收到这样的请求时，它不仅需要确定从哪里获取数据，还需要知道如何过滤、组合以及聚合数据以获得最终的结果。它采用了一种策略，通过Split-Apply-Combine范式&lt;span&gt;[6]&lt;/span&gt;来实现，该范式通常用于数据分析。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.3523809523809524&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0VVcUKEa0ClxT4hXADLJuAw1Zicqsy7RhczicIutgpMdBuqVjZscuCd4O2bHQhmRh4oJGicuIG1KpDPQ/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1050&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对&#x27;price_per_night&#x27;指标应用Split-Apply-Combine范式&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;步骤一：将请求拆分为原子指标请求&lt;/h3&gt;&lt;p&gt;当Minerva API接收到如上所述的查询请求时，它所做的第一件事就是通过创建一组相关的子查询，将任何派生指标分解为我们称为Minerva“原子”指标。如果一个用户查询只指定一个原子的Minerva指标，那么第一步基本上是一个空操作。&lt;/p&gt;&lt;p&gt;在上面的例子中，给定‘price_per_night’指标是一个比率指标（派生指标的一种特例），它包含一个分子(‘gross_booking_value_stays’)和一个分母(‘nights_booking’)，Minerva API将这个请求分解为两个子请求。&lt;/p&gt;&lt;h3&gt;步骤二：采用并执行每个子查询&lt;/h3&gt;&lt;p&gt;对于第1步中确定的原子指标，Minerva利用S3中存储的指标配置来推断相关的指标表达式和元数据，从而生成子查询。我们继续讨论这个例子：Minerva数据API查找“gross_booking_value_stays”的指标定义，发现它是一个SUM聚合，类似的，“nights_booking”指标也是如此。在这两个请求中，通过全局过滤器&#x27; dim_room_type != &quot; private-room&quot; &#x27;用于确保私人房间不在计算范围内。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5552380952380952&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0VVcUKEa0ClxT4hXADLJuAwibKicEMp9z5e5TC7KWCAicJia5Y2Tfc3icJ8cufzPYWU6e1cm1KQib3Ky57A/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1050&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对ADR指标应用Split-Apply-Combine范式&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;一旦为每个原子指标都生成了关联的子查询，Minerva API最终将查询发送给Druid或Presto。它将查询分割成几个跨越更小时间范围的“片”，然后在达到资源限制时将结果合并到单个数据帧中。在基于聚合粒度拼接数据帧之前，API还会丢弃任何不完整的前置或后置数据。&lt;/p&gt;&lt;h3&gt;步骤三：将原子指标结果合并到单个数据帧中&lt;/h3&gt;&lt;p&gt;一旦Minerva获取到每个原子指标的数据帧，它会通过连接时间戳列上的数据帧将它们组合成一个单独的数据帧。作为最后一步，Minerva API在以序列化JSON格式将最终结果返回给客户端之前将执行任何必要的聚合后计算、排序和限制操作。&lt;/p&gt;&lt;p&gt;总之，通过Minerva的数据源API和数据API，我们可以抽象出确定从哪里获取数据以及如何返回数据的过程。这个API作为Minerva的单一抽象层，可以满足来自下游应用程序的任何请求。然而，我们的故事并没有就此结束：我们的许多工程挑战都涉及到如何将不同的应用程序与这个API集成，我们将在下一节探讨这些挑战。&lt;/p&gt;&lt;h1&gt;数据消费经验&lt;/h1&gt;&lt;p&gt;考虑到Airbnb内部数据消费者的多样性，我们开始构建针对不同角色和用例的工具。通过Minerva API，我们构建了广泛的用户界面，这些用户界面提供了一致的数据消费体验。正如我们在&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2MTgxODgwNA==&amp;amp;mid=2247483890&amp;amp;idx=1&amp;amp;sn=b91ffef8a8c32fe24439afa367b0205a&amp;amp;chksm=fc73bc29cb04353f2de39edcd82c90e5300d1374b3a0806603bf8cb6b894d54043eb04ae0366&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;第一篇文章&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;第一篇文章&lt;/a&gt;中简要提到的，有四个主要的集成点，每个点支持一组不同的工具和用户：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据分析（Data Analysis）：&lt;/span&gt;与Python和R集成，主要用于高级数据分析&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据探索（Data Exploration）：&lt;/span&gt;与BI工具（如Superset、Metric Explorer&lt;span&gt;[7]&lt;/span&gt;和Tableau)的集成，为精通数据的分析师量身定制，以帮助商业洞察&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;报告（Reporting）：&lt;/span&gt;与XRF（eXecutive Reporting Framework，执行报告框架）&lt;span&gt;[8]&lt;/span&gt;集成，为希望了解当前业务状态的管理层量身定制&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;实验（Experimentation）：&lt;/span&gt;与ERF（Experimentation Reporting Framework，实验报告框架）集成，专为在Airbnb进行A/B测试的数据科学家、工程师或产品经理量身定制&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当我们构建这些特性时，我们总是在一致性、灵活性和可访问性之间进行权衡。例如，Metric Explorer主要是为非数据专家的非技术用户构建的，这意味需要为它优化一致性和可访问性，而不是灵活性。Metric Explorer有严格的执行保护，防止用户做错误的事情，并且几乎没有机会偏离确定的道路。&lt;/p&gt;&lt;p&gt;作为另一个极端，通常受数据科学家青睐的R和Python客户端要灵活得多。用户可以完全控制如何利用客户端API来执行定制分析或可视化。在接下来的几节中，我们将介绍这些消费体验是如何被创建的。&lt;/p&gt;&lt;h3&gt;与Metric Explorer集成&lt;/h3&gt;&lt;p&gt;Metric Explorer由Airbnb创建，任何人（无论他们的数据专业水平如何）都可以利用数据做出明智的决策。由于其面向广泛的目标用户，Metric Explorer优化了可访问性和数据一致性，而不是灵活性。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5419047619047619&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0VVcUKEa0ClxT4hXADLJuAwGS9kOuAn3ibPThAicVIdHv1dM98ic3jd6MGd4E071UEMjABLW8FuJ05GA/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1050&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Metric Explorer对于想要回答高级业务问题的非技术用户来说非常适合&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;所有Metric Explorer的指标、维度和相关元数据都来自Minerva的指标存储库，并被注入到Elasticsearch&lt;span&gt;[9]&lt;/span&gt;中。在用户对数据执行任何操作之前，这些元数据作为上下文方便的显示在右侧栏上。&lt;/p&gt;&lt;p&gt;当用户选择执行Group By和Filter之类的数据操作时，Metrics Explorer按等级顺序显示维度，这样只有很少或没有业务上下文的用户可以轻松的挖掘信息，而不需要提前知道维度值（如上所示）。&lt;/p&gt;&lt;p&gt;当用户对数据进行切片时，Minerva API会自动确定哪个组合是有效的，并且只会对有效的数据组合进行切割。在这种体验中，用户不需要知道任何有关所涉及指标来源的底层物理表的信息。&lt;/p&gt;&lt;h3&gt;与Apache Superset集成&lt;/h3&gt;&lt;p&gt;虽然Metrics Explorer提供了有关参数的高级信息，但更有探索精神的用户可以在Superset中进行更多操作。Apache Superset&lt;span&gt;[10]&lt;/span&gt;是Airbnb自助BI解决方案的核心工具。考虑到Superset在公司内的广泛应用，我们知道需要提供类SQL的功能，从而与Superset进行集成，以便Minerva能够被广泛采用。&lt;/p&gt;&lt;p&gt;用于Apache Superset和Tableau等BI工具的客户端接口要复杂得多，很多应用可以选择直接通过RESTful接口调用Minerva API。这些BI工具通常使用SQL（通过客户端），而不是HTTP请求进行访问。这意味着Minerva API需要支持类SQL接口，该接口需要遵循OLAP&lt;span&gt;[11]&lt;/span&gt;查询结构。为了构建这样一个接口，我们利用sqlparse&lt;span&gt;[12]&lt;/span&gt;在Minerva API中添加了一个SQL解析器，用于将SQL语句解析为AST，然后对其进行验证并将其转换为本地HTTP请求。&lt;/p&gt;&lt;p&gt;遵循DRY原则，我们复用Apache Calcite Avatica&lt;span&gt;[13]&lt;/span&gt;定义了客户机和服务器之间的通用数据库连接API。Minerva API充当Avatica HTTP服务器，客户端要么是基于SQLAlchemy&lt;span&gt;[14]&lt;/span&gt;定制的Python Database API&lt;span&gt;[15]&lt;/span&gt;数据库驱动程序，要么是Avatica提供的JDBC连接器（Tableau）。&lt;/p&gt;&lt;p&gt;传统BI工具在工具内部实现自定义业务逻辑，而Minerva通过类SQL的AGG指标表达式来整合这些逻辑。下表中，我们比较了在传统BI工具和Superset工具中运行的查询：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.38285714285714284&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0VVcUKEa0ClxT4hXADLJuAwnNolUUBgwMomibfzWB1vUM6MyD9rkIGPK2EbYJ9wFhA1WhAbwDYDvog/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1050&quot;/&gt;&lt;/p&gt;&lt;p&gt;在左边的查询中，用户不需要指定指标应该从哪里计算，也不需要指定正确的聚合函数——这些细节都被Minerva抽象了。&lt;/p&gt;&lt;p&gt;最后，假设Minerva中有12,000个指标和5,000个维度，但并不是所有的指标-维度组合都是有效的。例如，活动列表可以通过主机所在的位置来切割，但不能通过客人的出发位置来切割（也就是说，每个预订的客人属性可能不同）。我们在图表控件中添加了事件监听器，以确保左侧视窗中只显示符合条件的指标和维度的组合。这种设计有助于减少认知负载，简化数据挖掘过程。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.54&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0VVcUKEa0ClxT4hXADLJuAwNmrYIOS4mZ48mwOgP2MjahacMqiaJjYBva3AfeMtVicZHCe5Y12oQsMw/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1050&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Superset是以指标为中心的，用户可以从单个虚拟源查询所有指标和维度&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;与XRF（eXecutive Reporting Framework）集成&lt;/h3&gt;&lt;p&gt;如&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2MTgxODgwNA==&amp;amp;mid=2247483890&amp;amp;idx=1&amp;amp;sn=b91ffef8a8c32fe24439afa367b0205a&amp;amp;chksm=fc73bc29cb04353f2de39edcd82c90e5300d1374b3a0806603bf8cb6b894d54043eb04ae0366&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;第一篇&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;第一篇&lt;/a&gt;所述，XRF是一个框架，用于生成由执行人员和领导团队使用的简洁、高保真的业务关键报告。这个框架是通过Minerva的配置来配置的，并且完全由Minerva API提供支持。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.37142857142857144&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0VVcUKEa0ClxT4hXADLJuAwHnIyFUVZ9RiapG07O5Lu1jU5hJPtd4AJg7n6mdJKuWVhQ6D1iasmW1Xg/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1050&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;XRF自动化了大量重复的手工工作，并允许我们标准化高保真的业务关键报告&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;要管理XRF报告，用户首先需要定义报告配置，并指定所需的业务指标、维度切片以及需要应用的全局筛选器。此外，用户还可以配置其他控制行为，比如某个指标是否需要执行聚合（如MTD、QTD或YTD）操作，以及为基于时间的比较增长率（如YoY、MoM或WoW）指定合适的单位。一旦指定了这些设置，Minerva API就会执行必要的聚合操作以及生成最终的报告。&lt;/p&gt;&lt;p&gt;XRF输出的数据可以通过自定义GoogleSheetHook渲染在Google表格中，也可以通过Presto连接到Tableau中。通过利用Minerva及其聚合逻辑中的指标定义，我们在用户选择的表示层中强制执行一致性保障。&lt;/p&gt;&lt;h3&gt;与ERF（Experimentation Reporting Framework）集成&lt;/h3&gt;&lt;p&gt;与分析或报告用例不同，实验用例比较特殊，用于报告的指标只是一个起点。为了做出正确的因果推论，在将指标转换为可用于有效统计比较的汇总统计数据之前，必须将指标与实验分配的数据结合起来。&lt;/p&gt;&lt;p&gt;通常，Minerva向ERF提供“原始事件”。根据随机单元和分析单元，我们使用不同的主题键将Minerva数据加入到分配日志中，以便每个事件都有相关的主题，以及与之相关的实验组。最后计算并汇总统计信息（如平均值、百分比变化和p值）并显示在ERF记分卡中。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.22857142857142856&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0VVcUKEa0ClxT4hXADLJuAwuEZiaJJXzg1Rla8FSAcRluhjyBMNh0scr6gR44Sndh5ETjgViaRKUQvQ/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1050&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;显示实验统计摘要的ERF记分卡&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;实验UI还会直接显示相关的Minerva元数据，用户还可以查看Minerva事件的描述和所有权信息。一个带有ETA信息的谱系视图允许用户跟踪ERF指标进展&lt;span&gt;[16]&lt;/span&gt;，并帮助他们在出现延迟的情况下联系相关的Minerva指标所有者。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.35619047619047617&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0VVcUKEa0ClxT4hXADLJuAwldLsps0RoaiaQUl0icOHbqF9Kj4XpQDIIWz2ia2SXyAx0v8W6ZvPc8XfA/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1050&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ERF显示指标元数据，链接到SLA Tracker[17]从而可视化数据谱系和时间线&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;总之，Minerva及其多种集成工具帮助用户能够在他们的计划报告中轻松跟踪指标，测量实验产生的变化，并探索意外的变化——所有这些都让用户相信数据是正确和一致的，这种信心极大的减少了获取洞察所花费的时间，增加了对数据的信任，并有助于支持数据驱动的决策。&lt;/p&gt;&lt;h1&gt;尾声&lt;/h1&gt;&lt;p&gt;Minerva引入了一种思考数据的新方法，不仅意味着以业务和指标为中心的用户接口，还需要我们调整传统BI工具（主要使用SQL）来适应Minerva API的接口。在某种意义上，这类似于将一个新的方钉（Minerva）插入一个现有的圆孔（BI Tools）中。&lt;/p&gt;&lt;p&gt;随着越来越多的组织接受类似Minerva的指标层的理念，我们相信将会有一系列新的挑战等着我们。也就是说，一些开创性的工作肯定会把分析带到新的水平，我们为能够为这一领域做出创新工作而感到自豪，我们也希望会有更多公司跟我们一样在这一领域做出贡献。&lt;/p&gt;&lt;h1&gt;感谢&lt;/h1&gt;&lt;p&gt;感谢每一个为这篇博文所介绍的工作和成果做出贡献的人&lt;span&gt;[18]&lt;/span&gt;。除了之前的致谢，我们还想感谢那些与我们合作，在工作中采用Minerva的人。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;所有商标都是各自所有者的财产，相关资料的使用仅用于身份识别的目的，并不意味着赞助或背书。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;Reference:&lt;/span&gt;&lt;br/&gt;[1] https://medium.com/airbnb-engineering/how-airbnb-enables-consistent-data-consumption-at-scale-1c0b6a8b9206&lt;br/&gt;[2] https://superset.apache.org/&lt;br/&gt;[3] https://www.tableau.com/&lt;br/&gt;[4] https://www.python.org/&lt;br/&gt;[5] https://www.r-project.org/&lt;br/&gt;[6] https://www.jstatsoft.org/article/view/v040i01&lt;br/&gt;[7] https://medium.com/airbnb-engineering/supercharging-apache-superset-b1a2393278bd#c576&lt;br/&gt;[8] https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70#efb9&lt;br/&gt;[9] https://www.elastic.co/elasticsearch/&lt;br/&gt;[10] https://medium.com/airbnb-engineering/supercharging-apache-superset-b1a2393278bd&lt;br/&gt;[11] https://en.wikipedia.org/wiki/Online_analytical_processing&lt;br/&gt;[12] https://pypi.org/project/sqlparse/v&lt;br/&gt;[13] https://calcite.apache.org/avatica/&lt;br/&gt;[14] https://www.sqlalchemy.org/&lt;br/&gt;[15] https://www.python.org/dev/peps/pep-0249/&lt;br/&gt;[16] https://medium.com/airbnb-engineering/visualizing-data-timeliness-at-airbnb-ee638fdf4710&lt;br/&gt;[17] https://medium.com/airbnb-engineering/visualizing-data-timeliness-at-airbnb-ee638fdf4710&lt;br/&gt;[18] https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70#8a0a&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;你好，我是俞凡，在Motorola做过研发，现在在Mavenir做技术工作，对通信、网络、后端架构、云原生、DevOps、CICD、区块链、AI等技术始终保持着浓厚的兴趣，平时喜欢阅读、思考，相信持续学习、终身成长，欢迎一起交流学习。&lt;br/&gt;微信公众号：DeepNoMind&lt;/p&gt;&lt;/blockquote&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>