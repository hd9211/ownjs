<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>37bb583e573a342b22348a3e9ded88b1</guid>
<title>Uber：大规模、半自动化 Go GC 调优</title>
<link>https://toutiao.io/k/de25y8u</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;大家好，我是程序员幽鬼。&lt;/p&gt;&lt;p&gt;Uber 是国外大规模使用 Go 的公司之一，在 GitHub 上，他们开源了不少 Go 相关项目。最出名的有以下几个：&lt;/p&gt;&lt;p&gt;其中 guide 是他们内部的 Go 编码规范，目前已经被翻译成了多国语言，其中包括简体中文版本：https://github.com/xxjwxc/uber_go_guide_cn。&lt;/p&gt;&lt;p&gt;Uber 更多内容开源项目可以访问他们的 GitHub 首页：https://github.com/uber-go。&lt;/p&gt;&lt;p&gt;此外，https://github.com/jaegertracing/jaeger 也是 Uber 开发的，之后捐赠给 CNCF，这是一个分布式追踪平台，用于监控基于微服务的分布式系统。&lt;/p&gt;&lt;p&gt;因此他们在 Go 上有很多经验。本文介绍 Uber 如何在 30 个关键任务服务中节省 7 万个内核。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;本文作者是 Cristian Velazquez，他是 Uber Maps Production Engineering 团队的 Sr Production Engineer II。他负责跨多个组织的多个效率计划，其中最相关的是 Java 和 Go 的垃圾收集调优。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1、介绍&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;实现盈利的方式有开源和节流，对于 Uber 技术团队（其他公司技术团队其实也类似）来说，提升资源利用率，进而减少服务器数量，这是减少成本的一种方式。有些公司通过换语言实现，比如 Python 换为 Go 等。而对 Go 服务来说，可能最有效的工作是针对 GOGC 的优化。在本文中，我们将分享在高效、低风险、大规模、半自动化的 Go GC 调优机制方面的经验。&lt;/p&gt;&lt;p&gt;Uber 有数千个微服务，并由基于云原生和基于调度程序的基础设施提供支持，这些服务大部分是用 Go 编写的。我们的 Maps Production Engineering 团队之前在 Java 微服务 GC 调优方面有很多经验，也取得了很好的效果，现在这些经验在 Go GC 方面也发挥了重要的作用。&lt;/p&gt;&lt;p&gt;&lt;span&gt;2021 年初，我们探索了对 Go 服务进行 GC 调优的可能性。我们运行了几个 CPU 配置文件来评估当前的事务状态，我们发现 GC 是绝大多数关键任务服务的 CPU 最大消耗者。以下是一些 CPU 配置文件的表示，其中 GC（由 runtime.scanobject 方法标识）消耗了分配的计算资源的很大一部分。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;示例服务 #1：&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;2.3513513513513513&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q59YiaaCibZXzJQETFS8Er8ibpdxr8rFSZZSBokI2ewB0iaTiaicqLDL5HAY9w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;222&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 1：示例服务 #1 的 GC CPU 成本&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;示例服务 #2&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;2.3706896551724137&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q5HU03HWYibF9ouQt8VA72zTVdd0libb9Fes3bZNtGkaEa4KuTMvYv2vFg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;232&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 2：示例服务 #2 的 GC CPU 成本&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;受到这一发现的启发，我们开始为相关服务调整 GC。令我们高兴的是，Go 的 GC 实现和调整的简单性使我们能够自动化大部分检测和调整机制。我们将在以下部分详细介绍我们的方法及其效果。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2、GOGC Tuner&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;除了触发事件，Go 运行时会定期调用并发垃圾收集器，其中触发事件是基于内存值的。因此， 更多内存对 Go 服务来说更有利，因为它减少了 GC 必须运行的时间。此外，我们意识到我们的主机 CPU 与内存的比例是 1:5（1 核：5 GB RAM），而大多数 Go 服务的配置比例是 1:1 ~ 1:2。因此，我们有信心可以利用更多内存来减少 GC 的 CPU 影响。这是一种与服务无关的机制，如果应用得当，会产生很大的影响。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;深入研究 Go 的垃圾收集超出了本文的范围，但以下是这项工作的相关部分：Go 中的垃圾收集是并发的，涉及分析所有对象以确定哪些对象仍然可以访问。我们将可到达对象称为“实时数据集”。Go 仅提供一个选项：GOGC， 以实时数据集的百分比表示，用于控制垃圾收集。GOGC 值充当数据集的乘数。&lt;strong&gt;GOGC&lt;/strong&gt; 的默认值为 100%，这意味着 Go 运行时将为新分配保留与实时数据集相同的内存量。例如：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;hard_target = live_dataset + live_dataset * (GOGC / 100).&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后，pacer 负责预测触发 GC 的最佳时间，以避免命中硬目标（软目标）。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.1111111111111112&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q5M1OVSdniaADXM9r9fSibvm67dKAB0Rwz493icjCkYdacxDMF2QeWicDOag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;450&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 3：具有默认配置的示例堆&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3、动态多样：一个值无法适应所有场景&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们发现固定的 GOGC 值的调整不适合 Uber 的服务。以下是可能的挑战：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;它不知道分配给容器的最大内存，并可能导致内存不足问题。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;我们的微服务有各种内存利用率组合。例如，分片系统可以有非常不同的实时数据集。我们在其中一项服务中遇到了这种情况，其中 p99 利用率为 1G 但 p1 为 100MB，因此 100MB 实例具有巨大的 GC 影响。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4、自动化案例&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;GOGCTuner 是一个库，它简化了为服务所有者调整垃圾收集的过程，并在其之上添加了一个可靠层。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;GOGCTuner 根据容器的内存限制（或服务所有者的上限）动态计算正确的 GOGC 值，并使用 Go 的运行时 API 设置它。以下是 GOGCTuner 库功能的详细信息：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;简化配置，便于推理和确定性计算。对于初学者来说，&lt;span&gt;GOGC&lt;/span&gt;=100% 的确定性不足，因为它仍然依赖于实时数据集。另一方面，70% 的限制可确保服务始终使用 70% 的堆空间。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;防止 OOM（内存不足）：该库从 cgroup 读取内存限制并使用 70% 的默认硬限制，根据我们的经验，这是一个安全值。&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;需要注意的是，这种保护是有限制的。Tuner 只能调整缓冲区分配，因此如果你的服务活动对象高于限制，则 Tuner 将设置默认下限为 1.25X 你的活动对象利用率。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;对于极端情况允许更高的 GOGC 值，例如：&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;正如我们上面提到的，手动 GOGC 不是确定性的。我们仍然依赖实时数据集的大小。如果 live_dataset 将我们的最后一个峰值翻倍了怎么办？GOGCTuner 将以更多 CPU 为代价强制执行相同的内存限制。相反，手动调整可能会导致 OOM。因此，服务所有者过去常常为这些类型的场景提供足够的缓冲。请参见下面的示例：&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;正常流量（实时数据集为 150M）&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.55078125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q5zWuz4BdYGfib2PLYP1pJzNxu0V5NIkT8Pzyia4kZc7ARKPlZU1x2GjOw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 4：正常操作。左侧为默认配置，右侧为手动调整&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;流量增加了 2 倍（实时数据集为 300M）&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6880907372400756&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q5ORtcEZAicgRtVhB8Sv4yGbXHnGZicRhDiaON2yDuPSdicWKpBRWUR5xXDA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1058&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 5：双倍负载。左侧为默认配置，右侧为手动调整&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;GOGCTuner 达到 70% 时流量增加了 2 倍（实时数据集为 300M）&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q55RnNjHQDqRyicfsbUcPHiccf8R8HjqJ0AYf2oYAwIBX6o3QDJic02wuRg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 6：将负载加倍，但使用调谐器。左边是默认配置，右边是GOGCTuner调优&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;使用 &lt;span&gt;MADV_FREE&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt; 内存策略的服务会导致错误的内存指标。例如，我们的可观察性指标显示 50% 的内存利用率（实际上它已经释放了 50% 中的 20%）。然后服务所有者只是使用这个“不准确”的指标来调整 GOGC。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5、可观察性&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们发现缺乏一些关键指标，这些指标可以让我们更深入地了解每个服务的垃圾收集。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;垃圾收集之间的间隔：了解我们是否仍然可以调整很有用。例如，Go 强制每 2 分钟进行一次垃圾收集。如果你的服务仍然具有较高的 GC 影响，但你已经看到此图的 120 秒，这意味着你不能再使用 GOGC 进行调优。在这种情况下，你需要优化分配。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.28984375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q5r5G2KGBGsqXMXogzia1ncZkUc0KrWONUyakSQ5tViciaoRFxNZxbQrebA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 7：GC 之间的间隔图表&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;GC CPU 影响：知道哪些服务受 GC 影响最大。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.2828125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q5OIib2P5Vp0fWfwNhDeTM2AF2Lp4f5BVfLWicMoyPqGDhpWtSolGvBxaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 8：p99 GC CPU 成本图表&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;实时数据集（Live dataset）大小：帮助我们识别内存泄漏。服务所有者注意到的问题是他们看到内存利用率有所增加。为了向他们展示没有内存泄漏，我们添加了“实时使用”指标，该指标显示了稳定的利用率。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.2890625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q5ctL375PnGe93h3rQ9QDkPDsNZ7muVpicLkicmwGZahicmoFYbn5Lsnj6A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 9：估计的 p99 实时数据集图表&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.30859375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q5EGJ36v0TsicPdicNWcyWodiaS3MD5lLNp4l461EsxyjweEjtYxtP71coQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 10：调谐器分配给应用程序的 min、p50、p99 GOGC 值图表&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;6、实现&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们最初的方法是每秒运行一次代码来监控堆指标，然后相应地调整 GOGC 值。这种方法的缺点是开销开始变得相当大，因为为了读取堆指标，Go 需要执行 STW（&lt;span&gt;ReadMemStats&lt;/span&gt;&lt;sup&gt;[2]&lt;/sup&gt;），并且它有点不准确，因为我们每秒可以进行多次垃圾收集。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;幸运的是，我们找到一个不错的方法。Go 有终结器（&lt;span&gt;SetFinalizer&lt;/span&gt;&lt;sup&gt;[3]&lt;/sup&gt;），它们是在对象将被垃圾收集时运行的函数。它们主要用于清理 C 代码或其他一些资源的内存。我们能够使用一个自引用终结器，它会在每次 GC 调用时自行重置。这使得我们能够减少 CPU 开销。例如：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.9921722113502935&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q55GltPW7aQAsVrTRZ89nicMbMA9d4Cv69oibwtYAKxafxv5l89qEotYtg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1022&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 11：GC 触发事件的示例代码&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;调用 &lt;code&gt;runtime.SetFinalizer(f, finalizerHandler)&lt;/code&gt; 代替直接调用 &lt;code&gt;finalizerHandler&lt;/code&gt; 以允许处理程序在每次 GC 上运行；它基本上不会让引用消失，因为它不是保活的昂贵资源（它只是一个指针）。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;7、影响&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我们的几十个服务中部署了 GOGCTuner 之后，我们深入研究了其中一些显著的、CPU 利用率提高到两位数的服务。仅这些服务就累计节省了大约 70K 个内核。以下是 2 个这样的示例：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.3193359375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q55ySJU8qWQmibB2Eaia4ZZRp8ZX7r95RBSZ4hJhrXJlcG9nlADowibDEFA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 12：可观察性服务在数千个计算内核上运行，live_dataset 具有高标准偏差（最大值是最小值的 10 倍），显示 p99 CPU 利用率降低了约 65%&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.3212890625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jdTRWcqrowQdfegP8Ms0NY2y7n7Uv0q5lIEXQIXSB9ycbSGZVSIextshKbWtoKcuM0q67bV0iaEvtX83MiapIf0w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;figcaption&gt;图 13：任务关键型 Uber 吃掉在数千个计算核心上运行的服务，显示 p99 CPU 利用率降低了约 30%&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由此产生的 CPU 利用率降低在战术上改善了 p99 延迟（以及相关的 SLA、用户体验），并在战略上改善了容器成本（因为服务是根据其利用率进行扩展的）。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;8、总结&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;垃圾收集（GC）是应用程序中最难以捉摸，同时也是被低估的性能影响因素之一。Go 强大的 GC 机制和简化的调优，加之我们大规模的 Go 服务以及强大的内部平台（如 Go、计算、可观察性），使我们能够产生如此大规模的影响。由于技术和能力的变化，同时问题空间本身的发展，我们希望继续改进我们调整 GC 的方式。&lt;/p&gt;&lt;p&gt;最后再次重申我们在开头提到的内容：没有一个适合所有场景的 GOGC 值。由于公有云和运行在其中的容器化工作负载的性能高度可变，我们认为 GC 性能在云原生设置中将保持可变。再加上我们使用的绝大多数 CNCF 可观测项目都是用 Go 编写的（如 Kubernetes、Prometheus、Jaeger 等），这意味着任何外部的大规模部署也可以从这种努力中受益。&lt;/p&gt;&lt;p&gt;比较可惜的是，目前没看到 Uber 开源了这个工具。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;原文链接：https://eng.uber.com/how-we-saved-70k-cores-across-30-mission-critical-services/&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;MADV_FREE: &lt;span&gt;https://man7.org/linux/man-pages/man2/madvise.2.html&lt;/span&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;p&gt;ReadMemStats: &lt;span&gt;https://golang.org/pkg/runtime/#ReadMemStats&lt;/span&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;p&gt;SetFinalizer: &lt;span&gt;https://golang.org/pkg/runtime/#SetFinalizer&lt;/span&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9d0fb0487ae486b4ed2e48e5891a1473</guid>
<title>「多图预警」详解Kafka中的数据采集和统计机制</title>
<link>https://toutiao.io/k/eeozwnr</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在讲解 &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg4ODY1NTcxNg==&amp;amp;mid=2247489315&amp;amp;idx=1&amp;amp;sn=b51a08c0d77a7718d9b5234963d6f451&amp;amp;chksm=cff68d28f881043e84d03c4cc6e4e11c4ee8712fb49fd3740ba6ba5468093193e2f22e9eeb67&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Kafka的副本同步限流机制三部曲(源码篇)&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Kafka的副本同步限流机制三部曲(源码篇)&lt;/a&gt;&lt;span&gt; 第二篇(原理篇) 之前&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我想先讲解一下 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;Kafka中的数据采集和统计机制&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;当你了解这个机制之后才会更容易理解限流机制&lt;/span&gt;&lt;strong&gt; &lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqI2xAzzPDVEgeWodhfpQwUNb3yd8xsyqwGEOahcWDGAziaRPsjYp8OTiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;20&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;你会不会好奇,kafka监控中,那些数据都是怎么计算出来的 比如下图这些指标&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2971542025148908&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqIDxXZafiaIAGcjUGrtOtJKSjYvvXf1fQIQ4ZblDhAI4O3XLYbHPf0picA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1511&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;LogiKM监控图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这些数据都是通过Jmx获取的kafka监控指标, 那么我们今天来探讨一下,这些指标都是怎么被计算出来的&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在开始分析之前,我们可以 自己思考一下&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;如果让你统计前一分钟内的流速,你会怎么统计才能够让数字更加精确呢？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我相信你脑海中肯定出现了一个词：&lt;/span&gt;&lt;span&gt;&lt;strong&gt;滑动窗口&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在kafka的数据采样和统计中,也是用了这个方法, 通过多个样本&lt;/span&gt;&lt;code&gt;&lt;span&gt;Sample&lt;/span&gt;&lt;/code&gt;&lt;span&gt;进行采样,并合并统计&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;当然这一个过程少不了&lt;strong&gt;滑动窗口&lt;/strong&gt;的影子&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;采集和统计类图&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们先看下整个Kafka的数据采集和统计机制的类图&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.29168309026409145&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqIPKGhuRAbsBfYNiaDYicTpP5rcwQUtPmrLzfEmx8z8Cz9LkYr0icqou2Qw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;5074&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;数据采集和统计全类图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;看着整个类图好像很复杂,但是最核心的就是两个Interface接口&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;code&gt;Measurable:&lt;/code&gt;&lt;/strong&gt; 可测量的、可统计的 Interface。这个Interface 有一个方法, 专门用来计算需要被统计的值的&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;/**&lt;br/&gt;* 测量这个数量并将结果作为双精度返回&lt;br/&gt;* 参数：&lt;br/&gt;* config – 此指标的配置&lt;br/&gt;* now – 进行测量的 POSIX 时间（以毫秒为单位）&lt;br/&gt;* 返回：&lt;br/&gt;* 测量值&lt;br/&gt;*/&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;double&lt;/span&gt; &lt;span&gt;measure&lt;/span&gt;&lt;span&gt;(MetricConfig config, &lt;span&gt;long&lt;/span&gt; now)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;比如说返回 &lt;/span&gt;&lt;code&gt;&lt;span&gt;近一分钟的bytesIn&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;code&gt;Stat:&lt;/code&gt;&lt;/strong&gt; 记录数据, 上面的是统计,但是统计需要数据来支撑, 这个Interface就是用来做记录的,这个Interface有一个方法&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;br/&gt;&lt;span&gt; &lt;span&gt;/**&lt;br/&gt; * 记录给定的值&lt;br/&gt; * 参数：&lt;br/&gt; * config – 用于该指标的配置&lt;br/&gt; * value – 要记录的值&lt;br/&gt; * timeMs – 此值发生的 POSIX 时间（以毫秒为单位）&lt;br/&gt; */&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;record&lt;/span&gt;&lt;span&gt;(MetricConfig config, &lt;span&gt;double&lt;/span&gt; value, &lt;span&gt;long&lt;/span&gt; timeMs)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt; &lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;有了这两个接口,就基本上可以&lt;strong&gt;记录数据&lt;/strong&gt;和&lt;strong&gt;数据统计&lt;/strong&gt;了&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;当然这两个接口都有一个 &lt;strong&gt;&lt;code&gt;MetricConfig&lt;/code&gt;&lt;/strong&gt; 对象&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3989169675090253&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqIjEoTvE344Bib2UrTfDY396IAyEpI921iaNAdhcOOt1UI43Ieoqibov5aA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;554&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;MetricConfig&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这是一个统计配置类, 主要是定义&lt;strong&gt;采样的样本数&lt;/strong&gt;、&lt;strong&gt;单个样本的时间窗口大小&lt;/strong&gt;、&lt;strong&gt;单个样本的事件窗口大小&lt;/strong&gt;、&lt;strong&gt;限流机制&lt;/strong&gt;有了这样一个配置了,就可以自由定义时间窗口的大小,和采样的样本数之类的影响最终数据精度的变量。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这里我需要对两个参数重点说明一下&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;单个样本的时间窗口大小:&lt;/strong&gt; 当前记录时间 - 当前样本的开始时间 &amp;gt;= 此值  则需要使用下一个样本。&lt;strong&gt;单个样本的事件窗口大小:&lt;/strong&gt; 当前样本窗口时间次数 &amp;gt;= 此值  则需要使用下一个样本&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在整个统计中,不一定是按照&lt;strong&gt;时间窗口&lt;/strong&gt;来统计的, 也可以按照&lt;strong&gt;事件窗口&lt;/strong&gt;来统计, 具体按照不同需求选择配置&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;好了,大家脑海里面已经有了最基本的概念了,我们接下来就以一个kafka内部经常使用的 &lt;/span&gt;&lt;code&gt;&lt;span&gt;SampledStat&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 记录和统计的抽象类来好好的深入分析理解一下。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;SampledStat 样本记录统计抽象类&lt;/span&gt;&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;这个记录统计抽象类,是按照采样的形式来计算的。里面使用了一个或者多个样本进行采样统计 &lt;/span&gt;&lt;code&gt;&lt;span&gt;List&amp;lt;Sample&amp;gt; samples&lt;/span&gt;&lt;/code&gt;&lt;span&gt;; 当前使用的样本: &lt;/span&gt;&lt;code&gt;&lt;span&gt;current&lt;/span&gt;&lt;/code&gt;&lt;span&gt;样本初始化的值: &lt;/span&gt;&lt;code&gt;&lt;span&gt;initialValue&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;code&gt;SampledStat :&lt;/code&gt;&lt;/strong&gt; 实现了&lt;/span&gt;&lt;code&gt;&lt;span&gt;MeasurableStat&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 的抽象类,说明它又能采集记录数据,又能统计分析数据&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;当然它自身也定义了有两个抽象方法&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;br/&gt;&lt;span&gt;  &lt;span&gt;/** 更新具体样本的数值 (单个样本)**/&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;&lt;span&gt;protected&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;update&lt;/span&gt;&lt;span&gt;(Sample sample, MetricConfig config, &lt;span&gt;double&lt;/span&gt; value, &lt;span&gt;long&lt;/span&gt; timeMs)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;  &lt;span&gt;/**组合所有样本的数据 来统计出想要的数据 **/&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;double&lt;/span&gt; &lt;span&gt;combine&lt;/span&gt;&lt;span&gt;(List&amp;lt;Sample&amp;gt; samples, MetricConfig config, &lt;span&gt;long&lt;/span&gt; now)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5743283582089552&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqIhzWpq6lNia8Jic0KPbrrrIERpVvib0GEsGhLuPUfAnNXRq2nzhJia0h8QQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1675&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;SampledStat图形化展示&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如上图所示, 是一个&lt;/span&gt;&lt;code&gt;&lt;span&gt;SampledStat&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 的图形化展示, 其中定义了 若干个样本 Sample&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;记录数据&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;record&lt;/span&gt;&lt;span&gt;(MetricConfig config, &lt;span&gt;double&lt;/span&gt; value, &lt;span&gt;long&lt;/span&gt; timeMs)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        Sample sample = current(timeMs);&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (sample.isComplete(timeMs, config))&lt;br/&gt;            sample = advance(config, timeMs);&lt;br/&gt;        update(sample, config, value, timeMs);&lt;br/&gt;        sample.eventCount += &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;获取当前的&lt;strong&gt;Sample&lt;/strong&gt;号,如果没有则创建一个新的&lt;strong&gt;Sample&lt;/strong&gt;,  创建的时候设置 &lt;strong&gt;初始化值&lt;/strong&gt; 和 &lt;strong&gt;Sample起始时间(当前时间)&lt;/strong&gt; ,并保存到样品列表里面&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;判断这个&lt;strong&gt;Sample&lt;/strong&gt;是否完成(超过窗口期),判断的逻辑是 &lt;/span&gt;&lt;code&gt;&lt;span&gt;当前时间 - 当前Sample的开始时间 &amp;gt;= 配置的时间窗口值 或者 事件总数 &amp;gt;= 配置的事件窗口值&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;  &lt;span&gt;/** 当前时间 - 当前Sample的开始时间 &amp;gt;= 配置的时间窗口值 或者  事件总数 &amp;gt;= 配置的事件窗口值 **/&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; &lt;span&gt;isComplete&lt;/span&gt;&lt;span&gt;(&lt;span&gt;long&lt;/span&gt; timeMs, MetricConfig config)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;            &lt;span&gt;return&lt;/span&gt; timeMs - lastWindowMs &amp;gt;= config.timeWindowMs() || eventCount &amp;gt;= config.eventWindow();&lt;br/&gt;        }&lt;br/&gt;        &lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&quot;3&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;如果这个&lt;strong&gt;Sample&lt;/strong&gt;已经完成(超过窗口期), 则开始选择下一个窗口,如果下一个还没创建则创建新的,如果下一个已经存在,则重置这个&lt;strong&gt;Sample&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;拿到最终要使用的&lt;strong&gt;Sample&lt;/strong&gt;后, 将数据记录到这个&lt;strong&gt;Sample&lt;/strong&gt;中。具体怎么记录是让具体的实现类来实现的,因为想要最终统计的数据可以不一样,比如你只想记录&lt;strong&gt;Sample&lt;/strong&gt;中的最大值,那么更新的时候判断是不是比之前的值大则更新,如果你想统计平均值,那么这里就让单个&lt;strong&gt;Sample&lt;/strong&gt;中所有的值累加（最终会 除以 &lt;strong&gt;Sample&lt;/strong&gt;数量 求平均数的）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;记录事件次数+1。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7342549923195084&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqIrvwjJZBA6pBGbSnNyIBjLickSicOFmveOtq8yrDfOpGic38hXAR1p3HPw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1302&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;记录数据的展示图&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;统计数据&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;    &lt;span&gt;/** 测量  统计 数据**/&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;double&lt;/span&gt; &lt;span&gt;measure&lt;/span&gt;&lt;span&gt;(MetricConfig config, &lt;span&gt;long&lt;/span&gt; now)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;// 重置过期样本&lt;/span&gt;&lt;br/&gt;        purgeObsoleteSamples(config, now);&lt;br/&gt;        &lt;span&gt;// 组合所有样本数据,并展示最终统计数据,具体实现类来实现该方法&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; combine(&lt;span&gt;this&lt;/span&gt;.samples, config, now);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;先重置 &lt;strong&gt;过期样本&lt;/strong&gt; , 过期样本的意思是：当前时间 - 每个样本的起始事件 &amp;gt; 样本数量 * 每个样本的窗口时间 ; 就是滑动窗口的概念,只统计这个滑动窗口的样本数据, 过期的样本数据会被重置(过期数据不采纳), 如下图所示&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7391834247410116&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqIIQnpvicsGEoXfOUkzbAfHC3wBeAOtT4KsNmv9icdR6qG4t8ib8kKicFDHA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1641&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;滑动窗口重置过期数据&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;组合所有样本数据并进行不同维度的统计并返回数值, 因为不同场景想要得到的数据不同，所以这个只是一个抽象方法,需要实现类来实现这个计算逻辑,比如如果是计算平均值 &lt;/span&gt;&lt;code&gt;&lt;span&gt;Avg&lt;/span&gt;&lt;/code&gt;&lt;span&gt;, 它的计算逻辑就是把所有的&lt;strong&gt;样本数据值累加&lt;/strong&gt;并除以&lt;strong&gt;累积的次数&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;那我们再来看看不同的统计实现类&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;Avg 计算平均值&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;一个简单的&lt;/span&gt;&lt;code&gt;&lt;span&gt;SampledStat&lt;/span&gt;&lt;/code&gt;&lt;span&gt;实现类 它统计所有样本最终的平均值 每个样本都会累加每一次的记录值， 最后把所有样本数据叠加 / 总共记录的次数&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5128205128205128&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqIynmmL1SJb5U0O9vk3NHERDGVBSmic4tnhqoOCgFajO1BMVUmBF87trA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;780&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;在这里插入图片描述&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;Max 计算最大值&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;每个样本都保存这个样本的最大值, 然后最后再对比所有样本值的最大值&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5155844155844156&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqIb0k37jd2xumPZn3BtDZtHFyoXkzRQibk95u1fCH04eQrlOLrlSibzIGQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;770&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;在这里插入图片描述&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;WindowedSum 所有样本窗口总和值&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;每个样本累积每一次的记录值, 统计的时候 把所有样本的累计值 再累积返回&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.42503259452411996&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqIMlqkfQNAjSlqJGAKNFpDLItiak2g3PPpruvZjH1fNGtOC38fU2iaoZEg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;767&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;在这里插入图片描述&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Rate 样本记录统计求速率&lt;/span&gt;&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;Rate&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 也是实现了 &lt;/span&gt;&lt;code&gt;&lt;span&gt;MeasurableStat&lt;/span&gt;&lt;/code&gt;&lt;span&gt;接口的,说明 它也有 记录&lt;/span&gt;&lt;code&gt;&lt;span&gt;record&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 和 统计 &lt;/span&gt;&lt;code&gt;&lt;span&gt;measure&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 的方法, 实际上这个类 是一个组合类 ，里面组合了 &lt;/span&gt;&lt;code&gt;&lt;span&gt;SampledStat&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 和&lt;/span&gt;&lt;code&gt;&lt;span&gt;TimeUnit unit&lt;/span&gt;&lt;/code&gt;&lt;span&gt; ,这不是很明显了么, SampledStat负责记录和统计, 得到的数据 跟时间&lt;/span&gt;&lt;code&gt;&lt;span&gt;TimeUnit&lt;/span&gt;&lt;/code&gt;&lt;span&gt;做一下处理就得出来速率了, 比如&lt;/span&gt;&lt;code&gt;&lt;span&gt;SampledStat&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的实现类&lt;/span&gt;&lt;code&gt;&lt;span&gt;AVG&lt;/span&gt;&lt;/code&gt;&lt;span&gt;可以算出来 被统计的 评价值, 但是如果我们再除以 一个时间维度, 是不是就可以得出 &lt;strong&gt;平均速率&lt;/strong&gt; 了&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;如何计算统计的有效时间呢&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这个&lt;strong&gt;有效时间&lt;/strong&gt; 的计算会影响着最终&lt;strong&gt;速率&lt;/strong&gt;的结果&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;   &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;long&lt;/span&gt; &lt;span&gt;windowSize&lt;/span&gt;&lt;span&gt;(MetricConfig config, &lt;span&gt;long&lt;/span&gt; now)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;// 将过期的样本给重置掉&lt;/span&gt;&lt;br/&gt;        stat.purgeObsoleteSamples(config, now);&lt;br/&gt;        &lt;span&gt;// 总共运行的时候 = 当前时间 - 最早的样本的开始时间&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;long&lt;/span&gt; totalElapsedTimeMs = now - stat.oldest(now).lastWindowMs;&lt;br/&gt;        &lt;span&gt;// 总时间/单个创建时间 = 多少个完整的窗口时间&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;int&lt;/span&gt; numFullWindows = (&lt;span&gt;int&lt;/span&gt;) (totalElapsedTimeMs / config.timeWindowMs());&lt;br/&gt;        &lt;span&gt;int&lt;/span&gt; minFullWindows = config.samples() - &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;        &lt;span&gt;// If the available windows are less than the minimum required, add the difference to the totalElapsedTime&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (numFullWindows &amp;lt; minFullWindows)&lt;br/&gt;            totalElapsedTimeMs += (minFullWindows - numFullWindows) * config.timeWindowMs();&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; totalElapsedTimeMs;&lt;br/&gt;    }&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这是Rate的有效时间的计算逻辑,当然&lt;/span&gt;&lt;code&gt;&lt;span&gt;Rate&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 还有一个子类是 &lt;/span&gt;&lt;code&gt;&lt;span&gt;SampleRate&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.35199004975124376&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqIISfQmfx9c7IXN5c3woY2hdwrhlEMZFRoZFdkeP50iadqVrRlx9b38Ng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;804&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;SampleRate的窗口Size计算逻辑&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这个子类,将 有效时间的计算逻辑改的更简单, 如果运行时间&amp;lt;一个样本窗口的时间 则他的运行时间就是单个样本的窗口时间, 否则就直接用这个运行的时间, 这个计算逻辑更简单 它跟&lt;/span&gt;&lt;code&gt;&lt;span&gt;Rate&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的区别就是, 不考虑采样的时间是否足够多,我们用图来简单描述一下&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;SampleRate&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9505376344086022&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqIq2f3bF8Uqian6xZDaKnGek8sqX3EDrpsQTKS2GCgHkOHrKibDFBX4ATg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;930&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;SampleRate 速率逻辑&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;Rate&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8142031379025598&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqIibph8DTOC76lwpB9Sme0VqibD3sYEa9rgpABt9THLeIHna6m5N7l0Iag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1211&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;Rate 速率逻辑&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Meter 包含速率和累积总指标的复合统计数据&lt;/span&gt;&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;这是一个&lt;/span&gt;&lt;code&gt;&lt;span&gt;CompoundStat&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的实现类, 说明它是一个复合统计, 可以统计很多指标在这里面 它包含速率指标和累积总指标的复合统计数据&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;底层实现的逻辑还是上面讲解过的&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;副本Fetch流量的速率统计 案例分析&lt;/span&gt;&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;我们知道 在分区副本重分配过程中,有一个限流机制,就是指定某个限流值,副本同步过程不能超过这个阈值。&lt;/span&gt;&lt;span&gt;做限流,那么肯定首先就需要统计 副本同步 的流速；&lt;/span&gt;&lt;span&gt;那么上面我们&lt;/span&gt;讲&lt;span&gt;了这么多,你应该很容易能够想到如果统计了吧？&lt;/span&gt;&lt;span&gt;流速  bytes/s , 统计一秒钟同步了多少流量, 那么我们可以把样本窗口设置为 &lt;/span&gt;&lt;/span&gt;&lt;code&gt;&lt;span&gt;1s&lt;/span&gt;&lt;/code&gt;&lt;span&gt;,然后多设置几个样本窗口求平均值。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;接下来我们看看 Kafka是怎么统计的, 首先找到记录 Follower Fetch 副本流量的地方如下&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;ReplicaFetcherThread#processPartitionData&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;if&lt;/span&gt;(quota.isThrottled(topicPartition))&lt;br/&gt;  quota.record(records.sizeInBytes)&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7287390029325513&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqI7wHl46wLCJSBK0zFtPbia2M7g2K0GpkNPaTmEuTE7TDZyE6yvru03EA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;682&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;设置时间窗口配置&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这里设置的&lt;/span&gt;&lt;code&gt;&lt;span&gt;timeWindowMs&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 单个样本窗口时间= 1 s&lt;/span&gt;&lt;code&gt;&lt;span&gt;numQuotaSamples&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 样本数 = 11 当然这些都是可以配置的&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5091277890466531&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kmWVxLDDVAXanWpBUwgJpibGt5zCApiaqICPzSJ49NZaNmJTN1GjX7oRaERicQBhDvtypDqs2nVC4D1asD5RjSHKQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;986&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;查看使用了哪个实现类&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们可以看到最终是使用了 &lt;strong&gt;&lt;code&gt;SampleRate&lt;/code&gt;&lt;/strong&gt; 来统计流量 !&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Gauge 瞬时读数的指标&lt;/span&gt;&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;上面我们起始是主要讲解了&lt;/span&gt;&lt;code&gt;&lt;span&gt;Measurable&lt;/span&gt;&lt;/code&gt;&lt;span&gt;接口, 它的父类是&lt;/span&gt;&lt;code&gt;&lt;span&gt;MetricValueProvider&amp;lt;Double&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;span&gt; ,它没有方法,只是定义,当还有一个子接口是 &lt;/span&gt;&lt;code&gt;&lt;span&gt;Gauge&lt;/span&gt;&lt;/code&gt;&lt;span&gt; ,它并不是上面那种采样的形式来统计数据, 它返回的是当前的值, &lt;span&gt;&lt;strong&gt;瞬时值&lt;/strong&gt;&lt;/span&gt;它提供的方法是 &lt;/span&gt;&lt;code&gt;&lt;span&gt;value()&lt;/span&gt;&lt;/code&gt;&lt;span&gt; ， &lt;/span&gt;&lt;code&gt;&lt;span&gt;Measurable&lt;/span&gt;&lt;/code&gt;&lt;span&gt;提供的是&lt;/span&gt;&lt;code&gt;&lt;span&gt;measure()&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这个在kafka中使用场景很少,就不详细介绍了。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;好了,这一篇我们主要讲解了一下 Kafka中的数据采集和统计机制&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;那么 接下来下一篇,我们来聊聊 Kafka的监控机制, 如何把这些采集&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;到的信息给保存起来并对外提供!!!&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>0bd6afc79874dfdd90a0777c368e33b8</guid>
<title>不是主管，如何带人成事？——《横向领导力》读书笔记</title>
<link>https://toutiao.io/k/0h4y4iw</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;weui-dialog&quot;&gt;
      &lt;p class=&quot;weui-dialog__hd&quot;&gt;&lt;strong class=&quot;weui-dialog__title&quot;&gt;&quot;Top Stories&quot; is disabled&lt;/strong&gt;&lt;/p&gt;
      &lt;p class=&quot;weui-dialog__bd&quot;&gt;
        Enable &quot;Top Stories&quot; in &quot;Settings&quot; &amp;gt; &quot;General&quot; &amp;gt; &quot;Manage Discover&quot;      &lt;/p&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a62f5ae2109dc067ced73c94a1493bcb</guid>
<title>一文遍历大数据架构变迁史</title>
<link>https://toutiao.io/k/0vjvg6w</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p class=&quot;original_area_primary&quot;&gt;
                                                                                                &lt;/p&gt;

                    
                                                    


                
                
                
                
                                                                
                                
                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.15625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YriaiaJPb26VN5koUu22VNrAnuXDfGLRs8w4tRT63wErRVia5ic9J4ZyzWLDwcKT1Ldrzibn8lWIAnCQmkMCAVEtuIg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;640&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;作者 ｜ 松子（李博源）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;策划 ｜ Tina&lt;/span&gt;&lt;/section&gt;&lt;p&gt;编者按：《透过数字化转型再谈数据中台》系列连载 6-8 篇左右，作者结合自己在数据中台领域多年实践经验，总结了数据架构知识、BI 知识，以及分享给大家一些产业互联网实施经验。本文是系列文章中的第三篇。&lt;/p&gt;&lt;p&gt;在前面两篇 “关于数字化转型的几个见解 ”、“唯一性定理中的数据中台”提到了数据中台发展问题。比如概念发展太快，信息量过载，以及存在广义、狭义的数据中台定义的差别等，涉及到的这些知识都离不开数据架构的范畴，所以这一篇我会通过大数据架构发展的视角来总结与分享。（一些知识继承自己在 2015 年写的《从数据仓库到大数据，数据平台这 25 年是怎样进化的？》，又名我所经历的大数据平台发展史系列），主要涉及三个方面：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;从数仓架构到大数据架构总共三个时代九种架构的演进&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;自己整理的大数据技术栈&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最新一代的 Data Mesh 架构的数据平台&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;1&lt;/span&gt;数据平台的发展在悄然发生变化&lt;/section&gt;&lt;p&gt;从现在的企业发展来看，大家的诉求重点已经从经营与分析转为数据化的精细运营。在如何做好精细化运营过程中，企业也面临着来自创新、发展、内卷等的各方面压力。随着业务量、数据量增长，大家对数据粒度需求从之前的高汇总逐渐转为过程化的细粒度明细数据，以及从 T+1 的数据转为近乎实时的数据诉求。&lt;/p&gt;&lt;p&gt;大量的数据需求、海量的临时需求，让分析师、数据开发疲惫不堪。这些职位也变成了企业资源的瓶颈，传统 BI 中的 Report、OLAP 等工具也都无法满足互联网行业个性化的数据需求。大家开始考虑如何把需求固定为一个面向最终用户自助式、半自助的产品，来快速获取数据并分析得到结果，数据通过各类数据产品对外更有针对性的数据价值传递。（关于数据产品一个题外补充：当总结出的指标、分析方法（模型）、使用流程与工具有机的结合在一起时数据产品就此产生，随着数据中台 &amp;amp; 数据平台的建设逐渐的进入快速迭代期，数据产品、数据产品经理这两个词逐渐的升温并逐渐到今天各大公司对数产品经理岗位的旺盛诉求，目前这两方面的方法论也逐步的体系化、具象化）。&lt;/p&gt;&lt;p&gt;在这十几年中，影响数据仓库、数据平台、数据中台、数据湖的演进变革的因素也很多，比如不断快速迭代的业务模式与膨胀的群体规模所带来的数据量的冲击，新的大数据处理技术的驱动。还有落地在数据中台上各种数据产品的建设，比如工具化数据产品体系、各种自助式的数据产品、平台化各种数据产品的建设。这些数据建设能力的泛化，也让更多的大众参与数据中台的建设中 ，比如一些懂 SQL 的用户以及分析师参与数据平台直接建设比重增加 。还有一些原本数据中台具备的能力也有一些逐步地被前置到业务系统进行处理。&lt;/p&gt;&lt;section&gt;&lt;span&gt;2&lt;/span&gt;一张图看清楚大数据架构发展&lt;/section&gt;&lt;p&gt;数据仓库在国外发展多年，于大约在 1998-1999 年传入中国。进入中国以后，发展出了很多专有名词，比如数据仓库、数据中心、数据平台、数据中台、数据湖等，从大数据架构角度来看可用三个时代九种架构来做总结，其中前四代是传统数据仓库时代的架构，后面五代是大数据架构模式。其中有两个承前启后的地方：&lt;/p&gt;&lt;p&gt;如下图所示&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5037764350453172&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcuwB6zzrUhUG3MUrQAU6VB0txI4n2FJzGtvpcVGwroqw3vUVU3iaBEb5g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2648&quot;/&gt;&lt;/p&gt;&lt;p&gt;三个时代：非互联网、互联网、移动互联网时代，每一种时代的业务特点、数据量、数据类型各不相同，自然数据架构也是有显著差异的。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8073270013568521&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VPY4FqZ532jOlwca5Qxsibcug5ZlbUmjjv1ChouohOmCoxjPC2OINbqWqxxWGpwoIdE6XtAQx9t9zg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1474&quot;/&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.35453315290933696&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VPY4FqZ532jOlwca5Qxsibcu3R1uKBQxWk3CGv60txggsIYBkaobsYtSn9N8puhDZnNseyByXXlodQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1478&quot;/&gt;&lt;span&gt;表格源自：《我所经历的大数据平台发展史》&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;3&lt;/span&gt;从数据到大数据的数据架构总结&lt;/section&gt;&lt;p&gt;我自己对传统数据仓库的发展，简单抽象为为五个时代、四种架构（或许也不是那么严谨）。&lt;/p&gt;&lt;p&gt;五个时代大概，按照两位数据仓库大师 Ralph kilmball、Bill Innmon 在数据仓库建设理念上碰撞阶段来作为小的分界线：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;大概在 1991 年之前，数据仓库的实施基本采用全企业集成的模式。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;大概在 1992 年企业在数据仓库实施基本采用 EDW 的方式，Bill Innmon 博士出版了《如何构建数据仓库》，里面清晰的阐述了 EDW 架构与实施方式。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;1994-1996 年是数据集市时代，这个时代另外一种维度建模、数据集市的方式较为盛行起来，其主要代表之一 Ralph Kimball 博士出版了他的第一本书“The DataWarehouse Toolkit”（《数据仓库工具箱》），里面非常清晰的定义了数据集市、维度建模。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;大概在 1996-1997 年左右的两个架构竞争时代。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;1998-2001 年左右的合并年代。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在主要历史事件中提到了两位经典代表人物：Bill Innmon、Ralph kilmball。这两位在数据界可以算是元祖级别的人物。现在数据中台 / 平台的很多设计理念依然受到他俩 90 年代所提出方法论为依据。&lt;/p&gt;&lt;section&gt;&lt;span/&gt;经典的 BIll Inmon 和 Ralph kilmball 争论&lt;/section&gt;&lt;p&gt;Bill Inmon 提出的遵循的是自上而下的建设原则，Ralph kilmball 提出自下而上的建设原则，两种方法拥护者会在不同场合争论哪一种方法论更有优势。&lt;/p&gt;&lt;p&gt;两位大师对于建设方法争论要点：&lt;/p&gt;&lt;p&gt;1. 其中 Bill Inmon 的方法论：认为仅仅有数据集市是不够的，提倡先必须得从企业级的数据模型角度入手来构建。企业级模型就有较为完善的业务主题域划分、逻辑模型划分，在解决某个业务单元问题时可以很容易的选择不同数据路径来组成数据集市。&lt;/p&gt;&lt;p&gt;后来数据仓库在千禧年传到中国后，几个大实施厂商都是遵守该原则的实施方法，也逐渐的演进成了现在大家熟悉的数据架构中关于数据层次的划分 ：&lt;/p&gt;&lt;p&gt;上个 10 年的国内实施数据仓库以及数据平台企业，有几家专业的厂商：IBM、Teradata、埃森哲、菲奈特 (被东南收购)、亚信等。这些厂商针对自己领域服务的客户，从方案特点等一系列角度出发，在实施中对 ODS 层、EDW、DM 等不同数据层逐步地赋予了各种不同的功能与含义。现在大家熟知的数据模型层次划分，基本上也是传承原有的 Bill Inmon 的方法论。&lt;/p&gt;&lt;p&gt;2. 数据集市年代的代表人物为 Ralph kilmball，他的代表作是 《The Data Warehouse Toolkit》。这本书就是大名鼎鼎的《数据仓库工具箱》。企业级数据的建设方法主张自下而上建立数据仓库，极力推崇创建数据集市，认为数据仓库是数据集市的集合，信息总是被存储在多维模型中。&lt;/p&gt;&lt;p&gt;这种思想从业务或部门入手，设计面向业务或部门主题数据集市。随着更多的不同业务或部门数据集市实施落地，此时企业可以根据需要来合并不同的数据集市，并逐步形成企业级的数据仓库，这种方式被称为自下而上 (Botton-up) 方法。这个方法在当时刚好与 Bill Innmon 的自上而下建设方法相反。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7753721244925575&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VPY4FqZ532jOlwca5Qxsibcuq7LNyAiasfa7eo5QnsibuMYonrBrickTCkFrn4tRPNEKtStPrP23NThYA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1478&quot;/&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2257617728531856&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcusjERWia9r9Ngj1mXVVs9x80mPSD256CY2iaebCj3mJjvqmjFUaicSZ3AQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1444&quot;/&gt;&lt;/p&gt;&lt;p&gt;随着数据仓库的不断实践与迭代发展，从争吵期进入到了合并的时代，其实争吵的结果要么一方妥协，要么新的结论出现。Bill inmon 与 Ralph kilmball 的争吵没有结论，干脆提出一种新的架构包含对方，也就是后来 Bill Inmon 提出的 CIF（corporation information factory）信息工厂的架构模式，这个架构模式将 Ralph kilmball 的数据集市包含了进来，有关两种数据仓库实施方法论的争吵才逐步地平息下来。&lt;/p&gt;&lt;section&gt;&lt;span&gt;4&lt;/span&gt;非互联网四代架构&lt;/section&gt;&lt;section&gt;&lt;span/&gt;第一代 edw 架构&lt;/section&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.4732620320855615&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcujVspzpKV5YfnjuUbBoMTxtLPDReaVhNA3iaKTVVYlFZzeqHliaJnvfWg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2244&quot;/&gt;现在数据建设中使用到的“商业智能” 、“信息仓库”等很多专业术语、方法论，基本上是在上世纪 60 年代至 90 年代出现的。比如“维度模型”这个词是上世纪 60 年代 GM 与 Darmouth College 大学第一次提出， “DatawareHouse”、“事实” 是在上个世纪 70 年代 BIll Inmon 明确定义出来的，后来 90 年代 BIll Inmon 出版《如何构建数据仓库》一书更加体系化的与明确定义了如何构建数据仓库，这套方法在落地上形成了第一代数据仓库架构。&lt;/p&gt;&lt;p&gt;在第一代的数据仓库中，清晰地定义了数据仓库 (Data Warehouse) 是一个面向主题的 (Subject Oriented) 、集成的 ( Integrate ) 、相对稳定的 (Non -Volatile ) 、反映历史变化 ( Time Variant) 的数据集合，用于支持管理决策（ Decision Marking Support）。&lt;/p&gt;&lt;p&gt;数据库、数据仓库小的区别：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;数据库系统的设计目标是事务处理。数据库系统是为记录更新和事务处理而设计，数据的访问的特点是基于主键，大量原子，隔离的小事务，并发和可恢复是关键属性，最大事务吞吐量是关键指标，因此数据库的设计都反映了这些需求。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数据仓库的设计目标是决策支持。历史的、摘要的、聚合的数据比原始的记录重要的多。查询负载主要集中在即席查询和包含连接，聚合等复杂查询操作上。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;其次，数据仓库 (Data Warehouse) 是对多种异构数据源进行有效集成与处理，是按照主题的方式对数据进行重新整合，且包一般不怎么修改的历史数据，一句话总结面向主题、集成性、稳定性和时变性。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;数据仓库 (Data Warehouse) 从特点上来看：&lt;/p&gt;&lt;p&gt;数据仓库是面向主题的。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;数据仓库是集成的，数据仓库的数据有来自于分散的操作型数据，将所需数据从原来的数据中抽取出来，进行加工与集成，统一与综合之后才能进入数据仓库。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数据仓库是不可更新的，数据仓库主要是为决策分析提供数据，所涉及的操作主要是数据的查询。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数据仓库是随时间而变化的，传统的关系数据库系统比较适合处理格式化的数据，能够较好的满足商业商务处理的需求，它在商业领域取得了巨大的成功。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;数据仓库和数据库系统的区别，一言蔽之：OLAP 和 OLTP 的区别。数据库支持是 OLTP，数据仓库支持的是 OLAP。&lt;/p&gt;&lt;section&gt;&lt;span/&gt;第二代大集市架构&lt;/section&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.47934845840605&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcusWoklQRlrchQkDO0icfrDPHtiapL3LXtdwTwdvITzfImFibT3y7BKVcYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3438&quot;/&gt;&lt;/p&gt;&lt;p&gt;第二代就是 Ralph kilmball 的大集市的架构。第二代架构基本可以成为总线型架构，从业务或部门入手，设计面向业务或部门主题数据集市。Kilmball 的这种构建方式可以不用考虑其它正在进行的数据类项目实施，只要快速满足当前部门的需求即可，这种实施的好处是阻力较小且路径很短。&lt;/p&gt;&lt;p&gt;但是考虑到在实施中可能会存在多个并行的项目，是需要在数据标准化、模型阶段是需要进行维度归一化处理，需要有一套标准来定义公共维度，让不同的数据集市项目都遵守相同的标准，在后面的多个数据集市做合并时可以平滑处理。比如业务中相似的名词、不同系统的枚举值、相似的业务规则都需要做统一命名，这里在现在的中台就是全域统一 ID 之类的东西。&lt;/p&gt;&lt;p&gt;主要核心：&lt;/p&gt;&lt;section&gt;&lt;span/&gt;第三代汇总维度集市 &amp;amp;CIF2.0 数仓结构&lt;/section&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.4706814580031696&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcuQXM8KFquBIgSVVhhvWVEFeoqjaqaSHb2ER7DmJrNDM11yUzYkaQsibg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3786&quot;/&gt;&lt;img data-ratio=&quot;0.46764860599684377&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcuoCS6kofZpYwPltHakyJ1F0iau6rnX4WsSjLALsrUU6nC8B2JOwG2JwQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3802&quot;/&gt;&lt;/p&gt;&lt;p&gt;CIF（corporation information factor）信息工厂（作者备注，关于 Cif 的英文版文章名字 Corporate Information Factory (CIF) Overview），Bill Inmon 认为企业的发展会随着信息资源重要性会逐步的提升，会出现一种信息处理架构，类似工厂一样能满足所有信息的需求与请求。这个信息工厂的功能包含了数据存储与处理（活跃数据、沉默数据），支持跨部门甚至跨企业的数据访问与整合，同时也要保证数据安全性等。&lt;/p&gt;&lt;p&gt;刚好 CIF 架构模式也逐步的变成了数据仓库第三代架构。为什么把这个 CIF 架构定义成一个经典架构呢，因为 CIF 的这种架构总结了前面提到的两种架构的同时，又把架构的不同层次定义得非常明确。&lt;/p&gt;&lt;p&gt;例如 CIF 2.0 主要包括集成转换层（Integrated and Transformation Layer）、操作数据存储（Operational Data Store）、数据仓库（Enterprise Data Warehouse）、数据集市（Data Mart）、探索仓库（Exploration Warehouse）等部件。Data Mart 分为后台（Back Room）和前台（Front Room）两部分。后台主要负责数据准备工作，称为数据准备区（Staging Area），前台主要负责数据展示工作，称为数据集市（Data Mart）。&lt;/p&gt;&lt;p&gt;这个经典的架构在后来 2006 年~2012 年进入到这个领域的从业者，乃至现在有些互联网企业的数据平台架构也是相似的。&lt;/p&gt;&lt;section&gt;&lt;span/&gt;第四代 OPDM 操作实时数仓&lt;/section&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5380952380952381&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcuGdaN9RhhziavEjw2Ovo8pKXRFjic0ZC3ic8Ctbicvkb7ACkl3wB0rhWibQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3780&quot;/&gt;&lt;/p&gt;&lt;p&gt;OPDM 大约是在 2011 年提出来的，严格上来说，Opdm 操作型数据集市（仓库）是实时数据仓库的一种，他更多的是面向操作型数据而非历史数据查询与分析。&lt;/p&gt;&lt;p&gt;在这里很多人会问到什么是操作型数据？比如财务系统、CRM 系统、营销系统生产系统，通过某一种机制实时的把这些数据在各数据孤岛按照业务的某个层次有机的自动化整合在一起，提供业务监控与指导。&lt;/p&gt;&lt;section&gt;&lt;span&gt;5&lt;/span&gt;互联网的五代大数据处理架构&lt;/section&gt;&lt;p&gt;在文章的开头有提过，传统行业第三代架构与大数据第一代架构在架构形式上基本相似，只不过是通过大数据的处理技术尝试对传统第三架构进行落地的。&lt;/p&gt;&lt;p&gt;比如说在 Hadoop&amp;amp;Hive 刚兴起的阶段，有用 SyaseIQ、Greenplum 等技术来作为大数据处理技术，后来 Hadoop&amp;amp;hive 以及 Facebook Scribe、Linkedin kafka 等逐步开源后又产生了新的适应互联网大数据的架构模式。&lt;/p&gt;&lt;p&gt;后续阿里巴巴淘系的 TImeTunnel 等更多的近百种大数据处理的开源技术，进一步促进了整个大数据处理架构与技术框架的发展，我在后面会给出一个比较完善截止到目前所有技术的数据处理框架。&lt;/p&gt;&lt;p&gt;按照大数据的使用场景、数据量、数据的类型，在架构上也基本上分为流式处理技术框架、批处理技术框架等， 所以互联网这五代的大数据处理框架基本上是围绕着批处理、流式处理以及混合型架构这三种来做演进。&lt;/p&gt;&lt;section&gt;&lt;span/&gt;第一代离线大数据统计分析技术架构&lt;/section&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5591925804691762&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcumZHUZKLTfeAMm41tUqnctc6MJMlUlZUtrDRRiaAPQAf1SM8o6RFLOAw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3666&quot;/&gt;&lt;/p&gt;&lt;p&gt;这个结构与第三代的数据处理架构非常相似，具体如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8340192043895748&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcuxrjGibXwnDDiccImmI4ZGPBsic4RlbVVCsicdE1Ynrygp7XBU5d44TibADA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1458&quot;/&gt;&lt;/p&gt;&lt;p&gt;这代架构定位是为了解决传统 BI 的问题，简单来说，数据分析的业务没有发生任何变化，但是因为数据量、性能等问题导致系统无法正常使用，需要进行升级改造，此类架构便是为了解决这个问题。&lt;/p&gt;&lt;section&gt;&lt;span/&gt;第二代流式架构&lt;/section&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5263713080168776&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcuTLoFBJ6QlcicoFA8S9cmibhmkr5VnwVpWvmBJQ8ZN1pibEWyTbqOM4PyQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3792&quot;/&gt;&lt;/p&gt;&lt;p&gt;流式的应用场景非常广泛， 比如搜索、推荐、信息流等都是在线化的，对数据实时性的要求变更高，自然计算与使用是同步进行的。随着业务的复杂化，数据的处理逻辑更加复杂，比如各种维度交叉、关联、聚类，以及需要更多算法或机器学习。这些应用场景可以完全地分为两类：&lt;/p&gt;&lt;p&gt;流式计算处理框架与第一代的大数据处理框架相比，去掉了原有的 ETL 过程，数据流过数据通道时得到处理，处理结果通过消息的方式推送数据消费者。&lt;/p&gt;&lt;p&gt;流式计算框架舍弃了大数据离线批量处理模式，只有很少的数据存储，所以数据保存周期非常短。如果有历史数据场景或很复杂历史数据参与计算的场景，实现起来难度就比较大。&lt;/p&gt;&lt;p&gt;现在一些场景，会把流式计算的结果数据周期性地存到批处理的数据存储区域。如果有场景需要使用历史数据，流式计算框架会把保存的历史结果用更新的方式进行加载，再做进一步处理。&lt;/p&gt;&lt;section&gt;&lt;span/&gt;第三代 Lambda 大数据架构&lt;/section&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5178571428571429&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcuIdfWcibLfAveYiaFOEUicPsEoCCsicQXrO0Yia9ULxUDKmrjiaeyscPpL6WA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3808&quot;/&gt;&lt;/p&gt;&lt;p&gt;Lambda 架构是由 Twitter 工程师南森·马茨（Nathan Marz）提出的，是一种经典的、实施广泛的技术架构。后来出现的其他大数据处理架构也是 Lambda 架构的优化或升级版。&lt;/p&gt;&lt;p&gt;Lambda 架构有两条数据链路，一条兼顾处理批量、离线数据结构，一条是实时流式处理技术 。&lt;/p&gt;&lt;p&gt;Lambda 架构主要的组成是批处理、流式处理、数据服务层这三部分。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;批处理层 (Bathchlayer) ：Lambda 架构核心层之一，批处理接收过来的数据，并保存到相应的数据模型中，这一层的数据主题、模型设计的方法论是继承面向统计分析离线大数据中的。而且一般都会按照比较经典的 ODS、DWD、DWB、ST/ADM 的层次结构来划分。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;流式处理层 (Speed Layer) ：Lambda 另一个核心层，为了解决比如各场景下数据需要一边计算一边应用以及各种维度交叉、关联的事件流与持续计算的问题，计算结果在最后与批处理层的结果做合并。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;服务层 ( Serving layer) ：这是 Lambda 架构的最后一层，服务层的职责是获取批处理和流处理的结果，向用户提供统一查询视图服务。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Lamabda 架构理念从出现到发展这么多年，优缺点非常明显。比如稳定与性能上的优势，ETL 处理计算利用晚上时间来做，能复用部分实时计算的资源。劣势，两套数据流因为结果要做合并，所有的算法要实现两次，一次是批处理、一次是实时计算，最终两个结果还得做合并显得会很复杂。&lt;/p&gt;&lt;section&gt;&lt;span/&gt;Kappa 大数据架构&lt;/section&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5131302521008403&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcuiaZynmsFLKwLCu9Vk62I2KaWqfZ1vCCicw6eYFdBHicX4H2whCWj8h69Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3808&quot;/&gt;&lt;/p&gt;&lt;p&gt;在 Lamadba 架构下需要维护两套的代码，为了解决这个问题，LinkedIn 公司的 Jay Kreps 结合实际经验与个人思考提出了 Kappa 架构。&lt;/p&gt;&lt;p&gt;Kappa 架构核心是通过改进流式计算架构的计算、存储部分来解决全量的问题，使得实时计算、批处理可以共用一套代码。Kappa 架构认为对于历史数据的重复计算几率是很小的，即使需要，可以通过启用不同的实例的方式来做重复计算。&lt;/p&gt;&lt;p&gt;其中 Kappa 的核心思想是：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;用 Kafka 或者类似 MQ 队列系统收集各种各样的数据，需要几天的数据量就保存几天。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当需要全量重新计算时，重新起一个流计算实例，从头开始读取数据进行处理，并输出到一个新的结果存储中。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当新的实例做完后，停止老的流计算实例，并把一些老的结果删除。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Kappa 架构的优点在于将实时和离线代码统一起来，方便维护而且统一了数据口径。&lt;/p&gt;&lt;p&gt;Kappa 架构与 Lamabda 架构相比，其优缺点是：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Lambda 架构需要维护两套跑在批处理和实时流上的代码，两个结果还需要做 merge， Kappa 架构下只维护一套代码，在需要时候才跑全量数据。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Kappa 架构下可以同时启动很多实例来做重复计算，有利于算法模型调整优化与结果对比，Lamabda 架构下，代码调整比较复杂。所以 kappa 架构下，技术人员只需要维护一个框架就可以，成本很小。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;kappa 每次接入新的数据类型格式是需要定制开发接入程序，接入周期会变长。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Kappa 这种架构过度依赖于 Redis、Hbase 服务，两种存储结构又不是满足全量数据存储的，用来做全量存储会显得浪费资源。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span/&gt;Unified 大数据架构&lt;/section&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5168067226890757&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcugTwWr7TodeLXVwK1eem5icztIOe30OsCeKuZKXl8opB7Aw677B5rX6A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3808&quot;/&gt;&lt;/p&gt;&lt;p&gt;以上的这些架构都围绕大数据处理为主，Unifield 架构则更激进，将机器学习和数据处理整合为一体，从核心上来说，Unifield 在 Lambda 基础上进行升级，在流处理层新增了机器学习层。数据经过数据通道进入数据湖，新增了模型训练部分，并且将其在流式层进行使用。同时流式层不单使用模型，也包含着对模型的持续训练。&lt;/p&gt;&lt;section&gt;&lt;span/&gt;IOTA 架构&lt;/section&gt;&lt;p&gt;IOTA 大数据架构是一种基于 AI 生态下的、全新的数据架构模式，这个概念由易观于 2018 年首次提出。IOTA 的整体思路是设定标准数据模型，通过边缘计算技术把所有的计算过程分散在数据产生、计算和查询过程当中，以统一的数据模型贯穿始终，从而提高整体的计算效率，同时满足计算的需要，可以使用各种 Ad-hoc Query 来查询底层数据。&lt;/p&gt;&lt;p&gt;主要有几个特点：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;去 ETL 化：ETL 和相关开发一直是大数据处理的痛点，IOTA 架构通过 Common Data Model 的设计，专注在某一个具体领域的数据计算，从而可以从 SDK 端开始计算，中央端只做采集、建立索引和查询，提高整体数据分析的效率。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Ad-hoc 即时查询：鉴于整体的计算流程机制，在手机端、智能 IOT 事件发生之时，就可以直接传送到云端进入 real time data 区，可以被前端的 Query Engine 来查询。此时用户可以使用各种各样的查询，直接查到前几秒发生的事件，而不用在等待 ETL 或者 Streaming 的数据研发和处理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;边缘计算（Edge-Computing）：将过去统一到中央进行整体计算，分散到数据产生、存储和查询端，数据产生既符合 Common Data Model。同时，也给与 Realtime model feedback，让客户端传送数据的同时马上进行反馈，而不需要所有事件都要到中央端处理之后再进行下发。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;可能是由于我接触到的范围有限，暂时还没有遇到一家企业完整按照 IOTA 这个架构模式来实施的，暂时没有更多的个人经验来分享这块。&lt;/p&gt;&lt;section&gt;&lt;span/&gt;小结&lt;/section&gt;&lt;p&gt;大数据架构的每一代的定义与出现是有必然性的， 当然没有一个严格上的时间区分点。直接给出一个每种架构比较：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8463648834019204&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcuDv9RTs69dsWeuuHKJWFic5qdvMOs2pU2s4scoXGJRKmuibhJUjEheNwA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1458&quot;/&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8083333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcuWZGzLndpF9eWZzcic8G5fbxNa1iaRyibkL3gBxZMSpk0wNKkjth2WNZIw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1440&quot;/&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1856946354883081&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcuFQf9yfgSem1O9SrV2oXvP1ibpwdqzb03OkiawFZ5k1jPFL3yxIicp5X4w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1454&quot;/&gt;&lt;/p&gt;&lt;p&gt;架构讲完了，落地肯定是离不开技术的，我之前花了不少时间整理了一下目前大数据方向的技术栈的内容。&lt;/p&gt;&lt;section&gt;&lt;span&gt;6&lt;/span&gt;大数据处理技术栈&lt;/section&gt;&lt;p&gt;分享完了架构，在从大数据技术栈的角度来看看对应的数据采集、数据传输、数据存储、计算、ide 管理、分析可视化微服务都有哪些技术，下图的技术栈我花了蛮多的时间梳理的。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.56309963099631&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VPY4FqZ532jOlwca5QxsibcurDFNIE4LgTAswLOLLsH8DkRAQcOrCctLPkEsfRa1r8k1Ribmz4yChRA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2710&quot;/&gt;&lt;/p&gt;&lt;p&gt;这个技术栈暂时没有按照没有按照批处理、流式技术的分类的角度来分类，稍微有点遗憾。&lt;/p&gt;&lt;section&gt;&lt;span&gt;7&lt;/span&gt;Data Mesh 面向域的分散式数据架构&lt;/section&gt;&lt;p&gt;Data Mesh 是在 2019 年左右，由 ThoughtWorks 的首席技术顾问 Zhamak Dehghani 提出的（《How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh》https://martinfowler.com/articles/data-monolith-to-mesh.html）。她将对客户进行企业数据平台实施过程出现的问题和面向领域设计中的微服务结合了起来，思考出来了一种新式面向域的数据架构。&lt;/p&gt;&lt;p&gt;企业面向数据平台的实施中，不管是数据 BI 系统，还是基于大数据 (数据湖) 架构模式，或者是基于云数据平台，无一例外地延续着一个架构（Monolithic Architecture）的核心模式，只是这个架构的表现形式从一个严格规范化的数据仓库，到更加专业的大数据（数据湖），最终转化成一个多种实践模式的混合。&lt;/p&gt;&lt;p&gt;现在这些大数据平台实施与解决方案难以通过简单复制来达到规模化、商业化，企业数据平台项目实施要三到五年的时间，巨大的投入使得投入产出比不够高，很难获取预期的收益。原文提到 Zhamak Dehghani 基于对企业数据平台架构现状和弊端以及微服务的视角提出了 Data Meth 面向域的分布式架构模式。这个架构模式有四个特点：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;面向域的数据架构&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;自服务式的平台基础设施&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数据产品导向的管理与角色&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;基于灵活、规模化、演进式的基础设施交付能力&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;讲一下自己的理解 (可能理解还是比较浅)：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;面向域的数据架构：对数据内容即插即用的类似一种 SaaS 能力，比如根据领域建模来设计数据模型，比如之前 IBM 的 IAA 模型，Teradata 金融标准模型提到的用户主题域，参与者主题域、地址主题、集团客户主题等等，这类主题有自己的数据接入标准。比如通过数据处理流程、统计指标、数据资产管理的模板化配置，只关心输入内容就可以得到完整输出，并且自动完成合规、安全、管理以及运营型的一些工作。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;自服务式的平台基础设施：为数据域架构中提到落地功能提供必要的产品能力，例如提供各种快速组件化、配置化的基础模板工具。像是提供自动化数据加工管理，数据模型建模到自动化 ETL 过程，指标维度分析模板、数据应用模板等，最终实现自动化与规模化。(以前自己设计过一个自动化 ETL 引擎，并实现了最小迷你版落地，但是待解决的问题还比较多)。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数据产品导向的管理与角色，数据的价值本身就是透过数据产品对外进行传递，从数据产品的角度来说偏业务数据产品、偏工具平台数据产品，这些都是在推进数据平台的建设，自然不管数据价值的透传方式、效率、洞察等都会通过租户使用平台工具去建设自己的数据能力。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;自己也在思考未来给企业提供的数据服务能力是什么样子，以及基于元数据驱动数据中台 / 平台是什么样子的。&lt;/p&gt;&lt;section&gt;&lt;span&gt;8&lt;/span&gt;写在结尾&lt;/section&gt;&lt;p&gt;自己在 2015 年时曾经写过一篇从数据团队组织变化角度来分享大数据的架构进化的文章，这次从大数据处理架构做了一个发展总结，两个角度基本上涵盖了数据中台 / 平台建设比较重点两个问题。&lt;/p&gt;&lt;p&gt;在上一篇中提到一个话题：数据中台是有组织结构的保障，很多地方都有提到数据中台必须得有强力的组织上的保障！确实需要吗？我的观点是什么呢？这个系列的下一篇给大家讲解数据中台的组织结构。&lt;/p&gt;&lt;section&gt;&lt;span&gt;相关文章：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;amp;mid=2651076577&amp;amp;idx=4&amp;amp;sn=f1a94450ce3b7e68f2119844603ddcd4&amp;amp;chksm=bdb9cfb28ace46a4fc4a403d3b1d1dbcfc6d51ff28107cbdd80f7b46b1a2af91ee49a92e2342&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;透过数字化转型再谈数据中台（一）：关于数字化转型的几个见解&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;透过数字化转型再谈数据中台（一）：关于数字化转型的几个见解&lt;/span&gt;&lt;/a&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;amp;mid=2651077382&amp;amp;idx=1&amp;amp;sn=cfd705410cf8a205b1cf6fef7ffb3543&amp;amp;chksm=bdb9c3558ace4a4363f3aa47880228bc7413479c85c9cfdb0d265fdbfd7c59629009e40ce842&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;透过数字化转型再谈数据中台（二）：唯一性定理中的数据中台&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;透过数字化转型再谈数据中台（二）：唯一性定理中的数据中台&lt;/span&gt;&lt;/a&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;作者简介：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;松子（李博源），BI&amp;amp; 数据产品老兵一枚，漂过几个大厂。2016 年到现在持续输出原创内容几十篇，《中台翻车纪实》 、《从数据仓库到大数据，数据平台这 25 年是怎样进化的》 、《数据产品三部曲系列》等系列有思考深度的文章。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;本周好文推荐&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;amp;mid=2651078496&amp;amp;idx=1&amp;amp;sn=50b68cfe793d6f9e578a1bc7a6718245&amp;amp;chksm=bdb9c7338ace4e254ecf368cfd9725d25611975baeb6853403751fa60856e7e9c5add225d13c&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;继进入紧急状态后，美国再次提升优先级，将黑客攻击与恐怖袭击并列&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;amp;mid=2651078437&amp;amp;idx=1&amp;amp;sn=8e50f955233715d41175156232ead629&amp;amp;chksm=bdb9c7768ace4e60e2ad9c812d5c4ca61a018be83f07c613275ad1cfe0236179b9c7ba60858b&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;微软在低代码领域憋大招，跟RPA厂商抢生意？&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;amp;mid=2651078350&amp;amp;idx=1&amp;amp;sn=5e46aff9f05b85eda33a5b24bc95057e&amp;amp;chksm=bdb9c69d8ace4f8bb0f96eef6896e526c964f5ac29ca557b9b3dff1eb8f74ced926de93cb58f&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;基于HarmonyOS 2的“超级终端”来了！这几款手机即日起可升级&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;amp;mid=2651078149&amp;amp;idx=1&amp;amp;sn=ca4c765bdf96b81825a45d990af294ea&amp;amp;chksm=bdb9c6568ace4f403184611fb71884ccebee4f03246d4d0cc6fe8d8721d4359dda6bb0032375&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;问了尤雨溪25个问题后，我的很多想法开始变了&lt;/a&gt;&lt;br/&gt;&lt;hr/&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;InfoQ 写作平台&lt;/strong&gt;&lt;/span&gt;欢迎所有热爱技术、热爱创作、热爱分享的内容创作者入驻！&lt;/p&gt;&lt;p&gt;还有更多&lt;strong&gt;超值活动&lt;/strong&gt;等你来！&lt;/p&gt;&lt;p&gt;扫描下方二维码&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;填写申请，成为作者&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VMUia3dCUYO9ibsKefPyjCb3cE8icVo6icHrWCdhNK7GicHicRoY0NW8sm5GMmdaGMPSKibSfH4RSpCT9QzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;216&quot;/&gt;&lt;/p&gt;&lt;section&gt;开启你的创作之路吧~&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;1.5241545893719808&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VMUia3dCUYO9ibsKefPyjCb3cSj6SwpZVZuyUwT9IYICsUO8J6JHaZb3wibuA3yTn9jkAiaNs8ibvjicEbQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1242&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;点个在看少个 bug&lt;/span&gt; &lt;span&gt;👇&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>03f0f2569efb5c63dba2dd5fc3d18a96</guid>
<title>Python 远程连接服务器，用它就够了</title>
<link>https://toutiao.io/k/2fgxo80</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6666666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/atOH362Boyvxhic5qr1MyXN1TFKUQAy0OZA8rnOSIfHAJNhCpK0hV0ySMSwsbA3e6ydd47MaZb3zhyVXY9bk40Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;在使用 Python 写一些脚本的时候，在某些情况下，我们需要频繁登陆远程服务去执行一次命令，并返回一些结果。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;在 shell 环境中，我们是这样子做的。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; sshpass -p &lt;span&gt;${passwd}&lt;/span&gt; ssh -p &lt;span&gt;${port}&lt;/span&gt; -l &lt;span&gt;${user}&lt;/span&gt; -o StrictHostKeyChecking=no xx.xx.xx.xx &lt;span&gt;&quot;ls -l&quot;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后你会发现，你的输出有很多你并不需要，但是又不去不掉的一些信息（也许有方法，请留言交流），类似这样&lt;/p&gt;&lt;pre&gt;&lt;code&gt;host: xx.xx.xx.xx, port: xx&lt;br/&gt;Warning: Permanently added &#x27;[xx.xx.xx.xx]:xx&#x27; (RSA) to the list of known hosts.&lt;br/&gt;Login failure: [Errno 1] This server is not registered to rmp platform, please confirm whether cdn server.&lt;br/&gt;total 4&lt;br/&gt;-rw-r--r-- 1 root root 239 Mar 30  2018 admin-openrc&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;对于直接使用 shell 命令，来执行命令的，可以直接使用管道，或者将标准输出重定向到文件的方法取得执行命令返回的结果&lt;/p&gt;&lt;h2&gt;&lt;span&gt;# &lt;/span&gt;&lt;span&gt;1. 使用 subprocess&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;若是使用 Python 来做这件事，通常我们会第一时间，想到使用 os.popen，os.system，commands，subprocess 等一些命令执行库来间接获取 。&lt;/p&gt;&lt;p&gt;但是据我所知，这些库获取的 output 不仅只有标准输出，还包含标准错误（也就是上面那些多余的信息）&lt;/p&gt;&lt;p&gt;所以每次都要对 output 进行的数据清洗，然后整理格式化，才能得到我们想要的数据。&lt;/p&gt;&lt;p&gt;用 subprocess 举个例子，就像这样子&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; subprocess&lt;br/&gt;ssh_cmd = &lt;span&gt;&quot;sshpass -p ${passwd} ssh -p 22 -l root -o StrictHostKeyChecking=no xx.xx.xx.xx  &#x27;ls -l&#x27;&quot;&lt;/span&gt;&lt;br/&gt;status, output = subprocess.getstatusoutput(ssh_cmd)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 数据清理，格式化的就不展示了&lt;/span&gt;&lt;br/&gt;&amp;lt;code...&amp;gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过以上的文字 + 代码的展示 ，可以感觉到 ssh 登陆的几大痛点&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;痛点一&lt;/strong&gt;：需要额外安装 sshpass（如果不免密的话）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;痛点二&lt;/strong&gt;：干扰信息太多，数据清理、格式化相当麻烦&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;痛点三&lt;/strong&gt;：代码实现不够优雅（有点土），可读性太差&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;痛点四&lt;/strong&gt;：ssh 连接不能复用，一次连接仅能执行一次&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;痛点五&lt;/strong&gt;：代码无法全平台，仅能在 Linux 和 OSX 上使用&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解决这几个问题，我搜索了全网关于 Python SSH 的文章，&lt;span&gt;还真的被我找到了两个库&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;# &lt;/span&gt;&lt;span&gt;2. 使用 sh.ssh&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;首先来介绍第一个，&lt;code&gt;sh.ssh&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;sh&lt;/code&gt; 是一个可以让你通过函数的调用来完成 Linxu/OSX 系统命令的一个库，非常好用，关于它有机会也写篇介绍。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; python3 -m pip install sh&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;今天只介绍它其中的一个函数：&lt;code&gt;ssh&lt;/code&gt;&lt;/p&gt;&lt;p&gt;通常两台机器互访，为了方便，可设置免密登陆，这样就不需要输入密码。&lt;/p&gt;&lt;p&gt;这段代码可以实现免密登陆，并执行我们的命令 &lt;code&gt;ls -l&lt;/code&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;from&lt;/span&gt; sh &lt;span&gt;import&lt;/span&gt; ssh&lt;br/&gt;output=ssh(&lt;span&gt;&quot;root@xx.xx.xx.xx&quot;&lt;/span&gt;, &lt;span&gt;&quot;-p 22&quot;&lt;/span&gt;, &lt;span&gt;&quot;ls -l&quot;&lt;/span&gt;)&lt;br/&gt;print(output)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但有可能 ，我们并不想设置互信免密，为了使这段代码更通用，我假定我们没有设置免密，只能使用密码进行登陆。&lt;/p&gt;&lt;p&gt;问题就来了，要输入密码，必须得使用交互式的方法来输入呀，在 Python 中要如何实现呢？&lt;/p&gt;&lt;p&gt;原来 ssh 方法接收一个 &lt;code&gt;_out&lt;/code&gt; 参数，这个参数可以为一个字符串，表示文件路径，也可以是一个文件对象（或者类文件对象），还可以是一个回调函数，意思是当有标准输出时，就会调用将输出内容传给这个函数。&lt;/p&gt;&lt;p&gt;这就好办了呀。&lt;/p&gt;&lt;p&gt;我只要识别到有 &lt;code&gt;password:&lt;/code&gt; 字样，就往标准输入写入我的密码就好了呀。&lt;/p&gt;&lt;p&gt;完整代码如下：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; sys&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; sh &lt;span&gt;import&lt;/span&gt; ssh&lt;br/&gt;&lt;br/&gt;aggregated = &lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;ssh_interact&lt;/span&gt;&lt;span&gt;(char, stdin)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;global&lt;/span&gt; aggregated&lt;br/&gt;    sys.stdout.write(char.encode())&lt;br/&gt;    sys.stdout.flush()&lt;br/&gt;    aggregated += char&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; aggregated.endswith(&lt;span&gt;&quot;password: &quot;&lt;/span&gt;):&lt;br/&gt;        stdin.put(&lt;span&gt;&quot;you_password\n&quot;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;output=ssh(&lt;span&gt;&quot;root@xx.xx.xx.xx&quot;&lt;/span&gt;, &lt;span&gt;&quot;-p 22&quot;&lt;/span&gt;, &lt;span&gt;&quot;ls -l&quot;&lt;/span&gt;,_tty_in=&lt;span&gt;True&lt;/span&gt;, _out_bufsize=&lt;span&gt;0&lt;/span&gt;, _out=ssh_interact)&lt;br/&gt;print(output)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这是官方文档（http://amoffat.github.io/sh/tutorials/interacting_with_processes.html?highlight=ssh）给的一些信息，写的一个demo。&lt;/p&gt;&lt;p&gt;尝试运行后，发现程序会一直在运行中，永远不会返回，不会退出，回调函数也永远不会进入。&lt;/p&gt;&lt;p&gt;通过调试查看源代码，仍然查不到问题所在，于是去 Github 上搜了下，原来在 2017 年就已经存在这个问题了，到现在 2020 年了还没有修复，看来使用 &lt;code&gt;sh.ssh&lt;/code&gt; 的人并不多，于是我又“追问”了下，期望能得到回复。&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0226939970717424&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/QB6G4ZoE187ibjO4ia2ib5XKbkicaVH0VArIGnVQclicxS0UyN4pBKJEJuQyDAKXoDwQFxfmZjGYLoZk0KtBpJ6Sa2g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1366&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;以上这个问题，只有在需要输入密码才会出现，如果设置了机器互信是没有问题的。&lt;/p&gt;&lt;p&gt;为了感受 &lt;code&gt;sh.ssh&lt;/code&gt; 的使用效果，我设置了机器互信免密，然后使用如下这段代码。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;from&lt;/span&gt; sh &lt;span&gt;import&lt;/span&gt; ssh&lt;br/&gt;&lt;br/&gt;my_server=ssh.bake(&lt;span&gt;&quot;root@xx.xx.xx.xx&quot;&lt;/span&gt;, &lt;span&gt;&quot;-p 22&quot;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 相当于执行登陆一次执行一次命令，执行完就退出登陆&lt;/span&gt;&lt;br/&gt;print(my_server.ls())&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 可在 sleep 期间，手动登陆服务器，使用 top ，查看当前有多少终端在连接&lt;/span&gt;&lt;br/&gt;time.sleep(&lt;span&gt;5&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 再次执行这条命令时，登陆终端数将 +1，执行完后，又将 -1&lt;/span&gt;&lt;br/&gt;print(my_server.ifconfig())&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;惊奇地发现使用 &lt;code&gt;bake&lt;/code&gt; 这种方式，&lt;code&gt;my_server.ls()&lt;/code&gt; 和 &lt;code&gt;my_server.ifconfig()&lt;/code&gt; 这种看似是通过同一个ssh连接，执行两次命令，可实际上，你可以在远程机器上，执行 top 命令看到已连接的终端的变化，会先 &lt;code&gt;+1&lt;/code&gt; 再 &lt;code&gt;-1&lt;/code&gt;，说明两次命令的执行是通过两次连接实现的。&lt;/p&gt;&lt;p&gt;如此看来，使用 &lt;code&gt;sh.ssh&lt;/code&gt; 可以解决痛点一（如果上述问题能得到解决）、痛点二、痛点三。&lt;/p&gt;&lt;p&gt;但是它仍然无法复用 ssh 连接，还是不太方便，不是我理想中的最佳方案。&lt;/p&gt;&lt;p&gt;最重要的一点是， &lt;code&gt;sh&lt;/code&gt; 这个模块，仅支持  Linxu/OSX ，在 Windows 你得使用它的兄弟库 - &lt;code&gt;pbs&lt;/code&gt; ，然后我又去  pypi 看了一眼 pbs，已经 “年久失修”，没人维护了。&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.20748059280169373&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/QB6G4ZoE187ibjO4ia2ib5XKbkicaVH0VArITtSOwp02y0YLKib5Pe9iaQeqMZL4nJz5yaSJwjCUZs945uDA47FYJqFA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1417&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;至此，我离 “卒”，就差最后一根稻草了。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;# &lt;/span&gt;&lt;span&gt;3. 使用 paramiko&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;带着最后一丝希望，我尝试使用了 &lt;code&gt;paramiko&lt;/code&gt; 这个库，终于在 &lt;code&gt;paramiko&lt;/code&gt; 这里，找回了本应属于 Python 的那种优雅。&lt;/p&gt;&lt;p&gt;你可以通过如下命令去安装它&lt;/p&gt;&lt;pre&gt;&lt;code&gt;$ python3 -m pip install paramiko&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后接下来，就介绍几种常用的 ssh 登陆的方法&lt;/p&gt;&lt;h3&gt; &lt;span&gt;方法1：基于用户名和密码的 sshclient 方式登录&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;然后你可以参考如下这段代码，在 Linux/OSX 系统下进行远程连接&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; paramiko&lt;br/&gt;&lt;br/&gt;ssh = paramiko.SSHClient()&lt;br/&gt;&lt;span&gt;# 允许连接不在know_hosts文件中的主机&lt;/span&gt;&lt;br/&gt;ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 建立连接&lt;/span&gt;&lt;br/&gt;ssh.connect(&lt;span&gt;&quot;xx.xx.xx.xx&quot;&lt;/span&gt;, username=&lt;span&gt;&quot;root&quot;&lt;/span&gt;, port=&lt;span&gt;22&lt;/span&gt;, password=&lt;span&gt;&quot;you_password&quot;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 使用这个连接执行命令&lt;/span&gt;&lt;br/&gt;ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(&lt;span&gt;&quot;ls -l&quot;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 获取输出&lt;/span&gt;&lt;br/&gt;print(ssh_stdout.read())&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 关闭连接&lt;/span&gt;&lt;br/&gt;ssh.close()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt; &lt;span&gt;方法2：基于用户名和密码的 transport 方式登录&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;方法1 是传统的连接服务器、执行命令、关闭的一个操作，多个操作需要连接多次，无法复用连接[&lt;strong&gt;痛点四&lt;/strong&gt;]。&lt;/p&gt;&lt;p&gt;有时候需要登录上服务器执行多个操作，比如执行命令、上传/下载文件，方法1 则无法实现，那就可以使用 transport 的方法。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; paramiko&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 建立连接&lt;/span&gt;&lt;br/&gt;trans = paramiko.Transport((&lt;span&gt;&quot;xx.xx.xx.xx&quot;&lt;/span&gt;, &lt;span&gt;22&lt;/span&gt;))&lt;br/&gt;trans.connect(username=&lt;span&gt;&quot;root&quot;&lt;/span&gt;, password=&lt;span&gt;&quot;you_passwd&quot;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 将sshclient的对象的transport指定为以上的trans&lt;/span&gt;&lt;br/&gt;ssh = paramiko.SSHClient()&lt;br/&gt;ssh._transport = trans&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 剩下的就和上面一样了&lt;/span&gt;&lt;br/&gt;ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())&lt;br/&gt;ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(&lt;span&gt;&quot;ls -l&quot;&lt;/span&gt;)&lt;br/&gt;print(ssh_stdout.read())&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 关闭连接&lt;/span&gt;&lt;br/&gt;trans.close()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt; &lt;span&gt;方法3：基于公钥密钥的 SSHClient 方式登录&lt;/span&gt;&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; paramiko&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 指定本地的RSA私钥文件&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# 如果建立密钥对时设置的有密码，password为设定的密码，如无不用指定password参数&lt;/span&gt;&lt;br/&gt;pkey = paramiko.RSAKey.from_private_key_file(&lt;span&gt;&#x27;/home/you_username/.ssh/id_rsa&#x27;&lt;/span&gt;, password=&lt;span&gt;&#x27;12345&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 建立连接&lt;/span&gt;&lt;br/&gt;ssh = paramiko.SSHClient()&lt;br/&gt;ssh.connect(hostname=&lt;span&gt;&#x27;xx.xx.xx.xx&#x27;&lt;/span&gt;,&lt;br/&gt;            port=&lt;span&gt;22&lt;/span&gt;,&lt;br/&gt;            username=&lt;span&gt;&#x27;you_username&#x27;&lt;/span&gt;,&lt;br/&gt;            pkey=pkey)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 执行命令&lt;/span&gt;&lt;br/&gt;stdin, stdout, stderr = ssh.exec_command(&lt;span&gt;&#x27;ls -l&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 结果放到stdout中，如果有错误将放到stderr中&lt;/span&gt;&lt;br/&gt;print(stdout.read())&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 关闭连接&lt;/span&gt;&lt;br/&gt;ssh.close()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt; &lt;span&gt;方法4：基于密钥的 Transport 方式登录&lt;/span&gt;&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; paramiko&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 指定本地的RSA私钥文件&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# 如果建立密钥对时设置的有密码，password为设定的密码，如无不用指定password参数&lt;/span&gt;&lt;br/&gt;pkey = paramiko.RSAKey.from_private_key_file(&lt;span&gt;&#x27;/home/you_username/.ssh/id_rsa&#x27;&lt;/span&gt;, password=&lt;span&gt;&#x27;12345&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 建立连接&lt;/span&gt;&lt;br/&gt;trans = paramiko.Transport((&lt;span&gt;&#x27;xx.xx.xx.xx&#x27;&lt;/span&gt;, &lt;span&gt;22&lt;/span&gt;))&lt;br/&gt;trans.connect(username=&lt;span&gt;&#x27;you_username&#x27;&lt;/span&gt;, pkey=pkey)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 将sshclient的对象的transport指定为以上的trans&lt;/span&gt;&lt;br/&gt;ssh = paramiko.SSHClient()&lt;br/&gt;ssh._transport = trans&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 执行命令，和传统方法一样&lt;/span&gt;&lt;br/&gt;stdin, stdout, stderr = ssh.exec_command(&lt;span&gt;&#x27;df -hl&#x27;&lt;/span&gt;)&lt;br/&gt;print(stdout.read().decode())&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 关闭连接&lt;/span&gt;&lt;br/&gt;trans.close()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以上四种方法，可以帮助你实现远程登陆服务器执行命令，如果需要复用连接：一次连接执行多次命令，可以使用 &lt;strong&gt;方法二&lt;/strong&gt; 和 &lt;strong&gt;方法四&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;用完后，记得关闭连接。&lt;/p&gt;&lt;h3&gt; &lt;span&gt;实现 sftp 文件传输&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;同时，paramiko 做为 ssh 的完美解决方案，它非常专业，利用它还可以实现 sftp 文件传输。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; paramiko&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 实例化一个trans对象# 实例化一个transport对象&lt;/span&gt;&lt;br/&gt;trans = paramiko.Transport((&lt;span&gt;&#x27;xx.xx.xx.xx&#x27;&lt;/span&gt;, &lt;span&gt;22&lt;/span&gt;))&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 建立连接&lt;/span&gt;&lt;br/&gt;trans.connect(username=&lt;span&gt;&#x27;you_username&#x27;&lt;/span&gt;, password=&lt;span&gt;&#x27;you_passwd&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 实例化一个 sftp对象,指定连接的通道&lt;/span&gt;&lt;br/&gt;sftp = paramiko.SFTPClient.from_transport(trans)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 发送文件&lt;/span&gt;&lt;br/&gt;sftp.put(localpath=&lt;span&gt;&#x27;/tmp/11.txt&#x27;&lt;/span&gt;, remotepath=&lt;span&gt;&#x27;/tmp/22.txt&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 下载文件&lt;/span&gt;&lt;br/&gt;sftp.get(remotepath=&lt;span&gt;&#x27;/tmp/22.txt&#x27;&lt;/span&gt;, localpath=&lt;span&gt;&#x27;/tmp/33.txt&#x27;&lt;/span&gt;)&lt;br/&gt;trans.close()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;到这里，Paramiko 已经完胜了，但是仍然有一个痛点我们没有提及，就是多平台，说的就是 Windows，这里就有一件好事，一件坏事了，。&lt;/p&gt;&lt;p&gt;好事就是：paramiko 支持 windows&lt;/p&gt;&lt;p&gt;坏事就是：你需要做很多复杂的准备，你可 google 解决，但是我建议你直接放弃，坑太深了。&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.14461738002594035&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/QB6G4ZoE187ibjO4ia2ib5XKbkicaVH0VArIglwtCU0Or77ia3VOl0j62Sn7bLlYDRU4HZYo3ZpME1l9Vcx0UyYsxNg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1542&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;h3&gt; &lt;span&gt;注意事项&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;使用 paramiko 的时候，有一点需要注意一下，这个也是我自己 &quot;踩坑&quot; 后才发现的，其实我觉得这个设计挺好的，如果你不需要等待它返回数据，可以直接实现异步效果，只不过对于不知道这个设计的人，确实是个容易掉坑的点&lt;/p&gt;&lt;p&gt;就是在执行 &lt;code&gt;ssh.exec_command(cmd)&lt;/code&gt; 时，这个命令并不是同步阻塞的。&lt;/p&gt;&lt;p&gt;比如下面这段代码，执行时，你会发现 脚本立马就结束退出了，并不会等待 5 s 后，再 执行 ssh.close()&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; paramiko&lt;br/&gt;&lt;br/&gt;trans = paramiko.Transport((&lt;span&gt;&quot;172.20.42.1&quot;&lt;/span&gt;, &lt;span&gt;57891&lt;/span&gt;))&lt;br/&gt;trans.connect(username=&lt;span&gt;&quot;root&quot;&lt;/span&gt;, password=&lt;span&gt;&quot;youpassword&quot;&lt;/span&gt;)&lt;br/&gt;ssh = paramiko.SSHClient()&lt;br/&gt;ssh._transport = trans&lt;br/&gt;stdin, stdout, stderr = ssh.exec_command(&lt;span&gt;&quot;sleep 5;echo ok&quot;&lt;/span&gt;)&lt;br/&gt;ssh.close()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但是如果改成这样，加上一行 stdout.read()， paramiko 就知道，你需要这个执行的结果，就会在 read() 进行阻塞。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; paramiko&lt;br/&gt;&lt;br/&gt;trans = paramiko.Transport((&lt;span&gt;&quot;172.20.42.1&quot;&lt;/span&gt;, &lt;span&gt;57891&lt;/span&gt;))&lt;br/&gt;trans.connect(username=&lt;span&gt;&quot;root&quot;&lt;/span&gt;, password=&lt;span&gt;&quot;youpassword&quot;&lt;/span&gt;)&lt;br/&gt;ssh = paramiko.SSHClient()&lt;br/&gt;ssh._transport = trans&lt;br/&gt;stdin, stdout, stderr = ssh.exec_command(&lt;span&gt;&quot;sleep 5;echo ok&quot;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 加上一行 read()&lt;/span&gt;&lt;br/&gt;print(stdout.read())&lt;br/&gt;ssh.close()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;&lt;span&gt;# &lt;/span&gt;&lt;span&gt;4. 写在最后&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;经过了一番对比，和一些实例的展示，可以看出 Paramiko 是一个专业、让人省心的 ssh 利器，个人认为 Paramiko 模块是运维人员必学模块之一，如果你恰好需要在 Python 代码中实现 ssh 到远程服务器去获取一些信息，那么我把 Paramiko 推荐给你。&lt;/p&gt;&lt;p&gt;最后，希望这篇文章，能给你带来帮助。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;# &lt;/span&gt;&lt;span&gt;5. 参考链接&lt;/span&gt;&lt;/h2&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://github.com/paramiko/paramiko&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;http://docs.paramiko.org&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://www.liujiangblog.com/blog/15/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;http://docs.paramiko.org/en/stable/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.07625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/WLXa0NsmXuiap5yprf7DJXhpdhC0XIBAopbpFTUe1eSSuGbT5Kg63CPBicfpxwLAFIm2wPkicB5NWdSicbzziaibPXSA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;800&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU1OTI0NjI1NQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/atOH362BoyuUe1icelWmbMyTCRwoFPScmosYQheSZ9wsmr61Bfr2rvNav9j9QpDnUulNpCotEiaAoLzSAm4jZTjA/0?wx_fmt=png&quot; data-nickname=&quot;AirPython&quot; data-alias=&quot;AirPython&quot; data-signature=&quot;专注于Python爬虫/自动化/Web原创技术干货！&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>