<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>9d0760ce99221bb4ac3d05cc8932ef3b</guid>
<title>几年前，我撸了一套 RabbitMQ 的客户端</title>
<link>https://toutiao.io/k/7sdt779</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不好意思，又好多天没更文章了……&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;眼看着离过年越来越近了，很多工作都要在年前冲刺、收个尾。比如：工作总结、绩效考核、奖金、确定今年 KPI……&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于我负责的部门一百多人，虽然有下面的各位 Leader 帮忙，但是我的工作量还是很大的，每天一脑门子杂七杂八的事情，还有大大小小的各种会议……真没时间输出文章。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这不，在我的读者群里，都被大家催更了。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.336&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/6nbNnibOq5KQKmK4rd6zL1aJeMZXKv3CU0r3eicYAoJqp7vmiadGu9oeOSolbqHo2I9VpR4ufFQSibkXLNmUhsnpiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1250&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.13087248322147652&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/6nbNnibOq5KQKmK4rd6zL1aJeMZXKv3CUymwFH896mXvfPYCYx1I6OteiaGiaib4YXj8yOFnib3MjkuVWKrvbSpicibgw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;596&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在此感谢：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阿德、enjoy.day、Genos等等（不一一列举了，我都记在心里了）各位老铁催更。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RabbitMQ 的新文章总算写好了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我在&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MTg3NDYwNg==&amp;amp;mid=2247484978&amp;amp;idx=1&amp;amp;sn=e0e741de7970de41ce2a3f8e7c800b05&amp;amp;chksm=fcd8ca73cbaf436593a03ae397e6fce0659595698187552527ea4c868fa8e66f32727b5837dd&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;上篇文章&lt;/a&gt;说过，如果使用 RabbitMQ，尽可能使用框架，而不要去使用 RabbitMQ 提供的 Java 版客户端。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;细说起来，其实还是因为 RabbitMQ 客户端的使用有很多的注意事项，稍微不注意，就容易翻车。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我是 2013 年就开始用起了 RabbitMQ，一路使用，一路和它一起成长。当时，由于用的早，市面上也没有特别成熟的 RabbitMQ 客户端框架。所以，不得已之下，只好自己做了一套客户端。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这其中，正好也有了许多独特的经验也和大家分享一下，以免后来者陷入“后人哀之而不鉴之，亦使后人而复哀后人也”的套娃中。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一、那么，就先从网络连接开始吧&lt;/span&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1. 应该长久生存的连接&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 RabbitMQ 中，由于需要客户端和服务器端进行握手，所以导致客户端和服务器端的连接如果要成功创建，需要很高的成本。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每一个连接的创建至少需要 &lt;span&gt;&lt;strong&gt;7&lt;/strong&gt;&lt;/span&gt; 个 TCP 包，这还只是普通连接。如果需要 TLS 的参与，则 TCP 包会更多。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而且，RabbitMQ 中主要是以 Channel 方式通信，所以，每次创建完 Connection 网络连接，还得创建 Channel，这又需要 &lt;span&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/span&gt; 个 TCP 包。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果，每次用完，再把连接关闭，首先还要关闭已经创建的 Channel，这也需要 &lt;span&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/span&gt; 个 TCP 包。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后，再关闭已经建立好的 Connection 连接，又需要 &lt;span&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/span&gt; 个 TCP 包。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;咱们算算，如果一个连接从创建到关闭，一共需要多少个 TCP 包？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;7 + 2 + 2 + 2 = 13&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一共需要 13 个包。这个成本是很昂贵的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，在 RabbitMQ 中，连接最好缓存起来，重复使用更好。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2. Channel 还是独占好&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 RabbitMQ 自己的客户端中，Channel 出于性能原因，并不是线程安全的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而如果咱们为了线程共用，给 Channel 人为的在外部加上锁，本身就和 RabbitMQ 的 Channel 设计意图是冲突的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，最好的办法就是一个线程一个 Channel。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3. Channel 最好也别关&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就像连接应该缓存起来那样，Channel 的打开和关闭也需要时间成本，而且没有必要去重新创建 Channel，所以，Channel 也应该缓存起来重用。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4. 别把消费和发送的连接搞在一起&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;把消费和发送的连接搞在一起，这是个很容易犯的错误！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们用 RabbitMQ 的时候，我们自己的系统本身大部分都是既要发消息也要收消息的。对于这种情况，有很多程序员走了极端：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;他们觉得 RabbitMQ 连接成本高，所以省着用。于是就把发消息和收消息的连接混在一起，使用同一个 TCP 连接。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这很可能会埋一个大雷。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为，当我们发消息很频繁的时候，我们收消息也是走的同一个 TCP 通道，收完了消息，客户端还要给 RabbitMQ 服务器端一个 ACK。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RabbitMQ 服务器端，对于每个 TCP 连接都会分配专门的进程，如果遇到这个进程繁忙，这个 ACK 很可能被丢弃，又或者等待处理的时间过长。而这种情况又会导致 RabbitMQ 中的未确认消息会被堆积的越来越多，影响到整套系统。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，消费和发送的连接必须分开，各干各的事情。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5. 别搞太多连接和 Channel，RabbitMQ 的 Web 受不了&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RabbitMQ 的 Web 插件会收集很多连接，和其对应 Channel 的相关数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果连接和 Channel 堆积太多了，整个 Web 打开会非常慢，几乎无法对 RabbitMQ 进行管理。所以，要注意限制连接和 Channel 的数量。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;二、消息很宝贵，千万别乱抛弃哦&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用来通信的消息是很宝贵的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为每条消息都可能携带了关键的数据和信息。所以，保证消息不丢失，需要根据消息的重要性，采取很多的措施。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1. 小心，Queue 存在再发消息&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一条消息，在 RabbitMQ 中会先发到 Exchange，再由 Exchange 交给对应的 Queue。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而当 Queue 不存在，或者没匹配到合适的 Queue 的时候，默认就会把消息发到系统中的 /dev/null 中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;而且还不会报错。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个坑当年把我坑惨了！我猜这个坑无数人踩过吧。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，在发送消息的时候，最好通过 declare passive 这种方法去探测下队列是否存在，保证消息发送不会丢的莫名其妙。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2. 收到消息请告诉我&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在使用 RabbitMQ 客户端的时候，发送消息，一定要考虑使用 confirm 机制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个机制就是当消息收到了，RabbitMQ 会往客户端发送一个通知，客户端收到这个通知后，如果存在一个 confirm 处理器，那么就会回调这个处理器处理。这时候，我们就能确保消息是被中间件收到了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，一定要考虑使用 confirm 处理器去确保消息被 RabbitMQ 服务器收到。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3. 有时候消息出了问题我也需要知道&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在某些业务里，可能需要知道消息发送失败的场景，以便执行失败的处理逻辑。这时候，就要考虑 RabbitMQ 客户端的 return 机制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个机制就是当消息在服务器端路由的时候出现了错误，比如没有 Exchange、或者 RoutingKey 不存在，则 RabbitMQ 会返回一个响应给客户端。客户端收到后会回调 return 的处理器。这时候，客户端所在系统就能感知到这种错误了，从而进行对应的处理。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4. 为了一定不丢消息我也是拼了&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有的时候，消息需要处理强一致性这种事务性质的业务。这时候，就必须开启 RabbitMQ 的事务模式。但是，这个模式会导致整体 RabbitMQ 的性能下降 250 倍。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般没有必要，不建议开启。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5. 把消息写到磁盘上&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般来说，为了防止消息丢失，需要在 RabbitMQ 服务器收到消息的时候，先持久化消息到磁盘上，防止服务器状态出现问题，消息丢失。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，持久化消息，必须先持久化队列，持久化队列完还不行，还必须把消息的 delivery mode 设置为 2，这样才能把消息存到磁盘。但是，这种行为会让整个 RabbitMQ 的性能下降 60%。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种可以根据实际情况进行抉择。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;三、对于收消息这件事，别由着性子来&lt;/span&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1. 能一次拿多个干嘛要一次只拿一个&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很多时候，一些 RabbitMQ 的新手，觉得如果在一个 mainloop 类似的无限循环里，去主动获取消息，会更加及时的获取到消息，也会拥有更加出色的性能。所以，他们会使用 get 这种行为去取代 consume 这种行为。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时候，他们其实已经踩进了大坑。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了能主动 get 服务器消息，很多新手会去写一个无限循环，然后不断尝试去 RabbitMQ 服务器端获取消息。但是，get 方法，其实是只去获取了队列中的第一条消息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而采用 consume 方式呢，它的默认方式是只要有消息，就会批量的拿，直到拿光所有还没消费过的消息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个是一条条拿，一个是批量拿，哪个效率更高一目了然。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，尽量采用 consume 方式获取消息。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2. 拿消息也要讲方法论的&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;消费消息的时候，其实最难掌握的就是：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一次我们到底要取多少条消息？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于 RabbitMQ 来讲，如果我们不对消费行为做限制，他会有多少消息就获取多少消息。这就造成了一个问题：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果消息过多，我们一次性把消息读取到内存，很可能就会把应用的内存挤崩掉。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，我们要对这种情况做一些限制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时候，需要限制一次获取消息的数量，一般来讲，当我们的业务是异步发送，异步消费，不需要实时给回响应的时候，经验数据是一次获取 1000 条。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，系统和系统不一样，硬件条件也不一样，大家可以根据实际的情况来设置一次性获取的消息数量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;重点要说说同步。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在很多时候，我们需要通过 RabbitMQ 传送消息，并能通过临时队列等技巧去实时返回处理结果。这时候，就没办法一次抓多条数据进行处理了，因为，有发送端在等处理结果，依次处理，再依次返回，黄花菜都凉了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而且大部分时候，这种同步等待响应的业务是有顺序要求的。所以，也不能并行同时抓出多条信息处理。那么，彼时，设置每次只消费一条消息就是理所应当的了。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;最后&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从上面的内容中，你也看到了，RabbitMQ 客户端如果要使用，对新手是多可恶的一件事情，各种坑，各种复杂性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，如果你觉得 Spring 之类的 AMQP 客户端框架合你心意，那么你就使用它。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，Spring 的东西有个毛病，如果你要用它，你的应用必须也都要用 Spring。有些时候，也没有这种必要。这时候，你就可以根据我说的这些注意事项和经验，自己开发一套 RabbitMQ 的封装框架，去降低 RabbitMQ 的使用门槛。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，再次感谢读者群里催更的各位兄弟姐妹。还有想进群的读者可以加我微信，拉你入群。我们一起聊技术、工作、八卦。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9852216748768473&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/6nbNnibOq5KQibCDibpTo0kqofPehQvDDibibcb3bQUELdY3Knsl4r0RcgsV9l4icr3icmZQfaBXtSFNTxmdQlAZT1OQg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;609&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我准备了一些纯手打的高质量PDF：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;深入浅出Java多线程、HTTP超全汇总、Java基础核心总结、程序员必知的硬核知识大全、简历面试谈薪的超全干货。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;别看数量不多，但篇篇都是干货，看完的都说很肝。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;领取方式：扫码关注后，在公众号后台回复：666&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.440625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/6nbNnibOq5KSnObMQf98GBHlgrmrLrBjnEX3Dhrp6ibhSlBtM0zFXIgUb1Us6CXON4EMJwyCcKhDxLwTulgAb52Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MTg3NDYwNg==&amp;amp;mid=2247484978&amp;amp;idx=1&amp;amp;sn=e0e741de7970de41ce2a3f8e7c800b05&amp;amp;chksm=fcd8ca73cbaf436593a03ae397e6fce0659595698187552527ea4c868fa8e66f32727b5837dd&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;别人家的团队怎么用RabbitMQ：我总结的5点规范&lt;/a&gt;&lt;strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MTg3NDYwNg==&amp;amp;mid=2247484978&amp;amp;idx=1&amp;amp;sn=e0e741de7970de41ce2a3f8e7c800b05&amp;amp;chksm=fcd8ca73cbaf436593a03ae397e6fce0659595698187552527ea4c868fa8e66f32727b5837dd&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MTg3NDYwNg==&amp;amp;mid=2247484971&amp;amp;idx=1&amp;amp;sn=f6708bd5ca27540806c0dab8d926b97d&amp;amp;chksm=fcd8ca6acbaf437c7d1a85d997fdf79dec93bf468764d389ceea767d2f2172dd353aff677c92&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;最终一致性，一致只会迟到，但绝不会缺席&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MTg3NDYwNg==&amp;amp;mid=2247484940&amp;amp;idx=1&amp;amp;sn=6ccff5e4aaa2d6d73ff4ee441b79991e&amp;amp;chksm=fcd8ca4dcbaf435bdbb2897a12b6da488fdd2f1bf276b70689902de6107937ce73fc19e3ec63&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;当年，我的架构师之路差点完蛋，幸亏了它&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c96ea45cf8a4cbbc43c417a9384c3c90</guid>
<title>读《演进式架构》学习笔记</title>
<link>https://toutiao.io/k/pdyq1ir</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;td class=&quot;blog_detail&quot;&gt;
&lt;input id=&quot;js_detail&quot; type=&quot;hidden&quot; value=&quot;![](http://misc.linkedkeeper.com/misc/img/blog/202102/linkedkeeper0_36c35b03-623e-49e5-9a78-f1d442eb5bce.jpg)&amp;#10;&amp;#10;&amp;lt;i&amp;gt;本笔记不是书的摘抄，内容是通过笔者阅读书之后，对知识内容的消化提炼而成，故不敢以此文指导他人学习，但愿与读者多多交流，如有错误还望多多指点。&amp;lt;/i&amp;gt;&amp;#10;&amp;#10;## 01 什么是演进式架构？&amp;#10;&amp;#10;外文技术书翻译后通常很难理解，此书也不例外，首先，书中对演进式架构的定义就很晦涩 —— 演进式架构是支持跨多个维度进行**引导性**增量变更的架构。&amp;#10;&amp;#10;第一，先多读几遍，念顺了；&amp;#10;&amp;#10;第二，通过拆解关键词，来理解定义。&amp;#10;&amp;#10;**定义中的关键字一**：多个维度。&amp;#10;&amp;#10;所谓多个维度，指的是架构师不要只关注技术维度对架构演进的影响，也要关注数据、安全、运维等纬度的变化影响。除此之外，康威也提醒架构师，还应关注团队之间的协同纬度的变化影响。在现实情况下，一次组织架构的调整，将很大程度影响着架构演进的路径。&amp;#10;&amp;#10;**定义中的关键字二**：增量和引导。&amp;#10;&amp;#10;“增量和引导”是演进式架构包含的两个关键特征，其中“增量”表达了架构随时间不断变化的概念，而“引导”的含义反映了我们期望的架构演进方向。&amp;#10;&amp;#10;回到生物学的隐喻，演进是这样一个过程：建立一个适用的并能在其所处的不断变化的环境中持续运行的系统。&amp;#10;&amp;#10;&amp;lt;br/&amp;gt;&amp;#10;&amp;#10;理解了引导的含义，那么“引导”引导的是什么？引导的原则又是什么？&amp;#10;&amp;#10;我们知道，安全性、吞吐量、低延迟、故障恢复能力都可以定义为系统的架构特征，由于这些特征有的是相互冲突的，比如安全性与性能。所以，对架构师而言，在架构演进过程中需要评估和权衡这些不同的特征，而所谓引导就是评估这些不同架构特征，让架构演进中不随着时间而磨损掉这些特征。简单说，引导就是架构师期望架构具备那些特征。&amp;#10;&amp;#10;关于引导的原则，本书引入了进化计算中的概念 —— 适应度函数，让架构师可以通过适应度函数来解释什么方案更好，并用它衡量何时能达到目标，但笔者通读之后，没有理解，故不过多阐述。&amp;#10;&amp;#10;之后，本书又重点介绍了增量变更、架构耦合对演进式架构的影响，内容围绕持续交付、领域驱动设计、架构演进等方面，内容并不新鲜，故也不做罗列。&amp;#10;&amp;#10;## 02 如何构建可演进的架构&amp;#10;&amp;#10;如何构建？本书的逻辑是这样的。&amp;#10;&amp;#10;架构耦合很大程序决定了技术架构的演进能力，清晰解耦的架构易于演进，反之则会妨碍演进。回答如何构建演进式架构，我理解的是从微服务架构开始，后面的内容基本也都是在围绕着微服务和领域驱动设计再说，有兴趣的读者可以去读一下本书。&quot;/&gt;
&lt;p id=&quot;markdown_detail&quot;/&gt;
&lt;br/&gt;
&lt;p&gt;本文受原创保护，未经作者授权，禁止转载。 linkedkeeper.com (文／张松然)  &lt;a href=&quot;/site/copyright.action&quot;&gt;©著作权归作者所有&lt;/a&gt;&lt;/p&gt;

&lt;/td&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>669a92365a6ba08a08a27d53ef409a8b</guid>
<title>Spring 是如何解析 &lt;bean&gt; 标签的？</title>
<link>https://toutiao.io/k/tk6aq1f</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;前情回顾&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上回「&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU4NzYyMDE4MQ==&amp;amp;mid=2247484614&amp;amp;idx=1&amp;amp;sn=4083d7d8cbc2b35af97f0fd053732f4e&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;Spring IoC 容器初始化（2）&lt;/a&gt;」说到了 Spring 如何解析我们定义的 &amp;lt;bean&amp;gt; 标签，代码跟进了一层又一层，跋山涉水，最终来到了 BeanDefinitionParserDelegate#parseBeanDefinitionElement 方法。不过这个方法只是表面，并未深入解析 &amp;lt;bean&amp;gt; 中的 class 等属性以及 property 等子标签。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文继续跟进。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;嗯，还是要耐着点性子，最好写个 demo 打断点跟踪一下，这样理解起来才更深刻。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;如何解析 &amp;lt;bean&amp;gt; 的内容？&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;继续看代码：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;BeanDefinitionParserDelegate&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; AbstractBeanDefinition &lt;span&gt;parseBeanDefinitionElement&lt;/span&gt;&lt;span&gt;(&lt;br/&gt;        Element ele, String beanName, @Nullable BeanDefinition containingBean)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;      String className = &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;      &lt;span&gt;// 读取 &amp;lt;bean&amp;gt; 标签的 class 属性&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; (ele.hasAttribute(CLASS_ATTRIBUTE)) {&lt;br/&gt;        className = ele.getAttribute(CLASS_ATTRIBUTE).trim();&lt;br/&gt;      }&lt;br/&gt;      String parent = &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;      &lt;span&gt;// 读取 &amp;lt;bean&amp;gt; 标签的 parent 属性&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; (ele.hasAttribute(PARENT_ATTRIBUTE)) {&lt;br/&gt;        parent = ele.getAttribute(PARENT_ATTRIBUTE);&lt;br/&gt;      }&lt;br/&gt;&lt;br/&gt;      &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;// 创建 BeanDefinition 对象（GenericBeanDefinition）&lt;/span&gt;&lt;br/&gt;        AbstractBeanDefinition bd = createBeanDefinition(className, parent);&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 解析 scope、lazy-init、autowire 等属性&lt;/span&gt;&lt;br/&gt;        parseBeanDefinitionAttributes(ele, beanName, containingBean, bd);&lt;br/&gt;        bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT));&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 解析 meta 标签&lt;/span&gt;&lt;br/&gt;        parseMetaElements(ele, bd);&lt;br/&gt;            &lt;br/&gt;        &lt;span&gt;// 解析 lookup-method 标签&lt;/span&gt;&lt;br/&gt;        parseLookupOverrideSubElements(ele, bd.getMethodOverrides());&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 解析 replace-method 标签&lt;/span&gt;&lt;br/&gt;        parseReplacedMethodSubElements(ele, bd.getMethodOverrides());&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 解析 constructor-arg 标签&lt;/span&gt;&lt;br/&gt;        parseConstructorArgElements(ele, bd);&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 解析 property 标签&lt;/span&gt;&lt;br/&gt;        parsePropertyElements(ele, bd);&lt;br/&gt;            &lt;br/&gt;        &lt;span&gt;// 解析 qualifier 标签&lt;/span&gt;&lt;br/&gt;        parseQualifierElements(ele, bd);&lt;br/&gt;&lt;br/&gt;        bd.setResource(&lt;span&gt;this&lt;/span&gt;.readerContext.getResource());&lt;br/&gt;        bd.setSource(extractSource(ele));&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; bd;&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;// catch ...&lt;/span&gt;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里才是真正解析 &amp;lt;bean&amp;gt; 标签内容的地方，比如常见的 class、parent、scope、lazy-init、autowire、property、constructor-arg 等，还有不常见的 lookup-method、replace-method 等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该方法内部调用了一个个方法去解析不同的标签。这里我们只跟进常见的 property 如何解析，其他方法大体也都差不多，有兴趣可以自行研究。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;parsePropertyElements 方法代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;BeanDefinitionParserDelegate&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;  &lt;span&gt;// 解析 property 标签&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;parsePropertyElements&lt;/span&gt;&lt;span&gt;(Element beanEle, BeanDefinition bd)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    NodeList nl = beanEle.getChildNodes();&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; nl.getLength(); i++) {&lt;br/&gt;      Node node = nl.item(i);&lt;br/&gt;      &lt;span&gt;// 筛选 &amp;lt;property&amp;gt; 标签&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; (isCandidateElement(node) &amp;amp;&amp;amp; nodeNameEquals(node, PROPERTY_ELEMENT)) {&lt;br/&gt;        parsePropertyElement((Element) node, bd);&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;parsePropertyElement&lt;/span&gt;&lt;span&gt;(Element ele, BeanDefinition bd)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;// property 标签的 name 属性&lt;/span&gt;&lt;br/&gt;    String propertyName = ele.getAttribute(NAME_ATTRIBUTE);&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (!StringUtils.hasLength(propertyName)) {&lt;br/&gt;      &lt;span&gt;// error&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;this&lt;/span&gt;.parseState.push(&lt;span&gt;new&lt;/span&gt; PropertyEntry(propertyName));&lt;br/&gt;    &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; (bd.getPropertyValues().contains(propertyName)) {&lt;br/&gt;        &lt;span&gt;// error&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt;;&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;// 这里解析得到的是 RuntimeBeanReference 或者 TypedStringValue&lt;/span&gt;&lt;br/&gt;      Object val = parsePropertyValue(ele, bd, propertyName);&lt;br/&gt;      PropertyValue pv = &lt;span&gt;new&lt;/span&gt; PropertyValue(propertyName, val);&lt;br/&gt;      parseMetaElements(ele, pv);&lt;br/&gt;      pv.setSource(extractSource(ele));&lt;br/&gt;      &lt;span&gt;// 将解析到的值添加到 BeanDefinition 的属性列表&lt;/span&gt;&lt;br/&gt;      bd.getPropertyValues().addPropertyValue(pv);&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;finally&lt;/span&gt; {&lt;br/&gt;      &lt;span&gt;this&lt;/span&gt;.parseState.pop();&lt;br/&gt;    }&lt;br/&gt;  }    &lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个方法主要做了什么呢？&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;遍历节点并找到 property 标签&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;解析 property 标签的 name 属性，将它对应的值封装为 RuntimeBeanReference 类型或者 TypedStringValue 类型（其中前者对应 ref 属性，后者对应 value 属性，可参考前文 application-ioc.xml 文件），然后再封装为 PropertyValue 类型，并保存到 BeanDefinition 的属性列表中。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;解析 ref 和 value 的过程如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;BeanDefinitionParserDelegate&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;  public&lt;/span&gt; Object &lt;span&gt;parsePropertyValue&lt;/span&gt;&lt;span&gt;(Element ele, BeanDefinition bd, @Nullable String propertyName)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    String elementName = (propertyName != &lt;span&gt;null&lt;/span&gt; ?&lt;br/&gt;        &lt;span&gt;    &quot;&amp;lt;property&amp;gt; element for property &#x27;&quot;&lt;/span&gt; + propertyName + &lt;span&gt;&quot;&#x27;&quot;&lt;/span&gt; :&lt;br/&gt;            &lt;span&gt;&quot;&amp;lt;constructor-arg&amp;gt; element&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// Should only have one child element: ref, value, list, etc.&lt;/span&gt;&lt;br/&gt;    NodeList nl = ele.getChildNodes();&lt;br/&gt;    Element subElement = &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; nl.getLength(); i++) {&lt;br/&gt;      Node node = nl.item(i);&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; (node &lt;span&gt;instanceof&lt;/span&gt; Element &amp;amp;&amp;amp; !nodeNameEquals(node, DESCRIPTION_ELEMENT) &amp;amp;&amp;amp;&lt;br/&gt;          !nodeNameEquals(node, META_ELEMENT)) {&lt;br/&gt;        &lt;span&gt;// Child element is what we&#x27;re looking for.&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (subElement != &lt;span&gt;null&lt;/span&gt;) {&lt;br/&gt;          error(elementName + &lt;span&gt;&quot; must not contain more than one sub-element&quot;&lt;/span&gt;, ele);&lt;br/&gt;        }&lt;br/&gt;        &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;          subElement = (Element) node;&lt;br/&gt;        }&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// ref 和 value 属性，二者不能并存&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;boolean&lt;/span&gt; hasRefAttribute = ele.hasAttribute(REF_ATTRIBUTE);&lt;br/&gt;    &lt;span&gt;boolean&lt;/span&gt; hasValueAttribute = ele.hasAttribute(VALUE_ATTRIBUTE);&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; ((hasRefAttribute &amp;amp;&amp;amp; hasValueAttribute) ||&lt;br/&gt;        ((hasRefAttribute || hasValueAttribute) &amp;amp;&amp;amp; subElement != &lt;span&gt;null&lt;/span&gt;)) {&lt;br/&gt;      error(elementName +&lt;br/&gt;        &lt;span&gt;&quot; is only allowed to contain either &#x27;ref&#x27; attribute OR &#x27;value&#x27; attribute OR sub-element&quot;&lt;/span&gt;, ele);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// ref 属性&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (hasRefAttribute) {&lt;br/&gt;      String refName = ele.getAttribute(REF_ATTRIBUTE);&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; (!StringUtils.hasText(refName)) {&lt;br/&gt;        error(elementName + &lt;span&gt;&quot; contains empty &#x27;ref&#x27; attribute&quot;&lt;/span&gt;, ele);&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;// 封装为 RuntimeBeanReference 类型&lt;/span&gt;&lt;br/&gt;      RuntimeBeanReference ref = &lt;span&gt;new&lt;/span&gt; RuntimeBeanReference(refName);&lt;br/&gt;      ref.setSource(extractSource(ele));&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; ref;&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;// value 属性&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (hasValueAttribute) {&lt;br/&gt;      &lt;span&gt;// 封装为 TypedStringValue 类型&lt;/span&gt;&lt;br/&gt;      TypedStringValue valueHolder = &lt;span&gt;new&lt;/span&gt; TypedStringValue(ele.getAttribute(VALUE_ATTRIBUTE));&lt;br/&gt;      valueHolder.setSource(extractSource(ele));&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; valueHolder;&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;// 若还有子元素，继续解析&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (subElement != &lt;span&gt;null&lt;/span&gt;) {&lt;br/&gt;      &lt;span&gt;// 这里包含了 property 标签的子标签，例如 list、map、set 等&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; parsePropertySubElement(subElement, bd);&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;      error(elementName + &lt;span&gt;&quot; must specify a ref or value&quot;&lt;/span&gt;, ele);&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;property 标签的解析算是相对复杂的，其他标签（meta、constructor-arg 等）的解析过程大体是类似的，不再一一分析。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;经过 BeanDefinitionParserDelegate#parseBeanDefinitionElement 方法的解析和封装后，就得到了保存我们自定义 bean 信息的 BeanDefinition，即 GenericBeanDefinition。Spring 又把 BeanDefinition 和别名信息封装成了 BeanDefinitionHolder：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;BeanDefinitionParserDelegate&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;  &lt;span&gt;&lt;span&gt;public&lt;/span&gt; BeanDefinitionHolder &lt;span&gt;parseBeanDefinitionElement&lt;/span&gt;&lt;span&gt;(Element ele, @Nullable BeanDefinition containingBean)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    String id = ele.getAttribute(ID_ATTRIBUTE);&lt;br/&gt;    String nameAttr = ele.getAttribute(NAME_ATTRIBUTE);&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// ...&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// 解析后得到的 BeanDefinition&lt;/span&gt;&lt;br/&gt;    AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, containingBean);&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (beanDefinition != &lt;span&gt;null&lt;/span&gt;) {&lt;br/&gt;      &lt;span&gt;// ...&lt;/span&gt;&lt;br/&gt;      String[] aliasesArray = StringUtils.toStringArray(aliases);&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; BeanDefinitionHolder(beanDefinition, beanName, aliasesArray);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，在向 IoC 容器注册之前，还有一个 decorateBeanDefinitionIfRequired 方法，它主要是用来处理默认名称空间（即 http://www.springframework.org/schema/beans）之外的 bean 定义，比如 &amp;lt;tx&amp;gt;、&amp;lt;context&amp;gt; 等，这里仍然先沿着主线走，暂不深入分析。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来就是将 BeanDefinition 注册到 IoC 容器：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;DefaultBeanDefinitionDocumentReader&lt;/span&gt; &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;BeanDefinitionDocumentReader&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span&gt;  // ...&lt;/span&gt;&lt;br/&gt;    &lt;br/&gt;  &lt;span&gt;&lt;span&gt;protected&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;processBeanDefinition&lt;/span&gt;&lt;span&gt;(Element ele, BeanDefinitionParserDelegate delegate)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;// 解析后的 BeanDefinition 封装成的 BeanDefinitionHolder&lt;/span&gt;&lt;br/&gt;    BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (bdHolder != &lt;span&gt;null&lt;/span&gt;) {&lt;br/&gt;      bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder);&lt;br/&gt;      &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;// Register the final decorated instance.&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 注册 BeanDefinition&lt;/span&gt;&lt;br/&gt;        BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry());&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;catch&lt;/span&gt; (BeanDefinitionStoreException ex) {&lt;br/&gt;        getReaderContext().error(&lt;span&gt;&quot;Failed to register bean definition with name &#x27;&quot;&lt;/span&gt; +&lt;br/&gt;        bdHolder.getBeanName() + &lt;span&gt;&quot;&#x27;&quot;&lt;/span&gt;, ele, ex);&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;// Send registration event.&lt;/span&gt;&lt;br/&gt;      getReaderContext().fireComponentRegistered(&lt;span&gt;new&lt;/span&gt; BeanComponentDefinition(bdHolder));&lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;BeanDefinitionReaderUtils&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;  &lt;span&gt;// ...&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;registerBeanDefinition&lt;/span&gt;&lt;span&gt;(&lt;br/&gt;      BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry)&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;throws&lt;/span&gt; BeanDefinitionStoreException &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// Register bean definition under primary name.&lt;/span&gt;&lt;br/&gt;    String beanName = definitionHolder.getBeanName();&lt;br/&gt;    registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// Register aliases for bean name, if any.&lt;/span&gt;&lt;br/&gt;    String[] aliases = definitionHolder.getAliases();&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (aliases != &lt;span&gt;null&lt;/span&gt;) {&lt;br/&gt;      &lt;span&gt;for&lt;/span&gt; (String alias : aliases) {&lt;br/&gt;        registry.registerAlias(beanName, alias);&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;IoC 容器是哪个？如何注册呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前文提到过，Spring 默认的 IoC 容器是 DefaultListableBeanFactory，来看下它的继承结构：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.53046875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/ophTb90oYCSQXV27XgPhoHD5xMXWZokcfQDdhNics8917ka9ncSTCjxnItFuMelWXfnT1FiaL2wVXQrdVHvJ0sjA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到 DefaultListableBeanFactory 实现了 BeanDefinitionRegistry 接口。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所谓的“注册”到 IoC 容器，其实就是把 BeanDefinition 保存到了 DefaultListableBeanFactory  持有的一个 Map 中，如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;DefaultListableBeanFactory&lt;/span&gt; &lt;span&gt;extends&lt;/span&gt; &lt;span&gt;AbstractAutowireCapableBeanFactory&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;ConfigurableListableBeanFactory&lt;/span&gt;, &lt;span&gt;BeanDefinitionRegistry&lt;/span&gt;, &lt;span&gt;Serializable&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;  &lt;span&gt;// ...&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;registerBeanDefinition&lt;/span&gt;&lt;span&gt;(String beanName, BeanDefinition beanDefinition)&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;throws&lt;/span&gt; BeanDefinitionStoreException &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    Assert.hasText(beanName, &lt;span&gt;&quot;Bean name must not be empty&quot;&lt;/span&gt;);&lt;br/&gt;    Assert.notNull(beanDefinition, &lt;span&gt;&quot;BeanDefinition must not be null&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (beanDefinition &lt;span&gt;instanceof&lt;/span&gt; AbstractBeanDefinition) {&lt;br/&gt;    &lt;span&gt;  try&lt;/span&gt; {&lt;br/&gt;        ((AbstractBeanDefinition) beanDefinition).validate();&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;catch&lt;/span&gt; (BeanDefinitionValidationException ex) {&lt;br/&gt;        &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName,&lt;br/&gt;          &lt;span&gt;&quot;Validation of bean definition failed&quot;&lt;/span&gt;, ex);&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// 获取已存在的 BeanDefinition&lt;/span&gt;&lt;br/&gt;    BeanDefinition existingDefinition = &lt;span&gt;this&lt;/span&gt;.beanDefinitionMap.get(beanName);&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (existingDefinition != &lt;span&gt;null&lt;/span&gt;) {&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; (!isAllowBeanDefinitionOverriding()) {&lt;br/&gt;        &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; BeanDefinitionOverrideException(beanName, beanDefinition, existingDefinition);&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;// 这几个异常信息是不是有点眼熟？&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (existingDefinition.getRole() &amp;lt; beanDefinition.getRole()) {&lt;br/&gt;        &lt;span&gt;// e.g. was ROLE_APPLICATION, now overriding with ROLE_SUPPORT or ROLE_INFRASTRUCTURE&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (logger.isInfoEnabled()) {&lt;br/&gt;          logger.info(&lt;span&gt;&quot;Overriding user-defined bean definition for bean &#x27;&quot;&lt;/span&gt; + beanName +&lt;br/&gt;            &lt;span&gt;&quot;&#x27; with a framework-generated bean definition: replacing [&quot;&lt;/span&gt; +&lt;br/&gt;            existingDefinition + &lt;span&gt;&quot;] with [&quot;&lt;/span&gt; + beanDefinition + &lt;span&gt;&quot;]&quot;&lt;/span&gt;);&lt;br/&gt;        }&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (!beanDefinition.equals(existingDefinition)) {&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (logger.isDebugEnabled()) {&lt;br/&gt;          logger.debug(&lt;span&gt;&quot;Overriding bean definition for bean &#x27;&quot;&lt;/span&gt; + beanName +&lt;br/&gt;            &lt;span&gt;&quot;&#x27; with a different definition: replacing [&quot;&lt;/span&gt; + existingDefinition +&lt;br/&gt;            &lt;span&gt;&quot;] with [&quot;&lt;/span&gt; + beanDefinition + &lt;span&gt;&quot;]&quot;&lt;/span&gt;);&lt;br/&gt;        }&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (logger.isTraceEnabled()) {&lt;br/&gt;          logger.trace(&lt;span&gt;&quot;Overriding bean definition for bean &#x27;&quot;&lt;/span&gt; + beanName +&lt;br/&gt;            &lt;span&gt;&quot;&#x27; with an equivalent definition: replacing [&quot;&lt;/span&gt; + existingDefinition +&lt;br/&gt;            &lt;span&gt;&quot;] with [&quot;&lt;/span&gt; + beanDefinition + &lt;span&gt;&quot;]&quot;&lt;/span&gt;);&lt;br/&gt;        }&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;this&lt;/span&gt;.beanDefinitionMap.put(beanName, beanDefinition);&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; (hasBeanCreationStarted()) {&lt;br/&gt;        &lt;span&gt;// Cannot modify startup-time collection elements anymore (for stable iteration)&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;synchronized&lt;/span&gt; (&lt;span&gt;this&lt;/span&gt;.beanDefinitionMap) {&lt;br/&gt;          &lt;span&gt;this&lt;/span&gt;.beanDefinitionMap.put(beanName, beanDefinition);&lt;br/&gt;          List&amp;lt;String&amp;gt; updatedDefinitions = &lt;span&gt;new&lt;/span&gt; ArrayList&amp;lt;&amp;gt;(&lt;span&gt;this&lt;/span&gt;.beanDefinitionNames.size() + &lt;span&gt;1&lt;/span&gt;);&lt;br/&gt;          updatedDefinitions.addAll(&lt;span&gt;this&lt;/span&gt;.beanDefinitionNames);&lt;br/&gt;          updatedDefinitions.add(beanName);&lt;br/&gt;          &lt;span&gt;this&lt;/span&gt;.beanDefinitionNames = updatedDefinitions;&lt;br/&gt;          removeManualSingletonName(beanName);&lt;br/&gt;        }&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;// 注册到 Map 中&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// Still in startup registration phase&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;this&lt;/span&gt;.beanDefinitionMap.put(beanName, beanDefinition);&lt;br/&gt;        &lt;span&gt;this&lt;/span&gt;.beanDefinitionNames.add(beanName);&lt;br/&gt;        removeManualSingletonName(beanName);&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;this&lt;/span&gt;.frozenBeanDefinitionNames = &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;&lt;span&gt;    if&lt;/span&gt; (existingDefinition != &lt;span&gt;null&lt;/span&gt; || containsSingleton(beanName)) {&lt;br/&gt;      resetBeanDefinition(beanName);&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (isConfigurationFrozen()) {&lt;br/&gt;      clearByTypeCache();&lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面几个异常信息是不是有点眼熟？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个 beanDefinitionMap 是个什么呢？它就是个 Map：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;/** Map of bean definition objects, keyed by bean name. */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; Map&amp;lt;String, BeanDefinition&amp;gt; beanDefinitionMap = &lt;span&gt;new&lt;/span&gt; ConcurrentHashMap&amp;lt;&amp;gt;(&lt;span&gt;256&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;小结&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到这里，Spring 已经从我们定义的 application-ioc.xml 文件中读取和解析到了 &amp;lt;bean&amp;gt; 标签的信息，并将其转换为内部的数据结构 BeanDefinition，然后注册到了 IoC 容器（也就是 DefaultListableBeanFactory）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了有个整体的把握，这里把主要流程梳理成了一个思维导图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.421011673151751&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/ophTb90oYCSQXV27XgPhoHD5xMXWZokcuf6gmFZnXo2KoBFdTInuLm5wJDFSFrSN9CT1m81RUTfGobTiaQ1em0Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2570&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实前面几篇文章主要是第一个步骤，也就是「初始化 BeanFactory，注册 Bean 定义」，而且只是沿着一条主线走下来的，其它细节部分有兴趣的小伙伴可以自行研究。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;IoC 容器已经建立，而且 BeanDefinition 也放进去了，如何从容器拿到我们想要的对象呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;欲知后事如何，且听下回分解~&lt;/p&gt;&lt;hr/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;咱也来体验一下这个名片&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU4NzYyMDE4MQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/ophTb90oYCSstvZP4AJ5fAFSlibueYhriaZdtxJfOb7OwWTdFVS044kDFlH2xgGSJxWEjdO24QTSp2ukBbnjIeFA/0?wx_fmt=png&quot; data-nickname=&quot;WriteOnRead&quot; data-alias=&quot;WriteOnRead&quot; data-signature=&quot;Java学习与分享。知易行难，坚持更难。加油！&quot;/&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>be60a453a77e1173886a60050b57760c</guid>
<title>条分缕析 Raft 算法（续）：日志压缩和性能优化</title>
<link>https://toutiao.io/k/sfxw3o1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;em data-darkmode-color-16136621561195=&quot;rgb(128, 157, 185)&quot; data-darkmode-original-color-16136621561195=&quot;#fff|rgb(52, 73, 94)|rgb(52, 73, 94)&quot; data-style=&quot;caret-color: rgb(52, 73, 94); color: rgb(52, 73, 94); font-family: &amp;quot;Source Sans Pro&amp;quot;, &amp;quot;Helvetica Neue&amp;quot;, Arial, sans-serif; font-size: 16px; text-align: start; white-space: normal; text-size-adjust: auto;&quot; class=&quot;js_darkmode__1&quot;&gt;&lt;strong data-darkmode-bgcolor-16068282692859=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16068282692859=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-16068282692859=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16068282692859=&quot;rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; font-size: medium; letter-spacing: 0.544px; text-align: start; white-space: normal; caret-color: rgb(52, 73, 94); background-color: rgb(255, 255, 255); color: rgb(0, 0, 0); font-family: -apple-system-font, system-ui, &amp;quot;Helvetica Neue&amp;quot;, &amp;quot;PingFang SC&amp;quot;, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei UI&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif; visibility: visible; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__2&quot; data-darkmode-color-16094149065186=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16094149065186=&quot;rgb(0, 0, 0)&quot; data-darkmode-color-16107273892940=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16107273892940=&quot;#fff|rgb(52, 73, 94)|rgb(0, 0, 0)&quot; data-darkmode-color-16121907968588=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16121907968588=&quot;#fff|rgb(52, 73, 94)|rgb(0, 0, 0)&quot; data-darkmode-bgcolor-16121907968588=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16121907968588=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16136621561195=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16136621561195=&quot;#fff|rgb(52, 73, 94)|rgb(52, 73, 94)|rgb(0, 0, 0)&quot; data-darkmode-bgcolor-16136621561195=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16136621561195=&quot;#fff|rgb(255, 255, 255)&quot;&gt;&lt;span data-darkmode-bgcolor-16068282692859=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16068282692859=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-16068282692859=&quot;rgb(136, 136, 136)&quot; data-darkmode-original-color-16068282692859=&quot;rgb(136, 136, 136)&quot; data-darkmode-color-16094149065186=&quot;rgb(136, 136, 136)&quot; data-darkmode-original-color-16094149065186=&quot;rgb(136, 136, 136)&quot; data-darkmode-color-16107273892940=&quot;rgb(136, 136, 136)&quot; data-darkmode-original-color-16107273892940=&quot;#fff|rgb(52, 73, 94)|rgb(0, 0, 0)|rgb(136, 136, 136)&quot; data-darkmode-color-16121907968588=&quot;rgb(136, 136, 136)&quot; data-darkmode-original-color-16121907968588=&quot;#fff|rgb(52, 73, 94)|rgb(0, 0, 0)|rgb(136, 136, 136)&quot; data-darkmode-bgcolor-16121907968588=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16121907968588=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16136621561195=&quot;rgb(136, 136, 136)&quot; data-darkmode-original-color-16136621561195=&quot;#fff|rgb(52, 73, 94)|rgb(52, 73, 94)|rgb(0, 0, 0)|rgb(136, 136, 136)&quot; data-darkmode-bgcolor-16136621561195=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16136621561195=&quot;#fff|rgb(255, 255, 255)&quot;&gt;&lt;span data-darkmode-bgcolor-16068282692859=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16068282692859=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-16068282692859=&quot;rgb(217, 33, 66)&quot; data-darkmode-original-color-16068282692859=&quot;rgb(217, 33, 66)&quot; data-darkmode-color-16094149065186=&quot;rgb(217, 33, 66)&quot; data-darkmode-original-color-16094149065186=&quot;rgb(217, 33, 66)&quot; data-darkmode-color-16107273892940=&quot;rgb(217, 33, 66)&quot; data-darkmode-original-color-16107273892940=&quot;#fff|rgb(52, 73, 94)|rgb(0, 0, 0)|rgb(136, 136, 136)|rgb(217, 33, 66)&quot; data-darkmode-color-16121907968588=&quot;rgb(217, 33, 66)&quot; data-darkmode-original-color-16121907968588=&quot;#fff|rgb(52, 73, 94)|rgb(0, 0, 0)|rgb(136, 136, 136)|rgb(217, 33, 66)&quot; data-darkmode-bgcolor-16121907968588=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16121907968588=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16136621561195=&quot;rgb(217, 33, 66)&quot; data-darkmode-original-color-16136621561195=&quot;#fff|rgb(52, 73, 94)|rgb(52, 73, 94)|rgb(0, 0, 0)|rgb(136, 136, 136)|rgb(217, 33, 66)&quot; data-darkmode-bgcolor-16136621561195=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16136621561195=&quot;#fff|rgb(255, 255, 255)&quot;&gt;▲ &lt;/span&gt;&lt;span data-darkmode-bgcolor-16068282692859=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16068282692859=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-16068282692859=&quot;rgb(39, 84, 255)&quot; data-darkmode-original-color-16068282692859=&quot;rgb(2, 30, 170)&quot; data-style=&quot;max-width: 100%; color: rgb(2, 30, 170); text-align: center; font-size: 11px; letter-spacing: 1px; visibility: visible;&quot; class=&quot;js_darkmode__3&quot; data-darkmode-color-16094149065186=&quot;rgb(39, 84, 255)&quot; data-darkmode-original-color-16094149065186=&quot;rgb(2, 30, 170)&quot; data-darkmode-color-16107273892940=&quot;rgb(39, 84, 255)&quot; data-darkmode-original-color-16107273892940=&quot;#fff|rgb(52, 73, 94)|rgb(0, 0, 0)|rgb(136, 136, 136)|rgb(2, 30, 170)&quot; data-darkmode-color-16121907968588=&quot;rgb(39, 84, 255)&quot; data-darkmode-original-color-16121907968588=&quot;#fff|rgb(52, 73, 94)|rgb(0, 0, 0)|rgb(136, 136, 136)|rgb(2, 30, 170)&quot; data-darkmode-bgcolor-16121907968588=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16121907968588=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16136621561195=&quot;rgb(39, 84, 255)&quot; data-darkmode-original-color-16136621561195=&quot;#fff|rgb(52, 73, 94)|rgb(52, 73, 94)|rgb(0, 0, 0)|rgb(136, 136, 136)|rgb(2, 30, 170)&quot; data-darkmode-bgcolor-16136621561195=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16136621561195=&quot;#fff|rgb(255, 255, 255)&quot;&gt;点击上方&quot;多颗糖&quot;&lt;/span&gt;&lt;span data-darkmode-bgcolor-16068282692859=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16068282692859=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-16068282692859=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16068282692859=&quot;rgb(62, 62, 62)&quot; data-style=&quot;max-width: 100%; color: rgb(62, 62, 62); text-align: center; font-size: 11px; letter-spacing: 1px; visibility: visible;&quot; class=&quot;js_darkmode__4&quot; data-darkmode-color-16094149065186=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16094149065186=&quot;rgb(62, 62, 62)&quot; data-darkmode-color-16107273892940=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16107273892940=&quot;#fff|rgb(52, 73, 94)|rgb(0, 0, 0)|rgb(136, 136, 136)|rgb(62, 62, 62)&quot; data-darkmode-color-16121907968588=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16121907968588=&quot;#fff|rgb(52, 73, 94)|rgb(0, 0, 0)|rgb(136, 136, 136)|rgb(62, 62, 62)&quot; data-darkmode-bgcolor-16121907968588=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16121907968588=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16136621561195=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16136621561195=&quot;#fff|rgb(52, 73, 94)|rgb(52, 73, 94)|rgb(0, 0, 0)|rgb(136, 136, 136)|rgb(62, 62, 62)&quot; data-darkmode-bgcolor-16136621561195=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16136621561195=&quot;#fff|rgb(255, 255, 255)&quot;&gt;关注公众号&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;在上篇&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwODA2NjIxOA==&amp;amp;mid=2247484140&amp;amp;idx=1&amp;amp;sn=37876b5dda5294ea7f6211f0a3300ea5&amp;amp;chksm=97098129a07e083fe65f8b87c2ec516b630a8f210961038f0091fbcd69468b41edbe193891ee&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;《条分缕析 Raft 算法》&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;《条分缕析 Raft 算法》&lt;/a&gt;中推导和梳理了 Raft 算法，但仍有一些细节没有包含到，这篇文章作为补充。&lt;/p&gt;&lt;h2&gt;1 日志压缩&lt;/h2&gt;&lt;p&gt;随着时间推移，存储的日志会越来越多，不但占据很多磁盘空间，服务器重启做日志重放也需要更多的时间。如果没有办法来压缩日志，将会导致可用性问题：要么磁盘空间被耗尽，要么花费太长时间启动。所以日志压缩是必要的。&lt;/p&gt;&lt;p&gt;日志压缩的一般思路是，日志中的许多信息随着时间推移会变成过时的，可以丢弃。例如：一个将 x 设置为 2 的操作，如果在未来将 x 设置为了 3，那么 x=2 这个操作就过时了，可以丢弃。&lt;/p&gt;&lt;p&gt;一旦日志记录被提交并应用于状态机，那么用于到达当前状态的中间状态和操作就不再需要了，它们可以被压缩掉。&lt;/p&gt;&lt;p&gt;和配置变化不同，不同的系统有不同的日志压缩方式，取决于你的性能考量，以及基于硬盘还是基于内存。&lt;strong&gt;日志压缩的大部分责任都落在状态机上。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;不同的压缩方法有几个核心的共同点：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;不将压缩决定集中在 Leader 上，每个服务器独立地压缩其已提交的日志&lt;/strong&gt;。这就避免了 Leader 将日志传递给已有该日志的 Follower，同时也增强了模块化，减少交互，将整个系统的复杂性最小化。（对于非常小的状态机，基于 Leader 的日志压缩也许更好。）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;将之前的 log 的维护责任从 Raft 转移到状态机&lt;/strong&gt;。Raft 要保存最后被丢弃的记录的index和term，用于&lt;span&gt; &lt;/span&gt;&lt;code&gt;AppendEntries RPC&lt;/code&gt;一致性检查。同时，也需要保存最新的配置信息：成员变更失败需要回退配置，最近的配置必须保存。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;一旦丢弃了前面部分的日志，状态机就承担两个新的责任：1. 如果服务器重启了，需要将最新的快照加载到状态机后再接受 log；此外，2. 需要向较慢的 follower(日志远落后于 Leader)发送一致的状态镜像。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;1.1 基于内存的状态机的快照&lt;/h3&gt;&lt;p&gt;状态机的数据集小于 10GB 的时候选择 memory-based 状态机是合理的。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5674157303370787&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hBL5R2neMA2kqXZgc8tIcKoOAgdUubEHk0sZeiayJPfsrqD7R1YebXUOKxOH3ib7vKdHLJbicesTyYoyicNO3ATEWw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;712&quot;/&gt;&lt;/p&gt;&lt;p&gt;上图显示了 memory-based 状态机的基本想法：对内存的数据结构(树形或哈希等)进行序列化并存储，同时存储 Raft 重启需要的状态：最后一条记录的 index 和 term 以及该索引处的最新配置，然后这个 index 之前的日志和快照都可以丢弃了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;memory-based 状态机的快照的大部分工作是序列化内存中的数据结构&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;通过上面的介绍，Leader 可能偶尔需要把它的状态发送给慢 Followers 或新加入集群的服务器。快照信息通过&lt;span&gt; &lt;/span&gt;&lt;code&gt;InstallSnapshot RPC&lt;/code&gt;&lt;span&gt; &lt;/span&gt;来传输。你肯定在论文中看过下图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;1.4824281150159744&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hBL5R2neMA2kqXZgc8tIcKoOAgdUubEHSFdf1ugroq9TDyYTF8cHscebqVTepWZRo4IMwAIbH6pZjOrIux8Mhw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;626&quot;/&gt;&lt;/p&gt;&lt;h4&gt;1.1.1 快照的并发性&lt;/h4&gt;&lt;p&gt;创建一个快照需要耗费很长时间，包括序列化和写入磁盘。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;例如，在今天的服务器上拷贝 10GB 的内存花费大约1秒钟，序列化它通常将花费更长的时间：即使 SSD 1秒钟也仅能写入大约 100MB。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;因此，序列化和写快照都要与常规操作并发进行，避免服务不可用。&lt;/p&gt;&lt;p&gt;copy-on-write 技术允许进行新的更新而不影响写快照。有两个方法来实现：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;状态机可以用不可变的(immutable)数据结构来实现。因为状态机命令不会 in-place 的方式来修改状态(通常使用追加的方式)，快照任务可以引用之前状态的并把状态一致地写入到快照。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;另外，也可以使用操作系统的 copy-on-write。例如，在 Linux 上可以使用 fork 来复制父进程的整个地址空间，然后子进程就可以把状态机的状态写出并退出，整个过程中父进程都可以持续地提供服务。LogCabin中当前使用的就是这种方法。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;1.1.2 何时做快照&lt;/h4&gt;&lt;p&gt;服务器需要决定什么时候做快照。太过频繁地做快照，将会浪费磁盘带宽和其他资源；太不频繁地做快照，则有存储空间耗尽的风险，并且重启服务需要更长的重放日志时间。&lt;/p&gt;&lt;p&gt;一个简单的策略是设置一个阈值，当日志大小超过阈值则做快照。然而，这会导致对于小型状态机时有着不必要的大日志。&lt;/p&gt;&lt;p&gt;一个更好的方法是引入快照大小和日志大小的对比，如果日志超过快照好几倍，可能就需要做快照。但是在做快照之前计算快照的大小是困难并且繁重的，会引入额外负担。所以使用前一个快照的大小是比较合理的行为，一旦日志大小超过之前的快照的大小乘以扩展因子(expansion factor)，服务器就做快照。&lt;/p&gt;&lt;p&gt;这个扩展因子权衡空间和带宽利用率。例如，扩展因子为 4 的话会有 20% 的带宽用于快照(每1byte 的快照写入有对应的 4bytes 的 log 写入)和大约 6 倍的硬盘空间使用(旧的快照+日志+新的快照)。&lt;/p&gt;&lt;p&gt;快照仍然会导致 CPU 和磁盘的占用率突发，可以增加额外的磁盘来减轻该现象。&lt;/p&gt;&lt;p&gt;同时，可以通过调度使得做快照对客户端请求没有影响。服务器需要协调保证在某一时刻集群只有小部分成员集同时在做快照。由于 Raft 是多数派成员构成的 commit，所以这样就不会影响请求的提交了。当 Leader 想做快照的时候，首先要先下台，让其他服务器选出另一个 Leader 接替工作。如果这个方法充分地可行，就可能消除快照的并发，服务器在快照期间其实是不可用的(这可能会造成集群的容错能力降低的问题)。这是一个令人兴奋的提升集群性能并降低实现机制的机会。（这里其实可以通过实现指定服务器做快照来优化，braft 里就有提到这点。）&lt;/p&gt;&lt;h4&gt;1.1.3 实现的关注点&lt;/h4&gt;&lt;p&gt;这一节回顾快照的主要组件的实现并讨论实现的难点：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;保存和加载快照&lt;/strong&gt;：保存快照需要对其序列化并写入磁盘，而加载则是反序列化。通过流式接口(streaming interface)可以避免将整个快照缓冲到内存中。可能对流进行压缩并附带一个 checksum 比较好。LogCabin 先把快照写入一个临时文件，当写完并且刷到磁盘后，再把文件改名。这是为了避免server启动的时候加载到部分的快照。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;传输快照&lt;/strong&gt;：传输快照牵涉到如何实现&lt;span&gt; &lt;/span&gt;&lt;code&gt;InstallSnapshot RPC&lt;/code&gt;。传输的性能通常不是非常重要(一个需要这种动作的 Follower 不会参与到日志的 commit 决策中，因此不需要立即完成)。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;消除不安全的日志访问和丢弃日志条目&lt;/strong&gt;：最初设计 LogCabin 的时候没有考虑日志压缩，因此代码上假定了如果 entry i 在日志中，那么 entry 1 到 i - 1 也一定在日志中。有了日志压缩，这就不再成立了，前面的 entry 可能已经被丢弃了。这里需要仔细推理和测试。可能对一些强类型的系统做这些是简单的，编译器会强制检查日志访问并处理越界的问题。一旦我们使得所有的日志访问都是安全的，丢弃前面的日志就很直接了。在这之前，我们都只能单独地测试保存、加载和传输快照。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;通过 copy-on-write 并发地做快照&lt;/strong&gt;：可能需要重新设计状态机或利用操作系统的 fork。LogCabin 当前使用的是 fork，相比于线程交互性很差，要使其正确工作也有一定的难度。然而，它的代码量很小，而且不需要修改状态机数据结构。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;决定何时做快照&lt;/strong&gt;：我们建议&lt;strong&gt;在开发的过程中每应用一条日志就做一个快照，这样便于快速定位问题&lt;/strong&gt;。一旦实现完成，就需要增加一个更有效的机制选择什么时候做快照。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;1.2 基于磁盘的状态机的快照&lt;/h3&gt;&lt;p&gt;对于几十或上百 GB 的状态机，需要使用磁盘作为主要存储。对于每一条记录，当其被提交并应用到状态机后，其实就可以被丢弃了，因为磁盘已经持久化存储了，可以理解为每条日志就做了一个快照。&lt;/p&gt;&lt;p&gt;Disk-based 状态机的主要问题是，磁盘会导致性能不佳。在没有写缓冲的情况下，每应用一条命了都需要进行一次或多次随机磁盘写入，这会限制系统的整体吞吐量。&lt;/p&gt;&lt;p&gt;Disk-based 状态机仍然需要支持向日志落后的 Follower 提供最新的快照，而写快照也要继续提供服务，所以仍然需要 copy-on-write 技术以在一定期间内保持一个一致地快照传输。幸运的是，磁盘总是被划分为逻辑块，因此在状态机中实现应该是直接的。基于磁盘的状态机也可以依靠操作系统的支持，例如 Linux 的 LVM 也可以用来创建快照。&lt;/p&gt;&lt;h4&gt;1.2.1 增量清理的方法&lt;/h4&gt;&lt;p&gt;增量的方法做压缩如 log cleaning 或 LSM tree，是可能的。他们快照的实现会更复杂，但有如下优点：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;每次只操作数据的一部分，所以压缩的负载随着时间来看是均匀的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;写入磁盘的效率更高。它们使用大范围的、连续的写入。递增清理的方法可以有选择的压缩磁盘中拥有最多可重复使用空间的部分，可以写入更少的数据。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;传递快照更为简单，因为它们不会 in-place 地修改磁盘的区域。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;1.2.2 Log cleaning&lt;/h4&gt;&lt;p&gt;来自于&lt;span&gt; &lt;/span&gt;The Design and Implementation of a Log-Structured File System。&lt;/p&gt;&lt;p&gt;Log cleaning 写入时直接追加，日志被切分为多个连续的 Segments。每一个 segment 通过以下三个步骤进行压缩：&lt;/p&gt;&lt;p&gt;为了最小化对正常操作的影响，这个过程应该并发地做。&lt;/p&gt;&lt;p&gt;由于将有效的记录转存到日志的头部，日志出现乱序，可以包含附加的信息(比如 version number)以在日志应用的时候重建正确的顺序。&lt;/p&gt;&lt;p&gt;选择哪些段做清理的策略对性能有非常大的影响。Log cleaning 建立了一个模型，不仅考虑live entry 的占比，同时考虑这些 entry 会存活多长时间。&lt;strong&gt;但不幸的是，每个状态机的 live entry 会有所不同&lt;/strong&gt;。&lt;/p&gt;&lt;h4&gt;1.2.3 LSM tree&lt;/h4&gt;&lt;p&gt;LSM tree 由于 BigTable 的提出被广泛使用。&lt;/p&gt;&lt;p&gt;LSM tree 是树型的数据结构，存储有序的键值对。在高层次上和 Log cleaning 一样：大的顺序写并且不 in-place 地修改磁盘上的数据。。然而，LSM tree 并没有在日志中维护所有状态，而是重新组织状态以便更好地进行随机读。&lt;/p&gt;&lt;p&gt;典型的 LSM tree 将最近的写入在磁盘上保持一份小的 log。当 log 达到一定的大小后，对 key 进行排序并且写入一个叫做 run 的文件中。Runs 不会 in-place 修改，但是会周期性地对 runs 进行 merge，产生新的 runs 并丢弃旧的，merge 的过程像 merge sort。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;1.2861035422343323&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hBL5R2neMA2kqXZgc8tIcKoOAgdUubEH5eUxe6Jic9DOy6Mq1IApibOOXniccGUWY4ibnt3War6m4H99wZ8pn6tPmw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;367&quot;/&gt;&lt;/p&gt;&lt;p&gt;在正常操作期间，状态机可以直接在这些数据上操作。对于读一个 key 来说，首先检查是否在最近的 log 中有修改，之后检查每一个 run。为了避免对每一个 run 做 key 的检查，一些系统对每一个 run 创建了 bloom filter。&lt;/p&gt;&lt;h4&gt;1.2.4 Raft 中的 Log cleaning 和 LSM tree&lt;/h4&gt;&lt;p&gt;LogCabin 还未实现 Log cleaning 或 LSM tree，把 LSM tree 应用到 Raft 是直截了当的，因为 Raft 日志已经将最近的记录持久地存储在磁盘上，LSM tree 可以将最近的数据以更方便的树型保存在内存中，这将提高查找的性能。并且当 Raft 日志达到指定大小的时候，这个树按顺序写到磁盘作为一个新的 run。传输状态的时候 Leader 需要把所有的 run 发送给Follower(不包含内存中的树)；幸运的是，runs 都是不可变的，所以不必担心传输过程中 runs 被修改。&lt;/p&gt;&lt;p&gt;把 Log cleaning 应用到 Raft 就不是这么明显了。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5247148288973384&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hBL5R2neMA2kqXZgc8tIcKoOAgdUubEHZN4SdOT1p6duib5zX60bTzmsMdtttbXHUx6sn7dV5C6lib2d5WB9PniaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;789&quot;/&gt;&lt;/p&gt;&lt;h3&gt;1.3 其它日志压缩&lt;/h3&gt;&lt;p&gt;略。&lt;/p&gt;&lt;h2&gt;2 性能优化&lt;/h2&gt;&lt;h3&gt;2.1 Writing to the leader’s disk in parallel&lt;/h3&gt;&lt;p&gt;在前面的实现中，Leader 将日志写到磁盘后，再将该日志复制到它的 Follower，然后等待 Follower 将该日志写到他们的磁盘上。这里出现了两次连续的磁盘写入等待，这将导致显著的延迟。&lt;/p&gt;&lt;p&gt;Leader 可以在向 Follower 并行复制日志的同时写入自己的磁盘，如图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.34620174346201743&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hBL5R2neMA2kqXZgc8tIcKoOAgdUubEHvkw3dM4NPwyzkyjk9chFFMyPbnZ9kl58bxT3wMWVXsaINCm5LqpH1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;803&quot;/&gt;&lt;/p&gt;&lt;p&gt;a 是没有并行优化的，而 b 是进行并行优化的。&lt;/p&gt;&lt;p&gt;如果多数派 Follower 已经写入磁盘，Leader 甚至可以在该记录写入自己的磁盘之前就提交，这仍然是安全的。&lt;/p&gt;&lt;h3&gt;2.2 Batch 和 Pipeline&lt;/h3&gt;&lt;p&gt;Raft 支持 Batch 和 Pipeline，这两者对性能提升都很重要。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Batch：Leader 可以一次收集多个客户端 requests，然后一批发送给 Follower。当然，我们也需要有一个最大发送 size 来限制每次最多可以发送多少数据，LogCabin 使用 1M 大小。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Pipeline：如果只是用 batch，Leader 还是需要等待 Follower 返回才能继续后面的流程，我们这里还可以使用 Pipeline 来进行加速。Leader 会维护一个&lt;span&gt; &lt;/span&gt;&lt;code&gt;nextIndex&lt;/code&gt;&lt;span&gt; &lt;/span&gt;的变量来表示下一个给 Follower 发送的 log 位置，通常情况下，只要 Leader 跟 Follower 建立起了连接，我们都会认为网络是稳定互通的。所以当 Leader 给 Follower 发送了一批 log 之后，它可以直接更新&lt;span&gt; &lt;/span&gt;&lt;code&gt;nextIndex&lt;/code&gt;，并且立刻发送后面的 log，不需要等待 Follower 的返回。如果网络出现了错误，或者 Follower 返回一些错误，Leader 就重新调整&lt;span&gt; &lt;/span&gt;&lt;code&gt;nextIndex&lt;/code&gt;，然后重新发送 log。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;AppendEntries RPC&lt;/code&gt;&lt;span&gt; &lt;/span&gt;一致性检查保证了 pipeline 的安全性，但是，如果 RPC 失败/超时了，Leader 就要将&lt;span&gt; &lt;/span&gt;&lt;code&gt;nextIndex&lt;/code&gt;&lt;span&gt; &lt;/span&gt;递减回到初始值重来。如果&lt;span&gt; &lt;/span&gt;&lt;code&gt;AppendEntries RPC&lt;/code&gt;&lt;span&gt; &lt;/span&gt;一致性检查还是失败，Leader 可能进一步递减&lt;span&gt; &lt;/span&gt;&lt;code&gt;nextIndex&lt;/code&gt;&lt;span&gt; &lt;/span&gt;重试发送前一个记录，或者等待前一个记录被确认。&lt;/p&gt;&lt;p&gt;最初的线程架构阻碍了 pipeline，因为它只能支持每个 Follower 一个 RPC。这里 Leader 必须多线程地与一个 Follower 建立多个连接。&lt;/p&gt;&lt;p&gt;如果 Leader 与一个 Follower 共用一个连接使用 pipeline 的话, 那么效果会是怎样的呢?其实这样和 Batch 没有多大区别，tcp 层面已经是串行的了，tcp 有滑动窗口来做 batch，同时单条连接保证了消息很少会乱序。&lt;/p&gt;&lt;p&gt;那么，如果使用多线程连接的话可能存在什么问题？即使因为在多个连接中不能保证有序，但是大部分情况还是先发送的先到达；即使后发送的先到达了，由于有&lt;span&gt; &lt;/span&gt;&lt;code&gt;AppendEntries RPC&lt;/code&gt;&lt;span&gt; &lt;/span&gt;一致性检查的存在，后发送的自然会失败，失败后重试即可。&lt;/p&gt;&lt;p&gt;Raft 系统的整体性能在很大程度上取决于如何安排 batch 和 pipeline。如果在高负载的情况下，一个 batch 中积累的请求数量不够，整体处理效率就会很低，导致低吞吐量和高延迟。另一方面，如果在一个 batch 中积累了太多的请求，延迟将不必要地变高，因为早期的请求要等待后来的请求到达。&lt;/p&gt;&lt;h3&gt;2.3 pre-vote&lt;/h3&gt;&lt;p&gt;网络分区会导致某个节点的数据与集群最新数据差距拉大，但是 term 因为不断尝试选主而变得很大。网络恢复之后，Leader 向其进行日志复制时，就会导致 Leader 因为 term 较小而下台。这种情况可以引入 pre-vote 来避免。Follower 在转变为 Candidate 之前，先与集群节点通信，获得集群 Leader 是否存活的信息，如果当前集群有 Leader 存活，Follower 就不会转变为 Candidate，也不会增加term。&lt;/p&gt;&lt;h3&gt;2.4 MultiRaft&lt;/h3&gt;&lt;p&gt;来自 CockroachDB 的优化：https://www.cockroachlabs.com/blog/scaling-RAFT/&lt;/p&gt;&lt;p&gt;Raft 的 Leader 向 Follower 的心跳间隔一般都较小，在 100ms 粒度，当复制实例数较多的时候，心跳包的数量就呈指数增长。如图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.72&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hBL5R2neMA2kqXZgc8tIcKoOAgdUubEHLOvocEwe1Nb5hQFicn8EBuXH11JUbnNkfVUbUHCkr7mtnpk9qXkgMdA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;300&quot;/&gt;&lt;/p&gt;&lt;p&gt;这里将复制组之间的心跳合并到节点之间的心跳。如图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.7066666666666667&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hBL5R2neMA2kqXZgc8tIcKoOAgdUubEHXY6pBibD4XAPDsicQlXibSXs5n2BjKdl5SWRgponJAZLDVnnNSVcSYuWQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;300&quot;/&gt;&lt;/p&gt;&lt;p&gt;braft 提供了静默模式：通常复制组不需要频繁的切换 Leader，我们可以将主动 Leader Election 的功能关闭，这样就不需要维护 Leader Lease 的心跳了。复制组依靠业务 Master 进行被动触发 Leader Election，这个可以只在 Leader 节点宕机时触发，整体的心跳数就从复制实例数降为节点数。&lt;/p&gt;&lt;h2&gt;Reference&lt;/h2&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;CONSENSUS BRIDGING THEORY AND PRACTICE:&lt;span&gt; &lt;/span&gt;https://web.stanford.edu/~ouster/cgi-bin/papers/OngaroPhD.pdf&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;理论基础 · Raft phd 论文中的pipeline 优化:&lt;span&gt; &lt;/span&gt;http://mysql.taobao.org/monthly/2019/03/08/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;TiKV 源码解析系列 - Raft 的优化:&lt;span&gt; &lt;/span&gt;https://zhuanlan.zhihu.com/p/25735592&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Scaling Raft:&lt;span&gt; &lt;/span&gt;https://www.cockroachlabs.com/blog/scaling-RAFT/&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;RAFT介绍:&lt;span&gt; &lt;/span&gt;https://github.com/baidu/braft/blob/master/docs/cn/raft_protocol.md&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p/&gt;&lt;h2&gt;相关阅读&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;欢迎关注我的公众号：&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.36484375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hBL5R2neMA0PQZZyg2UDdVFmgOic1w9rm3ZW3abQc06ibpYefXJykbeQ6NhFeV82KMG5CEKvsMbAvRw9VnmjMibug/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>770d4700fcf9b5a6b02f91a3541dd684</guid>
<title>gRPC 的 4 种基础通信模式</title>
<link>https://toutiao.io/k/3sn14va</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;题图 |  from freepik&lt;/span&gt;&lt;/p&gt;&lt;p&gt;本文将讨论 gRPC 应用程序的 4 种基础通信模式：一元 RPC、服务器端流 RPC、客户端流 RPC 以及双向流 RPC。在这个过程中，我们会使用一些真实用例来展示每种模式，使用 gRPC IDL 进行服务定义，并使用 Go 语言来实现服务和客户端。&lt;/p&gt;&lt;h2&gt;1. 一元RPC模式&lt;/h2&gt;&lt;p&gt;我们从最简单的 RPC 风格开始讨论 gRPC 通信模式。一元 RPC 模式也被称为简单 RPC 模式。在该模式中，当客户端调用服务器端的远程方法时，客户端发送请求至服务器端并获得一个响应，与响应一起发送的还有状态细节以及 trailer 元数据。接下来看一个真实的用例，来进一步了解一元 RPC 模式。&lt;/p&gt;&lt;p&gt;假设需要为基于 gRPC 的在线零售应用程序构建 &lt;code&gt;OrderManagement&lt;/code&gt; 服务，并在该服务中实现 &lt;code&gt;getOrder&lt;/code&gt; 方法。借助该方法，客户端可以通过订单 ID 检索已有的订单。如图1 所示，客户端发送一个带有订单 ID 的请求，服务器端给出响应，响应中包含订单的信息。因此，它遵循一元 RPC 模式。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.3290566037735849&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/riafuBXuN2hrcssibTO5WbZ6iaMP9HULQO6NOxv5icuGOIicMk3lLIJ989zO7j2uXLIsLKHr7O9Qc7udkJibxqzB2XpA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1325&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图1：一元 RPC 模式&lt;/span&gt;&lt;/p&gt;&lt;p&gt;下面来实现这种模式。第一步就是为 &lt;code&gt;OrderManagement&lt;/code&gt; 服务及其 &lt;code&gt;getOrder&lt;/code&gt; 方法创建服务定义。如代码清单1 所示，可以使用 protocol buffers 进行服务定义，&lt;code&gt;getOrder&lt;/code&gt; 远程方法接受一个订单 ID 的请求，并且会给出一个包含 &lt;code&gt;Order&lt;/code&gt; 消息的响应。在本用例中，&lt;code&gt;Order&lt;/code&gt; 消息具有描述订单所需的结构。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;代码清单1&lt;/span&gt;　&lt;code&gt;OrderManagement&lt;/code&gt; 服务定义，服务中的 &lt;code&gt;getOrder&lt;/code&gt; 方法遵循一元 RPC 模式&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;syntax = &quot;proto3&quot;;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;import &quot;google/protobuf/wrappers.proto&quot;; ➊&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;package ecommerce;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;service OrderManagement {&lt;/p&gt;&lt;p&gt;    rpc getOrder(google.protobuf.StringValue) returns (Order); ➋&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;message Order { ➌&lt;/p&gt;&lt;p&gt;    string id = 1;&lt;/p&gt;&lt;p&gt;    repeated string items = 2; ➍&lt;/p&gt;&lt;p&gt;    string description = 3;&lt;/p&gt;&lt;p&gt;    float price = 4;&lt;/p&gt;&lt;p&gt;    string destination = 5;&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;❶ 导入这个包，从而使用常见的类型，如 &lt;code&gt;StringValue&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;❷ 检索订单的远程方法。&lt;/p&gt;&lt;p&gt;❸ 定义 &lt;code&gt;Order&lt;/code&gt; 类型。&lt;/p&gt;&lt;p&gt;❹ 使用 &lt;code&gt;repeated&lt;/code&gt; 表明这个字段在消息中可以重复出现任意次，包括 0 次。在这里，一条订单消息可以有任意数量的条目。&lt;/p&gt;&lt;p&gt;然后，借助 gRPC 服务定义的 proto 文件，就可以生成服务器端骨架代码并实现 &lt;code&gt;GetOrder&lt;/code&gt; 方法的逻辑了。代码清单2 展示了 &lt;code&gt;OrderManagement&lt;/code&gt; 服务的 Go 实现。作为 &lt;code&gt;GetOrder&lt;/code&gt; 方法的输入，单个订单 ID（&lt;code&gt;String&lt;/code&gt;）用来组成请求，这样做可以很容易地在服务器端找到订单并以 &lt;code&gt;Order&lt;/code&gt; 消息（&lt;code&gt;Order&lt;/code&gt; 结构体）的形式进行响应。&lt;code&gt;Order&lt;/code&gt; 消息可以和 &lt;code&gt;nil&lt;/code&gt; 错误一起返回，从而告诉 gRPC，我们已经处理完 RPC，可以将 &lt;code&gt;Order&lt;/code&gt; 返回到客户端了。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;代码清单2&lt;/span&gt;　使用 Go 语言编写的 &lt;code&gt;OrderManagement&lt;/code&gt; 服务的 &lt;code&gt;GetOrder&lt;/code&gt; 方法实现&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;p&gt;// server/main.go&lt;/p&gt;&lt;p&gt;func (s *server) GetOrder(ctx context.Context,&lt;/p&gt;&lt;p&gt;        orderId *wrapper.StringValue) (*pb.Order, error) {&lt;/p&gt;&lt;p&gt;    // 服务实现&lt;/p&gt;&lt;p&gt;       ord := orderMap[orderId.Value]&lt;/p&gt;&lt;p&gt;       return &amp;amp;ord, nil&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;现在来实现客户端的逻辑，从而远程调用 &lt;code&gt;GetOrder&lt;/code&gt; 方法。与服务器端的实现一样，可以为自己喜欢的语言生成代码来创建客户端存根，然后使用该存根调用服务，代码清单3 使用 Go gRPC 客户端调用 &lt;code&gt;OrderManagement&lt;/code&gt; 服务。当然，首先要创建到服务器端的连接并初始化调用服务的客户端存根。然后，就可以调用客户端存根的 &lt;code&gt;GetOrder&lt;/code&gt; 方法，从而实现对远程方法的调用。这时会得到一个 &lt;code&gt;Order&lt;/code&gt; 消息作为响应，其中包含服务定义中使用 protocol buffers 所定义的订单信息。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;代码清单3&lt;/span&gt;　使用 Go 语言调用远程 &lt;code&gt;GetOrder&lt;/code&gt; 方法的客户端实现&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;p&gt;// 建立到服务器端的连接.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;orderMgtClient := pb.NewOrderManagementClient(conn)&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;// 获取订单&lt;/p&gt;&lt;p&gt;retrievedOrder , err := orderMgtClient.GetOrder(ctx,&lt;/p&gt;&lt;p&gt;       &amp;amp;wrapper.StringValue{Value: &quot;106&quot;})&lt;/p&gt;&lt;p&gt;log.Print(&quot;GetOrder Response -&amp;gt; : &quot;, retrievedOrder)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;这种一元 RPC 模式非常容易实现，适用于大多数进程间通信用例。在多种语言间，实现方式都是非常类似的，本文的示例代码仓库提供了 Go 和 Java 的源代码。&lt;/p&gt;&lt;p&gt;现在，我们已经对一元 RPC 模式有了大致的了解，接下来看一下服务器端流 RPC 模式。&lt;/p&gt;&lt;h2&gt;2. 服务器端流RPC模式&lt;/h2&gt;&lt;p&gt;在一元 RPC 模式中，gRPC 服务器端和 gRPC 客户端在通信时始终只有一个请求和一个响应。在服务器端流 RPC 模式中，服务器端在接收到客户端的请求消息后，会发回一个响应的序列。这种多个响应所组成的序列也被称为“流”。在将所有的服务器端响应发送完毕之后，服务器端会以 trailer 元数据的形式将其状态发送给客户端，从而标记流的结束。&lt;/p&gt;&lt;p&gt;下面通过一个真实的用例来进一步了解服务器端流。在 &lt;code&gt;OrderManagement&lt;/code&gt; 服务中，假设需要实现一个订单搜索功能，利用该功能，只要提供一个搜索词就能得到匹配的结果，如图2 所示。&lt;code&gt;OrderManagement&lt;/code&gt; 服务不会将所有匹配的订单一次性地发送给客户端，而是在找到匹配的订单时，逐步将其发送出去。这意味着当订单服务的客户端发出一个请求之后，会接收到多条响应消息。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.3333333333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/riafuBXuN2hrcssibTO5WbZ6iaMP9HULQO6FDVB6fOia8jEHrcnVZtg4NIib5J9BnJibKfxVpm6B8EYticRTgfWoJyjJQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1326&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2：服务器端流 RPC 模式&lt;/span&gt;&lt;/p&gt;&lt;p&gt;现在，在 &lt;code&gt;OrderManagement&lt;/code&gt; 服务的 gRPC 服务定义中新增 &lt;code&gt;searchOrders&lt;/code&gt; 方法。如代码清单4 所示，&lt;code&gt;searchOrders&lt;/code&gt; 方法定义与代码清单 3-1 中的 &lt;code&gt;getOrder&lt;/code&gt; 方法非常类似，但是在服务定义的 proto 文件中，我们通过使用 &lt;code&gt;returns (stream Order)&lt;/code&gt; 将返回参数指定为订单的流。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;代码清单4&lt;/span&gt;　使用服务器端流 RPC 模式的服务定义&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;p&gt;syntax = &quot;proto3&quot;;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;import &quot;google/protobuf/wrappers.proto&quot;;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;package ecommerce;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;service OrderManagement {&lt;/p&gt;&lt;p&gt;    ...&lt;/p&gt;&lt;p&gt;    rpc searchOrders(google.protobuf.StringValue) returns (stream Order); ➊&lt;/p&gt;&lt;p&gt;    ...&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;message Order {&lt;/p&gt;&lt;p&gt;    string id = 1;&lt;/p&gt;&lt;p&gt;    repeated string items = 2;&lt;/p&gt;&lt;p&gt;    string description = 3;&lt;/p&gt;&lt;p&gt;    float price = 4;&lt;/p&gt;&lt;p&gt;    string destination = 5;&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;➊ 通过返回 &lt;code&gt;Order&lt;/code&gt; 消息的 &lt;code&gt;stream&lt;/code&gt; 定义服务器端流。&lt;/p&gt;&lt;p&gt;通过服务定义，可以生成服务器端的代码，然后通过实现所生成的接口，就可以为 &lt;code&gt;OrderManagement&lt;/code&gt; 服务的 &lt;code&gt;searchOrders&lt;/code&gt; 方法构建逻辑了。在代码清单5 所示的 Go 实现中，&lt;code&gt;SearchOrders&lt;/code&gt; 方法有两个参数，分别是字符串类型的 &lt;code&gt;searchQuery&lt;/code&gt; 和用来写入响应的特殊参数 &lt;code&gt;OrderManagement_SearchOrdersServer&lt;/code&gt;。&lt;code&gt;OrderManagement_SearchOrdersServer&lt;/code&gt; 是流的引用对象，可以写入多个响应。这里的业务逻辑是找到匹配的订单，并通过流将其依次发送出去。当找到新的订单时，使用流引用对象的 &lt;code&gt;Send(...)&lt;/code&gt; 方法将其写入流。一旦所有响应都写到了流中，就可以通过返回 &lt;code&gt;nil&lt;/code&gt; 来标记流已经结束，服务器端的状态和其他 trailer 元数据会发送给客户端。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;代码清单5&lt;/span&gt;　使用 Go 语言编写的 &lt;code&gt;SearchOrders&lt;/code&gt; 方法的 &lt;code&gt;OrderManagement&lt;/code&gt; 服务实现&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;p&gt;func (s *server) SearchOrders(searchQuery *wrappers.StringValue,&lt;/p&gt;&lt;p&gt;        stream pb.OrderManagement_SearchOrdersServer) error {&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;        for key, order := range orderMap {&lt;/p&gt;&lt;p&gt;                log.Print(key, order)&lt;/p&gt;&lt;p&gt;                for _, itemStr := range order.Items {&lt;/p&gt;&lt;p&gt;                        log.Print(itemStr)&lt;/p&gt;&lt;p&gt;                        if strings.Contains(&lt;/p&gt;&lt;p&gt;                                itemStr, searchQuery.Value) { ➊&lt;/p&gt;&lt;p&gt;                                // 在流中发送匹配的订单&lt;/p&gt;&lt;p&gt;                                err := stream.Send(&amp;amp;order) ➋&lt;/p&gt;&lt;p&gt;                                if err != nil {&lt;/p&gt;&lt;p&gt;                                   return fmt.Errorf(&lt;/p&gt;&lt;p&gt;                                            &quot;error sending message to stream : %v&quot;,&lt;/p&gt;&lt;p&gt;                                                    err) ➌&lt;/p&gt;&lt;p&gt;                                }&lt;/p&gt;&lt;p&gt;                                log.Print(&quot;Matching Order Found : &quot; + key)&lt;/p&gt;&lt;p&gt;                                break&lt;/p&gt;&lt;p&gt;                        }&lt;/p&gt;&lt;p&gt;                }&lt;/p&gt;&lt;p&gt;        }&lt;/p&gt;&lt;p&gt;        return nil&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;❶ 查找匹配的订单。&lt;/p&gt;&lt;p&gt;❷ 通过流发送匹配的订单。&lt;/p&gt;&lt;p&gt;❸ 检查在将消息以流的形式发送给客户端的过程中可能出现的错误。&lt;/p&gt;&lt;p&gt;客户端的远程方法调用和一元 RPC 模式中的非常类似。但是，因为服务器端往流中写入了多个响应，所以这里必须处理多个响应。因此，我们在 gRPC 客户端的 Go 语言实现中使用 &lt;code&gt;Recv&lt;/code&gt; 方法从客户端流中检索消息，并且持续检索，直到流结束为止，如代码清单6 所示。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;代码清单6&lt;/span&gt;　使用 Go 语言编写的 &lt;code&gt;SearchOrders&lt;/code&gt; 方法的 &lt;code&gt;OrderManagement&lt;/code&gt; 客户端实现&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;p&gt;// 建立到服务器端的连接&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;        c := pb.NewOrderManagementClient(conn)&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;     searchStream, _ := c.SearchOrders(ctx,&lt;/p&gt;&lt;p&gt;        &amp;amp;wrapper.StringValue{Value: &quot;Google&quot;}) ➊&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;        for {&lt;/p&gt;&lt;p&gt;                searchOrder, err := searchStream.Recv() ➋&lt;/p&gt;&lt;p&gt;                if err == io.EOF { ➌&lt;/p&gt;&lt;p&gt;                        break&lt;/p&gt;&lt;p&gt;                }&lt;/p&gt;&lt;p&gt;        // 处理可能出现的错误&lt;/p&gt;&lt;p&gt;                log.Print(&quot;Search Result : &quot;, searchOrder)&lt;/p&gt;&lt;p&gt;     }&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;❶ &lt;code&gt;SearchOrders&lt;/code&gt; 方法返回 &lt;code&gt;OrderManagement_SearchOrdersClient&lt;/code&gt; 的客户端流，它有一个名为 &lt;code&gt;Recv&lt;/code&gt; 的方法。&lt;/p&gt;&lt;p&gt;❷ 调用客户端流的 &lt;code&gt;Recv&lt;/code&gt; 方法，逐个检索 &lt;code&gt;Order&lt;/code&gt; 响应。&lt;/p&gt;&lt;p&gt;❸ 当发现流结束的时候，&lt;code&gt;Recv&lt;/code&gt; 会返回 &lt;code&gt;io.EOF&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;下面看一下客户端流 RPC 模式，它恰好与服务器端流 RPC 模式相反。&lt;/p&gt;&lt;h2&gt;3. 客户端流RPC模式&lt;/h2&gt;&lt;p&gt;在客户端流 RPC 模式中，客户端会发送多个请求给服务器端，而不再是单个请求。服务器端则会发送一个响应给客户端。但是，服务器端不一定要等到从客户端接收到所有消息后才发送响应。基于这样的逻辑，我们可以在接收到流中的一条消息或几条消息之后就发送响应，也可以在读取完流中的所有消息之后再发送响应。&lt;/p&gt;&lt;p&gt;现在进一步扩展 &lt;code&gt;OrderManagement&lt;/code&gt; 服务，从而更好地理解客户端流 RPC 模式。假设希望在 &lt;code&gt;OrderManagement&lt;/code&gt; 服务中添加新的 &lt;code&gt;updateOrders&lt;/code&gt; 方法，从而更新一个订单集合，如图3 所示。在这里，我们想以消息流的形式发送订单列表到服务器端，服务器端会处理这个流并发送一条带有已更新订单状态的消息给客户端。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.3333333333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/riafuBXuN2hrcssibTO5WbZ6iaMP9HULQO6kF4TRPDxjNsDsbficxtoBSaVmSU4oLIBRgguegmFcSzzWHBf7jMd43A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1326&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图3：客户端流 RPC 模式&lt;/span&gt;&lt;/p&gt;&lt;p&gt;然后，可以将 &lt;code&gt;updateOrders&lt;/code&gt; 方法添加到 &lt;code&gt;OrderManagement&lt;/code&gt; 服务的服务定义文件中，如代码清单7 所示。只需使用 &lt;code&gt;stream Order&lt;/code&gt; 作为 &lt;code&gt;updateOrders&lt;/code&gt; 方法的参数，就能表明 &lt;code&gt;updateOrders&lt;/code&gt; 会接收来自客户端的多条消息作为输入。因为服务器端只发送一个响应，所以返回值是单一的字符串消息。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;代码清单7&lt;/span&gt;　具有客户端流 RPC 功能的服务定义&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;p&gt;syntax = &quot;proto3&quot;;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;import &quot;google/protobuf/wrappers.proto&quot;;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;package ecommerce;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;service OrderManagement {&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;    rpc updateOrders(stream Order) returns (google.protobuf.StringValue);&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;message Order {&lt;/p&gt;&lt;p&gt;    string id = 1;&lt;/p&gt;&lt;p&gt;    repeated string items = 2;&lt;/p&gt;&lt;p&gt;    string description = 3;&lt;/p&gt;&lt;p&gt;    float price = 4;&lt;/p&gt;&lt;p&gt;    string destination = 5;&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;当更新完服务定义文件之后，就可以生成服务器端和客户端的代码了。在服务器端，需要实现 &lt;code&gt;OrderManagement&lt;/code&gt; 服务中所生成的 &lt;code&gt;updateOrders&lt;/code&gt; 方法接口。在代码清单8 所示的 Go 实现中，&lt;code&gt;UpdateOrders&lt;/code&gt; 方法有一个 &lt;code&gt;OrderManagement_UpdateOrdersServer&lt;/code&gt; 参数，它是客户端传入消息流的引用对象。因此，可以通过调用该对象的 &lt;code&gt;Recv&lt;/code&gt; 方法来读取消息。根据业务逻辑，可以读取其中一些消息，也可以读取所有的消息。服务只需调用 &lt;code&gt;OrderManagement_UpdateOrdersServer&lt;/code&gt; 对象的 &lt;code&gt;SendAndClose&lt;/code&gt; 方法就可以发送响应，它同时也标记服务器端消息终结了流。如果要提前停止读取客户端流，那么服务器端应该取消客户端流，这样客户端就知道停止生成消息了。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;代码清单8&lt;/span&gt;　使用 Go 语言编写的 &lt;code&gt;UpdateOrders&lt;/code&gt; 方法的 &lt;code&gt;OrderManagement&lt;/code&gt; 服务实现&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;p&gt;func (s *server) UpdateOrders(stream pb.OrderManagement_UpdateOrdersServer) error {&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;        ordersStr := &quot;Updated Order IDs : &quot;&lt;/p&gt;&lt;p&gt;        for {&lt;/p&gt;&lt;p&gt;                order, err := stream.Recv() ➊&lt;/p&gt;&lt;p&gt;                if err == io.EOF { ➋&lt;/p&gt;&lt;p&gt;                        // 完成读取订单流&lt;/p&gt;&lt;p&gt;                        return stream.SendAndClose(&lt;/p&gt;&lt;p&gt;                                &amp;amp;wrapper.StringValue{Value: &quot;Orders processed &quot;&lt;/p&gt;&lt;p&gt;                                + ordersStr})&lt;/p&gt;&lt;p&gt;                 }&lt;/p&gt;&lt;p&gt;                 // 更新订单&lt;/p&gt;&lt;p&gt;                 orderMap[order.Id] = *order&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;                 log.Printf(&quot;Order ID &quot;, order.Id, &quot;: Updated&quot;)&lt;/p&gt;&lt;p&gt;                 ordersStr += order.Id + &quot;, &quot;&lt;/p&gt;&lt;p&gt;        }&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;❶ 从客户端流中读取消息。&lt;/p&gt;&lt;p&gt;❷ 检查流是否已经结束。&lt;/p&gt;&lt;p&gt;下面来看这个客户端流用例的客户端实现。如代码清单9 中的 Go 实现所示，客户端可以通过客户端流引用，借助 &lt;code&gt;updateStream.Send&lt;/code&gt; 方法发送多条消息。一旦所有消息都以流的形式发送出去，客户端就可以将流标记为已完成，并接收来自服务器端的响应。这是通过流引用的 &lt;code&gt;CloseAndRecv&lt;/code&gt; 方法实现的。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;代码清单9&lt;/span&gt;　使用 Go 语言编写的 &lt;code&gt;UpdateOrders&lt;/code&gt; 方法的 &lt;code&gt;OrderManagement&lt;/code&gt; 客户端实现&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;p&gt;// 建立到服务器端的连接&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;        c := pb.NewOrderManagementClient(conn)&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;updateStream, err := client.UpdateOrders(ctx) ➊&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;   if err != nil { ➋&lt;/p&gt;&lt;p&gt;           log.Fatalf(&quot;%v.UpdateOrders(_) = _, %v&quot;, client, err)&lt;/p&gt;&lt;p&gt;   }&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;   // 更新订单1&lt;/p&gt;&lt;p&gt;   if err := updateStream.Send(&amp;amp;updOrder1); err != nil { ➌&lt;/p&gt;&lt;p&gt;           log.Fatalf(&quot;%v.Send(%v) = %v&quot;,&lt;/p&gt;&lt;p&gt;                   updateStream, updOrder1, err) ➍&lt;/p&gt;&lt;p&gt;   }&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;   // 更新订单2&lt;/p&gt;&lt;p&gt;   if err := updateStream.Send(&amp;amp;updOrder2); err != nil {&lt;/p&gt;&lt;p&gt;           log.Fatalf(&quot;%v.Send(%v) = %v&quot;,&lt;/p&gt;&lt;p&gt;                   updateStream, updOrder2, err)&lt;/p&gt;&lt;p&gt;   }&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;   // 更新订单3&lt;/p&gt;&lt;p&gt;   if err := updateStream.Send(&amp;amp;updOrder3); err != nil {&lt;/p&gt;&lt;p&gt;           log.Fatalf(&quot;%v.Send(%v) = %v&quot;,&lt;/p&gt;&lt;p&gt;                   updateStream, updOrder3, err)&lt;/p&gt;&lt;p&gt;   }&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;   updateRes, err := updateStream.CloseAndRecv() ➎&lt;/p&gt;&lt;p&gt;   if err != nil {&lt;/p&gt;&lt;p&gt;           log.Fatalf(&quot;%v.CloseAndRecv() got error %v, want %v&quot;,&lt;/p&gt;&lt;p&gt;                   updateStream, err, nil)&lt;/p&gt;&lt;p&gt;   }&lt;/p&gt;&lt;p&gt;   log.Printf(&quot;Update Orders Res : %s&quot;, updateRes)&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;❶ 调用 &lt;code&gt;UpdateOrders&lt;/code&gt; 远程方法。&lt;/p&gt;&lt;p&gt;❷ 处理与 &lt;code&gt;UpdateOrders&lt;/code&gt; 相关的错误。&lt;/p&gt;&lt;p&gt;❸ 通过客户端流发送订单更新的请求。&lt;/p&gt;&lt;p&gt;❹ 处理在发送消息到流时发生的错误。&lt;/p&gt;&lt;p&gt;❺ 关闭流并接收响应。&lt;/p&gt;&lt;p&gt;当调用这个方法后，会收到服务的响应消息。现在，我们对服务器端流 RPC 模式和客户端流 RPC 模式都有了非常好的了解。接下来将介绍双向流 RPC 模式，它是前面讨论的不同 RPC 风格的一种组合。&lt;/p&gt;&lt;h2&gt;4. 双向流RPC模式&lt;/h2&gt;&lt;p&gt;在双向流 RPC 模式中，客户端以消息流的形式发送请求到服务器端，服务器端也以消息流的形式进行响应。调用必须由客户端发起，但在此之后，通信完全基于 gRPC 客户端和服务器端的应用程序逻辑。下面通过一个示例来进一步了解双向流 RPC 模式。如图4 所示，在 &lt;code&gt;OrderManagement&lt;/code&gt; 服务用例中，假设需要一个订单处理功能，通过该功能，用户可以发送连续的订单集合（订单流），并根据投递地址对它们进行组合发货，也就是说，订单要根据投递目的地进行组织和发货。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.3574660633484163&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/riafuBXuN2hrcssibTO5WbZ6iaMP9HULQO6c2pRRlvemY4eBWY0ZZebyq3k7Qh79jEn2ichftKGhbrIiccwKGL2Ldaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1326&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图4：双向流 RPC 模式&lt;/span&gt;&lt;/p&gt;&lt;p&gt;可以看到，这个业务用例的关键步骤如下所示。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;客户端应用程序通过建立与服务器端的连接并发送调用元数据（头信息）初始化业务用例。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;一旦连接成功建立，客户端应用程序就发送连续的订单 ID 集合，这些订单需要由 &lt;code&gt;OrderManagement&lt;/code&gt; 服务进行处理。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;每个订单 ID 以独立的 gRPC 消息的形式发送至服务器端。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;服务会处理给定订单 ID 所对应的每个订单，并根据订单的投递位置将它们组织到发货组合中。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;每个发货组合可能会包含多个订单，它们应该被投递到相同的目的地。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;订单是成批处理的。当达到指定的批次大小时，当前创建的所有发货组合都会被发送至客户端。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;假设流中有 4 个订单，其中有 2 个订单要发送至位置 &lt;code&gt;X&lt;/code&gt;，另外两个要发送至位置 &lt;code&gt;Y&lt;/code&gt;，则可以将其表示为 &lt;code&gt;X&lt;/code&gt;、&lt;code&gt;Y&lt;/code&gt;、&lt;code&gt;X&lt;/code&gt;、&lt;code&gt;Y&lt;/code&gt;。如果批次大小为 3，那么所创建的订单发货组合会是 &lt;code&gt;[X, X]&lt;/code&gt;、&lt;code&gt;[Y]&lt;/code&gt; 和 &lt;code&gt;[Y]&lt;/code&gt;。这些发货组合也会以流的形式发送至客户端。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这个业务用例的核心理念就是一旦调用 RPC 方法，那么无论是客户端还是服务器端，都可以在任意时间发送消息。这也包括来自任意一端的流结束标记。&lt;/p&gt;&lt;p&gt;下面看一下上述用例的服务定义。如代码清单10 所示，可以定义一个 &lt;code&gt;processOrders&lt;/code&gt; 方法，该方法接受一个字符串流作为方法参数，代表了订单流 ID 并且以 &lt;code&gt;CombinedShipment&lt;/code&gt; 流作为方法的返回值。因此，通过将方法参数和返回参数均声明为 &lt;code&gt;stream&lt;/code&gt;，可以定义双向流的 RPC 方法。发货组合的消息也是通过服务定义声明的，它包含了订单元素的列表。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;代码清单10&lt;/span&gt;　具有双向流 RPC 功能的服务定义&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;p&gt;syntax = &quot;proto3&quot;;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;import &quot;google/protobuf/wrappers.proto&quot;;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;package ecommerce;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;service OrderManagement {&lt;/p&gt;&lt;p&gt;    ...&lt;/p&gt;&lt;p&gt;    rpc processOrders(stream google.protobuf.StringValue)&lt;/p&gt;&lt;p&gt;        returns (stream CombinedShipment); ➊&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;message Order { ➋&lt;/p&gt;&lt;p&gt;    string id = 1;&lt;/p&gt;&lt;p&gt;    repeated string items = 2;&lt;/p&gt;&lt;p&gt;    string description = 3;&lt;/p&gt;&lt;p&gt;    float price = 4;&lt;/p&gt;&lt;p&gt;    string destination = 5;&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;message CombinedShipment { ➌&lt;/p&gt;&lt;p&gt;    string id = 1;&lt;/p&gt;&lt;p&gt;    string status = 2;&lt;/p&gt;&lt;p&gt;    repeated Order ordersList = 3;&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;❶ 在双向流 RPC 模式中，将方法参数和返回参数均声明为 &lt;code&gt;stream&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;❷ &lt;code&gt;Order&lt;/code&gt; 消息的结构。&lt;/p&gt;&lt;p&gt;❸ &lt;code&gt;CombinedShipment&lt;/code&gt; 消息的结构。&lt;/p&gt;&lt;p&gt;接下来，就可以根据更新后的服务定义生成服务器端的代码了。服务应该实现 &lt;code&gt;OrderManagement&lt;/code&gt; 服务中的 &lt;code&gt;processOrders&lt;/code&gt; 方法。如代码清单11 所示，在 Go 实现中，&lt;code&gt;ProcessOrders&lt;/code&gt; 方法有一个 &lt;code&gt;OrderManagement_ProcessOrdersServer&lt;/code&gt; 参数，它是客户端和服务器端之间消息流的对象引用。借助这个流对象，服务器端可以读取客户端以流的方式发送的消息，也能写入服务器端的流消息并返回给客户端。传入的消息流可以通过该引用对象的 &lt;code&gt;Recv&lt;/code&gt; 方法来读取。在 &lt;code&gt;ProcessOrders&lt;/code&gt; 方法中，服务可在持续读取传入消息流的同时，使用 &lt;code&gt;Send&lt;/code&gt; 方法将消息写入同一个流中。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;代码清单11&lt;/span&gt;　使用 Go 语言编写的 &lt;code&gt;ProcessOrders&lt;/code&gt; 方法的 &lt;code&gt;OrderManagement&lt;/code&gt; 服务实现&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;p&gt;func (s *server) ProcessOrders(&lt;/p&gt;&lt;p&gt;        stream pb.OrderManagement_ProcessOrdersServer) error {&lt;/p&gt;&lt;p&gt;        ...&lt;/p&gt;&lt;p&gt;        for {&lt;/p&gt;&lt;p&gt;                orderId, err := stream.Recv() ➊&lt;/p&gt;&lt;p&gt;                if err == io.EOF { ➋&lt;/p&gt;&lt;p&gt;                        ...&lt;/p&gt;&lt;p&gt;                        for _, comb := range combinedShipmentMap {&lt;/p&gt;&lt;p&gt;                                stream.Send(&amp;amp;comb) ➌&lt;/p&gt;&lt;p&gt;                        }&lt;/p&gt;&lt;p&gt;                        return nil                ➍&lt;/p&gt;&lt;p&gt;                }&lt;/p&gt;&lt;p&gt;                if err != nil {&lt;/p&gt;&lt;p&gt;                        return err&lt;/p&gt;&lt;p&gt;                }&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;                // 基于目的地位置，&lt;/p&gt;&lt;p&gt;                // 将订单组织到发货组合中的逻辑&lt;/p&gt;&lt;p&gt;                ...&lt;/p&gt;&lt;p&gt;                //&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;                if batchMarker == orderBatchSize { ➎&lt;/p&gt;&lt;p&gt;                        // 将组合后的订单以流的形式分批发送至客户端&lt;/p&gt;&lt;p&gt;                        for _, comb := range combinedShipmentMap {&lt;/p&gt;&lt;p&gt;                                // 将发货组合发送到客户端&lt;/p&gt;&lt;p&gt;                                stream.Send(&amp;amp;comb)     ➏&lt;/p&gt;&lt;p&gt;                        }&lt;/p&gt;&lt;p&gt;                        batchMarker = 0&lt;/p&gt;&lt;p&gt;                        combinedShipmentMap = make(&lt;/p&gt;&lt;p&gt;                                map[string]pb.CombinedShipment)&lt;/p&gt;&lt;p&gt;                } else {&lt;/p&gt;&lt;p&gt;                        batchMarker++&lt;/p&gt;&lt;p&gt;                }&lt;/p&gt;&lt;p&gt;        }&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;❶ 从传入的流中读取订单 ID。&lt;/p&gt;&lt;p&gt;❷ 持续读取，直到流结束为止。&lt;/p&gt;&lt;p&gt;❸ 当流结束时，将所有剩余的发货组合发送给客户端。&lt;/p&gt;&lt;p&gt;❹ 通过返回 &lt;code&gt;nil&lt;/code&gt; 标记服务器端流已经结束。&lt;/p&gt;&lt;p&gt;❺ 按批次处理订单。当达到该批次的规模时，将所有已创建的发货组合以流的形式发送给客户端。&lt;/p&gt;&lt;p&gt;❻ 将发货组合写入流中。&lt;/p&gt;&lt;p&gt;这里是基于订单 ID 来处理传入的订单的，当创建新的发货组合后，服务会将其写入相同的流中。这与客户端流 RPC 模式不同，当时服务通过 &lt;code&gt;SendAndClose&lt;/code&gt; 方法写入流并将其关闭。当发现客户端流已经结束时，发送 &lt;code&gt;nil&lt;/code&gt; 标记服务器端流的结束。&lt;/p&gt;&lt;p&gt;如代码清单12 所示，客户端实现与之前的示例非常相似。当客户端通过 &lt;code&gt;OrderManagement&lt;/code&gt; 对象调用 &lt;code&gt;ProcessOrders&lt;/code&gt; 方法时，它会得到一个对流的引用（&lt;code&gt;streamProcOrder&lt;/code&gt;），这个引用可以用来发送消息到服务器端，也能读取来自服务器端的消息。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;代码清单12&lt;/span&gt;　使用 Go 语言编写的 &lt;code&gt;ProcessOrders&lt;/code&gt; 方法的 &lt;code&gt;OrderManagement&lt;/code&gt; 客户端实现&lt;/p&gt;&lt;/blockquote&gt;&lt;pre&gt;&lt;p&gt;// 处理订单&lt;/p&gt;&lt;p&gt;streamProcOrder, _ := c.ProcessOrders(ctx) ➊&lt;/p&gt;&lt;p&gt;        if err := streamProcOrder.Send(&lt;/p&gt;&lt;p&gt;                &amp;amp;wrapper.StringValue{Value:&quot;102&quot;}); err != nil { ➋&lt;/p&gt;&lt;p&gt;                log.Fatalf(&quot;%v.Send(%v) = %v&quot;, client, &quot;102&quot;, err)&lt;/p&gt;&lt;p&gt;        }&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;        if err := streamProcOrder.Send(&lt;/p&gt;&lt;p&gt;                &amp;amp;wrapper.StringValue{Value:&quot;103&quot;}); err != nil {&lt;/p&gt;&lt;p&gt;                log.Fatalf(&quot;%v.Send(%v) = %v&quot;, client, &quot;103&quot;, err)&lt;/p&gt;&lt;p&gt;        }&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;        if err := streamProcOrder.Send(&lt;/p&gt;&lt;p&gt;                &amp;amp;wrapper.StringValue{Value:&quot;104&quot;}); err != nil {&lt;/p&gt;&lt;p&gt;                log.Fatalf(&quot;%v.Send(%v) = %v&quot;, client, &quot;104&quot;, err)&lt;/p&gt;&lt;p&gt;        }&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;        channel := make(chan struct{}) ➌&lt;/p&gt;&lt;p&gt;    go asncClientBidirectionalRPC(streamProcOrder, channel) ➍&lt;/p&gt;&lt;p&gt;    time.Sleep(time.Millisecond * 1000) ➎&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;        if err := streamProcOrder.Send(&lt;/p&gt;&lt;p&gt;                &amp;amp;wrapper.StringValue{Value:&quot;101&quot;}); err != nil {&lt;/p&gt;&lt;p&gt;                log.Fatalf(&quot;%v.Send(%v) = %v&quot;, client, &quot;101&quot;, err)&lt;/p&gt;&lt;p&gt;        }&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;        if err := streamProcOrder.CloseSend(); err != nil { ➏&lt;/p&gt;&lt;p&gt;                log.Fatal(err)&lt;/p&gt;&lt;p&gt;        }&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;lt;- channel&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;func asncClientBidirectionalRPC (&lt;/p&gt;&lt;p&gt;            streamProcOrder pb.OrderManagement_ProcessOrdersClient,&lt;/p&gt;&lt;p&gt;            c chan struct{}) {&lt;/p&gt;&lt;p&gt;        for {&lt;/p&gt;&lt;p&gt;                combinedShipment, errProcOrder := streamProcOrder.Recv() ➐&lt;/p&gt;&lt;p&gt;                if errProcOrder == io.EOF { ➑&lt;/p&gt;&lt;p&gt;                        break&lt;/p&gt;&lt;p&gt;                }&lt;/p&gt;&lt;p&gt;                log.Printf(&quot;Combined shipment : &quot;, combinedShipment.OrdersList)&lt;/p&gt;&lt;p&gt;        }&lt;/p&gt;&lt;p&gt;        &amp;lt;-c&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;❶ 调用远程方法并获取流引用，以便在客户端写入和读取。&lt;/p&gt;&lt;p&gt;❷ 向服务发送消息。&lt;/p&gt;&lt;p&gt;❸ 创建 &lt;code&gt;Goroutines&lt;/code&gt; 所使用的通道。&lt;/p&gt;&lt;p&gt;❹ 使用 &lt;code&gt;Goroutines&lt;/code&gt; 调用函数，以便并行读取来自服务的消息。&lt;/p&gt;&lt;p&gt;❺ 模拟向服务发送消息的延迟。&lt;/p&gt;&lt;p&gt;❻ 为客户端流标记流的结束（订单 ID）。&lt;/p&gt;&lt;p&gt;❼ 在客户端读取服务的消息。&lt;/p&gt;&lt;p&gt;❽ 该条件探测流是否已经结束。&lt;/p&gt;&lt;p&gt;客户端可以在任意时间发送消息给服务并关闭流。读取消息也是同样的道理。前面的示例使用了 Go 语言中的 &lt;code&gt;Goroutines&lt;/code&gt;，在两个并发线程中执行客户端的消息写入逻辑和消息服务逻辑。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;img data-ratio=&quot;1.3348264277715565&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/riafuBXuN2hrcssibTO5WbZ6iaMP9HULQO6NelAgibg2fPVphcicObHGJU45TA0u5YnYicV72Kka1Yq4v2NzWzOAiaPicQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;893&quot;/&gt;　&lt;span&gt;&lt;code&gt;Goroutines&lt;/code&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;在 Go 语言中，&lt;code&gt;Goroutines&lt;/code&gt; 是能够与其他函数或方法并行运行的函数或方法，可以将它们视为轻量级的线程。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;客户端可以并发读取和写入同一个流，输入流和输出流可以独立进行操作。这里所展示的是稍微复杂的示例，它展现了双向流 RPC 模式的威力。流的操作完全独立，客户端和服务器端可以按照任意顺序进行读取和写入，理解这一点非常重要。一旦建立连接，客户端和服务器端之间的通信模式就完全取决于客户端和服务器端本身。&lt;/p&gt;&lt;p&gt;目前我们已经讨论了所有可能的通信模式，可以使用它们实现基于 gRPC 的应用程序之间的交互。至于具体选择哪种通信模式，并没有硬性的规定，但是最好的办法就是分析业务用例，并据此选择最合适的模式。&lt;/p&gt;&lt;p&gt;在结束关于 gRPC 通信模式的讨论之前，还有一个重要的方面需要了解，即 gRPC 是如何应用于微服务通信的。&lt;/p&gt;&lt;h2&gt;5. 使用gRPC实现微服务通信&lt;/h2&gt;&lt;p&gt;gRPC 的主要用途之一就是实现微服务以及服务之间的通信。在微服务的服务间通信中，gRPC 会与其他通信协议一同使用，并且 gRPC 服务通常会实现为多语言服务（由不同的语言实现）。为了进一步理解该技术，下面来看在线零售系统这样一个真实的场景，如图5 所示，它是对前述内容的扩展。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.65832531280077&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/riafuBXuN2hrcssibTO5WbZ6iaMP9HULQO6PKiaMBia6a792WgrOZE6xyCdYkUyHIMxb8ktHVLWqJIk1Cv5E7ibXumNA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2078&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图5：使用 gRPC 和其他协议的通用微服务部署模式&lt;/span&gt;&lt;/p&gt;&lt;p&gt;该场景中有许多微服务，每个微服务都面向在线零售系统的特定业务能力。有一些服务的实现形式是 gRPC 服务，如 &lt;code&gt;Product&lt;/code&gt; 服务；另外还有一些组合服务，如 &lt;code&gt;Catalog&lt;/code&gt; 服务，它会调用底层的服务来构建其业务能力。大多数同步消息可以使用 gRPC 来传递。如果有特定的异步消息场景，可能需要持久化消息，那么就可以使用事件代理或消息代理，如 Kafka、Active MQ、RabbitMQ 和 NATS。当需要将特定的业务功能暴露到外部时，可以使用传统的基于 REST 或 OpenAPI 的服务或者 GraphQL 服务。因此，&lt;code&gt;Catalog&lt;/code&gt; 和 &lt;code&gt;Checkout&lt;/code&gt; 等服务消费基于 gRPC 的后端服务，同时暴露基于 REST 或 GraphQL 的外部接口。&lt;/p&gt;&lt;p&gt;在大多数实际用例中，这些面向外部的服务是通过 API 网关暴露的。这里可以应用各种非功能性的能力，如安全性、节流、版本化等。大多数这样的 API 使用像 REST 或 GraphQL 这样的协议，但还有一种可能，这种情况不太常见，那就是只要 API 网关支持暴露 gRPC 接口，gRPC 就可以作为对外的接口。API 网关实现了横切性的功能，如认证、日志、版本化、节流和负载均衡。通过组合使用 API 网关与 gRPC API，可以将这些功能部署到核心 gRPC 服务之外。这种架构还有另外一个重要方面，那就是可以使用多种编程语言，但共享相同的服务契约，比如通过相同的 gRPC 服务定义来生成代码。这样一来，便可以根据服务的业务能力来选择适当的实现技术。&lt;/p&gt;&lt;h2&gt;6. 小结&lt;/h2&gt;&lt;p&gt;gRPC 提供了一组不同的 RPC 通信风格，用于在基于 gRPC 的应用程序之间构建进程间通信。本文探讨了 4 种主要的通信模式，其中一元 RPC 模式是最基本的一种模式，它是一种非常简单的请求–响应式 RPC；服务器端流 RPC 模式可以在第一次调用远程方法后从服务向消费者发送多条消息；客户端流 RPC 模式可以从客户端向服务发送多条消息；双向流 RPC 模式有一点复杂，其中流的操作是完全独立的，客户端和服务器端可以按照任意顺序进行读取和写入。另外，本文深入研究了如何通过一些真实的用例来实现这些模式。&lt;/p&gt;&lt;p&gt;本文内容对实现任何 gRPC 用例都非常有用，你可以根据实际情况选择最合适的通信模式。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;7. 新书推荐&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;本文引自《 gRPC与云原生应用开发：以Go和Java为例》，刚上架的新书，欢迎有需要的朋友关注。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;1.5733333333333333&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;600&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/riafuBXuN2ho8Hribw6biaGFfwVs23B3ibk4SFVeB0t7HzQNg0xed0uXytVuIFH2MLKOQ9KAv2icicibJUNuDaVOrGxVA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;8. 留言福利&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;小伙伴们，今天是开工第一天，请大家来聊聊开工后最想读的书是哪一本，理由是什么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;留言告诉我们，随机选取 3 位读者，可从图灵 2021 年出版的新书中任选一本，作为你的开工礼物。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统计截止时间：2021 年 2 月 22 日 12：00。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;图 灵 社 群&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.38248337028824836&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;902&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/riafuBXuN2hp0zZiaATs03SXyiazbWvib91XJvU5LRCfVxc3uYX6dsh74FtP5QtkRMnwBneJD1AWGiaTYHSiaYF6hp2w/640?wx_fmt=png&quot;/&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.2222222222222222&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;900&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/riafuBXuN2hokWPAAOxh38PFianicYLkjmIK9BSciaeDvzbbl3RcEumDAjpMJEqljN3NTbIuiaEwnRr1JpadGlOmHrw/640?wx_fmt=png&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9333333333333333&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;180&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/riafuBXuN2hoDbHDiaq3MURo3oAkfX8uRnzgvriaS0eREu0RU09ficjxDOjEc3eaPYVXakr0mMVEviciac15CibKXcztw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;点个&lt;/span&gt;&lt;strong&gt;&lt;span&gt;「在看」&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>