<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>38218c2e5d03bf32839f8fd37202bce5</guid>
<title>高吞吐、低延迟 Java 应用的 GC 优化实践</title>
<link>https://toutiao.io/k/92nisj7</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;src-views-article-detail-main-module__content--2qOBd markdown-body&quot;&gt;&lt;p&gt;“以下信息节选自涤生的翻译内容”&lt;/p&gt;
&lt;p&gt;本篇原文作者是 LinkedIn 的 Swapnil Ghike，这篇文章讲述了 LinkedIn 的 Feed 产品的 GC 优化过程，虽然文章写作于 April 8, 2014，但其中的很多内容和知识点非常有学习和参考意义。&lt;/p&gt;
&lt;h1&gt;背景&lt;/h1&gt;
&lt;p&gt;高性能应用构成了现代网络的支柱。LinkedIn 内部有许多高吞吐量服务来满足每秒成千上万的用户请求。为了获得最佳的用户体验，以低延迟响应这些请求是非常重要的。&lt;/p&gt;
&lt;p&gt;例如，我们的用户经常使用的产品是 Feed —— 它是一个不断更新的专业活动和内容的列表。Feed 在 LinkedIn 的系统中随处可见，包括公司页面、学校页面以及最重要的主页资讯信息。基础 Feed 数据平台为我们的经济图谱（会员、公司、群组等）中各种实体的更新建立索引，它必须高吞吐低延迟地实现相关的更新。如下图，LinkedIn Feeds 信息展示：&lt;br/&gt;
&lt;img src=&quot;https://a.perfma.net/img/233863&quot; alt=&quot;5.jpg&quot;/&gt;&lt;br/&gt;
为了将这些高吞吐量、低延迟类型的 Java 应用程序用于生产，开发人员必须确保在应用程序开发周期的每个阶段都保持一致的性能。确定最佳垃圾收集（Garbage Collection, GC）配置对于实现这些指标至关重要。&lt;/p&gt;
&lt;p&gt;这篇博文将通过一系列步骤来明确需求并优化 GC，它的目标读者是对使用系统方法进行 GC 优化来实现应用的高吞吐低延迟目标感兴趣的开发人员。在 LinkedIn 构建下一代 Feed 数据平台的过程中，我们总结了该方法。这些方法包括但不限于以下几点：并发标记清除（Concurrent Mark Sweep，CMS（参考[2]） 和 G1（参考 [3]） 垃圾回收器的 CPU 和内存开销、避免长期存活对象导致的持续 GC、优化 GC 线程任务分配提升性能，以及可预测 GC 停顿时间所需的 OS 配置。&lt;/p&gt;
&lt;h1&gt;优化 GC 的正确时机？&lt;/h1&gt;
&lt;p&gt;GC 的行为可能会因代码优化以及工作负载的变化而变化。因此，在一个已实施性能优化的接近完成的代码库上进行 GC 优化非常重要。而且在端到端的基本原型上进行初步分析也很有必要，该原型系统使用存根代码并模拟了可代表生产环境的工作负载。这样可以获取该架构延迟和吞吐量的真实边界，进而决定是否进行纵向或横向扩展。&lt;/p&gt;
&lt;p&gt;在下一代 Feed 数据平台的原型开发阶段，我们几乎实现了所有端到端的功能，并且模拟了当前生产基础设施提供的查询工作负载。这使我们在工作负载特性上有足够的多样性，可以在足够长的时间内测量应用程序性能和 GC 特征。&lt;/p&gt;
&lt;h1&gt;优化 GC 的步骤&lt;/h1&gt;
&lt;p&gt;下面是一些针对高吞吐量、低延迟需求优化 GC 的总体步骤。此外，还包括在 Feed 数据平台原型实施的具体细节。尽管我们还对 G1 垃圾收集器进行了试验，但我们发现 ParNew/CMS 具有最佳的 GC 性能。&lt;/p&gt;
&lt;h2&gt;1. 理解 GC 基础知识&lt;/h2&gt;
&lt;p&gt;由于 GC 优化需要调整大量的参数，因此理解 GC 工作机制非常重要。Oracle 的 Hotspot JVM 内存管理白皮书（参考 [4] ）是开始学习 Hotspot JVM GC 算法非常好的资料。而了解 G1 垃圾回收器的理论知识，可以参阅（参考 [3]）。&lt;/p&gt;
&lt;h2&gt;2. 仔细考量 GC 需求&lt;/h2&gt;
&lt;p&gt;为了降低对应用程序性能的开销，可以优化 GC 的一些特征。像吞吐量和延迟一样，这些 GC 特征应该在长时间运行的测试中观察到，以确保应用程序能够在经历多个 GC 周期中处理流量的变化。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stop-the-world 回收器回收垃圾时会暂停应用线程。停顿的时长和频率不应该对应用遵守 SLA 产生不利的影响。&lt;/li&gt;
&lt;li&gt;并发 GC 算法与应用线程竞争 CPU 周期。这个开销不应该影响应用吞吐量。&lt;/li&gt;
&lt;li&gt;非压缩 GC 算法会引起堆碎片化，进而导致的 Full GC 长时间 Stop-the-world，因此，堆碎片应保持在最小值。&lt;/li&gt;
&lt;li&gt;垃圾回收工作需要占用内存。某些 GC 算法具有比其他算法更高的内存占用。如果应用程序需要较大的堆空间，要确保 GC 的内存开销不能太大。&lt;/li&gt;
&lt;li&gt;要清楚地了解 GC 日志和常用的 JVM 参数，以便轻松地调整 GC 行为。因为 GC 运行随着代码复杂性增加或工作负载特性的改变而发生变化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们使用 Linux 操作系统、Hotspot Java7u51、32GB 堆内存、6GB 新生代（Young Gen）和 -XX:CMSInitiatingOccupancyFraction 值为 70（Old GC 触发时其空间占用率）开始实验。设置较大的堆内存是用来维持长期存活对象的对象缓存。一旦这个缓存生效，晋升到 Old Gen 的对象速度会显著下降。&lt;/p&gt;
&lt;p&gt;使用最初的 JVM 配置，每 3 秒发生一次 80ms 的 Young GC 停顿，超过 99.9% 的应用请求延迟 100ms（999线）。这样的 GC 效果可能适合于 SLA 对延迟要求不太严格应用。然而，我们的目标是尽可能减少应用请求的 999 线。GC 优化对于实现这一目标至关重要。&lt;/p&gt;
&lt;h2&gt;3. 理解 GC 指标&lt;/h2&gt;
&lt;p&gt;衡量应用当前情况始终是优化的先决条件。了解 GC 日志的详细细节（参考 [5]）（使用以下选项）：&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps 
-XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime
&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;p&gt;可以对该应用的 GC 特征有总体的把握。&lt;/p&gt;
&lt;p&gt;在 LinkedIn 的内部监控 inGraphs 和报表系统 Naarad，生成了各种有用的指标可视化图形，比如 GC 停顿时间百分比、一次停顿最大持续时间以及长时间内 GC 频率。除了 Naarad，有很多开源工具比如 gclogviewer 可以从 GC 日志创建可视化图形。在此阶段，可以确定 GC 频率和暂停持续时间是否满足应用程序满足延迟的要求。&lt;/p&gt;
&lt;h2&gt;4. 降低 GC 频率&lt;/h2&gt;
&lt;p&gt;在分代 GC 算法中，降低 GC 频率可以通过：(1) 降低对象分配/晋升率；(2) 增加各代空间的大小。&lt;/p&gt;
&lt;p&gt;在 Hotspot JVM 中，Young GC 停顿时间取决于一次垃圾回收后存活下来的对象的数量，而不是 Young Gen 自身的大小。增加 Young Gen 大小对于应用性能的影响需要仔细评估：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果更多的数据存活而且被复制到 Survivor 区域，或者每次 GC 更多的数据晋升到 Old Gen，增加 Young Gen 大小可能导致更长的 Young GC 停顿。较长的 GC 停顿可能会导致应用程序延迟增加和(或)吞吐量降低。&lt;/li&gt;
&lt;li&gt;另一方面，如果每次垃圾回收后存活对象数量不会大幅增加，停顿时间可能不会延长。在这种情况下，降低 GC 频率可能会使整个应用总体延迟降低和(或)吞吐量增加。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于大部分为短期存活对象的应用，仅仅需要控制上述的参数；对于长期存活对象的应用，就需要注意，被晋升的对象可能很长时间都不能被 Old GC 周期回收。如果 Old GC 触发阈值（Old Gen 占用率百分比）比较低，应用将陷入持续的 GC 循环中。可以通过设置高的 GC 触发阈值可避免这一问题。&lt;/p&gt;
&lt;p&gt;由于我们的应用在堆中维持了长期存活对象的较大缓存，将 Old GC 触发阈值设置为&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;-XX:CMSInitiatingOccupancyFraction=92 -XX:+UseCMSInitiatingOccupancyOnly
&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;p&gt;来增加触发 Old GC 的阈值。我们也试图增加 Young Gen 大小来减少 Young GC 频率，但是并没有采用，因为这增加了应用的 999 线。&lt;/p&gt;
&lt;h2&gt;5. 缩短 GC 停顿时间&lt;/h2&gt;
&lt;p&gt;减少 Young Gen 大小可以缩短 Young GC 停顿时间，因为这可能导致被复制到 Survivor 区域或者被晋升的数据更少。但是，正如前面提到的，我们要观察减少 Young Gen 大小和由此导致的 GC 频率增加对于整体应用吞吐量和延迟的影响。Young GC 停顿时间也依赖于 tenuring threshold （晋升阈值）和 Old Gen 大小（如步骤 6 所示）。&lt;/p&gt;
&lt;p&gt;在使用 CMS GC 时，应将因堆碎片或者由堆碎片导致的 Full GC 的停顿时间降低到最小。通过控制对象晋升比例和减小 -XX:CMSInitiatingOccupancyFraction 的值使 Old GC 在低阈值时触发。所有选项的细节调整和他们相关的权衡，请参考 Web Services 的 Java 垃圾回收（参考 [5] ）和 Java 垃圾回收精粹（参考 [6]）。&lt;/p&gt;
&lt;p&gt;我们观察到 Eden 区域的大部分 Young Gen 被回收，几乎没有 3-8 年龄对象在 Survivor 空间中死亡，所以我们将 tenuring threshold 从 8 降低到 2 (使用选项：-XX:MaxTenuringThreshold=2 ),以降低 Young GC 消耗在数据复制上的时间。&lt;/p&gt;
&lt;p&gt;我们还注意到 Young GC 暂停时间随着 Old Gen 占用率上升而延长。这意味着来自 Old Gen 的压力使得对象晋升花费更多的时间。为解决这个问题，将总的堆内存大小增加到 40GB，减小 -XX:CMSInitiatingOccupancyFraction 的值到 80，更快地开始 Old GC。尽管 -XX:CMSInitiatingOccupancyFraction 的值减小了，增大堆内存可以避免频繁的 Old GC。在此阶段，我们的结果是 Young GC 暂停 70ms，应用的 999 线在 80ms。&lt;/p&gt;
&lt;h2&gt;6. 优化 GC 工作线程的任务分配&lt;/h2&gt;
&lt;p&gt;为了进一步降低 Young GC 停顿时间，我们决定研究 GC 线程绑定任务的参数来进行优化。&lt;/p&gt;
&lt;p&gt;-XX:ParGCCardsPerStrideChunk 参数控制 GC 工作线程的任务粒度，可以帮助不使用补丁而获得最佳性能，这个补丁用来优化 Young GC 中的 Card table（卡表）扫描时间（参考[7]）。有趣的是，Young GC 时间随着 Old Gen 的增加而延长。将这个选项值设为 32678，Young GC 停顿时间降低到平均 50ms。此时应用的 999 线在 60ms。&lt;/p&gt;
&lt;p&gt;还有一些的参数可以将任务映射到 GC 线程，如果操作系统允许的话，-XX:+BindGCTaskThreadsToCPUs 参数可以绑定 GC 线程到个别的 CPU 核（见解释 [1]）。使用亲缘性 -XX:+UseGCTaskAffinity 参数可以将任务分配给 GC 工作线程（见解释 [2]）。然而，我们的应用并没有从这些选项带来任何好处。实际上，一些调查显示这些选项在 Linux 系统不起作用。&lt;/p&gt;
&lt;h2&gt;7. 了解 GC 的 CPU 和内存开销&lt;/h2&gt;
&lt;p&gt;并发 GC 通常会增加 CPU 使用率。虽然我们观察到 CMS 的默认设置运行良好，但是 G1 收集器的并发 GC 工作会导致 CPU 使用率的增加，显著降低了应用程序的吞吐量和延迟。与 CMS 相比，G1 还增加了内存开销。对于不受 CPU 限制的低吞吐量应用程序，GC 导致的高 CPU 使用率可能不是一个紧迫的问题。&lt;/p&gt;
&lt;p&gt;下图是 ParNew/CMS 和 G1 的 CPU 使用百分比：相对来说 CPU 使用率变化明显的节点使用 G1 参数 -XX:G1RSetUpdatingPauseTimePercent=20：&lt;br/&gt;
&lt;img src=&quot;https://a.perfma.net/img/233872&quot; alt=&quot;6.jpg&quot;/&gt;&lt;br/&gt;
下图是 ParNew/CMS 和 G1 每秒服务的请求数：吞吐量较低的节点使用 G1 参数 -XX:G1RSetUpdatingPauseTimePercent=20&lt;br/&gt;
&lt;img src=&quot;https://a.perfma.net/img/233885&quot; alt=&quot;7.jpg&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;8. 为 GC 优化系统内存和 I/O 管理&lt;/h2&gt;
&lt;p&gt;通常来说，GC 停顿有两种特殊情况：(1) 低 user time，高 sys time 和高 real time (2) 低 user time，低 sys time 和高 real time。这意味着基础的进程/OS设置存在问题。情况 (1) 可能意味着 JVM 页面被 Linux 窃取；情况 (2) 可能意味着 GC 线程被 Linux 用于磁盘刷新，并卡在内核中等待 I/O。在这些情况下，如何设置参数可以参考该 PPT（参考 [8]）。&lt;/p&gt;
&lt;p&gt;另外，为了避免在运行时造成性能损失，我们可以使用 JVM 选项 -XX:+AlwaysPreTouch 在应用程序启动时先访问所有分配给它的内存，让操作系统把内存真正的分配给 JVM。我们还可以将 vm.swappability 设置为0，这样操作系统就不会交换页面到 swap（除非绝对必要）。&lt;/p&gt;
&lt;p&gt;可能你会使用 mlock 将 JVM 页固定到内存中，这样操作系统就不会将它们交换出去。但是，如果系统用尽了所有的内存和交换空间，操作系统将终止一个进程来回收内存。通常情况下，Linux 内核会选择具有高驻留内存占用但运行时间不长的进程（OOM 情况下杀死进程的工作流（参考[9]）进行终止。在我们的例子中，这个进程很有可能就是我们的应用程序。优雅的降级是服务优秀的属性之一，不过服务突然终止的可能性对于可操作性来说并不好 —— 因此，我们不使用 mlock，只是通过 vm.swapability 来尽可能避免交换内存页到 swap 的惩罚。&lt;/p&gt;
&lt;p&gt;LinkedIn 动态信息数据平台的 GC 优化&lt;/p&gt;
&lt;p&gt;对于该 Feed 平台原型系统，我们使用 Hotspot JVM 的两个 GC 算法优化垃圾回收：&lt;/p&gt;
&lt;p&gt;Young GC 使用 ParNew，Old GC 使用 CMS。&lt;br/&gt;
Young Gen 和 Old Gen 使用 G1。G1 试图解决堆大小为 6GB 或更大时，暂停时间稳定且可预测在 0.5 秒以下的问题。在我们用 G1 实验过程中，尽管调整了各种参数，但没有得到像 ParNew/CMS 一样的 GC 性能或停顿时间的可预测值。我们查询了使用 G1 发生内存泄漏相关的一个 bug（见解释[3]），但还不能确定根本原因。&lt;br/&gt;
使用 ParNew/CMS，应用每三秒进行一次 40-60ms 的 Young GC 和每小时一个 CMS GC。JVM 参数如下：&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;// JVM sizing options
-server -Xms40g -Xmx40g -XX:MaxDirectMemorySize=4096m -XX:PermSize=256m -XX:MaxPermSize=256m   
// Young generation options
-XX:NewSize=6g -XX:MaxNewSize=6g -XX:+UseParNewGC -XX:MaxTenuringThreshold=2 -XX:SurvivorRatio=8 -XX:+UnlockDiagnosticVMOptions -XX:ParGCCardsPerStrideChunk=32768
// Old generation  options
-XX:+UseConcMarkSweepGC -XX:CMSParallelRemarkEnabled -XX:+ParallelRefProcEnabled -XX:+CMSClassUnloadingEnabled  -XX:CMSInitiatingOccupancyFraction=80 -XX:+UseCMSInitiatingOccupancyOnly   
// Other options
-XX:+AlwaysPreTouch -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -XX:-OmitStackTraceInFastThrow
&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;p&gt;使用这些参数，对于成千上万读请求的吞吐量，我们应用程序的 999 线降低到 60ms。&lt;/p&gt;
&lt;p&gt;解释&lt;/p&gt;
&lt;p&gt;[1] -XX:+BindGCTaskThreadsToCPUs 参数似乎在Linux 系统上不起作用，因为 hotspot/src/os/linux/vm/oslinux.cpp 的 distributeprocesses 方法在 JDK7 或 JDK8 中没有实现。&lt;/p&gt;
&lt;p&gt;[2] -XX:+UseGCTaskAffinity 参数在 JDK7 和 JDK8 的所有平台似乎都不起作用，因为任务的亲缘性属性永远被设置为 sentinelworker = (uint) -1。源码见 hotspot/src/share/vm/gcimplementation/parallelScavenge/{gcTaskManager.cpp，gcTaskThread.cpp, gcTaskManager.cpp}。&lt;/p&gt;
&lt;p&gt;[3] G1 存在一些内存泄露的 bug，可能 Java7u51 没有修改。这个 bug 仅在 Java 8 修正了。&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>bef9dab09790f19dfebfd8cc449c3076</guid>
<title>[推荐] 杭州某大厂：MySQL 连环问</title>
<link>https://toutiao.io/k/xjnx4kp</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，我是yes。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MySQL 面试题又更新啦！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请继续接招。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;说说分库分表？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随着用户量的激增和时间的堆砌，存在数据库里面的数据越来越多，此时的数据库就会产生瓶颈，出现资源报警、查询慢等场景。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先单机数据库所能承载的连接数、I/O及网络的吞吐等都是有限的，所以当并发量上来了之后，数据库就渐渐顶不住了。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.40814299900695133&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eSdk75TK4nEWAm9e6WibicVVnudWpTXSpbLKZHAvclSNUEknzcbZW02kVoUtBInLibrATW08HISruNjxULAicJSiakw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1007&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再则，如果单表的数据量过大，查询的性能也会下降。因为数据越多 B+ 树就越高，树越高则查询 I/O 的次数就越多，那么性能也就越差。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为上述的原因，不得已就得上分库分表了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;把以前存在一个数据库实例里的数据拆分成多个数据库实例，部署在不同的服务器中，&lt;span&gt;这是分库&lt;/span&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;把以前存在一张表里面的数据拆分成多张表，&lt;span&gt;这是分表&lt;/span&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般而言：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;分表：是为了解决由于单张表数据量多大，而导致查询慢的问题。大致三、四千万行数据就得拆分，不过具体还是得看每一行的数据量大小，有些字段都很小的可能支持更多行数，有些字段大的可能一千万就顶不住了。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;分库：是为了解决服务器资源受单机限制，顶不住高并发访问的问题，把请求分配到多台服务器上，降低服务器压力。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;你们一般怎么分库的？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般分库都是按照业务划分的，比如订单库、用户库等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有时候会针对一些特殊的库再作切分，比如一些活动相关的库都做了拆分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为做活动的时候并发可能会比较高，怕影响现有的核心业务，所以即使有关联，也会单独做拆分。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.7423971377459749&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eSdk75TK4nEWAm9e6WibicVVnudWpTXSpb6yoRNpHXmcfQqEqlOKaXxPqjotTEiaib2uCoXtWA3AebKEgiapcW6f3Aw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;559&quot;/&gt;&lt;/figure&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;那你觉得分库会带来什么问题呢？&lt;/span&gt;&lt;/h1&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;首先是&lt;span&gt;事务&lt;/span&gt;的问题。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们使用关系型数据库，有很大一点在于它保证事务完整性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而分库之后单机事务就用不上了，必须使用分布式事务来解决，而分布式事务基本的都是残缺的(我之前文章把分布式事务汇总了一波，后台搜索分布式事务就有了)。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是很重要的一点需要考虑。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;连表 JOIN 问题&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在一个库中的时候我们还可以利用 JOIN 来连表查询，而跨库了之后就无法使用 JOIN 了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时的解决方案就是&lt;span&gt;在业务代码中进行关联&lt;/span&gt;，也就是先把一个表的数据查出来，然后通过得到的结果再去查另一张表，然后利用代码来关联得到最终的结果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种方式实现起来稍微比较复杂，不过也是可以接受的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有可以&lt;span&gt;适当的冗余一些字段&lt;/span&gt;。比如以前的表就存储一个关联 ID，但是业务时常要求返回对应的 Name 或者其他字段。这时候就可以把这些字段冗余到当前表中，来去除需要关联的操作。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;那你们怎么分表的？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分表其实有两种：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;垂直分表，来看个图，很直观：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6628982528263104&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eSdk75TK4nEWAm9e6WibicVVnudWpTXSpb4eaOkdIoQsksMWPEyDJvonV78gfmqqelicN2FFfb7RZ7OJwFF6cSdEg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;973&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;垂直分表&lt;/span&gt;就是把一些不常用的大字段剥离出去。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;像上面的例子：用户名是很常见的搜索结果，性别和年龄占用的空间又不大，而地址和个人简介占用的空间相对而言就较大，我们都知道一个数据页的空间是有限的，把一些无用的数据拆分出去，一页就能存放更多行的数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内存存放更多有用的数据，就减少了磁盘的访问次数，性能就得到提升。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;水平分表&lt;/span&gt;，则是因为一张表内的数据太多了，上文也提到了数据越多 B+ 树就越高，访问的性能就差，所以进行水平拆分。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.39633638634471274&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eSdk75TK4nEWAm9e6WibicVVnudWpTXSpbC6sWOAAMlgwXMpYNlvgsf6FrWLQD1JFHqCe7bjjKFEOq3wFWj5RiabQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1201&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实不管这些，浅显的理解下，在一百个数据里面找一个数据快，还是在一万个数据里面找一个数据快？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;即使有索引，那厚的书目录多，翻目录也慢~&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;那分表会有什么问题？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;垂直分表还好，就是需要关联一下，而水平分表就有点麻烦了。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;排序、count、分页问题&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果一个用户的数据被拆分到多个表中，那查询结果分页就不像以前单张表那样直接就能查出来了，像 count 操作也是一样的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;只能由业务代码来实现或者用中间件将各表中的数据汇总、排序、分页然后返回。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;像 count 操作的结果其实可以缓存下来，然后每次数据增删都更新计数。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;路由问题&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分表的路由可以分：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Hash 路由&lt;/span&gt;，其实就是选择表中的某一列，然后进行 Hash 运算，将 Hash 运算得到的结果再对子表数进行取模，这样就能均匀的将数据分到不同的子表上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这跟 HashMap 选哪个桶是一样的原理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优点就是数据分布均匀。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缺点就是增加子表的时候麻烦，想想 HashMap的扩容，是不是得搬迁数据？这个分表也是一样的，我们可都知道，数据迁移一件麻烦事！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;范围路由&lt;/span&gt;，其实很简单，可以是时间，也可以是地址，表示一定的范围的即可。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如本来一张 User 表，我可以分 User_HZ、User_BJ、User_SH，按照地名来划分 User。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再比如 log 表，我可以将表分为 log_202103、 log_202104，把日志按照年月来划分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优点就是相对而言比较容易扩展，比如现在来个 GZ，那就加个 User_GZ。如果到了 5 月，那就建个 log_202105。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缺点就是数据可能分布不均匀，例如 BJ 的用户特别多或者某个月搞了促销，日志量特别大，等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;路由表&lt;/span&gt;，就是专门搞个表来记录路由信息，来看个图就很清楚了。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.653276955602537&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eSdk75TK4nEWAm9e6WibicVVnudWpTXSpblrE8Xmfc4av0iaHIDchGDc8lnyynXU6epNicRcyeE5W6amZqy3rLRzZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;473&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从图中我们就能得知，UserID 为 2 的用户数据在要去 User_3 这个用户表查询。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优点就是灵活咯，如果要迁移数据，直接迁移然后路由表一改就完事儿了~&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;缺点就是得多查一次，每次查询都需要访问路由表，不过这个一般会做缓存的。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;全局主键问题&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以前单表的时候很简单，就是主键自增，现在分表了之后就有点尴尬了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以需要一些手段来保证全局主键唯一。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;还是自增，只不过自增步长设置一下。比如现在有三张表，步长设置为3，三张表 ID 初始值分别是1、2、3。这样第一张表的 ID 增长是 1、4、7。第二张表是2、5、8。第三张表是3、6、9，这样就不会重复了。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;UUID，这种最简单，但是不连续的主键插入会导致严重的页分裂，性能比较差。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;分布式 ID，比较出名的就是 Twitter 开源的 sonwflake 雪花算法，具体就不展开了，不然就又是一篇文章了，简单点利用 redis 来递增也行。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;那上面说的路由问题的 Sharding-Key 如何设计呢？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们分表是按照某个列来拆分的，那个列就是 Sharding-Key，查询的时候必须带上这个列才行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如上面提到的  log_202103，那表明查询条件一定得带上日期，这样才能找到正确的表。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以设计上得考虑查询的条件来作为 Sharding-Key。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;举个常常会被问的订单表 Sharding-Key 例子。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你想着查找订单的时候会通过订单号去找，所以应该利用订单 ID 来作为 Sharding-Key。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是你想想，你打开外卖软件想查找你的历史订单的时候，你是没有订单 ID 的，你只有你的 UserID，那此时只能把所有子表都通过 UserID 遍历一遍，这样效率就很低了！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以你想着那用 UserID 来作为 Sharding-Key 吧！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，商家呢？商家肯定关心自己今天卖了多少单，所以他也要查找订单，但他只有自己的商家 ID，所以如果要查询订单，只能把所有子表都通过商家 ID 遍历一遍，这样效率就很低了！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以 Sharding-Key 是满足不了所有查询需求的，只能曲线救国。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般做法就是&lt;span&gt;冗余数据&lt;/span&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;将订单同步到另一张表中给商家使用，这个表按商家 ID 来作为 Sharding-Key，也可以将数据同步到 ES 中。一般而言这里的数据同步都是异步处理，不会影响正常流程。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;最后&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天的面试题主要是分库分表相关的，基本上常问的都涵盖了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MySQL 面试题未完，持续更新~&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为分库分表会带来很多复杂性，所以能不分库分表，就不要分库分表。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个前提请牢记。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有，&lt;span&gt;面试题交流群&lt;/span&gt;持续开放，已经分享了近 50 个面经。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;加我微信: yes_oba，备注面试，拉你进群。&lt;/p&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我是 yes，从一点点到亿点点，我们下篇见~&lt;/p&gt;&lt;section data-recommend-type=&quot;list-title&quot; data-recommend-tid=&quot;8&quot; data-mpa-template=&quot;t&quot; data-mid=&quot;&quot; data-from=&quot;yb-recommend&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;往期推荐&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; data-recommend-article-type=&quot;list-title&quot; data-recomment-template-id=&quot;8&quot; data-recommend-article-id=&quot;2247489107_1&quot; data-recommend-article-time=&quot;1619081400&quot; data-recommend-article-cover=&quot;http://mmbiz.qpic.cn/mmbiz_jpg/eSdk75TK4nGygiam8LvNnHpvoNO012TInP3YB3cYuqicIzOJudn4Tu3Q0UYiab4KKBo8hx0LFxNsb1Ys1OtHzsVNA/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;我给总监打了包票，结果......我不想3.25&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzkxNTE3NjQ3MA==&amp;amp;mid=2247489107&amp;amp;idx=1&amp;amp;sn=12c449ae8afc6d1d6d89b8236854eede&amp;amp;chksm=c1627b2af615f23c55fe23b3686c6c95f0512f4ce2a7559f78e751283b159b81968a40644274#rd&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzkxNTE3NjQ3MA==&amp;amp;mid=2247489107&amp;amp;idx=1&amp;amp;sn=12c449ae8afc6d1d6d89b8236854eede&amp;amp;chksm=c1627b2af615f23c55fe23b3686c6c95f0512f4ce2a7559f78e751283b159b81968a40644274&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;&lt;section data-recommend-title=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;我给总监打了包票，结果......我不想3.25&lt;/p&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; data-recommend-article-type=&quot;list-title&quot; data-recomment-template-id=&quot;8&quot; data-recommend-article-id=&quot;2247489047_1&quot; data-recommend-article-time=&quot;1618878060&quot; data-recommend-article-cover=&quot;http://mmbiz.qpic.cn/mmbiz_jpg/eSdk75TK4nHQJOTMnuMpLPx77KCicwSYCRicy2RIibkVavVB9skjWIbOXNHEvicXibQfCu7BuXo02dxpjicLdhDg2ic2w/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;总监问我：Kafka为什么要抛弃ZooKeeper？| 文末送书&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzkxNTE3NjQ3MA==&amp;amp;mid=2247489047&amp;amp;idx=1&amp;amp;sn=ac16366e70fce619409360a972562f28&amp;amp;chksm=c1627b6ef615f278cee7ffe2a3d68111dbd2292d99a83e6cad15de7bd66af8ed54a4c11e784a#rd&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzkxNTE3NjQ3MA==&amp;amp;mid=2247489047&amp;amp;idx=1&amp;amp;sn=ac16366e70fce619409360a972562f28&amp;amp;chksm=c1627b6ef615f278cee7ffe2a3d68111dbd2292d99a83e6cad15de7bd66af8ed54a4c11e784a&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;&lt;section data-recommend-title=&quot;t&quot; data-mid=&quot;&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;总监问我：Kafka为什么要抛弃ZooKeeper？| 文末送书&lt;/p&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e673c59e9f42b2dcaac6f769562148d6</guid>
<title>[推荐] 惊！这个 Go 开源项目号称「不改一行代码做秒杀」</title>
<link>https://toutiao.io/k/qnyxbs9</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;23&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;span&gt;阅读本文大概需要 2 分钟。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，我是 polarisxu。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到耗子叔发推文推荐了一个新开源的网关：Easegress。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.43005181347150256&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UzjmETLXwBaZWKKF0aSaChclOHu7laFedvaxa0eueVuPxwnhF2HdGLz3ZIrMTaEwy6DJ5TfbyHNMhhYgArxW5w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1158&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;打开看了下，这是一个 Go 语言实现的开源项目。它有如下亮点：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;高可用。内置 Raft 共识和领导者选举，提供 99.99％ 的可用性。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;流量编排。将各种过滤器动态地编排到流量管道。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;高性能。轻量级和基础特性提升性能。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;可观察性。以可读方式定期存放许多有意义的统计数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;可扩展性。使用高级编程语言开发自己的过滤器或控制器很容易。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一体化。简单的接口使其易于与其他系统集成，例如 Kubernetes Ingress，Easemesh Sidecar，Workflow 等。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;给一张架构图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4578125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UzjmETLXwBaZWKKF0aSaChclOHu7laFelnG5ouQsoNo4HAlGd7I5LXFaMlz93Kr5NEfywFoXLgdY4jibAxEevEA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体的功能特性，耗子叔给了一张图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;3.8641509433962264&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UzjmETLXwBaZWKKF0aSaChclOHu7laFecibnIyqiak6pfS1LYmYvaicg33tbR7Tcz4fkzGmia2LfYfAicRAiakiawibemQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1060&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看起来很强大，而且他们公司的产品宣传是：&lt;strong&gt;不改一行代码做秒杀&lt;/strong&gt;。有机会可以深入学习研究下。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然是国人开源项目，不过文档是全英文的，没有中文版。很显然是要走向国际的。&lt;strong&gt;阅读原文&lt;/strong&gt;可以直达项目首页：https://github.com/megaease/easegress。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;hr/&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;往期推荐&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UzjmETLXwBYuP3ncUTaemHXQYjOZDS40VoicqII73Hu9RncJv06g0kJhnrVicSmUfJRg5Wf9qcDHj7zf5vTjns5A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;258&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我是 polarisxu，北大硕士毕业，曾在 360 等知名互联网公司工作，10多年技术研发与架构经验！2012 年接触 Go 语言并创建了 Go 语言中文网！著有《&lt;/span&gt;&lt;span&gt;Go语言编程之旅&lt;/span&gt;&lt;span&gt;》、开源图书《&lt;/span&gt;&lt;span&gt;Go语言标准库&lt;/span&gt;&lt;span&gt;》等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;坚持输出技术（包括 Go、Rust 等技术）、职场心得和创业感悟！欢迎关注「polarisxu」一起成长！也欢迎加我微信好友交流：&lt;/span&gt;&lt;span&gt;gopherstudio&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>708505d3cd88587be98e4a30354d1380</guid>
<title>[推荐] 一文理解 Redis 底层数据结构</title>
<link>https://toutiao.io/k/a3gplbq</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-source-line=&quot;1&quot;&gt;Redis的5种常见数据结构：字符串(String)、列表(List)、散列(Hash)、集合(Set)、有序集合(Sorted Set)。这些都是Redis对外暴露的数据结构，本文将介绍这些数据结构的底层数据结构的实现。&lt;/p&gt;&lt;p data-source-line=&quot;3&quot;&gt;Redis底层数据结构有六种：&lt;/p&gt;&lt;ul data-source-line=&quot;4&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;简单动态字符串（SDS）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;列表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;字典&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;整数集合&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;跳跃表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;压缩列表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;快速列表&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-source-line=&quot;12&quot;&gt;简单动态字符串（SDS）&lt;/h2&gt;&lt;p data-source-line=&quot;14&quot;&gt;SDS是&quot;simple dynamic string&quot;的缩写。Redis中所有场景中出现的字符串，基本都是由SDS来实现的。&lt;/p&gt;&lt;p data-source-line=&quot;16&quot;&gt;使用场景：&lt;/p&gt;&lt;ul data-source-line=&quot;17&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;所有非数字的key。例如：&lt;code&gt;set msg &quot;hello world&quot;&lt;/code&gt;中的key msg.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;字符串数据类型的值。例如：&lt;code&gt;set msg &quot;hello world&quot;&lt;/code&gt;中的msg的值&lt;code&gt;&quot;hello wolrd&quot;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;非字符串数据类型中的“字符串值”。例如：&lt;code&gt;RPUSH fruits &quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;&lt;/code&gt;中的&lt;code&gt;&quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;21&quot;&gt;SDS结构图：&lt;/p&gt;&lt;p data-source-line=&quot;23&quot;&gt;&lt;img data-ratio=&quot;0.37174721189591076&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwQMQXH7jatA6qic7FxhOlD3lMxqC4iaGuE7grIlFJ6sicCCRbynhTicXRmA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;538&quot;/&gt;&lt;/p&gt;&lt;ul data-source-line=&quot;25&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;len：记录当前已使用的字节数（不包括&#x27;\0&#x27;），获取SDS长度的复杂度为O(1)（C 语言中获取字符串长度的时间复杂度为 O(N)）。此外，len值还避免了二进制安全与缓存区溢出的问题。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;alloc：记录当前字节数组总共分配的字节数量（不包括&#x27;\0&#x27;）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;flags：标记当前字节数组的属性，是sdshdr8还是sdshdr16等。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;buf：字节数组，用于保存字符串，包括结尾空白字符&#x27;\0&#x27;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-source-line=&quot;30&quot;&gt;&lt;code&gt;&lt;span&gt;// flags&lt;span&gt;值定义&lt;/span&gt;(&lt;span&gt;为了节约头部空间，在&lt;/span&gt;Redis3.2&lt;span&gt;开始，增加&lt;/span&gt;flag&lt;span&gt;字段。&lt;/span&gt;SDS&lt;span&gt;由一种数据结构变成了&lt;/span&gt;5&lt;span&gt;种数据结构，会根据&lt;/span&gt;SDS&lt;span&gt;存储的内容长度来选择不同的结构，以达到节省内存的效果&lt;/span&gt;)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_5  0&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_8  1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_16 2&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_32 3&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_64 4&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote data-source-line=&quot;39&quot;&gt;&lt;p&gt;注：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;二进制安全：通俗的讲，C语言中，用“\0”表示字符串的结束，如果字符串本身就有“\0”字符，字符串就会被截断，即非二进制安全；若通过某种机制，保证读写字符串时不损害其内容，这就是二进制安全。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;因为C字符串不记录自身的长度，所以strcat会假定用户在执行这个函数时，已经为dest分配足够多的内存了，可以容纳src字符串中的所有内容，而一旦这个假设不成立，就会产生缓存区溢出。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;h3 data-source-line=&quot;43&quot;&gt;频繁内存分配问题处理&lt;/h3&gt;&lt;p data-source-line=&quot;45&quot;&gt;每次增长或者缩短一个字符，程序都需要对保存这个字符串的数组进行一次内存重新分配操作。因为内存重分配涉及复杂的算法，并且可能需要执行系统调用，所以它通常是一个比较耗时的操作。&lt;/p&gt;&lt;p data-source-line=&quot;47&quot;&gt;为了避免C字符串的这种缺陷，SDS通过未使用空间解除了字符串长度和底层数组长度之间的关联。通过未使用空间，SDS实现了空间预分配和惰性空间释放两种优化策略。&lt;/p&gt;&lt;ol data-source-line=&quot;49&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;空间预分配&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;51&quot;&gt;空间预分配用于优化SDS的字符串增长操作。当SDS的API对一个SDS进行修改，并且需要对SDS进行空间扩展的时候，程序不仅会为SDS分配修改所必须要的空间，还会为SDS分配额外的未使用空间。其中，额外分配的未使用空间数量由以下公式决定：&lt;/p&gt;&lt;p data-source-line=&quot;57&quot;&gt;在扩展SDS空间之前，SDS API会先检查未使用空间是否足够，如果足够的话，API就会直接使用未使用空间，而无需执行内存重分配。通过空间预分配策略，Redis可以减少连续执行字符串增长操作所需的内存重分配次数。&lt;/p&gt;&lt;ol start=&quot;2&quot; data-source-line=&quot;59&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;惰性空间释放&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;61&quot;&gt;惰性空间释放用于优化SDS的字符串缩短操作。当SDS的API需要缩短SDS保存的字符串时，程序不会立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录下来，并等待将来使用。&lt;/p&gt;&lt;p data-source-line=&quot;63&quot;&gt;通过惰性空间释放策略，SDS避免了缩短字符串时所需的内存重分配操作，并为将来可能的增长操作提供了优化。&lt;/p&gt;&lt;p data-source-line=&quot;65&quot;&gt;与此同时，SDS也提供了响应的API可以在有需要时，真正的释放SDS里面的未使用空间，所以不用担心惰性空间释放策略会造成内存浪费。&lt;/p&gt;&lt;h2 data-source-line=&quot;67&quot;&gt;列表&lt;/h2&gt;&lt;p data-source-line=&quot;69&quot;&gt;列表在Redis中应用的非常广，列表的底层实现就是链表。此外，Redis的发布与订阅、慢查询、监视器等功能也用到了链表。&lt;/p&gt;&lt;p data-source-line=&quot;71&quot;&gt;列表特点：&lt;/p&gt;&lt;ul data-source-line=&quot;72&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;双端链表：带有指向前置节点和后置节点的指针，获取这两个节点的复杂度为O(1)。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无环：表头节点的prev和表尾节点的next都指向NULL，对链表的访问以NULL结束。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;链表长度计数器：带有len属性，获取链表长度的复杂度为O(1)。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多态：链表节点使用 void*指针保存节点值，可以保存不同类型的值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;77&quot;&gt;列表结构图：&lt;/p&gt;&lt;p data-source-line=&quot;79&quot;&gt;&lt;img data-ratio=&quot;0.5209471766848816&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwbJxwcmialX3lgnMv3gocSuvgic5bUDfNIpRiaicVXAEZTZ6icReicJMNBovQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;549&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;81&quot;&gt;列表的数据结构（adlist.h/listNode与adlist.h/list）：&lt;/p&gt;&lt;p data-source-line=&quot;83&quot;&gt;listNode：&lt;/p&gt;&lt;ul data-source-line=&quot;84&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;prev：前置节点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;next：后置节点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;value：节点值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;88&quot;&gt;list：&lt;/p&gt;&lt;h2 data-source-line=&quot;96&quot;&gt;字典&lt;/h2&gt;&lt;p data-source-line=&quot;98&quot;&gt;字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对的抽象数据结构。字典中的每一个键都是唯一的，可以通过键查找与之关联的值，并对其修改或删除。&lt;/p&gt;&lt;p data-source-line=&quot;100&quot;&gt;Redis的键值对存储就是用字典实现的，散列（Hash）的底层实现之一也是字典。&lt;/p&gt;&lt;p data-source-line=&quot;102&quot;&gt;字典的结构图（与JDk中的HashMap结构很相似）：&lt;/p&gt;&lt;p data-source-line=&quot;104&quot;&gt;&lt;img data-ratio=&quot;0.3811074918566775&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwc4KGUvAU6PYaLgaYHiaksQSZO0SHKErKibXVyWXHXTahl1UjGDr9W8xA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;921&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;106&quot;&gt;字典的数据结构（dict.h/dictht与dict.h/dict）：&lt;/p&gt;&lt;p data-source-line=&quot;108&quot;&gt;dict：&lt;/p&gt;&lt;ul data-source-line=&quot;109&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;type：针对不同类型的键值对，用于创建多类型的字典&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;privdata：针对不同类型的键值对，用于创建多类型的字典&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ht：两个元素的数组，包含两个dictht哈希表，一般字典只使用ht[0]哈希表，ht[1]哈希表会在对ht[0]哈希表进行rehash（重哈希）的时候使用，即当哈希表的键值对数量超过负载数量过多的时候，会将键值对迁移到ht[1]上&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;rehashidx：rehashidx也是跟rehash相关的，rehash的操作不是瞬间完成的，rehashidx记录着rehash的进度，图中没有进行rehash，它的值为-1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;114&quot;&gt;dictht：&lt;/p&gt;&lt;p data-source-line=&quot;120&quot;&gt;dictEntry：&lt;/p&gt;&lt;ul data-source-line=&quot;121&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;key：键&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;next：下一个dictEntry节点&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;value：union类型，支持不同类型的值&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-source-line=&quot;125&quot;&gt;渐进式hash&lt;/h3&gt;&lt;p data-source-line=&quot;127&quot;&gt;字典类型容量变化过程叫做rehash。需要满足一定的条件才能触发扩容机制：&lt;/p&gt;&lt;ol data-source-line=&quot;128&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;服务器当前没有进行BGWRITEAOF或者BGSAVE命令，且当前键值对个数超过一维数组的大小，才会触发扩容。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果当前键值对个数超过一维数组大小的五倍，无论是否在进行BGWRITEAOF或者BGSAVE命令，都会强制扩容。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果当前键值对个数少于一维数组大小的十分之一，则触发缩容过程。缩容不会考虑当前服务器是否在进行BGWRITEAOF或者BGSAVE命令。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;132&quot;&gt;渐进式hash的过程，简单来说类似数据库的迁移，读的时候先读ht[0]，读不到读ht[1]；写的时候只写ht[1]；ht[0]数据慢慢地往ht[1]上搬。&lt;/p&gt;&lt;p data-source-line=&quot;134&quot;&gt;当ht[0]的所有键值都迁至ht[1]之后，ht[0]变为空表，释放ht[0]。并将ht[1]设置为ht[0]，并在ht[1]新创建一个空白哈希表，将rehashidx属性的值设为-1，表示rehash操作已完成。&lt;/p&gt;&lt;p data-source-line=&quot;136&quot;&gt;具体步骤如下：&lt;/p&gt;&lt;ol data-source-line=&quot;138&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;为字典的备用哈希表分配空间：如果执行的是扩展操作，那么备用哈希表的大小为第一个大于等于(已用节点个数)*2的2n（2的n次方幂） 如果执行的是收缩操作，那么备用哈希表的大小为第一个大于等于(已用节点个数)的2n&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始（为-1时表示没有进行rehash）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当一次rehash工作完成之后，程序将rehashidx属性的值+1。同时在serverCron中调用rehash相关函数，在1ms的时间内，进行rehash处理，每次仅处理少量的转移任务(100个元素)。随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;145&quot;&gt;这里比较下Redis的渐进hash与JDk中HashMap的resize过程。如果对HashMap不了解，可以查看《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247483866&amp;amp;idx=1&amp;amp;sn=9ae4f9da57a198fdfc16265657e5efde&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;详解并发下的HashMap以及JDK8的优化&lt;/a&gt;》。&lt;/p&gt;&lt;h2 data-source-line=&quot;147&quot;&gt;整数集合&lt;/h2&gt;&lt;p data-source-line=&quot;149&quot;&gt;整数集合（intset）是Redis用于保存整数值的集合抽象数据结构，可以保存类型为int16_t、int32_t、int64_t的整数值，并且保证集合中不会出现重复元素 整数集合是集合（Set）的底层实现之一，如果一个集合只包含整数值元素，且元素数量不多时，会使用整数集合作为底层实现&lt;/p&gt;&lt;p data-source-line=&quot;152&quot;&gt;整数集合的结构图：&lt;/p&gt;&lt;p data-source-line=&quot;154&quot;&gt;&lt;img data-ratio=&quot;0.2747826086956522&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwnnOYZUcLPR1lvcM8ibLVFmXVJea0x7PDUGpPIxYdv5kytO6tUkt21Gw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;575&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;156&quot;&gt;整数集合的数据结构（inset.h/inset）：&lt;/p&gt;&lt;p data-source-line=&quot;158&quot;&gt;intset：&lt;/p&gt;&lt;ul data-source-line=&quot;159&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;encoding：决定contents数组的真正类型，如INTSET_ENC_INT16、INTSET_ENC_INT32、INTSET_ENC_INT64。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;length：记录整数集合的元素数量，即contents数组长度&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;contents：整数集合的每个元素在数组中按值的大小从小到大排序，且不包含重复项。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-source-line=&quot;163&quot;&gt;整数集合的升级&lt;/h3&gt;&lt;p data-source-line=&quot;165&quot;&gt;当想要添加一个新元素到整数集合中时，并且新元素的类型比整数集合现有的所有元素的类型都要长，整数集合需要先进行升级，才能将新元素添加到整数集合里面。每次想整数集合中添加新元素都有可能会引起升级，每次升级都需要对底层数组已有的所有元素进行类型转换。&lt;/p&gt;&lt;p data-source-line=&quot;167&quot;&gt;升级添加新元素：&lt;/p&gt;&lt;p data-source-line=&quot;173&quot;&gt;整数集合的升级策略可以提升整数集合的灵活性，并尽可能的节约内存。另外，整数集合不支持降级，一旦升级，编码就会一直保持升级后的状态。&lt;/p&gt;&lt;h2 data-source-line=&quot;175&quot;&gt;跳跃表&lt;/h2&gt;&lt;p data-source-line=&quot;177&quot;&gt;一个普通的单链表查询一个元素的时间复杂度为O(N)，即便该单链表是有序的。使用跳跃表（SkipList）是来解决查找问题的，它是一种有序的数据结构，不属于平衡树结构，也不属于Hash结构，它通过在每个节点维持多个指向其他节点的指针，而达到快速访问节点的目的 跳跃表是有序集合（Sorted Set）的底层实现之一，如果有序集合包含的元素比较多，或者元素的成员是比较长的字符串时，Redis会使用跳跃表做有序集合的底层实现。&lt;/p&gt;&lt;p data-source-line=&quot;180&quot;&gt;跳跃表其实可以把它理解为多层的链表，它有如下的性质：&lt;/p&gt;&lt;p data-source-line=&quot;187&quot;&gt;有关跳跃表的讲解，可以查看《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247483893&amp;amp;idx=1&amp;amp;sn=04e19d3f3a424bd53937c4bca78f3003&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;有关跳跃表的干货都在这里&lt;/a&gt;》&lt;/p&gt;&lt;p data-source-line=&quot;189&quot;&gt;跳跃表的结构图：&lt;/p&gt;&lt;p data-source-line=&quot;191&quot;&gt;&lt;img data-ratio=&quot;0.49741468459152016&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwLlkfia9Via47JDhg1U2I0CicnvaItUfkMosCsn0JkZJ9whEvMjXscSacQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;967&quot;/&gt;&lt;/p&gt;&lt;h2 data-source-line=&quot;197&quot;&gt;压缩列表&lt;/h2&gt;&lt;p data-source-line=&quot;199&quot;&gt;压缩列表（ziplist）是为了节约内存而设计的，是由一系列特殊编码的连续内存块组成的顺序性（sequential）数据结构，一个压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者一个整数值。&lt;/p&gt;&lt;p data-source-line=&quot;201&quot;&gt;压缩列表是列表（List）和散列（Hash）的底层实现之一，一个列表只包含少量列表项，并且每个列表项是小整数值或比较短的字符串，会使用压缩列表作为底层实现（在3.2版本之后是使用quicklist实现）。&lt;/p&gt;&lt;p data-source-line=&quot;203&quot;&gt;压缩列表的结构图：&lt;/p&gt;&lt;p data-source-line=&quot;205&quot;&gt;&lt;img data-ratio=&quot;0.07936507936507936&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZw1gyTUNkEoFVgRIia2VmIH6LlsYu7Yzu3IcPQJxG5tRZgAUhPSgibfrYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;693&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;207&quot;&gt;一个压缩列表可以包含多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。&lt;/p&gt;&lt;p data-source-line=&quot;209&quot;&gt;压缩列表的数据结构：&lt;/p&gt;&lt;ul data-source-line=&quot;211&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;zlbytes：记录整个压缩列表占用的内存字节数，在压缩列表内存重分配，或者计算zlend的位置时使用。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;zltail：记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，通过该偏移量，可以不用遍历整个压缩列表就可以确定表尾节点的地址。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;zllen：记录压缩列表包含的节点数量，但该属性值小于UINT16_MAX（65535）时，该值就是压缩列表的节点数量，否则需要遍历整个压缩列表才能计算出真实的节点数量。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;entryX：压缩列表的节点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;zlend：特殊值0xFF（十进制255），用于标记压缩列表的末端。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-source-line=&quot;217&quot;&gt;压缩列表节点的构成&lt;/h3&gt;&lt;p data-source-line=&quot;219&quot;&gt;&lt;img data-ratio=&quot;0.11711711711711711&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwfnGricWnnmBUw6Lw1ricMYmXzWBiagknicIVD6EfygeNC3ib19zN9EYo5rQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;444&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;221&quot;&gt;每个压缩列表节点可以保存一个字节数字或者一个整数值。压缩列表节点的数据结构：&lt;/p&gt;&lt;ul data-source-line=&quot;222&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;previous_entry_ength：记录压缩列表前一个字节的长度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;encoding：节点的encoding保存的是节点的content的内容类型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;content：content区域用于保存节点的内容，节点内容类型和长度由encoding决定。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-source-line=&quot;226&quot;&gt;快速列表&lt;/h2&gt;&lt;p data-source-line=&quot;228&quot;&gt;考虑到链表的附加空间相对太高，prev和next指针就要占去16个字节（64bit系统的指针是8个字节）。另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。因此Redis3.2版本开始对列表数据结构进行了改造，使用快速列表（quicklist）代替了压缩列表和列表。&lt;/p&gt;&lt;p data-source-line=&quot;230&quot;&gt;快速列表的结构图：&lt;/p&gt;&lt;p data-source-line=&quot;232&quot;&gt;&lt;img data-ratio=&quot;0.6107470511140236&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwibUXyMRzf0qFFCPM9NUtXwn45M69TWMdq15P4rcx9mKUZJdAKndU59w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;763&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;234&quot;&gt;快速列表的数据结构：&lt;/p&gt;&lt;p data-source-line=&quot;236&quot;&gt;quicklistNode：&lt;/p&gt;&lt;ul data-source-line=&quot;238&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;prev: 指向链表前一个节点的指针。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;next: 指向链表后一个节点的指针。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;zl: 数据指针。如果当前节点的数据没有压缩，那么它指向一个ziplist结构；否则，它指向一个quicklistLZF结构。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;sz: 表示zl指向的ziplist的总大小（包括zlbytes, zltail, zllen, zlend和各个数据项）。需要注意的是：如果ziplist被压缩了，那么这个sz的值仍然是压缩前的ziplist大小。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;count: 表示ziplist里面包含的数据项个数。这个字段只有16bit。稍后我们会一起计算一下这16bit是否够用。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;encoding: 表示ziplist是否压缩了（以及用了哪个压缩算法）。目前只有两种取值：2表示被压缩了（而且用的是LZF压缩算法），1表示没有压缩。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;container: 是一个预留字段。本来设计是用来表明一个quicklist节点下面是直接存数据，还是使用ziplist存数据，或者用其它的结构来存数据（用作一个数据容器，所以叫container）。但是，在目前的实现中，这个值是一个固定的值2，表示使用ziplist作为数据容器。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;recompress: 当我们使用类似lindex这样的命令查看了某一项本来压缩的数据时，需要把数据暂时解压，这时就设置recompress=1做一个标记，等有机会再把数据重新压缩。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;attempted_compress: 这个值只对Redis的自动化测试程序有用。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;extra: 其它扩展字段。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;249&quot;&gt;quickList：&lt;/p&gt;&lt;ul data-source-line=&quot;250&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;head: 指向头节点（左侧第一个节点）的指针。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;tail: 指向尾节点（右侧第一个节点）的指针。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;count: 所有ziplist数据项的个数总和。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;len: quicklist节点的个数。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;fill: 16bit，ziplist大小设置，存放list-max-ziplist-size参数的值。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;compress: 16bit，节点压缩深度设置，存放list-compress-depth参数的值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-source-line=&quot;257&quot;&gt;压缩深度&lt;/h3&gt;&lt;p data-source-line=&quot;259&quot;&gt;quicklist默认的压缩深度是0，也就是不压缩。压缩的实际深度由配置参数&lt;code&gt;list-compress-depth&lt;/code&gt;决定。为了支持快速的push/pop操作，quicklist的首尾两个ziplist不压缩，此时深度就是1；如果深度为2，就表示quicklist的首尾第一个 ziplist以及首尾第二个ziplist都不压缩。&lt;/p&gt;&lt;h3 data-source-line=&quot;261&quot;&gt;zipList长度&lt;/h3&gt;&lt;p data-source-line=&quot;262&quot;&gt;quicklist 内部默认单个ziplist长度为8k字节，超出了这个字节数，就会新起一个ziplist。ziplist的长度由配置参数&lt;code&gt;list-max-ziplist-size&lt;/code&gt;决定。&lt;/p&gt;&lt;h2 data-source-line=&quot;264&quot;&gt;编码&lt;/h2&gt;&lt;p data-source-line=&quot;266&quot;&gt;上面介绍了Redis的主要底层数据结构，包括简单动态字符串（SDS）、链表、字典、跳跃表、整数集合、压缩列表。但是Redis并没有直接使用这些数据结构来构建数据库，而是基于这些数据结构创建不同的编码，然后由不同条件下的不同编码来实现Redis的这些数据类型：字符串(String)、列表(List)、散列(Hash)、集合(Set)、有序集合(Sorted Set)。&lt;/p&gt;&lt;p data-source-line=&quot;268&quot;&gt;接下来就介绍Redis五种数据结构对应的编码。&lt;/p&gt;&lt;h3 data-source-line=&quot;270&quot;&gt;字符串对象的编码&lt;/h3&gt;&lt;p data-source-line=&quot;272&quot;&gt;上面介绍了SDS，但这只是字符串对象的其中一种实现。字符串对象的编码可能有三种：int、raw、embstr。&lt;/p&gt;&lt;ol data-source-line=&quot;274&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;int&lt;br/&gt;如果一个字符串对象，保存的值是一个整数值，并且这个整数值在long的范围内，那么Redis用整数值来保存这个信息，并且将字符串编码设置为 int。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;raw&lt;br/&gt;如果字符串对象保存的是一个字符串, 并且长度大于32个字节，它就会使用前面讲过的SDS（简单动态字符串）数据结构来保存这个字符串值，并且将字符串对象的编码设置为raw。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;embstr&lt;br/&gt;如果字符串对象保存的是一个字符串，但是长度小于32个字节，它就会使用embstr来保存了，embstr编码不是一个数据结构，而是对SDS的一个小优化，当使用SDS 的时候，程序需要调用两次内存分配，来给字符串对象和SDS各自分配一块空间，而embstr只需要一次内存分配，因为他需要的空间很少，所以采用连续的空间保存，即将SDS的值和字符串对象的值放在一块连续的内存空间上。这样能在短字符串的时候提高一些效率。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;283&quot;&gt;浮点数如何保存：&lt;/p&gt;&lt;p data-source-line=&quot;285&quot;&gt;Redis的字符串数据类型是支持保存浮点数，并且支持对浮点数进行加减操作，但是Redis在底层是把浮点数转换成字符串值，然后按照上述编码规则。对浮点数进行操作时，也是从字符串转换成浮点数进行计算，然后再转换成字符串进行保存的。&lt;/p&gt;&lt;p data-source-line=&quot;287&quot;&gt;编码转换条件：&lt;/p&gt;&lt;p data-source-line=&quot;289&quot;&gt;如果对一个int编码的字符串对象，修改它成非整数值，则对象就会使用raw编码。而Redis没有为embstr编码提供任何的修改操作，embstr编码的值是只读的，只要发生修改，立刻将编码转换成raw。&lt;/p&gt;&lt;table data-source-line=&quot;291&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码&lt;/th&gt;&lt;th&gt;使用条件&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;int&lt;/td&gt;&lt;td&gt;可以用long保存的整数&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;raw&lt;/td&gt;&lt;td&gt;长度大于32的字符串&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;embstr&lt;/td&gt;&lt;td&gt;字符串长度小于32字节（或者浮点数转换后满足）&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;297&quot;&gt;列表对象的编码&lt;/h3&gt;&lt;p data-source-line=&quot;299&quot;&gt;在 Redis 3.2 版本之前，列表对象底层由 压缩列表和双向链表配合实现，当元素数量较少的时候，使用压缩列表，当元素数量增多，就开始使用普通的双向链表保存数据。&lt;/p&gt;&lt;p data-source-line=&quot;301&quot;&gt;但是这种实现方式不够好，双向链表中的每个节点，都需要保存前后指针，这个内存的使用量 对于Redis这个内存数据库来说极其不友好。&lt;/p&gt;&lt;p data-source-line=&quot;303&quot;&gt;因此在 3.2 之后的版本，Redis新实现了一个数据结构，叫做快速列表（quicklist）。所有列表的底层实现都是这个数据结构了。它的底层实现基本上就是将 双向链表和压缩列表进行了结合，用双向的指针将压缩列表进行连接，这样不仅避免了压缩列表存储大量元素的性能压力，同时避免了双向链表连接指针占用空间过多的问题。&lt;/p&gt;&lt;h3 data-source-line=&quot;309&quot;&gt;集合对象的编码&lt;/h3&gt;&lt;p data-source-line=&quot;311&quot;&gt;集合对象的编码可以是intset或者hashtable。&lt;/p&gt;&lt;p data-source-line=&quot;313&quot;&gt;当集合中的所有元素都是整数，且元素的数量不大于512个的时候，使用intset编码。&lt;/p&gt;&lt;p data-source-line=&quot;315&quot;&gt;当元素不符合全部为整数值且元素个数小于512时，集合对象使用的编码方式为 hashtable。&lt;/p&gt;&lt;table data-source-line=&quot;317&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码&lt;/th&gt;&lt;th&gt;使用条件&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;intset&lt;/td&gt;&lt;td&gt;所有元素都是整数且元素个数小于 512&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;hashtable&lt;/td&gt;&lt;td&gt;其他数据&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;322&quot;&gt;有序集合对象的编码&lt;/h3&gt;&lt;p data-source-line=&quot;324&quot;&gt;有序集合对象的编码可以是ziplist以及skiplist。&lt;/p&gt;&lt;p data-source-line=&quot;326&quot;&gt;当使用ziplist编码时，有序集合对象的实现数据结构为压缩列表。当条件变化，ziplist编码会转换成skiplist编码。&lt;/p&gt;&lt;p data-source-line=&quot;328&quot;&gt;当使用skiplist编码的时候，内部使用zset 来实现数据的保存，zset的定义如下：&lt;/p&gt;&lt;pre data-source-line=&quot;329&quot;&gt;&lt;code&gt;typedef struct zset{&lt;br/&gt;  zskiplist *zsl&lt;span&gt;;&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;dict &lt;/span&gt;*&lt;span&gt;dict;&lt;br/&gt;&lt;/span&gt;}zset&lt;span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-source-line=&quot;335&quot;&gt;为什么需要同时使用跳跃表以及字典呢？&lt;/p&gt;&lt;p data-source-line=&quot;340&quot;&gt;因此，将字典和跳跃表结合进行使用，可以在O(1)的时间复杂度下完成查询分值操作，而对一些范围操作使用跳跃表可以达到O(logn)的时间复杂度。&lt;/p&gt;&lt;table data-source-line=&quot;342&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码&lt;/th&gt;&lt;th&gt;使用条件&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;ziplist&lt;/td&gt;&lt;td&gt;元素数量少于128且所有元素成员的长度小于64字节&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;skiplist&lt;/td&gt;&lt;td&gt;不满足上述条件的其他情况&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;347&quot;&gt;散列对象&lt;/h3&gt;&lt;p data-source-line=&quot;349&quot;&gt;散列对象的编码可以是ziplist或者hashtable.&lt;/p&gt;&lt;p data-source-line=&quot;351&quot;&gt;ziplist编码下的哈希对象，使用了压缩列表作为底层实现数据结构，用两个连续的压缩列表节点来表示哈希对象中的一个键值对。实现方式类似于上面的有序集合的场景。&lt;/p&gt;&lt;p data-source-line=&quot;353&quot;&gt;哈希结构本身在结构上和字典颇为相似，因此哈希对象中的每一个键值对都是字典中的一个键值对。&lt;/p&gt;&lt;table data-source-line=&quot;357&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码&lt;/th&gt;&lt;th&gt;使用条件&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;ziplist&lt;/td&gt;&lt;td&gt;键值对的键和值的长度都小于64字节，且键值对个数小于512&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;hastable&lt;/td&gt;&lt;td&gt;不满足上述条件的其他情况&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;362&quot;&gt;总结&lt;/h3&gt;&lt;table data-source-line=&quot;364&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;基础数据类型&lt;/th&gt;&lt;th&gt;可能的编码方式&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;字符串&lt;/td&gt;&lt;td&gt;int, raw, embstr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;列表&lt;/td&gt;&lt;td&gt;之前是 ziplist, linkedlist。3.2开始都是quicklist&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;集合&lt;/td&gt;&lt;td&gt;intset, hashtable&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;有序集合&lt;/td&gt;&lt;td&gt;ziplist, skiplist&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;散列&lt;/td&gt;&lt;td&gt;ziplist, hashtable&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p data-source-line=&quot;374&quot;&gt;参考文档：&lt;/p&gt;&lt;ol data-source-line=&quot;376&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;《Redis设计与实现》&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://github.com/redis/redis&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;《Redis 深度历险：核心原理和应用实践》&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c1cb2fcf208d68c00e0268021580dedc</guid>
<title>[推荐] 2.3 万 Star！直追微软 Visio，这个简洁实用的在线绘图工具必须推荐给你</title>
<link>https://toutiao.io/k/msg8jaf</link>
<content:encoded>&lt;div&gt;&lt;div/&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>