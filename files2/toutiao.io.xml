<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>ac069c684d33e315fca9f950f5a0b2a3</guid>
<title>峰值超2亿/秒，Kafka在美团数据平台的逆袭之战</title>
<link>https://toutiao.io/k/jmil15d</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEoNH7fCFmRbH5kV9awLiaU8HZfBfu234CTwgRHqibvrHV2p1vxMHzFpk6Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-1 Kafka概览图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图2-1，这张图是针对读写延迟碰到的问题，以及对应优化方案的一个概览图。我们把整个受影响的因素分为应用层和系统层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;应用层，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;主要表现在系统设计的不合理导致，包括消费者端的单线程模型存在缺陷导致运维指标失真，并且单consumer消费的分区数是不受限制的，当消费的分区数增多的时候可能会引起回溯读，因为消费能力不足就无法跟上实时最新的数据；其次是broker端，broker端主要表现在负载不均衡上，具体表现是磁盘使用率不均衡方面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们针对此做了磁盘均衡，但磁盘均衡需要使用分区迁移，分区迁移又引入了一些新的问题，包括迁移只能按批提交，这存在长尾问题，以及迁移fetcher和实时拉取fetcher存在资源竞争，分区迁移的fetcher会影响实时消费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;系统层，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;主要包括三个方面，一是pagecache的容量不足会导致磁盘读写，磁盘读写的性能显著慢于内存，而且容量不足时还会导致pagecache污染，pagecache污染后，磁盘读和回溯读会影响实时读；另一方面，Kafka目前使用的disk主要是HDD，HDD是比较符合顺序读写的场景。但是对于随机读写的场景，它的性能是不足的；最后由于CPU的资源竞争，在美团这边为了提高资源的利用率，IO密集型的服务（比如Kafka）会和CPU密集型的服务（比如实时作业）混布，混布其实是存在资源竞争的，也会影响读写的延迟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对刚才提到的应用层和系统层存在的各种问题，我们这边分层的去解决。对于应用层提到的每一点问题都会有针对性的解决方案，比如说限流、流水线加速、资源隔离等。针对系统层存在的问题，我们做了cgroup的优化以及物理核的隔离来保证当CPU实时计算的飙升时不会影响读写延迟。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEozEymJN5CwbKhvnGMaYE01yppMDIK07HGmbGwfSOcnXsUvRAjmd2xLA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图&lt;/span&gt;&lt;span&gt;2-2 Kafka应用层磁盘均衡&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面介绍一下读写延迟在应用层遇到到的问题，磁盘热点导致磁盘利用率不均衡，它会带来两个问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对这两个问题我们做了基于空闲磁盘优先这样一个分区迁移计算计划，整个计划分为5个点。如图2-2 所示，首先会有一个组件叫rebalancer，rebalancer通过目标的使用率和Kafka monitor组件不断从Kafka broker集群上报上来的当前磁盘的使用状况这两类指标持续生成具体的分区迁移计划，执行迁移计划并检查进度；然后rebalancer会向zookeeper的reassign节点提交刚才生成的迁移计划，Kafka的controller收到这个reassign事件之后会向整个Kafka broker集群提交reassign事件，然后Kafka broker集群让整体磁盘利用率趋于均衡值这样一个目标执行磁盘迁移计划。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图2-2所示，对于所有的disk，三个分区属于一个相对均衡的状态，那么如果有一个四个分区的disk，就会把其中一个分区迁移到另外两个分区的disk上，最终尽可能地保证整体磁盘利用率是均衡的。但是Kafka的分区迁移只能是按组提交的，在执行分区迁移过程中碰到了许多新的问题，下面会继续介绍这些问题是怎么解决的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分区迁移存在一个迁移效率不足的问题，因为是按组提交的，在上一批没有完成之前，下一批无法开始提交，这样就会导致整体迁移进度受阻，进而对读写请求造成影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对迁移效率问题以及带来的它带来的影响，我们主要做了三点改进：第一点是做流水线加速，流水线加速能够保证长尾分区不影响整体迁移进度；第二点是迁移取消，在原生Kafka版本中，当一个分区迁移被提交后，是无法中断的，只能等他迁移完成，那么如果他在影响一个实时读写请求的时候，如果它迟迟不能完成，可能另一个实时读写的请求一直都会受到影响；第三点是做fetcher隔离，Kafka在做分区迁移的时候会利用follower通过最近读去拉数据同步，当发起最近读的迁移请求和某一个实时写请求共享同一个fetcher的时候，迁移分区的读请求会影响实时分区的读请求，后面会进一步详细描述具体的问题和对应的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2）迁移优化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; ① 流水线加速&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEoZTpACJIdhZxJ8icwItOlyZc9GBDhUcxiafxpWib8QysCaicbibwV3sGZA5g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-3 流水线加速&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对长尾分区问题，我们主要是做了流水线加速，如图2-3所示，箭头以上原生Kafka版本只支持按组提交，比如说一批提交了四个分区，当tp4这个分区一直卡着无法完成的时候，后续所有分区都无法继续进行。采用流水线加速之后，即使tp4这个分区还没有完成，当其它三个分区已经完成的时候，后续就可以继续提交新的分区。可以看出在相同的时间内，原有的方案受阻于tp4没有完成后续所有分区都没办法完成，但是在新的方案中，tp4分区已经迁移到tp11分区了。图中虚线代表了一个无序的时间窗口，主要用于控制并发，目的是为了和原有的按组提交的个数保持一致，避免过多的迁移影响读写请求服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; ② 迁移取消&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEokLWRf0D6KG9794iaddFCTlY99mQnrRvJmJgFh1gsUJVgRqDbruXk6Vg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-4 迁移取消&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图2-4所示，箭头左侧描述了因为迁移影响的三种线上类型。第一种是因为迁移会触发最旧读，同步大量的数据，在这个过程中会首先将数据回刷到pagecache上，那么可能会污染pagecache，进而导致某个实时读的分区发生cache miss，就会导致实时读触发磁盘度进而影响读写请求；第二类和第三类分别描述的是当存在某些异常节点导致迁移hang住的时候，想对topic做某些操作，比如对topic扩容，例如在午高峰时由于流量上涨想对topic扩容，实际上这个时候扩容是无法完成的。因为在Kafka迁移过程中这些操作都被限制住。第三个和第二个有些类似，它的主要问题是当目标节点挂了，这个时候topic扩容也是无法完成的，用户可能一直忍受读写请求受影响，直到迁移完成。针对这种场景，线上无法忍受由于长时间迁移导致读写延迟变高的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对上面提到的各种问题，我们支持了一个功能叫迁移取消。当遇到这类问题时，管理员可以调用迁移取消命令，中断正在迁移的分区，针对第一种场景，pagecache就不会被污染，实时读得以保证；在二、三类场景中，因为迁移取消，扩容得以完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;迁移取消必须要删除那些还没有完成的分区，大量的删除会导致磁盘IO，称为性能瓶颈进而影响读写，因此在这里我们针对迁移取消做了平滑删除，避免因大量删除影响性能问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; ③ fetcher隔离&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEokibPIZ04ngJnzB7TeicUlfXOCSRjglhFwkHL15q2pIkIicSJZDuLBjPjw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-5 fetcher隔离&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图2-5，绿色代表实时读，红色代表延时读。当某一个follower的实时读和延时读共享同一个fetcher时，延时读会影响实时读。因为每一次延时读的数据量是显著大于实时读的，而且延时读容易触发磁盘读，可能数据已经不在pagecache中了，显著的拖慢了fetcher的拉取效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对这种问题我们做的策略叫fetcher隔离。也就是说所有isr的follower共享fetcher，所有非isr的follower共享fetcher，这样就能保证所有isr中的实时读不会被非isr的回溯读所影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3）Consumer异步化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEocTQGickBicp7mo3ziawhnfoKUeMxVkeohw09AVgCgk4t5QjxxpWRZyQXA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-6 Kafka-broker分阶段延时统计模型&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先来了解一下Kafka-broker分阶段延时统计模型，当一个Kafka的producer或consumer请求进入到Kafka-broker时，首先由processor将请求写入RequestQueue里面，然后RequestHandler就会从RequestQueue源源不断地去拉取请求进行处理，在RequestQueue中的等待时间是RequestQueueTime，RequestHandler具体的执行时间为LocalTime，当RequestHandler执行完毕后会将请求扔到DelayedPurgatory组件中，这个实际上就是一个延时队列。这个延时队列当触发某一个延时条件完成了以后会把请求塞到ResponseQueue中，在DelayedPurgatory队列持续的时间为RemoteTime，processor会不断的从ResponseQueue中将数据拉取出来发往客户端，标红的ResponseTime是可能会被客户端影响的，因为如果客户端接收能力不足，那么ResponseTime就会一直持续增加，从Kafka-broker角度，每一次请求总的延迟叫RequestTotalTime包含了刚才所有流程分阶段计时总和。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEokLuLpdO8NcnKf7giacktOlvYcc1DYZnl84eO0UnVvAZctdeqAAlsNiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-7 Consumer异步化&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主要问题是因为Kafka原生consumer基于NIO的单线程模型存在缺陷。如图2-7所示，在phase1，user首先在调用poll请求时，当本地无数据时，同时向broker1、broker2和broker3发送请求，实际上broker1的数据先回来了，Kafka Client立即将数据写入CompleteQueue，这个时候立即返回，不会再拉取broker2和broker3的数据，此时user线程会直接从CompleteQueue中读取数据，然后直接返回。此时broker2和broker3服务端可能已经处理好，数据已经准备就绪。user线程会继续调用poll，访问下一批请求，可是因为CompleteQueue依然存在broker1上次拉取的数据，这时user线程直接返回了，这样就会导致broker2和broker3中已就绪的数据一直得不到拉取。如图中phase2，因为单线程模型存在缺陷导致waitFetch这部分时长变大，导致Kafka-broker延时指标不断升高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEoTRdAx4nekKUOVibsmpARZhGtECZDvIaRDxIrJNDmKtUicvbUuY4IOnoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-8 引入异步拉取线程&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对这个问题我们的改进是引入异步拉取线程。异步拉取线程会及时的拉取就绪的数据，避免服务端延时指标受影响，而且原生Kafka并没有限制同时拉取的分区数，我们在这里做了限速，避免GC和OOM的发生。异步线程在后台持续不断地拉取数据放到CompleteQueue中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;3、系统层&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1）Raid卡加速&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEoe1DJ5D0XCo3weGPw9sDlqdYPFYMweCNiaz8DFdUz15sZatE6HicibraCg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-9 Raid卡加速&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;众所周知，Kafka的写入借助了Zero Copy技术将数据直接写入pagecache，但是随着随机读写并发量的提升，随机写导致的性能不足问题就会显现出来。表现是随机写入的延时会显著升高，针对这个问题我们引入了Raid卡。Raid卡有一个好处是自带缓存，而且Raid卡使用的是Raid-0模式，并没有冗余，与pagecache类似，在这一层会继续做merge，把数据merge成更大的block写入disk。更加充分利用顺序写HDD的带宽，借助Raid卡保证了随机写的性能是比较稳定的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2）cgroup隔离优化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEovake1Scx94aF4Ogk4a0TFf6bPAgATjS5WcSqPlicnho8wYmWxwlnSUA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-10 cgroup隔离&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在介绍cgroup的隔离优化之前需要提到的背景是，为了提高资源利用率，美团数据平台将IO密集型应用和CPU密集型应用混布。IO密集型应用在这里指的就是Kafka，CPU密集型应用在这里指的是Flink和Storm，但是原有的隔离策略存在两个问题：首先是物理核本身会存在资源竞争，在这个物理核下，共享的L1cache和L2cache都存在竞争，当实时平台CPU飙升时会导致Kafka读写延时受到影响；另外，Kafka的HT跨NUMA，增加内存访问耗时，如图2-10所示，跨NUMA节点是通过QPI去做远程访问，而这个远程访问的耗时是40ns。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对这两个问题我们改进了隔离策略，针对物理核的资源竞争，我们新的混布策略Kafka是独占物理核的，也就是说在新的隔离策略中，不存在同一个物理核被Kafka和Flink同时使用；然后是保证Kafka的所有超线程处于同一侧的NUMA，避免Kafka跨NUMA带来的访问延时。通过新的隔离策略，Kafka的读写延时不再受Flink CPU飙升的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;4、混合层-SSD新缓存架构&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEoECyT7g69DxbC87k3T5FOAK5EW93QsjOF0IJt7x3OvPcv30ibz4ooqTA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-11 混合层SSD新缓存架构&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先来了解一下Kafka的数据消费模型，Kafka利用操作系统提供的ZeroCopy技术处理数据读取请求，pagecache容量充裕时数据直接从pagecache拷贝到网卡，有效降低了读取延时。但是实际上往往pagecache的的容量是不足的，因为它不会超过一个机器的内存，容量不足时，ZeroCopy就会触发磁盘读，磁盘读不仅显著变慢，还会污染pagecache影响其他读写。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图2-11中左半部分所示，当一个延迟消费者去拉取数据时，发现pagecache中没有它想要的数据，这个时候就会触发磁盘读，磁盘读后会将数据回写到pagecache，导致pagecache污染，自己读写延迟变慢同时也会导致另一个实时消费受影响，因为对于实时消费而言，它一直读的是最新的数据，最新的数据按正常来说时不应该出发磁盘读的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEolxP0CDMOETnb1KwtN6Ms2ibHDSACxggbMGEWKRiaF4KHCIKtHFBUhY7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-12 SSD新缓存架构方案选型&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对这个问题，我们这边在做方案选型时有两种方案，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;方案一：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;读磁盘时不回写pagecache，比如使用DirectIO，不过Java并不支持；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;方案二：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在内存和HDD之间引入中间层，比如SDD，如图2-12所示，随着读取并发的增加，SSD的性能并不会显著降低，非常适合我们的使用场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEoWx9tw98Q2gHudfPNicUiaObYBFuFYu0lt0EKrLszbwkKtEadjq81eooA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-13 SSD新缓存架构决策&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;针对SSD的方案也有两种选型:&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;方案一：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;可以基于操作系统的内核实现，这种方案SSD与HDD存储空间按照固定大小分块，并且SSD与HDD建立映射关系，同时会基于数据局部性原理，cache miss后数据会按LRU和LFU替换SSD中部分数据，业界典型方案包括OpenCAS和FlashCache。优势是数据路由对应用层透明，对应用代码改动量小，并且社区活跃可用性好；但是问题是局部性原理并不满足Kafka的读写特性，而且缓存空间污染问题并未得到根本解决，因为它会根据LRU和LFU去替换SSD中的部分数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;方案二：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;是基于Kafka的应用层去实现，具体就是Kafka的数据按照时间维度存储在不同设备上，对于近实时数据直接放在SSD上，针对较为久远的数据直接放在HDD上，然后leader直接根据offset从对应设备读取数据。这种方案的优势是他的缓存策略充分考虑了Kafka的读写特性，确保近实时的数据消费请求全部落在SSD上，保证这部分请求处理的低延迟，同时从HDD读取的数据不回刷到SSD防止缓存污染，同时由于每个日志段都有唯一明确的状态，因此每次请求目的明确，不存在因cache miss带来的额外性能开销。同时劣势也很明显，需要在server端代码上进行改进，涉及的开发以及测试工作量较多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEo88WQnicyNqAOzaa8RYR150l2FbGhk090CxTmVyuMtJfRwEUxmiaKTA1Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-14 SSD新缓存架构具体实现&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面来介绍一下SSD新缓存架构的&lt;/span&gt;&lt;strong&gt;&lt;span&gt;具体实现。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首先新的缓存架构会将log内的多个segment按时间维度存储在不同的存储设备上，如图2-14中的红圈1，新缓存架构数据会有三种典型状态，一种叫only cache，指的是数据刚写进SSD，还未同步到HDD上；第2个是cached，指数据既同步到了HDD也有一部分缓存在SSD上；第三种类型叫withoutCache，指的是同步到了HDD但是SSD中已经没有缓存了；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;然后后台异步线程持续地将SSD数据同步到HDD上；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;随着SSD的持续写入，当存储空间达到阈值后，会按时间顺序删除距当前时间最久的数据，因为SSD他的数据空间也是有限的；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;副本可根据可用性要求灵活开启是否写入SSD；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;从HDD读取的数据是不会回刷到SSD上的，防止缓存污染。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEoWBiccuiczCCo12DojMheicyWkkGMPjFs5rQWCcBehJ3nZ437OpicKB2aLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图2-15 SSD新缓存架构细节优化&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍了具体实现之后，再来看一下&lt;/span&gt;&lt;strong&gt;&lt;span&gt;细节优化。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先是关于日志段同步，就是刚才说到的segment，只同步Inactive的日志段，Inactive指的是现在并没有在写的日志段，低成本解决数据一致性问题；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次是做同步限速优化，在SSD向HDD同步时是需要限速的，同时保护了两种设备，不会影响其他IO请求的处理，向SSD写入数据也是需要限速的，因为SSD的使用寿命是有限的。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;三、大规模集群管理优化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;了解了读写延迟优化之后，下面来看一下Kafka在美团数据平台是如何保证大规模集群的稳定性的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1、隔离优化&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEons2Ew6GoHKicMlUfS5YvYlpLSPUx7E51ib2NXfUJC9mQqMxvB50KgibIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图3-1 隔离优化&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于Kafka服务于多个业务，这些业务的topic混布在一起的话很有可能造成不同业务的不同topic之间相互影响。例如broker如果和controller混布在一起，当broker负载明显变高的时候，会导致controller无法及时处理请求，从而可能会造成整个集群发生故障，因为元数据的变更请求无法发送出去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对这些相互影响的问题，我们从业务、角色和优先级三个维度来做隔离优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第一点是业务隔离，如图3-1所示，每一个大的业务会有一个独立的kafka集群，比如外卖、团购、优选；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第二点是分角色隔离，这里Kafka的broker和controller以及他们依赖的组件zookeeper是部署在不同机器上的，避免之间相互影响；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第三点是可以分优先级，有的业务可能它的topic可用性等级特别高，那么我们就可以给他划分为VIP集群，给他更多的资源冗余去保证可用性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2、全链路监控&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEoOT69icM3qvSmTI21aDXgPIib7icYZbAkhnUNMcmthZ7IWJPiaxEwfd7CoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图3-2 全链路优化&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着集群规模的增大分区数变多，读写的客户端也会变多，Kafka当前提供的broker端粒度的延时指标在很多情况下无法真实反映某些客户端是否慢，还有一类问题是当集群发生故障时，如何能及时得到感知和处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对这两个问题，我们做了全链路监控这样一个项目。把Kafka核心组件以及指标全部收集起来做了一个全链路的追踪，通过分析上报上来的日志和指标，我们就可以建立细粒度的日志大盘。当某一个读写请求变慢时，我们通过日志大盘很容易就知道他具体是慢在哪个环节。日志和指标的解析服务可以自动实时感知故障还有一些慢节点，这两类故障有一部分我们可以做到自动处理，我们会把他通过事件的方式通知到Kafka manager，然后Kafka manager会根据这个事件自动去处理这些故障。还有一类故障是无法得到自动处理的，比如说僵尸节点，僵尸节点指的是zookeeper的临时节点还没有掉线，但是这个节点不管是controller也好还是客户端也好，都已经无法访问了，访问就会报错或者超时，这一类故障需要人工介入处理，会直接发给具体的管理员。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;3、服务生命周期管理&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEoY2ibzmR8TAkEAUVvosGIDqBoGFpAfb2W5icANBD7Mic4BAUIU02p53OFQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图3-3 服务生命周期管理&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先介绍一下当集群规模增大以后存在的一系列问题。之前版本的Kafka也有一套自动化运维的系统，但是它存在一些问题，首先是状态语义存在歧义，无法真实反映系统状态，往往需要借助日志和指标去找到真实系统是否健康或者异常；然后是状态不全面，异常case需人工介入处理，误操作风险极大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于这两点问题，我们引入了生命周期管理机制，保证状态能真实反映系统状态。生命周期管理指的是从服务开始运行到机器报废停止服务的全流程管理。并且做到了服务状态和机器状态联动，无需人工同步变更。而且新的生命周期管理机制的状态变更由特定的自动化运维触发，禁止人工变更。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;4、TOR容灾&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEoWlAG9ibfzEzk8C1kBQB6XpzZWb8PJOficm0uY6TbckiavI9HwC06FHdSQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图3-4 TOR容灾-挑战&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后一个集群管理优化是TOR容灾。随着集群规模的变大，Rack级别的故障变得平凡起来，而我们是无法容忍Rack级别的故障的，因为Rack级别的故障可能会导致分区不可用，原因是分区的多副本在同一个rack下，特别是在流存储环境下，当某些分区不可用时，它会导致收集侧的拥堵，影响其他topic的收集上报。并且当实时作业的某个分区出现异常时，它会影响整个链路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图3-4所示，当rack1发生故障时，TopicPartition1是完全不可用的，因为他的两个副本都在rack1上，TopicPartition2也是不可用的，虽然他有三个副本，但是他的两个副本都已经不可用了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;319&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8aEibu8LhlWJdmubIx7icuEEoe3Uo4FPdBwcvt1WA5nOZZhlQRiaN1jUMoNsu6LvC1uoYWmpD7UVpdZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图3-5 TOR容灾-改进&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对Rack级别的故障，我们做了TOR容灾。改进了副本的分配算法，保证同一个分区的不同副本不在同一个rack下，如图3-5所示，即使rack1整个发生故障，也能保证所有分区是可用的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;四、未来展望&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;最后介绍一下美团数据平台的Kafka未来可以做哪些优化：首先我们会继续去做Kafka的高可用建设，比如说客户端主动去做一些故障节点的避让，服务端通过多队列的方式去隔离一些异常请求，避免它们之间相互影响。另外，高可靠方面会去做quorum write多数派写优化，因为Kafka的ack等于1时是需要写入所有副本的。我们还会去做流批一体的存储架构，比如Kafka on HDFS。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;39&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section&gt;&lt;span&gt;作者丨赵海源&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;来源丨公众号：DataFunTalk（ID：datafuntalk）&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;dbaplus社群欢迎广大技术人员投稿，投稿邮箱：&lt;/span&gt;&lt;span&gt;editor@dbaplus.cn&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8f5de8bfc2abbb79541d46aac3698e1b</guid>
<title>开源｜腾讯出品的，基于云原生技术的成本优化项目</title>
<link>https://toutiao.io/k/eu428cf</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
            &lt;p&gt;&lt;span&gt;&lt;strong&gt;以下内容选自「码农周刊 VIP 会员」圈子，每日更新，精彩不断。&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;扫描下方二维码&lt;/span&gt;，即刻加入！&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;腾讯开源的，基于云原生技术的成本优化项目 &lt;span&gt;Crane&lt;/span&gt;。&lt;span&gt;Crane&lt;/span&gt; 遵循 FinOps 标准，旨在为云原生用户提供云成本优化一站式解决方案。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Crane 是腾讯内部云资源优化流程方法和工具的系统性输出，同时，Crane 核心能力的构建与规划均与 FinOps 基金会提出的能力模型完全契合。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Crane 致力于推荐资源和智能弹性配置，业务人员无需再为业务需要多少资源，自动扩缩容应该如何配置等问题而烦恼，Crane 会基于业务的时序变动数据给出最优解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;1171&quot; data-ratio=&quot;1.88&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AjN1jquNav9PmIJ4tODmFGkQTPUiafKWSUJKnttpVvSnPE2SvRLUllJlD4YVDQ9y7m1NxJBkbBEk0O4fCMRjgmg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot;/&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d546ff28513d27189b2f3a36143ac1ac</guid>
<title>Go 微服务工具包 Go kit 怎么集成 gRPC？</title>
<link>https://toutiao.io/k/zczfvlt</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;大家好，我是 frank。&lt;br/&gt;欢迎大家点击标题下方&lt;span&gt;蓝色&lt;/span&gt;文字「Golang 语言开发栈」关注公众号。&lt;br/&gt;&lt;strong&gt;设为星标&lt;/strong&gt;，第一时间接收推送文章。&lt;br/&gt;&lt;strong&gt;文末扫码&lt;/strong&gt;，加群一起学 Golang 语言。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;01 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;介绍&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们在上一篇文章「&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA4Mjc1NTMyOQ==&amp;amp;mid=2247485994&amp;amp;idx=1&amp;amp;sn=a17963c2958100053416ac3800b4b85a&amp;amp;chksm=9f81a044a8f62952d51a60b378ce785a313791ae4962a1cd9a1c19c1ba46f8f24a70fd9d4996&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Go 语言基于 Go kit 开发 Web 项目&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;Go 语言基于 Go kit 开发 Web 项目&lt;/strong&gt;&lt;/a&gt;」中，介绍了怎么使用 Go kit 开发 Web 项目，在这篇文章中，我们传输层使用的是 HTTP，本文我们介绍 Go kit 怎么集成 gRPC，也就是说我们在传输层使用 rpc。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在阅读完前面几篇文章后，我们已经了解 Go kit 分为三层，分别是 Transport、Endpoint 和 Service，其中 Transport 负责网络传输，Endpoint 负责接收请求和返回响应，Service 层负责定义业务接口，并实现接口方法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go kit 集成 gRPC，主要在 Transport 层实现。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;02 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;实现原理&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go kit 集成 gRPC，即将 gRPC 集成到 Go kit 的 Transport 层。Transport 层将接收到的网络请求转换为 Endpoint 层可以处理的对象，主要需要实现两个功能，解码和编码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中，解码负责把网络请求转换为 Endpoint 可以处理的请求对象；编码负责将 Endpoint 处理结果转换为响应对象，返回给客户端。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;03 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go kit 集成 gRPC 的示例项目&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在了解完实现原理之后，我们通过示例项目介绍 Go kit 怎么集成 gRPC，关于定义 proto 文件，和使用 protoc 生成 pb 文件，我们在之前的文章中已经介绍过，限于篇幅，本文不再赘述。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用 Go kit 集成 gRPC，实际上就是在 Transport 层使用 gRPC 传输，除此之外，它和我们上一节讲的使用 Go kit 开发 Web 项目的流程是一样的，共分为五个步骤实现该示例项目，分别是定义 proto 并生成 pb 文件、创建 service 层、创建 endpoint 层、创建 transport 层和定义主函数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;定义 proto&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;...&lt;br/&gt;option go_package = &quot;./user&quot;;&lt;br/&gt;&lt;br/&gt;service UserService {&lt;br/&gt;  rpc Register(RegisterReq) returns (RegisterRes) {}&lt;br/&gt;}&lt;br/&gt;...&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;生成 pb 文件&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;protoc -I proto \&lt;br/&gt;&amp;gt; --go_out ./pb/user --go_opt paths=source_relative \&lt;br/&gt;&amp;gt; --go-grpc_out=require_unimplemented_servers=&lt;span&gt;false&lt;/span&gt;:./pb/user --go-grpc_opt paths=source_relative \&lt;br/&gt;&amp;gt; proto/user.proto&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阅读上面这段代码，我们定义一个 proto 文件，并使用 protoc 工具生成 pb 文件，需要注意的是我们将 &lt;code&gt;require_unimplemented_servers&lt;/code&gt; 设置为 &lt;code&gt;false&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;原因如下：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;By default, to register services using the methods generated by this tool, the service implementations must embed the corresponding Unimplemented&lt;servicename&gt;Server for future compatibility. This is a behavior change from the grpc code generator previously included with protoc-gen-go. To restore this behavior, set the option require_unimplemented_servers=false.&lt;/servicename&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;Service&lt;/strong&gt; - 定义接口&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; IUser &lt;span&gt;interface&lt;/span&gt; {&lt;br/&gt; Register(ctx context.Context, username, email, password &lt;span&gt;string&lt;/span&gt;) error&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;type&lt;/span&gt; User &lt;span&gt;struct&lt;/span&gt;{}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(u User)&lt;/span&gt; &lt;span&gt;Register&lt;/span&gt;&lt;span&gt;(ctx context.Context, username, email, password &lt;span&gt;string&lt;/span&gt;)&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; username != &lt;span&gt;&quot;&quot;&lt;/span&gt; &amp;amp;&amp;amp; email != &lt;span&gt;&quot;&quot;&lt;/span&gt; &amp;amp;&amp;amp; password != &lt;span&gt;&quot;&quot;&lt;/span&gt; {&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt; }&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; errors.New(&lt;span&gt;&quot;register param is invalid&quot;&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阅读上面这段代码，我们在 Service 层创建 IUser 接口，接口包含一个方法 Register，需要注意的是，Register 方法会通过调用 &lt;code&gt;grpc.Handler&lt;/code&gt; 的 ServeGRPC 方法，将请求参数传递给 Go kit 处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;Endpoint&lt;/strong&gt; - 接收请求和返回响应&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;MakeUserEndpoint&lt;/span&gt;&lt;span&gt;(user IUser)&lt;/span&gt; &lt;span&gt;endpoint&lt;/span&gt;.&lt;span&gt;Endpoint&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;(ctx context.Context, request &lt;span&gt;interface&lt;/span&gt;{})&lt;/span&gt; &lt;span&gt;(response &lt;span&gt;interface&lt;/span&gt;{}, err error)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;  req := request.(RegisterReq)&lt;br/&gt;  err = user.Register(ctx, req.Username, req.Email, req.Password)&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;   log.Printf(&lt;span&gt;&quot;err:%s&quot;&lt;/span&gt;, err)&lt;br/&gt;  }&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; RegisterRes{&lt;br/&gt;   Username: req.Username,&lt;br/&gt;   Email:    req.Email,&lt;br/&gt;  }, &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阅读上面这段代码，在 Endpoint 层，我们给业务接口 IUser 构建 &lt;code&gt;endpoint.Endpoint&lt;/code&gt;，用于调用 Service 层的接口的方法处理请求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;Transport&lt;/strong&gt; - 传输层&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; grpcHandler &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt; register grpc.Handler&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(g *grpcHandler)&lt;/span&gt; &lt;span&gt;Register&lt;/span&gt;&lt;span&gt;(ctx context.Context, req *pb.RegisterReq)&lt;/span&gt; &lt;span&gt;(*pb.RegisterRes, error)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; _, res, err := g.register.ServeGRPC(ctx, req)&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;, err&lt;br/&gt; }&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; res.(*pb.RegisterRes), &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;NewUserServer&lt;/span&gt;&lt;span&gt;(ctx context.Context, endpoints Endpoints)&lt;/span&gt; &lt;span&gt;pb&lt;/span&gt;.&lt;span&gt;UserServiceServer&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; &amp;amp;grpcHandler{&lt;br/&gt;  register: grpc.NewServer(&lt;br/&gt;   endpoints.UserEndpoint,&lt;br/&gt;   DecodeRegister,&lt;br/&gt;   EncodeRegister,&lt;br/&gt;  ),&lt;br/&gt; }&lt;br/&gt;}  &lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阅读上面这段代码，我们在 Transport 层实现 pb 文件中的 UserServiceServer 方法，需要注意的是，我们在 NewUserService 函数中，传入 Endpoint。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;blockquote&gt;&lt;blockquote&gt;&lt;p&gt;完整代码，请参阅 Github。&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;04 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总结&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文我们通过示例项目介绍 Go kit 怎么集成 gRPC，通过集成 gRPC，Transport 层实现通过 rpc 进行网络传输。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;推荐阅读：&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA4Mjc1NTMyOQ==&amp;amp;mid=2247485871&amp;amp;idx=1&amp;amp;sn=5e9eac1cce46b90fdab7be5ea14be9ef&amp;amp;chksm=9f81a3c1a8f62ad7f00ae7659154d87c2790097944d8606cf440aa5cd58e29c9b13cedad2099&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Golang 语言 vendor 在 GOPATH 和 Modules 中的区别&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Golang 语言 vendor 在 GOPATH 和 Modules 中的区别&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA4Mjc1NTMyOQ==&amp;amp;mid=2247485896&amp;amp;idx=1&amp;amp;sn=7f13caa0a4a0efc9aa52f91449f1eee7&amp;amp;chksm=9f81a3a6a8f62ab0e4476eab641b65fc0376f817c7393dabdefeb239fcf8fb879bec353df558&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Golang 语言的多种变量声明方式和使用场景&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Golang 语言的多种变量声明方式和使用场景&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA4Mjc1NTMyOQ==&amp;amp;mid=2247485863&amp;amp;idx=1&amp;amp;sn=6e119515e734fddacc87713bb3b26ce8&amp;amp;chksm=9f81a3c9a8f62adf7d4b6e2b91538919799dd0b27ff0064780db052a1e5636f2a46a6f51a446&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Golang 语言微服务的服务发现组件 Consul 的系统架构介绍&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Golang 语言微服务的服务发现组件 Consul 的系统架构介绍&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA4Mjc1NTMyOQ==&amp;amp;mid=2247484749&amp;amp;idx=1&amp;amp;sn=6e5455fb53756f08c32940e476138753&amp;amp;chksm=9f81af23a8f626351263aaa520929fda1afd086bd7d708d2c6f7248880b0c764fd8ca3339caa&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Golang 语言中基础同步原语 Mutex 和 RWMutex 的区别&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Golang 语言中基础同步原语 Mutex 和 RWMutex 的区别&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA4Mjc1NTMyOQ==&amp;amp;mid=2247483808&amp;amp;idx=1&amp;amp;sn=3e71c90a6e8400e886144fe187c59077&amp;amp;chksm=9f81abcea8f622d84ba865bf5b7a738de092423b52dd3c8a539f964c15a4832add82b5b4249e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Go 语言学习之测试&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Go 语言学习之测试&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;参考资料：&lt;/strong&gt;&lt;br/&gt;https://github.com/grpc/grpc-go/blob/master/cmd/protoc-gen-go-grpc/README.md &lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>fce21cde7216398b1ab5e5933bb0d34f</guid>
<title>什么是跨级管理与跨级上报</title>
<link>https://toutiao.io/k/zzgnacw</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;原创不易，求分享、求一键三连&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hi，各位亲爱的小伙伴，小钗公号遵循日复盘-&amp;gt;周复盘-&amp;gt;月复盘-&amp;gt;季度复盘-&amp;gt;年总结策略，所以某类型文章到后期才会成体系。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4537037037037037&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTDVLKVBcphDxNyvHPMjr0cPBbSlPPchL1gRJNt6uiaAYloQicdhjJuqjnvOh6nRF6KFl5mib4k10SLQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天这篇文章属于&lt;strong&gt;「周复盘」&lt;/strong&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;两种跨级&lt;/span&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;跨级管理&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前两天&lt;strong&gt;「知识星球」&lt;/strong&gt;有个同学很生气，因为他的Leader总是喜欢跨级管理：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;Leader 35+，空降一年管理30人；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;小A 28，管理10人；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最近Leader有些行为逐渐让小A感到烦躁：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;Leader经常跟一线沟通技术细节；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Leader在横向业务的前置沟通中，会完全饶过小A找一线干活；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上案例都是在日常工作中发生，并不是项目特殊时期，这种跨级管理让小A感到很无奈。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作为一个一线Leader，你遇到这种&lt;strong&gt;「跨级管理」&lt;/strong&gt;该怎么办呢？&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;跨级上报&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;小B是一线Leader，因为一些渊源与部门负责人建立了联系，于是小B就像找到了上升通道一样，不断的与负责人沟通，内容包括但不限于：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;项目问题求助；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;团队问题暴露；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;开始小B的Leader还不以为意，但渐渐的他觉得不对了：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;每次小B出现问题，负责人总会比自己先知道；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;而实际协助小B解决问题的依旧是自己；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;小B渐渐不把自己当一回事了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;负责人偶尔会抱怨，为什么小B总是跨级上报，但因为要维护自己亲民的人设，也没有直接拒绝小B；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;于是小B的行为引发了三个人的烦恼。而问题还没结束，聪明的一线Leader小C发现小B的套路后，也开始了和负责人的工作交流...&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;于是一条&lt;strong&gt;「终南捷径」&lt;/strong&gt;似乎打开聊天工具就能发生，ROI极高！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作为中层干部，你发现下面Leader&lt;strong&gt;「跨级上报」&lt;/strong&gt;，又该怎么办呢？&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;跨级管理的本质&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先关注第一个问题，为什么会发生跨级管理，跨级管理的本质是什么？&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;正常情况下，跨级管理的本质是&lt;strong&gt;「梯队有问题」&lt;/strong&gt;，需要团队Leader向下进行补位&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如以下场景：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;下面同学项目要崩了，团队Leader直接下场指挥作战，打赢这场战役；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一线Leader出现了严重问题（不称职或要离职），团队Leader手上一时没有PlanB人选，只能自己上；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;团队Leader从战略层判断，下面某个团队接下来会上升为公司级核心，一线Leader一定搞不定，于是直接自己带队；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上情况都有一个特性：原来的Leader搞不定，需要进行补位。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有了这个认知，我们回到小A的问题，显然小A并不存在需要帮助的情况，那么他的Leader不停的跨级管理是为什么呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;回答可以是：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;小A Leader管理风格就是如此；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但管理风格就是如此显然是个&lt;strong&gt;「回避性的回答」&lt;/strong&gt;，类似的回答可以解释问题但并没有什么卵用，所以这里还需要深入挖掘，我们可以拿到以下客观条件：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;小A的Leader35+；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;管理30人；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;核心参与一线工作；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;正常情况下30人团队只需要一个Leader即可，由此我们可以做一个假设：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;小A Leader认为团队只需要一个Leader；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;小A Leader对自己的定位是一线Leader；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;小A Leader认为小A是组长或者一线员工；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而且从结构来说，小A的下属直接与其Leader对话肯定收益更高，所以小A可能是当前结构中唯一不满的人...&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但这也说明了跨级管理的另一个本质：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;特殊情况下，跨级管理是一种&lt;strong&gt;「降维使用」&lt;/strong&gt;，属于防守型战略&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种Case也很多：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;公司业务爆炸，规模由100人变成了10000人，我从管10人变成了管500人，从一线Leader变成了VP；但今年效益很差，预计公司规模要缩水80%，于是我回归一线Leader，提前布局开始跨量级管理；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;我今年已经35了，自觉能力有限、上升无望，为了今后职业生涯更好的适配性，准备一直干一线Leader的工作；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;因为一线Leader最接近业务，秀操作场景会很多，属于&lt;strong&gt;「低强度脑力、中强度体力」&lt;/strong&gt;工作者，待遇不差还很安全，只要守分，会是一个ROI很高的职位&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上，这也是跨级管理为什么很容易发生：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;梯队经常出问题；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;大Leader憋不住想装逼秀操作的心；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;有预期的&lt;strong&gt;「降维使用」&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;跨级上报的本质&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前我们聊过向上管理的本质：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;向上管理是获取（leader可提供）资源的手段；&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45740740740740743&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTDVLKVBcphDxNyvHPMjr0cPSjAgZZWpicbZsWibop5AfEJSiauElw7uZ9apEmHRW5fiayegAKdH0iathrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6287037037037037&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTDVLKVBcphDxNyvHPMjr0cPkLTMY8TvWda2LyQJabGlTMiawSjG7KxqV1Qm7Mt8gdysEysibtzwYCkA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你在团队中的势能，决定了你能获取的资源，其中leader的期待（看法），很大部分决定了你势能的多少。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以向上管理本质是你提升自身势能的一种手段。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;而跨级上报是管理Leader的Leader，是一种高阶的向上管理，收益会很高，当然风险会很大...&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;小B的行为自然是一种不好的示范，属于&lt;strong&gt;「能力不行强行借势」&lt;/strong&gt;，不然也不用每次其Leader帮他擦屁股了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而这里部门负责人显然有点&lt;strong&gt;「犯贱」&lt;/strong&gt;，为了维护自己的人设，直接把团队上升通道搞出问题了。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如果真有终南捷径，那大家也不用一路打怪升级了&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;核心问题还是团队资源有限，如果负责人选择帮助小B，那么小C和小D就会排队，最终负责人会因为自己的精力而引起公平问题。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;不患寡患不均，不可不慎&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再次看向此图：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8888888888888888&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTDVLKVBcphDxNyvHPMjr0cPuXkVD4gTxwaPcCibrUubhjsP9hbUAqsQt0tKhNkibMRvGI07LD4rtgQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不同的层级有他应得的资源，偶尔的向上管理是可以的，极少的跨级上报也可以原谅，但如果向上管理变成日常，那要你何用？&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;谁是你的老板&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;职位到一定阶段，实际的汇报关系会很复杂：虚线、实线、项目线、委员会...&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相信我，同时存在多个Leader的情况不在少数，这里需要思考一个问题：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;谁是你真正的老板，这里有个逻辑是：&lt;/p&gt;&lt;p&gt;谁对你负责，你就需要对谁负责；&lt;/p&gt;&lt;p&gt;你对谁负责，他就需要对你负责。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;思考以下问题：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;你汇报关系上的Leader是你的老板吗；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;帮你解决问题的是你的老板吗；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;给你升职加薪的是你的老板吗；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;你的老板和你的Leader发生冲突怎么办；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;你是你下属的Leader还是老板；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;怎么看待你的下属跨级上报；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;怎么看待你这次的跨级管理；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;你的老板是你Leader的Leader，那你该如何汇报；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;找准自己的老板，&lt;strong&gt;「找到自己真正的老板」&lt;/strong&gt;，这个话题其实很大，但是又有些敏感，一些信息还不好直接透露，如果大家感兴趣就留言，后续我们再做讨论。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;想要更多交流可以加我微信：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.2982954545454546&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/JdfjlwvwuTDVLKVBcphDxNyvHPMjr0cPKPibcsPQIPWE7N4oxlcXcO0nfs3YL19jRnrdmPxGDdGjibaOGibFK9uwQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1056&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;
          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>0d9cf2f5921049fa4d592ef5280b0034</guid>
<title>Flink 在米哈游的落地实践</title>
<link>https://toutiao.io/k/4yemxzp</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
            &lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;▼ 关注「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Apache Flink&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，获取更多技术干货 &lt;span&gt;▼&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU3Mzg4OTMyNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6FJHxaI14AsXuzeg4SybT0hiaCSohrIY75oiaOMzhQU7RouiafjNa76k2CtD6xxB2JqnawqFqV3zg3A/0?wx_fmt=png&quot; data-nickname=&quot;Apache Flink&quot; data-alias=&quot;apacheflinkcc&quot; data-signature=&quot;Flink 中文社区官微，Flink PMC 维护&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;本文作者米哈游大数据部实时计算负责人张剑，分享 Flink 在米哈游的应用及实践。本篇内容主要分为四个部分：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;背景介绍&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;实时平台建设&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;实时数仓和数据湖探索&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;未来发展与展望&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;Tips：&lt;/strong&gt;点击&lt;strong&gt;「阅读原&lt;/strong&gt;&lt;strong&gt;文」&lt;/strong&gt;查看更多技术内容～&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;一、背景介绍&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;米哈游成立于 2011 年，致力于为用户提供美好的、超出预期的产品与内容。公司陆续推出了多款高品质人气产品，包括《崩坏学园2》、《崩坏3》、《未定事件簿》、《原神》，动态桌面软件《人工桌面》以及社区产品《米游社》，并围绕原创 IP 打造了动画、漫画、音乐、小说及周边等多元产品。总部位于中国上海，并在新加坡、美国、加拿大、日本、韩国等国家和地区进行全球化布局。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Flink 在米哈游大数据发展过程中，一直扮演着重要角色。自实时计算平台建立以来，Flink 作为实时计算引擎，经历了多个发展阶段，实时计算平台也在不断地迭代完善。在米哈游内部，实时计算平台被称作 Mlink，主要以 Flink 为主，兼容 Spark Streaming 任务。从起初的 Flink Jar 包任务为主，发展到以 Flink Sql 为主，不断的降低了使用门槛和提高了任务的开发效率；从起初基础的 Flink 任务开发，发展到跨区域、跨云厂商的任务多版本管理，满足了业务发展的需求。在发展的过程中，米哈游不断地关注着社区的发展，并同社区和阿里云同学保持密切的联系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Mlink 主要是基于 Yarn 资源管理的计算平台，支持了数仓、算法、推荐、风控、大屏等业务。任务数 1000+，Sql 任务占比 80% 左右。使用的 Yarn Vcores 超 5000 核，内存 10T 左右，其中单个任务峰值吞吐在 500 万 QPS，每天吞吐的数据规模超千亿。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n13&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;二、实时平台建设&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n13&quot; mdtype=&quot;heading&quot;&gt;&lt;span/&gt;&lt;br/&gt;&lt;/h2&gt;&lt;h3 cid=&quot;n14&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;2.1 遇到的问题&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Flink 探索发展的过程中，都会遇到 Flink 使用的一些痛点，大家遇到的，同样在我们探索和实践的过程中也有所感触。总结起来，大概是以下五个方面：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;一是 Jar 任务的开发成本高，对于不熟悉 Flink 代码的同学来说使用成本过高。同时，Jar 任务维护成本高，一些代码逻辑的改动会涉及到重新打包、上传，上线等动作；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;二是任务管理功能缺失，其中多租户、历史版本回溯、开发版本和线上版本管理、UDF 管理、血缘管理是实时平台管理的重要内容；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;三是 Flink 引擎本身管理，主要涉及到多 Flink 版本管理，任务参数配置、常用 Connector 的二次开发、多资源环境管理等问题；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;四是任务的告警监控管理，任务问题诊断；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;五是同离线数仓互通，包括 Hive Catalog 管理，实时和离线调度依赖管理等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上面的五个问题，可能是普遍的问题，所以各家公司都会基于内部自建或者开源项目二次开发，来满足自身任务开发管理需求。对于米哈游，除了上述五个问题，还存在跨区域、跨云厂商中遇到的问题需要解决，主要是跨区域之后，任务上线和提交效率，跨云厂商，资源环境不一致等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n78&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;2.2 解决方案&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;实时平台建设主要围绕如上问题。目前实时平台架构如下：&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n19&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4943934760448522&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6PJZcAOyYribaEdLcNGkdH49PfgmOcpxhP0GAFRFWw1I4bibBVhZQdMYy2Gqjzw9Cef6ptfxf4paOg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1962&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图 1：多云多环境实时平台架构&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;前端控制云环境的切换。Backend Service 主要负责用户权限管理、任务的多版本管理、血缘管理，任务运维，任务上下线，任务监控和告警等工作。Executor Service 主要负责任务解析、任务提交运行、任务下线和同各类资源管理器交互等工作。其中，Backend Service 到 Executor Service 通过 Thrift 协议通信，Executor Service 的实现可以多语言扩展。架构设计主要解决跨地区跨云厂商问题，实现任务管理和任务运行之间解耦。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n22&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.48359375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6PJZcAOyYribaEdLcNGkdH4zRGtkCSMz6fz9DhtaFYQib4w1lheTZoTVoew8LoGG8nG0n7UV8tJKWA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图 2：Mlink 平台开发页面&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n24&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.525&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6PJZcAOyYribaEdLcNGkdH4iaJibSxckUGiaYXt6sBuWicibg8qUfWmox7DApHwMSyulPrNdVr5su5gu0A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图 3：Mlink平台运维页面&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n26&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.21640625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6PJZcAOyYribaEdLcNGkdH4v8KKVu061VmXy7R4qPoMskTnFtKUk952OpUqicTgaEaYfcRRAsc896w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图 4：Mlink 平台同步任务页面&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Mlink 实时计算平台主要设计了概览、开发、资源管理、运维、数据探查、同步任务、用户管理和执行器管理等模块。其中开发页面主要是用户编写任务和参数配置，包含历史版本管理等内容。资源管理主要是 Jar 包任务和 UDF 管理。运维主要是任务启停、任务运行监控、任务告警配置等。数据探查部分主要是预览部分数据功能，比如 Kafka Topic 支持按分区、按时间或者 Offset 预览数据。同步任务主要是为了方便管理同步任务，比如 CDC 到 Iceberg 一键同步和运行管理。执行器负责 Executor 的运维工作，包括 Executor 上下线，健康状态监控等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n112&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;2.3 遇到的挑战&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;平台建设和迭代过程中，我们遇到了不少的挑战，也产生了一些比较好的实践。&lt;/span&gt;&lt;span&gt;主要分享四个方面。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;■ &lt;/span&gt;第一是 Executor Service 开发和维护方面&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Executor 主要涉及到 Jar 和 Sql 任务解析提交部分。一开始的方案为了解决跨地区传输效率问题，特别是大的 jar 包传输，由后端进行任务解析，最后传输 job graph 到 Executor，Executor 再通过资源管理器 Api 提交，这个因为后端解析环境不一致问题，部分任务解析过程中会存在 action 动作，特别是涉及到 Hive 表和 Iceberg 表部分。最后采用后端不执行，改由 Executor 解析的方案。Executor 在解析过程中，遇到了 Executor 在运行很长一段时间后，会出现元空间 OOM 的情况。这个主要是因为 Executor 不断的加载任务需要 Class 类，会导致使用的元空间内存不断增加。这个主要是通过任务解析完成之后，卸载类加载器和堆 GC 设置来解决。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 第二是监控方面&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;监控采用的是 Influxdb 加 Grafana 的方案。随着任务量的不断增加，Influxdb 存储的 Series 超过百万，影响监控查看的稳定性，查询响应缓慢。一是扩展 Influxdb，执行端通过一致性 hash 的方案，分配任务 Metric 上报到不同 Influxdb。本身通过对 Flink 任务上报 Metric 进行一定程度的精简。其次在监控上，比如 Kafka 消费监控，目前是支持消费条数的延迟监控，自定义了 Kafka 消费延迟时间的监控，主要是采集了 Kafka 最慢并行度消费的时间，能够反映 Kafka 消费的最大延迟时间，能够反映某个时间点的数据一定被消费了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n35&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.68059181897302&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6PJZcAOyYribaEdLcNGkdH4DlzXGHUX10FLROFHorsnrpBB4GpwkibqMKViaPQcbj067ZnnicYJgHsmA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1149&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图 5：Grafana 监控示例&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 第三是 Connector 二次开发方面&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在 CDC 1.0 版本基础上迭代，支持 Mysql 采集的时候动态扩展字段和基于时间启动消费位点、采集的库表、位点等 Schema 信息。在 CDC 2.0 版本基础上，增加了全量读取库表流控和不需要 MySQL 开启 Binlog 的全量初始化功能。其中多 CDC 实例同步可能会对上游 Mysql 造成压力，采用了 Kafka 作为数据中转，根据库表主键字段作为 Topic 的 Key，保证 Binlog 的顺序，在下游不会出现数据乱序。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Iceberg 作为数据湖方案，改造的点主要是 Iceberg V2 表的支持上面，也就是 Upsert 表。建立 Iceberg 管理中心，会根据合并策略定期优化和清理，Flink 写入主要保证在 CDC 到 Iceberg V2 表顺序性，在如何减少 Delete File 上，在 Iceberg 写入上增加了 BloomFilter 的支持，能够显著减少 Delete File 大小。Iceberg 管理中心，支持了 V2 表合并和 Flink 提交冲突问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Clickhouse 方面，重构了 Clickhouse 写入代码，优化了 Clickhouse 的写入性能，支持了本地表和分布式表写入。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 第四是数据入湖和离线调度方面&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;实时平台集成了 Iceberg，并支持 Iceberg Hadoop、Hive、Oss、S3 多种 Catalog。CDC 到 Iceberg 入湖链路已经在部门生产业务上线使用。在数据入湖或者入仓中，如果下游表有被离线数仓用到的地方，都会有依赖调度问题，离线任务何时启动？目前我们主要通过计算任务的延迟时间和 Checkpoint 时间来确保数据已经入仓入湖。以 CDC 或者 Kafka 到 Iceberg 为例。首先采集 CDC 端采集延迟时间，Kafka 采集最慢并行度延迟时间，同时采集任务 Checkpoint 时间。现在的 Checkpoint 完成，Iceberg 版本不一定会更新，基于此，对 Iceberg 写入进行了改造。这样一个同步任务，如果 CDC 采集端没有延迟，Checkpoint 也已经完成，可以保证某个小时的数据一定已经入仓。实时平台提供任务延迟查询接口。离线调度以此接口为调度依赖节点。这样就保证了离线任务启动时候，入仓数据的完整性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n138&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;三、实时数仓和数据湖探索&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n138&quot; mdtype=&quot;heading&quot;&gt;&lt;span/&gt;&lt;br/&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;实时数据采集，目前主要是三条链路：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;一是日志类型，主要是通过 Filebeat 采集写入 Kafka，Es 作为 Filebeat 的监控；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;二是 Api 接口上报服务，后端接入 Kafka；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;三是 CDC 采集全量加增量 Mysql 数据，写入 Kafka 或者直接写入 Iceberg。之前是采用 Canal 作为增量采集方案，现在已经全部改为了 CDC。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;实时数仓架构设计和业内基本一致，包括 ODS、DWD、DWS 层，之后输出到各应用系统，比如 Clickhouse、Doris、Mysql、Redis 等。目前主要以 Kafka 作为中间承载，也在探索 Iceberg 作为中间层的使用。Iceberg 虽然具有流读功能，但是流读时候数据的顺序性问题，一直没有较好的方案解决，我们也是在探索过程中。探索的主要方向有两个：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;一是将 Kafka 和 Iceberg 作为混合 Source 方案，Flink 任务读取混合 Source 之后，基于 Iceberg 快照记录的 Kafka 位点，确定读取范围和切换点;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;二是社区 Flip-188 提出的引入 Dynamic Table 存储实现。&lt;/span&gt;&lt;span&gt;Flink 内置表由两部分组成，LogStore 和 FileStore。&lt;/span&gt;&lt;span&gt;LogStore 将满足消息系统的需要，而 FileStore 是列式格式文件系统。&lt;/span&gt;&lt;span&gt;在每个时间点，LogStore 和 FileStore 都会为最新写入的数据存储完全相同的数据 (LogStore 有 TTL)，但物理布局不同。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在实时数仓探索方面，主要是 CDC 到 Iceberg 入湖任务，已经在生产上使用。其中主要解决了四个问题：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;一是 CDC 采集问题，特别是多库多表采集，会集中采集到 Kafka，减少多个 CDC 任务对同一数据库影响;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;二是 Iceberg 支持 V2 表写入，包括写入的索引过滤减少 Delete 文件，Iceberg 管理中心合并和提交冲突;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;三是支持分库分表的数据校验和数据延迟检查;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;四是一键式任务生成。对于用户而言，只需要填写数据库相关信息，目标 Iceberg 表库名和表名，并支持使用 Kafka 中转，避免多个 CDC 实例采集同一个数据库实例。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;通过上述四个问题的解决，能够达到数据库数据分钟级数据入湖，入湖的数据校验和数据延迟依赖达成，方便下游离线任务调度启动。&lt;/span&gt;&lt;/section&gt;&lt;p cid=&quot;n47&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5506937033084311&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6PJZcAOyYribaEdLcNGkdH48sWaOjxL248veuyoaur89LLlP4mibLQNXeib8yS52QgjK30fyibSx2b5Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1874&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;图 6：数据入湖链路&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n196&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;四、未来发展与展望&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n196&quot; mdtype=&quot;heading&quot;&gt;&lt;span/&gt;&lt;br/&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;主要有四点：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;一是 Flink 动态表存储能够尽快实现落地，实现真正的实时数仓和流表一体；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;二是 Flink 任务动态扩缩容、基于任务诊断的主动资源调整、细粒度资源调整；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;三是 Flink 对批任务的读写优化，目前批任务 Flink 的使用面不如 Spark，如果未来能够在此补足，可以做到流批操作一个引擎，开发成本会显著降低；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;四是 Flink 加数据湖更好的落地推广。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;hr/&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;更多 Flink 相关技术问题，可扫码加入社区钉钉交流群～&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;4&quot; data-cropselx2=&quot;204&quot; data-cropsely1=&quot;1&quot; data-cropsely2=&quot;243&quot; data-fileid=&quot;100010716&quot; data-ratio=&quot;1.162531017369727&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu573SfR5B9zrZybQe6w2yUInzu48HG5BMCDdHgE77LRzrnlGSl2kzKKfp9ypsduOukxibm1W99g26w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;806&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt; &lt;img class=&quot;__bg_gif rich_pages wxw-img&quot; data-fileid=&quot;100010714&quot; data-ratio=&quot;1&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/Z6bicxIx5naLWBBEcl44aIic1Mthe1nZiaramW5s4e8WwyCYYbTzu6uPBpgI6sxNXNymEnOYKpJpcrItUia7lS64mA/640?wx_fmt=gif&quot;/&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;戳我，查看更多技术内容～&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>