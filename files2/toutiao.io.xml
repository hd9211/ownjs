<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>3993bbe28ee4164e43abb808086c8393</guid>
<title>30 岁的程序员出路在哪里？| 码农周刊第 321 期</title>
<link>https://toutiao.io/k/qdeuemt</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;body class=&quot;issue&quot; id=&quot;readabilityBody&quot;&gt;
        &lt;h1&gt;30 岁的程序员出路在哪里？| 码农周刊第 321 期&lt;/h1&gt;
        &lt;h2&gt;码农周刊第321期（2020-10-15）&lt;/h2&gt;
        &lt;p&gt;☞ &lt;a href=&quot;https://weekly.manong.io/bounce?nid=321&amp;amp;aid=19568&amp;amp;url=https%3A%2F%2Fvip.manong.io%2F%3F3210&quot; target=&quot;_blank&quot;&gt;薪资翻番如何实现？程序员的涨薪秘诀&lt;/a&gt;&lt;br/&gt;&amp;#13;
&lt;a href=&quot;https://weekly.manong.io/bounce?nid=321&amp;amp;aid=19568&amp;amp;url=https%3A%2F%2Fvip.manong.io%2F%3F3210&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_321.png&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;br/&gt;&amp;#13;
&lt;small&gt;&lt;a href=&quot;https://weekly.manong.io/bounce?nid=321&amp;amp;aid=19185&amp;amp;url=https%3A%2F%2Fjinshuju.net%2Ff%2FV7DxN9&quot; target=&quot;_blank&quot;&gt;商务合作&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;程序设计&quot;&gt;程序设计&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;「码农周刊 VIP 会员专属邮件周报」每周五发送，自订购之日算起，全年 52 期。&lt;/p&gt;
        
        &lt;p&gt;最佳实践&lt;/p&gt;
        
        &lt;p&gt;偏好模型在贝壳的应用&lt;/p&gt;
        
        &lt;p&gt;实战经验&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_3041.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
        &lt;h3 id=&quot;VIP会员专区&quot;&gt;VIP会员专区&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;工作地点：成都 | 薪资：15-30K | 简历投递邮箱：xiexiaofang@huobi.com&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;共包含 9 种英伟达开发的图像及视频合成方法&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;以 DDD 思想为基础，融合中台核心要素，赋能中台建设。&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;开箱即用的中后台前端/设计解决方案&lt;/p&gt;
        &lt;h3 id=&quot;工具资料&quot;&gt;工具资料&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;「码农周刊 VIP 会员专属邮件周报」每周五发送，自订购之日算起，全年 52 期。&lt;/p&gt;
        
        &lt;p&gt;详解&lt;/p&gt;
        
        &lt;p&gt;详细介绍&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;经验分享&lt;/p&gt;
        
        &lt;p&gt;供参考&lt;/p&gt;
        
        &lt;p&gt;经验分享&lt;/p&gt;
        
        &lt;p&gt;详细介绍&lt;/p&gt;
        
        &lt;p&gt;一步步教你&lt;/p&gt;
        
        &lt;p&gt;细致讲解&lt;/p&gt;
        
        &lt;p&gt;无废话&lt;/p&gt;
        
        &lt;p&gt;详细介绍&lt;/p&gt;
        
        &lt;p&gt;适合入门&lt;/p&gt;
        
        &lt;p&gt;多维度看问题&lt;/p&gt;
        
        &lt;p&gt;&lt;a href=&quot;https://github.com/streamnative/mop&quot; target=&quot;_blank&quot;&gt;GitHub 地址&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_3041.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
        &lt;h3 id=&quot;编程语言&quot;&gt;编程语言&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;「码农周刊 VIP 会员专属邮件周报」每周五发送，自订购之日算起，全年 52 期。&lt;/p&gt;
        
        &lt;p&gt;通俗易懂&lt;/p&gt;
        
        &lt;p&gt;适合新手&lt;/p&gt;
        
        &lt;p&gt;供参考&lt;/p&gt;
        
        &lt;p&gt;详细介绍&lt;/p&gt;
        
        &lt;p&gt;详解&lt;/p&gt;
        
        &lt;p&gt;完备分析&lt;/p&gt;
        
        &lt;p&gt;结合代码&lt;/p&gt;
        
        &lt;p&gt;代码示例&lt;/p&gt;
        
        &lt;p&gt;通俗易懂&lt;/p&gt;
        
        &lt;p&gt;经验分享&lt;/p&gt;
        
        &lt;p&gt;详解&lt;/p&gt;
        
        &lt;p&gt;细致分析&lt;/p&gt;
        &lt;h3 id=&quot;每周独家号推荐&quot;&gt;每周独家号推荐&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;一线互联网工程师，分享Linux C++ Go Python等后端开发技术。&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 444675 即可&lt;/p&gt;
        
        &lt;p&gt;老年程序猿，工作15年以上。以前极其不擅长写作，最近决定对着弱点迎难而上，写写原创的经验、心得。&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 426740 即可&lt;/p&gt;
        
        &lt;p&gt;分享一些在 ThinkJS 项目开发过程中总结的一些经验以及问题&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 253319 即可&lt;/p&gt;
        
        &lt;p&gt;专注互联网金融&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 26661 即可&lt;/p&gt;
        
        &lt;p&gt;主要是分享作为一个机器学习算法工程师的工作学习生活方面的内容，包括Python编程、机器学习和深度学习算法知识，偶尔可能分享一些计算机基础方面的知识，以及一些练习项目等&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 1584 即可&lt;/p&gt;
        &lt;h3 id=&quot;每周一书&quot;&gt;每周一书&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;本书介绍了 Kotlin 的基本语法、常用类型、面向对象编程以及一些高阶的知识。欢迎到&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;兑换阅读。&lt;/p&gt;
        &lt;h3 id=&quot;编程之外&quot;&gt;编程之外&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;天无绝程序员之路&lt;/p&gt;
        
        &lt;p&gt;供参考&lt;/p&gt;
        
        &lt;p&gt;经验之谈&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_3041.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
        &lt;p&gt;
        &lt;/p&gt;
        
        
        
        
        &lt;div class=&quot;qrcode&quot;&gt;
  &lt;img src=&quot;https://img.toutiao.io/ads/vip_qrcode.png&quot; alt=&quot;Qrcode 258&quot;/&gt;&lt;span&gt;加入码农周刊VIP会员&lt;/span&gt;
&lt;/div&gt;
    &lt;/body&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>adb91f8439cdc7bba291ab790afe12e0</guid>
<title>理解完这些基本上能解决面试中 MySQL 的事务问题</title>
<link>https://toutiao.io/k/szxq5t8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;h1 cid=&quot;n0&quot; mdtype=&quot;heading&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span&gt;&lt;em&gt;&lt;strong&gt;欢迎关注公众号【&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;Ccww技术博客&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;】，原创技术文章第一时间推出&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/h1&gt;&lt;hr/&gt;&lt;blockquote cid=&quot;n4&quot; mdtype=&quot;blockquote&quot;&gt;&lt;p cid=&quot;n1135&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;越努力，越幸运，&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n1136&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;本文已收藏在GitHub中JavaCommunity, 里面有面试分享、源码分析系列文章，欢迎收藏，点赞&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n1139&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;https://github.com/Ccww-lx/JavaCommunity&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 cid=&quot;n1134&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;前言&lt;/span&gt;&lt;/h2&gt;&lt;p cid=&quot;n1126&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;在面试中，基本上都会问到关于数据库的事务问题，如果啥都不会或者只回答到表面的上知识点的话，那面试基本上是没戏了，为了能顺利通过面试，那MySql的事务问题就需要了解，所以就根据网上的资料总结一版Mysql事务的知识点，巩固一下事务的知识。&lt;/span&gt;&lt;/p&gt;&lt;h2 cid=&quot;n1128&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;事务&lt;/span&gt;&lt;/h2&gt;&lt;p cid=&quot;n1130&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;事务是指逻辑上的一组操作，要么都执行，要么都不执行,&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n5&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;事务的特性（ACID）&lt;/span&gt;&lt;/h3&gt;&lt;ul class=&quot;list-paddingleft-2&quot; cid=&quot;n6&quot; mdtype=&quot;list&quot; data-mark=&quot;-&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n8&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;原子性(&lt;code&gt;Atomicity&lt;/code&gt;)：事务是不可分割的工作单元，要么都成功，要么都失败， 如果事务中一个sql语句执行失败，则已执行的语句也必须回滚，数据库退回到事务前的状态。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n10&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;一致性(&lt;code&gt;Consistency&lt;/code&gt;)：事务不能破坏数据的完整性和业务的一致性 。例如在银行转账时，不管事务成功还是失败，双方钱的总额不变&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n12&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;隔离性(&lt;code&gt;Isolation&lt;/code&gt;)：一个事务所操作的数据在提交之前，对其他事务的可见性设定（一般是不可见）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n14&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;持久性(&lt;code&gt;Durability&lt;/code&gt;)：事务提交之后，所做的修改就会永久保存，不会因为系统故障导致数据丢失&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p cid=&quot;n15&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;严格来说，只有同时满足数据库的事务ACID特性才能算一个完整的事务，但现实中实现能够真正满足的完整的事务特性少之又少，但是在实现中也必须尽量达到事务要求的特性。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n592&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;那么事务ACID特性具体怎么实现的呢？我们来分析看看，首先先看看事务的特性。&lt;/span&gt;&lt;/p&gt;&lt;hr/&gt;&lt;h2 cid=&quot;n418&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;原子性(&lt;/span&gt;&lt;code&gt;&lt;span&gt;Atomicity&lt;/span&gt;&lt;/code&gt;&lt;span&gt;)&lt;/span&gt;&lt;/h2&gt;&lt;p cid=&quot;n419&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;首先我们来看看事务的原子性特性，看看其如何实现的？&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n581&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;原子性(&lt;code&gt;Atomicity&lt;/code&gt;)：事务是不可分割的工作单元，要么都成功，要么都失败， 如果事务中一个sql语句执行失败，则已执行的语句也必须回滚，数据库退回到事务前的状态&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n428&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;原子性(&lt;code&gt;Atomicity&lt;/code&gt;)的实现离不开 MySQL的事务日志 &lt;code&gt;undo log&lt;/code&gt;日志类型，当事务需要回滚的时候需要将数据库状态回滚到事务开始前，即需要撤销所有已经成功执行的sql语句。那么&lt;code&gt;undo log&lt;/code&gt;起了关键性作用：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n432&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;strong&gt;当事务对数据库进行修改时，InnoDB会生成对应的&lt;code&gt;undo log&lt;/code&gt;&lt;/strong&gt;&lt;strong&gt;；如果事务执行失败或调用了&lt;code&gt;rollback&lt;/code&gt;&lt;/strong&gt;&lt;strong&gt;，导致事务需要回滚，便可以利用&lt;code&gt;undo log&lt;/code&gt;&lt;/strong&gt;&lt;strong&gt;中的信息将数据回滚到修改之前的样子。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n420&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;那么&lt;code&gt;undo log&lt;/code&gt;是什么呢？每个数据变更操作是怎么被记录下来的呢？&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n434&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;undo log（ 回滚日志 ）&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n421&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;code&gt;undo log&lt;/code&gt; (回滚日志)：是采用&lt;strong&gt;段(&lt;code&gt;segment&lt;/code&gt;&lt;/strong&gt;&lt;strong&gt;)&lt;/strong&gt;的方式来记录的，每个&lt;code&gt;undo&lt;/code&gt;操作在记录的时候占用一个&lt;strong&gt;&lt;code&gt;undo log segment&lt;/code&gt;&lt;/strong&gt;。为什么会在数据更改操作的时候，记录了相对应的&lt;code&gt;undo log&lt;/code&gt;呢？其目的在于：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n523&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;其中，&lt;code&gt;undo log&lt;/code&gt;分为：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n455&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;数据更改的&lt;code&gt;undo log&lt;/code&gt;怎么记录的呢？&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n462&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt; 因为&lt;code&gt;insert&lt;/code&gt;操作的记录，只对事务本身可见，对其他事务不可见。故该&lt;code&gt;undo log&lt;/code&gt;可以在事务提交后直接删除，不需要进行&lt;code&gt;purge&lt;/code&gt;操作，&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n536&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt; 而&lt;code&gt;Delete&lt;/code&gt;操作在事务中实际上并不是真正的删除掉数据行，而是一种Delete Mark操作，在记录上标识&lt;code&gt;Delete_Bit&lt;/code&gt;，而不删除记录。是一种&quot;假删除&quot;,只是做了个标记，真正的删除工作需要后台&lt;code&gt;purge&lt;/code&gt;线程去完成。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n546&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;code&gt;update&lt;/code&gt;分为两种情况：&lt;code&gt;update&lt;/code&gt;的列是否是主键列。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n532&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;与&lt;code&gt;insert undo log&lt;/code&gt;不同的，&lt;code&gt;update undo log&lt;/code&gt;日志，当事务提交的时候，innodb不会立即删除&lt;code&gt;undo log&lt;/code&gt;， 会将该事务对应的&lt;code&gt;undo log&lt;/code&gt;放入到删除列表中，未来通过&lt;code&gt;purge&lt;/code&gt;线程来删除。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n542&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;因为后续还可能会用到&lt;code&gt;undo log&lt;/code&gt;，如隔离级别为&lt;code&gt;repeatable read&lt;/code&gt;时，事务读取的都是开启事务时的最新提交行版本，只要该事务不结束，该行版本就不能删除（即&lt;code&gt;undo log&lt;/code&gt;不能删除）,且&lt;code&gt;undo log&lt;/code&gt;分配的页可重用减少存储空间和提升性能。 &lt;/span&gt;&lt;/p&gt;&lt;blockquote cid=&quot;n488&quot; mdtype=&quot;blockquote&quot;&gt;&lt;p cid=&quot;n563&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;Note：purge线程两个主要作用是：清理undo页和清除page里面带有Delete_Bit标识的数据行。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p cid=&quot;n588&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n590&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;接着我们来看看事务的隔离性，看看事务有哪些隔离级别，而且事务并发中会产生什么问题。&lt;/span&gt;&lt;/p&gt;&lt;hr/&gt;&lt;h2 cid=&quot;n570&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;隔离性(&lt;/span&gt;&lt;code&gt;&lt;span&gt;Isolation&lt;/span&gt;&lt;/code&gt;&lt;span&gt;)&lt;/span&gt;&lt;/h2&gt;&lt;p cid=&quot;n584&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;隔离性(&lt;code&gt;Isolation&lt;/code&gt;)，是指事务内部的操作与其他事务是隔离的，并发执行的各个事务之间不能互相干扰 ，一个事务所操作的数据在提交之前，对其他事务的可见性设定(一般是不可见)。&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n624&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;事务隔离级别&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n896&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;而且数据库为了在并发下有效保证读取数据正确性，数据库提供了&lt;span&gt;四种事务隔离级别&lt;/span&gt;&amp;gt;，分别为：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot; cid=&quot;n614&quot; mdtype=&quot;list&quot; data-mark=&quot;-&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n616&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;读未提交(&lt;strong&gt;脏读&lt;/strong&gt;)：允许读取尚未提交的数据，允许脏读&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n618&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;读已提交（ &lt;strong&gt;不可重复读&lt;/strong&gt; ）：允许读取事务已经提交的数据&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n620&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;可重复读（ &lt;strong&gt;幻读&lt;/strong&gt; ）：在同一个事务内的查询结果都是和事务开始时刻查询一致的（ InnoDB默认级别 ）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n622&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;串行化：所有事务逐个依次执行， 每次读都需要获得表级共享锁，读写相互都会阻塞&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p cid=&quot;n572&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;其中，&lt;span&gt;不同的隔离级别可能会存在在不同并发问题&lt;/span&gt;，主要并发问题包括：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot; cid=&quot;n780&quot; mdtype=&quot;list&quot; data-mark=&quot;+&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n782&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;strong&gt;数据丢失：&lt;/strong&gt; 两个或多个事务操作相同数据，基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题——最后的更新覆盖了其他事务所做的更新&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n786&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;strong&gt;脏读：&lt;/strong&gt;读到了其他事务还未提交的数据，事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n787&quot; mdtype=&quot;paragraph&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.38437978560490044&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFmmXvxnaQq5p8dQSTj5K8EMicF2c6WyBkFbQfOSzcbq6jk8YJGFcOh46g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;653&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n789&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;strong&gt;不可重复读（重点是修改）：&lt;/strong&gt;在一个事务中，先后进行两次相同的读取，由于另一个事务修改了数据，导致前后两次结果的不一致，事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n790&quot; mdtype=&quot;paragraph&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.35222052067381315&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFm6tdicD2HjhvRXibhXCtTn6rH5cLPuicuexv7oH3wYibnBrovbvo4JHxvkw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;653&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n792&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;strong&gt;幻读（重点是新增、删除）：&lt;/strong&gt; 在一个事务中，先后进行两次相同的读取（一般是范围查询），由于另一个事务新增或删除了数据，导致前后两次结果不一致&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n793&quot; mdtype=&quot;paragraph&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.3592085235920852&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFm4d2C0AiaquwswcPdYyLxc9hTiamoyVbgdozoCSmNBmj2dvbykQyrZkdQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;657&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote cid=&quot;n916&quot; mdtype=&quot;blockquote&quot;&gt;&lt;p cid=&quot;n921&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;不可重复读和幻读的区别？&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n922&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;不可重复读和幻读最大的区别，就在于如何通过锁机制来解决他们产生的问题，&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n924&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;使用锁机制来实现这两种隔离级别，在可重复读中，相同sql第一次读取到数据后就将这些数据加锁，其它事务无法更新操作这些数据来实现可重复读了隔离。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n926&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;但这种处理方式却无法锁住insert的数据，因此会出现当事务A先前读取了数据，事务B再&lt;code&gt;insert&lt;/code&gt;数据提交，结果发现事务A就会发现莫名其妙多了些数据，这就是幻读，不能通过行锁来避免 。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p cid=&quot;n914&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;了解了并发问题后，来看看不同的隔离级别可能会存在在不同并发问题：&lt;/span&gt;&lt;/p&gt;&lt;figure cid=&quot;n868&quot; mdtype=&quot;table&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr cid=&quot;n869&quot; mdtype=&quot;table_row&quot;&gt;&lt;th&gt;&lt;span&gt;事务隔离级别&lt;/span&gt;&lt;/th&gt;&lt;th&gt;&lt;span&gt;脏读&lt;/span&gt;&lt;/th&gt;&lt;th&gt;&lt;span&gt;不可重复读&lt;/span&gt;&lt;/th&gt;&lt;th&gt;&lt;span&gt;幻读&lt;/span&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr cid=&quot;n874&quot; mdtype=&quot;table_row&quot;&gt;&lt;td&gt;&lt;span&gt;读未提交&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;是&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;是&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;是&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr cid=&quot;n879&quot; mdtype=&quot;table_row&quot;&gt;&lt;td&gt;&lt;span&gt;不可重复读&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;否&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;是&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;是&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr cid=&quot;n884&quot; mdtype=&quot;table_row&quot;&gt;&lt;td&gt;&lt;span&gt;可重复读&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;否&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;否&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;是&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr cid=&quot;n889&quot; mdtype=&quot;table_row&quot;&gt;&lt;td&gt;&lt;span&gt;串行化&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;否&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;否&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;否&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p cid=&quot;n70&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;为了实现事务隔离，延伸出了数据库锁。其中，&lt;span&gt;&lt;strong&gt;innodb事务的隔离级别是由锁机制和MVCC（多版本并发控制）来实现的&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n71&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;那我们来先看看锁的原理，怎么使用锁来实现事务隔离的呢？&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n73&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;锁机制&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n971&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;锁机制的基本工作原理，事务在修改数据之前，需要先获得相应的锁；获得锁之后，事务便可以修改数据；该事务操作期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁，&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n74&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;MySQL主要分成三种类型（级别）的锁机制：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot; cid=&quot;n75&quot; mdtype=&quot;list&quot; data-mark=&quot;+&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n77&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;表级锁：最大颗粒度的锁机制，锁定资源争用的概率也会最高 ，并发度最低 ，但开销小，加锁快，不会出现死锁，&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n79&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;行级锁：最大颗粒度的锁机制很小， 发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能 ，但 开销大，加锁慢；会出现死锁 ，&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n81&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;页级锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p cid=&quot;n82&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;而且不同的存储引擎支持不同的的锁机制，主要分析一下InnoDB锁。&lt;/span&gt;&lt;/p&gt;&lt;h4 cid=&quot;n83&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;InnoDB锁&lt;/span&gt;&lt;/h4&gt;&lt;p cid=&quot;n84&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt; InnoDB实现了以下两种类型的行锁&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n90&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;对于&lt;code&gt;UPDATE&lt;/code&gt;,&lt;code&gt;DELETE&lt;/code&gt;,&lt;code&gt;INSERT&lt;/code&gt;操作， InnoDB会自动给涉及及数据集加排他锁（Ｘ）；对于普通SELECT语句，InnoDB不会加任何锁,&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n91&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;而且因为InnoDB引擎允许行锁和表锁共存，实现多粒度锁机制，使用意向锁实现表锁机制，&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n97&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;意向锁(IS、IX)是InnoDB数据操作之前自动加的，不需要用户干预。它的意义在于：当事务想去进行锁表时，可以先判断意向锁是否存在，存在时则可快速返回该表不能启用表锁，否则就需要等待，&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n98&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;其中，四种锁的兼容性如下&lt;/span&gt;&lt;/p&gt;&lt;figure cid=&quot;n99&quot; mdtype=&quot;table&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr cid=&quot;n100&quot; mdtype=&quot;table_row&quot;&gt;&lt;th&gt;&lt;span&gt;当前锁模式/是否兼容/请求锁模式&lt;/span&gt;&lt;/th&gt;&lt;th&gt;&lt;span&gt;X&lt;/span&gt;&lt;/th&gt;&lt;th&gt;&lt;span&gt;IX&lt;/span&gt;&lt;/th&gt;&lt;th&gt;&lt;span&gt;S&lt;/span&gt;&lt;/th&gt;&lt;th&gt;&lt;span&gt;IS&lt;/span&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr cid=&quot;n106&quot; mdtype=&quot;table_row&quot;&gt;&lt;td&gt;&lt;span&gt;X&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;冲突&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;冲突&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;冲突&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;冲突&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr cid=&quot;n112&quot; mdtype=&quot;table_row&quot;&gt;&lt;td&gt;&lt;span&gt;IX&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;冲突&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;兼容&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;冲突&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;兼容&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr cid=&quot;n118&quot; mdtype=&quot;table_row&quot;&gt;&lt;td&gt;&lt;span&gt;S&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;冲突&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;冲突&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;兼容&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;兼容&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr cid=&quot;n124&quot; mdtype=&quot;table_row&quot;&gt;&lt;td&gt;&lt;span&gt;IS&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;冲突&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;兼容&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;兼容&lt;/span&gt;&lt;/td&gt;&lt;td&gt;&lt;span&gt;兼容&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p cid=&quot;n130&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;如果一个事务请求的锁模式与当前的锁兼容，InnoDB就请求的锁授予该事务；反之，如果两者两者不兼容，该事务就要等待锁释放。&lt;/span&gt;&lt;/p&gt;&lt;h4 cid=&quot;n131&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;InnoDB行锁&lt;/span&gt;&lt;/h4&gt;&lt;p cid=&quot;n132&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;InnoDB的行锁是通过给索引上的&lt;strong&gt;索引项加锁&lt;/strong&gt;来实现的。&lt;strong&gt;只有通过索引检索数据，才能使用行锁，否则将使用表锁（锁住索引的所有记录）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n133&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;innodb的行锁，默认是由&lt;strong&gt;&lt;code&gt;临键锁(next-key)&lt;/code&gt;&lt;/strong&gt;算法实现的，可以防止幻读。根据索引，划分为一个个&lt;strong&gt;左开右闭&lt;/strong&gt;的区间。当进行范围查询的时候，若命中索引且能够检索到数据，则锁住记录所在的区间和它的下一个区间,&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n134&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;其实，&lt;strong&gt;临键锁(Next-Key)&lt;/strong&gt;=&lt;strong&gt;记录锁(Record Locks)&lt;/strong&gt;+&lt;strong&gt;间隙锁(Gap Locks)&lt;/strong&gt;，&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n140&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;具体的使用体现在哪里呢？如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.46060606060606063&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFmIvTG2Z905QUWVJgL5KYvySqTVgJf3licqul9aCZgbMvlFthtOpTYVww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;660&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot; cid=&quot;n145&quot; mdtype=&quot;list&quot; data-mark=&quot;+&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n147&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;当记录不存在（不论是等值查询，还是范围查询）时，next-key将退化成&lt;strong&gt;Gap Lock（间隙锁）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n148&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.5150602409638554&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFmWpbMHJ8rEpFJyCiaa9vZGXPUsvricjWr0KxzQzHPyickY8zibqNLb6OemQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;664&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n150&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;当条件是精准匹配（即为等值查询时）且记录存在时，并且是唯一索引，&lt;strong&gt;临键锁(Next-Key)&lt;/strong&gt;退化成&lt;strong&gt;Record Lock（记录锁）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n151&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4180790960451977&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFmsdCoFtlnGsncibWh7DLGCDy9lsEjbJsgKISMUpKVkcauW4Fuibd54L0w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;708&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n153&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;当条件是精准匹配（即为等值查询时）且记录存在，但不是唯一索引时，&lt;strong&gt;临键锁(Next-Key)&lt;/strong&gt;会有精准值的数据会增加&lt;strong&gt;Record Lock（记录锁）&lt;/strong&gt;和精准值前后的区间的数据会增加&lt;strong&gt;Gap Lock（间隙锁)&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n154&quot; mdtype=&quot;paragraph&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4880597014925373&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFmz0VibbGWM6LPXzu6v2WfxfX41Xuo26h2StJrzu0GMpjtSojga6nbSVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;670&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 cid=&quot;n961&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;如何使用锁解决并发问题&lt;/span&gt;&lt;/h4&gt;&lt;p cid=&quot;n962&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;利用锁解决脏读、不可重复读、幻读&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n960&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;code&gt;Multiversion concurrency control&lt;/code&gt; (&lt;code&gt;MVCC&lt;/code&gt; 多版本并发控制)&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n165&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;code&gt;InnoDB&lt;/code&gt;的&lt;code&gt;MVCC&lt;/code&gt;是通过在每行记录后面保存两个隐藏的列来实现的，&lt;strong&gt;一个保存了行的事务ID（事务ID就会递增 ）&lt;/strong&gt;，&lt;strong&gt;一个保存了行的回滚段的指针&lt;/strong&gt; 。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n398&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.21217391304347827&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgyKx4nzfu3dK9SD5jxqxFmR7uEiaSiaIwwML2kqPjwfcejNLV9I5qJrznHCtAhl7n3l6NiaDuMNCgGg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;575&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n400&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;每开始一个新的事务，都会自动递增产 生一个新的事务id。事务开始时刻的会把事务id放到当前事务影响的行事务id中，而&lt;code&gt;DB_ROLL_PTR&lt;/code&gt;表示指向该行回滚段的指针，该行记录上所有版本数据，在undo中都通过链表形式组织，该值实际指向undo中该行的历史记录链表，&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n166&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;span&gt;在并发访问数据库时，对正在事务中的数据做MVCC多版本的管理，以避免写操作阻塞读操作，并且会通过比较版本解决幻读&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n167&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;而且MVCC只在&lt;code&gt;REPEATABLE READ&lt;/code&gt;和&lt;code&gt;READ COMMITIED&lt;/code&gt;两个隔离级别下才会工作，&lt;strong&gt;其中，MVCC实现实质就是保存数据在某个时间点的&lt;span&gt;快照&lt;/span&gt;来实现的。&lt;/strong&gt; 那哪些操作是快照读？&lt;/span&gt;&lt;/p&gt;&lt;h4 cid=&quot;n168&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;快照读和当前读&lt;/span&gt;&lt;/h4&gt;&lt;p cid=&quot;n169&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;strong&gt;快照读&lt;/strong&gt;，innodb快照读，数据的读取将由 cache(原本数据) + undo(事务修改前的数据) 两部分组成&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n173&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;strong&gt;当前读&lt;/strong&gt;，SQL读取的数据是最新版本。通过锁机制来保证读取的数据无法通过其他事务进行修改&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n186&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;那么在RR隔离级别下，MVCC具体是如何操作的。&lt;/span&gt;&lt;/p&gt;&lt;h4 cid=&quot;n187&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;RR隔离级别下，MVCC具体操作&lt;/span&gt;&lt;/h4&gt;&lt;p cid=&quot;n188&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;strong&gt;SELECT操作&lt;/strong&gt;，InnoDB遵循以后两个规则执行：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot; start=&quot;&quot; cid=&quot;n189&quot; mdtype=&quot;list&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n191&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;span&gt;InnoDB只查找版本早于当前事务版本的数据行（即行的事务编号小于或等于当前事务的事务编号）&lt;/span&gt;，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的记录。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n193&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;span&gt;行的删除版本要么未定义,读取到事务开始之前状态的版本&lt;/span&gt;&amp;gt;,这可以确保事务读取到的行，在事务开始之前未被删除.只有同时满足的两者的记录，才能返回作为查询结果.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p cid=&quot;n194&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;strong&gt;INSERT&lt;/strong&gt;：&lt;span&gt;InnoDB为新插入的每一行保存当前事务编号作为行版本号&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n195&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;strong&gt;DELETE&lt;/strong&gt;：&lt;span&gt;InnoDB为删除的每一行保存当前事务编号作为行删除标识&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n196&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;：&lt;span&gt;InnoDB为插入一行新记录，保存当前事务编号作为行版本号，同时保存当前事务编号到原来的行作为行删除标识&lt;/span&gt;&amp;gt;。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n197&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;保存这两个额外系统版本号，使大多数读操作都可以不用加锁。这样设计使得读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行，不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作。&lt;span md-inline=&quot;tab&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n198&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;分析完了原子性和隔离性，我们继续看看事务的持久性。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n980&quot; mdtype=&quot;paragraph&quot;&gt;&lt;/p&gt;&lt;h2 cid=&quot;n931&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;持久性(&lt;/span&gt;&lt;code&gt;&lt;span&gt;Durability&lt;/span&gt;&lt;/code&gt;&lt;span&gt;)&lt;/span&gt;&lt;/h2&gt;&lt;p cid=&quot;n940&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;持久性(&lt;code&gt;Durability&lt;/code&gt;)：事务提交之后，所做的修改就会永久保存，不会因为系统故障导致数据丢失，&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n983&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;而且其实现的关键在于&lt;code&gt;redo log&lt;/code&gt;， 在执行SQL时会保存已执行的SQL语句到一个指定的Log文件，当执行&lt;code&gt;recovery&lt;/code&gt;时重新执行&lt;code&gt;redo log&lt;/code&gt;记录的SQL操作。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n991&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;那么&lt;code&gt;redo log&lt;/code&gt;如何实现的呢？&lt;/span&gt;&lt;/p&gt;&lt;h3 cid=&quot;n993&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;redo log&lt;/span&gt;&lt;/h3&gt;&lt;p cid=&quot;n995&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;当向数据库写入数据时，执行过程会首先写入Buffer Pool，Buffer Pool中修改的数据会定期刷新到磁盘中（这一过程称为刷脏），这整一过程称为redo log。redo log 分为：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n1019&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;Buffer Pool的使用可以大大提高了读写数据的效率，但是也带了新的问题：如果MySQL宕机，而此时Buffer Pool中修改的数据在内存还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n1016&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;为了确保事务的持久性，在当事务提交时，会调用&lt;code&gt;fsync&lt;/code&gt;接口对&lt;code&gt;redo log&lt;/code&gt;进行刷盘, （即&lt;code&gt;redo log buffer&lt;/code&gt;写日志到磁盘的&lt;code&gt;redo log file&lt;/code&gt;中 ）,刷新频率由 &lt;code&gt;innodb_flush_log_at_trx_commit&lt;/code&gt;变量来控制的：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n1043&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;redo log有更加详细的解读，后续有时间再补上，到现在为止，已经将事务三个特性都理解了，那事务一致性呢？&lt;/span&gt;&lt;/p&gt;&lt;hr/&gt;&lt;h2 cid=&quot;n1049&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;一致性(&lt;/span&gt;&lt;code&gt;&lt;span&gt;Consistency&lt;/span&gt;&lt;/code&gt;&lt;span&gt;)&lt;/span&gt;&lt;/h2&gt;&lt;p cid=&quot;n989&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;一致性(&lt;code&gt;Consistency&lt;/code&gt;)：事务不能破坏数据的完整性和业务的一致性 ：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n1065&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;那是如何保证数据一致性的？&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n1067&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;其实数据一致性是通过事务的原子性、持久性和隔离性来保证的&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot; cid=&quot;n1072&quot; mdtype=&quot;list&quot; data-mark=&quot;-&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n1074&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;原子性：语句要么全执行，要么全不执行，是事务最核心的特性，事务本身就是以原子性来定义的；实现主要基于undo log&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n1076&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;持久性：保证事务提交后不会因为宕机等原因导致数据丢失；实现主要基于redo log&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n1078&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;隔离性：保证事务执行尽可能不受其他事务影响；InnoDB默认的隔离级别是RR，RR的实现主要基于锁机制（包含next-key lock）、MVCC（包括数据的隐藏列、基于undo log的版本链、ReadView）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 cid=&quot;n4927&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p cid=&quot;n932&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;其中要同时满足ACID特性，这样的事务少之又少。实际中很多例子都只是满足一些特性，比如：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot; cid=&quot;n4931&quot; mdtype=&quot;list&quot; data-mark=&quot;+&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n4934&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;MySQL的NDB Cluster事务不满足持久性和隔离性；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n4935&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;InnoDB默认事务隔离级别是可重复读，不满足隔离性；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n4941&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;Oracle默认的事务隔离级别为READ COMMITTED，不满足隔离性&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p cid=&quot;n4929&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;所以我们只能使用这个四个维度的特性去衡量事务的操作。&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n934&quot; mdtype=&quot;paragraph&quot;&gt;&lt;/p&gt;&lt;blockquote cid=&quot;n7947&quot; mdtype=&quot;blockquote&quot;&gt;&lt;p cid=&quot;n7949&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;谢谢各位点赞，没点赞的点个赞支持支持&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n7949&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;最后，微信搜《Ccww技术博客》观看更多文章，也欢迎关注一波。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/EvicK4z5ZDrgfBz2Ve78FylxcGWmXaueSuqPguurBCWEkeY1ibeLl1wlxUyibdesc4YeuiaJJjSt6HTiab2iaHyXyyicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.36857142857142855&quot; data-w=&quot;350&quot;/&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>cea9d0db36842e2f797115424f4207d3</guid>
<title>Spring Boot 开发秘籍：事件异步处理</title>
<link>https://toutiao.io/k/y424dbu</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在项目实际开发过程中，我们有很多这样的业务场景：一个事务中处理完一个业务逻辑后需要跟着处理另外一个业务逻辑，伪码大致如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ProductServiceImpl&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt; ...&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;saveProduct&lt;/span&gt;&lt;span&gt;(Product product)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        productMapper.saveOrder(product);&lt;br/&gt;        notifyService.notify(product);&lt;br/&gt;    }&lt;br/&gt; ...&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很简单并且很常见的一段业务逻辑：首先将产品先保存数据库，然后发送通知。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;某一天你们可能需要把新增的产品存到Es中，这时候也需要代码可能变成这样：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ProductServiceImpl&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt; ...&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;saveProduct&lt;/span&gt;&lt;span&gt;(Product product)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        productMapper.saveProduct(product);&lt;br/&gt;        esService.saveProduct(product)&lt;br/&gt;        notifyService.notify(product);&lt;br/&gt;    }&lt;br/&gt; ...&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随着业务需求的变化，代码也需要跟着一遍遍的修改。而且还会存在另外一个问题，如果通知系统挂了，那就不能再新增产品了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于上面这种情况非常适合引入消息中间件（消息队列）来对业务进行解耦，但并非所有的业务系统都会引入消息中间件（引入会第三方架构组件会带来很大的运维成本）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Spring提供了事件驱动机制可以帮助我们实现这一需求。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;Spring事件驱动&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;spring事件驱动由3个部分组成&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ApplicationEvent：表示事件本身，自定义事件需要继承该类，用来定义事件&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ApplicationEventPublisher：事件发送器，主要用来发布事件&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;ApplicationListener：事件监听器接口，监听类实现ApplicationListener 里onApplicationEvent方法即可，也可以在方法上增加@EventListener以实现事件监听。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实现Spring事件驱动一般只需要三步：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;自定义需要发布的事件类，需要继承ApplicationEvent类&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用ApplicationEventPublisher来发布自定义事件&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用@EventListener来监听事件&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;「这里需要特别注意一点，默认情况下事件是同步的。即事件被publish后会等待Listener的处理。如果发布事件处的业务存在事务，监听器处理也会在相同的事务中。如果需要异步处理事件，可以onApplicationEvent方法上加@Aync支持异步或在有@EventListener的注解方法上加上@Aync。」&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4776315789473684&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PxMzT0Oibf4g1Rz1NKILAx0c0G6n2zb9yliaF3JUxszq1RbFX9SdKkIs3SaapF3OUZlU6uLvp28jUTutaGic8bJKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;760&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;源码实战&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ProductEvent&lt;/span&gt; &lt;span&gt;extends&lt;/span&gt; &lt;span&gt;ApplicationEvent&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;ProductEvent&lt;/span&gt;&lt;span&gt;(Product product)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;super&lt;/span&gt;(product);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ProductServiceImpl&lt;/span&gt; &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;IproductService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt; ...&lt;br/&gt;    &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; ApplicationEventPublisher publisher;&lt;br/&gt; &lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;(rollbackFor = Exception.class)&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;saveProduct&lt;/span&gt;&lt;span&gt;(Product product)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;  productMapper.saveProduct(product); &lt;br/&gt;        &lt;span&gt;//事件发布&lt;/span&gt;&lt;br/&gt;        publisher.publishEvent(product);&lt;br/&gt;    }&lt;br/&gt;    ...&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Slf&lt;/span&gt;4j&lt;br/&gt;&lt;span&gt;@AllArgsConstructor&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ProductListener&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; NotifyService notifyServcie;&lt;br/&gt;&lt;br/&gt; &lt;span&gt;@Async&lt;/span&gt;&lt;br/&gt; &lt;span&gt;@Order&lt;/span&gt;&lt;br/&gt; &lt;span&gt;@EventListener&lt;/span&gt;(ProductEvent.class)&lt;br/&gt; &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;notify&lt;/span&gt;&lt;span&gt;(ProductEvent event)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;  Product product = (Product) event.getSource();&lt;br/&gt;  notifyServcie.notify(product, &lt;span&gt;&quot;product&quot;&lt;/span&gt;);&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;在SpringBoot启动类上增加&lt;code&gt;@EnableAsync&lt;/code&gt; 注解&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Slf&lt;/span&gt;4j&lt;br/&gt;&lt;span&gt;@EnableSwagger&lt;/span&gt;2&lt;br/&gt;&lt;span&gt;@SpringBootApplication&lt;/span&gt;&lt;br/&gt;&lt;span&gt;@EnableAsync&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ApplicationBootstrap&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;...&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;使用了Async后会使用默认的线程池SimpleAsyncTaskExecutor，一般我们会在项目中自定义一个线程池。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Configuration&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ExecutorConfig&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;/** 核心线程数 */&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; corePoolSize = &lt;span&gt;10&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;/** 最大线程数  */&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; maxPoolSize = &lt;span&gt;50&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;/** 队列大小  */&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; queueCapacity = &lt;span&gt;10&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;/** 线程最大空闲时间   */&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; keepAliveSeconds = &lt;span&gt;150&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Bean&lt;/span&gt;(&lt;span&gt;&quot;customExecutor&quot;&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; Executor &lt;span&gt;myExecutor&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        ThreadPoolTaskExecutor executor = &lt;span&gt;new&lt;/span&gt; ThreadPoolTaskExecutor();&lt;br/&gt;        executor.setCorePoolSize(corePoolSize);&lt;br/&gt;        executor.setMaxPoolSize(maxPoolSize);&lt;br/&gt;        executor.setQueueCapacity(queueCapacity);&lt;br/&gt;        executor.setThreadNamePrefix(&lt;span&gt;&quot;customExecutor-&quot;&lt;/span&gt;);&lt;br/&gt;        executor.setKeepAliveSeconds(keepAliveSeconds);&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// rejection-policy：当pool已经达到max size的时候，如何处理新任务&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// CALLER_RUNS：不在新线程中执行任务，而是由调用者所在的线程来执行&lt;/span&gt;&lt;br/&gt;        executor.setRejectedExecutionHandler(&lt;span&gt;new&lt;/span&gt; ThreadPoolExecutor.CallerRunsPolicy());&lt;br/&gt;        executor.initialize();&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; executor;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4be7cff0f417238998cfd3495a7bdb4d</guid>
<title>星星之火，可否燎原：关于深度学习和大数据系统融合现状的认识</title>
<link>https://toutiao.io/k/sdb9eoy</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我博士毕业的 2016 年，我就关注到了一个比较小众的算法工程方向——深度学习和大数据系统的融合。&lt;/span&gt;&lt;span&gt;具体来说，就是将深度学习放在大数据系统上（当时主要指 Spark），从而实现分布式深度学习。&lt;/span&gt;&lt;span&gt;当时我觉得，这个方向会在未来工业应用中占有一席之地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是现在 2020 年来看，深度学习和大数据系统融合这个方向已经沉寂了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.32564102564102565&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Q3H1TCddfvNzTkibibhTheuCzQ0iakthtziaicR5obAAelXd29ZOjwlib6Uu9u7HvJc5clhPzX9bNibz7cwhzr2IGxaHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;390&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;一、红旗还能打多久？&lt;/strong&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习和大数据系统融合这个沉寂的辽原上，有一些零散的星火。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt; TensorFlow on Spark&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2017年 2 月 13 日，雅虎宣布开源 TensorFlowOnSpark (https://github.com/yahoo/TensorFlowOnSpark)。TensorFlowOnSpark 为 Apache Hadoop 和 Apache Spark 集群带来可扩展的深度学习。&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; Horovod on Spark&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Horovod (https://github.com/horovod/horovod) 是一个支持TensorFlow、Keras、PyTorch和Apache MXNet的分布式训练框架。Horovod的目标是让分布式深度学习更快更易用。 目前 Horovod 已经支持了 Spark。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; Flink-AI-Extend&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Flink-AI-Extended (https://github.com/alibaba/flink-ai-extended) 由阿里于2019 年 6月 28 号推出，其结合了TensorFlow和Flink，为用户提供了更方便有用的工具。&lt;span data-sgtrans-text=&quot;5-4&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span data-sgtrans-text=&quot;5-4&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我司内部 Spark-Fuel 是 TensorFlow on Spark  的加强版本。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;深度学习和大数据系统融合的这些项目，不过是昏暗草原上的零散几个小火堆。&lt;/span&gt;&lt;span&gt;整个草原还是沉闷还是沉寂。&lt;/span&gt;&lt;span&gt;我这个“小娃娃”就要问了，深度学习和大数据系统融合的红旗到底还能打多久？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大约在 &lt;/span&gt;&lt;span&gt;2014&lt;/span&gt;&lt;span&gt;-2016 &lt;/span&gt;&lt;span&gt;年，分布式&lt;/span&gt;&lt;span&gt;深&lt;/span&gt;&lt;span&gt;度&lt;/span&gt;&lt;span&gt;学&lt;/span&gt;&lt;span&gt;习开始在工业界落&lt;/span&gt;&lt;span&gt;地。&lt;/span&gt;&lt;span&gt;在工业界落地的第一件事&lt;/span&gt;&lt;span&gt;就是找到一个合适的集群编排&lt;/span&gt;&lt;span&gt;系统，进而管理用于深度学习的机器&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;把我们自己&lt;/span&gt;&lt;span&gt;代入&lt;/span&gt;&lt;span&gt;将&lt;/span&gt;&lt;span&gt;分布&lt;/span&gt;&lt;span&gt;式深度&lt;/span&gt;&lt;span&gt;学习进行工业化的&lt;/span&gt;&lt;span&gt;人们，&lt;/span&gt;&lt;span&gt;我们会发现，当时M&lt;/span&gt;&lt;span&gt;esos 和 K&lt;/span&gt;&lt;span&gt;8S&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;做集群编排和管理都&lt;/span&gt;&lt;span&gt;不成熟，久经考验的成熟系统只有&lt;/span&gt;&lt;span&gt;是跑着 Spark 的 Yarn&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;这个时候，我们的&lt;/span&gt;&lt;span&gt;第一反应是将深度学习嵌入到&lt;/span&gt;&lt;span&gt; Spark 上，&lt;/span&gt;&lt;span&gt;解决掉&lt;/span&gt;&lt;span/&gt;&lt;span&gt;集群&lt;/span&gt;&lt;span&gt;编排管理的问题。&lt;/span&gt;&lt;span&gt;但现在已经是 &lt;/span&gt;&lt;span&gt;2020 &lt;/span&gt;&lt;span&gt;年了，K&lt;/span&gt;&lt;span&gt;8S 在和 Mesos 的竞争中&lt;/span&gt;&lt;span&gt;，干死了 Mesos&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;，自身也成熟起来，成为了集群编排管理的&lt;/span&gt;&lt;span&gt;工业实际&lt;/span&gt;&lt;span&gt;标准。&lt;/span&gt;&lt;span&gt;人们已经&lt;/span&gt;&lt;span&gt;能够方便地在 K8S&lt;/span&gt;&lt;span&gt; 的基础上构建起分布式深度学习能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时，随着 NLP 和 CV 等领域模型越来越复杂，比如现在的 Bert 等，CPU 已经扛不住这类模型的深度学习了。&lt;/span&gt;&lt;span&gt;深度学习转向 GPU，已经成为大势所趋。&lt;/span&gt;&lt;span&gt;用没有成熟 GPU 调度能力的大数据系统去支持类似 Bert 模型的分布式训练，就是脑子有病。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结起来，深度学习和大数据系统融合，会面临两个问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt; K8S 的问题&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;K8S 已经成熟起来&lt;span&gt;。&lt;/span&gt;在 K8S 上搭建深度学习分布式训练集群，已经有很多成熟的案例。对比之下，在大数据系统搭建深度学习分布式训练集群，显得多余了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;GPU 的问题&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;NLP 和 CV 等领域模型越来越复杂，比如现在的 Bert 等，需要 GPU 支持。但大数据系统集群没有成熟的 GPU 调度能力。 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在上述情势下，深度学习嵌入大数据系统，目标是解决什么问题，又能解决什么问题？现在继续推动深度学习嵌入大数据系统，是不是逆技术趋势而动？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.6527777777777778&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Q3H1TCddfvOEK4HUwjTzKNDThV5Lwf5l4oax73MWER1wH5VT22nhOjzGSfsMiatEqVYBnaqibAj5oaQaZNFicqryQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1440&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;二、革命目标是什么&lt;span/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当前 K8S 的成熟，和对 GPU 的需求，都让深度学习和大数据系统融合这个技术领域的前途似乎一片黑暗。&lt;/span&gt;&lt;span&gt;但是对于深度学习和大数据系统融合的前途，我却有不同的理解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图所示，最近几年，广告推荐搜索领域的算法推陈出新，我们作为小团队也尝试过其中几种方法，也取得了一定效果。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.54296875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Q3H1TCddfvMnqcGkAqM02cr92YE5X4Z8vwMBlOjuibrtqRDAKpct4R8OkoBj6UU6xtkJxuFV8ObGuv25dDVABuA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但我们在线上用的这些模型和超级大场景团队用的这些模型，有没有区别呢？区别大了去了，我们的模型用了用户几百几千维特征和道具几十几百维特征，交叉也不敢做。不要问为什么只能用这些特征，问就是训练组件支持不了更大的模型。也不要问为什么 LR 的训练能支持千万级特征，问就是我们退步了。像我们这样，占工业界绝大数的大腰部和底部的广告推荐搜索场景的算法工程师，并没有相应超大规模深度学习系统的支持。&lt;/span&gt;&lt;span&gt;其实这些腰部和底部数据量没有金字塔尖的超级大场景那么大，只需要也只能够一个轻量的深度学习分布式训练框架训练一个亿级乃至十亿级 embedding 模型便能带来可观的效果提升。如果我们能够改造深度学习框架，并且支持基本所有广告推荐搜索团队都要使用的大数据集群（不然没法处理大量的样本和特征），我们一个小团队立马获得了大规模深度学习能力的工程能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，当前广告推荐搜索算法工程师们不管是出于快速迭代模型的考虑，还是出于尝试强化学习的考虑，都对在线学习有比较强烈的述求。&lt;/span&gt;&lt;span&gt;而这个也是大数据系统的强项。&lt;/span&gt;&lt;span&gt;大数据系统中的 Storm 和 Flink 是工业界标准的实时数据处理框架，具备的 Exactly-Once (数据不重复) 、多数据流时间窗口聚合和反压机制（平滑数据流速度）特性都是在长期的工业实践中锤炼出来的。&lt;/span&gt;&lt;span&gt;如果我们成熟地完成深度学习和大数据系统中的实时数据处理系统结合，我们一个小团队就能立马获得在线学习和强化学习的工程基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过上面到场景，我们了解到，通过深度学习和大数据系统融合做的分布式训练组件，满足了一些特性之后，还是有一些需求的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;轻量级&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不需要算法团队搭建训练集群，复用现有大数据系统集群就有分布式训练能力。还有一个附带的好处是，直接在大数据系统集群训练，不需要频繁地进行大数据的转移。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;离线以及在线&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时具备离线和在线训练能力&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;大规模&lt;/span&gt;&lt;span&gt;广告推荐搜索&lt;/span&gt;&lt;span&gt;深度学习模型&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;针对&lt;span&gt;广告推荐搜索&lt;/span&gt;领域的大规模模型。这类模型计算相对简单，但容量达到&lt;span&gt;亿级乃至十亿级&lt;/span&gt; Embedding。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们将深度学习和大数据系统融合的目标设定为，轻量级的离线以及在线的&lt;span&gt;大规模&lt;/span&gt;&lt;span&gt;广告推荐搜索&lt;/span&gt;&lt;span&gt;深度学习模型的&lt;/span&gt;分布式训练组件，那么事情还有作为的空间。这个目标换成人话来说，广告推荐搜索领域的算法人员可以很方便地离线或者在线地训练亿级乃至十亿级的大规模模型。聚焦上面的目标之后，上一章提到的问题便可以解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt; 解决 K8S 的问题&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;K8S 集群上的&lt;span&gt;超大规模深度学习&lt;/span&gt;&lt;span/&gt;&lt;span&gt;分布式&lt;/span&gt;&lt;span&gt;训练组件肯定是非轻量级的。对于占大部分的腰部和底部的广告推荐搜索领域，轻量级也就是拿来就能&lt;span&gt;训练亿级乃至十亿级的大规模模型&lt;/span&gt;，是有相当的吸引力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;解决 GPU 的问题&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;广告推荐搜索领域的&lt;/span&gt;&lt;span&gt;亿级乃至十亿级的大规模模型，模型很大，但计算复杂性缺不高。模型大量的是 ID 类特征的 Embedding, lookup 操作是比较快速的。对于这类模型，CPU 是能扛得住的。 &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;三、北上 VS 南下路线之争&lt;/strong&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦我们确立了，深度学习和大数据系统融合的目标是，&lt;/span&gt;&lt;span&gt;轻量级的离线以及在线的&lt;/span&gt;&lt;span&gt;大规模&lt;/span&gt;&lt;span/&gt;&lt;span&gt;广告推荐搜索&lt;/span&gt;&lt;span&gt;深度学习模型的&lt;/span&gt;&lt;span&gt;分布式训练组件&lt;/span&gt;&lt;span&gt;，下面就是要确定路线。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在的深度学习和大数据系统融合工作，在做的过程中，可能都没有意识到深度学习和大数据系统融合，其实有两条路线可以走。&lt;/span&gt;&lt;span&gt;哪两条路线呢？&lt;/span&gt;&lt;span&gt;深度学习和大数据系统融合，本质上是将深度学习放置在大数据系统之上，具体做法无非， 1）南下——改下层的大数据系统，使大数据系统能够适应深度学习框架；&lt;/span&gt;&lt;span&gt;2）北上——改上层深度学习框架，使之能运行在大数据系统上。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4978038067349927&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Q3H1TCddfvNzTkibibhTheuCzQ0iakthtziaspzSutCZn1CgYhQH2bLKKNt9g74JGyaFPu4aiatWdcNzuibNhLW2OMcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;683&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;现在不管 TensorFlow on Spark 还是 Horovod on Spark 或者 Flink AI Extend，都是南下 “改大数据系统使之适应深度学习框架” 的路线上的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;南下 “改大数据系统使之适应深度学习框架” 的路线，最大的特点就是简单。&lt;/span&gt;&lt;span&gt;只要大数据系统改动，满足深度学习框架需要的环境就可以了。&lt;/span&gt;&lt;span&gt;但是啊，所有命运赠送的礼物，早已在暗中标好价格。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.9316860465116279&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Q3H1TCddfvNzTkibibhTheuCzQ0iakthtziaWxzTxrDy0cC4nWibQjjWbe2nsDcG8UASbl7W0RA0NaVcQ3K3QDpqjlg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;688&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;简单意味着施展空间太小。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt; 超大规模深度学习能力缺失&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当前的深度学习框架 TensorFlow 和 Pytorch 自带的 PS 模块都相对简单，并不天然具备亿级乃至十亿级规模模型的训练能力。如果只改动大数据系统的话，那么深度学习和大数据系统融合之后，并不具备超大规模深度学习能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; 易用性下降&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;由于是对大数据系统进行改造，因此部署深度学习和大数据系统融合的时候，必须对现有集群进行改造。这样方便性和易用性下降。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt; 稳定性下降&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;大数据系统系统基本上都是 scala 写的，集群分配内存资源是分配给 JVM 的。但是 Tensorflow 和 Pytorch 深度学习框架底层是 C++，可以直接申请机器上的内存。当模型特别大，比如上亿乃至上十亿级 Embedding 模型，C++ 直接申请机器上的内存比较多。训练这类模型的任务多了，很容易冲击大数据集群的内存分配，造成稳定性下降。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那么我们是不是走北上路线—— “改深度学习框架，使之能运行在大数据系统上” 呢？这条路线复杂度高，需要大量的工程工作。具体的工作包括，实现一个 Parameter Server，将这个 Parameter Server 嵌入深度学习框架，改造深度学习框架改变其运行的模式。说起来很简单的样子，但是实现起来好复杂。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;四、当前的形式和我们的任务&lt;/strong&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么我突然又关心起，很久之前关注的深度学习和大数据系统融合呢？&lt;/span&gt;&lt;span&gt;当然是我们在这方面有了一些自己的工作。&lt;/span&gt;&lt;span&gt;这篇文章比较详细地阐释了我们对深度学习和大数据系统融合的理解，这些理解凝聚在我们的工作里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，为了实现我们对深度学习和大数据系统融合的理解，我们引入了一个非常非常奇怪的设定，可能会成为杀死我们工作的达摩克里斯之剑。&lt;/span&gt;&lt;span&gt;这个下篇文章会详细介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.7627118644067796&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Q3H1TCddfvNzTkibibhTheuCzQ0iakthtziaCZSSsWFcsfRNxhoS9BD7mgD9Zlkop7ad0iaWS7bXukPADshNZklyRnQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;413&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们看准了深度学习和大数据系统融合方向的价值，也对当前实现路线有了自己的理解。&lt;/span&gt;&lt;span&gt;那便要躬身入局，全力一搏。&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>dd1bafaf35fb5c1f2fbaa9327c77c095</guid>
<title>面试官：如何写出让 CPU 跑得更快的代码？</title>
<link>https://toutiao.io/k/l6chi61</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6356877323420075&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DU5g3I7vpskPKGc2AVN5icSasGiaxoa1NIJWILJqTibPeibIZv2jkj6ianZSw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1076&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;hr/&gt;&lt;h2&gt;&lt;span&gt;前言&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;代码都是由 CPU 跑起来的，我们代码写的好与坏就决定了 CPU 的执行效率，特别是在编写计算密集型的程序，更要注重 CPU 的执行效率，否则将会大大影响系统性能。&lt;/p&gt;&lt;p&gt;CPU 内部嵌入了 CPU Cache（高速缓存），它的存储容量很小，但是离 CPU 核心很近，所以缓存的读写速度是极快的，那么如果 CPU 运算时，直接从 CPU Cache 读取数据，而不是从内存的话，运算速度就会很快。&lt;/p&gt;&lt;p&gt;但是，大多数人不知道 CPU Cache 的运行机制，以至于不知道如何才能够写出能够配合 CPU Cache 工作机制的代码，一旦你掌握了它，你写代码的时候，就有新的优化思路了。&lt;/p&gt;&lt;p&gt;那么，接下来我们就来看看，CPU Cache 到底是什么样的，是如何工作的呢，又该写出让 CPU 执行更快的代码呢？&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.34772462077012833&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUqltTazYGAUDNlrTfuPx6rgBxLw3ynWVJIQSGAVlM7bc73W4znSPoZg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1714&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;hr/&gt;&lt;h2&gt;&lt;span&gt;正文&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;CPU Cache 有多快？&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;你可能会好奇为什么有了内存，还需要 CPU Cache？根据摩尔定律，CPU 的访问速度每 18 个月就会翻倍，相当于每年增长 60% 左右，内存的速度当然也会不断增长，但是增长的速度远小于 CPU，平均每年只增长 7% 左右。于是，CPU 与内存的访问性能的差距不断拉大。&lt;/p&gt;&lt;p&gt;到现在，一次内存访问所需时间是 &lt;code&gt;200~300&lt;/code&gt; 多个时钟周期，这意味着 CPU 和内存的访问速度已经相差 &lt;code&gt;200~300&lt;/code&gt; 多倍了。&lt;/p&gt;&lt;p&gt;为了弥补 CPU 与内存两者之间的性能差异，就在 CPU 内部引入了  CPU Cache，也称高速缓存。&lt;/p&gt;&lt;p&gt;CPU Cache 通常分为大小不等的三级缓存，分别是 &lt;strong&gt;L1 Cache、L2 Cache 和 L3 Cache&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;由于 CPU Cache 所使用的材料是 SRAM，价格比内存使用的 DRAM 高出很多，在当今每生产 1 MB 大小的 CPU Cache 需要 7 美金的成本，而内存只需要 0.015 美金的成本，成本方面相差了 466 倍，所以 CPU Cache 不像内存那样动辄以 GB 计算，它的大小是以 KB 或 MB 来计算的。&lt;/p&gt;&lt;p&gt;在 Linux 系统中，我们可以使用下图的方式来查看各级 CPU Cache 的大小，比如我这手上这台服务器，离 CPU 核心最近的 L1 Cache 是 32KB，其次是 L2 Cache 是 256KB，最大的 L3 Cache 则是 3MB。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.7211740041928721&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUiaYtfLibicW11HOurkPCxZ6WcY0JHr1oGpcRvyNKsozexRSR3iaUzpulVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;954&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;其中，&lt;strong&gt;L1 Cache 通常会分为「数据缓存」和「指令缓存」&lt;/strong&gt;，这意味着数据和指令在 L1 Cache 这一层是分开缓存的，上图中的 &lt;code&gt;index0&lt;/code&gt; 也就是数据缓存，而 &lt;code&gt;index1&lt;/code&gt; 则是指令缓存，它两的大小通常是一样的。&lt;/p&gt;&lt;p&gt;另外，你也会注意到，L3 Cache 比 L1 Cache 和 L2 Cache 大很多，这是因为 &lt;strong&gt;L1 Cache 和 L2 Cache 都是每个 CPU 核心独有的，而 L3 Cache 是多个 CPU 核心共享的。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;程序执行时，会先将内存中的数据加载到共享的 L3 Cache 中，再加载到每个核心独有的 L2 Cache，最后进入到最快的 L1 Cache，之后才会被 CPU 读取。它们之间的层级关系，如下图：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6649056603773585&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUZic96QWC2PPxCPP9HeOPgzcmfSj9I80u1W15JpyIUib3LbibMpjFTh0Rw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1325&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;越靠近 CPU 核心的缓存其访问速度越快，CPU 访问 L1 Cache 只需要 &lt;code&gt;2~4&lt;/code&gt; 个时钟周期，访问 L2 Cache 大约 &lt;code&gt;10~20&lt;/code&gt; 个时钟周期，访问 L3 Cache 大约 &lt;code&gt;20~60&lt;/code&gt; 个时钟周期，而访问内存速度大概在 &lt;code&gt;200~300&lt;/code&gt; 个 时钟周期之间。如下表格：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5965189873417721&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUwhcPrwJ0d1niaQBKwCcsIvXC5Bm5MibIsgRum9riaEg7z2WibopJGaQQug/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;632&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;所以，CPU 从 L1 Cache 读取数据的速度，相比从内存读取的速度，会快 &lt;code&gt;100&lt;/code&gt; 多倍。&lt;/strong&gt;&lt;/p&gt;&lt;hr/&gt;&lt;h3&gt;&lt;span&gt;CPU Cache 的数据结构和读取过程是什么样的？&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的，而不是按照单个数组元素来读取数据的，在 CPU Cache 中的，这样一小块一小块的数据，称为 &lt;strong&gt;Cache Line（缓存块）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;你可以在你的 Linux 系统，用下面这种方式来查看 CPU 的 Cache Line，你可以看我服务器的 L1 Cache Line 大小是 64 字节，也就意味着 &lt;strong&gt;L1 Cache 一次载入数据的大小是 64 字节&lt;/strong&gt;。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.20949263502454993&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUpgXIYYgic3eJ5SHJNKFVRnLPwCd2qNnEGEichslHoZLWt8GsyEu49Nqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1222&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;比如，有一个 &lt;code&gt;int array[100]&lt;/code&gt; 的数组，当载入 &lt;code&gt;array[0]&lt;/code&gt; 时，由于这个数组元素的大小在内存只占 4 字节，不足 64 字节，CPU 就会&lt;strong&gt;顺序加载&lt;/strong&gt;数组元素到 &lt;code&gt;array[15]&lt;/code&gt;，意味着 &lt;code&gt;array[0]~array[15]&lt;/code&gt; 数组元素都会被缓存在 CPU Cache 中了，因此当下次访问这些数组元素时，会直接从 CPU Cache 读取，而不用再从内存中读取，大大提高了 CPU 读取数据的性能。&lt;/p&gt;&lt;p&gt;事实上，CPU 读取数据的时候，无论数据是否存放到 Cache 中，CPU 都是先访问 Cache，只有当 Cache 中找不到数据时，才会去访问内存，并把内存中的数据读入到 Cache 中，CPU 再从 CPU Cache 读取数据。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5844875346260388&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUfV2liaq9Sm18DGvnOFhxAHpGX1U3GqBwNlyj3W2biaRLeWTsv6NBrdvA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;722&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这样的访问机制，跟我们使用「内存作为硬盘的缓存」的逻辑是一样的，如果内存有缓存的数据，则直接返回，否则要访问龟速一般的硬盘。&lt;/p&gt;&lt;p&gt;那 CPU 怎么知道要访问的内存数据，是否在 Cache 里？如果在的话，如何找到 Cache 对应的数据呢？我们从最简单、基础的&lt;strong&gt;直接映射 Cache（&lt;em&gt;Direct Mapped Cache&lt;/em&gt;）&lt;/strong&gt; 说起，来看看整个 CPU Cache 的数据结构和访问逻辑。&lt;/p&gt;&lt;p&gt;前面，我们提到 CPU 访问内存数据时，是一小块一小块数据读取的，具体这一小块数据的大小，取决于 &lt;code&gt;coherency_line_size&lt;/code&gt; 的值，一般 64 字节。在内存中，这一块的数据我们称为&lt;strong&gt;内存块（&lt;em&gt;Bock&lt;/em&gt;）&lt;/strong&gt;，读取的时候我们要拿到数据所在内存块的地址。&lt;/p&gt;&lt;p&gt;对于直接映射 Cache 采用的策略，就是把内存块的地址始终「映射」在一个 CPU Line（缓存块） 的地址，至于映射关系实现方式，则是使用「取模运算」，取模运算的结果就是内存块地址对应的 CPU Line（缓存块） 的地址。&lt;/p&gt;&lt;p&gt;举个例子，内存共被划分为 32 个内存块，CPU Cache 共有 8 个 CPU Line，假设 CPU 想要访问第 15 号内存块，如果 15 号内存块中的数据已经缓存在 CPU Line 中的话，则是一定映射在 7 号 CPU Line 中，因为 &lt;code&gt;15 % 8&lt;/code&gt; 的值是 7。&lt;/p&gt;&lt;p&gt;机智的你肯定发现了，使用取模方式映射的话，就会出现多个内存块对应同一个 CPU Line，比如上面的例子，除了 15 号内存块是映射在 7 号 CPU Line 中，还有 7 号、23 号、31 号内存块都是映射到 7 号 CPU Line 中。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;1.0351390922401171&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUwLEOS9ugA1Km1PvBQf6zJ9ffp8HzIFBo5AdqI87aUqO25SUUExafHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;683&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;因此，为了区别不同的内存块，在对应的 CPU Line 中我们还会存储一个&lt;strong&gt;组标记（Tag）&lt;/strong&gt;。这个组标记会记录当前 CPU Line 中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。&lt;/p&gt;&lt;p&gt;除了组标记信息外，CPU Line 还有两个信息：&lt;/p&gt;&lt;p&gt;CPU 在从 CPU Cache 读取数据的时候，并不是读取 CPU Line 中的整个数据块，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个&lt;strong&gt;字（&lt;em&gt;Word&lt;/em&gt;）&lt;/strong&gt;。那怎么在对应的 CPU Line 中数据块中找到所需的字呢？答案是，需要一个&lt;strong&gt;偏移量（Offset）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;因此，一个内存的访问地址，包括&lt;strong&gt;组标记、CPU Line 索引、偏移量&lt;/strong&gt;这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。而对于 CPU Cache 里的数据结构，则是由&lt;strong&gt;索引 + 有效位 + 组标记 + 数据块&lt;/strong&gt;组成。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6840363937138131&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUGmFpHBHryZfZCrS1CcXAAXwZq4la5afWIFtIfATQJpGGGBQkicIMcHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1209&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;如果内存中的数据已经在 CPU Cahe 中了，那 CPU 访问一个内存地址的时候，会经历这 4 个步骤：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;根据内存地址中索引信息，计算在 CPU Cahe 中的索引，也就是找出对应的 CPU Line 的地址；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;找到对应 CPU Line 后，判断 CPU Line 中的有效位，确认 CPU Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对比内存地址中组标记和 CPU Line 中的组标记，确认 CPU Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;根据内存地址中偏移量信息，从 CPU Line 的数据块中，读取对应的字。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;到这里，相信你对直接映射 Cache 有了一定认识，但其实除了直接映射 Cache 之外，还有其他通过内存地址找到 CPU Cache 中的数据的策略，比如全相连 Cache （&lt;em&gt;Fully Associative Cache&lt;/em&gt;）、组相连 Cache （&lt;em&gt;Set Associative Cache&lt;/em&gt;）等，这几种策策略的数据结构都比较相似，我们理解流直接映射 Cache 的工作方式，其他的策略如果你有兴趣去看，相信很快就能理解的了。&lt;/p&gt;&lt;hr/&gt;&lt;h3&gt;&lt;span&gt;如何写出让 CPU 跑得更快的代码？&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;我们知道 CPU 访问内存的速度，比访问 CPU Cache 的速度慢了 100 多倍，所以如果 CPU 所要操作的数据在 CPU Cache 中的话，这样将会带来很大的性能提升。访问的数据在 CPU Cache 中的话，意味着&lt;strong&gt;缓存命中&lt;/strong&gt;，缓存命中率越高的话，代码的性能就会越好，CPU 也就跑的越快。&lt;/p&gt;&lt;p&gt;于是，「如何写出让 CPU 跑得更快的代码？」这个问题，可以改成「如何写出 CPU 缓存命中率高的代码？」。&lt;/p&gt;&lt;p&gt;在前面我也提到， L1 Cache 通常分为「数据缓存」和「指令缓存」，这是因为 CPU 会别处理数据和指令，比如 &lt;code&gt;1+1=2&lt;/code&gt; 这个运算，&lt;code&gt;+&lt;/code&gt; 就是指令，会被放在「指令缓存」中，而输入数字 &lt;code&gt;1&lt;/code&gt; 则会被放在「数据缓存」里。&lt;/p&gt;&lt;p&gt;因此，&lt;strong&gt;我们要分开来看「数据缓存」和「指令缓存」的缓存命中率&lt;/strong&gt;。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;如何提升数据缓存的命中率？&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;假设要遍历二维数组，有以下两种形式，虽然代码执行结果是一样，但你觉得哪种形式效率最高呢？为什么高呢？&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;1.3868613138686132&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUaWq5KdzLgGiaTeUj6icIrEgVHbzteS2cMUQlbkEfiawYibpunTLQO08DBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;548&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;经过测试，形式一 &lt;code&gt;array[i][j]&lt;/code&gt;  执行时间比形式二 &lt;code&gt;array[j][i]&lt;/code&gt; 快好几倍。&lt;/p&gt;&lt;p&gt;之所以有这么大的差距，是因为二维数组 &lt;code&gt;array&lt;/code&gt; 所占用的内存是连续的，比如长度 &lt;code&gt;N&lt;/code&gt; 的指是 &lt;code&gt;2&lt;/code&gt; 的话，那么内存中的数组元素的布局顺序是这样的：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.2391304347826087&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DU1V6Raia4HWY3ZAUReO3jbvGHRib59hCUbpRZ612thav03UbGoujvSuSQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;920&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;形式一用 &lt;code&gt;array[i][j]&lt;/code&gt;  访问数组元素的顺序，正是和内存中数组元素存放的顺序一致。当 CPU 访问 &lt;code&gt;array[0][0]&lt;/code&gt; 时，由于该数据不在 Cache 中，于是会「顺序」把跟随其后的 3 个元素从内存中加载到 CPU Cache，这样当 CPU 访问后面的 3 个数组元素时，就能在 CPU Cache 中成功地找到数据，这意味着缓存命中率很高，缓存命中的数据不需要访问内存，这便大大提高了代码的性能。&lt;/p&gt;&lt;p&gt;而如果用形式二的 &lt;code&gt;array[j][i]&lt;/code&gt; 来访问，则访问的顺序就是：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.2391304347826087&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DULaIspIibUC6T3XxxOlc0YRmlI6Wa8nHf1qviaDzxBLoAEdk61tmW4jNg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;920&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;你可以看到，访问的方式跳跃式的，而不是顺序的，那么如果 N 的数值很大，那么操作 &lt;code&gt;array[j][i]&lt;/code&gt; 时，是没办法把 &lt;code&gt;array[j+1][i]&lt;/code&gt; 也读入到 CPU Cache 中的，既然 &lt;code&gt;array[j+1][i]&lt;/code&gt; 没有读取到 CPU Cache，那么就需要从内存读取该数据元素了。很明显，这种不连续性、跳跃式访问数据元素的方式，可能不能充分利用到了 CPU Cache 的特性，从而代码的性能不高。&lt;/p&gt;&lt;p&gt;那访问 &lt;code&gt;array[0][0]&lt;/code&gt; 元素时，CPU 具体会一次从内存中加载多少元素到 CPU Cache 呢？这个问题，在前面我们也提到过，这跟 CPU Cache Line 有关，它表示 &lt;strong&gt;CPU Cache 一次性能加载数据的大小&lt;/strong&gt;，可以在 Linux 里通过 &lt;code&gt;coherency_line_size&lt;/code&gt; 配置查看 它的大小，通常是 64 个字节。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.20949263502454993&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUpgXIYYgic3eJ5SHJNKFVRnLPwCd2qNnEGEichslHoZLWt8GsyEu49Nqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1222&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;也就是说，当 CPU 访问内存数据时，如果数据不在 CPU Cache 中，则会一次性会连续加载 64 字节大小的数据到 CPU Cache，那么当访问 &lt;code&gt;array[0][0]&lt;/code&gt; 时，由于该元素不足 64 字节，于是就会往后&lt;strong&gt;顺序&lt;/strong&gt;读取 &lt;code&gt;array[0][0]~array[0][15]&lt;/code&gt; 到 CPU Cache 中。顺序访问的 &lt;code&gt;array[i][j]&lt;/code&gt; 因为利用了这一特点，所以就会比跳跃式访问的 &lt;code&gt;array[j][i]&lt;/code&gt; 要快。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;因此，遇到这种遍历数组的情况时，按照内存布局顺序访问，将可以有效的利用 CPU Cache 带来的好处，这样我们代码的性能就会得到很大的提升，&lt;/strong&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;如何提升指令缓存的命中率？&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;提升数据的缓存命中率的方式，是按照内存布局顺序访问，那针对指令的缓存该如何提升呢？&lt;/p&gt;&lt;p&gt;我们以一个例子来看看，有一个元素为 0 到 100 之间随机数字组成的一维数组：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5985401459854015&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DU9LLoj74jOfcObSSxeWI3Rc3mgkbJ51n7jAKiajAjxTfSPJB4XrAJ5rg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;548&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;接下来，对这个数组做两个操作：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.927007299270073&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DULmPvhCfBh9RvNIa8TRCZasTczRGWsTVk75zwo76mAWeGwkaEndYn2A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;548&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;figure&gt;&lt;br/&gt;&lt;/figure&gt;&lt;p&gt;那么问题来了，你觉得先遍历再排序速度快，还是先排序再遍历速度快呢？&lt;/p&gt;&lt;p&gt;在回答这个问题之前，我们先了解 CPU 的&lt;strong&gt;分支预测器&lt;/strong&gt;。对于 if 条件语句，意味着此时至少可以选择跳转到两段不同的指令执行，也就是 if 还是 else 中的指令。那么，&lt;strong&gt;如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;当数组中的元素是随机的，分支预测就无法有效工作，而当数组元素都是顺序的，分支预测器会动态地根据历史命中数据对未来进行预测，这样命中率就会很高。&lt;/p&gt;&lt;p&gt;因此，先排序再遍历速度会更快，这是因为排序之后，数字是从小到大的，那么前几次循环命中 &lt;code&gt;if &amp;lt; 50&lt;/code&gt; 的次数会比较多，于是分支预测就会缓存 &lt;code&gt;if&lt;/code&gt; 里的 &lt;code&gt;array[i] = 0&lt;/code&gt; 指令到 Cache 中，后续 CPU 执行该指令就只需要从 Cache 读取就好了。&lt;/p&gt;&lt;p&gt;如果你肯定代码中的 &lt;code&gt;if&lt;/code&gt; 中的表达式判断为 &lt;code&gt;true&lt;/code&gt; 的概率比较高，我们可以使用显示分支预测工具，比如在 C/C++ 语言中编译器提供了 &lt;code&gt;likely&lt;/code&gt; 和 &lt;code&gt;unlikely&lt;/code&gt; 这两种宏，如果 &lt;code&gt;if&lt;/code&gt; 条件为 &lt;code&gt;ture&lt;/code&gt; 的概率大，则可以用 &lt;code&gt;likely&lt;/code&gt; 宏把 &lt;code&gt;if&lt;/code&gt; 里的表达式包裹起来，反之用 &lt;code&gt;unlikely&lt;/code&gt; 宏。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5539906103286385&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUzOCKyzJmM68G89T8hSbibBuEch9QQQF0IY59uUtfibN3Fn2rTt5whcJg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;852&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;实际上，CPU 自身的动态分支预测已经是比较准的了，所以只有当非常确信 CPU 预测的不准，且能够知道实际的概率情况时，才建议使用这两种宏。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;如果提升多核 CPU 的缓存命中率？&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;在单核 CPU，虽然只能执行一个进程，但是操作系统给每个进程分配了一个时间片，时间片用完了，就调度下一个进程，于是各个进程就按时间片交替地占用 CPU，从宏观上看起来各个进程同时在执行。&lt;/p&gt;&lt;p&gt;而现代 CPU 都是多核心的，进程可能在不同 CPU 核心来回切换执行，这对 CPU Cache 不是有利的，虽然 L3 Cache 是多核心之间共享的，但是 L1 和 L2 Cache 都是每个核心独有的，&lt;strong&gt;如果一个进程在不同核心来回切换，各个核心的缓存命中率就会受到影响&lt;/strong&gt;，相反如果进程都在同一个核心上执行，那么其数据的 L1 和 L2 Cache 的缓存命中率可以得到有效提高，缓存命中率高就意味着 CPU 可以减少访问 内存的频率。&lt;/p&gt;&lt;p&gt;当有多个同时执行「计算密集型」的线程，为了防止因为切换到不同的核心，而导致缓存命中率下降的问题，我们可以把&lt;strong&gt;线程绑定在某一个 CPU 核心上&lt;/strong&gt;，这样性能可以得到非常可观的提升。&lt;/p&gt;&lt;p&gt;在 Linux 上提供了 &lt;code&gt;sched_setaffinity&lt;/code&gt; 方法，来实现将线程绑定到某个 CPU 核心这一功能。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.23548387096774193&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUvZ5zh4RImou6azJ9KMevyTDPcTHLffjYgxyckdaggftIY6hJgiarkYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1240&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;hr/&gt;&lt;h3&gt;&lt;span&gt;总结&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;由于随着计算机技术的发展，CPU 与 内存的访问速度相差越来越多，如今差距已经高达好几百倍了，所以 CPU 内部嵌入了 CPU Cache 组件，作为内存与 CPU 之间的缓存层，CPU Cache 由于离 CPU 核心很近，所以访问速度也是非常快的，但由于所需材料成本比较高，它不像内存动辄几个 GB 大小，而是仅有几十 KB 到 MB 大小。&lt;/p&gt;&lt;p&gt;当 CPU 访问数据的时候，先是访问 CPU Cache，如果缓存命中的话，则直接返回数据，就不用每次都从内存读取速度了。因此，缓存命中率越高，代码的性能越好。&lt;/p&gt;&lt;p&gt;但需要注意的是，当 CPU 访问数据时，如果 CPU Cache 没有缓存该数据，则会从内存读取数据，但是并不是只读一个数据，而是一次性读取一块一块的数据存放到 CPU Cache 中，之后才会被 CPU 读取。&lt;/p&gt;&lt;p&gt;内存地址映射到 CPU Cache 地址里的策略有很多种，其中比较简单是直接映射 Cache，它巧妙的把内存地址拆分成「索引 + 组标记 + 偏移量」的方式，使得我们可以将很大的内存地址，映射到很小的 CPU Cache 地址里。&lt;/p&gt;&lt;p&gt;要想写出让 CPU 跑得更快的代码，就需要写出缓存命中率高的代码，CPU L1 Cache 分为数据缓存和指令缓存，因而需要分别提高它们的缓存命中率：&lt;/p&gt;&lt;p&gt;另外，对于多核 CPU 系统，线程可能在不同 CPU 核心来回切换，这样各个核心的缓存命中率就会受到影响，于是要想提高进程的缓存命中率，可以考虑把线程绑定 CPU 到某一个 CPU 核心。&lt;/p&gt;&lt;hr/&gt;&lt;h2&gt;&lt;span&gt;絮叨&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;分享个喜事，小林平日里忙着输出文章，今天收到一份特别的快递，是 CSDN 寄来的奖状。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6587360594795539&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/J0g14CUwaZcKapyUj66hkhTng5Zof8DUZ0IFb8hhbujk32TmfGFhf050tBp0Y99Z45Ee6v0PwhnjVq73FsDEVA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1345&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;骄傲的说，你们关注的是 CSDN 首届技术原创第一名的博主，以后简历又可以吹牛逼了&lt;/p&gt;&lt;p&gt;没有啦，其实主要还是&lt;strong&gt;谢谢你们不离不弃的支持&lt;/strong&gt;。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5902612826603325&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcKapyUj66hkhTng5Zof8DUVwlCFh1n6JlGk9YqHE2t6sNc4UfFw0Za60dcwsambuF9A16w06086A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;842&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;em&gt;哈喽，我是小林，就爱图解计算机基础，如果觉得文章对你有帮助，欢迎分享给你的朋友，也给小林点个「在看」，这对小林非常重要，谢谢你们，给各位小姐姐小哥哥们抱拳了，我们下次见！&lt;/em&gt;&lt;/p&gt;&lt;hr/&gt;&lt;h5&gt;&lt;span&gt;推荐阅读&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;这个星期不知不觉输出了 3 篇文章了，前面的 2 篇还没看过的同学，赶紧去看看呀！&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&amp;amp;mid=2247485960&amp;amp;idx=1&amp;amp;sn=476d40b3e272149ba6c7370340e9768f&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;天啦噜！知道硬盘很慢，但没想到比 CPU Cache 慢 10000000 倍&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&amp;amp;mid=2247485918&amp;amp;idx=1&amp;amp;sn=f7fa3aa2a7cc362eeebad09d4d6fa03a&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt;CPU 执行程序的秘密，藏在了这 15 张图里&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>