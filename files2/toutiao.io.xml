<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>f8d08c2cd899b197a64121906a95c096</guid>
<title>仙女逗猫棒自嗨解闷神器，点击链接立即下单！</title>
<link>https://toutiao.io/k/1f9ycl7</link>
<content:encoded>&lt;div&gt;&lt;body id=&quot;readabilityBody&quot;&gt;


&lt;/body&gt;
&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d40ba7b5bb696d353f0f2927d20c40cf</guid>
<title>JuiceFS 即将发布 1.0 并调整开源许可</title>
<link>https://toutiao.io/k/ggg0uey</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;post_content markdown&quot;&gt;&lt;h2 id=&quot;开源一周年&quot;&gt;开源一周年&lt;/h2&gt;&lt;p&gt;JuiceFS 开始于 2017 年，是一款云原生分布式文件系统，旨在帮助企业解决多云、跨云、混合云环境下所面临的诸多挑战：数据安全和保护、大数据架构升级、海量小文件访问、Kubernetes 标准存储等。 JuiceFS 完全兼容 POSIX、HDFS、S3 访问协议，并提供 Kubernetes CSI 驱动，在全球公有云上均有全托管服务。为了更好的打造让开发者爱不释手的软件，我们于 2021 年 1 月 11 日在 GitHub 上开源了 JuiceFS。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;今天， JuiceFS 已经开源一周年了！&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;一年前的今天，我们将 JuiceFS 在 GitHub 上开源，初心其实很简单：&lt;strong&gt;希望通过开源让 JuiceFS 被更多的开发者知道、了解、并使用。&lt;/strong&gt;毕竟软件最大的价值还是被使用。开源后的 JuiceFS 让用户不再担心黑盒的云服务，用户可以自行下载代码，探索 JuiceFS 的无限可能；开发者可以查阅 JuiceFS 的代码，从最底层了解、熟悉、信任他，甚至可以参与到 JuiceFS 的打造中。我们希望营造一个互相尊重的社区文化，身处其中不仅可以使用 JuiceFS，也可以在这交流新场景、新玩法，还可以讨论 JuiceFS 的工程设计理念和参与未来方向的制定。&lt;/p&gt;&lt;p&gt;开发者们对 JuiceFS 开源的反馈也超出我们的预期，开源第一周就登上了 GitHub Trending、Hacker News、InfoQ 等以开发者为主要受众的的媒体平台。&lt;/p&gt;&lt;p&gt;经过一年的时间，JuiceFS 在社区和产品都取得了长足的进步，但行百里者半九十，我们深知坚持的难度，也将继续怀着开放和连接的心态砥砺前行。&lt;/p&gt;&lt;h2 id=&quot;产品全面升级-更加开放&quot;&gt;产品全面升级，更加开放&lt;/h2&gt;&lt;p&gt;JuiceFS 刚开源时，元数据引擎的选择只有 Redis。存储介质为内存的 Redis 在数据可靠性和扩展性上存在诸多挑战。我们将元数据引擎的相关代码进行了可插拔改造，引入了对关系型数据库和像 TiKV 这样的事务型 KV 存储的支持，解决了可靠性和可扩展性问题，给了用户更多的选择。&lt;/p&gt;&lt;p&gt;作为 JuiceFS 数据持久层的对象存储，我们也支持了近 40 种，基本涵盖了公有云、边缘云、私有云等环境中部署使用的常见种类。当然，如果有遗漏欢迎 GitHub 上发起 issue，我们将尽快支持。拓宽 JuiceFS 的生态和提升 JuiceFS 开放性是我们矢志不渝的追求。&lt;/p&gt;&lt;p&gt;最开始的 JuiceFS 只支持应用最广泛的 POSIX API，此后陆续支持了 HDFS、S3 API，和 Kubernetes CSI 和 Windows 操作系统，未来我们还将支持更多更灵活的访问方式。 这些协议点缀成线，将散落在企业内部的数据孤岛，编织成网，更好的帮助企业打通多态业务系统的数据，整合不同的技术体系，连接多云，帮助客户搭建更加开放的数据存储平台。&lt;/p&gt;&lt;p&gt;JuiceFS 还提供了元数据的备份和导入功能，让用户在「意外」面前更多一份保障和可靠。 这一功能给予了用户按照 JSON 格式进行备份的能力，提高数据可读性的同时，也保证了数据在不同元数据引擎间的可交换性。最后，可靠的 JuiceFS 还提供了 &lt;strong&gt;「回收站」&lt;/strong&gt; 的功能，在这里可以找到那些被误删除的数据。&lt;/p&gt;&lt;p&gt;除了在产品开放性上的持续投入，我们还将目光放到了文档的开放性和易用性上。我们深刻理解，文档是用户与产品之间重要的纽带！自 JuiceFS 开源以来，我们始终坚持高品质的技术与高品质的文档并行输出的原则。2021 年，我们对文档进行了三次完整迭代，实现了&lt;strong&gt;文档从「专业性」到「普适性」，再到「体验性」的持续蜕变。&lt;/strong&gt;优化文档的工作仍在继续，努力确保 JuiceFS 的文档能够 &lt;strong&gt;「让新用户马上用」，「让老用户放心用」&lt;/strong&gt;。除了文档的工作以外，在快速的版本迭代中，JuiceFS 也一直保持数据格式、通信协议的兼容性，保证版本的向前兼容，让用户可以平滑升级。&lt;/p&gt;&lt;p&gt;JuiceFS 开源的一年里，产品也有了巨大的变化，也让我们更加坚定走开源路线是无比正确的，因为只有开放的生态是最具生命力的。&lt;/p&gt;&lt;h2 id=&quot;丰富场景落地-生态共建&quot;&gt;丰富场景落地，生态共建&lt;/h2&gt;&lt;p&gt;JuiceFS 开源的一年里，依托我们的开源社区，我们完成了开发者和代码贡献、用户和使用场景的连接。&lt;/p&gt;&lt;p&gt;在短短的一年时间里，有超过 4400 多位的开发者给 JuiceFS 点了个赞。这些开发者不仅仅来自于中国，也有来自于欧洲、美洲大陆、非洲，甚至中东的地区的开发者。新冠疫情虽然隔断了我们物理上的联系，但开源社区让我们齐聚一堂，一起在过去的 2021年，为 JuiceFS 的社区添砖加瓦。过去的一年里有超过 40 位贡献者完成了超过 800 次 Pull Requests，这是我们通过 GitHub 和开发者群体完成的 800 次连接。在这 800 次连接的加持下，JuiceFS 发布了 16 次新版本，这些背后默默关注 JuiceFS 的社区用户，让我们压力倍增的同时也给我们满满的动力。&lt;/p&gt;&lt;p&gt;基于微信和 Slack 的社群，搭建了超过 1500 人的用户交流群组，参与了 9 场活动，大家从使用出发，满载而归的是 33 篇关于 JuiceFS 的技术内容和场景实践。在这里，我们连接了场景和用户。文件系统是各种应用开发的基石，如何与其他应用结合，提供杰出的表现和良好的体验，形成生态，是 JuiceFS 社区的重要工作。在过去的一年中，JuiceFS 已经在一些领域受到了大家的认可，取得了不错的进展。&lt;/p&gt;&lt;h3 id=&quot;大数据生态&quot;&gt;大数据生态&lt;/h3&gt;&lt;p&gt;JuiceFS 可以完全兼容 HDFS，与 Hadoop 生态无缝集成，一些客户已经替换了 HDFS实现存算分离的架构升级。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Apache Kylin 4.0 发布了使用 JuiceFS 构建集群的解决方案。&lt;/li&gt;&lt;li&gt;利用 ClickHouse 和 Elasticsearch 的数据生命周期特性，JuiceFS 可以轻松实现数据分层存储，为用户增效降本。&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;ai-生态&quot;&gt;AI 生态&lt;/h3&gt;&lt;p&gt;JuiceFS 多访问协议的支持可以大量省去业务流程中数据迁移调度工作，与主流机器学习、深度学习训练框架全部兼容。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;旷视技术团队还贡献了 JuiceFS Python SDK，方便在 Serverless 环境中访问 JuiceFS 数据。&lt;/li&gt;&lt;li&gt;JuiceFS 缓存加速是 AI 训练场景最受欢迎的特性，PaddlePaddle 已经将 JuiceFS 集成到 Paddle Operator 中为训练加速。&lt;/li&gt;&lt;li&gt;云知声团队的伙伴为 Fluid 社区贡献了 JuiceFSRuntime。&lt;/li&gt;&lt;li&gt;向量搜索引擎 Milvus 也发布了基于 JuiceFS 构建分布式集群的解决方案。&lt;/li&gt;&lt;li&gt;Byzer 社区也将 JuiceFS 作为云原生文件系统集成到自己的解决方案中。&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;kubernetes-生态&quot;&gt;Kubernetes 生态&lt;/h3&gt;&lt;p&gt;JuiceFS 非常适合作为 PV（PersistentVolume）使用，是容器原生存储(Container Native Storage)。社区提供了 CSI 驱动和全面的文档指南，而且已经入驻了 KubeSphere 应用商店，在 Rancher 和云托管的 Kubernetes 服务中使用也同样简单。&lt;/p&gt;&lt;p&gt;在使用 JuiceFS 的朋友，也希望把你的经验和问题反馈到 JuiceFS 社区，不仅能得到支持和帮助，还能让你的经验帮到很多人，这正是开源社区的价值和魅力。&lt;/p&gt;&lt;h2 id=&quot;多行业生产环境验证-juicefs-1-0-来了&quot;&gt;多行业生产环境验证，JuiceFS 1.0 来了&lt;/h2&gt;&lt;p&gt;对于存储系统而言，可靠性永远排在第一位。JuiceFS 创新性地将元数据和数据分别保存到成熟的数据库和对象存储中，一开始就有了可靠性保证，这也是众多科技公司在能够在 JuiceFS 发布半年内就投入生产环境并保证稳定运行的关键所在。依托于标准访问协议，JuiceFS 采用了开源社区已有的测试集来保证兼容性和可靠性，还有各种单元测试、压力测试、混沌测试和性能测试保障，在产品快速迭代的同时保证每次版本发布的高品质。&lt;/p&gt;&lt;p&gt;JuiceFS 开源的一年里，已经有小米、Shopee、理想汽车、知乎、航天宏图、尧信等多家厂商在生产环境中部署了 JuiceFS，稳定运行半年以上:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;小米用 JuiceFS 做 AI 平台的存储底座。&lt;/li&gt;&lt;li&gt;Shopee 将 JuiceFS 作为云平台的文件存储服务提供给各业务线，支持了多样的业务场景。&lt;/li&gt;&lt;li&gt;理想汽车用 JuiceFS 实现了数仓的存算分离。&lt;/li&gt;&lt;li&gt;知乎用 JuiceFS 把 Flink 流计算的启动加载提速 4 倍。&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;JuiceFS 已经稳定持续的运行多家互联网和 AI 企业的生产环境中，不仅仅为客户降本，更为客户提升数据使用的效率和缩短新业务上线的周期，当然内置的数据保护和加密也让客户大大宽心。在过去的一年里，每天在线的 JuiceFS 集群数量也稳步上升，从最初的几个，到现在的超过 500，保持了较高的增长速率。值得一提的是，这仅仅是我们有记录的数据，相信还有很多我们没联系到的用户。&lt;/p&gt;&lt;p&gt;在国内外互联网、自动驾驶、基因测序、金融科技、智能制造等多个行业，以及广大社区开发者的支持、验证和持续反馈之下，经过全面的评估和各类场景下的验证，&lt;strong&gt;JuiceFS 社区将于本周发布 JuiceFS v1.0-beta&lt;/strong&gt;，欢迎社区用户测试并给我们反馈，根据反馈改进后发布 v1.0-GA。&lt;/p&gt;&lt;h2 id=&quot;重新思考开源许可&quot;&gt;重新思考开源许可&lt;/h2&gt;&lt;p&gt;回到 2021 年发布之初，JuiceFS 只支持在挂载后通过 POSIX 方式访问数据，应用是通过内核来访问数据，并不需要直接跟 JuiceFS 打交道，应用并不会被 GPL 系列的许可影响，所以当时采用了文件存储界使用最广泛的 GPL 许可（AGPL v3）。&lt;/p&gt;&lt;p&gt;随着 JuiceFS 的不断迭代，引入了更多的访问协议和 SDK（S3 兼容的 HTTP 协议以及跟 HDFS兼容的 Java SDK），影响用户基于它们去开发商业产品。同时，也有一些开源社区和开发者希望将 JuiceFS 作为存储底座，整合到自己的项目中，但 AGPL v3 与其他开源协议（比如 Apache 协议）的兼容性不太好，阻碍了更多人去享受 JuiceFS 提供的多协议互通和高效缓存系统等诸多便利。&lt;/p&gt;&lt;p&gt;所以，为了我们的初心——打造开发者最喜欢的存储产品，&lt;strong&gt;Juicedata 团队决定自 JuiceFS v1.0 起将许可更改为 Apache 2.0&lt;/strong&gt;。&lt;/p&gt;&lt;h2 id=&quot;重新定义文件存储-未来可期&quot;&gt;重新定义文件存储，未来可期&lt;/h2&gt;&lt;p&gt;JuiceFS v1.0 是一个重要的里程碑，代表它可以被放心的使用于各种场景的生产环境，开始接受更多更严苛的挑战。之后社区仍将持续加大投入，持续为大家带来更多有价值的特性，比如呼声最高的配额管理，Snapshot，支持更多元数据引擎等。&lt;/p&gt;&lt;p&gt;随着数据规模的快速增长，分布式文件系统愈发重要。传统分布式文件系统都采用自底向上的一整套系统，复杂度高，难以掌握。&lt;strong&gt;JuiceFS 创新性地分离元数据和数据存储，并尽量复用已有的成熟数据库和对象存储等基础设施，访问协议也是同时兼容所有主流的接口，将分布式文件系统的系统复杂度和使用门槛大幅降低，重新定义了分布式文件系统的构建方式，通过一套体系和不同组件的搭配，可以满足不同规模和场景的非结构化存储需求。&lt;/strong&gt;同时，JuiceFS 是完全云原生的设计，可以跟云上的生态很好地衔接，符合云存储发展的大趋势，有非常广泛的应用前景。&lt;/p&gt;&lt;p&gt;尽管 JuiceFS 已经做了非常多的减法，尽量避免重复造轮子，打造成熟可靠的存储产品仍然需要巨大的工程投入。我们在过去一年里也进一步壮大了工程师团队，很多都是从 JuiceFS 社区的参与到加入 Juicedata 团队，也欢迎更多志同道合的同学们加入，一起开创分布式文件存储的新时代。&lt;/p&gt;&lt;p&gt;开源产品的研发，需要持续的资金投入，我们花了 4 年验证过的商业化服务也在快速增长，为 JuiceFS 的发展提供持续可靠的资金保障。开源是我们的星辰大海，商业化为它保障护航。&lt;/p&gt;&lt;p&gt;道阻且长，但行则将至！&lt;/p&gt;&lt;h2 id=&quot;用户寄语&quot;&gt;用户寄语&lt;/h2&gt;&lt;blockquote&gt;&lt;p&gt;按姓氏首字母排序&lt;/p&gt;&lt;/blockquote&gt;&lt;p/&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>2f61baa7fea3d61909ee93aca1366309</guid>
<title>SRE实战(02)Clickhouse在好大夫服务治理中的落地应用</title>
<link>https://toutiao.io/k/5sm7ge2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzUxOTg4NDAxMg==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHckm30ntrWF1lvbNOuHe4CIsuyHnQzuic3lrU8gpVn8BKiaTfqsbmtKykTZlRxoOtwD47QJukbALZBtQ/0?wx_fmt=png&quot; data-nickname=&quot;HaoDF技术团队&quot; data-alias=&quot;haodf_tech&quot; data-signature=&quot;好大夫在线技术实践与分享，欢迎大家一起交流！更欢迎加入我们，一起用“科技创造优质医疗”！&quot; data-from=&quot;0&quot;/&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6171875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXnoW2xYhRmEg78icv3ANxAqWDiayDL8P5WegGjo7d9Vv1icI0nhKMU3oIww/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我有一剑，可搬山，可填海！&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;上一篇分享了SRE的相关理论、概念，以及如何&lt;span&gt;从技术债务&lt;/span&gt;&lt;span&gt;入手来推进SRE建设&lt;/span&gt;（见：&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUxOTg4NDAxMg==&amp;amp;mid=2247484061&amp;amp;idx=1&amp;amp;sn=2b74a7ad1962eede684f08be413ccf54&amp;amp;chksm=f9f39f1ece84160876e2adeb21bdf6598a438028136e65cf81da4c39711c0fed4f5a8edae4f6&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;SRE实战(01) 初识+探索SRE如何推进好大夫在线技术债务改造&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;SRE实战(01) 初识+探索SRE如何推进好大夫在线技术债务改造&lt;/a&gt;），本篇再来聊一聊建设落地过程中遇到的一大问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着SRE的概念逐步推广，越来越多的业务接入微服务治理平台，大量数据也随之而来，&lt;span&gt;ElasticSearch&lt;/span&gt;对海量日志的实时分析逐渐出现了性能问题。&lt;/span&gt;&lt;span&gt;另外，随着治理平台自身的发展以及各种监控大盘的陆续上马，业务研发对&lt;/span&gt;&lt;span&gt;日志可视化的实时性要求也&lt;/span&gt;&lt;span&gt;越来越高，查询的数据规模和范围也越来越大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了不让平台建设拖SRE落地的后腿，经过调研，我们最终选择了Clickhouse这一新生利器。接下来我来汇报一下，Clickhouse在好大夫微服务治理中是如何落地实&lt;/span&gt;&lt;span&gt;战的。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;微服务治理暴露出的数据存储问题&lt;/h3&gt;&lt;p&gt;随着微服务架构在好大夫的推进，带来了诸多便利，同时服务间调用越来越复杂，也面临了一系系列难题：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;如何离线分析识别出不合理的服务依赖?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;基于链路分析如何快速定位问题？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如何控制成本存储亿级日志数据?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如何从亿级数据里提炼分析出有价值的指标？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如何实时分析亿级数据及时触发告警？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;针对长期指标如何选存储引擎？&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如何聚拢不同的数据源打造友好的可视化界面?&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;...&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;运营好微服务离不开三种数据分析：Metrics,Tracing,Logging。&lt;/p&gt;&lt;p&gt;首先Tracing日志反映微服务间的链路拓扑，分析服务性能，追踪定位链路问题。也就是常说的APM (Application Performance Management) 即应用性能管理分析。好大夫APM分析，是基于自研的TraceLog模型。&lt;/p&gt;&lt;p&gt;另外一类日志是服务运行时产生的log,如nginx,tomcat,服务自定义的日志等，好大夫服务运行时产生的日志LocalLog也有自己的一套规范。&lt;/p&gt;&lt;p&gt;Metrics主要用于监控告警，大部分指标提炼于Tracing和Logging。好大夫早期日志存储分析基于ELK体系，服务运行监控告警也是实时从ES数据源读取。APM则是离线分析后进行数据展示。&lt;/p&gt;&lt;p&gt;随着业务的发展，日志在不断增加，Elasticsearch存储压力越来越大，磁盘IO瓶颈逐渐显现。&lt;/p&gt;&lt;p&gt;另外告警项的增加，对时效性要求也越来越高，ES实时查询压力骤增。&lt;/p&gt;&lt;p&gt;APM部分场景需要实时查询，聚合，计算同比、环比等，原先的spark体系按不同维度离线分析的模式不再灵活，离线还带来了存储成本的骤增，分析后的数据比原始数据还要大，聚合的时间维度比较粗。不太满足实时异常定位分析。&lt;/p&gt;&lt;p&gt;再加上云原生的推进，产生的日志事件，传统的模式对云原生资源监控更加力不从心，从而引入了Prometheus体系。而Prometheus生态对长期持久化指标不太友好。&lt;/p&gt;&lt;p&gt;针对以上问题，一种主流的方案会选择拥抱大数据生态，Hadoop,Hiv,Storm,Spark,Flink等。&lt;/p&gt;&lt;h3&gt;十字路口的抉择&lt;/h3&gt;&lt;p&gt;基于成本和应用场景考虑，我们否定了Hadoop/Spark解决方案！&lt;/p&gt;&lt;p&gt;世间没有银弹，Hadoop体系也不例外。Hadoop/Spark体系高度集成化，在提供了巨大的方便同时，也带来了臃肿和复杂，各种组件强强组合，有时候显得过于笨重，也带来了巨大成本。&lt;/p&gt;&lt;p&gt;机器资源成本 + 运维成本 + 人力成本。&lt;/p&gt;&lt;p&gt;Hbase/Hiv存储基于物理机，再加上计算节点需要十多台物理机。整体部署的成本和运维成本都比较高。&lt;/p&gt;&lt;p&gt;再者系统架构组内成员趋向Golang开发，而大数据生态偏向Java。&lt;/p&gt;&lt;p&gt;同时大数据部门和系统架构部分属两个不同的组织架构，根据“康威定律”，这将带来的巨大的无形沟通成本。&lt;/p&gt;&lt;p&gt;那有没有不依赖Hadoop生态体系的解决方案呢？&lt;/p&gt;&lt;p&gt;&lt;span&gt;回到原点&lt;/span&gt;&lt;/p&gt;&lt;p&gt;其实我们更多的使用场景是：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;实时性: 实时查询服务QPS/P99&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;按不同维度聚合数据生成相应的指标: 服务接口维度指标，QPS/P99/错误率&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;长期存储数据支持降准稀疏: 服务长期趋势指标，QPM/P99/服务拓扑关系&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;高频大批量写入，低频查询: 亿级TPS日志写入，分钟级别读取&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多维度列式查询：不同维度的下钻，上卷，切面，切块，旋转&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数据压缩比高：吃住原先由Elasticsearch/Prometheus每日生成TB级别的日志&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;丰富的函数库，丰富的数据类型: 统计函数/分位数/数组函数等&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;原生支持分布式集群，多副本，多分区，高效的索引，丰富的引擎: 查询秒级响应&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;先看一下数据库全景图，数据存储种类比较丰富，关系型数据库OLTP/OLAP，非关系型NoSQL。有支持列式存储，有支持时序性存储等等，针对不同的应用场景，精细划分。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7620221948212084&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXnibcr4anhztDGJR5cXmXXQukf3nLVJJ0sS1U2ibvzkK8nVR6CxNjN2znA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;811&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;经过调研我们的应用场景是一种典型的OLAP模式，随着调研的深入Clickhouse进入视野，它高效的性能让我们感到惊叹。&lt;/p&gt;&lt;p&gt;在单个节点的情况下，对一张拥有133个字段的数据表分别在1000万、1亿和10亿三种数据体量下执行基准测试，基准测试的范围涵盖43项SQL查询。在1亿数据集体量的情况下，ClickHouse的平均响应速度是Vertica的2.63倍、InfiniDB的17倍、MonetDB的27倍、Hive的126倍、MySQL的429倍以及Greenplum的10倍。不同类型的数据库对比参考附录，这里给一个CLickhouse与Mysql性能对比图。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4564814814814815&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXnxFFDZ1rFFXt3dcP6skibWoFhOcM5UtibtgQmcp6yjhZZ0TtyjaE7lpicQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最终基于功能、性能、成本考虑，我们选择了Clickhouse。&lt;/p&gt;&lt;h3&gt;OLAP领域的黑马&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2815533980582524&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXnxAWibnwQaWtyw04OCX5YMBxQ8RFg5vX1gLAaMM93WGH6UIKU6picbAlA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Clickhouse是俄罗斯yandex公司于2016年开源的一个列式数据库管理系统，在OLAP领域像一匹黑马一样，以其超高的性能受到业界的青睐。&lt;/p&gt;&lt;p&gt;&lt;span&gt;Clickhouse 为何这么优秀&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;完备的DBMS功能(Database Management System，数据库管理系统)&lt;/p&gt;&lt;p&gt;支持DDL/DML/权限控制/备份恢复/分布式管理等等&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;列式存储与数据压缩&lt;/p&gt;&lt;p&gt;同一列的数据往往有更高的共性，这意味着能有更高的压缩比。在Yandex.Metrica的生产环境中，数据总体的压缩比可以达到8:1（未压缩前17PB，压缩后2PB）。列式存储除了降低IO和存储的压力之外，还为向量化执行做好了铺垫。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;向量化引擎与SIMD提高了CPU利用率，多核多节点并行化大查询&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了实现向量化执行，需要利用CPU的SIMD指令。SIMD的全称是Single Instruction Multiple Data，即用单条指令操作多条数据。现代计算机系统概念中，它是通过数据并行以提高性能的一种实现方式（其他的还有指令级并行和线程级并行），它的原理是在CPU寄存器层面实现数据的并行操&lt;/p&gt;&lt;p&gt;ClickHouse共拥有合并树、内存、文件、接口和其他6大类20多种表索引，根据不同的场景选择不同的引擎，而不是开发一种引擎适配多种场景。&lt;/p&gt;&lt;p&gt;由于SIMD不适合用于带有较多分支判断的场景，ClickHouse也大量使用了多线程技术以实现提速，以此和向量化执行形成互补。&lt;/p&gt;&lt;p&gt;ClickHouse采用Multi-Master多主架构，集群中的每个节点角色对等，天然规避了单点故障的问题，非常适合用于多数据中心、异地多活的场景。&lt;/p&gt;&lt;p&gt;数据分片是将数据进行横向切分，这是一种在面对海量数据的场景下，解决存储和查询瓶颈的有效手段。ClickHouse提供了本地表（Local Table）与分布式表（Distributed Table）的概念。借助分布式表，能够代理访问多个数据分片，从而实现分布式查询。&lt;/p&gt;&lt;p&gt;&lt;span&gt;不足：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应用场景&lt;/span&gt;&lt;/p&gt;&lt;p&gt;ClickHouse 更适用于作为一个数据分析的数据库，它非常擅长针对于干净的，结构化的，不变的日志/事件数据进行分析。例如下述场景：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;✓ 网页及APP分析(Web and App analytics)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;✓ 广告网络以及广告投放(Advertising networks and RTB)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;✓ 通信领域(Telecommunications)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;✓ 在线电商以及金融(E-commerce and finance)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;✓ 信息安全(Information security)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;✓ 监控遥测(Monitoring and telemetry)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;✓ 时序数据(Time series)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;✓ 商业分析(Business intelligence)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;✓ 网友(Online games)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;✓ 物联网(Internet of Things)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如下场景一般不适用 ClickHouse&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;✕ 事务处理(Transactional workloads (OLTP))&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;✕ 高频次的K-V 请求(Key-value requests with a high rate)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;✕ 文件块存储(Blob or document storage)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;✕ 过度normalized 的数据(Over-normalized data)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Clickhouse在微服务治理中的具体实战&lt;/h3&gt;&lt;p&gt;&lt;span&gt;应用拓扑&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7506527415143603&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXnoz4ibldD8aicibsWQRtYhHEn1r0aB0MVbzkRnWZZrpUtkdUUY1cWzkeNw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;766&quot;/&gt;&lt;/p&gt;&lt;p&gt;实战心得&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1.选择合适的引擎&lt;/p&gt;&lt;p&gt;Clickhouse有众多的数据库引擎，&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;MergeTree是基础引擎，有主键索引、数据分区、数据副本、数据采样、删除和修改等功能，&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ReplacingMergeTree 有了去重功能，&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SummingMergeTree 有了汇总求和功能，&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AggregatingMergeTree 有聚合功能，&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;CollapsingMergeTree 有折叠删除功能，&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;VersionedCollapsingMergeTree 有版本折叠功能，&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;GraphiteMergeTree 有压缩汇总功能。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在这些的基础上还可以叠加Replicated和Distributed。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Integration系列用于集成外部的数据源，常用的有HADOOP，MySQL。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;例如日志存储，目前Es也冗余了全量的日志，于是对Clickhouse存储异常有较高的容忍度。我们选取了Distributed + MergeTree模式，这里为了控制成本，采用多分片零副本的模式，当然为了高可用，最好还是要冗余多副本。&lt;/p&gt;&lt;p&gt;针对海量数据的存储，一种主流的做法就是实现Sharding方案。可以在客户端做Balance，也有数据库的中间件模式。Clickhouse Distributed表引擎就相当于Sharding方案中的中间件层，Distributed表不真实存储数据，对外提供插入和查询的路由功能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5557377049180328&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXndibpe98PO49VYXMB1XAClAdjXMq0NHIiczuzB9iavMDQUeOAK5damoyEg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;610&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2.表名的规范&lt;/p&gt;&lt;p&gt;为了适配常见的ORM模型，本地表一般采用&quot;local_&quot;开头如local_metrics，分布式表采用实际表如metrics。当然每个公司有自己的规范，主要还是为了方便区分和使用。&lt;/p&gt;&lt;p&gt;3.过期时间&lt;/p&gt;&lt;p&gt;由于存储的是日志类型，一般具有一定的时效性，我们设置表的TTL(Time To Live)时间，方便到期后数据自动删除。所以在建表的时候一般会带有Timestamp字段，一般我们是设置表级别TTL，当然Clickhouse还有支持更丰富的TTL类型，支持数据TTL，列TTL。&lt;/p&gt;&lt;p&gt;关于TTL小贴士：[注1]&lt;/p&gt;&lt;pre&gt;&lt;code&gt;1）TTL默认的合并频率由MergeTree的merge_with_ttl_timeout参数控制，默认86400秒，即1天。它维护的是一个专有的TTL任务队列。有别于MergeTree的常规合并任务，如果这个值被设置的过小，可能会带来性能损耗。&lt;br/&gt;（2）除了被动触发TTL合并外，也可以使用optimize命令强制触发合并。例如，触发一个分区合并：&lt;br/&gt;optimize TABLE table_name&lt;br/&gt;触发所有分区合并：&lt;br/&gt;optimize TABLE table_name FINAL&lt;br/&gt;（3）ClickHouse目前虽然没有提供删除TTL声明的方法，但是提供了控制全局TTL合并任务的启停方法：&lt;br/&gt;SYSTEM STOP/START TTL MERGES&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4.分区&lt;/p&gt;&lt;p&gt;Clickhouse 数据分区和数据分片是两个不同的概念，数据分区是一种纵切，数据分片是一种横切。目前只有MergeTree类型的才支持分区策略。分区用PARTITION BY修饰。借助分区能提升查询性能，过滤掉不再分区的的数据。由于日志的时效性，大部分查询条件都会带上时间，所有按时间分区非常合适。但分区的粒度不能过度或者过小，当然没有区分度的字段也不能用来设置分区，一般按月或者按日来进行分区。关于分区的设置可以参考[注3]&lt;/p&gt;&lt;p&gt;分区的合并过程可查看下图： &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4425925925925926&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXnuDeBgIjhibEEeGvmgAqSxKibgkOOm6NWzvzh5sUwv7uf8FBicZb2cRNUg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;5.分片副本策略&lt;/p&gt;&lt;p&gt;Clickhouse分片分区策略配置在/etc/metrika.xml中，前面说了基于成本和容错性考虑，我们采用多分片0副本的策略。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;log_nshards_0replicas&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;shard&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;replica&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;host&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;clickhouse1&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;host&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;port&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;9000&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;port&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;user&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;user&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;user&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;password&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;password&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;password&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;replica&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;shard&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;shard&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;replica&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;host&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;clickhouse2&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;host&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;port&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;9000&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;port&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;user&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;user&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;user&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;password&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;password&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;password&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;replica&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;shard&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;log_nshards_0replicas&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;由于日志类型没有很好的字段用于分片，这边采用rand()随机划分策略，尽量让分片数据均衡。另外Clickhouse集群配置有个分片权重设置，权重越大，分片写入数据越多，我们在新节点加入的时候会提高权重用于均衡数据。当然了这种靠手工的运维的模式不太适合频繁的节点上下线，如果有这方面的需求可以考虑引入数据均衡的中间件。更多关于分片的数据写入的细节可以参考[注2]。&lt;/p&gt;&lt;p&gt;6.索引&lt;/p&gt;&lt;p&gt;一级索引，PRIMARY KEY一般用于ORDER BY指定，由于我们存的大部分都是日志或指标类型，从而采用timestamp做一级索引。&lt;/p&gt;&lt;p&gt;稀疏索引，MergeTree每一行索引标记对应的是一段数据，仅需使用少量的索引标记就能够记录大量数据的区间位置信息，默认的索引粒度(8192)。由于稀疏索引占用空间小，所以primary.idx内的索引数据常驻内存，取用速度自然极快。&lt;/p&gt;&lt;p&gt;二级索引，除了一级索引之外，MergeTree同样支持二级索引。二级索引又称跳数索引。关于索引的更多细节可以参考附录[索引]&lt;/p&gt;&lt;p&gt;7.参数配置&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;最大并发查询数 max_concurrent_queries 原则上Clickhouse建议查询QPS小于100，但我们有按每分钟聚合查询的需求，这时候100就比较小了，调整max_concurrent_queries=500，需要注意的是，关注SQL的执行时间及机器负载设置合理值，避免高并发的查询影响Clickhouse性能。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;压缩比 Clickhouse默认lz4压缩算法，MergeTree引擎压缩后和Elasticsearch对比，存储空间大约只有后者的1/10。更多关于压缩参考[ClickHouse数据的压缩和原理]。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多用户支持 默认Clickhouse安装后用户是default，空密码，需要做修改，避免安全问题。同时按不同的database设置不同的用户角色。同时注意密码加密方式，我们采用password_double_sha1_hex。另外我们为web可视化终端单独设置了用户，单独配置用户行为。[注4]&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;熔断机制 基于用户设置sql最大执行时间execution_time=5，类似pt-kill，超过阈值会终止查询。防止查询造成Clickhouse Server过载。还可设置result_rows/read_rows。为了避免内存耗尽造成异常，按需设置max_memory_usage。[注5]&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;web&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;interval&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;duration&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;3600&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;duration&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;queries&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;500&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;queries&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;errors&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;100&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;errors&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;result_rows&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;100&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;result_rows&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;read_rows&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;2000&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;read_rows&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;execution_time&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;5&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;execution_time&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;interval&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;web&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;web_user&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;password_double_sha1_hex&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;***&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;password_double_sha1_hex&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;networks&lt;/span&gt; &lt;span&gt;incl&lt;/span&gt;&lt;span&gt;&lt;span&gt;=&quot;&lt;/span&gt;networks&lt;span&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span&gt;replace&lt;/span&gt;&lt;span&gt;&lt;span&gt;=&quot;&lt;/span&gt;replace&lt;span&gt;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;ip&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;::/0&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;ip&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;networks&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;profile&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;default&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;profile&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;quota&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;web&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;quota&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;  // 引用用户策略&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;access_management&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;1&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;access_management&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;web_user&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;8.可视化&lt;/p&gt;&lt;p&gt;一般采用tabix。为了支持Prometheus，Elasticsearch，Clickhouse，我们选择Grafana，见：Clickhouse-Data-Source(https://grafana.com/grafana/plugins/grafana-clickhouse-datasource/?tab=installation)。&lt;/p&gt;&lt;h3&gt;实战场景&lt;/h3&gt;&lt;p&gt;&lt;span&gt;全站可用性监控大盘&lt;/span&gt;&lt;/p&gt;&lt;p&gt;主要功能是实时查询，目前Clickhouse已对接好大夫在线绝大多数原始日志数据。包括入口流量日志KongLog，链路日志TracingLog，业务自定义日志LocalLog，组件及框架可用性日志如小程序日志、JS异常日志、页面性能日志等等。&lt;/p&gt;&lt;p&gt;表结构示例:&lt;/p&gt;&lt;pre&gt;&lt;code&gt; CREATE TABLE {database}.{local_table} ON CLUSTER {cluster}&lt;br/&gt;(&lt;br/&gt;    `date` Date,&lt;br/&gt;    `timestamp` DateTime,&lt;br/&gt;    ...&lt;br/&gt;)&lt;br/&gt;ENGINE = MergeTree&lt;br/&gt;PARTITION BY date&lt;br/&gt;ORDER BY timestamp&lt;br/&gt;TTL timestamp + toIntervalDay(30)&lt;br/&gt;SETTINGS index_granularity = 8192&lt;br/&gt;&lt;br/&gt;CREATE TABLE {database}.{table} ON CLUSTER {cluster} &lt;br/&gt;AS {database}.{local_table}&lt;br/&gt;ENGINE = Distributed({cluster}, {database}, {table}, rand())&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;那么基于这些原始日志就能实时监控趋势了，产品形态如图：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6148148148148148&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXn5vEIicV9BzkdRPbcq8micpkwJTeFbcNjZibANtMN5EPzsuZ5OibgsNhQZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5074074074074074&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXnXibY16JmrQWsCW7ia2xjBvbP5BVW1aUpfzic1IJmbLA1ZhF77OjGq15yg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;APM&lt;/span&gt;&lt;/p&gt;&lt;p&gt;主要用于分析服务的性能，我们存储了Tracing日志，依然是Distributed + MergeTree模式。&lt;/p&gt;&lt;p&gt;Tracing日志记录了服务的上下游服务及接口，上下游机器ip，RPC请求耗时，请求状态等。&lt;/p&gt;&lt;p&gt;这样我们就可以分析上下游细节了，如上下游QPM，依赖接口的延迟P99。&lt;/p&gt;&lt;p&gt;比如分析服务的上下游QPM，依赖接口的延迟p99，服务的网络延迟P99，接口的错误率等等。&lt;/p&gt;&lt;p&gt;这依赖Clickhouse丰富的函数，常用统计函数/分位数/中位数/数组函数等等，针对大量数据还可以基于采样查询SAMPLE BY.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.41203703703703703&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXny3ibnrSc35Ty7sqc5TbNAk56FLKTlgucrNR6micEv9coGJBNPEv0OXsg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如P99(由于延迟具有长尾效应，一般统计第99分位数据)&lt;/p&gt;&lt;pre&gt;&lt;code&gt;SELECT&lt;br/&gt;    (intDiv(toUInt32(timestamp), 1) * 1) * 1000 as t,&lt;br/&gt;    quantile(0.99)(consume) as p99&lt;br/&gt;FROM apm.trace_logs&lt;br/&gt;&lt;br/&gt;WHERE&lt;br/&gt;    timestamp &amp;gt;= toDateTime(1605147889)&lt;br/&gt;    AND app_name = &#x27;app&#x27;&lt;br/&gt;GROUP BY&lt;br/&gt;    t&lt;br/&gt;ORDER BY t&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;APM常见的场景就是提供链路画像，需要按TraceID搜索，TraceID类似UUID字符串，不具备索引区分度。每次查询都会全表扫描，如何能快速查找TraceID对应的链路数据呢？&lt;/p&gt;&lt;pre&gt;&lt;code&gt;# 本地表存储tracing日志&lt;br/&gt; CREATE TABLE apm.local_trace_logs ON CLUSTER {cluster}&lt;br/&gt;(&lt;br/&gt;    `date` Date,&lt;br/&gt;    `timestamp` DateTime,&lt;br/&gt;    `trace_id` String, // uuid 随机32字符串&lt;br/&gt;    ...&lt;br/&gt;)&lt;br/&gt;ENGINE = MergeTree&lt;br/&gt;PARTITION BY date&lt;br/&gt;ORDER BY timestamp&lt;br/&gt;TTL timestamp + toIntervalDay(30)&lt;br/&gt;SETTINGS index_granularity = 8192&lt;br/&gt;&lt;br/&gt;# 分布式表Distributed&lt;br/&gt;CREATE TABLE apm.trace_logs ON CLUSTER {cluster} &lt;br/&gt;AS apm.local_trace_logs&lt;br/&gt;ENGINE = Distributed({cluster}, apm, trace_logs, rand())&lt;br/&gt;&lt;br/&gt;# 提取入口trace_id数据即level=1，生成物化视图，这个视图的数据只有原表的10%的量级。&lt;br/&gt; CREATE MATERIALIZED VIEW apm.local_entrances&lt;br/&gt;(&lt;br/&gt;    `date` Date,&lt;br/&gt;    `timestamp` DateTime,&lt;br/&gt;    `trace_id` String,&lt;br/&gt;    ...&lt;br/&gt;)&lt;br/&gt;ENGINE = MergeTree&lt;br/&gt;PARTITION BY date&lt;br/&gt;ORDER BY timestamp&lt;br/&gt;TTL timestamp + toIntervalDay(6)&lt;br/&gt;SETTINGS index_granularity = 8192 AS&lt;br/&gt;SELECT&lt;br/&gt;    date,&lt;br/&gt;    timestamp,&lt;br/&gt;    trace_id,&lt;br/&gt;    ...&lt;br/&gt;FROM apm.local_trace_logs&lt;br/&gt;WHERE level = &#x27;1&#x27;&lt;br/&gt;&lt;br/&gt;# Distributed 暴露给外查询的引擎&lt;br/&gt;CREATE TABLE apm.entrances ON CLUSTER {cluster} &lt;br/&gt;AS apm.local_entrances&lt;br/&gt;ENGINE = Distributed({cluster}, apm, entrances, rand())&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;统计发现这样提取后物化视图的数据只有原表的10%了，在查询的时候，我们先从entrances表中查询给定的{trace_id}的数据，拿到{timestamp}、{date}后。再将{trace_id}、{timestamp±5min}、{date}带去trace_logs表中查询，因为trace_logs按date分区，并且有timestamp索引，这样就不用全部扫描了，只用查询&lt;code&gt;timestamp between {timestamp-5min} and {timestamp+5min} and date = {date}&lt;/code&gt;的数据即可。&lt;/p&gt;&lt;p&gt;当然如果后续trace_logs数据再翻翻，我们还有优化的空间。根据前缀索引模型，我们截取trace_id前n位记作sub_id,然后根据sub_id做索引，根据数据量的大小调整n的值，这样我们能将单次查询数据控制在一定的范围内。&lt;/p&gt;&lt;p&gt;如果数据量过大，还可以根据特征字段配置采样策略。&lt;/p&gt;&lt;p&gt;产品形态：&lt;/p&gt;&lt;p&gt;运行时&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.086111111111111&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXnCnHNJJxzb2jtPmh1icVciagYQlVoxPT31kK7MOLEzGVazBjVD3rNIxew/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;拓扑分析 &lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5101851851851852&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXnMZB7u5QYfBg3ONYkT2ss64vSdIKcCIyUceq14usfMWzNNJY4jZCZlg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;链路分析 &lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.687962962962963&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXnnnfsTrkicCGoY1xkHicbk9sCh4oNfISMeWHO6RRkH7BwFVS2gvaScT4A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;告警指标分析&lt;/span&gt;&lt;/p&gt;&lt;p&gt;好大夫早期的监控告警是依托于Elasticsearch，数据可视化也是基于Elasticsearch。随着告警项的增加，并发查询增加，导致Elasticsearch负载过高，无法正常提供服务，同时Elasticsearch写入面临磁盘I/O瓶颈。为了监控的高可用及时效性，我们全面迁移到Clickhouse。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.20925925925925926&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXnaSIRIFhLCeiaAf5ic1JSbNoLwwqYdVahLicmyfET8lP7Vhf2uXeHG5aIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前大约每分钟有2000+SQL并发执行，5s内能分析完毕，分析后的数据按分钟聚合后存储到Clickhouse中。&lt;/p&gt;&lt;p&gt;这里采用了GraphiteMergeTree引擎，同理由于是临时存储，依然采用多分片零副本的分片策略。GraphiteMergeTree类似于Graphite数据库，是一个图表数据库，这里我们参考Prometheus时序数据库的思想，将原始数据按不同的维护聚合分析后转换成key-value的数据类型。其中name为指标名，tags为指标的多维度标签，是一个数组类型，date用于分区，ts指标插入时间，val是指标的具体值是Float64格式，update用于降准稀疏。&lt;/p&gt;&lt;p&gt;&lt;span&gt;Prometheus就可以通过exporter拉取这些分析后的指标，&lt;/span&gt;经&lt;span&gt;过判定触发告警。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;如app的QPM可以表示为：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;date:    2021-11-25&lt;br/&gt;name:    app_request_qpm&lt;br/&gt;tags:    [&#x27;app_name=demo&#x27;,&#x27;ttl=forever&#x27;]&lt;br/&gt;val:     336608&lt;br/&gt;ts:      2021-11-26 23:00:00&lt;br/&gt;updated: 2021-11-26 23:00:22&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查询最近5min demo的访问量:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;SELECT sum(val) as total&lt;br/&gt;FROM metrics&lt;br/&gt;WHERE (name = &#x27;app_request_qpm&#x27;) &lt;br/&gt;AND has(tags, &#x27;app_name=demo&#x27;)&lt;br/&gt;AND date=today() and ts&amp;gt;now()-300&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;表结构&lt;/p&gt;&lt;pre&gt;&lt;code&gt;# 本地表用于存储指标&lt;br/&gt;CREATE TABLE apm.local_metrics ON CLUSTER {CLUSTER}&lt;br/&gt;(&lt;br/&gt;    `date` Date DEFAULT toDate(0),&lt;br/&gt;    `name` String,&lt;br/&gt;    `tags` Array(String),&lt;br/&gt;    `val` Float64,&lt;br/&gt;    `ts` DateTime,&lt;br/&gt;    `updated` DateTime DEFAULT now()&lt;br/&gt;)&lt;br/&gt;ENGINE = GraphiteMergeTree(&#x27;graphite_metric&#x27;)&lt;br/&gt;PARTITION BY date&lt;br/&gt;ORDER BY (name, tags, ts)&lt;br/&gt;TTL ts + toIntervalDay(30)&lt;br/&gt;&lt;br/&gt;# 分布式表&lt;br/&gt;CREATE TABLE apm.metrics ON CLUSTER {CLUSTER}&lt;br/&gt;AS apm.local_metrics&lt;br/&gt;ENGINE = Distributed(&#x27;{CLUSTER}&#x27;, &#x27;apm&#x27;, &#x27;local_metrics&#x27;, rand())&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;特征数据归档&lt;/span&gt;&lt;/p&gt;&lt;p&gt;前面看到我们存储了大量的原始日志数据，也看到物化视图的威力，那还有哪些场景能使用这把利器。目前提供给业务方的自定义的日志LocalLog，常用event和app_name来标识不同的类型。LocalLog记录了全服务的日志，数据量级非常大，为了更好地检索数据，避免查询大表LocalLog，我们把常用的event剥离出来，单独生成物化视图，从而提升查询性能。&lt;/p&gt;&lt;p&gt;比如为配合Tracing日志，我们在框架中集成了调用中间件的日志，复用了LocalLog，记录微服务调用中间件的详情，如mysql sql详情，RabbitMQ发布、消费记录等。这时我们就可以基于event事件分离出中间件日志单独生成视图。这类场景还有很多，比如分离出客户端慢交互数据，特定埋点的用户行为日志等。&lt;/p&gt;&lt;pre&gt;&lt;code&gt; CREATE MATERIALIZED VIEW apm.local_middleware_logs&lt;br/&gt;(&lt;br/&gt;    `date` Date,&lt;br/&gt;    `timestamp` DateTime,&lt;br/&gt;    `trace_id` String,&lt;br/&gt;    `event` String,&lt;br/&gt;    ...&lt;br/&gt;)&lt;br/&gt;ENGINE = MergeTree&lt;br/&gt;PARTITION BY date&lt;br/&gt;ORDER BY timestamp&lt;br/&gt;TTL timestamp + toIntervalDay(6)&lt;br/&gt;SETTINGS index_granularity = 8192 AS&lt;br/&gt;SELECT&lt;br/&gt;    date,&lt;br/&gt;    timestamp,&lt;br/&gt;    trace_id,&lt;br/&gt;    event,&lt;br/&gt;    ...&lt;br/&gt;FROM apm.local_biz_logs&lt;br/&gt;WHERE event in (&#x27;mysql&#x27;,&#x27;rabbitmq&#x27;...)&lt;br/&gt;&lt;br/&gt;CREATE TABLE apm.middleware_logs ON CLUSTER {cluster} &lt;br/&gt;AS apm.local_middleware_logs&lt;br/&gt;ENGINE = Distributed({cluster}, apm, middleware_logs, rand())&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;前面我们存储了基于原始日志分析后等到聚合指标metrics，有些数据需要长期存储，比如存储一个Q，一年等。如微服务的QPM，P99需要永久存储，方便从长期时间维度查看趋势，从而评估服务整体健康度演化趋势。我们可以对感兴趣的metrics打上tags TTL=&quot;forever&quot;。这样我们设置local_view_metrics的引擎策略GraphiteMergeTree roll_up上卷模式，graphite_metric_view。按不同的策略对同名指标包含相同tags的数据进行降准稀疏，&amp;lt;=7d内存储原始指标，7d~30d按小时进行上卷，&amp;gt;30d按天进行上卷，上卷的策略有sum/avg/min/max等。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;# 物化视图 提取特定tags的指标&lt;br/&gt;CREATE MATERIALIZED VIEW apm.local_view_metrics ON CLUSTER {CLUSTER}&lt;br/&gt;(&lt;br/&gt;    `date` Date DEFAULT toDate(0),&lt;br/&gt;    `name` String,&lt;br/&gt;    `tags` Array(String),&lt;br/&gt;    `val` Float64,&lt;br/&gt;    `ts` DateTime,&lt;br/&gt;    `updated` DateTime DEFAULT now()&lt;br/&gt;)&lt;br/&gt;ENGINE = GraphiteMergeTree(&#x27;graphite_metric_view&#x27;)&lt;br/&gt;PARTITION BY date&lt;br/&gt;ORDER BY (name, tags, ts)&lt;br/&gt;SETTINGS index_granularity = 8192 AS&lt;br/&gt;SELECT&lt;br/&gt;    date,&lt;br/&gt;    name,&lt;br/&gt;    tags,&lt;br/&gt;    val,&lt;br/&gt;    ts,&lt;br/&gt;    updated&lt;br/&gt;FROM apm.local_metrics&lt;br/&gt;WHERE has(tags, &#x27;ttl=forever&#x27;) = 1&lt;br/&gt;&lt;br/&gt;CREATE TABLE apm.view_metrics ON CLUSTER {CLUSTER}&lt;br/&gt;AS apm.local_view_metrics&lt;br/&gt;ENGINE = Distributed(&#x27;{cluster}&#x27;, &#x27;apm&#x27;, &#x27;local_view_metrics&#x27;, rand())&lt;br/&gt;&lt;br/&gt;# graphite_metric_view 配置策略&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;graphite_metric_view&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;path_column_name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;tags&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;path_column_name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;time_column_name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;ts&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;time_column_name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;value_column_name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;val&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;value_column_name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;version_column_name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;updated&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;version_column_name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;default&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;function&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;avg&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;function&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;retention&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;0&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;precision&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;30&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;precision&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;retention&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;retention&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;604800&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;precision&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;3600&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;precision&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;retention&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;retention&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;2592000&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;precision&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;86400&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;precision&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;retention&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;default&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;pattern&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;regexp&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;rollup_sum&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;regexp&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;function&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;sum&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;function&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;retention&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;0&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;precision&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;30&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;precision&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;retention&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;retention&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;604800&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;precision&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;3600&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;precision&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;retention&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;retention&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;2592000&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;age&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;precision&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;86400&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;precision&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;retention&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;pattern&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        ...&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;graphite_metric_view&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;Prometheus远程存储&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着监控体系向云原生靠拢，我们整体也是采用了Prometheus。但是Prometheus官方并没有提供长期数据持久化的方案，但有些业务指标需要长期存储。我们采用本地存储15d+远程存储的模式。远程存储采用CLickhouse，这也是&lt;/span&gt;经&lt;span&gt;过对比后选定的，业内也有选择InfluxDB，但社区版的InfluxDB不支持集群模式，加上引入新的DB产生的运维成本，最终还是选择了Clickhouse，毕竟有一定的经验积累了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;我们自研了Prometheus2CLickhouse_adapter，将数据从Prometheus同步到CLickhouse。有兴趣的同学可以查看源码，目前已经开源到GitHub: remote_storage_adapter。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2916666666666667&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcls2sXF9kQ9xEV6tQjUyOXnU2p5mPRzhdibMYbhKL61dQ12DMPRX0HehmMyGplwLtVygBstAK1I78w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;业务尝试&lt;/span&gt;&lt;/p&gt;&lt;p&gt;目前已有业务方对接了Clickhouse，主要场景是多方向聚合数据，然后按不同的维度检索数据（多维度的统计数据实时查询）。一开始也考虑直接用熟悉的MySQL/MongoDB，但都有性能瓶颈问题，千万级数据查询会到大于10s，无法满足业务需求，改用Clickhouse后查询在200ms内。由于业务数据需要高可用，数据不可丢失，这里采用了三分片一副本的策略，准备了6个节点，ck1~6。类似于RedisCluster模式，实现两两备份。&lt;/p&gt;&lt;p&gt;另外为了提升写入性能，我们设置了异步同步模式internal_replication=true，Distributed表在该shard中只会选择一个合适的replica，并写入数据，多replica副本间的数据复制则交给本地表引擎如ReplicatedMergeTree。&lt;/p&gt;&lt;p&gt;集群配置&lt;/p&gt;&lt;pre&gt;&lt;code&gt;# 分片副本&lt;br/&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;nshards_1replicas&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;shard&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;internal_replication&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;true&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;internal_replication&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;replica&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;host&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;clickhouse1&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;host&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;port&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;9000&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;port&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;user&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;user&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;user&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;password&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;password&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;password&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;replica&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;replica&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;host&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;clickhouse4&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;host&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;port&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;9000&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;port&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;user&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;user&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;user&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;password&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;password&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;password&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;replica&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;shard&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    ...&lt;br/&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;nshards_1replicas&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;# 变量用于建表时的占位符，策略将存在zookeeper中.&lt;br/&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;macros&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;layer&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;02&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;layer&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;shard&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;01&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;shard&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;replica&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;ck2-01-01&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;replica&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;macros&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;表结构&lt;/p&gt;&lt;pre&gt;&lt;code&gt;CREATE TABLE default.local_tests ON CLUSTER nshards_1replicas&lt;br/&gt;(&lt;br/&gt;    `id` Int64,&lt;br/&gt;    `diseaseid` Int64,&lt;br/&gt;    `ctime` DateTime,&lt;br/&gt;    ...&lt;br/&gt;)&lt;br/&gt;ENGINE = ReplicatedMergeTree(&#x27;/clickhouse/tables/{shard}/local_tests&#x27;, &#x27;{replica}&#x27;)&lt;br/&gt;PARTITION BY toYYYYMMDD(ctime)&lt;br/&gt;ORDER BY (ctime, diseaseid)&lt;br/&gt;TTL ctime + toIntervalDay(7)&lt;br/&gt;SETTINGS index_granularity = 8192&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;CREATE TABLE default.tests ON CLUSTER nshards_1replicas &lt;br/&gt;AS {database}.local_tests&lt;br/&gt;ENGINE = Distributed(nshards_1replicas, default, tests, rand())&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;上线之后业务反馈还不错，数据查询反馈很及时。&lt;/h3&gt;&lt;h3&gt;展望&lt;/h3&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Clickhouse管理平台的演进 由于Clickhouse迭代升级非常频繁，每个月会更新一版，但是部署运维偏向手动。故障转移，参数配置等运维成本较高。做好权限控制，将集群下发给业务方使用。为了高可用及稳定性，后续会向PaaS平台演进。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;拓宽Clickhouse使用场景，对接更多的业务方需求。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;减少Clickhouse黑盒模式，要知其然知其所以然，加深对Clickhouse的深入研究。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;提升CLickhouse中间件的稳定性，借助混沌工程思想，做好周期性故障演练。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;小结&lt;/h3&gt;&lt;p&gt;在大数据时代，人人都是数据分析师，OLAP也一直在进化，适应着时代的发展。当下微服务治理产生的数据也越来越大，为了辅助研发同学更好的治理线上服务，OLAP数据库将发挥着越来越重要的作用。尤其是实时查询，不同的人关注的不同的维度，通过上卷，下钻及时定位异常问题。本篇我们一起探讨了Clickhouse在好大夫微服务治理中发挥的作用，后续我们还将&lt;span&gt;分享&lt;/span&gt;更多的应用场景，期待大家共同讨论。最后推荐一本书：《ClickHouse原理解析与应用实践》https://book.douban.com/subject/35091211/。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;参考资料：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;clickhouse vs elasticsearch benchmark：https://www.alibabacloud.com/blog/clickhouse-vs--elasticsearch_597898；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;clickhouse vs mysql benchmark：http://mmedojevic.com/2020/03/09/clickhouse-vs-mysql/；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Performance comparison of analytical DBMS：https://clickhouse.yandex/benchmark.html；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ClickHouse数据的压缩和原理：https://blog.csdn.net/weixin_43975771/article/details/115861032；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;“索引”&lt;span&gt; 朱凯著.ClickHouse原理解析与应用实践.机械工业出版社华章分社.2020:215.&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;[注1] “&lt;/span&gt;TTL” &lt;span&gt;朱凯著.ClickHouse原理解析与应用实践.机械工业出版社华章分社.2020:255.&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;[注2] “&lt;/span&gt;分片写入核心流程”&lt;span&gt; 朱凯著.ClickHouse原理解析与应用实践.机械工业出版社华章分社.2020:473.&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;[注3] “&lt;/span&gt;数据的分区规则&lt;span&gt;朱凯著.ClickHouse原理解析与应用实践.机械工业出版社华章分社.2020:208.&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;[注4] &lt;/span&gt;用户配置：https://clickhouse.com/docs/en/operations/settings/settings-users/&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;[注5] &lt;/span&gt;配额：https://clickhouse.com/docs/en/operations/quotas/&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;------- END -------&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;【作者简介】&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;方勇：好大夫基础架构部高级工程师，专注于 SRE，微服务、中间件的稳定性和可用性建设，整体负责好大夫服务治理云平台的设计和搭建。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100000431&quot; data-ratio=&quot;0.4962518740629685&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ODCWCINiaHcnnHcF2z11mEfFzXJnPq6QsNWiamcZ9X18Q1ibCq2sEJQj7UANSXLduq9rkWo4xED9SFGNtrpmMGTFw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1334&quot;/&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;124&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;p&gt;好大夫在线创立于2006年，是中国领先的互联网医疗平台之一。已收录国内10496家正规医院的69.2万名医生信息。其中，23万名医生在平台上实名注册，直接向患者提供线上医疗服务。“让行医简单，看病不难” ，始终追求“成为值得信赖的医疗平台”。&lt;/p&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span data-raw-text=&quot;好&quot; data-textnode-index-1641282081426=&quot;111&quot; data-index-1641282081426=&quot;5381&quot; class=&quot;character&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;也许你还想看：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a4147e2c42ba8d4fba5008d1c22e4688</guid>
<title>基于 SeaTunnel 构建 CDC 流式应用</title>
<link>https://toutiao.io/k/gzu6o13</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;点击蓝字 关注我们&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;目前参与的项目属于公司里面数据量大、计算密集的一个重要业务项目，需要提供高效且准确的 OLAP 服务，并提供灵活且实时的报表。业务数据存储在 MySQL 中，数据增长多而且快，出现了多个千万级、亿级的大表。随着数据量的日益增长和实时分析的需求越来越大，急需对系统进行流式计算、实时化改造。正是在这个背景下，开始了我们与 Apache SeaTunnel 的故事。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;01&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;方案概述&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们基于 &lt;strong&gt;SeaTunnel&lt;/strong&gt; 提出了把报表的数据实时化的方案，该方案主要通过 &lt;strong&gt;SeaTunnel CDC + Elasticsearch&lt;/strong&gt; 实现。支持将 MySQL 中的全量和增量数据实时地采集、计算、并同步到 Elasticsearch 中，Elasticsearch 作为我们的实时报表和即席分析引擎。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;本文所有的实战演练都将在单机上执行，并结合 docker 进行演示，全程只涉及 SQL 纯文本，无需一行 Java 代码。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;实现具体思路是， 使用 CDC 全量/增量同步变更数据，且保证消费一致性，然后将结果输出到 Elasticsearch。这种架构，依赖组件少，维护成本低，开箱即用。具体来说 &lt;span&gt;&lt;strong&gt;SeaTunnel 是一个集采集、计算、传输于一体的工具&lt;/strong&gt;&lt;/span&gt;，其吸引我们的&lt;span&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/span&gt;有：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;减少维护的组件、降低维护成本和开发成本；&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;减少端到端延迟;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;支持 Exactly Once 的读取和传输;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;支持全量和增量流式读取&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3053348&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/nD3VA87gH3kPCAmBpSHwefPpyqyAyr2BCTIVVdbqvc1iaErxEAaVsBQT4HgezcaI3Piae6miaRjnQHqqjTvsDbAyw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;881&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;02&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;环境准备&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;01&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;通过 docker 安装基础环境&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;可以手动下载:&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://github.com/leo65535/seatunnel-sql-demo/blob/main/cdc/docker-compose.yml&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git clone git&lt;span&gt;@github&lt;/span&gt;.com:leo65535/seatunnel-sql-demo.git&lt;br/&gt;cd seatunnel-sql-demo/cdc&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;该 Docker Compose 中包含的容器有：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;02&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt; 启动 / 停止基础环境容器&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;启动所有的容器，只需要在 docker-compose.yml 所在目录下运行如下命令：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;docker-compose up --force-recreate -d&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;03&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;下载 Apache Flink 环境(&amp;gt;=1.13.3)&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;此次实践，我们将使用 SeaTunnel 中的 flink 引擎，所以我们需要完整的 flink 环境，并下载依赖包。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;cd /opt&lt;br/&gt;wget https:&lt;span&gt;//repo.huaweicloud.com/apache/flink/flink-1.13.3/flink-1.13.3-bin-scala_2.11.tgz&lt;/span&gt;&lt;br/&gt;tar xf flink-&lt;span&gt;1.13&lt;/span&gt;&lt;span&gt;.3&lt;/span&gt;-bin-scala_2&lt;span&gt;.11&lt;/span&gt;.tgz&lt;br/&gt;cd flink-&lt;span&gt;1.13&lt;/span&gt;&lt;span&gt;.3&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;wget -P ./lib/ https:&lt;span&gt;//repo1.maven.org/maven2/org/apache/flink/flink-sql-connector-elasticsearch7_2.11/1.13.3/flink-sql-connector-elasticsearch7_2.11-1.13.3.jar | \&lt;/span&gt;&lt;br/&gt;wget -P ./lib/ https:&lt;span&gt;//repo1.maven.org/maven2/org/apache/flink/flink-connector-jdbc_2.11/1.13.3/flink-connector-jdbc_2.11-1.13.3.jar | \&lt;/span&gt;&lt;br/&gt;wget -P ./lib/ https:&lt;span&gt;//repo1.maven.org/maven2/com/ververica/flink-sql-connector-mysql-cdc/2.1.1/flink-sql-connector-mysql-cdc-2.1.1.jar | \&lt;/span&gt;&lt;br/&gt;wget -P ./lib/ https:&lt;span&gt;//repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.22/mysql-connector-java-8.0.22.jar&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/section&gt;&lt;span&gt;‍&lt;/span&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;04&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;编译 SeaTunnel 项目&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;git clone git&lt;span&gt;@github&lt;/span&gt;.com:apache/incubator-seatunnel.git&lt;br/&gt;cd incubator-seatunnel&lt;br/&gt;git reset --hard d2dc8bf&lt;br/&gt;mvn clean install -DskipTests&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;span&gt;‍&lt;/span&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;至此，我们的基础环境都已经准备就绪。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;03&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;数据准备&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;此节模拟业务生产库数据，创建表，并模拟写入数据。通过 &lt;span&gt;mysql -h127.0.0.1 -uroot -p123456 &lt;/span&gt;进入 MySQL 控制台。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;CREATE DATABASE test;&lt;br/&gt;&lt;br/&gt;CREATE TABLE test.users (&lt;br/&gt;  id bigint PRIMARY KEY AUTO_INCREMENT,&lt;br/&gt;  &lt;span&gt;name &lt;span&gt;varchar&lt;/span&gt;&lt;span&gt;(&lt;span&gt;20&lt;/span&gt;)&lt;/span&gt; NULL,&lt;br/&gt;  birthday timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP&lt;br/&gt;)&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;INSERT INTO test.users (name) VALUES (&lt;span&gt;&#x27;hello&#x27;&lt;/span&gt;);&lt;br/&gt;INSERT INTO test.users (name) VALUES (&lt;span&gt;&#x27;world&#x27;&lt;/span&gt;);&lt;br/&gt;INSERT INTO test.users (name) VALUES (&lt;span&gt;&#x27;hudi&#x27;&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;span&gt;‍&lt;/span&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;04&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;启动 CDC 任务&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;01&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;解压 SeaTunnel 包&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;此节，我们将启动 SeaTunnel 任务，将 MySQL 的数据cdc到 ElasticSearch 中。我们先进入 SeaTunnel 项目中，在上面步骤中，已经编译好 seatunnel-dist-2.0.5-SNAPSHOT-2.11.8-bin.tar.gz 包。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;tar xf seatunnel-dist/target/seatunnel-dist-&lt;span&gt;2.0&lt;/span&gt;&lt;span&gt;.5&lt;/span&gt;-SNAPSHOT-&lt;span&gt;2.11&lt;/span&gt;&lt;span&gt;.8&lt;/span&gt;-bin.tar.gz&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;‍&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;02&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;配置任务&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;生成 cdc 配置文件，语法采用 FlinkSQL 。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;cd seatunnel-dist-&lt;span&gt;2.0&lt;/span&gt;&lt;span&gt;.5&lt;/span&gt;-SNAPSHOT-&lt;span&gt;2.11&lt;/span&gt;&lt;span&gt;.8&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;tee config/application.conf &amp;lt;&amp;lt;-&lt;span&gt;&#x27;EOF&#x27;&lt;/span&gt;&lt;br/&gt;SET &lt;span&gt;&#x27;table.dml-sync&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;true&#x27;&lt;/span&gt;;&lt;br/&gt;SET &lt;span&gt;&#x27;parallelism.default&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;1&#x27;&lt;/span&gt;;&lt;br/&gt;SET &lt;span&gt;&#x27;execution.checkpointing.interval&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;5sec&#x27;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;CREATE TABLE &lt;span&gt;mysql_users&lt;/span&gt; &lt;span&gt;(&lt;br/&gt;  id BIGINT PRIMARY KEY NOT ENFORCED,&lt;br/&gt;  name STRING,&lt;br/&gt;  birthday TIMESTAMP(&lt;span&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br/&gt;) &lt;span&gt;WITH&lt;/span&gt; &lt;span&gt;(&lt;br/&gt;  &lt;span&gt;&#x27;connector&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;mysql-cdc&#x27;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&#x27;hostname&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;localhost&#x27;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&#x27;port&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;3306&#x27;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&#x27;username&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;root&#x27;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&#x27;password&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;123456&#x27;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&#x27;database-name&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;test&#x27;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&#x27;table-name&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;users&#x27;&lt;/span&gt;&lt;br/&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;CREATE TABLE &lt;span&gt;es_users&lt;/span&gt; &lt;span&gt;(&lt;br/&gt;  id BIGINT PRIMARY KEY NOT ENFORCED,&lt;br/&gt;  name STRING,&lt;br/&gt;  birthday TIMESTAMP(&lt;span&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br/&gt;) &lt;span&gt;WITH&lt;/span&gt; &lt;span&gt;(&lt;br/&gt;  &lt;span&gt;&#x27;connector&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;elasticsearch-7&#x27;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&#x27;hosts&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;http://localhost:9200&#x27;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&#x27;index&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;users&#x27;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&#x27;format&#x27;&lt;/span&gt; = &lt;span&gt;&#x27;json&#x27;&lt;/span&gt;&lt;br/&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;INSERT INTO es_users SELECT * FROM mysql_users;&lt;br/&gt;EOF&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;span&gt;‍&lt;/span&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;03&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;启动任务&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们使用 local 模式，本地启动 cdc 任务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;export FLINK_HOME=/opt/flink-&lt;span&gt;1.13&lt;/span&gt;&lt;span&gt;.3&lt;/span&gt;&lt;br/&gt;bin/start-seatunnel-sql.sh --target local -Drest.port=&lt;span&gt;8081&lt;/span&gt; -Dtaskmanager.numberOfTaskSlots=&lt;span&gt;1&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;此时可以打开&lt;span&gt; &lt;span&gt;locahost:8081&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.762037&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/nD3VA87gH3kPCAmBpSHwefPpyqyAyr2ByBahFq4mzhQzxAD0Jdm99CmxvGezBSkLB5LbNiaNxwcSAhjlZkRgicLw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;05&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;验证cdc是否正常&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;01&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;打开 Kibana&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;浏览器打开 &lt;em&gt;http://localhost:5601&lt;/em&gt; , 点击 Dev Tools 页签，在编辑窗口&lt;/p&gt;&lt;p&gt;输入查询如下语句。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;POST /_sql?format=txt&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;query&quot;&lt;/span&gt;: &lt;span&gt;&quot;SELECT id, name, birthday FROM users&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;fetch_size&quot;&lt;/span&gt;: &lt;span&gt;10&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;span&gt;‍&lt;/span&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7231481&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/nD3VA87gH3kPCAmBpSHwefPpyqyAyr2BZPu0JgNicN7LLCz6prQBnhoCT47aONt7CLSyWHXkyJibJCpLQkibnsbkQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;02&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;尝试在 MySQL 中更新一条数据&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们会发现，ElasticSearch 也同步更新了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7203704&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/nD3VA87gH3kPCAmBpSHwefPpyqyAyr2BYFQaenFu0gIt4jzC67g7rqZYgVI6IfhicfwVchDBjdUPv7vFhkicbibgA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;06&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;结尾&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;在本文中，展示了如何使用 SeaTunnel 集成 MySQL, Elasticsearch 以及 Kibana 来快速搭建一个实时分析应用。整个过程无需一行 Java/Scala 代码，使用 SQL 纯文本即可完成。期望通过本文，可以让读者了解到 SeaTunnel 的易用和强大，包括轻松连接各种外部系统、对事件时间和乱序数据处理的原生支持、维表关联、丰富的内置函数等等。希望你能喜欢我们的实战演练，并从中获得乐趣和知识！&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;作者简介&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/nD3VA87gH3kPCAmBpSHwefPpyqyAyr2BxC87XTTN66OqHLGgwEOz1Opj5M2RHHbZC9gQQ2ozd6DOYLtUYuLNow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;673&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;谢磊&lt;/strong&gt;，就职于中移（苏州）软件技术有限公司。主要负责大数据集群运维、调优，以及漏洞修复。在实时数据处理和大数据分析方面有丰富经验，长期活跃于开源社区。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img data-ratio=&quot;1&quot; data-w=&quot;344&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/nD3VA87gH3kPCAmBpSHwefPpyqyAyr2B04LmnibMBMkqJ67HCmAvzsP3zmMIYPj85qs9ibGPomELyF7U2S4hD3HQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;rich_pages wxw-img&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;//  保持联络&lt;span&gt; &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;微信号 : Seatunnel&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;来，和社区一同成长！&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Apache SeaTunnel （Incubating) 是一个分布式、高性能、易扩展、用于海量数据（离线&amp;amp;实时）同步和转化的数据集成平台。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;仓库地址： &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://github.com/apache/incubator-seatunnel&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;网址：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://seatunnel.apache.org/&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Proposal：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://cwiki.apache.org/confluence/display/INCUBATOR/SeaTunnelProposal&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;衷心欢迎更多人加入！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;能够进入 Apache 孵化器，SeaTunnel 新的路程才刚刚开始，但社区的发展壮大需要更多人的加入。我们相信，在「&lt;strong&gt;Community Over Code&lt;/strong&gt;」（社区大于代码）、「&lt;strong&gt;Open and Cooperation&lt;/strong&gt;」（开放协作）、「&lt;strong&gt;Meritocracy&lt;/strong&gt;」（精英管理）、以及「&lt;strong&gt;多样性与共识决策&lt;/strong&gt;」等 The Apache Way 的指引下，我们将迎来更加多元化和包容的社区生态，共建开源精神带来的技术进步！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们诚邀各位有志于让本土开源立足全球的伙伴加入 SeaTunnel 贡献者大家庭，一起共建开源!&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;提交问题和建议：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://github.com/apache/incubator-seatunnel/issues&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;贡献代码：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;https://github.com/apache/incubator-seatunnel/pulls&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;订阅社区开发邮件列表 : &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;dev-subscribe@seatunnel.apache.org&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;开发邮件列表：&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;dev@seatunnel.apache.org&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;加入 Slack: &lt;/strong&gt;&lt;strong/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://join.slack.com/t/apacheseatunnel/shared_invite/zt-10u1eujlc-g4E~ppbinD0oKpGeoo_dAw&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关注 Twitter: &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://twitter.com/ASFSeaTunnel&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;往期推荐&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzkwNTMwNTEyNA==&amp;amp;mid=2247483779&amp;amp;idx=1&amp;amp;sn=34b89861c2d56651080f049f0e95c016&amp;amp;chksm=c0f88cc8f78f05ded430b3222c297f54e0ee7b95062f515e7183d02044f544b9c3f28b52a62c&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;全票通过！数据集成平台 SeaTunnel 成功进入 Apache 孵化器&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;全票通过！数据集成平台 SeaTunnel 成功进入 Apache 孵化器&lt;/span&gt;&lt;/a&gt;&lt;span&gt;！&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzkwNTMwNTEyNA==&amp;amp;mid=2247483836&amp;amp;idx=1&amp;amp;sn=d5228d9ecbf363d9478af81ca800a1c2&amp;amp;chksm=c0f88cf7f78f05e1266b7ca83661afdd61dbf03bd474e85fd4d5869638c2490ab67568d30f9a&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;诚邀您参与 SeaTunnel 官宣进入 Apache 孵化器后首秀&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;诚邀您参与 SeaTunnel 官宣进入 Apache 孵化器后首秀&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzkwNTMwNTEyNA==&amp;amp;mid=2247483855&amp;amp;idx=1&amp;amp;sn=7e8696f3f7f50403a8beec2eedb74500&amp;amp;chksm=c0f88c84f78f05920e0f439ac01e6731b68fbbfd465a3107a5e69c787efacc1287992e7a92d2&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;感谢陪伴 | 一路有你，真好！&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;感谢陪伴 | 一路有你，真好！&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;你&lt;span&gt;“在看”&lt;/span&gt;我吗？&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.5691057&quot; data-w=&quot;123&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AZyoUmChaxAmOJWKHundrOBsmzE1SiabjF9uvGiaFodXaSObKkVf3ycn9ECZ0RZ98TZldoZibkEZ51y7aoV778efg/640?wx_fmt=png&quot; data-type=&quot;png&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>6b636b9eaebb464527414216810bf75c</guid>
<title>春联专用喷胶，点击领券现价只需4.6元！</title>
<link>https://toutiao.io/k/1i9uqmb</link>
<content:encoded>&lt;div&gt;&lt;body data-spm=&quot;10720394/n&quot; id=&quot;readabilityBody&quot;&gt;
    
    
    
    
    
    
      
      
    
    
    
    
    
  &lt;/body&gt;
&lt;/div&gt;</content:encoded>
</item>
</channel></rss>