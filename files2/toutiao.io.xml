<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>3993bbe28ee4164e43abb808086c8393</guid>
<title>30 岁的程序员出路在哪里？| 码农周刊第 321 期</title>
<link>https://toutiao.io/k/qdeuemt</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;body class=&quot;issue&quot; id=&quot;readabilityBody&quot;&gt;
        &lt;h1&gt;30 岁的程序员出路在哪里？| 码农周刊第 321 期&lt;/h1&gt;
        &lt;h2&gt;码农周刊第321期（2020-10-15）&lt;/h2&gt;
        &lt;p&gt;☞ &lt;a href=&quot;https://weekly.manong.io/bounce?nid=321&amp;amp;aid=19568&amp;amp;url=https%3A%2F%2Fvip.manong.io%2F%3F3210&quot; target=&quot;_blank&quot;&gt;薪资翻番如何实现？程序员的涨薪秘诀&lt;/a&gt;&lt;br/&gt;&amp;#13;
&lt;a href=&quot;https://weekly.manong.io/bounce?nid=321&amp;amp;aid=19568&amp;amp;url=https%3A%2F%2Fvip.manong.io%2F%3F3210&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_321.png&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;br/&gt;&amp;#13;
&lt;small&gt;&lt;a href=&quot;https://weekly.manong.io/bounce?nid=321&amp;amp;aid=19185&amp;amp;url=https%3A%2F%2Fjinshuju.net%2Ff%2FV7DxN9&quot; target=&quot;_blank&quot;&gt;商务合作&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;程序设计&quot;&gt;程序设计&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;「码农周刊 VIP 会员专属邮件周报」每周五发送，自订购之日算起，全年 52 期。&lt;/p&gt;
        
        &lt;p&gt;最佳实践&lt;/p&gt;
        
        &lt;p&gt;偏好模型在贝壳的应用&lt;/p&gt;
        
        &lt;p&gt;实战经验&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_3041.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
        &lt;h3 id=&quot;VIP会员专区&quot;&gt;VIP会员专区&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;工作地点：成都 | 薪资：15-30K | 简历投递邮箱：xiexiaofang@huobi.com&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;共包含 9 种英伟达开发的图像及视频合成方法&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;以 DDD 思想为基础，融合中台核心要素，赋能中台建设。&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;开箱即用的中后台前端/设计解决方案&lt;/p&gt;
        &lt;h3 id=&quot;工具资料&quot;&gt;工具资料&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;「码农周刊 VIP 会员专属邮件周报」每周五发送，自订购之日算起，全年 52 期。&lt;/p&gt;
        
        &lt;p&gt;详解&lt;/p&gt;
        
        &lt;p&gt;详细介绍&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;经验分享&lt;/p&gt;
        
        &lt;p&gt;供参考&lt;/p&gt;
        
        &lt;p&gt;经验分享&lt;/p&gt;
        
        &lt;p&gt;详细介绍&lt;/p&gt;
        
        &lt;p&gt;一步步教你&lt;/p&gt;
        
        &lt;p&gt;细致讲解&lt;/p&gt;
        
        &lt;p&gt;无废话&lt;/p&gt;
        
        &lt;p&gt;详细介绍&lt;/p&gt;
        
        &lt;p&gt;适合入门&lt;/p&gt;
        
        &lt;p&gt;多维度看问题&lt;/p&gt;
        
        &lt;p&gt;&lt;a href=&quot;https://github.com/streamnative/mop&quot; target=&quot;_blank&quot;&gt;GitHub 地址&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_3041.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
        &lt;h3 id=&quot;编程语言&quot;&gt;编程语言&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;「码农周刊 VIP 会员专属邮件周报」每周五发送，自订购之日算起，全年 52 期。&lt;/p&gt;
        
        &lt;p&gt;通俗易懂&lt;/p&gt;
        
        &lt;p&gt;适合新手&lt;/p&gt;
        
        &lt;p&gt;供参考&lt;/p&gt;
        
        &lt;p&gt;详细介绍&lt;/p&gt;
        
        &lt;p&gt;详解&lt;/p&gt;
        
        &lt;p&gt;完备分析&lt;/p&gt;
        
        &lt;p&gt;结合代码&lt;/p&gt;
        
        &lt;p&gt;代码示例&lt;/p&gt;
        
        &lt;p&gt;通俗易懂&lt;/p&gt;
        
        &lt;p&gt;经验分享&lt;/p&gt;
        
        &lt;p&gt;详解&lt;/p&gt;
        
        &lt;p&gt;细致分析&lt;/p&gt;
        &lt;h3 id=&quot;每周独家号推荐&quot;&gt;每周独家号推荐&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;一线互联网工程师，分享Linux C++ Go Python等后端开发技术。&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 444675 即可&lt;/p&gt;
        
        &lt;p&gt;老年程序猿，工作15年以上。以前极其不擅长写作，最近决定对着弱点迎难而上，写写原创的经验、心得。&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 426740 即可&lt;/p&gt;
        
        &lt;p&gt;分享一些在 ThinkJS 项目开发过程中总结的一些经验以及问题&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 253319 即可&lt;/p&gt;
        
        &lt;p&gt;专注互联网金融&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 26661 即可&lt;/p&gt;
        
        &lt;p&gt;主要是分享作为一个机器学习算法工程师的工作学习生活方面的内容，包括Python编程、机器学习和深度学习算法知识，偶尔可能分享一些计算机基础方面的知识，以及一些练习项目等&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 1584 即可&lt;/p&gt;
        &lt;h3 id=&quot;每周一书&quot;&gt;每周一书&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;本书介绍了 Kotlin 的基本语法、常用类型、面向对象编程以及一些高阶的知识。欢迎到&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;兑换阅读。&lt;/p&gt;
        &lt;h3 id=&quot;编程之外&quot;&gt;编程之外&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;天无绝程序员之路&lt;/p&gt;
        
        &lt;p&gt;供参考&lt;/p&gt;
        
        &lt;p&gt;经验之谈&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_3041.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
        &lt;p&gt;
        &lt;/p&gt;
        
        
        
        
        &lt;div class=&quot;qrcode&quot;&gt;
  &lt;img src=&quot;https://img.toutiao.io/ads/vip_qrcode.png&quot; alt=&quot;Qrcode 258&quot;/&gt;&lt;span&gt;加入码农周刊VIP会员&lt;/span&gt;
&lt;/div&gt;
    &lt;/body&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>37d366bafa8c5238523f4b6ef8320a53</guid>
<title>基于 Flink 实时计算商品订单流失量</title>
<link>https://toutiao.io/k/ta8nmrj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设有个需求需要实时计算商品的订单流失量，规则如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;用户点击商品 A，但购买了同类商品 B，则商品 A 记为一次订单流失量；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;点击商品 A 到购买同类商品 B 的有效时间窗口应该小于 12 个小时；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;有效窗口内多次点击商品 A 视为一次订单流失。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第三条规则可以理解为数据流去重，我在上一节已经介绍过了。为了更加专注于计算商品的订单流失量，本篇文章不再关注数据去重。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到这个需求，想到可以用上一节的 ProcessFunction 进行状态管理，比如说基于用户进行分流，然后每个用户维护一个状态和一个有效时间窗口，触发购买同类事件后进行数据统计，过了有效期后舍弃。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，有没有更优雅的一点方式呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答案是有的，我们可以使用 Flink 自带的 CEP 来实现。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面先简单介绍下 FlinkCEP，然后给出代码实践。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.FlinkCEP&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.1 什么是 CEP&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CEP 全称为 Complex Event Process，是在 Flink 之上实现的复杂事件处理（CEP）库。它允许你在无界的事件流中检测事件模式，让你有机会掌握数据中重要的事项。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：“起床--&amp;gt;洗漱--&amp;gt;吃饭--&amp;gt;上班”这一系列串联起来的事件流形成的模式称为 CEP。如果发现某一次起床后没有刷牙洗脸亦或是吃饭就直接上班，就可以把这种非正常的事件流匹配出来进行分析，看看今天是不是起晚了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再举几个经典例子：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;异常检测：打车计费后 12 小时还未结束订单；用户短时间内连续完成多个订单；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;实时营销：用户在不同平台进行比价；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据监控：检测某些指标，比如订单流失量。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.2 FlinkCEP 原理&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;FlinkCEP 内部是用 &lt;strong&gt;「NFA（非确定有限自动机）&lt;strong&gt;「来实现的，由点和边组成的一个状态图，以一个初始状态作为起点，经过一系列的中间状态，达到终态。点分为」&lt;/strong&gt;起始状态」&lt;/strong&gt;、&lt;strong&gt;「中间状态」&lt;/strong&gt;、&lt;strong&gt;「最终状态」&lt;/strong&gt;三种，边分为 &lt;strong&gt;「take」&lt;/strong&gt;、&lt;strong&gt;「ignore」&lt;/strong&gt;、&lt;strong&gt;「proceed」&lt;/strong&gt; 三种。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.36666666666666664&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/210IyDic7rafcRdtzhZOkAGw6763nVBBmzMLNwlaoupt2K3AZ871UwJJzKJv8npB7xOumGia3PYfzia8DOR0TLA5g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;「take」&lt;/strong&gt;：必须存在一个条件判断，当到来的消息满足 take 边条件判断时，把这个消息放入结果集，将状态转移到下一状态。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;「ignore」&lt;/strong&gt;：当消息到来时，可以忽略这个消息，将状态自旋在当前不变，是一个自己到自己的状态转移。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;「proceed」&lt;/strong&gt;：又叫做状态的空转移，当前状态可以不依赖于消息到来而直接转移到下一状态。举个例子，当用户购买商品时，如果购买前有一个咨询客服的行为，需要把咨询客服行为和购买行为两个消息一起放到结果集中向下游输出；如果购买前没有咨询客服的行为，只需把购买行为放到结果集中向下游输出就可以了。也就是说，如果有咨询客服的行为，就存在咨询客服状态的上的消息保存，如果没有咨询客服的行为，就不存在咨询客服状态的上的消息保存，咨询客服状态是由一条 proceed 边和下游的购买状态相连。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，在我们的场景中不会涉及太多复杂的概念。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.FlinkCEP 简单上手&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本节内容引用参考 1，用于完成基本的概念讲解和 Demo 实现。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1 单个 Pattern&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们先从简单的内容入手。看看在单个Pattern下，Flink CEP是如何匹配的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.1.1 各个API的用法&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在学习 Flink CEP 的过程中，很容易找到相似的博文，文章中使用表格列举出了各个 API 的作用。然而大家很容易发现，这东西太像正则表达式了（实际上底层匹配逻辑的实现方式应该也和正则表达式类似）。因此，结合正则表达式理解这些 API 显得十分快速，所以我自作主张，加上了功能相近的正则表达式。例如，我们要用 CEP 匹配字母 x：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.7058823529411765&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/210IyDic7rafcRdtzhZOkAGw6763nVBBmUWPsqULoQAwlCbEOLdeS3uc6O1WxoN53KIl7fpV95X3fq5PAbxDSSw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1326&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.1.2 仅使用 where 和 or 写一个程序&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如说，我们现在有一个简单的需求，对于输入的数据流中，匹配所有以 x 或 y 开头的数据：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;CepDemo&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;var&lt;/span&gt; environment = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;        &lt;span&gt;var&lt;/span&gt; stream = environment.setParallelism(&lt;span&gt;1&lt;/span&gt;).addSource(&lt;span&gt;new&lt;/span&gt; ReadLineSource(&lt;span&gt;&quot;Data.txt&quot;&lt;/span&gt;));&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 使用 where 和 or 来定义两个需求；&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 当然也可以放在一个 where 里。&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;var&lt;/span&gt; pattern = Pattern.&amp;lt;String&amp;gt;begin(&lt;span&gt;&quot;start&quot;&lt;/span&gt;).where(&lt;span&gt;new&lt;/span&gt; IterativeCondition&amp;lt;&amp;gt;() {&lt;br/&gt;            &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; &lt;span&gt;filter&lt;/span&gt;&lt;span&gt;(String s, Context&amp;lt;String&amp;gt; context)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;                &lt;span&gt;return&lt;/span&gt; s.startsWith(&lt;span&gt;&quot;x&quot;&lt;/span&gt;);&lt;br/&gt;            }&lt;br/&gt;        }).or(&lt;span&gt;new&lt;/span&gt; IterativeCondition&amp;lt;&amp;gt;() {&lt;br/&gt;            &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; &lt;span&gt;filter&lt;/span&gt;&lt;span&gt;(String s, Context&amp;lt;String&amp;gt; context)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;                &lt;span&gt;return&lt;/span&gt; s.startsWith(&lt;span&gt;&quot;y&quot;&lt;/span&gt;);&lt;br/&gt;            }&lt;br/&gt;        });&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// CEP.pattern 的第一个参数是数据流，第二个是规则；&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 然后利用 select 方法抽取出匹配到的数据。&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 这里用了 lambda 表达式&lt;/span&gt;&lt;br/&gt;        CEP.pattern(stream, pattern).select((map -&amp;gt;&lt;br/&gt;                Arrays.toString(map.get(&lt;span&gt;&quot;start&quot;&lt;/span&gt;).toArray()))&lt;br/&gt;        ).addSink(&lt;span&gt;new&lt;/span&gt; SinkFunction&amp;lt;&amp;gt;() {&lt;br/&gt;            &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;invoke&lt;/span&gt;&lt;span&gt;(String value, Context context)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;                System.out.println(value);&lt;br/&gt;            }&lt;br/&gt;        });&lt;br/&gt;        environment.execute();&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于输入的数据流：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;x1&lt;br/&gt;z2&lt;br/&gt;c3&lt;br/&gt;y4&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们有输出：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;读取：x1   &lt;br/&gt;[x1]   &lt;br/&gt;读取：z2   &lt;br/&gt;读取：c3   &lt;br/&gt;读取：y4   &lt;br/&gt;[y4]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到，Flink CEP 可以根据输入的每一条数据进行匹配。单条数据可以是本文中的字符串，也可以是复杂的事件对象，当然也可以是字符。如果每一条数据都是一个字符，那 CEP 就和正则表达式十分相似了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.1.3 加上量词&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来，还是在单个 Pattern 中，我们加上量词 API，研究研究 Flink CEP 是如何匹配多条数据的。从这里开始，事情和正则表达式有了一些差距。差距主要在结果的数量上。由于是流计算，因此在实际处理过程中，Flink 无法知道后续的数据，所以会输出所有匹配的结果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如，使用 timesOrMore() 函数，匹配以 a 开头的字符串出现 3 次及以上的情况，首先编写代码(其他代码与上方的例子完全一致，为节约篇幅不再列出，下同)：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;var&lt;/span&gt; pattern = Pattern.&amp;lt;String&amp;gt;begin(&lt;span&gt;&quot;start&quot;&lt;/span&gt;).where(&lt;span&gt;new&lt;/span&gt; IterativeCondition&amp;lt;&amp;gt;() {&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; &lt;span&gt;filter&lt;/span&gt;&lt;span&gt;(String s, Context&amp;lt;String&amp;gt; context)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; s.startsWith(&lt;span&gt;&quot;a&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}).timesOrMore(&lt;span&gt;3&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随后在Data.txt中输入如下字符串序列：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;a1&lt;br/&gt;a2&lt;br/&gt;a3&lt;br/&gt;b1&lt;br/&gt;a4&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行程序，输出如下结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;读取：a1&lt;br/&gt;读取：a2&lt;br/&gt;读取：a3&lt;br/&gt;[a1, a2, a3]&lt;br/&gt;读取：b1&lt;br/&gt;读取：a4&lt;br/&gt;[a1, a2, a3, a4]&lt;br/&gt;[a2, a3, a4]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面分析一下执行流程。程序开始后，等待数据流入。当a1和a2输入后，由于暂时不满足条件，所以没有产生结果，只是将数据储存在状态中。a3到来后，第一次满足了匹配条件，因此程序输出结果 &lt;span&gt;[a1, a2, a3]&lt;/span&gt;。随后，b1输入，不满足条件；接下来a4输入。此时，a1、a2和a3依旧储存在状态中，因此依然可以参与匹配。匹配可以产生多个结果，但是有两个原则：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;必须严格按照数据流入的顺序；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;产生的结果必须包含当前元素；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;原则 1 很好理解，由于数据的流入是按照 a1 -&amp;gt; a2 -&amp;gt; a3 -&amp;gt; a4 的顺序，所以结果生成的序列也必须按照这个顺序，不能删减中间数据，更不能打乱顺序。因此， [a1, a2, a4] 和  [a3, a2, a4, a1] 这种结果是不可能生成的。原则 2 就更好理解了，数据是因为 a4 的流入才产生的，再考虑到我们设定的量词条件是“三个及以上”，因此产生的结果只可能是 [a2, a3, a4] 和 [a1, a2, a3, a4]。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同理，如果我们在 Data.txt 最后加入一行 a5，则程序输出结果如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;读取：a1&lt;br/&gt;读取：a2&lt;br/&gt;读取：a3&lt;br/&gt;[a1, a2, a3]&lt;br/&gt;读取：b1&lt;br/&gt;读取：a4&lt;br/&gt;[a1, a2, a3, a4]&lt;br/&gt;[a2, a3, a4]&lt;br/&gt;读取：a5&lt;br/&gt;[a1, a2, a3, a4, a5]&lt;br/&gt;[a2, a3, a4, a5]&lt;br/&gt;[a3, a4, a5]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;按照这种思路，如果我们继续加上 a6、a7、a8、……、a100，那么每个数据产生的结果会越来越多，因为 Flink CEP 会把所有符合条件的数据储存在状态里。&lt;strong&gt;「这样下去不行的，要不然内存养不起它的」&lt;/strong&gt;。因此，oneOrMore() 和 timesOrMore() 之类的函数后面，一般都要跟上 until() 函数，从而指定终止条件。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.1.4 把量词换成 times()&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果使用和上面一样的数据，但是把量词换成 times(3)，会产生什么样的结果？我们首先修改代码：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;var pattern = Pattern.&amp;lt;String&amp;gt;begin(&lt;span&gt;&quot;start&quot;&lt;/span&gt;).&lt;span&gt;where&lt;/span&gt;(new IterativeCondition&amp;lt;&amp;gt;() {&lt;br/&gt;    @Override&lt;br/&gt;    public boolean filter(String s, Context&amp;lt;String&amp;gt; context) {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; s.startsWith(&lt;span&gt;&quot;a&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}).&lt;span&gt;times&lt;/span&gt;(3);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于固定了只匹配三个，再加上前文提到的两个原则的束缚，结果就很明显了：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;读取：a1&lt;br/&gt;读取：a2&lt;br/&gt;读取：a3&lt;br/&gt;[a1, a2, a3]&lt;br/&gt;读取：b1&lt;br/&gt;读取：a4&lt;br/&gt;[a2, a3, a4]&lt;br/&gt;读取：a5&lt;br/&gt;[a3, a4, a5]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从 a1 到 b1 的逻辑完全相同，当读取到 a4 时，由于只匹配 3 个，同时结果必须包含 a4，因此产生的结果只能是 [a2, a3, a4] 。同理读取到 a5 后，由于结果必须包含 a5 且只匹配 3 个，所以结果只能是 [a3, a4, a5] 。这种情况下，过期的数据会被清理掉，妈妈再也不用担心我的内存不够用了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了固定参数，times() 函数还支持 times(from, to) 指定边界。这种情况下的匹配结果和上文类似，相信大家很容易就能推出来，在此我就不再赘述了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.1.5 使用严格模式&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家也许注意到，上文的 Data.txt 中，一直有一个讨厌的 b1。由于不满足我们的基本匹配条件，b1 直接被我们的程序忽略掉了。这是因为 Flink CEP 默认采用了不严格的匹配模式，而在某些情况下，这种数据是不能忽略的，这时候就可以使用 consecutive() 函数，指定严格的匹配模式。修改代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;var pattern = Pattern.&amp;lt;String&amp;gt;begin(&lt;span&gt;&quot;start&quot;&lt;/span&gt;).&lt;span&gt;where&lt;/span&gt;(new IterativeCondition&amp;lt;&amp;gt;() {&lt;br/&gt;    @Override&lt;br/&gt;    public boolean filter(String s, Context&amp;lt;String&amp;gt; context) {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; s.startsWith(&lt;span&gt;&quot;a&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}).&lt;span&gt;times&lt;/span&gt;(3).consecutive();&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行程序，产生如下结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;读取：a1&lt;br/&gt;读取：a2&lt;br/&gt;读取：a3&lt;br/&gt;[a1, a2, a3]&lt;br/&gt;读取：b1&lt;br/&gt;读取：a4&lt;br/&gt;读取：a5&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时，由于 a1、a2、a3 是紧密相连的，因此被成功匹配。而 a2、a3、a4 和 a3、a4、a5 中间由于多了一个 b1，在严格模式下不能被匹配。可以看出，严格模式下的匹配策略更像正则表达式。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.2 多个 Pattern&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般而言，需要使用 CEP 的任务都得依靠多个 Pattern 才能解决。此时，可以使用 followedBy()、next() 等函数创建一个新的 Pattern，并按照不同的逻辑将新 Pattern 和前一个 Pattern 连接起来。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.2.1 使用 followedBy() 创建一个新的 Pattern&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们再来看一下如何处理多个 Pattern，比如说我们需要匹配“包含 2-3 个 a 开头的字符串，同时包含 1-2 个 b 开头的字符串”的输入数据。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;// 我们用 times(2,3) 来控制匹配 2-3 次；&lt;/span&gt;&lt;br/&gt;&lt;span&gt;// followBy 用于控制两个具有顺序的关系的 Pattern。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;var&lt;/span&gt; pattern = Pattern.&amp;lt;String&amp;gt;begin(&lt;span&gt;&quot;start&quot;&lt;/span&gt;).where(&lt;span&gt;new&lt;/span&gt; IterativeCondition&amp;lt;&amp;gt;() {&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; &lt;span&gt;filter&lt;/span&gt;&lt;span&gt;(String s, Context&amp;lt;String&amp;gt; context)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; s.startsWith(&lt;span&gt;&quot;a&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}).times(&lt;span&gt;2&lt;/span&gt;, &lt;span&gt;3&lt;/span&gt;).followedBy(&lt;span&gt;&quot;middle&quot;&lt;/span&gt;).where(&lt;span&gt;new&lt;/span&gt; IterativeCondition&amp;lt;String&amp;gt;() {&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; &lt;span&gt;filter&lt;/span&gt;&lt;span&gt;(String s, Context&amp;lt;String&amp;gt; context)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; s.startsWith(&lt;span&gt;&quot;b&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}).times(&lt;span&gt;1&lt;/span&gt;, &lt;span&gt;2&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;CEP.pattern(stream, pattern).select(map -&amp;gt; {&lt;br/&gt;    &lt;span&gt;// 把匹配的结果装进 list 中。&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;var&lt;/span&gt; list = map.get(&lt;span&gt;&quot;start&quot;&lt;/span&gt;);&lt;br/&gt;    list.addAll(map.get(&lt;span&gt;&quot;middle&quot;&lt;/span&gt;));&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; Arrays.toString(list.toArray());&lt;br/&gt;}).addSink(&lt;span&gt;new&lt;/span&gt; SinkFunction&amp;lt;&amp;gt;() {&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;invoke&lt;/span&gt;&lt;span&gt;(String value, Context context)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        System.out.println(value);&lt;br/&gt;    }&lt;br/&gt;});&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我们使用了 followedBy () 函数，该函数创建了一个名为 “middle” 的新 Pattern，新 Pattern 中包含了指向原 Pattern 的引用。同样发生变化的是 select 函数中的 lambda 表达式。在表达式中，我们除了获取名为 “start” 的 Pattern 中的数据，还获取了名为 “middle” 的 Pattern 的数据，并将他们拼在一起。这与正则表达式中的子表达式特别类似，实际上，我们可以将每个 Pattern 近似看作一个子表达式，在读取结果的时候，使用 Pattern 的名字，从 map 中提取出结果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据的输入为：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;a1&lt;br/&gt;a2&lt;br/&gt;a3&lt;br/&gt;b1&lt;br/&gt;a4&lt;br/&gt;a5&lt;br/&gt;b2&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据输出为：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;读取：a1&lt;br/&gt;读取：a2&lt;br/&gt;读取：a3&lt;br/&gt;读取：b1&lt;br/&gt;[a1, a2, a3, b1]&lt;br/&gt;[a1, a2, b1]&lt;br/&gt;[a2, a3, b1]&lt;br/&gt;读取：a4&lt;br/&gt;读取：a5&lt;br/&gt;读取：b2&lt;br/&gt;[a1, a2, a3, b1, b2]&lt;br/&gt;[a1, a2, b1, b2]&lt;br/&gt;[a2, a3, a4, b2]&lt;br/&gt;[a2, a3, b1, b2]&lt;br/&gt;[a3, a4, a5, b2]&lt;br/&gt;[a3, a4, b2]&lt;br/&gt;[a4, a5, b2]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一下子产生了这么多数据，我一开始还是很懵的。接下来我们逐步分析下：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;a1, a2 依次读入，不满足整体条件，但是满足 “start” 条件，且产生了 [a1, a2] 这一中间结果，存在状态中；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;a3 读入，不满足整体条件，但是满足 “start” 条件，且产生了 [a2, a3] 和 [a1, a2, a3] 两个结果；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;b1 读入，满足 “middle” 条件，产生 [b1] 中间结果。此时整体条件满足，因此和上述中间结果组合输出 [a1, a2, a3, b1] 、 [a1, a2, b1] 和 [a2, a3, b1] ；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;a4 读入，继续满足 “start” 条件，产生 [a2, a3, a4] 和 [a3, a4]；两个结果，但是由于这两个结果是在 b1 读入之后产生的，因此这两个结果不能和 [b1] 进行组合；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;a5 读入，继续满足 “start” 条件，产生 [a3, a4, a5] 和 [a4, a5] 两个中间结果，同理不能和 [b1] 进行组合；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;b2 读入，继续满足 “middle” 条件，产生 [b1, b2] 和 [b2] 两个中间结果。这里开始比较复杂了，需要严格结合时间顺序来分析。由于 b1 是在 a4 之前读入的，因此包含 b1 的序列 [b1, b2] 只能与 [a1, a2] 、 [a2, a3] 和 [a1, a2, a3] 进行关联。而 [b2] 则可以与包含了 a4 或 a5 的 [a2, a3, a4] 、 [a3, a4]、 [a3, a4, a5] 和 [a4, a5] 四个序列关联，因此此时输出结果如下：&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[a1, a2, a3, b1, b2]    // [a1, a2, a3] 和 [b1, b2] 关联&lt;br/&gt;[a1, a2, b1, b2]        // [a1, a2] 和 [b1, b2] 关联&lt;br/&gt;[a2, a3, a4, b2]        // [a2, a3, a4] 和 [b2] 关联&lt;br/&gt;[a2, a3, b1, b2]        // [a2, a3] 和 [b1, b2] 关联&lt;br/&gt;[a3, a4, a5, b2]        // [a3, a4, a5] 和 [b2] 关联&lt;br/&gt;[a3, a4, b2]            // [a3, a4] 和 [b2] 关联&lt;br/&gt;[a4, a5, b2]            // [a4, a5] 和 [b2] 关联&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么有一个问题，为什么 [b2] 不能与 [a1, a2] 、 [a2, a3] 和 [a1, a2, a3] 进行关联呢？还是要站在时间序列的角度进行解释。因为只有 b1 是跟随在这三个元素后面的，所以只有包含 b1 的两个序列（[b1] 和 [b1, b2]）可以和它们进行关联，这就是 followedBy 的含义。为了验证这一观点，我们在 Data.txt 最后加上一个 b3，在其他代码均不变的情况下，最后读入 b3 后，输出如下结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[a2, a3, a4, b2, b3]&lt;br/&gt;[a3, a4, a5, b2, b3]&lt;br/&gt;[a3, a4, b2, b3]&lt;br/&gt;[a4, a5, b2, b3]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分析如下：当读入 b3 后，满足 “middle” 条件，生成 [b2, b3] 和 [b3]。其中，只有 [b2, b3] 包含了 b2，由于 b2 是距离 [a2, a3, a4] 、 [a3, a4]、 [a3, a4, a5] 和 [a4, a5] 四个序列最近的数据，因此只有 [b2, b3] 才能和上述四个序列关联。而 [b3] 由于不包含 b2，因此无法和它们关联。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.2.2 将 followedBy() 换成 next()&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以将 next () 看作是加强版的 followedBy ()。在 followedBy 中，两个 Pattern 直接允许不紧密连接，例如上文中的 [a1, a2] 和 [b1] ，他们中间隔了一个 a3. 这种数据在 next () 中会被丢弃掉。使用上文同样的数据（不包括 b3），将代码中的 followedBy 换成 next，修改如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;var pattern = Pattern.&amp;lt;String&amp;gt;begin(&lt;span&gt;&quot;start&quot;&lt;/span&gt;).&lt;span&gt;where&lt;/span&gt;(new IterativeCondition&amp;lt;&amp;gt;() {&lt;br/&gt;    @Override&lt;br/&gt;    public boolean filter(String s, Context&amp;lt;String&amp;gt; context) {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; s.startsWith(&lt;span&gt;&quot;a&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}).&lt;span&gt;times&lt;/span&gt;(2, 3).next(&lt;span&gt;&quot;middle&quot;&lt;/span&gt;).&lt;span&gt;where&lt;/span&gt;(new IterativeCondition&amp;lt;String&amp;gt;() {&lt;br/&gt;    @Override&lt;br/&gt;    public boolean filter(String s, Context&amp;lt;String&amp;gt; context) throws Exception {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; s.startsWith(&lt;span&gt;&quot;b&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}).&lt;span&gt;times&lt;/span&gt;(1, 2);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行后，看到如下结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;读取：a1&lt;br/&gt;读取：a2&lt;br/&gt;读取：a3&lt;br/&gt;读取：b1&lt;br/&gt;[a1, a2, a3, b1]&lt;br/&gt;[a2, a3, b1]&lt;br/&gt;读取：a4&lt;br/&gt;读取：a5&lt;br/&gt;读取：b2&lt;br/&gt;[a1, a2, a3, b1, b2]&lt;br/&gt;[a2, a3, b1, b2]&lt;br/&gt;[a3, a4, a5, b2]&lt;br/&gt;[a4, a5, b2]&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;和之前的结果进行分析，发现结果中的 [a1, a2, b1] 、 [a1, a2, b1, b2]、 [a2, a3, a4, b2] 和 [a3, a4, b2] 均被排除，因为他们相比原序列，分别缺少了 a3、a3、a5、a5。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;span/&gt;2.2.3 greedy() 做了什么&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于 greedy () 的用法，可以说是十分令人迷惑的。我看了许多文章，对 greedy () 的描述几乎都是一笔带过。描述大多是 “尽可能多的匹配”，但是实际上，大多数情况下加不加 greedy () 几乎没有任何区别。&lt;strong&gt;「因为 greedy () 虽然被归为量词 API，但是它实际上是在多个 Pattern 中才能起作用的。」&lt;/strong&gt; 为此，我找到了 greedy () 的实现逻辑，在 NFACompiler 类的 updateWithGreedyCondition 方法中，代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;private void updateWithGreedyCondition(&lt;br/&gt; State&amp;lt;T&amp;gt; state,&lt;br/&gt; IterativeCondition&amp;lt;T&amp;gt; takeCondition) {&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; (StateTransition&amp;lt;T&amp;gt; stateTransition : state.getStateTransitions()) {&lt;br/&gt;  stateTransition.setCondition(&lt;br/&gt;   new RichAndCondition&amp;lt;&amp;gt;(stateTransition.getCondition(), &lt;br/&gt;   new RichNotCondition&amp;lt;&amp;gt;(takeCondition)));&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阅读代码，发现该方法实际上添加了一个逻辑：&lt;strong&gt;「确认当前条件满足转换到下一个 state 所需的条件，且不满足当前 state 的条件」&lt;/strong&gt;。意思就是，如果当前处于 Pattern1，但是出现了一条同时满足两个 Pattern1 和 Pattern2 条件的数据，在不加 greedy () 的情况下，会跳转到 Pattern2，但是如果加了 greedy ()，则会留在 Pattern1。下面我们来验证一下，编写如下代码：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;var pattern = Pattern.&amp;lt;String&amp;gt;begin(&lt;span&gt;&quot;start&quot;&lt;/span&gt;).&lt;span&gt;where&lt;/span&gt;(new IterativeCondition&amp;lt;&amp;gt;() {&lt;br/&gt;    @Override&lt;br/&gt;    public boolean filter(String s, Context&amp;lt;String&amp;gt; context) {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; s.startsWith(&lt;span&gt;&quot;a&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}).&lt;span&gt;times&lt;/span&gt;(2, 3).next(&lt;span&gt;&quot;middle&quot;&lt;/span&gt;).&lt;span&gt;where&lt;/span&gt;(new IterativeCondition&amp;lt;String&amp;gt;() {&lt;br/&gt;    @Override&lt;br/&gt;    public boolean filter(String s, Context&amp;lt;String&amp;gt; context) throws Exception {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; s.length() == 3;&lt;br/&gt;    }&lt;br/&gt;}).&lt;span&gt;times&lt;/span&gt;(1, 2);&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这一代码中，如果一条数据为a开头，且长度为3，则同时满足“start”和“middle”。同时，为了方便区分数据到底属于哪个Pattern，我们在输出前加入分隔符：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;CEP.pattern(stream, pattern).select(map -&amp;gt; {&lt;br/&gt;    var list = map.get(&lt;span&gt;&quot;start&quot;&lt;/span&gt;);&lt;br/&gt;    list.add(&lt;span&gt;&quot;|&quot;&lt;/span&gt;);&lt;br/&gt;    list.addAll(map.get(&lt;span&gt;&quot;middle&quot;&lt;/span&gt;));&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; Arrays.toString(list.toArray());&lt;br/&gt;}).addSink(new SinkFunction&amp;lt;&amp;gt;() {&lt;br/&gt;    @Override&lt;br/&gt;    public void invoke(String value, Context context) {&lt;br/&gt;        System.out.println(value);&lt;br/&gt;    }&lt;br/&gt;});&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;准备如下数据：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;a&lt;br/&gt;a1&lt;br/&gt;a22&lt;br/&gt;b33&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在不加greedy()的情况下，运行结果如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;读取：a&lt;br/&gt;读取：a1&lt;br/&gt;读取：a22&lt;br/&gt;[a, a1, |, a22]&lt;br/&gt;读取：b33&lt;br/&gt;[a, a1, a22, |, b33]&lt;br/&gt;[a, a1, |, a22, b33]&lt;br/&gt;[a1, a22, |, b33]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;观察结果，可知a22在两个Pattern中左右横跳，输出了所有可能的结果。接下来我们加上greedy()：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;var pattern = Pattern.&amp;lt;String&amp;gt;begin(&lt;span&gt;&quot;start&quot;&lt;/span&gt;).&lt;span&gt;where&lt;/span&gt;(new IterativeCondition&amp;lt;&amp;gt;() {&lt;br/&gt;    @Override&lt;br/&gt;    public boolean filter(String s, Context&amp;lt;String&amp;gt; context) {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; s.startsWith(&lt;span&gt;&quot;a&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}).&lt;span&gt;times&lt;/span&gt;(2, 3).greedy().next(&lt;span&gt;&quot;middle&quot;&lt;/span&gt;).&lt;span&gt;where&lt;/span&gt;(new IterativeCondition&amp;lt;String&amp;gt;() {&lt;br/&gt;    @Override&lt;br/&gt;    public boolean filter(String s, Context&amp;lt;String&amp;gt; context) throws Exception {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; s.length() == 3;&lt;br/&gt;    }&lt;br/&gt;}).&lt;span&gt;times&lt;/span&gt;(1, 2);&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行结果如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;读取：a&lt;br/&gt;读取：a1&lt;br/&gt;读取：a22&lt;br/&gt;读取：b33&lt;br/&gt;[a, a1, a22, |, b33]&lt;br/&gt;[a1, a22, |, b33]&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时，a22 被划到了 “start” 这一 Pattern 中。由此可见，greedy () 影响的是 “同时满足两个 Pattern 条件的数据的划分逻辑”，而且加了 greedy () 后，产生的结果会变少，并不是直观印象中的，产生尽可能多条的数据。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.代码实践&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单看一下代码，主要以注释方式进行讲解&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输入数据为：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;952483,310884,4580532,pv,1511712000&lt;br/&gt;952483,5119439,982926,pv,1511712000&lt;br/&gt;952483,4484065,1320293,pv,1511712000&lt;br/&gt;952483,5097906,149192,pv,1511712000&lt;br/&gt;952483,2348702,3002561,pv,1511712000&lt;br/&gt;952483,2157435,1013319,buy,1511712020&lt;br/&gt;952483,1132597,4181361,pv,1511712020&lt;br/&gt;952483,3505100,2465336,pv,1511712020&lt;br/&gt;952483,3815446,2342116,pv,1511712030&lt;br/&gt;952483,3815446,2442116,buy,1511712030&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据源代码为：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; com.aze.producer;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.streaming.api.functions.source.SourceFunction;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; java.io.BufferedReader;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; java.io.FileReader;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;/**&lt;br/&gt; * &lt;span&gt;@Author&lt;/span&gt;: aze&lt;br/&gt; * &lt;span&gt;@Date&lt;/span&gt;: 2020-09-16 14:41&lt;br/&gt; */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ReadLineSource&lt;/span&gt;  &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;SourceFunction&lt;/span&gt;&amp;lt;&lt;span&gt;String&lt;/span&gt;&amp;gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; String filePath;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; canceled = &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;ReadLineSource&lt;/span&gt;&lt;span&gt;(String filePath)&lt;/span&gt;&lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;this&lt;/span&gt;.filePath = filePath;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;run&lt;/span&gt;&lt;span&gt;(SourceContext&amp;lt;String&amp;gt; sourceContext)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;        BufferedReader reader = &lt;span&gt;new&lt;/span&gt; BufferedReader(&lt;span&gt;new&lt;/span&gt; FileReader(filePath));&lt;br/&gt;        &lt;span&gt;while&lt;/span&gt; (!canceled &amp;amp;&amp;amp; reader.ready()){&lt;br/&gt;            String line = reader.readLine();&lt;br/&gt;            sourceContext.collect(line);&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;cancel&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        canceled = &lt;span&gt;true&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主代码为&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; com.aze.consumer;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; lombok.val;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; com.aze.producer.ReadLineSource;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.api.common.eventtime.WatermarkStrategy;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.api.common.state.ValueState;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.api.common.state.ValueStateDescriptor;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.api.java.functions.KeySelector;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.cep.CEP;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.cep.nfa.aftermatch.AfterMatchSkipStrategy;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.cep.pattern.Pattern;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.cep.pattern.conditions.IterativeCondition;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.configuration.Configuration;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.streaming.api.TimeCharacteristic;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.streaming.api.functions.KeyedProcessFunction;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.streaming.api.windowing.time.Time;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; org.apache.flink.util.Collector;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; java.time.Duration;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;/**&lt;br/&gt; * 订单流失率&lt;br/&gt; *&lt;br/&gt; * &lt;span&gt;@Author&lt;/span&gt;: aze&lt;br/&gt; * &lt;span&gt;@Date&lt;/span&gt;: 2020-09-23 14:45&lt;br/&gt; */&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;OrderLostCEP&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;        val env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;        env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);&lt;br/&gt;        env.setParallelism(&lt;span&gt;1&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;        val dataStream = env.addSource(&lt;span&gt;new&lt;/span&gt; ReadLineSource(&lt;span&gt;&quot;src/main/resources/data.txt&quot;&lt;/span&gt;));&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 先配置一下事件时间&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 然后利用 uid 和商品类别进行分组（商品类别的第一个字母代表一级类别）&lt;/span&gt;&lt;br/&gt;        val keyStream = dataStream.assignTimestampsAndWatermarks(WatermarkStrategy&lt;br/&gt;                .&amp;lt;String&amp;gt;forBoundedOutOfOrderness(Duration.ofSeconds(&lt;span&gt;30&lt;/span&gt;))&lt;br/&gt;                .withTimestampAssigner((SerializableTimestampAssigner&amp;lt;String&amp;gt;)&lt;br/&gt;                        (s, l) -&amp;gt; Long.parseLong(s.split(&lt;span&gt;&quot;,&quot;&lt;/span&gt;)[&lt;span&gt;4&lt;/span&gt;]) * &lt;span&gt;1000&lt;/span&gt;))&lt;br/&gt;                .keyBy((KeySelector&amp;lt;String, String&amp;gt;) s -&amp;gt;&lt;br/&gt;                        s.split(&lt;span&gt;&quot;,&quot;&lt;/span&gt;)[&lt;span&gt;0&lt;/span&gt;] + &lt;span&gt;&quot;-&quot;&lt;/span&gt; + s.split(&lt;span&gt;&quot;,&quot;&lt;/span&gt;)[&lt;span&gt;2&lt;/span&gt;].substring(&lt;span&gt;0&lt;/span&gt;, &lt;span&gt;1&lt;/span&gt;));&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 我们采用不丢弃的策略，主要逻辑在于，点击商品 A，而购买同类商品 B 和同类商品 C 算作两次订单流失&lt;/span&gt;&lt;br/&gt;        val noSkip = AfterMatchSkipStrategy.noSkip();&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 制定一个匹配规则；&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 用 followedByAny 指定不确定的松散连续，读者可以试下其与 followedBy 的区别。&lt;/span&gt;&lt;br/&gt;        val pattern = Pattern&lt;br/&gt;                .&amp;lt;String&amp;gt;begin(&lt;span&gt;&quot;start&quot;&lt;/span&gt;, noSkip).where(&lt;span&gt;new&lt;/span&gt; IterativeCondition&amp;lt;String&amp;gt;() {&lt;br/&gt;                    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; &lt;span&gt;filter&lt;/span&gt;&lt;span&gt;(String s, Context&amp;lt;String&amp;gt; ctx)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;                        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;&quot;pv&quot;&lt;/span&gt;.equals(s.split(&lt;span&gt;&quot;,&quot;&lt;/span&gt;)[&lt;span&gt;3&lt;/span&gt;]);&lt;br/&gt;                    }&lt;br/&gt;                }).within(Time.minutes(&lt;span&gt;10&lt;/span&gt;))&lt;br/&gt;                .followedByAny(&lt;span&gt;&quot;end&quot;&lt;/span&gt;).where(&lt;span&gt;new&lt;/span&gt; IterativeCondition&amp;lt;String&amp;gt;() {&lt;br/&gt;                    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; &lt;span&gt;filter&lt;/span&gt;&lt;span&gt;(String s, Context&amp;lt;String&amp;gt; ctx)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;                        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;&quot;buy&quot;&lt;/span&gt;.equals(s.split(&lt;span&gt;&quot;,&quot;&lt;/span&gt;)[&lt;span&gt;3&lt;/span&gt;]);&lt;br/&gt;                    }&lt;br/&gt;                });&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 经过 CEP 规则匹配后，抽取点击的事件流&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 利用商品 id 进行分组，并利用 process 进行状态统计。&lt;/span&gt;&lt;br/&gt;        val patStream = CEP.pattern(keyStream, pattern)&lt;br/&gt;                .select(map -&amp;gt; map.get(&lt;span&gt;&quot;start&quot;&lt;/span&gt;).get(&lt;span&gt;0&lt;/span&gt;))&lt;br/&gt;                .keyBy((KeySelector&amp;lt;String, String&amp;gt;) s -&amp;gt; s.split(&lt;span&gt;&quot;,&quot;&lt;/span&gt;)[&lt;span&gt;1&lt;/span&gt;])&lt;br/&gt;                .process(&lt;span&gt;new&lt;/span&gt; KeyedProcessFunction&amp;lt;String, String, Object&amp;gt;() {&lt;br/&gt;&lt;br/&gt;                    &lt;span&gt;private&lt;/span&gt; ValueState&amp;lt;Long&amp;gt; clickState;&lt;br/&gt;&lt;br/&gt;                    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;open&lt;/span&gt;&lt;span&gt;(Configuration parameters)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;                        clickState = getRuntimeContext().getState(&lt;br/&gt;                                &lt;span&gt;new&lt;/span&gt; ValueStateDescriptor&amp;lt;&amp;gt;(&lt;span&gt;&quot;OrderLost&quot;&lt;/span&gt;, Long.class));&lt;br/&gt;                    }&lt;br/&gt;&lt;br/&gt;                    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;                    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;processElement&lt;/span&gt;&lt;span&gt;(String in, Context ctx, Collector&amp;lt;Object&amp;gt; out)&lt;/span&gt;&lt;br/&gt;                            &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;                        Long clickValue = clickState.value();&lt;br/&gt;                        clickValue = clickValue == &lt;span&gt;null&lt;/span&gt; ? &lt;span&gt;1L&lt;/span&gt; : ++clickValue;&lt;br/&gt;                        clickState.update(clickValue);&lt;br/&gt;                        out.collect(&lt;span&gt;&quot;【&quot;&lt;/span&gt; + in.split(&lt;span&gt;&quot;,&quot;&lt;/span&gt;)[&lt;span&gt;1&lt;/span&gt;] + &lt;span&gt;&quot;】OrderLost:&quot;&lt;/span&gt; + clickValue);&lt;br/&gt;&lt;br/&gt;                    }&lt;br/&gt;                });&lt;br/&gt;&lt;br/&gt;        patStream.print();&lt;br/&gt;&lt;br/&gt;        env.execute(&lt;span&gt;&quot;test&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;【3505100】OrderLost:1&lt;br/&gt;【3815446】OrderLost:1&lt;br/&gt;【4484065】OrderLost:1&lt;br/&gt;【5097906】OrderLost:1&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3.总结&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文主要介绍了如何使用 FlinkCEP，并给出诸多 Demo 进行学习。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但完成开头的需求是，我采用的是基于 uid 和商品类别进行分组，然后用 cep 去挖掘配对规则。当然也可以先基于 uid 进行分组，然后用 cep 挖掘配对模式 [点击商品、购买商品]，然后利用 select 去过滤是否是同类商品。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后留一个新需求：如果需要同时计算商品的下单量、CTR 该怎么操作？&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.参考&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;《探索如何使用Flink CEP》&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;《Apache Flink CEP 实战》&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>6310784f29aaaf9e27568f153cfe015b</guid>
<title>大家用过 API 网关吗?</title>
<link>https://toutiao.io/k/rwvdh2x</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p&gt;今天和大家说说API网关，根据字面含义，和API接口相关，同时又是服务入口。不知道大家所在公司有没有用过，如果用过，是开源的呢？还是自研？或者是云服务厂商的产品？&lt;/p&gt;&lt;p&gt;早在2012年我第二次在sina的时候，就维护过一个API网关产品，当时领导还让我看了一本API书籍，不过讲的是API基础设施和API经济，不得不说，领导还是很有战略眼光的。&lt;/p&gt;&lt;p&gt;使用PHP做了一个网关层，怕别人说性能问题，我一直底气不足，后来发现大家还挺爱用的，原因就是它提供了接口的数据统计功能，就这么一个功能，使用的人却挺多。&lt;/p&gt;&lt;p&gt;所以说，和一个产品一样，功能再多，技术实现方式再牛，也不一定有用，重要的是提供了价值。&lt;/p&gt;&lt;p&gt;意思就是API网关大家不要理解为一个纯技术的产品，而是要以更开阔的视角去看它。&lt;/p&gt;&lt;p&gt;在我看来，API网关提供了两大核心功能：&lt;/p&gt;&lt;p&gt;1：分层，相比SLB的反向代理和负载均衡，API网关提供了更多的功能，从而简化后端服务，并清晰定义哪些应该是API网关做的，哪些是后端服务做的。&lt;/p&gt;&lt;p&gt;也就是说API网关应该是可编程的。&lt;/p&gt;&lt;p&gt;2：API治理&lt;/p&gt;&lt;p&gt;标准化了整个API生命周期，大家不要小看它，如果一开始就规范化，API开发、维护、生产的效率将会极大提升。&lt;/p&gt;&lt;p&gt;对于大公司来说，可能热衷于自己实现或者二次开发API网关，其实它对于性能和稳定性要求极高，所以使用云厂商的服务相对靠谱一些。&lt;/p&gt;&lt;p&gt;阿里云API网关的核心功能：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;568&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.9830729166666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5Wib5Wh04ugw5LWKr2gge4hdVWH4Ut7Lia3XTqxnyLjPyzAKOiamfxicZ2lt2diaRrEGOqP1YZGHq5NovNSgCF67RTw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;768&quot;/&gt;&lt;/p&gt;&lt;p&gt;那么如何接入API网关呢？它不像其他的云服务，不会很快看到效果，需要很长的时间才能体现它的价值；同时涉及面也比较广，大家只有统一思想，才能用好它。&lt;/p&gt;&lt;p&gt;如果你一开始就用它，包袱会小很多，如果中途接入它，需要面临兼容性的问题。&lt;/p&gt;&lt;p&gt;那它的重要性在哪儿呢？因为不管你用分布式架构还是微服务，内部不管怎么玩，对外基本上还是API接口，所以说API网关永远不过时，这也是我们在选型或者自研产品时候要注意的，一定要选择哪些基础，有长期存在价值的技术服务。&lt;/p&gt;&lt;p&gt;你们公司用了吗？&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_reward_qrcode&quot;&gt;
                                &lt;p class=&quot;tips_global&quot;&gt;Long-press QR code to transfer me a reward&lt;/p&gt;
                                                                &lt;p class=&quot;reward_tips&quot;&gt;觉得写得还不错？就鼓励一下吧！&lt;/p&gt;
                                &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; id=&quot;js_reward_qrcode_img&quot;/&gt;&lt;/span&gt;
                                &lt;p class=&quot;tips_global&quot;&gt;As required by Apple&#x27;s new policy, the Reward feature has been disabled on Weixin for iOS. You can still reward an Official Account by transferring money via QR code.&lt;/p&gt;
                            &lt;/div&gt;
                                                                            
                              
            &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e05bb3d938e289331f69f30778018f35</guid>
<title>记一次对端机器宕机后的 TCP 行为</title>
<link>https://toutiao.io/k/2abl3q4</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;h1&gt;解Bug之路-记一次对端机器宕机后的tcp行为&lt;/h1&gt;&lt;h2&gt;前言&lt;/h2&gt;&lt;p&gt;机器一般过质保之后，就会因为各种各样的问题而宕机。而这一次的宕机，让笔者观察到了平常观察不到的tcp在对端宕机情况下的行为。经过详细跟踪分析原因之后，发现可以通过调整内核tcp参数来减少宕机造成的影响。&lt;/p&gt;&lt;h2&gt;Bug现场&lt;/h2&gt;&lt;p&gt;笔者所在的公司用某个中间件的古老版本做消息转发，此中间件在线上运行有些年头了，大约刚开始部署的时候机器还是全新的，现在都已经过保了。机器的宕机导致了一些诡异的现象。如下图所示:&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5424028268551236&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEficzNQ6w9S1Wv5HTgItLAPQ1yTCgM2HCxH95WibsPjypTicP4d5Tc0K17w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1132&quot;/&gt;&lt;br/&gt;在中间件所在机器宕机之后，出现了调用中间件超时的现象。抛开各种业务细节，会发现出现了时间很长的超时。其中一波在821s之后报出了Connection reset异常，还有一波在940s之后报出了Connection timed out(Read failed)异常。&lt;/p&gt;&lt;h2&gt;线索追查&lt;/h2&gt;&lt;p&gt;发现出bug的时间点很微妙,有将近10个请求是在22:32:22.300左右集中报错，并且这个时间点有Connection reset。&lt;br/&gt;另一波是在22:34.11.450左右集中报错,并且这个时间点由Connection timed out(Read failed)。&lt;br/&gt;于是笔者看了下此中间件client的网络模型,如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.4825174825174825&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfmA5DicN5ibK9qhyic5el0fYZWfkU0xOsY04AZf3DzfocgkKyfRiaia80v5w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1430&quot;/&gt;&lt;br/&gt;这就很容易理解，为何请求为何都是在同一时刻超时，因为是顺序请求，后面的几个请求还没发送出去，就由于第一个请求超时而导致后面的所有请求报错。如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.2684659090909091&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfPgicbNTHaHRcXWrdrrU7Pch9DtfkAFY6wE9WuOMply0IbW7UABNxD7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1408&quot;/&gt;&lt;br/&gt;进一步推出，真正的socket超时时间是请求1(最长)的超时时间。&lt;br/&gt;即对应&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Connection reset的821s&lt;br/&gt;Connection timed out(Read failed)的940s&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;client设置了socket.soTimeOut为0&lt;/h3&gt;&lt;p&gt;这个中间件采用了bio模型，并且socket没有设置超时时间，其业务超时时间通过业务层的future来控制。但是这个超时时间只有在真正发送请求的时间起作用，每个请求之前还会有其它的一段交互，如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.33646112600536193&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfvfXHe69xhsPt65GxfVia95C2ibWpN6Kk0g1ticMUMfpfx8hmT4jclNBpA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1492&quot;/&gt;&lt;br/&gt;至此，问题原因已经很明显了，在(do something)的那个过程由于socket设置soTimeOut为0，导致卡住了相当长的一段时间。代码如下图所示:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;.....&lt;br/&gt;protected int soTimeout;&lt;br/&gt;......&lt;br/&gt;protected void initialiseSocket(Socket sock) throws SocketException, IllegalArgumentException {&lt;br/&gt;     ......&lt;br/&gt;      // 默认是0&lt;br/&gt;      sock.setSoTimeout(soTimeout);&lt;br/&gt;      ......&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;socket设置soTimeOut为0的表现&lt;/h3&gt;&lt;p&gt;问题本身的查找是比较简单的，如果仅仅只有这些的话，笔者也不会将其写成一篇博客。&lt;br/&gt;由于socket设置timeout(&amp;gt;0)是一种常识，很少遇到设置为0的情况。于是其引起的现象引起了笔者的兴趣。我们看看socket设置timeout为0后jdk源码的描述:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;    /**&lt;br/&gt;      * ......&lt;br/&gt;     *  A timeout of zero is interpreted as an infinite timeout.&lt;br/&gt;     * ......&lt;br/&gt;     */&lt;br/&gt;    public synchronized void setSoTimeout(int timeout) throws SocketException {&lt;br/&gt;        if (isClosed())&lt;br/&gt;            throw new SocketException(&quot;Socket is closed&quot;);&lt;br/&gt;        if (timeout &amp;lt; 0)&lt;br/&gt;          throw new IllegalArgumentException(&quot;timeout can&#x27;t be negative&quot;);&lt;br/&gt;&lt;br/&gt;        getImpl().setOption(SocketOptions.SO_TIMEOUT, new Integer(timeout));&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;里面有这么一段话&lt;/p&gt;&lt;pre&gt;&lt;code&gt;A timeout of zero is interpreted as an infinite timeout&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;按上述字母解释为如果设置为0的话，应该是等待无限长的时间(直到进程重启)。&lt;br/&gt;可是按照线上业务的表现，确是有超时时间的，只不过时间很长。最长的达到了940s，即15分钟多。&lt;br/&gt;这就引起了笔者的兴趣，到底是什么让这个无限的超时时间被打断呢？我们继续分析。&lt;/p&gt;&lt;h2&gt;Connection reset&lt;/h2&gt;&lt;p&gt;首先我们聚焦于第一个异常报错Connection reset(22:32分), 笔者本身阅读过tcp协议栈源码，知道基本上所有Connection reset都由对端发出。所以笔者料定在22:32分的时候，机器肯定又活过来了，但是对应的中间件进程确没有起来，所以没有对应的端口，进而当包过来的时候，发送tcp reset包回去(即使当前中间件起来了也会发送reset,因为tcp本身的seq序列号校验失败)。如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.3932432432432432&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfkjiccib3LYK1vqClKOAeIicQHQmGCRkjAT2Q6AiaWA1nBf1V6nu1XJ9ib9A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1480&quot;/&gt;&lt;br/&gt;然后了解到在22:32左右，为了拷贝宿主机内部的消息记录，运维确实将宕掉的机器重新给拉起来了，这进一步印证了我的想法。但是按照笔者的推论，在22:32分新发出重传的所有的请求都被Connection reset了，为何在将近两分钟之后(准确的说是在1分49s之后由又报了一波错？)继续往下分析。&lt;br/&gt;(注意22:32分和22:34分报错的是不同的socket连接)&lt;/p&gt;&lt;h2&gt;Connection timed out(Read failed)&lt;/h2&gt;&lt;p&gt;这个错误很少遇到。不知道是在哪种情况下触发。具体的异常栈为:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Caused by: java.net.SocketException: Connection timed out(Read failed)&lt;br/&gt;         at java.net.SocketInputStream.socketRead0(Native Method) ~[?1.8.0_121]&lt;br/&gt;         at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[?:1.8.0_121]&lt;br/&gt;         ......&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;于是用sublime搜索Connection timed out,发现其只在Java_java_net_PlainSocketImpl_socketConnect出现，和上面的异常栈明显不符合。&lt;br/&gt;那么就从socketRead0入手，我们详细看看源代码:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;JNIEXPORT jint JNICALL&lt;br/&gt;Java_java_net_SocketInputStream_socketRead0(JNIEnv *env, jobject this,&lt;br/&gt;                                            jobject fdObj, jbyteArray data,&lt;br/&gt;                                            jint off, jint len, jint timeout)&lt;br/&gt;{&lt;br/&gt;    ......&lt;br/&gt;     nread = NET_Read(fd, bufP, len);&lt;br/&gt;&lt;br/&gt;    if (nread &amp;lt;= 0) {&lt;br/&gt;        if (nread &amp;lt; 0) {&lt;br/&gt;&lt;br/&gt;            switch (errno) {&lt;br/&gt;                case ECONNRESET:&lt;br/&gt;                case EPIPE:&lt;br/&gt;                    JNU_ThrowByName(env, &quot;sun/net/ConnectionResetException&quot;,&lt;br/&gt;                        &quot;Connection reset&quot;);&lt;br/&gt;                    break;&lt;br/&gt;&lt;br/&gt;                case EBADF:&lt;br/&gt;                    JNU_ThrowByName(env, JNU_JAVANETPKG &quot;SocketException&quot;,&lt;br/&gt;                        &quot;Socket closed&quot;);&lt;br/&gt;                    break;&lt;br/&gt;&lt;br/&gt;                case EINTR:&lt;br/&gt;                     JNU_ThrowByName(env, JNU_JAVAIOPKG &quot;InterruptedIOException&quot;,&lt;br/&gt;                           &quot;Operation interrupted&quot;);&lt;br/&gt;                     break;&lt;br/&gt;&lt;br/&gt;                default:&lt;br/&gt;                    NET_ThrowByNameWithLastError(env,&lt;br/&gt;                        JNU_JAVANETPKG &quot;SocketException&quot;, &quot;Read failed&quot;);&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;    ......&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;答案就在NET_ThrowByNameWithLastError里面，其最后调用的是os::stderr来获取kernel返回的error字符串。&lt;br/&gt;查了下linux stderr手册，发现是ETIMEDOUT对应了Connection timed out。&lt;br/&gt;但是后面的Connection timed out(Read failed)中的(Read failed)不应该拼接在后面，因为其逻辑是kernel返回error就用kernel的error,否则用defaultDetail即(Read failed和errno的组合)。具体原因，笔者并没有在openJdk源码中找到，猜测可能是版本的原因或者oracleJdk和openJdk之间细微的差别。&lt;/p&gt;&lt;h2&gt;ETIMEDOUT&lt;/h2&gt;&lt;p&gt;既然是linux kernel返回的，笔者就立马翻了linux源码。&lt;br/&gt;(这其中有个插曲，就是笔者一开始看的是2.6.24内核源码，发现怎么计算都对不上数据。后来看到线上用的是2.6.32内核版本，翻了对应版本的源码，才搞定)&lt;br/&gt;既然是sockRead0返回的，那肯定不是socket创建连接阶段(SYN)，肯定到了establish的send/rcv阶段。这个错误最有可能就是在重传失败的时候返回的错误。于是翻了下重传的源代码:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;static void tcp_retransmit_timer(struct sock *sk)&lt;br/&gt;{&lt;br/&gt;    ......&lt;br/&gt;    // 检查当前重传是否已经超过最大时间&lt;br/&gt;    if (tcp_write_timeout(sk))&lt;br/&gt;        goto out;&lt;br/&gt;    ......&lt;br/&gt;    icsk-&amp;gt;icsk_backoff++;&lt;br/&gt;    icsk-&amp;gt;icsk_retransmits++;&lt;br/&gt;out_reset_timer:&lt;br/&gt;    // 重新重传定时器，rto最大为TCP_RTO_MAX即为120s&lt;br/&gt;    icsk-&amp;gt;icsk_rto = min(icsk-&amp;gt;icsk_rto &amp;lt;&amp;lt; 1, TCP_RTO_MAX);&lt;br/&gt;    inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS, icsk-&amp;gt;icsk_rto, TCP_RTO_MAX);&lt;br/&gt;    if (retransmits_timed_out(sk, sysctl_tcp_retries1 + 1))&lt;br/&gt;        __sk_dst_reset(sk);&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面逻辑是首先判定是否超时，如果未超时则设置下一个超时时间。逻辑如下图所示：&lt;br/&gt;&lt;img data-ratio=&quot;0.45468509984639016&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfnbLm2eUyiakIiciaSqIBkbBiaGiaI3QPUKWicM3SLWg6H8Qu3xTBoUhZ9uHg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1302&quot;/&gt;&lt;br/&gt;我们再看下tcp_write_timeout:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;static int tcp_write_timeout(struct sock *sk){&lt;br/&gt;    ...&lt;br/&gt;    // 对SYN，即创建连接过程中的处理&lt;br/&gt;    ...&lt;br/&gt;    // retry即使kernel中的tcp_retries2&lt;br/&gt;    // 即cat /proc/sys/net/ipv4/tcp_retries2即是15&lt;br/&gt;    retry_until = sysctl_tcp_retries2;&lt;br/&gt;    // 下面就是超时判断的过程&lt;br/&gt;     if (retransmits_timed_out(sk, retry_until)) {&lt;br/&gt;        /* Has it gone just too far? */&lt;br/&gt;        // 如果超过最大时间，则调用tcp_write_err&lt;br/&gt;        tcp_write_err(sk);&lt;br/&gt;        return 1;&lt;br/&gt;    }&lt;br/&gt;    return 0;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;tcp_write_err确实返回了ETIMEDOUT,如下面源码所示:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;static void tcp_write_err(struct sock *sk)&lt;br/&gt;{&lt;br/&gt;    sk-&amp;gt;sk_err = sk-&amp;gt;sk_err_soft ? : ETIMEDOUT;&lt;br/&gt;    // 返回ETIMEDOUT&lt;br/&gt;    sk-&amp;gt;sk_error_report(sk);&lt;br/&gt;&lt;br/&gt;    tcp_done(sk);&lt;br/&gt;    NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPABORTONTIMEOUT);&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;至此，基本可以判定就是tcp_write_timeout超时了，也即其中的&lt;br/&gt;retransmits_timed_out判定超时。&lt;br/&gt;很明显为什么940s的时候没有Connection reset，就是由于先判断了tcp_write_timeout超时导致没有发送下一个重传包，而直接time_out,如果发了，那就是Connection reset。&lt;/p&gt;&lt;h2&gt;retransmits_timed_out的计算过程&lt;/h2&gt;&lt;p&gt;这个计算过程直接上源码:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;static inline bool retransmits_timed_out(struct sock *sk,&lt;br/&gt;                     unsigned int boundary)&lt;br/&gt;{&lt;br/&gt;    unsigned int timeout, linear_backoff_thresh;&lt;br/&gt;    unsigned int start_ts;&lt;br/&gt;&lt;br/&gt;    if (!inet_csk(sk)-&amp;gt;icsk_retransmits)&lt;br/&gt;        return false;&lt;br/&gt;&lt;br/&gt;    if (unlikely(!tcp_sk(sk)-&amp;gt;retrans_stamp))&lt;br/&gt;        start_ts = TCP_SKB_CB(tcp_write_queue_head(sk))-&amp;gt;when;&lt;br/&gt;    else&lt;br/&gt;        start_ts = tcp_sk(sk)-&amp;gt;retrans_stamp;&lt;br/&gt;&lt;br/&gt;    linear_backoff_thresh =&lt;br/&gt;(TCP_RTO_MAX/TCP_RTO_MIN);&lt;br/&gt;&lt;br/&gt;    if (boundary &amp;lt;= linear_backoff_thresh)&lt;br/&gt;        timeout = ((2 &amp;lt;&amp;lt; boundary) - 1) * TCP_RTO_MIN;&lt;br/&gt;    else&lt;br/&gt;        timeout = ((2 &amp;lt;&amp;lt; linear_backoff_thresh) - 1) * TCP_RTO_MIN +&lt;br/&gt;              (boundary - linear_backoff_thresh) * TCP_RTO_MAX;&lt;br/&gt;&lt;br/&gt;    return (tcp_time_stamp - start_ts) &amp;gt;= timeout;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上述源码中,boundary = 15，那么&lt;br/&gt;TCP_RTO_MAX=120s,TCP_RTO_MIN=200ms&lt;br/&gt;linear_backoff_thresh = ilog2(120s/200ms)=ilog2(600)=ilog2(1001011000二进制),ilog的实现为:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;#define ilog2(n)&lt;br/&gt;(                        \&lt;br/&gt;    __builtin_constant_p(n) ? (        \&lt;br/&gt;        (n) &amp;lt; 1 ? ____ilog2_NaN() :    \&lt;br/&gt;        (n) &amp;amp; (1ULL &amp;lt;&amp;lt; 63) ? 63 :    \&lt;br/&gt;        ......&lt;br/&gt;        (n) &amp;amp; (1ULL &amp;lt;&amp;lt;  9) ?  9 :    \&lt;br/&gt;        /* 即(1001011000 &amp;amp; 1000000000)=1=&amp;gt;返回9 */&lt;br/&gt;        ......&lt;br/&gt;)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;由于boundary=15 &amp;gt; linear_backoff_thresh(9)所以，计算超时时间为:&lt;br/&gt;timeout = ((2 &amp;lt;&amp;lt; linear_backoff_thresh) - 1) &lt;em&gt;TCP_RTO_MIN +(boundary - linear_backoff_thresh)&lt;/em&gt;TCP_RTO_MAX;&lt;br/&gt;即(TCP_RTO_MIN=200ms,TCP_RTO_MAX=120s)&lt;br/&gt;timeout = ((2 &amp;lt;&amp;lt; 9 - 1) &lt;em&gt;0.2s + (15 - 9) &lt;/em&gt;120s=924.6s&lt;/p&gt;&lt;p&gt;值得注意的是，由上面的代码逻辑，我们tcp_retries=15指的并不是重传15次，而是在rto初始值为200ms的情况下计算一个最终超时时间，实际重传次数和15并没有直接的关系。&lt;/p&gt;&lt;h2&gt;重传最终超时的上下界&lt;/h2&gt;&lt;h3&gt;重传最终超时的下界&lt;/h3&gt;&lt;p&gt;由上面的计算可知,&lt;br/&gt;即在重传后的tcp_time_stamp（当前时间戳）- start_ts(第一次重传时间戳)&amp;gt;=924.6s的时候,即抛出异常，那么重传最终超时的下界就是924.6s，如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.39718804920913886&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfIRFeiaOmlbnlMIjwQ9YibVD5BoHCXwCEGKsGxicsgV6icBY0YznfOoOVCw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1138&quot;/&gt;&lt;/p&gt;&lt;h3&gt;重传最终超时的上界&lt;/h3&gt;&lt;p&gt;我们假设在第N次的时候tcp_time_stamp - start_ts=924.5999s时候进行超时判定，那么势必会进行下一次重传，并在924.5999+120=1044.5999s后超时，如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.4656160458452722&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfEt2icACH7o22ibHpzG9f24ELsWsSVWOooWChf5icjvcB0BwYfq7BqzCZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1396&quot;/&gt;&lt;br/&gt;那么，重传最终超时的上界就是1044.6s&lt;br/&gt;最终结论:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;重传最终超时的上下界是:&lt;br/&gt;[924.6,1044.6]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;用不同的rto计算下最终超时&lt;/h2&gt;&lt;p&gt;由上面代码可知，重传rto是不停的*2,一直到TCP_RTO_MAX(120s)为止,阅读linux代码可知,在笔者的线上情况下,初始rto=srtt&amp;gt;&amp;gt;3 + rttvar(TCP_RTO_MIN)(当然了，实际比这个复杂的多,计算暂以TCP_RTO_MIN代替),即初始rto=200ms+(一个计算出来的值)&lt;br/&gt;笔者写了个模拟程序:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;public class RetransSimulate {&lt;br/&gt;&lt;br/&gt;    public static void timeOutCaclulate(double rto) {&lt;br/&gt;        double initialRto = rto;&lt;br/&gt;        double sum = 0;&lt;br/&gt;        while (true) {&lt;br/&gt;            sum += rto;&lt;br/&gt;            if (sum &amp;gt; 924600) {&lt;br/&gt;                break;&lt;br/&gt;            }&lt;br/&gt;            rto = rto * 2;&lt;br/&gt;            rto = rto &amp;lt; 120000 ? rto : 120000;&lt;br/&gt;        }&lt;br/&gt;        // 以50ms作为误差&lt;br/&gt;        if(Math.abs(sum - 939997) &amp;lt; 50){&lt;br/&gt;            System.out.println(&quot;rto=&quot;+initialRto+&quot;,timeout=&quot; + sum);&lt;br/&gt;            System.out.println();&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    public static void main(String[] args) {&lt;br/&gt;        // rtt &amp;gt; 3 + rttval(这个计算有点复杂，这边可以直接用TCP_RTO_MIN做计算)&lt;br/&gt;        // 以0.01ms为精度&lt;br/&gt;        double rto =  0.01 + 200;// 0.01 for random rtt &amp;gt; 3（初始扰动）,200 for TCP_RTO_MIN&lt;br/&gt;        // 最多计算到300&lt;br/&gt;        for (int i = 0; i &amp;lt; 10000; i++) {&lt;br/&gt;            timeOutCaclulate(rto);&lt;br/&gt;            rto += 0.01 ;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;发现距离线上真实表现超时时间最近的是:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;rto=215.00999999998635,timeout=939955.229999986&lt;br/&gt;&lt;br/&gt;rto=215.01999999998634,timeout=939965.459999986&lt;br/&gt;&lt;br/&gt;rto=215.02999999998633,timeout=939975.689999986&lt;br/&gt;&lt;br/&gt;rto=215.03999999998632,timeout=939985.919999986&lt;br/&gt;&lt;br/&gt;rto=215.0499999999863,timeout=939996.1499999859&lt;br/&gt;&lt;br/&gt;rto=215.0599999999863,timeout=940006.3799999859&lt;br/&gt;&lt;br/&gt;rto=215.0699999999863,timeout=940016.609999986&lt;br/&gt;&lt;br/&gt;rto=215.07999999998628,timeout=940026.839999986&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样，基本就能基本确定在宕机的时候，用的rto是215了&lt;br/&gt;题外话:&lt;br/&gt;之前博客里面笔者想当然的将rto认为成rtt，导致之前的模拟程序在rto的初始值没有加上200ms,我们同事在复现现场的时候，发现第一次重传包确实是200ms左右，和笔者的推理并不一样。&lt;br/&gt;使得笔者重新阅读了rto源码，发现其rto初始就要加上TCP_RTO_MIN(其实是rttvar,细节有点复杂,在此略过不表),感谢那位同事，也向之前阅读过笔者此篇博客的人道歉,笔者犯了想当然的毛病。&lt;/p&gt;&lt;h2&gt;机器响应的时间窗口&lt;/h2&gt;&lt;p&gt;由于到了800s/900s的时候，肯定已经到了TCP_RTO_MAX(120s),所以我们可以根据两个socket的报错时间计算一下机器响应的时间窗口。在这里为了简便分析，我们忽略包在网络中的最长存活时间,如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.5212620027434842&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfflCBjU5icFzw1lfcTxqcN8HE1FVTIgBgpwabiaOrCQ44rpVtnPwcuT4A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1458&quot;/&gt;&lt;br/&gt;即机器开始应答的时间应该在22:32:11至22:32:22之间。&lt;br/&gt;当然了，很难获取到机器真正开始应答的精确时间来证实笔者的计算。但是这个计算的意义在于如果两者的应答窗口没有交叠，那么笔者的上述推论就是错的，需要推倒重来。存在这个时间窗口，可以让笔者的推测在逻辑上自洽。&lt;/p&gt;&lt;p&gt;学习tcp最好的实战书籍无疑是&lt;/p&gt;&lt;section&gt;&lt;mpcps frameborder=&quot;0&quot; class=&quot;js_editor_cps&quot; data-datakey=&quot;1591402899899_0.07650296701936377&quot; data-uid=&quot;1591402899897&quot; data-type=&quot;1&quot; data-product=&quot;&quot; data-templateid=&quot;list&quot; data-pid=&quot;23989588&quot; data-packid=&quot;&quot; data-smartnum=&quot;&quot; data-categoryid=&quot;3&quot; data-appid=&quot;wx831660fe3ded4389&quot; data-report=&quot;s0%3D0%26s1%3D0%26s2%3D0%26s3%3Dtcp%252Fip%25E8%25AF%25A6%25E8%25A7%25A3%26s4%3D10%26s5%3D10%26s6%3Did_1591402953483_940825%26s7%3D%26s8%3D%26s9%3D%26s10%3D%26pid%3Dwx831660fe3ded4389_23989588%26uuid%3D32997630781785286764%26title%3DTCP%252FIP%25E8%25AF%25A6%25E8%25A7%25A3%2B%25E5%258D%25B71%25EF%25BC%259A%25E5%258D%258F%25E8%25AE%25AE%25EF%25BC%2588%25E5%258E%259F%25E4%25B9%25A6%25E7%25AC%25AC2%25E7%2589%2588%25EF%25BC%2589%26sid%3D3%26cid%3D3%26ratio%3D17.00%2525%26price%3D119.80%26&quot;/&gt;&lt;/section&gt;&lt;section&gt;里面各种对于tcp本身特性的实验数据，毕竟实践出真知，笔者也在其中获得了大量宝贵的知识和经验。&lt;br/&gt;&lt;/section&gt;&lt;h2&gt;后续改进&lt;/h2&gt;&lt;p&gt;将tcp_retries2减少。soTimeOut在这个中间件client代码里面由于其它问题不建议设置。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;机器宕机虽然不讨人喜欢，但是观察宕机后线上的种种表现可是一次难得机会，能够发现平时注意不到的坑。另外，定量分析其实蛮有意思的，尤其是种种数据都对上的时刻，挺有成就感^_^。&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>05cc57e1baf5881b6301b86c0c82df02</guid>
<title>HTTP keep-alive 和 TCP keepalive 的区别，你了解吗？</title>
<link>https://toutiao.io/k/630ifsg</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;文章目录
一、简介
  1.1、TCP协议简介
  1.2、HTTP协议简介
二、TCP keepalive
  2.1、简介
  2.2、实验
  2.3、扩展
三、HTTP keep-alive
  3.1、简介
  3.2、实验
    3.2.1、实验一：禁用keep-alive的http请求
    3.2.2、实验二：启用keep-alive的http请求
  3.3、扩展
四、总结
五、彩蛋&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;1、从文中找出我的IP&lt;br/&gt;2、http请求中是客服端还是服务端主动关闭的tcp连接？ &lt;br/&gt; 请阅读到最后的彩蛋部分&lt;/blockquote&gt;&lt;p&gt;HTTP和TCP都是老生常谈的知识点，本文不进行铺开赘述。我们可能在HTTP和TCP中都听说“长连接”的说法，也听过HTTP中有keep-alive，TCP中有keepalive。那么，HTTP和TCP的长连接有何区别？HTTP中的keep-alive和TCP中keepalive又有什么区别？&lt;/p&gt;&lt;p&gt;&lt;b&gt;Tips：&lt;/b&gt;HTTP中是keep-alive，TCP中是keepalive，HTTP中是带中划线的。大小写无所谓。&lt;/p&gt;&lt;h2&gt;一、简介&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-737aab4fcedf20a05584443221508141_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;860&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-737aab4fcedf20a05584443221508141_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;860&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-737aab4fcedf20a05584443221508141_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-737aab4fcedf20a05584443221508141_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上面是我先前做TCP协议分享时整理的一张表格，从上面可以看出：不管是在OSI七层网络模型还是在TCP/IP五层网络模型中，&lt;b&gt;TCP是传输层的一种协议，而HTTP是应用层的一种协议&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;HTTP和TCP的理论和实现还是相当复杂的，下面只简单介绍和本文主题相关的知识点。&lt;/p&gt;&lt;h2&gt;1.1、TCP协议简介&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TCP协议&lt;/b&gt;也叫传输控制协议（TCP，Transmission Control Protocol）是一种面向连接的、可靠的、基于字节流的传输层通信协议。使用TCP的两个程序（客户端和服务端）在交换数据前，通过三次握手来建立TCP连接，建立连接后就可以进行基于字节流的双工通讯，由TCP内部实现保证通讯的可靠性，完全通讯完成后，通过四次挥手断开连接。&lt;/p&gt;&lt;p&gt;在客户端和服务端间的网络一切正常、且双方都没主动发起关闭连接的请求时，此TCP连接理论上可以永久保持。但是，网络情况是及其复杂的，&lt;b&gt;在双方长时间未通讯时，如何得知对方还活着？如何得知这个TCP连接是健康且具有通讯能力的？&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;1.2、HTTP协议简介&lt;/h2&gt;&lt;p&gt;&lt;b&gt;HTTP协议&lt;/b&gt;是Hyper Text Transfer Protocol（超文本传输协议）的缩写。HTTP是万维网的数据通信的基础。HTTP是一个应用层协议，&lt;b&gt;通常&lt;/b&gt;运行在TCP协议之上。它由请求和响应构成，是一个标准的客户端服务器模型（C/S模型）。HTTP是一个&lt;b&gt;无状态&lt;/b&gt;的协议。&lt;/p&gt;&lt;p&gt;&lt;b&gt;无状态&lt;/b&gt;怎么解释？HTTP协议永远都是客户端发起请求，服务器回送响应。每次连接只处理一个请求，当服务器返回本次请求的应答后便立即关闭连接，下次请求客户端再重新建立连接。也就无法实现在客户端没有发起请求的时候，服务器主动将消息推送给客户端。&lt;/p&gt;&lt;p&gt;HTTP协议运行在TCP协议之上，它无状态会导致客户端的每次请求都需要重新建立TCP连接，接受到服务端响应后，断开TCP连接。对于每次建立、断开TCP连接，还是有相当的性能损耗的。&lt;b&gt;那么，如何才能尽可能的减少性能损耗呢？&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;二、TCP keepalive&lt;/h2&gt;&lt;h2&gt;2.1、简介&lt;/h2&gt;&lt;p&gt;正如上面提出的问题：&lt;b&gt;在双方长时间未通讯时，如何得知对方还活着？如何得知这个TCP连接是健康且具有通讯能力的？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TCP的保活机制就是用来解决此类问题，这个机制我们也可以称作：keepalive。保活机制默认是关闭的，TCP连接的任何一方都可打开此功能。有三个主要配置参数用来控制保活功能。&lt;/p&gt;&lt;p&gt;如果在一段时间（&lt;b&gt;保活时间：tcp_keepalive_time&lt;/b&gt;）内此连接都不活跃，开启保活功能的一端会向对端发送一个保活探测报文。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;若对端正常存活，且连接有效，对端必然能收到探测报文并进行响应。此时，发送端收到响应报文则证明TCP连接正常，重置保活时间计数器即可。&lt;/li&gt;&lt;li&gt;若由于网络原因或其他原因导致，发送端无法正常收到保活探测报文的响应。那么在一定&lt;b&gt;探测时间间隔（tcp_keepalive_intvl）&lt;/b&gt;后，将继续发送保活探测报文。直到收到对端的响应，或者达到配置的&lt;b&gt;探测循环次数上限（tcp_keepalive_probes）&lt;/b&gt;都没有收到对端响应，这时对端会被认为不可达，TCP连接随存在但已失效，需要将连接做中断处理。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在探测过程中，对端主机会处于以下四种状态之一：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-837ba2a1eb7beb10c036ca468f7db69f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1420&quot; data-rawheight=&quot;590&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-837ba2a1eb7beb10c036ca468f7db69f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1420&quot; data-rawheight=&quot;590&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-837ba2a1eb7beb10c036ca468f7db69f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-837ba2a1eb7beb10c036ca468f7db69f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;2.2、实验&lt;/h2&gt;&lt;p&gt;这里，强烈推荐《TCP/IP详解 卷1:协议》的第二版（这里一定是第二版）， &lt;b&gt;第17章：TCP保活机制&lt;/b&gt;。这里建议17章都看，17.1和17.2小节就涵盖了我上面介绍的内容。&lt;/p&gt;&lt;p&gt;17.2.1 小节中还通过实验的方式详细验证了“对端主机会处于以下四种状态”以及对于这四种状态TCP都是如何去处理。&lt;/p&gt;&lt;p&gt;这本书中的实验已经比较通俗易懂了，我暂且没有亲自动手去模拟实践，后续时间充足，会亲自动手进行实验。&lt;/p&gt;&lt;h2&gt;2.3、扩展&lt;/h2&gt;&lt;p&gt;上面提到了三个参数&lt;b&gt;保活时间：tcp_keepalive_time、探测时间间隔：tcp_keepalive_intvl、探测循环次数：tcp_keepalive_probes&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;这三个参数，在linux上可以在&lt;code&gt;/proc/sys/net/ipv4/&lt;/code&gt;路径下找到，或者通过&lt;code&gt;sysctl -a | grep keepalive&lt;/code&gt;命令查看当前内核运行参数。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@vm01 ~&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# cd /proc/sys/net/ipv4&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@vm01 ipv4&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# pwd&lt;/span&gt;
/proc/sys/net/ipv4
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@vm01 ipv4&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# cat /proc/sys/net/ipv4/tcp_keepalive_time&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;7200&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@vm01 ipv4&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# cat /proc/sys/net/ipv4/tcp_keepalive_probes&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@vm01 ipv4&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# cat /proc/sys/net/ipv4/tcp_keepalive_intvl&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;75&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@vm01 ipv4&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# sysctl -a | grep keepalive&lt;/span&gt;
net.ipv4.tcp_keepalive_time &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;7200&lt;/span&gt;
net.ipv4.tcp_keepalive_probes &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;
net.ipv4.tcp_keepalive_intvl &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;75&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;保活时间（tcp_keepalive_time）默认：7200秒&lt;/li&gt;&lt;li&gt;保活时间间隔（tcp_keepalive_intvl）默认：75秒&lt;/li&gt;&lt;li&gt;探测循环次数（tcp_keepalive_probes）默认：9次&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;也就是默认情况下一条TCP连接在2小时（7200秒）都没有报文交换后，会开始进行保活探测，若再经过9*75秒=11分钟15秒的循环探测都未收到探测响应，即共计：2小时11分钟15秒后会自动断开TCP连接。&lt;/p&gt;&lt;p&gt;别走开，还有一个骚操作&lt;/p&gt;&lt;p&gt;Linux平台下我们还可以借助&lt;code&gt;man&lt;/code&gt;命令查看TCP协议的一些描述和参数定义。下面两个命令的效果相同：&lt;/p&gt;&lt;p&gt;&lt;b&gt;数字7&lt;/b&gt;的含义是：&lt;code&gt;man&lt;/code&gt;命令使用手册共9章，TCP的帮助手册位于第7章。不知道在第几章也无所谓，使用&lt;code&gt;man tcp&lt;/code&gt;也可，弹出的手册左上角也有写第几章。(&lt;code&gt;man ls&lt;/code&gt;等同于&lt;code&gt;man 1 ls&lt;/code&gt;、&lt;code&gt;man ip&lt;/code&gt;等同于&lt;code&gt;man 8 ip&lt;/code&gt;，可以自己尝试使用 )。&lt;/p&gt;&lt;p&gt;下面我们看下&lt;code&gt;man tcp&lt;/code&gt;下的和我们本文有关的几个点： &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cded699db2d7191f62647ff0e084f901_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;966&quot; data-rawheight=&quot;303&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-cded699db2d7191f62647ff0e084f901_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;966&quot; data-rawheight=&quot;303&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-cded699db2d7191f62647ff0e084f901_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-cded699db2d7191f62647ff0e084f901_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e02739510ac2d09f731bff3fe55a646f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;963&quot; data-rawheight=&quot;386&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-e02739510ac2d09f731bff3fe55a646f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;963&quot; data-rawheight=&quot;386&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-e02739510ac2d09f731bff3fe55a646f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e02739510ac2d09f731bff3fe55a646f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e5045b618e763becad284a6ced8e1748_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2004&quot; data-rawheight=&quot;598&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-e5045b618e763becad284a6ced8e1748_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2004&quot; data-rawheight=&quot;598&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-e5045b618e763becad284a6ced8e1748_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e5045b618e763becad284a6ced8e1748_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上面介绍的三个参数&lt;b&gt;tcp_keepalive_time、tcp_keepalive_intvl、tcp_keepalive_probes&lt;/b&gt;都是系统级别的，针对整个系统生效。下面介绍针对单条Socket连接细粒度设置的三个选项参数：&lt;b&gt;保活时间：TCP_KEEPIDLE、保活探测时间间隔：TCP_KEEPINTVL、探测循环次数：TCP_KEEPCNT&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8df1e46e9de14df0c9724ca5d3e3c2ff_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2096&quot; data-rawheight=&quot;374&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-8df1e46e9de14df0c9724ca5d3e3c2ff_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2096&quot; data-rawheight=&quot;374&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-8df1e46e9de14df0c9724ca5d3e3c2ff_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8df1e46e9de14df0c9724ca5d3e3c2ff_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e9d468b62f99b86e32530daf1643251a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;998&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-e9d468b62f99b86e32530daf1643251a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;998&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-e9d468b62f99b86e32530daf1643251a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e9d468b62f99b86e32530daf1643251a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt; 在我们的Netty的框架中可以看到针对Socket选项的配置，如使用epoll的IO模型中&lt;code&gt;EpollSocketChannelConfig&lt;/code&gt;类中的配置：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb8cc0241c2127abbc5721f028c23403_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2186&quot; data-rawheight=&quot;1276&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-bb8cc0241c2127abbc5721f028c23403_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2186&quot; data-rawheight=&quot;1276&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-bb8cc0241c2127abbc5721f028c23403_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bb8cc0241c2127abbc5721f028c23403_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;更多细节，等你挖掘。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;三、HTTP keep-alive&lt;/h2&gt;&lt;h2&gt;3.1、简介&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/224595048/edit#commonResp&quot; class=&quot;internal&quot;&gt;HTTP协议简介&lt;/a&gt;中提到http协议是一个运行在TCP协议之上的无状态的应用层协议。它的特点是：客户端的每一次请求都要和服务端创建TCP连接，服务器响应后，断开TCP连接。下次客户端再有请求，则重新建立连接。&lt;/p&gt;&lt;p&gt;在早期的http1.0中，默认就是上述介绍的这种“请求-应答”模式。这种方式频繁的创建连接和销毁连接无疑是有一定性能损耗的。&lt;/p&gt;&lt;p&gt;所以引入了&lt;b&gt;keep-alive&lt;/b&gt;机制。http1.0默认是关闭的，通过http请求头设置“connection: keep-alive”进行开启；http1.1中默认开启，通过http请求头设置“connection: close”关闭。&lt;/p&gt;&lt;p&gt;&lt;b&gt;keep-alive&lt;/b&gt;机制：若开启后，在一次http请求中，服务器进行响应后，不再直接断开TCP连接，而是将TCP连接维持一段时间。在这段时间内，如果同一客户端再次向服务端发起http请求，便可以复用此TCP连接，向服务端发起请求，并重置timeout时间计数器，在接下来一段时间内还可以继续复用。这样无疑省略了反复创建和销毁TCP连接的损耗。&lt;/p&gt;&lt;h2&gt;3.2、实验&lt;/h2&gt;&lt;p&gt;下面用两组实验证明&lt;b&gt;HTTP keep-alive&lt;/b&gt;的存在。&lt;/p&gt;&lt;p&gt;实验工具：Wireshark&lt;/p&gt;&lt;p&gt;客户端IP：*.*.3.52&lt;/p&gt;&lt;p&gt;服务端IP：*.*.17.254&lt;/p&gt;&lt;h3&gt;3.2.1、实验一：禁用keep-alive的http请求&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8918cdcba83bd7d33d7e3df07a962b32_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2622&quot; data-rawheight=&quot;1658&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-8918cdcba83bd7d33d7e3df07a962b32_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2622&quot; data-rawheight=&quot;1658&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-8918cdcba83bd7d33d7e3df07a962b32_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-8918cdcba83bd7d33d7e3df07a962b32_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p&gt;从上图请求列表区中，我们可以发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;106、107、108三个请求是TCP建立连接三次握手的请求&lt;/li&gt;&lt;li&gt;109、110两个请求分别是：http的请求报文和http的响应报文&lt;/li&gt;&lt;li&gt;111、112、120、121这四个请求是TCP断开连接四次挥手的请求&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;（由于一台机器上网络请求较多，我加了筛选条件，仅显示客户端和服务端通信的网络请求，所以请求的序号是不连续的）&lt;/p&gt;&lt;p&gt;从上图中间的请求数据解析区，可以确定：此次http请求的请求头中有“Connection: close”，即keep-alive是关闭的。&lt;/p&gt;&lt;p&gt;结论：禁用keep-alive的http请求时，会先建立TCP连接，然后发送报文、响应报文、最后断开TCP连接。&lt;/p&gt;&lt;h3&gt;3.2.2、实验二：启用keep-alive的http请求&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-24904bb774a38233f254f4f6a86515ac_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2622&quot; data-rawheight=&quot;1658&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-24904bb774a38233f254f4f6a86515ac_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2622&quot; data-rawheight=&quot;1658&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-24904bb774a38233f254f4f6a86515ac_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-24904bb774a38233f254f4f6a86515ac_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-08c42b6f274a0f6a3465e171271f9689_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2678&quot; data-rawheight=&quot;1052&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-08c42b6f274a0f6a3465e171271f9689_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2678&quot; data-rawheight=&quot;1052&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-08c42b6f274a0f6a3465e171271f9689_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-08c42b6f274a0f6a3465e171271f9689_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt; 这次实验请求较多，一张图放不下，两张图是连续的，图1的第二块绿色区域和图2的第一块绿色区域是重叠的（注意看第一列的No.编号）&lt;/p&gt;&lt;p&gt;先说下我的操作：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;开启keep-alive前提下发起第一次http请求&lt;/li&gt;&lt;li&gt;7秒左右时，同样的机器同样的http请求，再重新调用一次&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们根据图中抓包，分析下网络请求：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;197、198、199请求：三次握手建立TCP建立连接&lt;/li&gt;&lt;li&gt;200、203请求：http的请求报文和http的响应报文&lt;/li&gt;&lt;li&gt;212请求：可以通过Protocol列看到它是一条TCP报文。我的理解是：在keep-alive这种机制下，客户端收到服务端响应报文后，需要告知服务端“已收到”。由于要复用TCP连接，所以会多一层保障机制，类似TCP的握手和挥手&lt;/li&gt;&lt;li&gt;459-1965请求（图1中的第一块黑色区域中）：6秒内（第二列代表Time），每隔1秒，发生一对TCP请求的来回，用来维护TCP连接的可用性。保证和等待该TCP连接被复用&lt;/li&gt;&lt;li&gt;1743、1744、1745、1755请求：其中的1743和1745是我第二次发起http请求的请求报文和响应报文。1744请求是：客户端发起请求时，服务端先回复客户端“已收到，马上处理”。紧接着1745将结果响应给客户端。1755则是客户端收到响应后，回复服务端“已收到响应，多谢”。&lt;/li&gt;&lt;li&gt;2028-3903请求：10秒内，每隔1秒，发生一对TCP请求的来回，用来维护TCP连接的可用性。保证和等待该TCP连接被复用&lt;/li&gt;&lt;li&gt;4127-4131请求：10秒内我没再发起http请求，四次挥手断开TCP连接。长时间没被复用，也没必要一直维持下去，浪费资源，还可能造成网络拥堵。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;注意：10秒无请求，TCP连接在断开，10秒也不是默认的，只是环境的配置。是Httpd守护进程，提供的keep-alive timeout时间设置参数。比如nginx的keepalive_timeout，和Apache的KeepAliveTimeout。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;3.3、扩展&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eec576264dafecb673cd8ce958cc526f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1384&quot; data-rawheight=&quot;1510&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-eec576264dafecb673cd8ce958cc526f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1384&quot; data-rawheight=&quot;1510&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-eec576264dafecb673cd8ce958cc526f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-eec576264dafecb673cd8ce958cc526f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt; 其实对于HTTP keep-alive机制可以总结为上图所示。&lt;/p&gt;&lt;p&gt;启用HTTP keep-Alive的优缺点：  优点：keep-alive机制避免了频繁建立和销毁连接的开销。 同时，减少服务端TIME_WAIT状态的TCP连接的数量(因为由服务端进程主动关闭连接) 缺点：若keep-alive timeout设置的时间较长，长时间的TCP连接维持，会一定程度的浪费系统资源。&lt;/p&gt;&lt;p&gt;总体而言，HTTP keep-Alive的机制还是利大于弊的，只要合理使用、配置合理的timeout参数。&lt;/p&gt;&lt;h2&gt;四、总结&lt;/h2&gt;&lt;p&gt;回到文章开头提出的问题：&lt;b&gt;HTTP和TCP的长连接有何区别？HTTP中的keep-alive和TCP中keepalive又有什么区别？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1、TCP连接往往就是我们广义理解上的长连接，因为它具备双端连续收发报文的能力；开启了keep-alive的HTTP连接，也是一种长连接，但是它由于协议本身的限制，服务端无法主动发起应用报文。&lt;/p&gt;&lt;p&gt;2、TCP中的keepalive是用来保鲜、保活的；HTTP中的keep-alive机制主要为了让支撑它的TCP连接活的的更久，所以通常又叫做：HTTP persistent connection（持久连接） 和 HTTP connection reuse（连接重用）。&lt;/p&gt;&lt;h2&gt;五、彩蛋&lt;/h2&gt;&lt;p&gt;&lt;b&gt;彩蛋一&lt;/b&gt;&lt;/p&gt;&lt;p&gt;你能从文中找出我在HTTP keep-alive实验中客户端和服务端的完整IP吗？&lt;/p&gt;&lt;p&gt;如能找出，说明对网络协议的了解已如火纯青。&lt;/p&gt;&lt;p&gt;&lt;b&gt;彩蛋二&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在HTTP请求中，到底是「服务端」还是「客户端」主动关闭连接呢？&lt;/p&gt;&lt;p&gt;看到过很多文章，有人说服务端、有人说客户端、有人说分情况（keep-alive的开启与否）既可能是客户端也可能是服务端。你信谁？最后翻来覆去发现各个网站的各种文章基本类似，只有观点，没有论据。&lt;/p&gt;&lt;p&gt;HTTP keep-alive章节的实验结果：&lt;b&gt;无论开启keep-alive与否，最终由服务端主动断开TCP连接。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;但是我给出问题的答案是：通常&lt;b&gt;由服务端主动关闭连接&lt;/b&gt;。没有写“肯定由服务端主动关闭连接”的原因是，我没遇到客户端主动关闭连接的场景，并不代表没有。网络和协议博大精深，等待我们继续去探索。&lt;/p&gt;&lt;p&gt;这个彩蛋的目的由两个：&lt;/p&gt;&lt;p&gt;1、告诉大家：网上的文章、他人的观点，还是要思辨的看待。&lt;/p&gt;&lt;p&gt;2、我确实想知道什么情况下，客户端主动关闭连接？欢迎大家私信讨论，一定要有真凭实据&lt;/p&gt;&lt;p&gt;&lt;b&gt;彩蛋三&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Wireshark&lt;/b&gt;是一款功能强大的网络封包分析可视化软件。《TCP/IP详解 卷1:协议》第二版相比第一版，书中的抓包工具也将&lt;b&gt;tcpdump&lt;/b&gt;改为&lt;b&gt;&lt;i&gt;*Wireshark。*&lt;/i&gt;&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 个人观点：《TCP/IP详解 卷1:协议》第一版和第二版结合起来看效果更好。第一版的TCP阻塞控制将的更通俗易懂，第二版的TCP保活机制讲的更清晰。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>