<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>94ad8e7d9f7281f79c81b8aa6c46cd0f</guid>
<title>用规则引擎让你一天上线十个需求</title>
<link>https://toutiao.io/k/ldd1cse</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;各位读者朋友大家好，我是薯条，好久没更文章，不知还有多少读者记得这个号，这篇文章写的有点精分，如果你有耐心看完本文，可以翻翻留言区，我会发个新年红包。&lt;/p&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;业务背景&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果是本号老读者，可能知道我是做数据系统的，作为一个在线数据服务组，我们这边承接的需求是小而多的。我在一家打车公司上班，运营大佬们认为不同用户在不同场景下有不同打车需求，设计出来很多子品类。于是我们组会承接这样一类需求：计算用户不同品类的各种实时单量，如：快车呼单量、拼车完单量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样的需求，一般处理流程是这样的：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2546419098143236&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJV5hHuUicxxAkYbxqPehPYWNK9iauXQ6z8mgu3P2qmrh1YXcz7qJ2SbWeQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1508&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;描述一下这个图：用户在订单流转状态关键节点发生动作时，系统会发一个MQ消息让供其他系统消费。其他系统通过一个明确的据口径判断这条msg是否符合当前业务逻辑，进而存db或是丢弃。比如一个需求要计算：拼车完单量，一个靠谱的拼车rd告诉你口径是：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;If aa.bb.cc == &lt;span&gt;1&lt;/span&gt;  &lt;span&gt;// 说明是多车型发单&lt;/span&gt;&lt;br/&gt;  Unmarshal(bb.cc.ee)&lt;br/&gt;  看&lt;span&gt;type&lt;/span&gt;是否为 &lt;span&gt;4&lt;/span&gt; &lt;br/&gt;&lt;span&gt;else&lt;/span&gt;  &lt;span&gt;// 单车型发单&lt;/span&gt;&lt;br/&gt; Unmarshal(bb.cc.ff)&lt;br/&gt;  看&lt;span&gt;type&lt;/span&gt;是否为 &lt;span&gt;4&lt;/span&gt; &lt;br/&gt;(&lt;span&gt;type&lt;/span&gt; = &lt;span&gt;4&lt;/span&gt; 的是拼车)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你对着这个口径，订阅mq，写数据提取和订单判断的逻辑，整个流程写代码1小时，自测一小时，由于你们机器太多，上线花了1整天，整体研发效率还行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二天，产品又给你提了个需求，想计算拼车的发单量，你又去找对应业务线的开发同学寻求一个取数口径，然后重复上面的过程。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第三天，产品上线了，效果不错，数据涨了3个点，老板非常开心，在周会上让PM讲两句他的心路历程，PM同学重点感谢了老板的栽培，然后轻描淡写的说了产品的底层逻辑和关键抓手。而他的几个精明的同事都get到了抓手是你，于是连夜赶PRD，要求你这个抓手把他们负责品类的各种实时单量全给抓出来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第四天，你崩溃了，因为你收到4个PM并行的8个单量需求，正当你奋笔疾书再次准备重复上述流程时，你睿智的老板告诉你这样做有不妥之处：来一个坑填一个萝卜是小农时代的做法，现在都21世纪了，时代变了，让你想一种通用解决方案，让系统走向工业时代！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你似懂非懂点了点头，查了各种CSDN、博客园、知乎、github，又在技术交流群各种@群里大佬有没有遇到这种场景。一番折腾后终于有了头绪，于是你高兴的向老板汇报：老板，我懂了，这个场景可以用&lt;strong&gt;JPATH&lt;/strong&gt; + &lt;strong&gt;Expression Eval来&lt;/strong&gt;解决！这样一来，再来新的需求只需要写在db里插入俩表达式就可以了，20个需求提过来也不用怕。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你的老板微笑着点了点头，看了一眼自己手上的劳力士，有意无意的晃了晃，说：小伙子很上道，自己也琢磨出解法了，赶紧设计方案，争取本周上线，尽快拿到业务结果，到时候升职加薪少不了你的！&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;实现方案&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个系统的核心需求有两点：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;数据提取&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;规则判断&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据提取即ETL，把mq的msg中关键信息提取出来，提取之后可能还需要简单处理一下(比如msg中事件时间是timestamp，你想转化为RFC3339格式) ，这里可以用JPATH 做数据提取 (如果你写过爬虫，一定知道用xpath去提取HTML中的node消息，jpath就是json数据的提取规则)。配置一个ETL rule，如图所示：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.38917525773195877&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVtLzqUc9akicgbQ1OFibse5e31kG40pNo832CiaVfCIpjzgiaw95bFPWTBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1552&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后是数据规则判断，即题目中提到的规则引擎，我们这里使用 开源库govaluate，比如上面拼车完单的例子，我们可以配置这样的规则：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;cc == &lt;span&gt;1&lt;/span&gt; ? ( in(&lt;span&gt;4&lt;/span&gt;, ee)? &lt;span&gt;1&lt;/span&gt;:&lt;span&gt;0&lt;/span&gt; ) : ( ff ==&lt;span&gt;4&lt;/span&gt; ? &lt;span&gt;1&lt;/span&gt;:&lt;span&gt;0&lt;/span&gt;)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;govaluate会把这个表达式构建出一颗ast，然后输入参数进行求值(是不是回忆起来了编译原理？)。接下来让我们研究一下这个库~&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;govaluate介绍与使用注意&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;govaluate支持对C风格的算数/字符串的表达式进行求值。比如这些例子(例子来源于&lt;code&gt;evaluation_test.go&lt;/code&gt;):&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;1. 100 ^ (23 * (2 | 5))&lt;br/&gt;2. 5 &amp;lt; 10 &amp;amp;&amp;amp; 1 &amp;lt; 5&lt;br/&gt;3. (foo == &lt;span&gt;true&lt;/span&gt;) || (bar == &lt;span&gt;true&lt;/span&gt;) // foo、bar为变量&lt;br/&gt;4. theft &amp;amp;&amp;amp; period == 24 ? 60     // theft、period为变量&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个库几乎支持你能想象到的任何表达式，有兴趣可以去这个test文件。除此之外它支持拓展UDF， 你可以自己写一些函数支持你的定制业务逻辑，它还支持执行类方法，更多信息可以看README。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当我们需要使用它时，只需要这几行代码：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;expression, err := govaluate.NewEvaluableExpression(&lt;span&gt;&quot;foo &amp;gt; 0&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;parameters := &lt;span&gt;make&lt;/span&gt;(&lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;interface&lt;/span&gt;{}, &lt;span&gt;8&lt;/span&gt;)&lt;br/&gt;parameters[&lt;span&gt;&quot;foo&quot;&lt;/span&gt;] = &lt;span&gt;-1&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;result, err := expression.Evaluate(parameters);&lt;br/&gt;&lt;span&gt;// result is now set to &quot;false&quot;, the bool value.&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过这个demo我们可以看到它的api被设计成了两步， 第一步&lt;strong&gt;NewEvaluableExpression&lt;/strong&gt;的功能主要是把表达式拓展为一颗AST，&lt;strong&gt;Evaluate&lt;/strong&gt;的主要功能是把用户参数填入ast求值。。举个例子：比如&lt;code&gt;1 + foo + 4 * boo&lt;/code&gt;这个表达式，在两个阶段分别做的事情是这样：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4743083003952569&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJViaTrpK0mHXiaEqJRfGYM6LQBgELYEjdIOaB4OBF17m2Luw8clkia7wib5g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1518&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6153846153846154&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVQ47mBDJ15xPpZBLoaVlErkDZgZWS18sShbA8HY3ocnMheZLmCiaD8KA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1456&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么生产项目代码中直接把这两步抄进去就可以了吗？显然不是。通过观察就可以发现， 第一步构造ast依赖的表达式其实是可以预先确定的，且表达式一般不会变化，没有必要用户每次传一个api就构造一颗ast然后求值。可以把表达式存入db，在项目启动or更新配置时加载到内存中， 比如搞一个&lt;code&gt;map[string]*EvaluableExpression&lt;/code&gt;, 把不同表达式的ast进行cache，这样用户每次请求时只需遍历ast进行求值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;预编译所带来的收益很显著，尤其是在你表达式比较复杂的情况下。我对&lt;code&gt;foo &amp;gt; 2? 1:0&lt;/code&gt;这个表达式分别做了现编译和预编译的benchmark，结果如下：&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;现编译&lt;span/&gt;&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5235404896421846&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVBmgEDSBEUcmdquNUTQY1icbiatlz2hb3qLjrqpsIGomzYEh3fuicicibK8g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2124&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;(现编译 构建ast占用62.3%的cpu开销，而eval只占2%)&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;预编译&lt;span/&gt;&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.25850965961361544&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVurkaBVl2OZia4oWZFplicCuQgYibgCgYAB2fESplOm1fY6Yq7xKsnKMZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2174&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;(预编译省掉了构建ast的成本，节约了大量cpu资源) &lt;span&gt;建议大&lt;/span&gt;&lt;span&gt;家如果使用这个库，有条件要用预编译版本。&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;govaluate 原理&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看起来govaluate很有意思， 接下来让我们挖一下它的源码。首先来看第一阶段，把表达式拓展为AST时的逻辑，我简单画了一张图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3270321361058601&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVPWYf6YphgOuqBfLlcPFw1N6bKjlfib5LZ0GMudopibibAyavS6BaV9eYw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2116&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面以&lt;code&gt;1 + foo + 4 * boo&lt;/code&gt;为例，&lt;strong&gt;parserToken&lt;/strong&gt;后，我们可以得到一堆token:&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6916376306620209&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVWVpWX2KssfbBMLBpDMMQNUR9b3TRZibXVTQc0OuUhJ45oSiaBia15Dq6A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1148&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;checkBalance&lt;/strong&gt;没啥好说的，核心功能就看小括号是否成对出现：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5913312693498453&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJViavNCicMTqhBuDiatVrAys0omkQnJWE5ARKY0HrDsZPNAcxGLloFK8sjg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;646&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而&lt;strong&gt;checkExpressionSyntax&lt;/strong&gt;阶段主要是check token之间是否符合预设规则，核心是这个函数：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.34539473684210525&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVtgibKaazibATy4A9TAxq5oPgzWvCqNK45OmxzyPD3drsTRLHCOVDGV2Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1216&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个函数会check当前的token是否是上一个token的合法值，合法值是预设的，比如NUMERIC的合法值是后面这些：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8816425120772947&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVsict9CppqvyWZ0skSKzmiaPFM7HXEGicOicCuplx4zaI5yVVgmVphlfic1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;828&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来的 &lt;strong&gt;optimizeTokens&lt;/strong&gt; 函数没啥好说的，主要就是编译一下正则。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比较有意思的是&lt;strong&gt;planStages&lt;/strong&gt;这个步骤。&lt;strong&gt;planStages&lt;/strong&gt;这个大步骤内部大概分成了planTokens、reorderStages、elideLiterals这三个小步骤，下面来一一介绍：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.2201834862385321&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVRdBQjRfibKJTYjOz4AgyZVUKhj81uL3GcPryszIZ4BySTYbkOicbot3g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;872&quot;/&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;planTokens&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个函数写的让我大开眼界，首先它用func做不同运算符的优先级计算，原理是func接收struct作为参数，而参数中的next为这个函数连接的下一个优先级的func。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2540880503144654&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJV2T1JicV3Vh6so8Y3xVgZRXAe8ZCX0b8qWibkgQuz1Za1bD7jEYQOJTJw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1590&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个func优先级打印出来是这样的：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3244274809160305&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJV17VVTWv4icTGWnn3dzuibk8LM33xVIQeWMeLtnicGj6SgzoLnLia1YwjMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1572&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有了运算符优先级之后，对于具体的节点，会继续看节点类型，比如是func，accesser还是valueType，valueType的节点对于不同的详细类型也有不同策略，比如数字节点会构建一个Node，而小括号节点会直接parser下一个token来构建优先级更高的树。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于不同的运算符，在这个函数链上会下沉构建出优先级比较高的节点，保证符合数学计算的规律。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;reorderStages&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里主要把ast重排序，让ast由普通tree变成avl tree，树旋转的代码写的特别骚气，比如&lt;code&gt;1 + foo + 4 * boo&lt;/code&gt; 这个表达式，planToken执行完后，会变成这样一颗树：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.0653753026634383&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVJOVlURLoZfVh4sicdItpJ5IdFEe38N1VMe2icjxt2oLdvYXdmbUeSOzw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;重排序的过程是把相同优先级的节点进行旋转，第一步是交换左右节点：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5721518987341773&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVvrdKuDK3hz1aibicOYtxy8C9ZibryNJ3oGDbzmoTeEIyj3cRakRuwdicdA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1580&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二步是LL左旋：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5102564102564102&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJV1VFuKKcBNzI6LZlR0zCO9ericmh7nQaicIg7ficszQibV3zLBCWHiaibVsBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1560&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样就平衡了，一个非常骚气的算法。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;elideLiterals&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个步骤是看叶子节点是否为&lt;code&gt;LITERAL&lt;/code&gt;，比如这棵树：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7185929648241206&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVXPA8iaJ3DDgKPSd0UXLliatRdtWLZaXRKDfN99yOybdNGkRYcg2bIYnQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;796&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这个阶段，各个子节点会进行dfs计算直接变成：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7753623188405797&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVqHBP0nHmszp7FEdpt3A9jYkfETxmexCL87V5Y31BerIVfzkltyU6cQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;276&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至此第一阶段的逻辑梳理完毕。而第二个阶段&lt;strong&gt;Evaluate&lt;/strong&gt;的主要功能是把用户参数填入ast，进行求值。这个过程比较简单，本文不在赘述。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;govaluate 不足&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;govaluate 看起来很美好，真的是这样吗？其实不然，这个项目最后一次commit是2017年，距今已经6年了。我们在使用期间也发现了很多小bug和代码优美度欠缺的地方。下面来简单列举几个：&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;弱类型&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;govaluate所有数字类型都是被解析为float64进行计算的，这么玩写代码爽了，但是当你用&lt;code&gt;1+2+9&lt;/code&gt;做表达式时，可能会得到一个类型为fload64的interface{}结果。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.08793103448275862&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVKjs28yHVsKeuI3uHM26TzQerJ4z239ibnsy7RbgicFoFBMt2DNCItn1g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1160&quot;/&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;函数限制&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;govaluate的函数有的返回值无法继续做运算。比如这个case：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5785340314136126&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVBPKG5Zqib9gzWFGYXlKaEo9YmeM09h9J1m9u8CtyzibLxG208tKdyaTw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1528&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看起来没有任何问题，但是执行会报错：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.042416452442159386&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVAW4fbHuadR8PCdWyntnunjupgdjP8kHlECcm4TMRGXvtr1UMX7XVBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1556&quot;/&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;参数会去除转义符&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如这段代码：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.23166023166023167&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVb78dAme4YlVPnvXpoW5aNRxIL2lrQIic8PAdMib9zelN3AGW5tC2ZXUA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1554&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;理论上结果应该含有转义符，实际上结果是:&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.10996563573883161&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVIukrf7ydrVpF4SW97teCcRDl23V8ibI1q15MGVUlPqecXUNCYKIY5Jw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1164&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实际上是这段代码搞的鬼，代码比较简单，就不解释了。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.33509234828496043&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVqOWSWZxkuozM9uIaDbtgicx7WaIzvRMOynjRE20u3ibGS6PVZANNe3Ow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1516&quot;/&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;奇奇怪怪的代码&lt;span/&gt;&lt;/h4&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;this关键字：这个就不举例子了，这个库里所有方法的接收者都是this，被官方建议熏陶过的我，看的我着实蛋疼...&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;双重否定表肯定：token解析阶段有这样的代码，不知道作者为啥要搞个双重否定，我的话，会用一个&lt;code&gt;isQuote&lt;/code&gt;代替。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.12251655629139073&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9IR9Ct85IUoD4jW0aicGeicJVlenic8mFQf9y5c8J2IQ9koKQoo3GTnmMNKwSBbQvEGsOoBySMHic0mxg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1208&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;govaluate改进&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作为一个17年后就没更新过的项目， 也不知道作者还会不会维护。业务发展是不等人，govaluate对于我们服务来说并不能满足需求，很多时候用起来比较别扭，所以我基于我们的场景对于govaluate做了一些定制改造。我个人还是非常喜欢这个库的，于是把代码fork了一份，加了个eplus后缀，改造了上面那几个匪夷所思的问题。并加了个比较定制化的feature：type promotion。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个听起来比较唬人， 其实就是支持更弱类型的表达式运算，比如我的库支持：&#x27;2&#x27; -1, &#x27;4&#x27; * 3，要支持这种功能，核心需要改两种地方：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;第一种地方是typeCheck。比如subStage会check两个字节点必须是float64类型， 我们要支持string operator num， 可以把typeCheck扩大为可以是chek node是否为 floatOrStr。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第二种地方是OpeatorOperate。前面我们把String类型也放进来让它支持计算了，但是在go里str和float终究是无法计算的， 所以到了计算阶段需要做一个type promotion，即把string类型转化为数字类型之后再计算。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结与反思&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;govaluate在我心中还是有一些不完美的地方，我们这里用它也是因为项目初期就引入了这个库，在大量的线上用例使用后要迁移这个库成本巨大， 对于用的不爽的地方只能改了。如果读者朋友有需求， 可以看一下市面上其他的表达式开源库， 比如gval。当然，如果你的场景比较复杂， 需要很多if else 或者for循环，那简单的规则引擎可能满足不了你的需求，此时可以考虑内嵌个更完整的脚本库或者嵌入lua， 不过这样就更复杂了， 慎重考虑把这样的东西直接放在db里面， 后期不好维护。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;反思&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;govaluate这个库对我有很多启发，最主要就是表达式的预编译可以节省大量CPU开销，组内某个项目目前的运行方式是随着请求现编译，构建执行计划dag图，理论上如果能预编译，请求到来只是对于对应param访问存储，可以节省大量CPU开销。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;跳脱出govaluate本身，我们系统选择JPATH + Expr做数据提取和条件描述做需求，本质上是因为这边的mq数据是JSON格式，JSON有一定的局限性，描述数据没啥问题，但是描述条件就比较困难了，理论上如果用XML这种技能描述条件，又能描述数据的交互形式，那我们可能会构建一个完全不同的系统。&lt;/p&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后稍微打个广告吧， 如果你也想使用govaluate，又有一些定制化的需求，欢迎star我的库然后提个issue， 我想试着维护一个开源库， 嘿嘿。&lt;/p&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;欢迎加入 &lt;strong&gt;随波逐流的薯条&lt;/strong&gt; 微信群。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;薯条目前有草帽群、木叶群、琦玉群，群交流内容不限于技术、投资、趣闻分享等话题。欢迎感兴趣的同学入群交流。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;入群请加薯条的个人微信：709834997。并备注：加入薯条微信群。&lt;/p&gt;&lt;p&gt;欢迎关注我的公众号~&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>f428d0c31404e887b105a4ba926ee7d8</guid>
<title>悄悄学习Doris，偷偷惊艳所有人 | Apache Doris四万字小总结</title>
<link>https://toutiao.io/k/w5o0jfy</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;h2&gt;Doris 简史&lt;/h2&gt;&lt;p&gt;Doris 自第一版诞生以来，经过了 11 年的发展，中间做过无数改进。这⾥只罗列对 Doris 发展来说⽐比较重要的关键节点与事件。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2008&lt;br/&gt;Doris1 ，「筑巢引凤」的重要基石&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在 Doris1 诞生之前，百度使用 MySQL Sharding 方式来为广告主提供广告报表支持。随着百度本身流量的增加，广告流量也随之增加，已有的 MySQL Sharding 方案变得不再能够满足业务的需求。当时数据存储和计算成熟的开源产品很少，Hbase 的导入性能只有大约 2000 条/秒，不能满足业务每小时新增的要求。而业务还在不断增长，来自业务的压力越来越大。在这种情况下，Doris1 诞生了，并且在 2008 年 10 月份跟随百度凤巢系统一起正式上线。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2009&lt;br/&gt;Doris2，解「百度统计」燃眉之急&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2008 年的百度统计服务大约有 50-60 台 MySQL，但是业务每天有 3000 万+条增量数据，由于 MySQL 的存储和查询性能无法满足需求，对存量数据的支撑已经到了极限，问题频出，万般无奈之下百度统计甚至关闭了新增用户的功能，以减少数据量的增加。&lt;/p&gt;&lt;p&gt;Doris1 由于当时时间紧、任务重，所以设计、实现的时候只为了能够满足凤巢的业务需求，并没有兼顾其他的应用需求。2009 年 Doris2 研发完成后上线百度统计，并且成功支撑百度统计后续的快速增长，成功的助力百度统计成为当时国内规模最大，性能、功能最强的统计平台。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2010&lt;br/&gt;Doris3 ，让查询再快一点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;随着业务数据量的不断增长，Doris2 系统的问题也逐渐成为业务发展的瓶颈。首先体现在 Doris2 无法满足业务的查询性能需求，主要是对于长时间跨度的查询请求、以及大客户的查询请求。其次，Doris2 在日常运维方面基本上都需要停服后手动操作，比如 Schema Change、集群扩缩容等，一方面用户体验很差，一方面还会增加集群运维的成本。最后，Doris2 本身并不是高可用系统，机器故障等问题还是会影响服务的稳定性，并且需要人肉进行复杂的操作来恢复服务。为了解决 Doris2 的问题，团队开始了 Doris3 设计、研发。Doris3 的主要架构中，DT（Data Transfer）负责数据导入、DS（Data Seacher）模块负责数据查询、DM（Data Master）模块负责集群元数据管理，数据则存储在 Armor 分布式 Key-Value 引擎中。Doris3 依赖 ZooKeeper 存储元数据，从而其他模块依赖 ZooKeeper 做到了无状态，进而整个系统能够做到无故障单点。&lt;/p&gt;&lt;p&gt;在数据分布方面 Doris3 引入了分区的概念。&lt;br/&gt;另外 Doris3 在日常运维 Schema Change，以及扩容、缩容等方面都做了针对性设计，使其能够自动化进行，不依赖线上人工操作。&lt;/p&gt;&lt;p&gt;Doris3 在 2011 年完成开发后逐渐替换 Doris2 所制成的业务，并且成功的解决了大客户查询的问题。而公司内部后续的新需求，也都由 Doris3 来承担支持。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2012&lt;br/&gt;MySQL + Doris3 ，百度的第一个 OLAP 平台&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2012 年随着 Doris3 逐步迁移 Doris2 的同时，大数据时代悄然到来。在公司内部，随着百度业务的发展，各个业务端需要更加灵活的方式来分析已有的数据。而此时的 Doris3 仍然只支持单表的统计分析查询，还不能够满足业务进行多维分析的需求。所以，为了能够支持业务的多维分析需求，Doris3 采用了 MySQL Storage Handler 的方式来扩展 Doris3。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2012&lt;br/&gt;OLAP Engine，突破底层存储束缚&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Doris3 支持报表分析场景时，底层通用 Key-Value 存储引擎的弊端也逐渐显露。&lt;br/&gt;为了能够在底层存储引擎上有所突破，OLAP Engine 项目启动了。这个项目的发起者是当时从 Google 来的高 T，为百度带来了当时业界最领先的底层报表引擎技术。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2013&lt;br/&gt;用 PALO，玩转 OLAP&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;底层技术的发展会激发上层业务的需求，而上层业务的需求同时会为底层的技术带来新的挑战。因此 Doris 亟需一款拥有分布式计算能力的查询引擎。新产品的名字命名为 PALO，意为玩转 OLAP。随着 PALO1 的正式上线，除了迁移所有 Doris3 已有的的业务外，也成功支持了当时百度内部大部分的 OLAP 分析场景。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2015&lt;br/&gt;PALO 2，让架构再简单一点&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如果说 PALO 1 是为了解决性能问题，那么 PALO 2 主要是为了在架构上进行优化。通过 PALO2 的工作，系统架构本身变得相当简洁，并且不需要任何依赖。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2017 and Future&lt;br/&gt;Apache Doris (incubating) ，是更广阔的世界&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Palo 于 2017 年正式在 GitHub 上开源，并且在 2018 年贡献给 Apache 社区，并将名字改为 Apache Doris(incubating)进行正式孵化。随着开源，Doris 已经在京东、美团、搜狐、小米等公司的生产环境中正式使用，也有越来越多的 Contributor 加入到 Doris 大家庭中。&lt;/p&gt;&lt;h2&gt;整体架构 - MPP架构&lt;/h2&gt;&lt;h3&gt;弹性MPP架构-极简架构&lt;/h3&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGOAygsK4821KIXL12cayTsdpAq4dvC15bgb06pfKDuWZ1JFCrIiaaGVw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;FE前端节点-主要负责元数据的管理、查询调度,解析sql的执行计划给BE，&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;BE-数据的存储和执行的引擎，这里存储和计算还是在一起的；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;FE:leader 、follower(参与选举)，水平扩容&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对外提供了mysql兼容的协议;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGeCypL2AxdSPaf8KKOaBPZgBq50xpTLTJEHeCwUH1Wo9Leec4ezNsjQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.49907407407407406&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGEictxHrM3Ls7zeOOpQfA4dL2whBFVHns3rPdVJkABJibAp0leEGJoXVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5166666666666667&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h4&gt;sql查询进入doris的过程:&lt;/h4&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;解析成逻辑执行计划-A|B两个表的scan -&amp;gt; Join -&amp;gt;聚合(group by K1 sum(V1) )，聚合操作 -&amp;gt; 最后再sort by sum(V1)排序 ；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MPP架构就是可以把执行计划转换成物理层面的，&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;假设有3个节点，会把执行计划类似fregment(有节点的组合)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;scanB扫描B表的数据，可能通过一个brokercust、dataSink和exchange这样的节点会把fregment串联起来，每个fregment中会有不同的计算节点；比如数据经过广播跟A表join，之后进行聚合操作；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;一个MPP就是支持两层的聚合，每个节点做完聚合操作后最后汇总到一个节点再做一次；在doris中支持在中间做一次shuffle，shuffle完成之后在上层再做一次聚合，这样子就不会有大单点的计算瓶颈。再推给上层去做排序。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;根据不同的机器每个fregment会拆成instent它执行的子单元，就可以充分发挥MPP的多基多合的能力，根据机器数量和设置的并行度，充分利用资源。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;智能CBO查询优化器&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGhEt3jEWsyxHPTic261X2fQb1YKeg9KibVCEm36ZfDibftHzCq69aEc5FA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.37777777777777777&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;dorisDB跟开源的apache doris有几个改造点:&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在FE这边的改造:&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;plan会根据cpu的成本预估，加入更多的统计信息(列的基数、直方图等等)，能够更准确的预估表的执行计划。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;两个表join时，使用brokercast join还是shuffle join还是其他join的一些方式，左右表过滤出来应该有多少行数等，哪个表作为左右表等；聚合函数用1层还是2层等等&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;极速向量化引擎&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGYicVtb4IdbEXpV3gdgrud3Pj2VGDFrhZALQ57xRCsLdovZNWI2ucaIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.43148148148148147&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h4&gt;高效的列式存储&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGGEDdze1jd3gKF9JYeYgicFJicYHpTMnfDZaf1YvfKZzD3znZobdNQRuQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.43425925925925923&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h4&gt;现代化物化视图加速&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGobH1ZoMttFiaJOxpmf0Lia9UzsklLibk11Nu4ghia4ySOHpbicByEOmchNg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.45740740740740743&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h4&gt;实时构建DWS数据&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGq1y7bzfWJKv6vTdfF51OcgH04wBLhEueSLib1PQcuS5UVxk0kRfOExw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5092592592592593&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;实时数据分析报表的场景:&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;flume-kafka-doris(进行实时数据的聚合)-BI工具的展示&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Join优化 — colocated Join&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGFwRzhY0cSm2R6mGuicGc3BP1yXN4FZVefedeawPtF6AOzRoe3LibIAeg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.462037037037037&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;doris多表关联有一个明显的优势:&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;原来的建模倾向于宽表，一旦维度的变更就会导致数据的重新刷新，灵活性降低。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;现场关联，秒级查询返回；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;除了高效的shuffle join外还会有一个colocate join 降低特别大的两个表的数据传输量。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;colocate join 在建表时就数据的分布方式，相同的数据可以哈希到一个桶中，所有的数据都可以在本地进行关联操作，最后再在上层做一次数据的聚合。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;极简运维，弹性伸缩&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGnicCXgZJ7FQRa1NSEcCqkT5cS6GCvsTx9RhCj8qUxJWuQk1pdUKEicdQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.4398148148148148&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h2&gt;设计原理&lt;/h2&gt;&lt;h3&gt;海量分布式存储系统Doris原理概述&lt;/h3&gt;&lt;p&gt;Doris是一个海量分布式 KV 存储系统，其设计目标是支持中等规模高可用可伸缩的 KV 存储集群。Doris可以实现海量存储，线性伸缩、平滑扩容，自动容错、故障转移，高并发，且运维成本低。部署规模，建议部署4-100+台服务器。&lt;/p&gt;&lt;h4&gt;逻辑架构&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGVXXnXeFuibwOXWX1vwkd0qsny7rLrnDnSMiayLFjdI7YhqtWhWjiaSgxA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.40555555555555556&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;Doris采用两层架构，Client 和 DataServer+Store。&lt;br/&gt;有四个核心组件，Client、DataServer、Store、Administration。&lt;br/&gt;应用程序通过Client SDK进行Doris的访问，每台服务器上部署一个Data Sever做服务器的管理，每台服务器上有自己的存储Store，整个集群的数据存储，每台机器独立部署。数据通过路由选择写入到不同的机器中。&lt;br/&gt;Administration为管理中心，提供配置、管理和监控。&lt;br/&gt;config指应用程序启动一个Data Server，在启动时要配置管理中心的ip地址，通关管理中心。管理中心会修改配置项感知到集群中加了新机器，对新机器管理，扩容等。待机器处于可用状态，将该机器的配置项通知给KV Client。从而KV Client进行新的路由选择。扩容、下线机器等的控制台界面通过Management管理。Monitor监控机器是否正常。&lt;/p&gt;&lt;h4&gt;KV Storage 概念模型&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGVVQl0oddbCA5e9POll9SzZnV9ySuiagkYMicVXXG8M66z9TePfgT8icQg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.4777777777777778&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;client写数据，绑定产品的namespace（逻辑隔离），构成新key，路由到具体机器上读写。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGDzZkm5TDKzMicU6P3icYmIk7EDmLkvy5wI4I6M7FepUNiczvriax1zFnicg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.38425925925925924&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;路由解析算法是设计的一个关键点，决定集群的管理方式，也决定了集群扩容的复杂性和难度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Doris的算法类似redis，有桶的概念，key映射到1w个虚拟节点，虚拟节点在映射到物理节点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;由于Doris设计时，用于4-100+规模的集群。因此，Doris分了1w个虚拟节点，当服务器超过100会导致负载不均衡，1000会更差，相当于每一个集群上有10个虚拟节点，虚拟节点会有10%的影响。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;扩容时，需要调节虚拟节点指向新的位置。具体过程为，暴利轮询新节点添加后，一个服务器上应该承载的虚拟节点个数，将超出的虚拟节点迁移到新机器即可。如上图左图有2个物理节点，扩容后，有3个物理节点，变为右图。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;基本访问架构&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGFTubuS6n0cgolATzh0Ah4ODCwOEHnS55Bh6xPXsUDdduwzLiacMyc3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5318725099601593&quot; data-w=&quot;1004&quot;/&gt;&lt;/p&gt;&lt;h4&gt;监控检测&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGosBwibPgZkF6EEozkEN3DCyUAzokMb8BgGO0W1XnrKXj3aWOAIGibgRQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5203703703703704&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;集群管理的重要角色Config Server，有一个功能是负责发现故障服务器。&lt;br/&gt;发现故障的方式有2种：&lt;/p&gt;&lt;p&gt;通常心跳检测是慢的，几秒进行一次心跳检测。更多时候，是client Fail失败报告发现无效服务器，当写入失败时，Client会告诉Config Server。Config Server校验，也访问失败，则通知其他client。&lt;/p&gt;&lt;h3&gt;基本原理&lt;/h3&gt;&lt;h4&gt;读取数据流程&lt;/h4&gt;&lt;p&gt;用户可使用MySQL客户端连接FE，执行SQL查询， 获得结果。&lt;/p&gt;&lt;p&gt;查询流程如下：&lt;/p&gt;&lt;p&gt;① MySQL客户端执行DQL SQL命令。&lt;br/&gt;② FE解析, 分析, 改写, 优化和规划, 生成分布式执行计划。&lt;br/&gt;③ 分布式执行计划由 若干个可在单台be上执行的plan fragment构成， FE执行exec_plan_fragment, 将plan fragment分发给BE，指定其中一台BE为coordinator。&lt;br/&gt;④ BE执行本地计算, 比如扫描数据。&lt;br/&gt;⑤ 其他BE调用transimit_data将中间结果发送给BE coordinator节点汇总为最终结果。&lt;br/&gt;⑥ FE调用fetch_data获取最终结果。&lt;br/&gt;⑦ FE将最终结果发送给MySQL client。&lt;/p&gt;&lt;p&gt;执行计划在BE上的实际执行过程比较复杂, 采用向量化执行方式，比如一个算子产生4096个结果，输出到下一个算子参与计算，而非batch方式或者one-tuple-at-a-time。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGbGZoibuAarUbRKWRCYsoVWScseMrqQVagl2OJHIGgaRcgQa28wRPH2A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.6555555555555556&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h4&gt;导入数据流程&lt;/h4&gt;&lt;p&gt;用户创建表之后, 导入数据填充表.&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;支持导入数据源有: 本地文件, HDFS, Kafka和S3.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;支持导入方式有: 批量导入, 流式导入, 实时导入.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;支持的数据格式有: CSV, Parquet, ORC等.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;导入发起方式有: 用RESTful接口, 执行SQL命令.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;数据导入的流程如下:&lt;/p&gt;&lt;p&gt;① 用户选择一台BE作为协调者, 发起数据导入请求, 传入数据格式, 数据源和标识此次数据导入的label, label用于避免数据重复导入. 用户也可以向FE发起请求, FE会把请求重定向给BE.&lt;br/&gt;② BE收到请求后, 向FE master节点上报, 执行loadTxnBegin, 创建全局事务。 因为导入过程中, 需要同时更新base表和物化索引的多个bucket, 为了保证数据导入的一致性, 用事务控制本次导入的原子性.&lt;br/&gt;③ BE创建事务成功后, 执行streamLoadPut调用, 从FE获得本次数据导入的计划. 数据导入, 可以看成是将数据分发到所涉及的全部的tablet副本上, BE从FE获取的导入计划包含数据的schema信息和tablet副本信息.&lt;br/&gt;④ BE从数据源拉取数据, 根据base表和物化索引表的schema信息, 构造内部数据格式.&lt;br/&gt;⑤ BE根据分区分桶的规则和副本位置信息, 将发往同一个BE的数据, 批量打包, 发送给BE, BE收到数据后, 将数据写入到对应的tablet副本中.&lt;br/&gt;⑥ 当BE coordinator节点完成此次数据导入, 向FE master节点执行loadTxnCommit, 提交全局事务, 发送本次数据导入的 执行情况, FE master确认所有涉及的tablet的多数副本都成功完成, 则发布本次数据导入使数据对外可见, 否则, 导入失败, 数据不可见, 后台负责清理掉不一致的数据.&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGmOZewJKFMj3LjaCxWicU2GIoKaj5F0qMbpGmD6ADxibnIicNfEFqW8Fdg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5527777777777778&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h4&gt;修改元数据流程&lt;/h4&gt;&lt;p&gt;更改元数据的操作有: 创建数据库, 创建表, 创建物化视图, 修改schema等等. 这样的操作需要:&lt;/p&gt;&lt;p&gt;元数据的更新操作流程如下:&lt;/p&gt;&lt;p&gt;① 用户使用MySQL client执行SQL的DDL命令, 向FE的master节点发起请求; 比如: 创建表.&lt;br/&gt;② FE检查请求合法性, 然后向BE发起同步命令, 使操作在BE上生效; 比如: FE确定表的列类型是否合法, 计算tablet的副本的放置位置, 向BE发起请求, 创建tablet副本.&lt;br/&gt;③ BE执行成功, 则修改内存的Catalog. 比如: 将table, partition, index, tablet的副本信息保存在Catalog中.&lt;br/&gt;④ FE追加本次操作到EditLog并且持久化.&lt;br/&gt;⑤ FE通过复制协议将EditLog的新增操作项同步到FE的follower节点.&lt;br/&gt;⑥ FE的follower节点收到新追加的操作项后, 在自己的Catalog上按顺序播放, 使得自己状态追上FE master节点.&lt;/p&gt;&lt;p&gt;上述执行环节出现失败, 则本次元数据修改失败.&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGyoQOBsQia5m29tC1rV5V5ib2OdLJXenlibKbobk3YdefZBuM94LKpicstA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.8314814814814815&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h3&gt;表设计详解&lt;/h3&gt;&lt;h4&gt;数据存储基本原理&lt;/h4&gt;&lt;p&gt;查找维度列的前缀的查找过程为: 先查找shortkey index, 获得逻辑块的起始行号, 查找维度列的行号索引, 获得目标列的数据块, 读取数据块, 然后解压解码, 从数据块中找到维度列前缀对应的数据项.&lt;/p&gt;&lt;h4&gt;加速数据处理&lt;/h4&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.32314814814814813&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGibzwXa8icKaa5YSd0fpibAYeTVTaS9MKVfJFInV4a7zucQqayia1dbbRLQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;DorisDB的表和关系型数据相同, 由行和列构成. 每行数据对应用户一条记录, 每列数据有相同数据类型. 所有数据行的列数相同, 可以动态增删列. DorisDB中, 一张表的列可以分为维度列(也成为key列)和指标列(value列), 维度列用于分组和排序, 指标列可通过聚合函数SUM, COUNT, MIN, MAX, REPLACE, HLL_UNION, BITMAP_UNION等累加起来. 因此, DorisDB的表也可以认为是多维的key到多维指标的映射.&lt;/p&gt;&lt;p&gt;在DorisDB中, 表中数据按列存储, 物理上, 一列数据会经过分块编码压缩等操作, 然后持久化于非易失设备, 但在逻辑上, 一列数据可以看成由相同类型的元素构成的数组. 一行数据的所有列在各自的列数组中保持对齐, 即拥有相同的数组下标, 该下标称之为序号或者行号. 该序号是隐式, 不需要存储的, 表中的所有行按照维度列, 做多重排序, 排序后的位置就是该行的行号.&lt;/p&gt;&lt;p&gt;查询时, 如果指定了维度列的等值条件或者范围条件, 并且这些条件中维度列可构成表维度列的前缀, 则可以利用数据的有序性, 使用range-scan快速锁定目标行.&lt;/p&gt;&lt;p&gt;当范围查找时, 如何快速地找到起始的目标行呢? 答案是shortkey index. 如下图所示: shortkey索引为稀疏索引,&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGtAITLxb3FVQaIDF2ibMEicJ6NzK1u7NYo2G9MOFuc6lF8XqlQykqUvjw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5157407407407407&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h4&gt;表模型介绍&lt;/h4&gt;&lt;p&gt;为了描述方便, 我们借鉴关系模式中的主键概念, 称DorisDB表的维度列的取值构成数据表的排序键, DorisDB的排序键对比传统的主键具有:&lt;/p&gt;&lt;p&gt;对于摄入(ingest)的主键重复的多行数据, 填充于(populate)数据表中时, 按照三种处理方式划分:&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;明细模型: 表中存在主键重复的数据行, 和摄入数据行一一对应, 用户可以召回所摄入的全部历史数据.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;聚合模型: 表中不存在主键重复的数据行, 摄入的主键重复的数据行合并为一行, 这些数据行的指标列通过聚合函数合并, 用户可以召回所摄入的全部历史数据的累积结果, 但无法召回全部历史数据.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更新模型: 聚合模型的特殊情形, 主键满足唯一性约束, 最近摄入的数据行, 替换掉其他主键重复的数据行. 相当于在聚合模型中, 为数据表的指标列指定的聚合函数为REPLACE, REPLACE函数返回一组数据中的最新数据.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;需要注意:&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;建表语句, 排序列的定义必须出现在指标列定义之前.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;排序列在建表语句中的出现次序为数据行的多重排序的次序.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;排序键的稀疏索引(shortkey index)会选择排序键的若干前缀列.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;明细模型&lt;/h4&gt;&lt;p&gt;DorisDB建表的默认模型是明细模型。&lt;/p&gt;&lt;p&gt;一般用明细模型来处理的场景有如下特点：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;需要保留原始的数据（例如原始日志，原始操作记录等）来进行分析；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;查询方式灵活, 不局限于预先定义的分析方式, 传统的预聚合方式难以命中;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数据更新不频繁。导入数据的来源一般为日志数据或者是时序数据, 以追加写为主要特点, 数据产生后就不会发生太多变化。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;聚合模型&lt;/h4&gt;&lt;p&gt;在数据分析领域，有很多需要对数据进行统计和汇总操作的场景。比如:&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;分析网站或APP访问流量，统计用户的访问总时长、访问总次数;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;广告厂商为广告主提供的广告点击总量、展示总量、消费统计等;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;分析电商的全年的交易数据, 获得某指定季度或者月份的, 各人口分类(geographic)的爆款商品.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;适合采用聚合模型来分析的场景具有如下特点：&lt;/p&gt;&lt;h4&gt;更新模型&lt;/h4&gt;&lt;p&gt;有些分析场景之下，数据会更新, DorisDB采用更新模型来满足这种需求。比如在电商场景中，定单的状态经常会发生变化，每天的订单更新量可突破上亿。在这种量级的更新场景下进行实时数据分析，如果在明细模型下通过delete+insert的方式，是无法满足频繁更新需求的; 因此, 用户需要使用更新模型来满足数据分析需求。&lt;/p&gt;&lt;p&gt;以下是一些适合更新模型的场景特点：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;已经写入的数据有大量的更新需求；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;需要进行实时数据分析。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;数据分布&lt;/h3&gt;&lt;h4&gt;数据分布方式&lt;/h4&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;数据分布：数据分布是将数据划分为子集, 按一定规则, 均衡地分布在不同节点上，以期最大限度地利用集群的并发性能。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;短查询：short-scan query，指扫描数据量不大，单机就能完成扫描的查询。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;长查询：long-scan query，指扫描数据量大，多机并行扫描能显著提升性能的查询。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;常见的四种数据分布方式有：(a) Round-Robin、(b) Range、(c) List和(d) Hash (DeWitt and Gray, 1992)。如下图所示:&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CG9q7A7Sk4yJZNsF8uWM7KSGCwxND4L2Kh1AfBl7WL3tU3Rtq7Pp5Qqw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.9398148148148148&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Round-Robin : 以轮转的方式把数据逐个放置在相邻节点上。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Range : 按区间进行数据分布，图中区间[1-3]，[4-6]分别对应不同Range。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;List : 直接基于离散的各个取值做数据分布，性别、省份等数据就满足这种离散的特性。每个离散值会映射到一个节点上，不同的多个取值可能也会映射到相同节点上。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hash : 按哈希函数把数据映射到不同节点上。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;如何选择排序键&lt;/h3&gt;&lt;h4&gt;排序键基本原理&lt;/h4&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;数据倾斜：业务方如果确定数据有很大程度的倾斜，那么建议采用多列组合的方式进行数据分桶，而不是只单独采用倾斜度大的列做分桶。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;高并发：分区和分桶应该尽量覆盖查询语句所带的条件，这样可以有效减少扫描数据，提高并发。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;高吞吐：尽量把数据打散，让集群以更高的并发扫描数据，完成相应计算。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;dynamic_partition.enable : 是否开启动态分区特性，可指定为 TRUE 或 FALSE。如果不填写，默认为 TRUE。&lt;/p&gt;&lt;p&gt;dynamic_partition.time_unit : 动态分区调度的粒度，可指定为 DAY/WEEK/MONTH。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;指定为 DAY 时，分区名后缀需为yyyyMMdd，例如20200325。图1 就是一个按天分区的例子，分区名的后缀满足yyyyMMdd。 PARTITION p20200321 VALUES LESS THAN (&quot;2020-03-22&quot;), PARTITION p20200322 VALUES LESS THAN (&quot;2020-03-23&quot;), PARTITION p20200323 VALUES LESS THAN (&quot;2020-03-24&quot;), PARTITION p20200324 VALUES LESS THAN (&quot;2020-03-25&quot;)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;指定为 WEEK 时，分区名后缀需为yyyy_ww，例如2020_13代表2020年第13周。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;指定为 MONTH 时，动态创建的分区名后缀格式为 yyyyMM，例如 202003。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;dynamic_partition.start: 动态分区的开始时间。以当天为基准，超过该时间范围的分区将会被删除。如果不填写，则默认为Integer.MIN_VALUE 即 -2147483648。&lt;/p&gt;&lt;p&gt;dynamic_partition.end: 动态分区的结束时间。 以当天为基准，会提前创建N个单位的分区范围。&lt;/p&gt;&lt;p&gt;dynamic_partition.prefix : 动态创建的分区名前缀。&lt;/p&gt;&lt;p&gt;dynamic_partition.buckets : 动态创建的分区所对应的分桶数量。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;指定为 DAY 时，分区名后缀需为yyyyMMdd，例如20200325。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;指定为 WEEK 时，分区名后缀需为yyyy_ww，例如 2020_13, 代表2020年第13周。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;指定为 MONTH 时，动态创建的分区名后缀格式为 yyyyMM，例如 202003。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DorisDB中为加速查询，在内部组织并存储数据时，会把表中数据按照指定的列进行排序，这部分用于排序的列（可以是一个或多个列），可以称之为Sort Key。明细模型中Sort Key就是指定的用于排序的列（即 DUPLICATE KEY 指定的列），聚合模型中Sort Key列就是用于聚合的列（即 AGGREGATE KEY 指定的列），更新模型中Sort Key就是指定的满足唯一性约束的列（即 UNIQUE KEY 指定的列）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;h2&gt;核心功能&lt;/h2&gt;&lt;h3&gt;存储结构设计解析&lt;/h3&gt;&lt;p&gt;Doris是基于MPP架构的交互式SQL数据仓库，主要用于解决近实时的报表和多维分析。Doris高效的导入、查询离不开其存储结构精巧的设计。&lt;/p&gt;&lt;h4&gt;设计目标&lt;/h4&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;批量导入，少量更新&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;绝大多数的读请求&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;宽表场景，读取大量行，少量列&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;非事务场景&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;良好的扩展性&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;储存文件格式&lt;/h4&gt;&lt;p&gt;1、存储目录结构&lt;/p&gt;&lt;p&gt;存储层对存储数据的管理通过storage_root_path路径进行配置，路径可以是多个。存储目录下一层按照分桶进行组织，分桶目录下存放具体的tablet，按照tablet_id命名子目录。&lt;/p&gt;&lt;p&gt;Segment文件存放在tablet_id目录下按SchemaHash管理。Segment文件可以有多个，一般按照大小进行分割，默认为256MB。其中，Segment v2文件命名规则为：${rowset_id}_${segment_id}.dat。&lt;/p&gt;&lt;p&gt;2、Segment v2文件结构&lt;/p&gt;&lt;p&gt;Segment整体的文件格式分为数据区域，索引区域和footer三个部分&lt;/p&gt;&lt;p&gt;SegmentFooterPB: 定义文件的元数据信息&lt;br/&gt;4个字节的FooterPB内容的checksum&lt;br/&gt;4个字节的FileFooterPB消息长度，用于读取FileFooterPB&lt;br/&gt;8个字节的MAGIC CODE，之所以在末位存储，是方便不同的场景进行文件类型的识别&lt;/p&gt;&lt;h4&gt;Footer信息&lt;/h4&gt;&lt;p&gt;Footer信息段在文件的尾部，存储了文件的整体结构，包括数据域的位置，索引域的位置等信息，其中有SegmentFooterPB，CheckSum，Length，MAGIC CODE 4个部分。&lt;/p&gt;&lt;p&gt;SegmentFooterPB数据结构如下：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CG7DvW7fb265PIAacXUVcRlGA6cibrHHjLjPApLiblo0w6oGs3xhgmUmLA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.6601851851851852&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;SegmentFooterPB采用了PB格式进行存储，主要包含了列的meta信息、索引的meta信息，Segment的short key索引信息、总行数。&lt;/p&gt;&lt;p&gt;1、列的meta信息&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;ColumnId：当前列在schema中的序号&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;UniqueId：全局唯一的id&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Type：列的类型信息&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Length：列的长度信息&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Encoding：编码格式&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Compression：压缩格式&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Dict PagePointer：字典信息&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2、列索引的meta信息&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;OrdinalIndex：存放列的稀疏索引meta信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ZoneMapIndex：存放ZoneMap索引的meta信息，内容包括了最大值、最小值、是否有空值、是否没有非空值。SegmentZoneMap存放了全局的ZoneMap信息，PageZoneMaps则存放了每个页面的统计信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;BitMapIndex：存放BitMap索引的meta信息，内容包括了BitMap类型，字典数据BitMap数据。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;BloomFilterIndex：存放了BloomFilter索引信息。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Ordinal Index (一级索引)&lt;/h4&gt;&lt;p&gt;Ordinal Index索引提供了通过行号来查找Column Data Page数据页的物理地址。Ordinal Index能够将按列存储数据按行对齐，可以理解为一级索引。其他索引查找数据时，都要通过Ordinal Index查找数据Page的位置。因此，这里先介绍Ordinal Index索引。&lt;/p&gt;&lt;p&gt;在一个segment中，数据始终按照key（AGGREGATE KEY、UNIQ KEY 和 DUPLICATE KEY）排序顺序进行存储，即key的排序决定了数据存储的物理结构。确定了列数据的物理结构顺序，在写入数据时，Column Data Page是由Ordinal index进行管理，Ordinal index记录了每个Column Data Page的位置offset、大小size和第一个数据项行号信息，即Ordinal。这样每个列具有按行信息进行快速扫描的能力。&lt;/p&gt;&lt;h4&gt;列数据存储&lt;/h4&gt;&lt;p&gt;Column的data数据按照Page为单位分块存储，每个Page大小一般为64*1024个字节。&lt;/p&gt;&lt;p&gt;Page在存储的位置和大小由ordinal index管理。&lt;/p&gt;&lt;p&gt;1、data page存储结构&lt;/p&gt;&lt;p&gt;DataPage主要为Data部分、Page Footer两个部分。&lt;br/&gt;Data部分存放了当前Page的列的数据。当允许存在Null值时，对空值单独存放了Null值的Bitmap，由RLE格式编码通过bool类型记录Null值的行号。&lt;br/&gt;Page Footer包含了Page类型Type、UncompressedSize未压缩时的数据大小、FirstOrdinal当前Page第一行的RowId、NumValues为当前Page的行数、NullMapSize对应了NullBitmap的大小。&lt;/p&gt;&lt;p&gt;2、数据压缩&lt;/p&gt;&lt;p&gt;针对不同的字段类型采用了不同的编码。默认情况下，针对不同类型采用的对应关系如下：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGmqIeocMHD5sKUuwmuxBdVnsncLdicv9qiaCjHZlqDaBQR2yZB5I5qChA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.33661971830985915&quot; data-w=&quot;710&quot;/&gt;&lt;/p&gt;&lt;p&gt;默认采用LZ4F格式对数据进行压缩。&lt;/p&gt;&lt;h4&gt;存储结构&lt;/h4&gt;&lt;p&gt;1、存储结构&lt;/p&gt;&lt;p&gt;Short Key Index前缀索引，是在key（AGGREGATE KEY、UNIQ KEY 和 DUPLICATE KEY）排序的基础上，实现的一种根据给定前缀列，快速查询数据的索引方式。这里Short Key Index索引也采用了稀疏索引结构，在数据写入过程中，每隔一定行数，会生成一个索引项。这个行数为索引粒度默认为1024行，可配置。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGteXtGTBHgoYiaacNzEq38r3pILzgia2q0ztJgtIfa3icKOFeAialicI22kw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.6092592592592593&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;其中，KeyBytes中存放了索引项数据，OffsetBytes存放了索引项在KeyBytes中的偏移。&lt;/p&gt;&lt;p&gt;2、索引生成规则&lt;/p&gt;&lt;p&gt;Short Key Index采用了前36 个字节，作为这行数据的前缀索引。当遇到 VARCHAR 类型时，前缀索引会直接截断。&lt;/p&gt;&lt;h4&gt;ZoneMap Index索引&lt;/h4&gt;&lt;p&gt;ZoneMap索引存储了Segment和每个列对应每个Page的统计信息。这些统计信息可以帮助在查询时提速，减少扫描数据量，统计信息包括了Min最大值、Max最小值、HashNull空值、HasNotNull不全为空的信息。&lt;/p&gt;&lt;h4&gt;BloomFilter&lt;/h4&gt;&lt;p&gt;当一些字段不能利用Short Key Index并且字段存在区分度比较大时，Doris提供了BloomFilter索引。&lt;/p&gt;&lt;h4&gt;Bitmap Index索引&lt;/h4&gt;&lt;p&gt;Doris还提供了BitmapIndex用来加速数据的查询。&lt;/p&gt;&lt;h3&gt;写入流程、删除流程分析&lt;/h3&gt;&lt;p&gt;Doris 针对不同场景支持了多种形式的数据写入方式，其中包括了从其他存储源导入 Broker Load、http 同步数据导入 Stream Load、例行的 Routine Load 导入和 Insert Into 写入等。同时导入流程会涉及 FE 模块（主要负责导入规划生成和导入任务的调度工作）、BE 模块（主要负责数据的 ETL 和存储）、Broker 模块（提供 Doris 读取远端存储系统中文件的能力）。其中 Broker 模块仅在 Broker Load 类型的导入中应用。&lt;/p&gt;&lt;p&gt;下面以 Stream Load 写入为例子，描述了 Doris 的整体的数据写入流程如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGND57ibicPicufA9icsVHtFHMG8uanvhtX4jG8F14EUxVoM3Z7fPU2K8jSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.7305263157894737&quot; data-w=&quot;950&quot;/&gt;&lt;/p&gt;&lt;p&gt;流程描述如下：&lt;/p&gt;&lt;p&gt;1、FE 接收用户的写入请求，并随机选出 BE 作为 Coordinator BE。将用户的请求重定向到这个 BE 上。&lt;br/&gt;2、Coordinator BE 负责接收用户的数据写入请求，同时请求 FE 生成执行计划并对调度、管理导入任务 LoadJob 和导入事务。&lt;br/&gt;3、Coordinator BE 调度执行导入计划，执行对数据校验、清理之后。&lt;br/&gt;4、数据写入到 BE 的存储层中。在这个过程中会先写入到内存中，写满一定数据后按照存储层的数据格式写入到物理磁盘上。&lt;/p&gt;&lt;h4&gt;数据分发流程&lt;/h4&gt;&lt;p&gt;数据在经过清洗过滤后，会通过 Open/AddBatch 请求分批量的将数据发送给存储层的 BE 节点上。在一个 BE 上支持多个 LoadJob 任务同时并发写入执行。LoadChannelMgr 负责管理了这些任务，并对数据进行分发。&lt;/p&gt;&lt;p&gt;数据分发和写入过程如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGwSLjfPHNOFlXcKpGsL6xtDm4fmVrXKSlXXic8NxhvOGN21kYyLCLVcw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.612037037037037&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;每次导入任务 LoadJob 会建立一个 LoadChannel 来执行，LoadChannel 维护了一次导入的通道，LoadChannel 可以将数据分批量写入操作直到导入完成。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;LoadChannel 会创建一个 TabletsChannel 执行具体的导入操作。一个 TabletsChannel 对应多个 Tablet。一次数据批量写入操作中，TabletsChannel 将数据分发给对应 Tablet，由 DeltaWriter 将数据写入到 Tablet，便开始了真正的写入操作。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;DeltaWriter 与 Memtable&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;DeltaWriter 主要负责不断接收新写入的批量数据，完成单个 Tablet 的数据写入。由于新增的数据可以是增量 Delta 部分，因此叫做 DeltaWriter。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;DeltaWriter 数据写入采用了类 LSM 树的结构，将数据先写到 Memtable 中，当 Memtable 数据写满后，会异步 flush 生成一个 Segment 进行持久化，同时生成一个新的 Memtable 继续接收新增数据导入，这个 flush 操作由 MemtableFlushExecutor 执行器完成。&lt;/p&gt;&lt;p&gt;Memtable 中采用了跳表的结构对数据进行排序，排序规则使用了按照 schema 的 key 的顺序依次对字段进行比较。这样保证了写入的每一个写入 Segment 中的数据是有序的。如果当前模型为非 DUP 模型（AGG 模型和 UNIQUE 模型）时，还会对相同 key 的数据进行聚合。&lt;/p&gt;&lt;h4&gt;物理写入&lt;/h4&gt;&lt;p&gt;1、RowsetWriter 各个模块设计&lt;/p&gt;&lt;p&gt;在物理存储层面的写入，由 RowsetWriter 完成。RowsetWriter 中又分为 SegmentWriter、ColumnWriter、PageBuilder、IndexBuilder 等子模块。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;其中 RowsetWriter 从整体上完成一次导入 LoadJob 任务的写入，一次导入 LoadJob 任务会生成一个 Rowset，一个 Rowset 表示一次导入成功生效的数据版本。实现上由 RowsetWriter 负责完成 Rowset 的写入。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SegmentWriter 负责实现 Segment 的写入。一个 Rowset 可以由多个 Segment 文件组成。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ColumnWriter 被包含在 SegmentWriter 中，Segment 的文件是完全的列存储结构，Segment 中包含了各个列和相关的索引数据，每个列的写入由 ColumnWriter 负责写入。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在文件存储格式中，数据和索引都是按 Page 进行组织，ColumnWriter 中又包含了生成数据 Page 的 PageBuilder 和生成索引 Page 的 IndexBuilder 来完成 Page 的写入。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最后，FileWritableBlock 来负责具体的文件的读写。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2、RowsetWriter 写入流程&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGPkBPowB4QXkbdDrVxd2lWR250rcgsOEMRuFxicwqSo3oibUaThbRKdDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.6972222222222222&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;物理写入流程的详细描述：&lt;/p&gt;&lt;p&gt;1.当一个 Memtable 写满时(默认为 100M)，将 Memtable 的数据会 flush 到磁盘上，这时 Memtable 内的数据是按 key 有序的。然后逐行写入到 RowsetWriter 中。&lt;br/&gt;2.RowsetWriter 将数据同样逐行写入到 SegmentWriter 中，RowsetWriter 会维护当前正在写入的 SegmentWriter 以及要写入的文件块列表。每完成写入一个 Segment 会增加一个文件块对应。&lt;br/&gt;3.SegmentWriter 将数据按行写入到各个 ColumnWriter 的中，同时写入 ShortKeyIndexBuilder。ShortKeyIndexBuilder 主要负责生成 ShortKeyIndex 的索引 Page 页。具体的 ShortKeyIndex 索引格式可以参见《Doris 存储层设计介绍 1——存储结构设计解析》文档。&lt;br/&gt;4.ColumnWriter 将数据分别写入 PageBuilder 和各个 IndexBuilder，PageBuilder 用来生成 ColumnData 数据的 PageBuilder，各个 IndexBuilder 包括了（OrdinalIndexBuilder 生成 OrdinalIndex 行号稀疏索引的 Page 格式、ZoneMapIndexBuilder 生成 ZoneMapIndex 索引的 Page 格式、BitMapIndexBuilder 生成 BitMapIndex 索引的 Page 格式、BloomFilterIndexBuilder 生成 BloomFilterIndex 索引的 Page 格式）。具体参考 Doris 存储文件格式解析。&lt;br/&gt;5.添加完数据后，RowsetWriter 执行 flush 操作。&lt;br/&gt;6.SegmentWriter 的 flush 操作，将数据和索引写入到磁盘。其中对磁盘的读写由 FileWritableBlock 完成。&lt;br/&gt;7.ColumnWriter 将各自数据、索引生成的 Page 顺序写入到文件中。&lt;br/&gt;8.SegmentWriter 生成 SegmentFooter 信息，SegmentFooter 记录了 Segment 文件的原数据信息。完成写入操作后，RowsetWriter 会再开启新的 SegmentWriter，将下一个 Memtable 写入新的 Segment，直到导入完成。&lt;/p&gt;&lt;h4&gt;Rowset 发布&lt;/h4&gt;&lt;p&gt;整个发布过程如下：&lt;/p&gt;&lt;p&gt;1.DeltaWriter 统计当前 RowsetMeta 元数据信息，包括行数、字节数、时间、Segment 数量。&lt;br/&gt;2.保存到 RowsetMeta 中，向 FE 提交导入事务。当前导入事务由 FE 开启，用来保证一次导入在各个 BE 节点的数据的同时生效。&lt;br/&gt;3.在 FE 协调好之后，由 FE 统一下发 Publish 任务使导入的 Rowset 版本生效。任务中指定了发布的生效 version 版本信息。之后 BE 存储层才会将这个版本的 Rowset 设置为可见。&lt;br/&gt;4.Rowset 加入到 BE 存储层的 Tablet 进行管理。&lt;/p&gt;&lt;h4&gt;删除流程&lt;/h4&gt;&lt;p&gt;目前 Delete 有两种实现，一种普通的删除类型为 DELETE，一种为 LOAD_DELETE。&lt;/p&gt;&lt;h4&gt;DELETE 执行流程&lt;/h4&gt;&lt;p&gt;DELETE 的支持一般的删除操作，实现较为简单，DELETE 模式下没有对数据进行实际删除操作，而是对数据删除条件进行了记录。存储在 Meta 信息中。当执行 Base Compaction 时删除条件会一起被合入到 Base 版本中。Base 版本为 Tablet 从[0-x]的第一个 Rowset 数据版本。具体流程如下：&lt;/p&gt;&lt;p&gt;1.删除时由 FE 直接下发删除命令和删除条件。&lt;br/&gt;2.BE 在本地启动一个 EngineBatchLoadTask 任务，生成新版本的 Rowset，并记录删除条件信息。这个删除记录的 Rowset 与写入过程的略有不同，该 Rowset 仅记录了删除条件信息，没有实际的数据。&lt;br/&gt;3.FE 同样发布生效版本。其中会将 Rowset 加入到 Tablet 中，保存 TabletMeta 信息。&lt;/p&gt;&lt;h4&gt;LOAD_DELETE 执行流程&lt;/h4&gt;&lt;p&gt;LOAD_DELETE 支持了在 UNIQUE KEY 模型下，实现了通过批量导入要删除的 key 对数据进行删除，能够支持大量数据删除能力。整体思路是在数据记录中加入删除状态标识，在 Compaction 流程中会对删除的 key 进行压缩。&lt;/p&gt;&lt;h3&gt;数据模型和物化视图&lt;/h3&gt;&lt;h4&gt;聚合模型&lt;/h4&gt;&lt;p&gt;聚合模型的特点就是将表中的列分为了 Key 和 Value 两种。 Key 就是数据的维度列，比如时间，地区等等。Value 则是数据的指标列，比如点击量，花费等。每个指标列还会有自己的聚合函数，包括 sum、min、max 和 bitmap_union 等。数据会根据维度列进行分组，并对指标列进行聚合。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CG6eeTltVZ6ibkw8IpNZGGGYricICD2s2jwclKnkbibbrsj1vYzkJHgxQYw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;&lt;p&gt;首先是导入数据 ，原始数据在导入过程中，会根据表结构中的 Key 进行分组，相同 Key 的 Value 会根据表中定义的 Aggregation Function 进行聚合。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGUVO49qNKk0B6CGgDEp0TNNtq7ibbaNNQwhLFGkSS2E61Uic12cznUsaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;&lt;p&gt;由于 Doris 采用的是 MVCC 机制进行的并发控制，所以每一次新的导入都是一个新的版本。我们把这种版本称为 Singleton 。&lt;/p&gt;&lt;p&gt;不断的导入新的数据后，尽管同一批次的数据在导入过程中已经发生了聚合，但不同版本之间的数据依旧存在维度列相同但是指标列并没有被聚合的情况。这时候就需要通过 Compaction 机制进行二次聚合。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGhHuCic9jR3CRsUG5iaoMjClL2OdDyal1rJ0iapvKBm2HRlib42TKuSKiarA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5625&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Compaction&lt;/strong&gt; 的意思其实就是将不同版本的数据进行合并。它 分为两个阶段，第一个阶段是： 当 Singleton 的数据版本个数到达 Doris 设置的阈值时，就会触发 Cumulative 级别的 Compaction。 这个级别的 Compaction 会将一个区间段内的版本数据根据定义好的聚合函数进行再聚合。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGickZenugBe0IfeEu7KUZKa6Ly5GIYwLGYF2dgklBVztyHCp94zZAeog/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5625&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;&lt;p&gt;说完聚合模型，再介绍一种聚合模型上的 提升查询效率 的方式—— 构建 Rollup&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGWZzeFHmXDeNATSYhKXQvtGhichtk5SibzBOcqkAdMhMEFx8Fkl6nCbDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;&lt;p&gt;Rollup 也就是上卷，是一种在多维分析中比较常用的操作——也就是从细粒度的数据向高层的聚合。&lt;/p&gt;&lt;p&gt;在 Doris 中，我们提供了在聚合模型上的构建 Rollup 功能，将数据根据更少的维度进行预聚合。将本身在用户查询时才会进行聚合计算的数据预先计算好，并存储在 Doris 中，从而达到提升用户粗粒度上的查询效率。&lt;/p&gt;&lt;p&gt;Rollup 还有一点好处在于，由于 Doris 具有在原始数据上实时计算的能力，因此不需要对所有维度的每个组合都创建 Rollup。尤其是在维度很多的情况下，可以取得一个存储空间和查询效率之间的平衡。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGJmcoWTLHKic7bsgFC0ib3C7ytFsK05Emv8OlMdvM8MXv7rnUUN5D7xRA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5625&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;&lt;p&gt;在创建 Rollup 的时候首先你需要有一个聚合模型的 Base 表，然后就可以取部分维度创建一个 Rollup 表。&lt;/p&gt;&lt;p&gt;聚合模型的优点就在于：划分维护和指标列后，数据本身已经进行过预聚合，对于分析型查询效率提升明显。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;但是聚合模型在某些用户场景下并不适用：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;很多业务并没有聚合的需求，就是要存储原始的用户行为日志。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;一些业务在初期还不能确认哪些是维度列，哪些是指标列&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;聚合模型本身更难理解，对新用户体验不好，比如一些查询结果和用户预期的不一致。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基于以上问题，我们增加了对明细数据模型的支持。&lt;/p&gt;&lt;h4&gt;明细模型&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGkHssFFjqcNtCWlRiaEXa4SrVss6DibRVEVGrhboMqZRNRoPyjCxEnHbg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5625&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;&lt;p&gt;明细数据模型刚好和聚合模型相反，不区分维护和指标列，并不对导入的数据做任何聚合，每条原始数据都会保留在表中。&lt;/p&gt;&lt;p&gt;明细模型就像 Mysql 中的表一样，优势就在于你可以详细追溯每个用户行为或订单详情。但劣势也很明显，分析型的查询效率不高。&lt;/p&gt;&lt;h4&gt;Doris 的物化视图&lt;/h4&gt;&lt;p&gt;物化视图的出现主要是为了满足用户，既能对原始明细数据的任意维度分析，也能快速的对固定维度进行分析查询的需求。&lt;/p&gt;&lt;p&gt;首先，什么是物化视图？&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGQ9cG97RZwdiah86PXMrxKLQpxB0E4cD7kOPficXG526FtfUZDUL6f6oQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;&lt;p&gt;从定义上来说，就是包含了查询结果的数据库对象，可能是对远程数据的本地 Copy；也可能是一个表或多表 Join 后结果的行或列的子集；也可能是聚合后的结果。说白了，就是预先存储查询结果的一种数据库对象。&lt;/p&gt;&lt;p&gt;在 Doris 中的物化视图，就是查询结果预先存储起来的特殊的表。&lt;/p&gt;&lt;p&gt;它的优势在于：&lt;br/&gt;1.对于那些经常重复的使用相同的子查询结果的查询性能大幅提升&lt;br/&gt;2.Doris 自动更新物化视图的数据，保证 Base 表和物化视图表的数据一致性。无需额外的维护成本&lt;br/&gt;3.查询的时候也可以自动匹配最优的物化视图&lt;/p&gt;&lt;h4&gt;物化视图&lt;/h4&gt;&lt;p&gt;目前支持的聚合函数包括常用的 sum、min、max、count 以及 pv、uv， 留存率等计算时常用的去重算法 hll_union，和用于精确去重计算 count(distinct) 的算法 bitmap_union。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGfHN7vok3wKypWaXiczahsOZ1gKWq4sjBV08Fb5oQVWUaNPeic8COeAJg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5625&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;&lt;p&gt;使用物化视图功能后，由于物化视图实际上是损失了部分维度数据的。所以对表的 DML 类型操作会有一些限制。&lt;/p&gt;&lt;p&gt;使用物化视图功能后，由于物化视图实际上是损失了部分维度数据的。所以对表的 DML 类型操作会有一些限制。&lt;/p&gt;&lt;p&gt;对于物化视图和 Rollup 来说，他们的共同点都是 通过预聚合 的方式来提升查询效率。 实际上物化视图是 Rollup 的一个超集，在覆盖 Rollup 的工作同时，还支持更灵活的聚合方式。&lt;/p&gt;&lt;p&gt;因此，如果对数据的分析需求既 覆盖了明细查询也存在分析类查询 ，则可以先创建一个明细模型的表，并构建物化视图。&lt;/p&gt;&lt;h2&gt;Doris SQL 原理解析&lt;/h2&gt;&lt;p&gt;SQL解析在下文中指的是将一条sql语句经过一系列的解析最后生成一个完整的物理执行计划的过程。&lt;/p&gt;&lt;p&gt;这个过程包括以下四个步骤：词法分析，语法分析，生成逻辑计划，生成物理计划。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGUH79zZaj4icEzUW9j0lwyfgNLNVvvL5JKRJXTwElF9HlbFrNau7WgZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.412962962962963&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h4&gt;设计目标&lt;/h4&gt;&lt;p&gt;Doris SQL解析架构的设计有以下目标：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;最大化计算的并行性&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最小化数据的网络传输&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;最大化减少需要扫描的数据&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;总体架构&lt;/h4&gt;&lt;p&gt;Doris SQL解析具体包括了五个步骤：词法分析，语法分析，生成单机逻辑计划，生成分布式逻辑计划，生成物理执行计划。&lt;/p&gt;&lt;p&gt;具体代码实现上包含以下五个步骤：Parse, Analyze, SinglePlan, DistributedPlan, Schedule。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CG4WbtsVLMGnaZnySAmhPDT0JlibQr8TqnCqkWjffaiawKNuh6s6dibiaONg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;1.5574074074074074&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;下文侧重介绍查询SQL的解析。&lt;/p&gt;&lt;p&gt;下图展示了一个简单的查询SQL在Doris的解析实现。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGRsicQUDIib1mgrZxUZboUZ2dbt1L0rib0zDOpufrVZl7EKZO020m58BWw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;1.2444444444444445&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h4&gt;Parse阶段&lt;/h4&gt;&lt;p&gt;词法分析采用jflex技术，语法分析采用java cup parser技术，最后生成抽象语法树（Abstract Syntax Tree）AST，这些都是现有的、成熟的技术，在这里不进行详细介绍。&lt;/p&gt;&lt;p&gt;AST是一种树状结构，代表着一条SQL。不同类型的查询select, insert, show, set, alter table, create table等经过Parse阶段后生成不同的数据结构（SelectStmt, InsertStmt, ShowStmt, SetStmt, AlterStmt, AlterTableStmt, CreateTableStmt等），但他们都继承自Statement，并根据自己的语法规则进行一些特定的处理。例如：对于select类型的sql， Parse之后生成了SelectStmt结构。&lt;/p&gt;&lt;p&gt;SelectStmt结构包含了SelectList，FromClause，WhereClause，GroupByClause，SortInfo等结构。这些结构又包含了更基础的一些数据结构，如WhereClause包含了BetweenPredicate（between表达式）, BinaryPredicate（二元表达式）， CompoundPredicate（and or组合表达式）, InPredicate（in表达式）等。&lt;/p&gt;&lt;h4&gt;Analyze阶段&lt;/h4&gt;&lt;p&gt;抽象语法树是由StatementBase这个抽象类表示。这个抽象类包含一个最重要的成员函数analyze()，用来执行Analyze阶段要做的事。&lt;/p&gt;&lt;p&gt;不同类型的查询select, insert, show, set, alter table, create table等经过Parse阶段后生成不同的数据结构（SelectStmt, InsertStmt, ShowStmt, SetStmt, AlterStmt, AlterTableStmt, CreateTableStmt等），这些数据结构继承自StatementBase，并实现analyze()函数，对特定类型的SQL进行特定的Analyze。&lt;/p&gt;&lt;p&gt;例如：select类型的查询，会转成对select sql的子语句SelectList, FromClause, GroupByClause, HavingClause, WhereClause, SortInfo等的analyze()。然后这些子语句再各自对自己的子结构进行进一步的analyze()，通过层层迭代，把各种类型的sql的各种情景都分析完毕。例如：WhereClause进一步分析其包含的BetweenPredicate（between表达式）, BinaryPredicate（二元表达式）， CompoundPredicate（and or组合表达式）, InPredicate（in表达式）等。&lt;/p&gt;&lt;h4&gt;生成单机逻辑Plan阶段&lt;/h4&gt;&lt;p&gt;这部分工作主要是根据AST抽象语法树生成代数关系，也就是俗称的算子数。树上的每个节点都是一个算子，代表着一种操作。&lt;/p&gt;&lt;p&gt;ScanNode代表着对一个表的扫描操作，将一个表的数据读出来。HashJoinNode代表着join操作，小表在内存中构建哈希表，遍历大表找到连接键相同的值。Project表示投影操作，代表着最后需要输出的列，图片表示只用输出citycode这一列。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGP5IYWHQGmIOdT2ZeH8auekRricKiaTVo1PLuPIkhWqs1BoiaXTTzsjaNA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5027777777777778&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h4&gt;生成分布式Plan阶段&lt;/h4&gt;&lt;p&gt;有了单机的PlanNode树之后，就需要进一步根据分布式环境，拆成分布式PlanFragment树（PlanFragment用来表示独立的执行单元），毕竟一个表的数据分散地存储在多台主机上，完全可以让一些计算并行起来。&lt;/p&gt;&lt;p&gt;这个步骤的主要目标是最大化并行度和数据本地化。主要方法是将能够并行执行的节点拆分出去单独建立一个PlanFragment，用ExchangeNode代替被拆分出去的节点，用来接收数据。拆分出去的节点增加一个DataSinkNode，用来将计算之后的数据传送到ExchangeNode中，做进一步的处理。&lt;/p&gt;&lt;p&gt;这一步采用递归的方法，自底向上，遍历整个PlanNode树，然后给树上的每个叶子节点创建一个PlanFragment，如果碰到父节点，则考虑将其中能够并行执行的子节点拆分出去，父节点和保留下来的子节点组成一个parent PlanFragment。拆分出去的子节点增加一个父节点DataSinkNode组成一个child PlanFragment，child PlanFragment指向parent PlanFragment。这样就确定了数据的流动方向。&lt;/p&gt;&lt;h4&gt;Schedule阶段&lt;/h4&gt;&lt;p&gt;这一步是根据分布式逻辑计划，创建分布式物理计划。主要解决以下问题：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;哪个 BE 执行哪个 PlanFragment&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;每个 Tablet 选择哪个副本去查询&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如何进行多实例并发&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;h2&gt;实践&lt;/h2&gt;&lt;h3&gt;Apache Doris 基于 Bitmap 的精确去重和用户行为分析&lt;/h3&gt;&lt;h4&gt;How Doris Count Distinct without Bitmap&lt;/h4&gt;&lt;p&gt;Doris 除了支持 HLL 近似去重，也是支持 Runtime 现场精确去重的。实现方法和 Spark，MR 类似。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGe3GNF6WcibK55OlBkx5c9ia970nuDn759TjgtW5h3tojam1rp16YEXPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.4756944444444444&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;p&gt;对于上图计算 PV 的 SQL，Doris 在计算时，会按照下图进行计算，先根据 page 列和 user_id 列 group by,最后再 count。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGLfaUE9gWtgCDurqicxg8Dd7ZyEpJdJVWANvu5y4oYEicrNxO2Mh1K7xQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.47800925925925924&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;p&gt;显然，上面的计算方式，当数据量越来越大，到几十亿，几百亿时，使用的 IO 资源，CPU 资源，内存资源，网络资源就会越来越多，查询也会越来越慢。&lt;/p&gt;&lt;p&gt;那么，下面一个自然而然的问题就是，应该如何让 Doris 的精确去重查询性能更快呢？&lt;/p&gt;&lt;h4&gt;How To Make Count Distinct More Faster&lt;/h4&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;堆机器&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Cache&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;优化 CPU 执行引擎 (向量化，SIMD，查询编译等)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;支持 GPU 执行引擎&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;预计算&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;How Doris Count Distinct With Bitmap&lt;/h4&gt;&lt;p&gt;要在 Doris 中预计算，自然要用到 Doris 的聚合模型，下面简单看下 Doris 中的聚合模型：&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5243055555555556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGib6ELqCib9DDU19iatFaFJgmX2lhVGmaMJhVdpd7MUUr9XsfzIK7soia0w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;p&gt;Doris 的聚合模型分为 Key 列和 Value 列，Key 列就是维度列，Value 列是指标列，Key 列全局有序，每个 Value 列会有对应的聚合函数，相同 Key 列的 Value 会根据对应的聚合函数进行聚合。上图中，Year，City 是 Key 列，Cost 是 Value 列，Cost 对应的聚合函数式 Sum。Doris 支持根据不同维度组合建立不同的 Rollup 表，并能在查询时自动路由。&lt;/p&gt;&lt;p&gt;所以要在 Doris 中实现 Count Distinct 的预计算，就是实现一种 Count Distinct 的聚合指标。那么可以像 Sum,Min,Max 聚合指标一样直接实现一种 Count Distinct 聚合指标吗?&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CG1d6NRXwIvSwRpbKia91wmLD0BFy0lR7Z2r5zBXKsULrCLyiaFyJWKB8A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.5439814814814815&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;p&gt;Doris 中聚合指标必须支持上卷。 但如果只保留每个 City 的 User 的去重值，就没办法上卷聚合出只有 Year 为维度的时候 User 的去重值，因为去重值不能直接相加，已经把明细丢失了，不知道在 2016 或 2017 年，北京和上海不重合的 User 有多少。&lt;/p&gt;&lt;p&gt;所以去重指标要支持上卷聚合，就必须保留明细，不能只保留一个最终的去重值。而计算机保留信息的最小单位是一个 bit，所以很自然的想到用 Bitmap 来保留去重指标的明细数据。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGDRGtPAZMz1H1owD2RDG9jHGu0h8kAApGybWVWIFqiaKiacmahJ5AfmDw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.5034722222222222&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;p&gt;Roaring Bitmap 的核心思路很简单，就是根据数据的不同特征采用不同的存储或压缩方式。 为了实现这一点，Roaring Bitmap 首先进行了分桶，将整个 int 域拆成了 2 的 16 次方 65536 个桶，每个桶最多包含 65536 个元素。&lt;/p&gt;&lt;p&gt;所以一个 int 的高 16 位决定了，它位于哪个桶，桶里只存储低 16 位。以图中的例子来说，62 的前 1000 个倍数，高 16 位都是 0，所以都在第一个桶里。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGNgibhgUlsic4e8UDP5EzdicvjmgxspgDWoQLvLTPaEhRgBgoIf0ZDPmcQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.5868055555555556&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;p&gt;然后在桶粒度针对不同的数据特点，采用不同的存储或压缩方式：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGkatArxnHehES6bPIPdKkZeBMeB8DXiaxiaLzZdbROu0iaQnEmN4uial2gQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.5254629629629629&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;p&gt;默认会采用 16 位的 Short 数组来存储低 16 位数据，当元素个数超过 4096 时，会采用 Bitmap 来存储数据。&lt;/p&gt;&lt;p&gt;第 3 类 Run Container 是优化连续的数据， Run 指的是 Run Length Encoding（RLE）&lt;/p&gt;&lt;p&gt;在做字典映射时，使用比较广泛的数据结构是 Trie 树。&lt;/p&gt;&lt;p&gt;Trie 树的问题是字典对应的编码值是基于节点位置决定的，所以 Trie 树是不可变的。这样没办法用来实现全局字典，因为要做全局字典必然要支持追加。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGJqRcOwSpVUEGtvbRwico1D85ic3IKoTIdIfficbV0HAOAYrcGkvbt35Hw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.5196759259259259&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;p&gt;如何让同一个 String 永远映射到同一个 ID。一个简单的思路是把 String 对应的 ID 直接序列化下来，因为全局字典只需要支持 String 到 ID 的单向查找，不需要支持 ID 到 String 的反向查找。&lt;/p&gt;&lt;p&gt;当全局字典越来越大的时候，就会面临内存不足的问题。一个自然的想法就是 Split。当全局字典拆成多个子树之后，必然会涉及到每个子树的按需加载和删除，这个功能是使用 Guava 的 LoadingCache 实现的。&lt;/p&gt;&lt;p&gt;为了解决读写冲突的问题，实现了 MVCC，使得读写可以同时进行。全局字典目前是存储在 HDFS 上的，一个全局字典目录下会有多个 Version，读的时候永远读取最新 Version 的数据，写的时候会先写到临时目录，完成后再拷贝到最新的 Version 目录。同时为了保证全局字典的串行更新，引入分布式锁。&lt;/p&gt;&lt;p&gt;目前基于 Trie 树的全局字典存在的一个问题是，全局字典的编码过程是串行的，没有分布式化，所以当全局字典的基数到几十亿规模时，编码过程就会很慢。一个可行的思路是，类似 Roaring Bitmap，可以将整个 Int 域进行分桶，每个桶对应固定范围的 ID 编码值，每个 String 通过 Hash 决定它会落到哪个桶内，这样全局字典的编码过程就可以并发。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGOBfAzvDrSwiaGXjRyKQA84hT82S967yIwe5XsJYsjxmUjAicDmmzibs1g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.5648148148148148&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;p&gt;正是由于目前基于 Trie 树的全局字典 无法分布式构建，滴滴的同学引入了基于 Hive 表的全局字典。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGq2iauTLV2gCRCNerViaMsp7YwibCIDurrQhuYnsdlhRqy1IckJxib97saw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.5127314814814815&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;p&gt;这种方案中全局字典本身是一张 Hive 表，Hive 表有两个列，一个是原始值，一个是编码的 Int 值，然后通过上面的 4 步就可以通过 Spark 或者 MR 实现全局字典的更新，和对事实表中 Value 列的替换。&lt;/p&gt;&lt;p&gt;基于 Hive 表的全局字典相比基于 Trie 树的全局字典的优点除了可以分布式化，还可以实现全局字典的复用。但是缺点也是显而易见，相比基于 Trie 树的全局字典，会使用多几倍的资源，因为原始事实表会被读取多次，而且还有两次 Join。&lt;/p&gt;&lt;h4&gt;How to Use Doris Bitmap&lt;/h4&gt;&lt;p&gt;Create Table （为了有更好的加速效果，最好建下 ROLLUP）&lt;/p&gt;&lt;pre&gt;&lt;code&gt;CREATE TABLE `pv_bitmap` (&lt;br/&gt;&lt;br/&gt;`dt` int,&lt;br/&gt;&lt;br/&gt;`page` varchar(10),&lt;br/&gt;&lt;br/&gt;`user_id` bitmap bitmap_union&lt;br/&gt;&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;AGGREGATE KEY(`dt`, page)&lt;br/&gt;&lt;br/&gt;DISTRIBUTED BY HASH(`dt`) BUCKETS 2;&lt;br/&gt;&lt;br/&gt;ALTER TABLE pv_bitmap ADD ROLLUP pv (page, user_id);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Load Data&lt;/p&gt;&lt;pre&gt;&lt;code&gt;cat data | curl --location-trusted -u user:passwd -T -&lt;br/&gt;&lt;br/&gt;-H &quot;columns: dt,page,user_id, user_id=$BITMAP_LOAD_FUNCTION(user_id)&quot;&lt;br/&gt;&lt;br/&gt;http://host:8410/api/test/pv_bitmap/_stream_load&lt;br/&gt;&lt;br/&gt;TO_BITMAP(expr) : 将 0 ~ 4294967295 的 unsigned int 转为 bitmap&lt;br/&gt;&lt;br/&gt;BITMAP_HASH(expr): 将任意类型的列通过 Hash 的方式转为 bitmap&lt;br/&gt;&lt;br/&gt;BITMAP_EMPTY(): 生成空 bitmap，用于 insert 或导入的时填充默认值&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Query&lt;/p&gt;&lt;pre&gt;&lt;code&gt;select bitmap_count(bitmap_union(user_id)) from pv_bitmap;                                select bitmap_union_count(user_id) from pv_bitmap;                                select bitmap_union_int(id) from pv_bitmap;&lt;br/&gt;&lt;br/&gt;BITMAP_UNION(expr) : 计算两个 Bitmap 的并集，返回值是序列化后的 Bitmap 值&lt;br/&gt;&lt;br/&gt;BITMAP_COUNT(expr) : 计算 Bitmap 的基数值&lt;br/&gt;&lt;br/&gt;BITMAP_UNION_COUNT(expr): 和 BITMAP_COUNT(BITMAP_UNION(expr)) 等价&lt;br/&gt;&lt;br/&gt;BITMAP_UNION_INT(expr) : 和 COUNT(DISTINCT expr) 等价(仅支持TINYINT,SMALLINT 和 INT)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Insert Into （ 可以加速无需上卷的精确去重查询场景 ）&lt;/p&gt;&lt;pre&gt;&lt;code&gt;insert into bitmaptable1 (id, id2) VALUES (1001, tobitmap(1000)), (1001, to_bitmap(2000));&lt;br/&gt;&lt;br/&gt;insert into bitmaptable1 select id, bitmapunion(id2) from bitmap_table2 group by id;&lt;br/&gt;&lt;br/&gt;insert into bitmaptable1 select id, bitmaphash(id_string) from table;&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;基于 Bitmap 的用户行为分析&lt;/h4&gt;&lt;p&gt;用户行为分析从字面意思上讲，就是分析用户的行为。分析用户的哪些行为呢？可以简单用 5W2H 来总结。即 Who(谁)、What(做了什么行为)、When(什么时间)、Where(在哪里)、Why(目的是什么)、How(通过什么方式)，How much (用了多长时间、花了多少钱)。&lt;/p&gt;&lt;p&gt;其终极目的就是为了不断优化产品，提升用户体验，让用户花更多的时间，花更多的钱在自己的产品上。&lt;/p&gt;&lt;p&gt;目前用户行为分析的解法大概有这么几种：&lt;/p&gt;&lt;p&gt;第一种就数据库的 Join 解法，一般效率是比较低的。我们在 Doris 中是可以用这种思路实现的。&lt;br/&gt;第二种是基于明细数据的，UDAF 实现。Doris 也是支持的。&lt;br/&gt;第三种是基于 Bitmap 的 UDAF 实现的，也就是今天要分享的。&lt;br/&gt;第四种是用专用的系统来做用户行为分析，专用系统的好处是可以针对特定场景，做更多的优化。&lt;/p&gt;&lt;h4&gt;Doris Intersect_count&lt;/h4&gt;&lt;p&gt;现在已经在 Doris 的聚合模型中支持了 Bitmap，所以可以基于 Bitmap 实现各类 UDF, UDAF，来实现大多数用户行为分析。&lt;/p&gt;&lt;h4&gt;Intersect_count 计算留存&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;select intersect_count(user_id, dt, &#x27;20191111&#x27;) as first_day,&lt;br/&gt;&lt;br/&gt;intersect_count(user_id, dt, &#x27;20191112&#x27;) as second_day,&lt;br/&gt;&lt;br/&gt;intersect_count(user_id, dt, &#x27;20191111&#x27;, &#x27;20191112&#x27;) as retention,&lt;br/&gt;&lt;br/&gt;from table&lt;br/&gt;&lt;br/&gt;where dt in (&#x27;20191111&#x27;, &#x27;20191112&#x27;)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;假如有 user_id 和 page 的信息，我们希望知道在访问美团页面之后，又有多少用户访问了外卖页面，也可以用 intersect_count 来进行计算。&lt;/p&gt;&lt;h4&gt;Intersect_count 筛选特定用户&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;select&lt;br/&gt;&lt;br/&gt;intersect_count(user_id, tag_value, &#x27;男&#x27;, &#x27;90后&#x27;, &#x27;10-20万&#x27;)&lt;br/&gt;&lt;br/&gt;from user_profile&lt;br/&gt;&lt;br/&gt;where (tag_type=&#x27;性别&#x27; and tag_value=&#x27;男&#x27;)&lt;br/&gt;&lt;br/&gt;or (tag_type=&#x27;年龄&#x27; and tag_value=&#x27;90后&#x27;)&lt;br/&gt;&lt;br/&gt;or (tag_type=&#x27;收入&#x27; and tag_value=&#x27;10-20万&#x27;)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后也可以通过 intersect_count 来进行一些特定用户的筛选。例如原始表里有 user_id，tag_value，tag_type 这些信息，我们想计算年收入 10-20 万的 90 后男性有多少，就可以用这个简单的 SQL 来实现。&lt;/p&gt;&lt;h4&gt;Doris Bitmap ToDo&lt;/h4&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;全局字典进行开源，支持任意类型的精确去重&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;支持 Int64，支持 Int64 后一方面支持更高基数的 bitmap 精确去重，另一方面如果原始数据中有 bigint 类型的数据便不需要全局字典进行编码。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;支持 Array 类型。很多用户行为分析的场景下的 UDAF 或 UDF，用 Array 表达更加方便和规范。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更方便更智能的批量创建 Rollup。当用户基数到达十多亿时，Bitmap 本身会比较大，而且对几十万个 Bitmap 求交的开销也会很大，因此还是需要建立 Rollup 来进行加速查询。更进一步，我们期望可以做到根据用户的查询特点去自动建立 Rollup。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;希望支持更多、更复杂的用户行为分析。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Summary&lt;/h4&gt;&lt;p&gt;如果应用基数在百万、千万量级，并拥有几十台机器，那么直接选择 count distinct 即可；&lt;/p&gt;&lt;p&gt;如果希望进行用户行为分析，可以考虑 IntersectCount 或者自定义 UDAF。&lt;/p&gt;&lt;p&gt;Reference&lt;/p&gt;&lt;h3&gt;Apache Doris 在美团外卖数仓中的应用实践&lt;/h3&gt;&lt;h4&gt;外卖运营业务特点&lt;/h4&gt;&lt;p&gt;外卖业务为大家提供送餐服务，连接商家与用户，这是一个劳动密集型的业务，外卖业务有上万人的运营团队来服务全国几百万的商家，并以“商圈”为单元，服务于“商圈”内的商家。“商圈”及其上层组织机构是一个变化维度，当“商圈”边界发生变化时，就导致在往常日增量的业务生产方式中，历史数据的回溯失去了参考意义。在所有展现组织机构数据的业务场景中，组织机构的变化是一个绕不开的技术问题。此外，商家品类、类型等其它维度也存在变化维的问题。如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGOM8d4IpHDic6osicYExzIgibMbJedq1WDjyPIyfficYibDTCvgaegYYYCaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.17669172932330826&quot; data-w=&quot;1064&quot;/&gt;&lt;/p&gt;&lt;h4&gt;数据生产面临的挑战&lt;/h4&gt;&lt;p&gt;数据爆炸，每日使用最新维度对历史数据进行回溯计算。在 Kylin 的 MOLAP 模式下存在如下问题：&lt;/p&gt;&lt;h4&gt;解决方案：引入 MPP 引擎，数据现用现算&lt;/h4&gt;&lt;p&gt;既然变化维的历史数据预计算成本巨大，最好的办法就是现用现算，但现用现算需要强大的并行计算能力。OLAP 的实现有 MOLAP、ROLAP、HOLAP 三种形式。长期以来，由于传统关系型 DBMS 的数据处理能力有限，所以 ROLAP 模式受到很大的局限性。随着分布式、并行化技术成熟应用，MPP 引擎逐渐表现出强大的高吞吐、低时延计算能力，号称“亿级秒开”的引擎不在少数，ROLAP 模式可以得到更好的延伸。例如：日数据量的 ROLAP 现场计算，周、月趋势的计算，以及明细数据的浏览都可以较好的应对。&lt;/p&gt;&lt;p&gt;下图是 MOLAP 模式与 ROLAP 模式下应用方案的比较：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGibRjBYYbiamspl3GcnksFZ7vZUpc8QUrMfgWzmxWVibSxYAe7YJTzfqLw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5435185185185185&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;MOLAP 模式的劣势&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;应用层模型复杂，根据业务需要以及 Kylin 生产需要，还要做较多模型预处理。这样在不同的业务场景中，模型的利用率也比较低。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Kylin 配置过程繁琐，需要配置模型设计，并配合适当的“剪枝”策略，以实现计算成本与查询效率的平衡。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;由于 MOLAP 不支持明细数据的查询，在“汇总+明细”的应用场景中，明细数据需要同步到 DBMS 引擎来响应交互，增加了生产的运维成本。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;较多的预处理伴随着较高的生产成本。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;ROLAP 模式的优势&lt;/p&gt;&lt;p&gt;综上所述，在变化维、非预设维、细粒度统计的应用场景下，使用 MPP 引擎驱动的 ROLAP 模式，可以简化模型设计，减少预计算的代价，并通过强大的实时计算能力，可以支撑良好的实时交互体验。&lt;/p&gt;&lt;h3&gt;Doris 引擎在美团的重要改进&lt;/h3&gt;&lt;h4&gt;Join 谓词下推的传递性优化&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGia4DicJt0PB8xgyKicvJicm9icbQnrgzSX8H6xLTQibaKBZoz3KZM1picdadQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.4848837209302326&quot; data-w=&quot;860&quot;/&gt;&lt;/p&gt;&lt;p&gt;如上图所示，对于下面的 SQL：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;select * from t1 join t2 on t1.id = t2.id where t1.id = 1&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Doris 开源版本默认会对 t2 表进行全表 Scan，这样会导致上面的查询超时，进而导致外卖业务在 Doris 上的第一批应用无法上线。&lt;/p&gt;&lt;p&gt;于是在 Doris 中实现了第一个优化：Join 谓词下推的传递性优化（MySQL 和 TiDB 中称之为 Constant Propagation）。Join 谓词下推的传递性优化是指：基于谓词 t1.id = t2.id 和 t1.id = 1, 可以推断出新的谓词 t2.id = 1，并将谓词 t2.id = 1 下推到 t2 的 Scan 节点。这样假如 t2 表有数百个分区的话，查询性能就会有数十倍甚至上百倍的提升，因为 t2 表参与 Scan 和 Join 的数据量会显著减少。&lt;/p&gt;&lt;h4&gt;查询执行多实例并发优化&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGmWdd6HcMwIOyQmCau0ibmuQU3sbNWDiaszn5vaw9XemP7noGM0LtDozg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.7132132132132132&quot; data-w=&quot;666&quot;/&gt;&lt;/p&gt;&lt;p&gt;如上图所示，Doris 默认在每个节点上为每个算子只会生成 1 个执行实例。这样的话，如果数据量很大，每个执行实例的算子就需要处理大量的数据，而且无法充分利用集群的 CPU、IO、内存等资源。&lt;/p&gt;&lt;p&gt;一个比较容易想到的优化手段是，可以在每个节点上为每个算子生成多个执行实例。这样每个算子只需要处理少量数据，而且多个执行实例可以并行执行。&lt;/p&gt;&lt;p&gt;下图是并发度设置为 5 的优化效果，可以看到对于多种类型的查询，会有 3 到 5 倍的查询性能提升：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGSAXgMlNrgha6ibiaE4je78ZOVZ9Dyr2qV8WYqiaDRwLj9lPnXoTFDms2g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.583743842364532&quot; data-w=&quot;812&quot;/&gt;&lt;/p&gt;&lt;h4&gt;Colocate Join&lt;/h4&gt;&lt;p&gt;Colocate Join（Local Join）是和 Shuffle Join、Broadcast Join 相对的概念，即将两表的数据提前按照 Join Key Shard，这样在 Join 执行时就没有数据网络传输的开销，两表可以直接在本地进行 Join。&lt;/p&gt;&lt;p&gt;整个 Colocate Join 在 Doris 中实现的关键点如下：&lt;/p&gt;&lt;p&gt;对于下面的 SQL，Doris Colocate Join 和 Shuffle Join 在不同数据量下的性能对比如下：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;select count(*) FROM A t1 INNER JOIN [shuffle] B t5    ON ((t1.dt = t5.dt) AND (t1.id = t5.id)) INNER JOIN [shuffle] C t6    ON ((t1.dt = t6.dt) AND (t1.id = t6.id)) where t1.dt in (xxx days);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGDDPUfFDo3UPSSN4tgPbszTSstNt5fbj8FXicNWAgzS7WiafHSsRYjBXw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.49074074074074076&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;Bitmap 精确去重&lt;/p&gt;&lt;p&gt;Doris 之前实现精确去重的方式是现场计算的，实现方法和 Spark、MapReduce 类似：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGnvaSaVq20Gqy15hTQmkCvgHLxFZricaNic97SMlTMpeCgKdopSugSLeg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.48518518518518516&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;对于上图计算 PV 的 SQL，Doris 在计算时，会按照下图的方式进行计算，先根据 page 列和 user_id 列 group by，最后再 Count：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGdq7mH4lbTzhR4GDsCRmzAXcuHBI2NbbT6NtZibGLDbOXcNm2laDYJRA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.47962962962962963&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;显然，上面的计算方式，当数据量越来越大，到几十亿几百亿时，使用的 IO 资源、CPU 资源、内存资源、网络资源会变得越来越多，查询也会变得越来越慢。&lt;/p&gt;&lt;p&gt;于是在 Doris 中新增了一种 Bitmap 聚合指标，数据导入时，相同维度列的数据会使用 Bitmap 聚合。有了 Bitmap 后，Doris 中计算精确去重的方式如下：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGx5b8Aiad0GfquFwGQ2aUXY5RJicwa9gub9GV7mHwk9eCoCia24NKQUo6g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5092592592592593&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;可以看到，当使用 Bitmap 之后，之前的 PV 计算过程会大幅简化，现场查询时的 IO、CPU、内存，网络资源也会显著减少，并且不再会随着数据规模而线性增加。&lt;/p&gt;&lt;h4&gt;总结与思考&lt;/h4&gt;&lt;p&gt;实践证明，以 Doris 引擎为驱动的 ROLAP 模式可以较好地处理汇总与明细、变化维的历史回溯、非预设维的灵活应用、准实时的批处理等场景。而以 Kylin 为基础的 MOLAP 模式在处理增量业务分析，固化维度场景，通过预计算以空间换时间方面依然重要。&lt;/p&gt;&lt;p&gt;业务方面，通过外卖数仓 Doris 的成功实践以及跨事业群的交流，美团已经有更多的团队了解并尝试使用了 Doris 方案。而且在平台同学的共同努力下，引擎性能还有较大提升空间，相信以 Doris 引擎为驱动的 ROLAP 模式会为美团的业务团队带来更大的收益。从目前实践效果看，其完全有替代 Kylin、Druid、ES 等引擎的趋势。&lt;/p&gt;&lt;p&gt;目前，数据库技术进步飞速，近期柏睿数据发布全内存分布式数据库 RapidsDB v4.0 支持 TB 级毫秒响应（处理千亿数据可实现毫秒级响应）。可以预见，数据库技术的进步将大大改善数仓的分层管理与应用支撑效率，业务将变得“定义即可见”，也将极大地提升数据的价值。&lt;/p&gt;&lt;h3&gt;Apache Doris 在京东广告的应用实践&lt;/h3&gt;&lt;h4&gt;原有系统存在的问题&lt;/h4&gt;&lt;p&gt;主要表现以下几个方面：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;原有系统已经逐渐无法满足我们日常业务的性能需求。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;日常业务所需的 Schema Change，Rollup 等操作，在原有系统上有极高的人力成本。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;原有系统的数据无法迁移，扩容需要重刷全部历史数据，运维成本极高。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在“618”和“双 11”的时候，原有系统会成为我们对外服务的一个隐患。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;因此需要一个合适的数据查询引擎来替代原有系统，考虑到团队的人力和研发能力，选择使用开源的 OLAP 引擎来替换原有系统。&lt;/p&gt;&lt;h4&gt;技术选型&lt;/h4&gt;&lt;p&gt;为广告主提供在线报表数据查询服务，因此该 OLAP 查询引擎必须满足：可以支持高并发查询，可以毫秒级返回数据，且可以随着业务的发展水平扩展。此外也承接了越来越多运营和采销同事的多维数据分析的需求，因此希望该 OLAP 引擎也可以支持高吞吐的 Ad-hoc 查询。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGnbeSSe0YuCKVnjcs6EFwfkia3zrHKXJZ1qzAHvzs2uSVnGfyiaib4uJEA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.7530864197530864&quot; data-w=&quot;648&quot;/&gt;&lt;/p&gt;&lt;p&gt;需要同时支持离线（T+1）大规模数据和实时（分钟级间隔）数据的导入，数据导入后即可查询，保证数据导入的实时性和原子性。离线数据（几十 G）的导入任务需要在 1 小时内完成，实时数据（百 M 到几 G）的导入任务需要在 10 分钟内完成。&lt;/p&gt;&lt;p&gt;在“618”这类大促前通常会进行扩容，因此需要新系统扩容方便，无需重刷历史数据来重新分布数据，且扩容后原有机器的数据最好可以很方便地迁移到新机器上，避免造成数据倾斜。&lt;/p&gt;&lt;p&gt;根据日常业务的需要，经常会进行 Schema Change 操作。由于原有系统对这方面的支持很差，希望新系统可以进行 Online Schema Change，且对线上查询无影响。&lt;/p&gt;&lt;p&gt;由于业务的日常变更会对一些表进行数据修复，因此新系统需要支持错误数据的删除，从而无需重刷全部历史数据，避免人力和计算资源的浪费。&lt;/p&gt;&lt;p&gt;目前开源的 OLAP 引擎很多，但由于面临大促的压力，需要尽快完成选型并进行数据迁移，因此只考察比较出名的几个 OLAP 系统：ClickHouse，Druid 和 Doris。&lt;/p&gt;&lt;p&gt;最终选择 Doris 来替换原有系统，主要基于以下几方面的考虑：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Doris 的查询速度是亚秒级的，并且相对 ClickHouse 来说，Doris 对高并发的支持要优秀得多。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Doris 扩容方便，数据可以自动进行负载均衡，解决了原有系统的痛点。ClickHouse 在扩容时需要进行数据重分布，工作量比较大。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Doris 支持 Rollup 和 Online Schema Change，这对日常业务需求十分友好。而且由于支持 MySQL 协议，Doris 可以很好地和之前已有的系统进行融合。而 Druid 对标准 SQL 的支持有限，并且不支持 MySQL 协议，改造成本很高。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;广告场景应用&lt;/h4&gt;&lt;p&gt;经过对系统的改造，目前使用 Doris 作为系统中的一个数据存储层，汇总了离线和实时数据，也为上层查询系统提供统一的效果数据查询接口。如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.7583444592790387&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGPjvJS0uFIVmeCoCMA73Doib0VWMibjDmqZPKlDK4ibp78XfdBuia9ry7BA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;749&quot;/&gt;&lt;/p&gt;&lt;p&gt;日常实时数据主要包含展现/点击跟单数据，DMP 人群包的效果数据以及十几条产品线的点击，展现和消耗数据，导入时间间隔从 1 分钟到 1 小时不等，数据量在百 M 左右的可以秒级导入，数据量在 1G 左右的可以在 1 分钟内完成。离线数据主要包含搜索词的效果数据和各种营销工具的基础数据，大多数都是 T+1 数据，每日新增数据量在 20G-30G，导入耗时在 10-20 分钟。&lt;/p&gt;&lt;p&gt;大多数效果数据报表，广告主的查询维度相对固定且可控，但要求能在毫秒级返回数据，所以必须保证这些查询场景下的性能。Doris 支持的聚合模型可以进行数据的预聚合，将点击，展现，消耗等数据汇总到建表时指定的维度。&lt;/p&gt;&lt;p&gt;此外，Doris 支持建立 Rollup 表（即物化视图）也可以在不同维度上进行预聚合，这种自定义的方式相比 Kylin 的自动构建 cube，有效避免了数据的膨胀，在满足查询时延的要求下，降低了磁盘占用。Doris 还可以通过 Rollup 表对维度列的顺序进行调整，避免了 Kylin 中因过滤维度列在 HBase RowKey 后部而造成的查询性能低下。&lt;/p&gt;&lt;p&gt;对于一些为广告主提供的营销工具，维度和指标通常会有 30~60 列之多，而且大部分查询要求按照所有维度列进行聚合，由于维度列较多，这种查询只能依赖于现场计算能力。目前对于这种类型的查询请求，会将其数据尽量均匀分布到多台 BE 上，利用 Doris MPP 架构的特性，并行计算，并通过控制查询时间范围（一个月），可以使 TP99 达到 3s 左右。&lt;/p&gt;&lt;p&gt;正是由于 Doris 具有自定义的预计算能力和不俗的现场计算能力，简化了日常工作。以为广告主提供的营销工具“行业大盘”为例，如图所示，这种业务场景下，不仅要计算广告主自身的指标数据，还需计算广告主所在类目的指标数据，从而进行对比。&lt;/p&gt;&lt;p&gt;原有系统数据分片只能按照指定列进行散列，没有分布式查询计划，就不能汇总类目维度数据。原先为了解决这种业务场景，虽然底层是同一数据源，但需要建两个表，一个是广告主维度表，一个是类目维度表，维护了两个数据流，增大了工作负担。&lt;/p&gt;&lt;p&gt;使用了 Doris 之后，广告主维度表可以 Rollup 出类目维度表。查询广告主维度数据时可以根据分区分桶（按照时间分区，按照广告主 ID 分桶）确定一个 Tablet，缩小数据查询范围，查询效率很高。查询类目维度时，数据已经按照广告主 ID 进行分片 ，可以充分利用 Doris 现场计算的能力，多个 BE 并行计算，实时计算类目维度数据，在我们的线上环境也能实现秒级查询。这种方案下数据查询更加灵活，无需为了查询性能而维护多个预计算数据，也可以避免多张表之间出现数据不一致的问题。&lt;/p&gt;&lt;h4&gt;实际使用效果&lt;/h4&gt;&lt;p&gt;Doris 支持聚合模型，可以提前聚合好数据，对计算广告效果数据点击，展现和消耗十分适合。对一些数据量较大的高基数表，可以对查询进行分析，建立不同维度或者顺序的的 Rollup 表来满足查询性能的需求。&lt;/p&gt;&lt;p&gt;Doris 支持 Online Schema Change，相比原有系统 Schema Change 需要多个模块联动，耗费多个人力数天才能进行的操作，Doris 只需一条 SQL 且在较短时间内就可以完成。对于日常需求来说，最常见的 Schema Change 操作就是加列，Doris 对于加列操作使用的是 Linked Schema Change 方式，该方式可以无需转换数据，直接完成，新导入的数据按照新的 Schema 进行导入，旧数据可以按照新加列的默认值进行查询，无需重刷历史数据。&lt;/p&gt;&lt;p&gt;Doris 通过 HLL 列和 BITMAP 列支持了近似/精确去重的功能，解决了之前无法计算 UV 的问题。&lt;/p&gt;&lt;p&gt;日常数据修复，相较于以前有了更多的方式可以选择。对于一些不是很敏感的数据，我们可以删除错误数据并进行重新导入；对于一些比较重要的线上数据，我们可以使用 Spark on Doris 计算正确数据和错误数据之间的差值，并导入增量进行修复。这样的好处是，不会暴露一个中间状态给广告主。还有一些业务会对一个或多个月的数据进行重刷。目前在测试使用 Doris 0.12 版本提供的 Temp Partition 功能，该功能可以先将正确数据导入到 Temp Partition 中，完成后可以将要删除的 Partition 和 Temp Partition 进行交换，交换操作是原子性的，对于上层用户无感知。&lt;/p&gt;&lt;p&gt;Doris 添加新的 BE 节点后可以自动迁移 Tablet 到新节点上，达到数据负载均衡。通过添加 FE 节点，则可以支撑更高的查询峰值，满足大促高并发的要求。&lt;/p&gt;&lt;p&gt;大促期间数据导入量会暴增，而且在备战期间，也会有憋单演练，在短时间内会产生大量数据导入任务。通过导入模块限制 Load 的并发，可以避免大量数据的同时导入，保证了 Doris 的导入性能。&lt;/p&gt;&lt;p&gt;Doris 在团队已经经历了数次大促，在所有大促期间无事故发生，查询峰值 4500+qps，日查询总量 8 千万+，TP99 毫秒级，数据日增量近 300 亿行，且实时导入数据秒级延迟。&lt;/p&gt;&lt;p&gt;Doris 支持低延时的高并发查询和高吞吐的 Ad-hoc 查询，但是这两类查询会相互影响，迁移到 Doris 的初期日常线上的主要问题就是高吞吐的查询占用资源过多，导致大量低延时的查询超时。后来使用两个集群来对两类查询进行物理隔离，解决了该问题。&lt;/p&gt;&lt;p&gt;Doris 在 0.11 版本时 FE 的 MySQL 服务 IO 线程模型较为简单，使用一个 Acceptor+ThreadPool 来完成 MySQL 协议的通信过程，单个 FE 节点在并发较高（2000+qps 左右）的时候会出现连接不上的问题，但此时 CPU 占用并不高。在 0.12 版本的时候，Doris 支持了 NIO，解决了这个问题，可以支撑更高的并发。也可以使用长连接解决这个问题，但需要注意 Doris 默认对连接数有限制，连接占满了就无法建立新的连接了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;h3&gt;基于 Doris 的小程序用户增长实践&lt;/h3&gt;&lt;p&gt;首先为什么要做思域精细化运营呢，这起源于两个痛点：&lt;/p&gt;&lt;p&gt;然后针对这两个问题，产品上面提出了一个解决方案 -- 就是分层运营，它主要分为两部分：一个是运营触达，还有一个是精细化的人群。&lt;/p&gt;&lt;p&gt;这套解决方案的收益和价值：&lt;/p&gt;&lt;p&gt;对于开发者来说：&lt;/p&gt;&lt;p&gt;对于整个生态来讲：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;提高了私欲利用率和活跃度&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;激活了开发者主动经营的意愿&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;促进了生态的良性循环&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;用户分层技术难点&lt;/h4&gt;&lt;p&gt;首先给大家简单介绍遇到的四个难点：&lt;/p&gt;&lt;p&gt;1.TB 级数据。数据量特别大，前面讲到是基于画像和行为去做的一个用户分层，数据量是特别大的，每天的数据量规模是 1T +&lt;br/&gt;2.查询的频响要求极高，毫秒级到秒级的一个要求。前面介绍 B 端视角功能时大家有看到，有一个预估人数的功能，用户只要点击 ”预估人数“ 按钮，需要从 TB 级的数据量级里面计算出筛选出的人群人数是多少，这种要在秒级时间计算 TB 级的数量的一个结果的难度其实可想而知&lt;br/&gt;3.计算复杂，需要动静组合。怎么理解？就是现在很多维度是没办法去做预聚合的，必须去存明细数据，然后去实时的计算，这个后面也会细讲&lt;br/&gt;4.产出用户包的时效性要求高。这个比较好理解，如果产出特别慢的话，肯定会影响用户体验&lt;/p&gt;&lt;p&gt;针对上面的四个难点，解法是：&lt;/p&gt;&lt;p&gt;&lt;strong&gt;针对第一个难点 --&amp;gt; 压缩存储，降低查询的数量级。&lt;/strong&gt;&lt;br/&gt;具体选型就是使用 Bitmap 存储，这解法其实很好理解，不管现在主流的 OLAP 引 擎有多么厉害，数据量越大，查询肯定会越慢，不可能说数据量越大，我查询还是一直不变的，这种其实不存在的，所以我们就需要降低存储。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;针对第二和第三个难点 --&amp;gt; 选择合适计算引擎&lt;/strong&gt;&lt;br/&gt;在调研了当前开源的包括 ClickHouse, Doris, Druid 等多种引擎后，最终选择了基于 MPP 架构的 OLAP 引擎 Doris。&lt;br/&gt;这里可以简单跟大家介绍一下选择 Doris 的原因，从性能来说其实都差不多，但是都 Doris 有几个优点:&lt;br/&gt;第一：它是兼容 Mysql 协议，也就是说你的学习成本非常低，基本上大家只要了解 mysql， 就会用 Doris， 不需要很大的学习成本。&lt;br/&gt;第二：Doris 运维成本很低，基本上就是自动化运维。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;针对第四个难点 --&amp;gt; 选择合适的引擎&lt;/strong&gt;&lt;br/&gt;通过对比 Spark 和 Doris，我们选择了 Doris ，后面会详细讲为什么会用 Doris。&lt;/p&gt;&lt;h4&gt;用户分层的架构和解决方案&lt;/h4&gt;&lt;p&gt;分层运营架构：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGrthW2N78JTZHyHpE1eZCEiaO7o4SvWlYYQnEib9f7yQHBr62BKqXAozw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.562962962962963&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;架构的话分为两部分，就是在线部分跟离线部分。&lt;/p&gt;&lt;p&gt;在线部分：&lt;br/&gt;分为了四层：服务层、解析层、计算层跟存储层，然后还有调度平台和监控平台。&lt;/p&gt;&lt;p&gt;服务层，主要功能包含：&lt;/p&gt;&lt;p&gt;解析层，是对 DSL 的一个解析、优化、路由以及 Sql 模板：&lt;/p&gt;&lt;p&gt;比如要查在线预估人数，首先会在解析层做一个 DSL 的解析，之后根据不同情景做 DSL 的优化，比如选择了近七天活跃且近七天不活跃的用户，这种要七天活跃和七天不活跃的交集显然就是零了，对不对？像这样情况在优化层直接将结果 0 返回给用户就不会再往下走计算引擎，类似还有很多其他优化场景。然后优化完之后会使用 DSL 路由功能，根据不同查询路由到不同的 Sql 模板进行模板的拼接。&lt;/p&gt;&lt;p&gt;计算层，计算引擎使用 Spark 和 Doris：&lt;/p&gt;&lt;p&gt;存储层：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Mysql：主要用来存用户分层的一些用户信息&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Redis：主要用作缓存&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Doris：主要存储画像数据和行为数据&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;AFS：主要是存储产出的用户包的一些信息&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;调度平台：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;主要是离线任务的调度&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;监控平台：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;整个服务稳定性的监控&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;离线部分：&lt;/p&gt;&lt;p&gt;离线部分的话主要是对需要的数据源（比如说画像、关注、行为等数据源）做 ETL 清洗，清洗完之后会做一个全局字典并写入 Doris。任务最终会产出用户包，并会分发给小程序 B 端跟百度统计：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;小程序 B 端：推送给手机端用户&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;百度统计：拿这些用户包做一次群体分析&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以上就是一个整体的架构。&lt;/p&gt;&lt;p&gt;图中大家可以看到有几个标红的地方，同时也用数字 1、2、3 做了标记，这几个标红是重点模块，就是针对于上面提到的四个难点做的重点模块改造，接下来会针对这三个重点模块一一展开进行讲解。&lt;/p&gt;&lt;p&gt;1、全局字典&lt;/p&gt;&lt;p&gt;首先讲解全局字典这个模块，全局字典的目的主要是为了解决难点一：数据量大，需要压缩存储同时压缩存储之后还要保证查询性能。&lt;/p&gt;&lt;p&gt;为啥要用全局字典：&lt;br/&gt;这里大家可能会有一个疑问，就是说用 BitMap 存储为啥还要做全局字典？这个主要是因为 Doris 的 BitMap 功能是基于 RoaringBitmap 实现的，因此假如说用户 ID 过于离散的时候，RoaringBitmap 底层存储结构用的是 Array Container 而不是 BitMap Container，Array Container 性能远远差于 BitMap Container。因此我们要使用全局字典将用户 ID 映射成连续递增的 ID，这就是使用全局字典的目的。&lt;/p&gt;&lt;p&gt;全局字典的更新逻辑概况：&lt;br/&gt;这里是使用 Spark 程序来实现的，首先加载经过 ETL 清洗之后各个数据源（画像、关注、行为这些数据源）和全局字典历史表（用来维护维护用户 ID 跟自增 ID 映射关系），加载完之后会判断 ETL 里面的用户 ID 是否已经存在字典表里面，如果有的话，就直接把 ETL 的数据写回 Doris 就行了，如果没有就说明这是一个新用户，然后会用 row_number 方法生成一个自增 ID ，跟这个新用户做一次映射，映射完之后更新到全局字典并写入 Doris。&lt;/p&gt;&lt;p&gt;2、Doris&lt;/p&gt;&lt;p&gt;接下来介绍第二个重点模块 Doris。&lt;/p&gt;&lt;p&gt;2.1 Doris 分桶策略&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGAcmyOOKL2KxXe5eibcxSv9ODKHCsrl0F1Ze1w119UoM9HCwL6kIg84g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.562962962962963&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;分桶策略的目的是为了解决难点二：查询频响要求高。&lt;/p&gt;&lt;p&gt;为啥要做分桶策略：&lt;/p&gt;&lt;p&gt;之前使用了全局字典保证用户的连续递增，但是发现用了全局字典之后，BitMap 的查询性能其实并没有达到预期。 Doris 其实是分布式的一个集群，它会按照某些 Key 进行分桶，也就是分桶之后用户 ID 在桶内就不连续，又变成零散的了。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.562962962962963&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGBCmQT40kZ89KFhUFNabDHINxre0f1zcaWYUOxIYDff0LwJ6lp8N5Zw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;方案其实就是在表里面增加了一个 hid 的字段，然后让 Doris 按照 hid 字段进行分桶，这里 hid 生成算法是：&lt;/p&gt;&lt;p&gt;hid = V/（M/N） 然后取整&lt;br/&gt;其中：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;V：全局字典的用户 ID 对应的整数&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;M：预估的用户总数&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;N：分层数&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;大家可以看一下：userid 是六个即 0~5，所以 M= 6；分为三个桶，N = 3；因此 M 除以 N 就等于二。这样的话我就要用 userid 去除以二，然后取整作为 hid。可以看一下，比如说 userid 是零，0÷2 取整为 0 ，userid 是一的话，hid 还是这样，因为 1÷2 的整数部分是零；同理 2÷2 、3÷2 是一，4÷2、5÷2 是二，这样的话就把 userid 跟 hid 做对应，然后再根据 hid 做分层。大家可以看到分层结果，hid = 0 时 userid 是 0、1，hid = 1 时 userid 是 2、3，hid = 2 时 userid 是 4、5，这样就保证了桶内连续。&lt;/p&gt;&lt;p&gt;2.2 doris 之用户画像标签优化&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGvT5G4o9eX5QTzsa0h74d7DTVSGhuHmenYdv4so1VicBdzMFERL1r6Wg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.562962962962963&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;画像标签优化解决的难点也是难点二：查询频响要求高。&lt;/p&gt;&lt;p&gt;方案一：&lt;br/&gt;tag_type, tag_value 。tag_type 是用来记录标签的类型，tag_value 是用来记录标签的内容。&lt;br/&gt;如图所示：比如说 tag_type 是性别，tag_value 可能是男或女，bitmap 这里就是存储所有性别是男的用户 id 列表。&lt;br/&gt;同样对于 tag_type 是地域、tag_value 是北京，bitmap 存储的是所有地域在北京的用户 id 列表。&lt;/p&gt;&lt;p&gt;方案二：&lt;br/&gt;大宽表，使用大宽表在一行记录了所有的标签，然后使用 bitmap 记录这个标签的用户 id 列表。&lt;/p&gt;&lt;p&gt;最终选择方案二，为什么没有选方案一呢 ？因为方案一它是一个标签对应一个用户 bitmap，当想查一个联合的结果就比较耗时，比如想查询性别是男且区域是北京的所有用户，这样的话需要取出 “男” 的用户和 “北京“ 的用户，两者之间做一个交集。肯定会有计算量会有更多的时间消耗，但是如果用大宽表去做存储的话，就可以根据用户常用的查询去构建一个物化视图，当用户的查询（比如在北京的男性）命中了物化视图，就可以直接去取结果，而不用再去做计算，从而降低耗时。&lt;/p&gt;&lt;p&gt;这里还有一个知识点跟大家分享一下：在使用 Doris 的时候，一定要尽量去命中它的前缀索引跟物化视图，这样会大大的提升查询效率。&lt;/p&gt;&lt;p&gt;2.3 doris 之动静组合查询&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CGta1WibLkvBLI7AykR7YUzmZY4Q741HjZNXYRPX545qJlqjpjPUp0HjA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.562962962962963&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;动静组合查询，对应的难点是难点三：计算复杂。&lt;/p&gt;&lt;p&gt;首先介绍一下什么叫动静组合查询：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;静态查询：定义为用户维度是固定的，就是可以进行预聚合的查询为静态查询。比如说男性用户，男性用户个就是一个固定的群体，不管怎么查用户肯定不会变，就可以提前进行预聚合的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;动态查询：主要偏向于一些行为，就是那种查询跟着用户的不同而不同。比如说查近 30 天收藏超过三次的用户，或者还有可能是近 30 天收藏超过四次的用户，这种的话就很随意，用户可能会查询的维度会特别的多，而且也没法没办法进行一个预聚合，所以称之为动态的一个查询。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;然后小程序用户分层，相比于同类型的用户分层功能增加了用户行为筛选，这也是小程序产品的特点之一。比如说可以查近 30 天用户支付订单超过 30 元的男性， 这种 ”近 30 天用户支付订单超过 30 元“ 的查询是没办法用 bitmap 做记录的，也没办法说提前计算好，只能在线去算。这种就是一个难点，就是说怎么用非 bitmap 表和 bitmap 做交并补集的运算，为了解决这个问题，结合上面的例子把查询拆分为四步：查近 30 天用户支付订单超过 30 元的男性，且年龄在 20 ~30 岁的用户（具体查询语句参考 PPT 图片）&lt;/p&gt;&lt;p&gt;第一步先查 20~30 岁的男性用户。因为是比较固定，这里可以直接查 bitmap 表。&lt;/p&gt;&lt;p&gt;第二步要查近 30 天用户支付订单超过 30 元的用户。这种的话就没办法去查 bitmap 表了，因为 bitmap 没有办法做这种聚合，只能去查行为表。&lt;/p&gt;&lt;p&gt;第三步就是要做用户 ID 跟在 线 bitmap 的一个转化。Doris 其实已经提供了这样的功能函数：to_bitmap，可以在线将用户 id 转换成 bitmap。&lt;/p&gt;&lt;p&gt;第四步是求交集。就是第一步和第四步的结果求交集。&lt;/p&gt;&lt;p&gt;然后，整篇的核心其实是在第三步：Doris 提供了 to_bitmap 的功能，它帮我们解决了非 bitmap 表和 bitmap 联合查询的问题。&lt;/p&gt;&lt;p&gt;以上是基于 Doris 用户分层方案的一个讲解，基于上述方案整体的性能收益是：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;95 分位耗时小于一秒&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;存储耗降低了 9.67 倍&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;行数优化了八倍&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;如何快速产出用户包&lt;/h4&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2O7sFho1EsiblwXWictib5f2CG7xM4IKfsxY7hMr3EC1nOricRaBQeEWDzdEpCcMSkhB8cxSJl0RFeeXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.56353591160221&quot; data-w=&quot;543&quot;/&gt;&lt;/p&gt;&lt;p&gt;现在讲一下第三部分：用户包。这部分主要是用来解决难点四：产出用户包要求时效性高。这个其实也有两个方案：&lt;/p&gt;&lt;p&gt;方案一：调度平台 + spark。&lt;br/&gt;这个其实比较容易理解，因为要跑离线任务很容易就想到了 spark。在这个调度平台里面用了 DAG 图，分三步：先产出用户的 cuid，然后再产出用户的 uid，最后是回调一下做一次更新。&lt;/p&gt;&lt;p&gt;方案二：调度平台 + solo。&lt;/p&gt;&lt;p&gt;最终的方案选型选用了Doris。&lt;/p&gt;&lt;p&gt;方案一使用的是 Spark ，它存在几个问题：比如 Yarn 调度比较耗时，有时候也会因为队列的资源紧张而会有延迟，所以有时候会出现一个很极端的情况就是：产出零个用户，也要 30 分钟才能跑完，这种对用户的体验度非常不好。&lt;/p&gt;&lt;p&gt;方案二的话就是利用了 Doris 的 SELECT INTO OUTFILE 产出结果导出功能，就是查出的结果可以直接导出到 AFS，这样的效果就是最快不到三分钟就可以产出百万级用户，所以 Doris 性能在某些场景下比 Spark 要好很多。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>dba61be31e6974694481b00703340549</guid>
<title>Python 超轻量级日志解决方案</title>
<link>https://toutiao.io/k/lupogxe</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KkCMRahHfcreUibKoGTYVPcPwqcbkHHkInwCjHlgiczjf4s1Bak4p1zSNcgWTgaAzBT15ickq7DS6WCOsG7vpV7ww/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;前言&lt;/span&gt;&lt;span/&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;日志，几乎每个程序都需要有的功能，对于很多比较大型的，多人合作的程序，使用专业的日志解决方案，比如 fluentd，是个不错的选择。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;fluentd 就是重了点，你需要搭建 fluentd 服务，然后不同的应用再通过相应的方式将日志信息传导 fluentd 服务中，当然重的好处是强大，它可以兼容多个语言，只有你的 client 实现好就行，还可以在日志传输管道中加入各种 hook，比如某个带关键字的日志要执行某种操作等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我的程序比较轻，之前都是运维同学搭建好了 fluentd+ES 一套日志管理系统，现在要自己弄，有点麻烦，所以决定使用其他方式来实现日志的管理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先列一下我简单的需求：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;1. 日志可以存入文件（最基本要求）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;2. 日志可以存入 MongoDB（方便搜索分析）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;3. 报警日志可以主动告警（方便我及时修复）&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;日志存文件&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先来实现前两个功能，利用 Python 自带的 logging 便可以实现将日志内容存入文件的功能，代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; time&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; logging&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; logging.handlers&lt;br/&gt;&lt;br/&gt;LOG_FILENAME = &lt;span&gt;&#x27;main.log&#x27;&lt;/span&gt;&lt;br/&gt;logger = logging.getLogger()&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;set_logger&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;    logger.setLevel(logging.INFO)&lt;br/&gt;&lt;br/&gt;    formatter = logging.Formatter(&lt;span&gt;&#x27;%(asctime)s - %(process)d-%(threadName)s - &#x27;&lt;/span&gt;&lt;br/&gt;                                  &lt;span&gt;&#x27;%(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s&#x27;&lt;/span&gt;)&lt;br/&gt;    console_handler = logging.StreamHandler()&lt;br/&gt;    console_handler.setFormatter(formatter)&lt;br/&gt;    logger.addHandler(console_handler)&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;# log output to file&lt;/span&gt;&lt;br/&gt;    file_handler = logging.handlers.RotatingFileHandler(&lt;br/&gt;        LOG_FILENAME, maxBytes=&lt;span&gt;10485760&lt;/span&gt;, backupCount=&lt;span&gt;5&lt;/span&gt;, encoding=&lt;span&gt;&quot;utf-8&quot;&lt;/span&gt;)&lt;br/&gt;    logger.addHandler(file_handler)&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;set_logger()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;logging 模块标准的写法，利用 logging 的 handler 功能实现格式化，同样利用 handler 功能，将日志存入到本地文件中。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;日志存 MongoDB&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用 log4mongo 库，可以让你的 logging 无缝将日志存入到 MongoDB 中，log4mongo 提供了符合 logging 调用格式的 Handler，直接使用则可，代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; time&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; logging&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; logging.handlers&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; log4mongo.handlers &lt;span&gt;import&lt;/span&gt; MongoHandler&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; logging &lt;span&gt;import&lt;/span&gt; *&lt;br/&gt;&lt;br/&gt;LOG_FILENAME = &lt;span&gt;&#x27;main.log&#x27;&lt;/span&gt;&lt;br/&gt;logger = logging.getLogger()&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;set_logger&lt;/span&gt;&lt;span&gt;(mongodb=False)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;    logger.setLevel(logging.INFO)&lt;br/&gt;&lt;br/&gt;    formatter = logging.Formatter(&lt;span&gt;&#x27;%(asctime)s - %(process)d-%(threadName)s - &#x27;&lt;/span&gt;&lt;br/&gt;                                  &lt;span&gt;&#x27;%(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s&#x27;&lt;/span&gt;)&lt;br/&gt;    console_handler = logging.StreamHandler()&lt;br/&gt;    console_handler.setFormatter(formatter)&lt;br/&gt;    logger.addHandler(console_handler)&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; mongodb:&lt;br/&gt;        &lt;span&gt;# log output to mongodb&lt;/span&gt;&lt;br/&gt;        db_name = &lt;span&gt;&#x27;bestpitcher_log&#x27;&lt;/span&gt;&lt;br/&gt;        mon_handler = MongoHandler(host=mongodb_config[&lt;span&gt;&#x27;host&#x27;&lt;/span&gt;],&lt;br/&gt;                                   port=int(mongodb_config[&lt;span&gt;&#x27;port&#x27;&lt;/span&gt;]),&lt;br/&gt;                                   database_name=db_name,&lt;br/&gt;                                   &lt;span&gt;# username=mongodb_config[&#x27;user&#x27;],&lt;/span&gt;&lt;br/&gt;                                   &lt;span&gt;# password=mongodb_config[&#x27;password&#x27;],&lt;/span&gt;&lt;br/&gt;                                   &lt;span&gt;# authentication_db=db_name&lt;/span&gt;&lt;br/&gt;                                   )&lt;br/&gt;        mon_handler.setLevel(logging.INFO)&lt;br/&gt;        logger.addHandler(mon_handler)&lt;br/&gt;    &lt;span&gt;else&lt;/span&gt;:&lt;br/&gt;        &lt;span&gt;# log output to file&lt;/span&gt;&lt;br/&gt;        file_handler = logging.handlers.RotatingFileHandler(&lt;br/&gt;            LOG_FILENAME, maxBytes=&lt;span&gt;10485760&lt;/span&gt;, backupCount=&lt;span&gt;5&lt;/span&gt;, encoding=&lt;span&gt;&quot;utf-8&quot;&lt;/span&gt;)&lt;br/&gt;        logger.addHandler(file_handler)&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;set_logger(mongodb=&lt;span&gt;True&lt;/span&gt;)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实例化 MongoHandler，获得相应的 handler，然后添加到 logger 中，便实现了将日志写入 MongoDB 的效果，如下图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.12057522123893805&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KkCMRahHfcreUibKoGTYVPcPwqcbkHHkII3ts3laN2SGO7EBhnZkaZmdZKRXYN0VBN0m4v7Y4Eh6YOOS4kt0frQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;904&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;日志报警&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;项目代码在阿里云上运行，阿里云提供了对日志文件进行监控并通过钉钉报警的功能，跟其他组同事交流，他不希望不是自己组里的项目也使用他这套，会显得很乱，至于会不会乱，不纠结，既然人家不想我这样搞，那就自己搞。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单调用，使用飞书的 WebHook 机器人可以非常轻松的实现日志推送报警的功能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在开始编写前，要理清飞书机器人的概念，飞书中其实有两种机器人，如果你通过【飞书机器人】去搜索，就会有点懵。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;飞书中，每个群组可以设置一个 WebHook 机器人，这个使用个人版飞书便可以直接使用，非常方便，我们的日志监控就利用 WebHook 机器人，其添加方式如下：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1. 先创建一个群，然后点击设置，然后点击【群机器人】，然后点击【添加机器人】&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7670682730923695&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KkCMRahHfcreUibKoGTYVPcPwqcbkHHkIIy0fZsMpOypndJ8lHKOUnMVZmiaGkVGrzickvyUWhbQG9tK6csKeQb2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;498&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7554630593132154&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KkCMRahHfcreUibKoGTYVPcPwqcbkHHkIwLSSiaSoz69ZkO8VFlN5bJKE7vFSITpdfvyDpNColAq2HwhBxTFqibwQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;961&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2. 简单配置 WebHook 机器人&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7554630593132154&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KkCMRahHfcreUibKoGTYVPcPwqcbkHHkINibfUFyBtqSlA2P2q4gfLUiauiaOoOeBooj9cTzRfxz8CFM6icfcend76Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;961&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从配置就可以看出，WebHook 机器人的工作原理，通过 HTTP 请求机器人的 webhook 地址，请求数据的格式符合 webhook 文档定义的格式变可以请求成功了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了安全，我这里还开启了【签名校验】，即如果你通过中间人攻击抓我的包，包中的内容是加密的，而我的后端程序会使用这个签名校验秘钥对加密内容进行解析，获得真实数据，与 WebHook 交互代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; base64&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; hashlib&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; hmac&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; datetime &lt;span&gt;import&lt;/span&gt; datetime&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; requests&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; requests.adapters &lt;span&gt;import&lt;/span&gt; HTTPAdapter&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; requests.packages.urllib3.util &lt;span&gt;import&lt;/span&gt; Retry&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; hashlib&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; base64&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; Crypto.Cipher &lt;span&gt;import&lt;/span&gt; AES&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; configs &lt;span&gt;import&lt;/span&gt; *&lt;br/&gt;&lt;br/&gt;timestamp = int(datetime.now().timestamp())&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;AESCipher&lt;/span&gt;&lt;span&gt;(object)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(self, key)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;        self.bs = AES.block_size&lt;br/&gt;        self.key = hashlib.sha256(AESCipher.str_to_bytes(key)).digest()&lt;br/&gt;&lt;br/&gt;&lt;span&gt;    @staticmethod&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;str_to_bytes&lt;/span&gt;&lt;span&gt;(data)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;        u_type = type(&lt;span&gt;b&quot;&quot;&lt;/span&gt;.decode(&lt;span&gt;&#x27;utf8&#x27;&lt;/span&gt;))&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; isinstance(data, u_type):&lt;br/&gt;            &lt;span&gt;return&lt;/span&gt; data.encode(&lt;span&gt;&#x27;utf8&#x27;&lt;/span&gt;)&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; data&lt;br/&gt;&lt;br/&gt;&lt;span&gt;    @staticmethod&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;_unpad&lt;/span&gt;&lt;span&gt;(s)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; s[:-ord(s[len(s) - &lt;span&gt;1&lt;/span&gt;:])]&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;decrypt&lt;/span&gt;&lt;span&gt;(self, enc)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;        iv = enc[:AES.block_size]&lt;br/&gt;        cipher = AES.new(self.key, AES.MODE_CBC, iv)&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; self._unpad(cipher.decrypt(enc[AES.block_size:]))&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;decrypt_string&lt;/span&gt;&lt;span&gt;(self, enc)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;        enc = base64.b64decode(enc)&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; self.decrypt(enc).decode(&lt;span&gt;&#x27;utf8&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;BaseBot&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(self)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;        self.session = requests.Session()&lt;br/&gt;        &lt;span&gt;# 设置重试&lt;/span&gt;&lt;br/&gt;        self.session.mount(&lt;span&gt;&#x27;https://&#x27;&lt;/span&gt;, HTTPAdapter(&lt;br/&gt;            max_retries=Retry(total=&lt;span&gt;5&lt;/span&gt;, method_whitelist=frozenset([&lt;span&gt;&#x27;GET&#x27;&lt;/span&gt;, &lt;span&gt;&#x27;POST&#x27;&lt;/span&gt;]))))&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;gen_sign&lt;/span&gt;&lt;span&gt;(self, secret)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;# 拼接时间戳以及签名校验&lt;/span&gt;&lt;br/&gt;        string_to_sign = &lt;span&gt;&#x27;{}\n{}&#x27;&lt;/span&gt;.format(timestamp, secret)&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;# 使用 HMAC-SHA256 进行加密&lt;/span&gt;&lt;br/&gt;        hmac_code = hmac.new(&lt;br/&gt;            string_to_sign.encode(&lt;span&gt;&quot;utf-8&quot;&lt;/span&gt;), digestmod=hashlib.sha256&lt;br/&gt;        ).digest()&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;# 对结果进行 base64 编码&lt;/span&gt;&lt;br/&gt;        sign = base64.b64encode(hmac_code).decode(&lt;span&gt;&#x27;utf-8&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; sign&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;BaseMsgBot&lt;/span&gt;&lt;span&gt;(BaseBot)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(self)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;        super(BaseMsgBot, self).__init__()&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;send_base_msg&lt;/span&gt;&lt;span&gt;(self, msg)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&quot;&quot;&quot;&lt;br/&gt;        发送基本的信息&lt;br/&gt;        :return:&lt;br/&gt;        &quot;&quot;&quot;&lt;/span&gt;&lt;br/&gt;        sign = self.gen_sign(WEBHOOK_SECRET)&lt;br/&gt;        params = {&lt;br/&gt;            &lt;span&gt;&quot;timestamp&quot;&lt;/span&gt;: timestamp,&lt;br/&gt;            &lt;span&gt;&quot;sign&quot;&lt;/span&gt;: sign,&lt;br/&gt;            &lt;span&gt;&quot;msg_type&quot;&lt;/span&gt;: &lt;span&gt;&quot;text&quot;&lt;/span&gt;,&lt;br/&gt;            &lt;span&gt;&quot;content&quot;&lt;/span&gt;: {&lt;span&gt;&quot;text&quot;&lt;/span&gt;: msg}&lt;br/&gt;        }&lt;br/&gt;&lt;br/&gt;        resp = requests.post(WEBHOOK_URL, json=params)&lt;br/&gt;        resp.raise_for_status()&lt;br/&gt;        result = resp.json()&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; result.get(&lt;span&gt;&quot;code&quot;&lt;/span&gt;) &lt;span&gt;and&lt;/span&gt; result.get(&lt;span&gt;&quot;code&quot;&lt;/span&gt;) != &lt;span&gt;0&lt;/span&gt;:&lt;br/&gt;            print(&lt;span&gt;f&quot;发送失败：&lt;span&gt;{result[&lt;span&gt;&#x27;msg&#x27;&lt;/span&gt;]}&lt;/span&gt;&quot;&lt;/span&gt;)&lt;br/&gt;            &lt;span&gt;return&lt;/span&gt;&lt;br/&gt;        print(&lt;span&gt;&quot;消息发送成功&quot;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;if&lt;/span&gt; __name__ == &lt;span&gt;&#x27;__main__&#x27;&lt;/span&gt;:&lt;br/&gt;    BaseMsgBot().send_base_msg(&lt;span&gt;&#x27;懒编程YYDS!&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;效果如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.47641509433962265&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KkCMRahHfcreUibKoGTYVPcPwqcbkHHkIdpHCx0S3nQOp4mSOdiboZK37voY0pibibJ1yYpT5hrcCpBJrtWSr9pMOA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;424&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;WebHook 机器人是不与我们的后端程序交互的，即无法实现，我发一段指令给他，他执行相应动作这样的效果，但对于单纯的日志监控，WebHook 够用了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;飞书中另外一种机器人是需要通过创建机器人应用的方式创建，这种机器人不在群组里，而是在工作台中，比如下图我创建了自己的应用机器人。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.31757289204097716&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KkCMRahHfcreUibKoGTYVPcPwqcbkHHkIiaqwCwmMmA2sa02BLwHntEoaDVmFMnAicwoibDg3VenEYWwvC8rYLzgcA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1269&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要创建这种机器人，需要企业版飞书，因为机器人获取消息、发送消息的功能需要申请相应的权限，当然，还有国内惯例，通过 APPSECRET 换取 2 小时后会过期的 access_token，这个我也弄了，因为我喜欢通过飞书机器人控制程序的一下动作，比如从日志机器人中发现了严重报错，但日志机器人无法控制程序，而我人在外面，此时可以通过应用机器人执行一些动作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;飞书 WebHook 机器人对接完了，那怎么与 logging 结合在一起使用呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为我已有的项目中已经大量的使用 logger 了，我不希望去逐行修改使用 logger 的方式，而是希望通过某种对 logger 无感的方式来实现日志传递到 WebHook 的效果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单阅读 logging 文档，发现没有 Hook 机制，没办法，只能看 logging 源码走继承重写的解决方案了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里可以总结一下我对库修改的方式，如果一个库，没有我想要的功能（通过文档判断），我就会去看它的源代码，然后尝试将核心类通过继承的方式弄出来，然后再在继承出的子类中添加自己的逻辑。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单分析，会发现 logger 下，使用的 info、warning、error 等方法，都会调用_log 方法，_log 方法会进一步执行相应的动作，这些动作我不关心，因为我会通过 super 方法直接使用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;琢磨一下自己的需求，对于 info 基本的日志，当然不需要日志报警，简单记录到 MongoDB 中就好了，对于 error 级别日志，报错了嘛，当然希望主动告诉我，但有时 info 基本，我也希望它主动告诉我，基于上述分析，写出如下代码：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;import&lt;/span&gt; logging&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; logging.handlers&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; logging &lt;span&gt;import&lt;/span&gt; *&lt;br/&gt;&lt;br/&gt;LOG_FILENAME = &lt;span&gt;&#x27;main.log&#x27;&lt;/span&gt;&lt;br/&gt;LOG_LEVEL = ERROR&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;MyLogger&lt;/span&gt;&lt;span&gt;(Logger)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(self, name, level=NOTSET)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;        super(MyLogger, self).__init__(name=name, level=level)&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;_log&lt;/span&gt;&lt;span&gt;(&lt;br/&gt;            self,&lt;br/&gt;            level,&lt;br/&gt;            msg,&lt;br/&gt;            args,&lt;br/&gt;            exc_info=None,&lt;br/&gt;            extra=None,&lt;br/&gt;            stack_info=False,&lt;br/&gt;            robot=False&lt;br/&gt;    )&lt;/span&gt; -&amp;gt; &lt;span&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&quot;&quot;&quot;&lt;br/&gt;&lt;br/&gt;        :param level:&lt;br/&gt;        :param msg:&lt;br/&gt;        :param args:&lt;br/&gt;        :param exc_info:&lt;br/&gt;        :param extra:&lt;br/&gt;        :param stack_info:&lt;br/&gt;        :param robot: 是否要通过飞书机器人将日志发送到飞书上&lt;br/&gt;        :return:&lt;br/&gt;        &quot;&quot;&quot;&lt;/span&gt;&lt;br/&gt;        super(MyLogger, self)._log(level, msg, args, exc_info, extra, stack_info)&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; robot &lt;span&gt;or&lt;/span&gt; level &amp;gt;= LOG_LEVEL:&lt;br/&gt;            msg_bot.send_base_msg(msg)&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;__reduce__&lt;/span&gt;&lt;span&gt;(self)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; getLogger, ()&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;logger = MyLogger(&lt;span&gt;&#x27;bestpitcher_log&#x27;&lt;/span&gt;, WARNING)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上述代码中，实现 MyLogger 基础于 Logger，然后重写其中的_log 方法，_log 方法中，第一件事便是通过 super 调用父类中_log 方法的逻辑，然后再添加自己的逻辑，即发送信息到飞书 webhook 的逻辑。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;_log 方法中，我添加了 robot 参数，如果打印日志时，设置了 robot，则发送到 webhook，此外还有默认日志级别，这里是 ERROR 级别，即 error 日志，就算 robot 为 False，也会主动发送日志到 webhook 中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单测试使用一下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;from&lt;/span&gt; logger &lt;span&gt;import&lt;/span&gt; logger&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;test_logger&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;    logger.info(&lt;span&gt;&#x27;[info] 这条日志只会记录在MongoDB中&#x27;&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;# exc_info 获得报错时的调用链&lt;/span&gt;&lt;br/&gt;    logger.error(&lt;span&gt;&#x27;[error] 这条日志会发送到WebHook机器人上&#x27;&lt;/span&gt;, exc_info=&lt;span&gt;True&lt;/span&gt;)&lt;br/&gt;    logger.warning(&lt;span&gt;&#x27;[warning] 这条日志也会发送到WebHook&#x27;&lt;/span&gt;, robot=&lt;span&gt;True&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;if&lt;/span&gt; __name__ == &lt;span&gt;&#x27;__main__&#x27;&lt;/span&gt;:&lt;br/&gt;    test_logger()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;WebHook 效果：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.29333333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KkCMRahHfcreUibKoGTYVPcPwqcbkHHkI7Hne5s2cKCFRM12Hq6541ouTPcalviamIfWfdCvzPUn7NmzxicRfrTuQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MongoDB 效果：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.14432989690721648&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KkCMRahHfcreUibKoGTYVPcPwqcbkHHkIOO46cqcumY2f1lAGSZBiaIa9qdwYiaOEEFWzlGdYVuprj3KIzbLZHLPA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;970&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;结尾&lt;/span&gt;&lt;span/&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;项目 Github 地址：https://github.com/ayuLiao/simple-logger&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我是二两，我们下篇文章见。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对了，公众号有我个人微信，可以找我玩。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Enjoy Coding.&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e68a5998ed61679ac401e36f24ac17e2</guid>
<title>几行烂代码，我赔了16万。</title>
<link>https://toutiao.io/k/zkhoe39</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p class=&quot;original_area_primary&quot;&gt;
                                                                                                &lt;/p&gt;

                    
                                            &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前几天在某平台看到一个技术问题，很有意思啊。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;涉及到的两个技术点，大家平时开发使用的也比较多，但是属于一个小细节，深挖下去，还是有点意思的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;来，先带你看一下问题是什么，同时给你解读一下这个问题：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;https://segmentfault.com/q/1010000040361592&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，这位同学给出了一个代码片段：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4826862539349423&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiakOuY7FMPC1QW3hyzG7Yjofq4t4fwtXhIr91TkvqDbUqn3ekPibQhMicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;953&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;他说他有一个 func 方法，这个方法里面干了两件事：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;1.先查询数据库里面的商品库存。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;2.如果还有库存，那么对库存进行减一操作，模拟商品卖出。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于第二件事，提问的同学其实写了两个操作在里面，所以我再细分一下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;2.1 对库存进行减一操作。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;2.2 在订单表插入订单数据。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很显然，这两个操作都会对数据库进行操作，且应该是应该原子性的操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，在方法上加了一个 &lt;code&gt;@Transactional&lt;/code&gt; 注解。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接着，为了解决并发访问的问题，他用 lock 把整个代码包裹了起来，保证在单体结构下，同一时刻只有一个请求能去执行减少库存，生成订单的操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;非常的完美。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，先把大前提申明一下：MySQL 数据库的隔离机制使用的是可重复读级别。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1609442060085837&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiad3yaTtmOkyFJic8oKgUzaAxlPB3W9yX4gicicIEyS3I55FrYu0KtZCQgQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1398&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个时候，问题就来了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果是高并发的情况下，假设真的就有多个线程同时调用 func 方法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要保证一定不能出现超卖的情况，那么就需要事务的开启与提交能完整的包裹在 lock 与 unlock之间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;显然事务的开启一定是在 lock 之后的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;故关键在于事务的提交是否一定在 unlock 之前？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果事务的提交在 unlock 之前，没有问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为事务已经提交了，代表库存一定减下来了，而这个时候锁还没释放，所以，其他线程也进不来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;画个简单的示意图如下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9353169469598965&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiapeybR8WlmNUEF67v9Lia36QzOh4SKM4c6d7bvxQUUL0AibTVV11tHWhg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;773&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;等 unlock 之后，再进来一个线程，执行查询数据库的操作，那么查询到的值一定是减去库存之后的值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，如果事务的提交是在 unlock 之后，那么有意思的事情就出现了，你很有可能发生超卖的情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的图就变成了这样的了，注意最后两个步骤调换了：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9113607990012484&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaffGjsDaqTBgXLtVmF6sPtThzmicnia28Ws0ouGdmds3PXOx2M2YKD3vw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;801&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;举个例子。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设现在库存就只有一个了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个时候 A，B 两个线程来请求下单。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;A 请求先拿到锁，然后查询出库存为一，可以下单，走了下单流程，把库存减为 0 了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是由于 A 先执行了 unlock 操作，释放了锁。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;B 线程看到后马上就冲过来拿到了锁，并执行了查询库存的操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;注意了，这个时候 A 线程还没来得及提交事务，所以 B 读取到的库存还是 1，如果程序没有做好控制，也走了下单流程。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;哦豁，超卖了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，再次重申问题：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上面的示例代码的情况下，如果事务的提交在 unlock 之前，是没有问题的。但是如果在 unlock 之后是会有问题的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;那么事务的提交到底是在 unlock 之前还是之后呢？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个事情，先把问题听懂了，接着我们先按下不表。你可以简单的思考一下。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.9607142857142857&quot; data-type=&quot;png&quot; data-w=&quot;280&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia36nHzibIsHsichX9TWBbmlyaLibFux0rxgp74UPJC3iblEZle6XCI7xWHg/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我想先聊聊这句被我轻描淡写，一笔带过，你大概率没有注意到的话：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;显然事务的开启一定是在 lock 之后的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这句话，不是我说的，是提问的同学说的：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.09343936381709742&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaiacc8icQibCdI5JAyDv60vIxFkOHXBaVlG6hQZUAxB97DDZRwkww6NRzg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1006&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你有没有一丝丝疑问？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;怎么就显然了？哪里就显然了？为什么不是一进入方法就开启事务了？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请给我证据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;来吧，瞅一眼证据。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.975&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiayln7ia3Zoya5WtIs9U7H6nnelK2XLqZ8PeNDllhCm1P4Rv2e0z7w4ZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;400&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;事务开启时机&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;证据，我们需要去源码里面找。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，我不得不多说一句 Spring 在事务这块的源码写的非常的清晰易懂，看起来基本上没有什么障碍。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;所以如果你不知道怎么去啃源码，那么事务这块源码，也许是你撕开源码的一个口子。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，不多说了，去找答案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答案就藏在这个方法里面的：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;org.springframework.jdbc.datasource.DataSourceTransactionManager#doBegin&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6890756302521008&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaDLV6ybfksZK8PyT6QFUjicico1q6f1P8ibyZ4g9c1SwvNkKLIfXicG78Hg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1071&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先看我下面框起来的那一行日志：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Switching JDBC Connection [HikariProxyConnection@946359486 wrapping com.mysql.jdbc.JDBC4Connection@7a24806] to manual commit&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你知道的，我是个技术博主，偶尔教点单词。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Switching，转换。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Connection，链接。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;manual commit，手动提交。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Switching ... to ...，把什么转换为什么。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;没想到吧，这次学技术的同时不仅学了几个单词，还会了一个语法。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.94&quot; data-type=&quot;png&quot; data-w=&quot;300&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiadib7R3iaS62aicSW0Yyo9JSflgl86kKCxzqu8bm4TI3ONpCcejUBGDLAQ/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，上面那句话翻译过来就非常简单了：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;把数据库连接切换为手动提交。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后，我们看一下打印这行日志的代码逻辑，也就是被框起来的代码部分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我单独拿出来：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.15566037735849056&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaicsyX1Xj49HVmd4LCYaQhzEcEYNz7MaicuFygiaSIv6ZibySpwbXd59mEg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;848&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;逻辑非常清晰，就是把连接的 AutoCommit 参数从 ture 修改为 false。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么现在问题就来了，这个时候，事务启动了吗？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我觉得没启动，只是就绪了而已。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;启动和就绪还是有一点点差异的，就绪是启动之前的步骤。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么事务的启动有哪些方式呢？&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;第一种：使用启动事务的语句，这种是显式的启动事务。比如 begin 或 start transaction 语句。与之配套的提交语句是 commit，回滚语句是 rollback。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;第二种：autocommit 的值默认是 1，含义是事务的自动提交是开启的。如果我们执行 set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很显然，在 Spring 里面采用的是第二种方式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而上面的代码 &lt;code&gt;con.setAutoCommit(false)&lt;/code&gt; 只是把这个链接的自动提交关掉。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事务真正启动的时机是什么时候呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;前面说的 begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才算是真正启动。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。需要注意的是这个命令在读已提交的隔离级别（RC）下是没意义的，和直接使用 start transaction 一个效果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;回到在前面的问题：什么时候才会执行第一个 SQL 语句？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就是在 lock 代码之后。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，显然事务的开启一定是在 lock 之后的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一个简单的“显然”，先给大家铺垫一下。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来，给大家上个动图看一眼，更加直观。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先说一下这个 SQL：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;select * from information_schema.innodb_trx;&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不多解释，你只要知道这是查询当前数据库有哪些事务正在执行的语句就行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你就注意看下面的动图，是不是第 27 行查询语句执行完成之后，查询事务的语句才能查出数据，说明事务这才真正的开启：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;__bg_gif rich_pages wxw-img&quot; data-ratio=&quot;0.9493087557603687&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiayt1qcTssWyIMW1shd6AB0G9zMicKBgVSSDXhxmrmqXInDVCIJtPvoxA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;868&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，我们把目光转移到这个方法的注释上：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3064516129032258&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia4E5m9K5qkMshYK8X1FicYfvxIdBh0TtKj3iaz3j8JnF2zhfFAbbT8v7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;620&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;写这么长一段注释，意思就是给你说，这个参数我们默认是 ture，原因就是在某些 JDBC 的驱动中，切换为自动提交是一个很重的操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么在哪设置的为 true 呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;没看到代码，我一般是不死心的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，一起去看一眼。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;setAutoCommit 这个方法有好几个实现类，我也不知道具体会走哪一个：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6629055007052186&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiamHonIsNPSZsBlSGC3eCiaZo6L2B6ia8iaLtKd988Ynsl1FJjcXtpfc2fw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;709&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，我们可以在下面这个接口打上一个断点：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;java.sql.Connection#setAutoCommit&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.17890772128060264&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia572pAfphTIbvLxI9Mic9zBmea77Dxw9fz1u1pvWv0Hbk4tKjCzEOCfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;531&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后重启程序，IDE 会自动帮你判断走那个实现类的：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3550834597875569&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia3ktylZPs9mr0D8eVAic1LbmYfMJIcs9zJNiaZ5fW19ibTYLib23WbthicyQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;659&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到，默认确实是 true。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;等等，你不会真的以为我是想让你看这个 true 吧？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我是想让你知道这个调试技巧啊。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不知道有多少个小伙伴曾经问过我：这个接口实现类好多啊，我怎么知道在哪打断点啊？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我说：很简单啊，就在每个实现类的第一行代码打上断点就好了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后他说：别闹，我经常给你的文章一键三联。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我当时就被感动了，既然是这样的好读者，我当然把可以直接在接口上打断点的这个小技巧教给他啦。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6461916461916462&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiacoCPyYfrwlzIgsJZfxNZLfReNYcQJiaM3jzGlw5K7CY1m2nlYj3ZWlQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;407&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，不扯远了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再说一个小细节，这一小节就收尾。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你再去看这小节的开头，我直接说答案藏在这个方法里面：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;org.springframework.jdbc.datasource.DataSourceTransactionManager#doBegin&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;直接把答案告诉你了，隐去了探索的过程。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是这个东西，就像是数学公式推导一样，省略了一步，就会让人看起来一脸懵逼。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就像下面这个小耗子一样：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.1095152603231597&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaUzFcxpqt5J38QolnjgXId9Ryicp24VxsK19BfI1JhFR7W5ZSjf0akSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;557&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，我是怎么知道在这个地方打断点的呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答案就是调用栈。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先给大家看一下我的代码：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5359116022099447&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiavmwhfGYmsdtc2f7aiaPn82sadZ60iar2HGAOyhiaaQv9AyHRhlFRLDNoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;724&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;啥也先不管，上来就先在 26 行，方法入口处打上断点，跑起来：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0702179176755449&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTial4PxbnrP9o6GOUn10ZgOdzx8agDfCjhLQWhLzia91ibbGfv9t5A56GTA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;诶，你看这个调用栈，我框起来的这个地方：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5916795069337443&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaSokibsXibjZuPWOFm6an0zLD6mxiaaN09VwbRicFwBtevymVmxR0UmWFag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;649&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看这个名字，你就不好奇吗？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;它简直就是在跳着脚，在喊你：点我，快，愣着干啥，你TM快点我啊。我这里有秘密！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后，我就这样轻轻的一点，就到了这里：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;org.springframework.transaction.interceptor.TransactionAspectSupport#invokeWithinTransaction&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里有个切面，可以理解为 try 里面就是在执行我们的业务代码逻辑：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.47380239520958084&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia36xBia3kBJcwHibHSyGHOUt18IOBfkISP7QB4n7LvBCsZczD8wMzG9EQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1336&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而在 try 代码块，执行我们的业务代码之前，有这样的一行代码：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2924791086350975&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiap6n6VibuI0PC9nayzHYKbOANH87u4T6ogicYDiadC9TP9e5VsPV6mIZicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;718&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;找到这里了，你就在这一行代码之前，再轻轻的打个断点，然后调试进去，就能找到这一小节开始的时候，说的这个方法：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;org.springframework.jdbc.datasource.DataSourceTransactionManager#doBegin&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不信？你看嘛，我不骗你。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;它们之间只隔了三个调用：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.747887323943662&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaIj4R3YtCdhdzf6iaFy4YMAvFpOnpbxQZmddFyeYrzoUPa2eobZtzoSw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;710&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样就找到答案了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;调用栈，另一个调试源码小技巧，屡试不爽，送给你。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;之前还是之后&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，前面是开胃菜，可能有的同学吃开胃菜就已经弄饱了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;没事，现在上正餐，再按一按还是能吃进去的。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img __bg_gif&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6507462686567164&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaQLYSyfjIIlwRqpyTl3ibfibeKPyZlJDTH38It1VsgBkEeAI7xiamObWmA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;335&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还是拿前面的这份代码来说事，流程就是这样的：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;2.00253807106599&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiatCSYahO6EhLOdXRuUDHAcqBcIejSY1srk2MRCQcZzKIM3yr2TwfDBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;394&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;1.先拿锁。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;2.查询库存。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;3.判断是否还有库存。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;4.有库存则执行减库存,创建订单的逻辑。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;5.没有库存则返回。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;6.释放锁。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以代码是这样的：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8893871449925261&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaPzyntByqnlbnicfwiaAne0ZcficjIwPVVU4svPUHxibV5qOvnFKXOaDOpw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;669&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;完全符合我们之前的那份代码片段，有事务，也有锁：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4826862539349423&quot; data-type=&quot;png&quot; data-w=&quot;953&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiakOuY7FMPC1QW3hyzG7Yjofq4t4fwtXhIr91TkvqDbUqn3ekPibQhMicA/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;回到我们最开始抛出来的问题：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;在上面的示例代码的情况下那么事务的提交到底是在 unlock 之前还是之后呢？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以带入一个具体的场景。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如我数据库里面有 10 个顶配版的 iPad，原价 1.6w 元一台，现在单价 1w 一个，这个价格够秒杀吧？&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.3609375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/ELQw2WCMgt0RyzxtDEe6icibJlRPbWx9uAyxdRLcRA5O0FbQne4S40Zw6MsXhBIh9Mib506xpomEhVre0uaI5oocg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;反正一共就 10 台，所以，我的数据库里面是这样的，&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3879598662207358&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiagKFyQp3eic21QaYPTaPiaRKYWKtN4sibJyvuicKOerOvMD7gshHO3U9nZg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;299&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后我搞 100 个人来抢东西，不过分吧？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我这里用 CountDownLatch 来模拟一下并发：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6926503340757239&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaGqY0UKflxAKicDKA2fAPzNZmgPpeHPIyWAmV0qWBfMKFVWibOeDgKqCA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;449&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;执行一下，先看结果，立马就见分晓：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img __bg_gif&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.6874115983026874&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiagDc0d8ficYz2fibGdGWoHMrvsibVxylN0VkPzkockrK9OhoP9ohFxq2vA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;707&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;动图右边的部分：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面是浏览器请求，触发 Controller 的代码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后中间是产品表，有 10 个库存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最下面是订单表，没有一条数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;触发了代码之后，库存为 0 了，没有问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，订单居然有 20 笔！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也就是说超卖了 10 个ipad pro 顶配版！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;超卖的，可不在活动预算范围内啊！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那可就是一个 1.6w 啊，10 个就是 16w 啊。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;就这么其貌不扬，人畜无害，甚至看起来猥猥琐琐的代码，居然让我亏了整整 16w 。&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8475&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiabL2LhDsvpmzfRX5XdWKTIWUCb68DTQFIqhrK89vVUiaZg9O97U53ALg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;400&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实，结果出现了，答案也就随之而来了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;在上面的示例代码的情况下，事务的提交在 unlock 之后。&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9113607990012484&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaffGjsDaqTBgXLtVmF6sPtThzmicnia28Ws0ouGdmds3PXOx2M2YKD3vw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;801&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实你仔细分析后，猜也能猜出来，肯定是在 unlock 之后的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而且上面的描述“unlock之后”其实是有一定的迷惑性的，因为释放锁是一个比较特别的操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;换一个描述，就比较好理解了：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;在上面的示例代码的情况下，事务的提交在方法运行结束之后。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你细品，这个描述是不是迷惑性就没有那么强了，甚至你还会恍然大悟：这不是常识吗？&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8133333333333334&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia5xcltTYq3R3ibUfMiaWJFrYLuhAbOmz8ib97cKLWiafLghSW8sJy7OJGVw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;300&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么是方法结束之后，分析具体原因之前，我想先简单分析一下这样的代码写出来的原因。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我猜可能是这样的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最开始的代码结构是这样：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4208754208754209&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaq8olOOvzhbT5yQfUppnwrVgWnNcIf6icwdaBHW8lfQ6EwU5Mu4tkDZQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;297&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后，写着写着发现不对，并发的场景下，库存是一个共享的资源，这玩意得加锁啊。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;于是搞了这出：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5738255033557047&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaIIEOd5NyVibjgwDrOVWSSB1DDUAh0UhNzfInOkYEknYTbekG4iaCeqzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;298&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后面再次审查代码的时候，发现：哟，这个第三步得是一个事务操作才行呀。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;于是代码就成了这样：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6542372881355932&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiatD6ojvLyS3kJrsmMa98rFBoGk4H57icicMqC4pWCiaOoU6jWia0Bo2BYVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;295&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;演进路线非常合理，最终的代码看起来也简直毫无破绽。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是问题到底出在哪里了呢？&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.88&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaRqyUF06bIg5cc1bxxt4agOxYkN6ejCIUFjPsOwVBXGNibKE9dLXDe9g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;300&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;找答案&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答案还是在这个类里面：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;org.springframework.transaction.interceptor.TransactionAspectSupport#invokeWithinTransaction&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9164810690423163&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTianJRT2iarkbV37EZcfQFtWvQMLL6ANLicSIHdHYVQYcjScZcEtyDH2xng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;898&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面我们聊事务开启的时候，说的是第 382 行代码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后 try 代码块里面执行的是我们的业务代码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在，我们要研究事务的提交了，所以主要看我框起来的地方。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先 catch 代码块里面，392 行，看方法名称已经非常的见名知意了：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;completeTransactionAfterThrowing&lt;/code&gt; 在抛出异常之后完成事务的提交。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你看我的代码，只是用到了 &lt;code&gt;@Transactional&lt;/code&gt; 注解，并没有指定异常。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么问题就来了：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Spring 管理的事务，默认回滚的异常是什么呢？&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你不知道答案，就可以带着问题去看源码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你知道答案，但是没有亲眼看到对应的代码，那么也可以去寻找源码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你知道答案，也看过这部分源码，温故而知新。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先说答案：&lt;strong&gt;默认回滚的异常是 RuntimeException 或者 Error&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我只需要在业务代码里面抛出一个 RuntimeException 的子类，比如这样的：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.25972006220839816&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaAMLeFzA1svTY4fTCzR0W75sTVpYmTBibPZxqK7PhG2LEMvP1paQlWeA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;643&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后在 392 行打上断点，开始调试就完事了：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3698060941828255&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiapM8R3WThF5hYvFxTqooPatXppYick40yEUBOGYUTvia7wRHbYyn7n2icA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;722&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;只需要往下调试几步，你就能走到这个方法来：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;org.springframework.transaction.interceptor.RuleBasedTransactionAttribute#rollbackOn&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6916030534351145&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaamr1n6VydlrdBAibdS7USiaMDqo5vWiayzYIrraVHeLxUPfYLAnSl31Xg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;655&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;发现这个 winner 对象为空，接着走了这个逻辑：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;return super.rollbackOn(ex);&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答案就藏着这行代码的背后：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.17201166180758018&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaxBlktwysdzh7icdpfD52jWZaOCspwOHpJW8k6Ov1Xp5Ko1yOt8efBVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;686&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果异常类型是 RuntimeException 或者 Error 的子类，那么就返回 true，即需要回滚，调用 rollback 方法：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6256613756613757&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiajWricdj84HVghrSHv8q81AebXQz2S9XkmlrryvVJSo8EsZpZGeicSRYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;756&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果返回为 false，则表示不需要回滚，调用 commit 方法：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7005494505494505&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaXOzbD337XwibhWY8ZiaODkQWsIdIGDTcbgOp9ChPgQmV5nIxsSFNfyGQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;728&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么怎么让它返回 false 呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很简单嘛，这样一搞就好了：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.28550074738415543&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia75QtefSD6nE1C7wrAJBgXoHwtpu1QVeibrUWYpTOLSPxq87OzV0NdqA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;669&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;框架给你留了口子，你就把它用起来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当我把代码改成上面那样，然后重新启动项目，再次访问代码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们去寻找出现指定异常不回滚的具体的实现逻辑在哪。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实也在我们刚刚看到的方法里面：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.52&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTialu7bc7UBJU9SuOrHm6rpLeuDY3MK9zxeL1a5RrTaUPlZ3YrAv6fc2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;875&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你看，这个时候 winner 不为 null 了。它是一个 NoRollbackRuleAttribute 对象了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以就走入这行代码，返回 false 了：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;return !(winner instanceof NoRollbackRuleAttribute);&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;于是，就成功走到了 else 分支里面，出了异常也 commit 了，你说神奇不神奇：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.518628912071535&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiafqPL6xDXQZBKkupwrkGPcP1s1X2G3C5OGvx88voicmwhvm9YvZWDqeQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;671&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;写到这里的时候，我突然想到了一个骚操作，甚至有可能变成一道沙雕面试题：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2674897119341564&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiafVkHno93Z8lJvgg2j55RNIvlZBd8WJTbgtgBm8Nk1pTpQLv096zl8g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;729&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个操作骚不骚，到底会回滚呢还是不回滚呢？&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8966666666666666&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia6BSRHoK72WelZXRnBzlVLg3yKWRMaklJI80Zt8K6GIYcKWFWXFiaIQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;300&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你在项目里看到这样的代码肯定是要骂一句傻逼的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是面试官就喜欢搞这些阴间的题目。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我想到这个问题的时候，我也不知道答案是什么，但是我知道答案还是在源码里面：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45491388044579534&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia47GbpHYwfsxNpibjKsCib3ia2RG4ZkjcWxseMOuicecTa4Eb1ReeBWyopQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;987&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，从结果上可以直观的看到，经过 for 循环之后， winner 是 RollbackRuleAttribute 对象，所以下面的代码返回 true，需要回滚：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;return !(winner instanceof NoRollbackRuleAttribute);&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;问题就变成了 winner 为什么经过 for 循环之后是 RollbackRuleAttribute？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答案需要你自己去调试一下，很容易就明白了，我描述起来比较费劲。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单一句话：导致 winner 是 RollbackRuleAttribute 的原因，就是因为被循环的这个 list 是先把 RollbackRuleAttribute 对象 add 了进去。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么为什么 RollbackRuleAttribute 对象先加入到集合呢？&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;org.springframework.transaction.annotation.SpringTransactionAnnotationParser#parseTransactionAnnotation(org.springframework.core.annotation.AnnotationAttributes)&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5937940761636107&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaNnSRCvpxm9c1W2QMvUticzMdeVuMmhZPHiauZeObMMk7LCYDiaomOcibnQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;709&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;别问，问就是因为代码是这样写的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么代码要这样写呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我想可能设计这块代码的开发人员觉得 rollbackFor 的优先级比 noRollbackFor 高吧。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再来一个问题：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Spring 源码怎么匹配当前这个异常是需要回滚的？&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;别想那么复杂，大道至简，直接递归，然后一层层的找父类，对比名称就完事了。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2734741784037559&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiay6HF3MM2cjUsDLyZGnQ2NyMG1xqR67jrJ62nukUTYW3sdcD7H0ctjQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;852&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你注意截图里面的注释：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个是 Found it!&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;表示找到了，匹配上了，用了感叹号表示很开心。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个是 If we&#x27;ve gone as far as we can go and haven&#x27;t found it...&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;啥意思呢，这个 as far as 在英语里面是一个连词，表示“直到..为止..”的意思。引导的是状语从句，强调的是程度或范围。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，上面这句话的意思就是：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果我们已经走到我们能走的最远的地方，还没匹配上，代码就只能这样写了：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1873589164785553&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaN3SFL3vdenG4icfDeZzhibNUSicPMOibydsnz5ntmHR81hO4XfPLghAg7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;443&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;异常类，最远的地方就是  Throwable.class。没匹配上，就返回 -1。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，通过两个没啥卵用的知识点，顺带学了点实战英语，关于业务代码出了异常回滚还是提交这一块的代码就差不多了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是我还是建议大家亲自去 Debug 一下，可太有意思了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后我们接着聊正常场景下的提交。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7018544935805991&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiavFTkKUibQ2iaqRO9eRS28Ms5JpYWgibmLyshBLgLAuYuM7JN32hGOpmAA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;701&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个代码块里面，try 我们也聊了，catch 我们也聊了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就差个 finally 了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我看网上有的文章说 finally 里面就是 commit 的地方。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;错了啊，老弟。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里只是把数据库连接给重置一下。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;方法上已经给你说的很清楚了：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3747841105354059&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaWBJ2QDVGxaib8QtSEq2EVfFAiaUVtN2BnhRj3fV72Md8IAjPJYVZWTKw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;579&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Spring 的事务是基于 ThreadLocal 来做的。在当前的这个事务里面，可能有一些隔离级别、回滚类型、超时时间等等的个性化配置。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不管是这个事务正常返回还是出现异常，只要它完事了，就得给把这些个性化的配置全部恢复到默认配置。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，放到了 finally 代码块里面去执行了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;真正的 commit 的地方是这行代码：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6897506925207756&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaWm8uW0dzkFqR45ySmDpg2UCH46RTQ9pABEY2KiaEjzM3zUIy2nkIptA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;722&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么问题又来了：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;走到这里来了，事务一定会提交吗？&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;话可别说的那么绝对，兄弟，看代码：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;org.springframework.transaction.support.AbstractPlatformTransactionManager#commit&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6302816901408451&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia6TLUlaMsJMxDM462Sew5yfDdlCP113salicUSWqsCPZWJgzuDw3phicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;852&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 commit 之前还有两个判断，如果事务被标记为 rollback-only 了，还是得回滚。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而且，你看日志。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我这事务还没提交呢，锁就被释放了？&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.398981324278438&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaoedPU49HibLPwLic5eeOaeU5Fj9TC7ibVG1D0VprCcwBhXf4cd6DeE5XA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;589&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接着往下看 commit 相关的逻辑，我们就会遇到老朋友：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.47644927536231885&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaWBcmJ0xr42zAKibtgP1EswLSO3ViaicHMyUOmyObrV21wyno9fNecIRgw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;552&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;HikariCP，SpringBoot 2.0 之后的默认连接池，强得一比，在之前的文章里面介绍过。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于事务的提交，就不大篇幅的介绍了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;给大家指个路：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;com.mysql.cj.protocol.a.NativeProtocol#sendQueryString&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这个方法的入口处打上断点：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.14160070360598065&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaGqmSviaicyyOZvaWnCPYwkAQ2U2eOgpoxOUVss6iaeAbw7AL4hLCbEiakA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1137&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后你会发现很多的 SQL 都会经过这个地方。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，为了你顺利调试，你需要在断点上设置一下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5316742081447964&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia0MI3eOMT5ibbbRlSXic9Pjic63iaDlL6eTLcvD9ewyXL9FPWUjsf3iafEdQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;442&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样只有 SQL 语句是 commit 的时候才会停下来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;又一个调试小细节，送给你，不客气。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在，我们知道原因了，那我现在把代码稍微变一下：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7041602465331279&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaBbfDulaoJM5T3bFCsoKMwsnibUez9e4Xbu5UE5E5W1SOLonncVZW1sQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;649&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;把 ReentrantLock 换成了 synchronized。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那你说这个代码还会不会有问题？&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.85&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaefMibOmI2ngHFdGAdtS4VlX1xr8GGCGKOicYm4oQE64N50H2nT1icufvg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;280&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说没有问题的同学请好好反思一下。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个地方的原理和前面讲的东西是一模一样的呀，肯定也是有问题的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个加锁方式就是错误的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以你记住了，以后面试官问你 &lt;code&gt;@Transactional&lt;/code&gt; 的时候，你把标准答案先背一遍之后，如果你对锁这块的知识点非常的熟悉，就可以在不经意间说一下结合锁用的时候的异常场景。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;别说你写的，就说你 review 代码的时候发现的，深藏功与名。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外记得扩展一下，现在都是集群服务了，加锁得上分布式锁。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是原理还这个原理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;既然都聊到分布式锁了，这和面试官又得大战几个回合。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;是你主动提起的，把面试官引到了你的主战场，拿几分，不过分吧。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个面试小技巧，送给你，不客气。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.2740315638450501&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia1qFBB3XJxMfmCGyIcquyGss7O9XVoDo2jrYNQaDXGLpZK6LzpJQZ0A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;697&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;解决方案&lt;/span&gt;&lt;span/&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在我们知道问题的原因了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;解决方案其实都呼之欲出了嘛。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;正确的使用锁，把整个事务放在锁的工作范围之内：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1220338983050848&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTial6MrCBXjDocb7eiaXysPKgOLVxg1LHpj0iawBmq2nx3ANbnaHgDfaYWg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;295&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样，就可以保证事务的提交一定是在 unlock 之前了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对不对？&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;__bg_gif rich_pages wxw-img&quot; data-ratio=&quot;0.9&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia77cb9PgDArZm07C7DV2XN8DQ9SGfRNNkhTeortbicibRskTcjuZTcGFg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;300&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说对的同学，今天就先到这里，请回去等通知啊。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;别被带到沟里去了呀，朋友。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你仔细想想这个事务会生效吗？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提示到这里还没想明白的同学，赶紧去搜一下事务失效的几种场景。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我这里说一个能正常使用的场景：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.377521613832853&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTialVkaWRN4iaqpgFL2WCyd9PdD9VltwibqicRNQd34ZNfUlsviavv2u6ib7yQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;347&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;只是这种自己注入自己的方式，我觉得很恶心。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果项目里面出现了这样的代码，一定是代码分层没有做好，项目结构极其混乱。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不推荐。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还可以使用编程式事务的方式去写，自己去控制事务的开启、提交、回滚。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比直接使用 &lt;code&gt;@Transactional&lt;/code&gt; 靠谱。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除此之外，还有一个骚一点的解决方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其他地方都不动，就只改一下 @Transactional 这个地方：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.25735294117647056&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia7ibYy94snGL8GzUBXLBamMbetUPpPmQRdTO7zZPqicVvQcXQNyDJiccog/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;680&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;把隔离级别串行化，再次跑测试用例，绝对不会出现超卖的情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;甚至都不需要加锁的逻辑。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你觉得好吗？&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0267175572519085&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiadB0PDLg86g8ZPGGLKQXrUTg92vesUQd0mSqQ7pibc5z9P2JlqXibKiaEg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;262&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好啥啊？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;串行化性能跟不上啊！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这玩意太悲观了，对于同一行的数据，读和写的时候都会进行加锁操作。当读写锁出现冲突的时候，后面来的事务就排队等着。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个骚操作，知道就行了，别用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你就当是一个没啥卵用的知识点就行了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，如果你们是一个不追求性能的场景，这个没有卵用的知识点就变成骚操作了。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;rollback-only&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面提到了这个 rollback-only，为了更好的行文，所以我一句话就带过了，其实它也是很有故事的，单独拿一节出来简单说一下，给大家模拟一下这个场景。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以后你见到这个异常就会感觉很亲切。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Spring 的事务传播级别默认是 REQUIRED，含义是如果当前没有事务，就新建一个事务，如果上下文中已经有一个事务，则共享这个事务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;直接上代码：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.1049107142857142&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiatzXibCnW9tug6v67ia18I9q6vzVdRgrheeYbAm33sKq3VqwDthpXZLiaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;448&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里有 sellProduct、sellProductBiz 两个事务，sellProductBiz 是内层事务，它会抛出了异常。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当执行整个逻辑的时候，会抛出这个异常：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Transaction rolled back because it has been marked as rollback-only&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.23209663503019845&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTia8DMpic1NkYIIFa8uEe7T59shHF1r7myaf5I2QMq3ibYibSWruNmiaibyKnQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1159&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据这个异常的堆栈，可以找到这个地方，在前面出现过：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5838926174496645&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiahDV83gFncqYtfWYw29uVO3iaetWmQ1Uq0Zzx00s5icN4OjAh9efWaQww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1192&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，我们只需要分析这个 if 条件为什么满足了，就大概摸清楚脉络了。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;if (!shouldCommitOnGlobalRollbackOnly() &amp;amp;&amp;amp; defStatus.isGlobalRollbackOnly())&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面的 shouldCommitOnGlobalRollbackOnly 默认为 false：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.1712846347607053&quot; data-type=&quot;png&quot; data-w=&quot;397&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaL1rcy8T3I7BrKEHKZRfC51JGwl1JgCIVGbBANynAZ93zCNBnsee7mQ/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;问题就精简为了：defStatus.isGlobalRollbackOnly() 为什么是true？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为 sellProductBiz 抛出异常后，会调用 completeTransactionAfterThrowing 方法执行回滚逻辑。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;肯定是这个方法里面搞事情了啊。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;org.springframework.transaction.support.AbstractPlatformTransactionManager#processRollback&lt;/p&gt;&lt;/blockquote&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7973856209150327&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiaicictDibTnSLPiciaXVzcicOw9bWtjFdZV0KHkHXFjz6o777Wc0VnCBjn1Ow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;918&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这里，把链接的 rollbackOnly 置为了 true。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，后面的事务想要 commit 的时候，一检查这个参数，哦豁，回滚吧。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大概就是这样的：&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.2011385199240987&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiakAlG3uDQwmCwickFLX4xQZaicLVC0ib0ibuLMJc8UN9hQ4M9xVy7DA9yMQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;527&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果这不是你期望的异常，怎么解决呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;理解了事务的传播机制就简单的一比：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0891304347826087&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTiacIfLL0uMsoLeuCbswyxEN0kAwGy5aiajmhIBrptpwf9UgfChRbsH44g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;460&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就这样，跑起来没毛病，互不干扰。&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8283870967741935&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt2vChCbyE4fWfyaLW0mYMTialwtcC3Wdhn6SicvkcM6gEiaeFyrYFkN5fI5I1XKqjR0udxdkIEEAflnQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;775&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;- EOF -&lt;/span&gt;&lt;/p&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_030&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section&gt;&lt;span&gt;推荐阅读&lt;/span&gt;  &lt;span&gt;点击标题可跳转&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&amp;amp;mid=2651508383&amp;amp;idx=1&amp;amp;sn=53dfd60bf954c4a008bed0a10d65a558&amp;amp;chksm=bd25a2e08a522bf6c24dccf93369f5b1379ab7d47a2df1744ebaf37fdc2c3db5d916d81d2576&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;一次线上JVM调优实践，FullGC40次/天到10天一次的优化过程&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;一次线上JVM调优实践，FullGC40次/天到10天一次的优化过程&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&amp;amp;mid=2651508382&amp;amp;idx=1&amp;amp;sn=8eb8bedf762bb2e99073896037298e98&amp;amp;chksm=bd25a2e18a522bf7d864009ebad5be93dd05bb56080bac22971beeec127bc40d58d185c84829&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;MySQL数据查询太多会OOM吗？&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;MySQL数据查询太多会OOM吗？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&amp;amp;mid=2651508301&amp;amp;idx=2&amp;amp;sn=5182195384e68aeb7eaa77ddfdc88b97&amp;amp;chksm=bd25a2328a522b24eba89f7ab1a6b47e04c566af72371352c3987a5f05225414ba6d2fb6d857&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;头条二面：你确定 ThreadLocal 真的会造成内存泄露？&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;头条二面：你确定 ThreadLocal 真的会造成内存泄露？&lt;/a&gt;&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看完本文有收获？请转发分享给更多人&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关注「ImportNew」，提升Java技能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9166666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2A8tXicCG8ylbWIGfdoDED35IRRySQZTXUkJ1eop9MHApzFibKnOo0diboXpl0rmS5mH78YJhsWQv0dhv718A6kUA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;点赞和在看就是最大的支持&lt;/span&gt;&lt;span&gt;❤️&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>30845a84df4f9c31bcafd6e43c912fa0</guid>
<title>深入浅出 Spark：内存计算的由来</title>
<link>https://toutiao.io/k/blk5hm3</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;p&gt;自 Spark 问世以来，已有将近十年的光景。2009 年，Spark 诞生于加州大学伯克利分校的 AMP 实验室（the Algorithms, Machines and People lab），并于 2010 年开源。2013 年，Spark 捐献给阿帕奇软件基金会（Apache Software Foundation），并于 2014 年成为 Apache 顶级项目。&lt;/p&gt;&lt;p&gt;2014，是个久远的年代，那个时候，大数据江湖群雄并起，门派林立。论内功，有少林派的 Hadoop，Hadoop 可谓德高望重、资历颇深，2006 年由当时的互联网老大哥 Yahoo！开源并迅速成为 Apache 顶级项目。所谓天下武功出少林，Hadoop 的三招绝学：HDFS（分布式文件系统）、YARN（分布式调度系统）、MapReduce（分布式计算引擎），为各门各派武功绝学的发展奠定了坚实基础。论阵法，有武当派的 Hive，Hive 可谓是开源分布式数据仓库的鼻祖。论剑法，有峨眉派的 Mahout，峨眉武功向来“一树开五花、五花八叶扶”，Mahout 在分布式系统之上提供主流的经典机器学习算法实现。论轻功，有昆仑派的 Storm，在当时，Storm 轻巧的分布式流处理框架几乎占据着互联网流计算场景的半壁江山。&lt;/p&gt;&lt;p&gt;Spark 师从 Hadoop，习得 MapReduce 内功心法，因天资聪慧、勤奋好学，年纪轻轻即独创内功绝学：Spark Core —— 基于内存的分布式计算引擎。青，出于蓝而胜于蓝；冰，水为之而寒于水。凭借扎实的内功，Spark 练就一身能为：&lt;/p&gt;&lt;section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Spark SQL —— 分布式数据分析&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Spark Streaming —— 分布式流处理&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Spark MLlib —— 分布式机器学习&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Spark GraphX —— 分布式图计算&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;自恃内功深厚、招式变幻莫测，Spark 初涉江湖便立下豪言壮语：One stack to rule them all —— 剑锋直指各大门派。小马乍行嫌路窄，大鹏展翅恨天低。各位看官不禁要问：Spark 何以傲视群雄？Spark 修行的内功心法 Spark Core，与老师 Hadoop 的 MapReduce 绝学相比，究竟有何独到之处？&lt;/p&gt;&lt;section&gt;
&lt;span&gt;1&lt;/span&gt; Hadoop MapReduce&lt;/section&gt;&lt;p&gt;欲探究竟，还需从头说起。在 Hadoop 出现以前，数据分析市场的参与者主要由以 IOE（IBM、Oracle、EMC）为代表的传统 IT 巨头构成，Share-nothing 架构的分布式计算框架大行其道。传统的 Share-nothing 架构凭借其预部署、高可用、高性能的特点在金融业、电信业大放异彩。然而，随着互联网行业飞速发展，瞬息万变的业务场景对于分布式计算框架的灵活性与扩展性要求越来越高，笨重的 Share-nothing 架构无法跟上行业发展的步伐。2006 年，Hadoop 应运而生，MapReduce 提供的分布式计算抽象，结合分布式文件系统 HDFS 与分布式调度系统 YARN，完美地诠释了“数据不动代码动”的新一代分布式计算思想。&lt;/p&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.39090909090909093&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOOsGfES71KOX45xyOdewiaYdAhRZtFzuNsf8pzL4eb6ankMnSJPLIWniauAQ5ZUtv8ZfkhGibBQWtbg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1430&quot;/&gt;&lt;/section&gt;&lt;p&gt;顾名思义，MapReduce 提供两类计算抽象，即 Map 和 Reduce。Map 抽象用于封装数据映射逻辑，开发者通过实现其提供的 map 接口来定义数据转换流程；Reduce 抽象用于封装数据聚合逻辑，开发者通过实现 reduce 接口来定义数据汇聚过程。Map 计算结束后，往往需要对数据进行分发才能启动 Reduce 计算逻辑来执行数据聚合任务，数据分发的过程称之为 Shuffle。MapReduce 提供的分布式任务调度让开发者专注于业务逻辑实现，而无需关心依赖管理、代码分发等分布式实现问题。在 MapReduce 框架下，为了完成端到端的计算作业，Hadoop 采用 YARN 来完成分布式资源调度从而充分利用廉价的硬件资源，采用 HDFS 作为计算抽象之间的数据接口来规避廉价磁盘引入的系统稳定性问题。&lt;/p&gt;&lt;p&gt;由此可见，Hadoop 的“三招一套”自成体系，MapReduce 搭配 YARN 与 HDFS，几乎可以实现任何分布式批处理任务。然而，近乎完美的组合也不是铁板一块，每一只木桶都有它的短板。HDFS 利用副本机制实现数据的高可用从而提升系统稳定性，但额外的分片副本带来更多的磁盘 I/O 和网络 I/O 开销，众所周知，I/O 开销会严重损耗端到端的执行性能。更糟的是，一个典型的批处理作业往往需要多次 Map、Reduce 迭代计算来实现业务逻辑，因此上图中的计算流程会被重复多次，直到最后一个 Reduce 任务输出预期的计算结果。我们来想象一下，完成这样的批处理作业，在整个计算过程中需要多少次落盘、读盘、发包、收包的操作？因此，随着 Hadoop 在互联网行业的应用越来越广泛，人们对其 MapReduce 框架的执行性能诟病也越来越多。&lt;/p&gt;&lt;section&gt;
&lt;span&gt;2&lt;/span&gt; Spark Core&lt;/section&gt;&lt;p&gt;时势造英雄，Spark 这孩子不仅天资过人，学起东西来更是认真刻苦。当别人都在抱怨老师 Hadoop 的 MapReduce 心法有所欠缺时，他居然已经开始盘算如何站在老师的肩膀上推陈出新。在 Spark 拜师学艺三年后的 2009 年，这孩子提出了“基于内存的分布式计算引擎”—— Spark Core，此心法一出，整个武林为之哗然。Spark Core 最引入注目的地方莫过于“内存计算”，这一说法几乎镇住了当时所有的初学者，大家都认为 Spark Core 的全部计算都在内存中完成，人们兴奋地为之奔走相告。兴奋之余，大家开始潜心研读 Spark Core 内功心法，才打开心法的手抄本即发现一个全新的概念 —— RDD。&lt;/p&gt;&lt;section&gt;
&lt;span&gt;3&lt;/span&gt; RDD&lt;/section&gt;&lt;p&gt;RDD（Resilient Distributed Datasets），全称是“弹性分布式数据集”。全称本身并没能很好地解释 RDD 到底是什么，本质上，RDD 是 Spark 用于对分布式数据进行抽象的数据模型。简言之，RDD 是一种抽象的数据模型，这种数据模型用于囊括、封装所有内存中和磁盘中的分布式数据实体。对于大部分 Spark 初学者来说，大家都有一个共同的疑惑：Spark 为什么要提出这么一个新概念？与其正面回答这个问题，不如我们来反思另一个问题：Hadoop 老师的 MapReduce 框架，到底欠缺了什么？有哪些可以改进的地方？前文书咱们提到：MapReduce 计算模型采用 HDFS 作为算子（Map 或 Reduce）之间的数据接口，所有算子的临时计算结果都以文件的形式存储到 HDFS 以供下游算子消费。下游算子从 HDFS 读取文件并将其转化为键值对（江湖人称 KV），用 Map 或 Reduce 封装的计算逻辑处理后，再次以文件的形式存储到 HDFS。不难发现，问题就出在数据接口上。HDFS 引发的计算效率问题我们不再赘述，那么，有没有比 HDFS 更好的数据接口呢？如果能够将所有中间环节的数据文件以某种统一的方式归纳、抽象出来，那么所有 map 与 reduce 算子是不是就可以更流畅地衔接在一起，从而不再需要 HDFS 了呢？—— Spark 提出的 RDD 数据模型，恰好能够实现如上设想。&lt;/p&gt;&lt;p&gt;为了弄清楚 RDD 的基本构成和特性，我们从它的 5 大核心属性说起。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;属性名&lt;/th&gt;&lt;th&gt;成员类型&lt;/th&gt;&lt;th&gt;属性含义&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;dependencies&lt;/td&gt;&lt;td&gt;变量&lt;/td&gt;&lt;td&gt;生成该 RDD 所依赖的父 RDD&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;compute&lt;/td&gt;&lt;td&gt;方法&lt;/td&gt;&lt;td&gt;生成该 RDD 的计算接口&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;partitions&lt;/td&gt;&lt;td&gt;变量&lt;/td&gt;&lt;td&gt;该 RDD 的所有数据分片实体&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;partitioner&lt;/td&gt;&lt;td&gt;方法&lt;/td&gt;&lt;td&gt;划分数据分片的规则&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;preferredLocations&lt;/td&gt;&lt;td&gt;变量&lt;/td&gt;&lt;td&gt;数据分片的物理位置偏好&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;对于 RDD 数据模型的抽象，我们只需关注前两个属性，即 dependencies 和 compute。任何一个 RDD 都不是凭空产生的，每个 RDD 都是基于一定的“计算规则”从某个“数据源”转换而来。dependencies 指定了生成该 RDD 所需的“数据源”，术语叫作依赖或父 RDD；compute 描述了从父 RDD 经过怎样的“计算规则”得到当前的 RDD。这两个属性看似简单，实则大有智慧。&lt;/p&gt;&lt;p&gt;与 MapReduce 以算子（Map 和 Reduce）为第一视角、以外部数据为衔接的设计方式不同，Spark Core 中 RDD 的设计以数据作为第一视角，不再强调算子的重要性，算子仅仅是 RDD 数据转换的一种计算规则，map 算子和 reduce 算子纷纷被弱化、稀释在 Spark 提供的茫茫算子集合之中。dependencies 与 compute 两个核心属性实际上抽象出了“从哪个数据源经过怎样的计算规则和转换，从而得到当前的数据集”。父与子的关系是相对的，将思维延伸，如果当前 RDD 还有子 RDD，那么从当前 RDD 的视角看过去，子 RDD 的 dependencies 与 compute 则描述了“从当前 RDD 出发，再经过怎样的计算规则与转换，可以获得新的数据集”。&lt;/p&gt;&lt;section&gt;&lt;img data-backh=&quot;225&quot; data-backw=&quot;562&quot; data-ratio=&quot;0.40097970608817357&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOOsGfES71KOX45xyOdewiaYbHjsZiaN1clicicjx7ibbwcaia7pwGVpxCFU7BwPc09boaiaHDgKjZkdhgTQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1429&quot;/&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;不难发现，所有 RDD 根据 dependencies 中指定的依赖关系和 compute 定义的计算逻辑构成了一条从起点到终点的数据转换路径。这条路径在 Spark 中有个专门的术语，叫作 Lineage —— 血统。Spark Core 依赖血统进行依赖管理、阶段划分、任务分发、失败重试，任意一个 Spark 计算作业都可以析构为一个 Spark Core 血统。关于血统，到后文书再展开讨论，我们继续介绍 RDD 抽象的另外 3 个属性，即 partitions、partitioner 和 preferredLocations。相比 dependencies 和 compute 属性，这 3 个属性更“务实”一些。&lt;/p&gt;&lt;p&gt;在分布式计算中，一个 RDD 抽象可以对应多个数据分片实体，所有数据分片构成了完整的 RDD 数据集。partitions 属性记录了 RDD 的每一个数据分片，方便开发者灵活地访问数据集。partitioner 则描述了 RDD 划分数据分片的规则和逻辑，采用不同的 partitioner 对 RDD 进行划分，能够以不同的方式得到不同数量的数据分片。因此，partitioner 的选取，直接决定了 partitions 属性的分布。preferredLocations —— 位置偏好，该属性与 partitions 属性一一对应，定义了每一个数据分片的物理位置偏好。具体来说，每个数据分片可以有以下几种不同的位置偏好：&lt;/p&gt;&lt;section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;本地内存：数据分片已存储在当前计算节点的内存中，可就地访问&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;本地磁盘：数据分片在当前计算节点的磁盘中有副本，可就地访问&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;本机架磁盘：当前节点没有分片副本，但是同机架其他机器的磁盘中有副本&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;其他机架磁盘：当前机架所有节点都没有副本，但其他机架的机器上有副本&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;无所谓：当前数据分片没有位置偏好&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;根据“数据不动代码动”的原则，Spark Core 优先尊重数据分片的本地位置偏好，尽可能地将计算任务分发到本地计算节点去处理。显而易见，本地计算的优势来源于网络开销的大幅减少，进而从整体上提升执行性能。&lt;/p&gt;&lt;p&gt;RDD 的 5 大属性从“虚”与“实”两个角度刻画了对数据模型的抽象，任何数据集，无论格式、无论形态，都可以被 RDD 抽象、封装。前面提到，任意分布式计算作业都可以抽象为血统，而血统由不同 RDD 抽象的依次转换构成，因此，任意的分布式作业都可以由 RDD 抽象之间的转换来实现。理论上，如果计算节点内存足够大，那么所有关于 RDD 的转换操作都可以放到内存中来执行，这便是“内存计算”的由来。&lt;/p&gt;&lt;section&gt;
&lt;span&gt;4&lt;/span&gt; 土豆工坊&lt;/section&gt;&lt;p&gt;从理论出发学习、理解新概念总是枯燥而乏味，通过生活化的类比来更好地理解 RDD 的构成和内存计算的由来也许会更轻松一些。假设有个生产桶装薯片的工坊，这个工坊规模小、工艺也比较原始。为了充分利用每一颗土豆、降低生产成本，工坊使用 3 条流水线来同时生产 3 种不同尺寸的桶装薯片，分别是小号、中号、大号桶装薯片。3 条流水线可以同时加工 3 颗土豆，每条流水线的作业流程都是一样的，即土豆的清洗、切片、烘焙、分发、装桶，其中分发环节用于区分小号、中号、大号 3 种薯片。所有小号薯片都会分发给第一条流水线，中号薯片分发给第二条流水线，不消说，大号薯片都分发给第三条流水线。看得出来，这家工坊工艺虽然简单，倒是也蛮有章法。桶装薯片的制作流程，与 Spark 分布式计算的执行过程颇为神似。&lt;/p&gt;&lt;section&gt;&lt;img data-backh=&quot;134&quot; data-backw=&quot;562&quot; data-ratio=&quot;0.23776223776223776&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOOsGfES71KOX45xyOdewiaY5sRpkT8wicBZFqSLFV3MEFDSX9ibWkVr5pBgEPDPVWrYlrwXX9A8SXtw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1430&quot;/&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;我们先从食材的视角审视薯片的加工流程，首先，3 颗土豆作为原始素材被送上流水线。流水线的第一道工序是清洗，原来带泥的土豆经过清洗变成了一颗颗“干净的土豆”。第二道工序是切片，土豆经过切片操作后，变成了一枚枚大小不一、薄薄的薯片，当然，这些薯片都还是生的，等到烘烤之后方能食用。第三道工序正是用来烘焙，生薯片在经过烘烤后，变成了可以食用的零食。到目前为止，所有流水线上都生产出了 “原味”的薯片，不过，薯片的尺寸参差不齐，如果现在就装桶的话，一来用户体验较差，二来桶的利用效率也低，不利于节约成本。因此，流水线上增加了分发的环节，分发操作先把不同尺寸的薯片区分开，然后根据预定规则把不同尺寸的薯片发送到对应的流水线上。每条流水线都执行同样的分发操作，即先区分大小号，然后再转发薯片。分发步骤完成后，每条流水线的薯片尺寸大小相当，最后通过机械手把薯片封装到对应尺寸的桶里，从而完成一次完整的薯片加工流程。&lt;/p&gt;&lt;p&gt;横看成岭侧成峰，我们再从流水线的视角，重新审视这个过程。从头至尾，除了分发环节，3 条流水线没有任何交集。在分发环节之前，每条流水线都是专心致志、各顾各地开展工作 —— 把土豆食材加载到流水线上、清洗、切片、烘焙；在分发环节完成后，3 条流水线也是各自装桶，互不影响。流水线式的作业方式提供了较强的容错能力，如果某个加工环节出错，流水线只需要重新加载一颗新的土豆食材就能够恢复生产。例如，假设第一条流水线在烘焙阶段不小心把薯片烤糊了，此时只需要在流水线的源头重新加载一颗新的土豆，所有加工流程会自动重新开始，不会影响最终的装桶操作。另外，3 条流水线提供了同时处理 3 颗土豆的能力，因此土豆工坊的并发能力为 3，每次可以同时装载并加工 3 颗土豆，大幅地提升了生产效率。&lt;/p&gt;&lt;p&gt;那么，用土豆工坊薯片加工的流程类比 Spark 分布式计算，会有哪些有趣的发现呢？仔细对比，每一种食材形态，如刚从地里挖出来的土豆食材、清洗后的“干净土豆”、生薯片、烤熟的薯片、分发后的薯片，不就是 Spark 中的 RDD 抽象吗？每个 RDD 都有 dependencies 和 compute 属性，对应地，每一种食材形态的 dependencies 就是流水线上前一个步骤的食材形态，而其 compute 属性就是从前一种食材形态转换到当前这种食材形态的加工方法。例如，对于烤熟的薯片（图中 bakedChipsRDD）来说，它的 dependencies 就是上一步的“已切好的生薯片”（chipsRDD），而它的 compute 属性，就是“烘焙”这一工艺方法。在土豆工坊的制作流程中，从头至尾会产生 6 个 RDD，即 potatosRDD、cleanedPotatosRDD、chipsRDD、bakedChipsRDD 和 shuffledBakedChipsRDD，分别对应不同的食材形态。注意，RDD 是对数据模型的抽象，它的 partitions 属性会对应多个数据分片实体。例如，对于原始食材 potatosRDD，它的 partitions 属性对应的是图中的 3 颗带泥土豆，每颗土豆代表一个“数据分片”。&lt;/p&gt;&lt;p&gt;同理，chipsRDD 的 partitions 属性包含的是从 3 颗土豆切出来的所有“生薯片”，每一枚生薯片都有一个 preferredLocation 用来标记自己所在的流水线，所有生薯片的 preferredLocation 集合构成了 chipsRDD 的 preferredLocations 属性。不难发现，如果我们把土豆工坊中的流水线看成是分布式计算节点，流水线上每一种食材形态的转换，都可以在计算节点中按序完成。特别地，如果节点内存足够大，那么所有上述转换，都可以在内存中完成。随着纳米工艺的飞速发展，在不远的将来，也许内存的价格会像现在的磁盘一样便宜。正是基于这样的判断，Spark 提出了“内存计算”的概念。&lt;/p&gt;&lt;section&gt;&lt;img data-backh=&quot;103&quot; data-backw=&quot;562&quot; data-ratio=&quot;0.18264520643806859&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOOsGfES71KOX45xyOdewiaYuFoHWHqC3CCsfUdoUaqjT2njsbMvZgWaXvpLpCib7ep3yrWAI0icx3Cw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1429&quot;/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;
&lt;span&gt;5&lt;/span&gt; Show me the code&lt;/section&gt;&lt;p&gt;Linus Torvalds 他老人家常说：“Talk is cheap. Show me the code.”。在本篇的最后，我们通过代码示例来直观地感受一下 RDD 的转换过程。学习一门新的编程语言，我们通常从“Hello World”开始；学习分布式开发，我们得从“Word Count”说起。在开始之前，我们准备一个纯文本文件，内容非常简单，只有 3 行文本，如下图所示：&lt;/p&gt;&lt;section&gt;&lt;img data-backh=&quot;223&quot; data-backw=&quot;562&quot; data-ratio=&quot;0.39618138424821003&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOOsGfES71KOX45xyOdewiaYF510E20yLJiaVCeQGbHmbG26X9awD115wibXYnvNsyNB1caCFVpPfT8Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;419&quot;/&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;“Word Count”任务的目标是拆分文本中的单词并对所有单词计数，对于上图中的文本内容，我们期望的结果是 I 的计数是 3，chips 的计数为 2，等等。在用代码来实现这个任务之前，我们先来思考一下：解决这个问题，都需要哪些步骤。首先，我们需要将文件内容读取到计算节点内存，同时对数据进行分片；对于每个数据分片，我们要将句子分割为一个个的单词，同样的单词可能存在于多个不同的分片中（如单词 I），因此需要对单词进行分发，从而使得同样的单词只存在于一个分片之中；最后，在所有分片上计算每个单词的计数。对于这样一个分词计数任务，如果采用 Hadoop MapReduce 框架来实现，往往需要用 Java 来实现 Map、Reduce 抽象，编写上百行代码。得益于 Spark RDD 数据模型的设计及其提供的丰富算子，无论是用 Java、Scala 还是 Python，只消几行代码，即可实现“Word Count”任务。&lt;/p&gt;&lt;section&gt;&lt;img data-backh=&quot;260&quot; data-backw=&quot;562&quot; data-ratio=&quot;0.4632610216934919&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOOsGfES71KOX45xyOdewiaYMhvqZjFETrDKKSYzUdXHNwlvic5VnM4CHdCEUWsrZv2zhrQBMZwFpTg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1429&quot;/&gt;&lt;/section&gt;&lt;p&gt;结合刚刚分析的“解题步骤”，我们首先通过 textFile 算子将文件内容加载到内存，同时对数据进行分片。然后，用 flatMap 和 map 算子实现分词和计 1 的操作。这里计 1 的目的有二，一来是将数据转换为（键, 值）对的形式从而调用 pairRDD 相关算子；二来为 Map 端聚合计算打下基础。关于 pairRDD、性能优化，我们在后文书会详细展开，此处先行略过。最后，通过 reduceByKey 算子完成单词的分发和计数。在这份代码中，我们仅用 5 行 Scala code 就实现了“Word Count”分布式计算作业。在算子的驱动下，不同形态 RDD 之间的依赖关系与转换过程一目了然。那么，如果把这段代码放到土豆工坊的流水线上，会是怎样的流程呢？&lt;/p&gt;&lt;section&gt;&lt;img data-backh=&quot;174&quot; data-backw=&quot;562&quot; data-ratio=&quot;0.30979020979020977&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VOOsGfES71KOX45xyOdewiaYDUDv1sVPeOeuI2icqiaUICbVgibzwc9Yfb5MCB54xy7hSHfJoSgjyj11Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1430&quot;/&gt;&lt;/section&gt;&lt;section&gt;
&lt;span&gt;6&lt;/span&gt; Postscript&lt;/section&gt;&lt;p&gt;本篇是《Spark 分布式计算科普专栏》的第一篇，笔者学浅才疏、疏漏难免。如果您有任何疑问，或是觉得文章中的描述有所遗漏或不妥，欢迎在评论区留言、讨论。掌握一门技术，书本中的知识往往只占两成，三成靠讨论，五成靠实践。更多的讨论能激发更多的观点、视角与洞察，也只有这样，对于一门技术的认知与理解才能更深入、牢固。在本篇博文中，我们从分布式计算发展历史的角度，审视了 Spark、RDD 以及内存计算的由来；以 RDD 的 5 大核心属性展开，讲解 RDD 的构成、依赖关系、转换过程，并结合“土豆工坊”的生活化示例来类比 RDD 转换和 Spark 分布式内存计算的工作流程。&lt;/p&gt;&lt;p&gt;最后，我们用一个简单的代码示例 —— Word Count 来直观地体会 Spark 算子与 RDD 的转换逻辑。细心的读者可能早已发现，文中多次提及“后文书再展开”，Spark 是一个精妙而复杂的分布式计算引擎，在本篇博文中我们不得不对 Spark 中的许多概念都进行了“前置引用”。换句话说，有些概念还没来得及解释（如 Lineage —— 血统），就已经被引入到了本篇博文中。这样的叙述方法也许会给一些读者带来困惑，毕竟，用一个还未说清的概念，去解释另一个新概念，总是感觉没那么牢靠。常言道：“出来混，迟早是要还的”。在后续的专栏文章中，我们会继续对 Spark 的核心概念与原理进行探讨，尽可能地还原 Spark 分布式内存计算引擎的全貌。&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者简介：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;吴磊，Spark Summit China 2017 讲师、World AI Conference 2020 讲师，曾任职于 IBM、联想研究院、新浪微博，具备丰富的数据库、数据仓库、大数据开发与调优经验，主导基于海量数据的大规模机器学习框架的设计与实现。现担任 Comcast Freewheel 机器学习团队负责人，负责计算广告业务中机器学习应用的实践、落地与推广。热爱技术分享，热衷于从生活的视角解读技术，曾于《IBM developerWorks》和《程序员》杂志发表多篇技术文章。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;h5&gt;&lt;span/&gt;今日荐文&lt;span/&gt;&lt;/h5&gt;&lt;p&gt;点击下方图片即可阅读&lt;/p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;amp;mid=2651041914&amp;amp;idx=1&amp;amp;sn=059ae1be87783817441ec2bbbc3c232a&amp;amp;chksm=bdbe48298ac9c13f62075c8bd77673161a8a0b64dc77fdf382ff18e3ae0dbeaf8eadeb06526d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img data-ratio=&quot;0.5505376344086022&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/YriaiaJPb26VM6zia0bf9gVyaZFn7eITk4zGWNHODyvx3WrATZzZy7tafZ3Jqgwhz83esPg4aHvE6oVo3ic7N5AMcw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;930&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span/&gt;120 天已至，华为全面断芯，没有 Plan B&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;hr/&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;InfoQ 读者交流群上线啦！各位小伙伴可以扫描下方二维码，添加 InfoQ 小助手，回复关键字“&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;进群&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;”申请入群。回复“&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;资料&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;”，获取资料包传送门，注册 InfoQ 网站后，可以任意领取一门极客时间课程，免费滴！大家可以和 InfoQ 读者一起畅所欲言，和编辑们零距离接触，超值的技术礼包等你领取，还有超值活动等你参加，快来加入我们吧！&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-ratio=&quot;1&quot; data-w=&quot;396&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YriaiaJPb26VMbposTkCibHIp3Gx4nCK08bvyGbOhibN6YgOt5A0zdQ1prTfZKicnZLLic6VUfdicYYUowH9nFCff3SKA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages __bg_gif&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;643&quot; data-ratio=&quot;1.1515625&quot; data-type=&quot;gif&quot; data-w=&quot;640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/YriaiaJPb26VNBX66P2F9dF2yuYfbcibGMuaBYgvK62MGPE9HhgU2vptFAUZdaO2cGKCsP4h1DnibIGywKSkFv9b6g/640?wx_fmt=gif&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点个在看少个 bug&lt;/span&gt; &lt;span&gt;👇&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>