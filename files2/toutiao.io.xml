<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>ee329d904956a6586a61b8632b65d874</guid>
<title>实时计算框架：Flink 集群搭建与运行机制</title>
<link>https://toutiao.io/k/qf07xgk</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;h1&gt;&lt;span&gt;一、Flink概述&lt;/span&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;1、基础简介&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink被设计在所有常见的集群环境中运行，以内存执行速度和任意规模来执行计算。主要特性包括：批流一体化、精密的状态管理、事件时间支持以及精确一次的状态一致性保障等。Flink不仅可以运行在包括YARN、Mesos、Kubernetes在内的多种资源管理框架上，还支持在裸机集群上独立部署。在启用高可用选项的情况下，它不存在单点失效问题。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.328125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBJkwQfW06UITaIeUib3yy1nlcHibGnUbq5VIqSAPm7N7GB7RLEZkmELZ0k6rl8MpLCENQFnmEsJvzw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;这里要说明两个概念：&lt;/p&gt;&lt;h2&gt;&lt;span&gt;2、应用场景&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Data Driven&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.29375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBJkwQfW06UITaIeUib3yy1nMGCKSuWgIZJY0lb0zHMGdIcSjXxSEhEPULCcJMCibzwmqKibJa4Ub8dQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;事件驱动型应用无须查询远程数据库，本地数据访问使得它具有更高的吞吐和更低的延迟，以反欺诈案例来看，DataDriven把处理的规则模型写到DatastreamAPI中，然后将整个逻辑抽象到Flink引擎，当事件或者数据流入就会触发相应的规则模型，一旦触发规则中的条件后，DataDriven会快速处理并对业务应用进行通知。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Data Analytics&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.2578125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBJkwQfW06UITaIeUib3yy1nPh29LjWATr5mVamMl1kUFicZhvznOdp9OBLSYb98XM9wlBGykuhEcPQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;和批量分析相比，由于流式分析省掉了周期性的数据导入和查询过程，因此从事件中获取指标的延迟更低。不仅如此，批量查询必须处理那些由定期导入和输入有界性导致的人工数据边界，而流式查询则无须考虑该问题，Flink为持续流式分析和批量分析都提供了良好的支持，实时处理分析数据，应用较多的场景如实时大屏、实时报表。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Data Pipeline&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.2203125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBJkwQfW06UITaIeUib3yy1ngXfIESX1UGZBYHQFv7oMfec2YwwgJ2cZ3Okwe14j7O332IY1ic2aSIA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;与周期性的ETL作业任务相比，持续数据管道可以明显降低将数据移动到目的端的延迟，例如基于上游的StreamETL进行实时清洗或扩展数据，可以在下游构建实时数仓，确保数据查询的时效性，形成高时效的数据查询链路，这种场景在媒体流的推荐或者搜索引擎中十分常见。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;二、环境部署&lt;/span&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;1、安装包管理&lt;/span&gt;&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;[root@hop01 opt]&lt;/span&gt;# &lt;span&gt;tar&lt;/span&gt; &lt;span&gt;-zxvf&lt;/span&gt; &lt;span&gt;flink-1&lt;/span&gt;&lt;span&gt;.7&lt;/span&gt;&lt;span&gt;.0-bin-hadoop27-scala_2&lt;/span&gt;&lt;span&gt;.11&lt;/span&gt;&lt;span&gt;.tgz&lt;/span&gt;&lt;br/&gt;&lt;span&gt;[root@hop02 opt]&lt;/span&gt;# &lt;span&gt;mv&lt;/span&gt; &lt;span&gt;flink-1&lt;/span&gt;&lt;span&gt;.7&lt;/span&gt;&lt;span&gt;.0&lt;/span&gt; &lt;span&gt;flink1&lt;/span&gt;&lt;span&gt;.7&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;&lt;span&gt;2、集群配置&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;管理节点&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 opt]&lt;span&gt;# cd /opt/flink1.7/conf&lt;/span&gt;&lt;br/&gt;[root@hop01 conf]&lt;span&gt;# vim flink-conf.yaml&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;jobmanager.rpc.address: hop01&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;分布节点&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 conf]&lt;span&gt;# vim slaves&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;hop02&lt;br/&gt;hop03&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;两个配置同步到所有集群节点下面。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;3、启动与停止&lt;/span&gt;&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;/opt/flink1.7/bin/&lt;span&gt;start&lt;/span&gt;-cluster.sh&lt;br/&gt;/opt/flink1&lt;span&gt;.7&lt;/span&gt;/&lt;span&gt;bin&lt;/span&gt;/&lt;span&gt;stop&lt;/span&gt;-cluster.sh&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动日志：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 conf]&lt;span&gt;# /opt/flink1.7/bin/start-cluster.sh&lt;/span&gt;&lt;br/&gt;Starting cluster.&lt;br/&gt;Starting standalonesession daemon &lt;span&gt;on&lt;/span&gt; host hop01.&lt;br/&gt;Starting taskexecutor daemon &lt;span&gt;on&lt;/span&gt; host hop02.&lt;br/&gt;Starting taskexecutor daemon &lt;span&gt;on&lt;/span&gt; host hop03.&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;&lt;span&gt;4、Web界面&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;访问：&lt;code&gt;http://hop01:8081/&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.3953125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBJkwQfW06UITaIeUib3yy1nH54vjEkicM2IC2icxFIAyd3wFdBic71icjUicMprymSoFcpjVj0POnicVZDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;三、开发入门案例&lt;/span&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;1、数据脚本&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;分发一个数据脚本到各个节点：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;/var/flink/&lt;span&gt;test&lt;/span&gt;/word.txt&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;&lt;span&gt;2、引入基础依赖&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;这里基于Java写的基础案例。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;&lt;span&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&amp;lt;&lt;span&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.apache.flink&lt;span&gt;&amp;lt;/&lt;span&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;flink-java&lt;span&gt;&amp;lt;/&lt;span&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.7.0&lt;span&gt;&amp;lt;/&lt;span&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&amp;lt;/&lt;span&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&amp;lt;&lt;span&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.apache.flink&lt;span&gt;&amp;lt;/&lt;span&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;flink-streaming-java_2.11&lt;span&gt;&amp;lt;/&lt;span&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.7.0&lt;span&gt;&amp;lt;/&lt;span&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&amp;lt;/&lt;span&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;dependencies&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;&lt;span&gt;3、读取文件数据&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;这里直接读取文件中的数据，经过程序流程分析出每个单词出现的次数。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;WordCount&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;// 读取文件数据&lt;/span&gt;&lt;br/&gt;        readFile () ;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;readFile&lt;/span&gt; &lt;span&gt;()&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;// 1、执行环境创建&lt;/span&gt;&lt;br/&gt;        ExecutionEnvironment environment = ExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 2、读取数据文件&lt;/span&gt;&lt;br/&gt;        String filePath = &lt;span&gt;&quot;/var/flink/test/word.txt&quot;&lt;/span&gt; ;&lt;br/&gt;        DataSet&amp;lt;String&amp;gt; inputFile = environment.readTextFile(filePath);&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 3、分组并求和&lt;/span&gt;&lt;br/&gt;        DataSet&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; wordDataSet = inputFile.flatMap(&lt;span&gt;new&lt;/span&gt; WordFlatMapFunction(&lt;br/&gt;        )).groupBy(&lt;span&gt;0&lt;/span&gt;).sum(&lt;span&gt;1&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 4、打印处理结果&lt;/span&gt;&lt;br/&gt;        wordDataSet.print();&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// 数据读取个切割方式&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;static&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;WordFlatMapFunction&lt;/span&gt; &lt;span&gt;implements&lt;/span&gt; &lt;span&gt;FlatMapFunction&lt;/span&gt;&amp;lt;&lt;span&gt;String&lt;/span&gt;, &lt;span&gt;Tuple2&lt;/span&gt;&amp;lt;&lt;span&gt;String&lt;/span&gt;, &lt;span&gt;Integer&lt;/span&gt;&amp;gt;&amp;gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;flatMap&lt;/span&gt;&lt;span&gt;(String input, Collector&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; collector)&lt;/span&gt;&lt;/span&gt;{&lt;br/&gt;            String[] wordArr = input.split(&lt;span&gt;&quot;,&quot;&lt;/span&gt;);&lt;br/&gt;            &lt;span&gt;for&lt;/span&gt; (String word : wordArr) {&lt;br/&gt;                collector.collect(&lt;span&gt;new&lt;/span&gt; Tuple2&amp;lt;&amp;gt;(word, &lt;span&gt;1&lt;/span&gt;));&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4806201550387597&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBJkwQfW06UITaIeUib3yy1n0fOJ6MU6WJAt47WiaNeJTwRibUUvCSnuu4UaWW8v1BJniaiaMckYQ6nMEQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;774&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;4、读取端口数据&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;在hop01服务上创建一个端口，并模拟一些数据发送到该端口：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 ~]&lt;span&gt;# nc -lk 5566&lt;/span&gt;&lt;br/&gt;c++,java&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过Flink程序读取并分析该端口的数据内容：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;WordCount&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;// 读取端口数据&lt;/span&gt;&lt;br/&gt;        readPort ();&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;readPort&lt;/span&gt; &lt;span&gt;()&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;// 1、执行环境创建&lt;/span&gt;&lt;br/&gt;        StreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 2、读取Socket数据端口&lt;/span&gt;&lt;br/&gt;        DataStreamSource&amp;lt;String&amp;gt; inputStream = environment.socketTextStream(&lt;span&gt;&quot;hop01&quot;&lt;/span&gt;, &lt;span&gt;5566&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 3、数据读取个切割方式&lt;/span&gt;&lt;br/&gt;        SingleOutputStreamOperator&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; resultDataStream = inputStream.flatMap(&lt;br/&gt;                &lt;span&gt;new&lt;/span&gt; FlatMapFunction&amp;lt;String, Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt;()&lt;br/&gt;        {&lt;br/&gt;            &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;flatMap&lt;/span&gt;&lt;span&gt;(String input, Collector&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; collector)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;                String[] wordArr = input.split(&lt;span&gt;&quot;,&quot;&lt;/span&gt;);&lt;br/&gt;                &lt;span&gt;for&lt;/span&gt; (String word : wordArr) {&lt;br/&gt;                    collector.collect(&lt;span&gt;new&lt;/span&gt; Tuple2&amp;lt;&amp;gt;(word, &lt;span&gt;1&lt;/span&gt;));&lt;br/&gt;                }&lt;br/&gt;            }&lt;br/&gt;        }).keyBy(&lt;span&gt;0&lt;/span&gt;).sum(&lt;span&gt;1&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 4、打印分析结果&lt;/span&gt;&lt;br/&gt;        resultDataStream.print();&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 5、环境启动&lt;/span&gt;&lt;br/&gt;        environment.execute();&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h1&gt;&lt;span&gt;四、运行机制&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.57890625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBJkwQfW06UITaIeUib3yy1nt4DVlGFdZjnwnOOp2WKHGaNic26HSvYAgQiboXp43vQ2krznubQyKjuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;FlinkClient&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;客户端用来准备和发送数据流到JobManager节点，之后根据具体需求，客户端可以直接断开连接，或者维持连接状态等待任务处理结果。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;JobManager&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在Flink集群中，会启动一个JobManger节点和至少一个TaskManager节点，JobManager收到客户端提交的任务后，JobManager会把任务协调下发到具体的TaskManager节点去执行，TaskManager节点将心跳和处理信息发送给JobManager。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;TaskManager&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;任务槽（slot）是TaskManager中最小的资源调度单位，在启动的时候就设置好了槽位数，每个槽位能启动一个Task，接收JobManager节点部署的任务，并进行具体的分析处理。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;五、源代码地址&lt;/span&gt;&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;GitHub·地址&lt;br/&gt;https:&lt;span&gt;//github.com/cicadasmile/big-data-parent&lt;/span&gt;&lt;br/&gt;GitEE·地址&lt;br/&gt;https:&lt;span&gt;//gitee.com/cicadasmile/big-data-parent&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU4Njg0MzYwNw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBCuF3zfJnqPKpUia4wfn1FUtTHpxxkR5HvbicPgOjibPicX0goMOkny1NdkLAJvBaqrYh3UdwMjiaDQMA/0?wx_fmt=png&quot; data-nickname=&quot;知了一笑&quot; data-alias=&quot;cicada_smile&quot; data-signature=&quot;积累是一个孤独且枯燥的过程&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>3cf12a636de5a263b8fb5d6e19b354dc</guid>
<title>Redis 技术专题系列之数据同步持久化机制</title>
<link>https://toutiao.io/k/5wy35j7</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;content&quot;&gt;
                                                                                                                                                                                        &lt;h1&gt;📚背景介绍&lt;/h1&gt; 
&lt;h4&gt;✒️ Redis数据恢复的介绍&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;通常情况下redis的数据全部存储在内存中，数据库一旦故障发生重启数据会全部丢失&lt;/strong&gt;，&lt;strong&gt;持久化功能在于能够有效地避免因进程退出造成的数据丢失问题&lt;/strong&gt;，&lt;strong&gt;在下次重启时利用之前持久化的文件即可实现数据恢复。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;✒️ Redis高可用的功能基础&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;即使是在redis cluster或者redis sentinel模式下主从同步数据的恢复仍然需要一段时间。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;✒️ Redis实际场景的分析&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;开启Redis持久化之后，数据将存放到磁盘中，数据库执行增量同步的时间要远小于全量同步&lt;/strong&gt;。&lt;strong&gt;在生产环境下故障的数据恢复有着非常重要的作用！&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-7747c7fe4ca5a234bc0b46a05d1af84a955.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;h1&gt;📚前提概要&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Redis是出了名的速度快，那是因为在内存中进行数据存储和操作；如果仅仅是在内存中进行数据存储，那就会导致以下问题&lt;/strong&gt;：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;数据随进程退出而消失&lt;/strong&gt;：&lt;strong&gt;当服务器断电或Redis Server进程退出时，内存肯定随之释放，最后数据也会丢失&lt;/strong&gt;；&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;有些小伙伴认为只是作为缓存，数据没有了，重新从数据库中读取放在里面即可，试想，如果是高并发场景，数据库岂不是压力很大；&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;重要数据无法恢复：数据丢失之后无法进行恢复，对于一些重要的数据，只是存在Redis中，而没有存在关系型数据库，如果数据丢失便不可恢复；比如刷礼品排行榜，如果数据丢失，用户肯定不愿意的&lt;/strong&gt;；&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;对于Redis持久化在工作中和面试过程中是一个很重要的技术点，必用必考，接下来详细说说Redis持久化；&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;📚 基本介绍&lt;/h1&gt; 
&lt;h2&gt;✒️ Redis持久化有两种方案&lt;/h2&gt; 
 
&lt;h2&gt;✒️ Redis持久化机制实现&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Redis是基于内存进行操作运算，如果不持久化数据再重启服务时会导致数据丢失&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;开启Redis持久化功能后，数据会保存到磁盘中。当redis重启后，可以从磁盘中恢复数据。&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;✒️ RDB快照（snapshot）&lt;/h3&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-d31583957047ebabeb0f96fcd2e348d13ae.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;h3&gt;✒️ RDB持久化方式&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;RDB持久化把当前进程数据生成快照（.rdb）文件保存到硬盘的过程，有手动触发和自动触发。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;✒️ RDB手动触发&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;手动触发有save和bgsave两命令&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h5&gt;✒️ save命令&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;该命令会阻塞当前Redis服务器，执行save命令期间，Redis不能处理其他命令，直到RDB过程完成为止&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;执行完成时候如果存在老的RDB文件，就把新的替代掉旧的。我们的客户端可能都是几万或者是几十万，这种方式显然不可取。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-a08822d0dbe6a331cfa1f573c50e1251760.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;在执行redis-cli shutdown关闭redis服务时，如果没有开启AOF持久化，自动执行save&lt;/strong&gt;。&lt;/p&gt; 
&lt;h5&gt;✒️ bgsave命令&lt;/h5&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Redis主进程fork一个子进程来创建临时RDB存储文件&lt;/strong&gt;，&lt;strong&gt;创建文件完成后对这个临时文件rename替换原先的RDB文件&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;RDB文件是一个单文件很适合数据的容灾备份与恢复&lt;/strong&gt;，&lt;strong&gt;通过RDB文件恢复数据库耗时较短&lt;/strong&gt;，&lt;strong&gt;通常1G的快照文件载入内存只需20s左右&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-4487fc30e2f75205c44b70c718137d07cca.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;h5&gt;✒️ bgsave命令和save命令&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;命令名称&lt;/th&gt; 
   &lt;th&gt;save&lt;/th&gt; 
   &lt;th&gt;bgsave&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;IO类型&lt;/td&gt; 
   &lt;td&gt;同步&lt;/td&gt; 
   &lt;td&gt;异步&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;是否阻塞&lt;/td&gt; 
   &lt;td&gt;是&lt;/td&gt; 
   &lt;td&gt;否&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;复杂度&lt;/td&gt; 
   &lt;td&gt;O(n)&lt;/td&gt; 
   &lt;td&gt;O(n)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;优点&lt;/td&gt; 
   &lt;td&gt;不会耗费额外内存&lt;/td&gt; 
   &lt;td&gt;不阻塞客户端访问&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;缺点&lt;/td&gt; 
   &lt;td&gt;阻塞客户端访问&lt;/td&gt; 
   &lt;td&gt;耗费多余客户端&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;在指定时间间隔内将内存中的数据库记录集dump到磁盘上&lt;/strong&gt;，RDB是默认的持久化方式，&lt;strong&gt;这种方式是就是将内存中数据以快照的方式写入到二进制文件中&lt;/strong&gt;,&lt;strong&gt;默认的文件名为dump.rdb&lt;/strong&gt;。&lt;/p&gt; 
&lt;h4&gt;✒️ RDB自动触发&lt;/h4&gt; 
&lt;p&gt;自动触发是由我们的配置文件来完成的，自动触发bgsave。&lt;/p&gt; 
&lt;h5&gt;✒️ 配置方法&lt;/h5&gt; 
 
&lt;h6&gt;✒️ 60秒内至少有10000个键被修改&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;save 900 1&lt;/strong&gt; #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;save 300 10&lt;/strong&gt; #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;save 60 10000&lt;/strong&gt; #在60秒(1分钟)之后，如果至少有10000个key发生变化，dump内存快照。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;关闭RDB方式持久化只需要将所有save保存策略注释掉即可&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h5&gt;✒️ RDB持久化命令&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;命令：&lt;strong&gt;config set dir /usr/local&lt;/strong&gt; //设置rdb文件保存路径&lt;/li&gt; 
 &lt;li&gt;备份：&lt;strong&gt;bgsave&lt;/strong&gt; //将dump.rdb保存到usr/local下&lt;/li&gt; 
 &lt;li&gt;恢复：&lt;strong&gt;将dump.rdb放到redis安装目录与redis.conf同级目录，重启redis即可&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;save命令是同步命令，bgsave命令是异步命令，会从redis主进程fork出一个子进程去处理，每次命令执行后会新生成一个rdb文件并覆盖原来的文件。&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;✒️ 修改配置&lt;/h3&gt; 
 
&lt;h2&gt;✒️ RDB的优缺点&lt;/h2&gt; 
&lt;h3&gt;✒️ 优点&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;（恢复速度快，适合大数量恢复机制）&lt;strong&gt;RDB保存的是某一个时间点的内存快照，非常适合灾难恢复。在恢复大数据集时速度快，1G的RDB数据恢复耗时大概20s，比AOF要快的多&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;✒️ 缺点&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;（间隔时间大并且丢失数据较为多）&lt;strong&gt;RDB通过触发某个时间点条件生成快照文件，如果5分钟保存一次的话，一旦发生故障会丢失好几分钟的数据&lt;/strong&gt;，&lt;strong&gt;配置不同的保存点让RDB至少可以保存5分钟的数据&lt;/strong&gt;。因此，如果Redis由于任何原因没有正确关闭而停止工作，你应该做好好丢失最近几分钟的数据&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;（CPU资源占用过大、内存资源占用过多）&lt;strong&gt;fork子进程消耗内存和CPU&lt;/strong&gt;，RDB经常需要 &lt;strong&gt;fork()&lt;/strong&gt; 才能使用子进程在磁盘上持久化。如果数据集很大，&lt;strong&gt;fork()可能很耗时，如果数据集非常大，CPU性能不好&lt;/strong&gt;，&lt;strong&gt;可能会导致Redis停止为客户机服务几毫秒甚至一秒钟。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;✒️ AOF(append-only file)&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-dff29886ab8ab80fa9edd079cb360ff1ac1.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;由于RDB快照方式的缺点，如果redis由于某些原因导致机器故障时，则会丢失最近几分钟写入的数据，而AOF持久化方式&lt;/strong&gt;，则通过追加的方式将操作命令添加到&lt;strong&gt;appendonly.aof&lt;/strong&gt;文件中，存储的文件是RESP协议指令文件。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-b17e8e5cb10a3fb9b41fd53b2e809e896c2.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;h3&gt;✒️ 配置方法&lt;/h3&gt; 
 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;配置好后，redis每次修改操作的命令会追加到AOF末尾，当redis重启后会重新执行AOF里的命令达到重建缓存数据集的目的，配置刷命令的频率&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;appendfsync always&lt;/strong&gt; ：&lt;strong&gt;每次有新命令追加到AOF文件时就执行一次fsync&lt;/strong&gt;，非常慢但最安全。服务器在每执行一个事件就把AOF缓冲区的内容强制性的写入硬盘上的AOF文件里，保证了数据持久化的完整性，效率是最慢的但最安全的；&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;appendfsync everysec&lt;/strong&gt; # &lt;strong&gt;服务端每隔一秒才会进行一次文件同步把内存缓冲区里的AOF缓存数据真正写入AOF文件里，兼顾了效率和完整性，极端情况服务器宕机只会丢失一秒内对Redis数据库的写操作；默认方式&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;appendfsync no&lt;/strong&gt; # &lt;strong&gt;从不fsync&lt;/strong&gt;，&lt;strong&gt;交由操作系统处理，速度快，表示默认系统的缓存区写入磁盘的机制，不做程序强制，数据安全性和完整性差一些。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr/&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;bgrewriteaof：后台运作重写机制&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;auto-aof-rewrite-min-size 64mb&lt;/strong&gt; # &lt;strong&gt;aof文件至少要达到64M才会自动重写，文件太小恢复速度本来就很快，重写的意义不大&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;auto-aof-rewrite-percentage 100&lt;/strong&gt; # &lt;strong&gt;aof文件自上一次重写后文件大小增长了100%，则再次触发重写执行bgrewriteaof命令可以手动重写aof文件，AOF重写redis会fork出一个子进程去做，不会对redis正常命令处理有太多影响。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr/&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;redis启动时如果既有rdb文件又有aof文件则优先选择aof文件恢复数据，因为aof一般来说数据更全一点。&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;全量同步(RDB)：每天定时（避开高峰期）或者采用一个周期实现将数据拷贝到一个地方&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;增量同步(AOF)：比如采用对行为的操作实现对数据的同步。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;增量同步比全量同步更加消耗服务器的内存，但是能够更加的保证数据的同步&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;📚 AOF的优缺点&lt;/h1&gt; 
&lt;h2&gt;✒️ 优点&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;AOF是通过保存Redis写操作的命令来实现持久化，使用AOF来持久化，Redis数据的安全性将大幅提高，异常宕机情况下最多丢失1s的数据。AOF文件记录了redis的写操作，格式清晰，易于理解和修改，利于数据的重建。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;AOF日志是一个只附加的日志，因此如果断电，就不会出现查找或损坏问题。即使日志由于某种原因（磁盘已满或其他原因）以半写的命令结束，redis check aof工具也可以轻松地修复它。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;当AOF太大时，Redis能够在后台自动重写AOF。重写是完全安全的，因为当Redis继续附加到旧文件时，一个全新的文件会生成，只需创建当前数据集所需的最少操作集，一旦第二个文件就绪，Redis就会切换这两个文件并开始附加到新文件中。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;AOF以易于理解和解析的格式包含所有操作的日志。你甚至可以轻松导出AOF文件。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;✒️ 缺点&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AOF文件通常比相同数据集的等效RDB文件大&lt;/strong&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;根据具体的fsync策略，AOF可能比RDB慢。&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;使用建议&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Redis默认开启了持久化功能，而且是全量RDB的，缺点是服务器宕机后可能会造成数据丢失。 建议最好还是搭配使用aof的everysec，&lt;strong&gt;既能够保证数据的同步,效率也还可以，但是会存在丢失一秒数据的可能性，就算丢失也关系不大&lt;/strong&gt;，因为数据库中已经存在了数据。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;混合持久化&lt;/h2&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-51c15feb96051f9791369fc4aec0c0515d6.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;如果开启了混合持久化，AOF在重写时，不再是单纯将内存数据转换为RESP命令写入AOF文件，而是将重写这一刻之前的内存做RDB快照处理，并且将RDB快照内容和增量的AOF修改内存数据的命令存在一起，都写入新的AOF文件，新的AOF文件会原子覆盖掉原来的AOF文件&lt;/strong&gt;。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;开启混合持久化命令&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;aof-use-rdb-preamble yes # 开启混合持久化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;appendonly.aof文件中同时保存着RDB和AOF两种格式的数据&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;RDB、AOF、混合持久化对比&lt;/h4&gt; 
&lt;p&gt;&lt;img src=&quot;https://oscimg.oschina.net/oscnet/up-8937fc5d21bbb6eac0d3905d3a66005e120.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
                                        &lt;/div&gt;
                                    &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>798a3c075d50adb791b541e23e944d48</guid>
<title>为什么 Go map 和 slice 是非线性安全的？</title>
<link>https://toutiao.io/k/euwldfo</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，我是煎鱼。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;初入 Go 语言的大门，有不少的小伙伴会快速的 3 天精通 Go，5 天上手项目，14 天上线业务迭代，21 天排查、定位问题，顺带捎个反省报告。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中最常见的初级错误，Go 面试较最爱问的问题之一：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.1726315789473684&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KVl0giak5ib4jmWIKV9zRh7fFAeicnSpYHljzkK4qPzpxlYcPZBWLAQGskD5DIba8PDQgAOiaH4Pol3uVZjkgYJdqw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;950&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么在 Go 语言里，map 和 slice 不支持并发读写，也就是是非线性安全的，为什么不支持？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;见招拆招后，紧接着就会开始讨论如何让他们俩 ”冤家“ 支持并发读写？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天我们这篇文章就来理一理，了解其前因后果，一起吸鱼学懂 Go 语言。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;非线性安全的例子&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;slice&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们使用多个 goroutine 对类型为 slice 的变量进行操作，看看结果会变的怎么样。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;var&lt;/span&gt; s []&lt;span&gt;string&lt;/span&gt;&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;9999&lt;/span&gt;; i++ {&lt;br/&gt;  &lt;span&gt;go&lt;/span&gt; &lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;   s = &lt;span&gt;append&lt;/span&gt;(s, &lt;span&gt;&quot;脑子进煎鱼了&quot;&lt;/span&gt;)&lt;br/&gt;  }()&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt; fmt.Printf(&lt;span&gt;&quot;进了 %d 只煎鱼&quot;&lt;/span&gt;, &lt;span&gt;len&lt;/span&gt;(s))&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输出结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;// 第一次执行&lt;br/&gt;进了 5790 只煎鱼&lt;br/&gt;// 第二次执行&lt;br/&gt;进了 7370 只煎鱼&lt;br/&gt;// 第三次执行&lt;br/&gt;进了 6792 只煎鱼&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你会发现无论你执行多少次，每次输出的值大概率都不会一样。也就是追加进 slice 的值，出现了覆盖的情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此在循环中所追加的数量，与最终的值并不相等。且这种情况，是不会报错的，是一个出现率不算高的隐式问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个产生的主要原因是程序逻辑本身就有问题，同时读取到相同索引位，自然也就会产生覆盖的写入了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;map&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同样针对 map 也如法炮制一下。重复针对类型为 map 的变量进行写入。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; s := &lt;span&gt;make&lt;/span&gt;(&lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;string&lt;/span&gt;)&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;99&lt;/span&gt;; i++ {&lt;br/&gt;  &lt;span&gt;go&lt;/span&gt; &lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;   s[&lt;span&gt;&quot;煎鱼&quot;&lt;/span&gt;] = &lt;span&gt;&quot;吸鱼&quot;&lt;/span&gt;&lt;br/&gt;  }()&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt; fmt.Printf(&lt;span&gt;&quot;进了 %d 只煎鱼&quot;&lt;/span&gt;, &lt;span&gt;len&lt;/span&gt;(s))&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输出结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;fatal error: concurrent map writes&lt;br/&gt;&lt;br/&gt;goroutine 18 [running]:&lt;br/&gt;runtime.throw(0x10cb861, 0x15)&lt;br/&gt;        /usr/&lt;span&gt;local&lt;/span&gt;/Cellar/go/1.16.2/libexec/src/runtime/panic.go:1117 +0x72 fp=0xc00002e738 sp=0xc00002e708 pc=0x1032472&lt;br/&gt;runtime.mapassign_faststr(0x10b3360, 0xc0000a2180, 0x10c91da, 0x6, 0x0)&lt;br/&gt;        /usr/&lt;span&gt;local&lt;/span&gt;/Cellar/go/1.16.2/libexec/src/runtime/map_faststr.go:211 +0x3f1 fp=0xc00002e7a0 sp=0xc00002e738 pc=0x1011a71&lt;br/&gt;main.main.func1(0xc0000a2180)&lt;br/&gt;        /Users/eddycjy/go-application/awesomeProject/main.go:9 +0x4c fp=0xc00002e7d8 sp=0xc00002e7a0 pc=0x10a474c&lt;br/&gt;runtime.goexit()&lt;br/&gt;        /usr/&lt;span&gt;local&lt;/span&gt;/Cellar/go/1.16.2/libexec/src/runtime/asm_amd64.s:1371 +0x1 fp=0xc00002e7e0 sp=0xc00002e7d8 pc=0x1063fe1&lt;br/&gt;created by main.main&lt;br/&gt;        /Users/eddycjy/go-application/awesomeProject/main.go:8 +0x55&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好家伙，程序运行会直接报错。并且是 Go 源码调用 &lt;code&gt;throw&lt;/code&gt; 方法所导致的致命错误，也就是说 Go 进程会中断。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不得不说，这个并发写 map 导致的 &lt;code&gt;fatal error: concurrent map writes&lt;/code&gt; 错误提示。我有一个朋友，已经看过少说几十次了，不同组，不同人...&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;是个日经的隐式问题。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;如何支持并发读写&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;对 map 上锁&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实际上我们仍然存在并发读写 map 的诉求（程序逻辑决定），因为 Go 语言中的 goroutine 实在是太方便了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;像是一般写爬虫任务时，基本会用到多个 goroutine，获取到数据后再写入到 map 或者 slice 中去。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go 官方在 Go maps in action 中提供了一种简单又便利的方式来实现：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;var&lt;/span&gt; counter = &lt;span&gt;struct&lt;/span&gt;{&lt;br/&gt;    sync.RWMutex&lt;br/&gt;    m &lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;int&lt;/span&gt;&lt;br/&gt;}{m: &lt;span&gt;make&lt;/span&gt;(&lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;int&lt;/span&gt;)}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这条语句声明了一个变量，它是一个匿名结构（struct）体，包含一个原生和一个嵌入读写锁 &lt;code&gt;sync.RWMutex&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要想从变量中中读出数据，则调用读锁：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;counter.RLock()&lt;br/&gt;n := counter.m[&lt;span&gt;&quot;煎鱼&quot;&lt;/span&gt;]&lt;br/&gt;counter.RUnlock()&lt;br/&gt;fmt.Println(&lt;span&gt;&quot;煎鱼:&quot;&lt;/span&gt;, n)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要往变量中写数据，则调用写锁：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;counter.Lock()&lt;br/&gt;counter.m[&lt;span&gt;&quot;煎鱼&quot;&lt;/span&gt;]++&lt;br/&gt;counter.Unlock()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这就是一个最常见的 Map 支持并发读写的方式了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;sync.Map&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;前言&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然有了 Map+Mutex 的极简方案，但是也仍然存在一定问题。那就是在 map 的数据量非常大时，只有一把锁（Mutex）就非常可怕了，一把锁会导致大量的争夺锁，导致各种冲突和性能低下。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;常见的解决方案是分片化，将一个大 map 分成多个区间，各区间使用多个锁，这样子锁的粒度就大大降低了。不过该方案实现起来很复杂，很容易出错。因此 Go 团队到比较为止暂无推荐，而是采取了其他方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该方案就是在 Go1.9 起支持的 &lt;code&gt;sync.Map&lt;/code&gt;，其支持并发读写 map，起到一个补充的作用。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;具体介绍&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go 语言的 &lt;code&gt;sync.Map&lt;/code&gt; 支持并发读写 map，采取了 “空间换时间” 的机制，冗余了两个数据结构，分别是：read 和 dirty，减少加锁对性能的影响：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; Map &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt; mu Mutex&lt;br/&gt; read atomic.Value &lt;span&gt;// readOnly&lt;/span&gt;&lt;br/&gt; dirty &lt;span&gt;map&lt;/span&gt;[&lt;span&gt;interface&lt;/span&gt;{}]*entry&lt;br/&gt; misses &lt;span&gt;int&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其是专门为 &lt;code&gt;append-only&lt;/code&gt; 场景设计的，也就是适合读多写少的场景。这是他的优点之一。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;若出现写多/并发多的场景，会导致 read map 缓存失效，需要加锁，冲突变多，性能急剧下降。这是他的重大缺点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提供了以下常用方法：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(m *Map)&lt;/span&gt; &lt;span&gt;Delete&lt;/span&gt;&lt;span&gt;(key &lt;span&gt;interface&lt;/span&gt;{})&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(m *Map)&lt;/span&gt; &lt;span&gt;Load&lt;/span&gt;&lt;span&gt;(key &lt;span&gt;interface&lt;/span&gt;{})&lt;/span&gt; &lt;span&gt;(value &lt;span&gt;interface&lt;/span&gt;{}, ok &lt;span&gt;bool&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(m *Map)&lt;/span&gt; &lt;span&gt;LoadAndDelete&lt;/span&gt;&lt;span&gt;(key &lt;span&gt;interface&lt;/span&gt;{})&lt;/span&gt; &lt;span&gt;(value &lt;span&gt;interface&lt;/span&gt;{}, loaded &lt;span&gt;bool&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(m *Map)&lt;/span&gt; &lt;span&gt;LoadOrStore&lt;/span&gt;&lt;span&gt;(key, value &lt;span&gt;interface&lt;/span&gt;{})&lt;/span&gt; &lt;span&gt;(actual &lt;span&gt;interface&lt;/span&gt;{}, loaded &lt;span&gt;bool&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(m *Map)&lt;/span&gt; &lt;span&gt;Range&lt;/span&gt;&lt;span&gt;(f &lt;span&gt;func&lt;/span&gt;(key, value &lt;span&gt;interface&lt;/span&gt;{})&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt;)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(m *Map)&lt;/span&gt; &lt;span&gt;Store&lt;/span&gt;&lt;span&gt;(key, value &lt;span&gt;interface&lt;/span&gt;{})&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Delete：删除某一个键的值。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Load：返回存储在 map 中的键的值，如果没有值，则返回 nil。ok 结果表示是否在 map 中找到了值。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;LoadAndDelete：删除一个键的值，如果有的话返回之前的值。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;LoadOrStore：如果存在的话，则返回键的现有值。否则，它存储并返回给定的值。如果值被加载，加载的结果为 true，如果被存储，则为 false。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Range：递归调用，对 map 中存在的每个键和值依次调用闭包函数 &lt;code&gt;f&lt;/code&gt;。如果 &lt;code&gt;f&lt;/code&gt; 返回 false 就停止迭代。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Store：存储并设置一个键的值。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实际运行例子如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;var&lt;/span&gt; m sync.Map&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;//写入&lt;/span&gt;&lt;br/&gt; data := []&lt;span&gt;string&lt;/span&gt;{&lt;span&gt;&quot;煎鱼&quot;&lt;/span&gt;, &lt;span&gt;&quot;咸鱼&quot;&lt;/span&gt;, &lt;span&gt;&quot;烤鱼&quot;&lt;/span&gt;, &lt;span&gt;&quot;蒸鱼&quot;&lt;/span&gt;}&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;4&lt;/span&gt;; i++ {&lt;br/&gt;  &lt;span&gt;go&lt;/span&gt; &lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;(i &lt;span&gt;int&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;   m.Store(i, data[i])&lt;br/&gt;  }(i)&lt;br/&gt; }&lt;br/&gt; time.Sleep(time.Second)&lt;br/&gt;&lt;br/&gt; &lt;span&gt;//读取&lt;/span&gt;&lt;br/&gt; v, ok := m.Load(&lt;span&gt;0&lt;/span&gt;)&lt;br/&gt; fmt.Printf(&lt;span&gt;&quot;Load: %v, %v\n&quot;&lt;/span&gt;, v, ok)&lt;br/&gt;&lt;br/&gt; &lt;span&gt;//删除&lt;/span&gt;&lt;br/&gt; m.Delete(&lt;span&gt;1&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt; &lt;span&gt;//读或写&lt;/span&gt;&lt;br/&gt; v, ok = m.LoadOrStore(&lt;span&gt;1&lt;/span&gt;, &lt;span&gt;&quot;吸鱼&quot;&lt;/span&gt;)&lt;br/&gt; fmt.Printf(&lt;span&gt;&quot;LoadOrStore: %v, %v\n&quot;&lt;/span&gt;, v, ok)&lt;br/&gt;&lt;br/&gt; &lt;span&gt;//遍历&lt;/span&gt;&lt;br/&gt; m.Range(&lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;(key, value &lt;span&gt;interface&lt;/span&gt;{})&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;  fmt.Printf(&lt;span&gt;&quot;Range: %v, %v\n&quot;&lt;/span&gt;, key, value)&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;br/&gt; })&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输出结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;Load: 煎鱼, &lt;span&gt;true&lt;/span&gt;&lt;br/&gt;LoadOrStore: 吸鱼, &lt;span&gt;false&lt;/span&gt;&lt;br/&gt;Range: 0, 煎鱼&lt;br/&gt;Range: 1, 吸鱼&lt;br/&gt;Range: 3, 蒸鱼&lt;br/&gt;Range: 2, 烤鱼&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;为什么不支持&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go Slice 的话，主要还是索引位覆写问题，这个就不需要纠结了，势必是程序逻辑在编写上有明显缺陷，自行改之就好。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但 Go map 就不大一样了，很多人以为是默认支持的，一个不小心就翻车，这么的常见。那凭什么 Go 官方还不支持，难不成太复杂了，性能太差了，到底是为什么？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;原因如下（via @go faq）：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;典型使用场景：map 的典型使用场景是不需要从多个 goroutine 中进行安全访问。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;非典型场景（需要原子操作）：map 可能是一些更大的数据结构或已经同步的计算的一部分。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;性能场景考虑：若是只是为少数程序增加安全性，导致 map 所有的操作都要处理 mutex，将会降低大多数程序的性能。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;汇总来讲，就是 Go 官方在经过了长时间的讨论后，认为 Go map 更应适配典型使用场景，而不是为了小部分情况，导致大部分程序付出代价（性能），决定了不支持。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在今天这篇文章中，我们针对 Go 语言中的 map 和 slice 进行了基本的介绍，也对不支持并发读者的场景进行了模拟展示。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同时也针对业内常见的支持并发读写的方式进行了讲述，最后分析了不支持的原因，让我们对整个前因后果有了一个完整的了解。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不知道你&lt;strong&gt;在日常是否有遇到过 Go 语言中非线性安全的问题呢，欢迎你在评论区留言和大家一起交流&lt;/strong&gt;！&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>0baf183864ce091273c574f0fa4b43e0</guid>
<title>Go 实现一个 JS 解释器</title>
<link>https://toutiao.io/k/4c58qqk</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;豆皮粉儿们，大家好呀。愉快的五一节就这么过去了，假期有没有好好游玩一番呢。今天给大家由 给大家讲解，如何用go实现一个js解释器。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;作者：&lt;span&gt;清风慕竹&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h1&gt;背景&lt;/h1&gt;&lt;p&gt;前段时间在开发版本发布系统过程中，为了追求系统的灵活性，我们允许用户通过写js的方式生成json配置，业务上有定制的需求可以通过js代码来实现，这样在不调整底层系统的情况下可以尽可能的支持业务中的个性化需求。由于发布系统是用golang开发的，所以这里需要一个go版本的js解释器（不需要考虑gc、jit、inline-cache等复杂内容，只是一个简单的解释器的实现，可以解析并执行js即可），能够在golang应用中安全的运行&lt;code&gt;js&lt;/code&gt;代码。&lt;/p&gt;&lt;h1&gt;实现思路&lt;/h1&gt;&lt;p&gt;关于js解释器的实现其实已经有很多版本了，比如tinyjs(c++版本的实现)、tinyjs.py(py版本的实现)、还有若干用js自举实现的版本，比如eval5 。这些解释器实现思路大致如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6050283860502839&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjy7HtlrSAxlXVib30VtPCDXlEL8ur3eF0fMclN5lm4IwD4pHqYQE17qMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2466&quot;/&gt;&lt;/p&gt;&lt;p&gt;其中转换步骤是可选的，这一步主要工作是将语法树上的节点转换成目标语言可执行的节点，对于eval5这种js-in-js的实现，这一步就不需要实现了。但是对js-in-x(x可能是go、c++、py)这种情况则需要增加转换的步骤。关于词法分析、语法解析这两块实现资料比较多，这里不再赘述，熟悉js的同学可以参考acorn、babel-parser、espree等实现，这里重点讲下转换和遍历执行的过程。&lt;/p&gt;&lt;h1&gt;go与js数据交换&lt;/h1&gt;&lt;p&gt;在转换、执行之前需要先解决go和js数据交换的问题，需要考虑 js&amp;lt; --- &amp;gt;go 双向的场景。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1.&lt;/span&gt;go代码访问js变量 js代码在ast语法树转换的过程中，对应的ast节点转换的过程中被转换成expression节点，基本的值被装箱成Value类型，golang访问js变量实际上访问的是变量对应的ast节点转换后生成的expression节点。比如在js中定义如下：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__github&quot;&gt;&lt;pre data-lang=&quot;&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;var&lt;/span&gt;&lt;span&gt; a &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;print&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;  console&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;log&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&#x27;hello &#x27;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; name&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;变量定义转换如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4396355353075171&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjyI1hWJfBrfU8L67vE76mZ98p4k1Tia5I0S1IlIPrh6brGfId7Qx2NVVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2634&quot;/&gt;&lt;/p&gt;&lt;p&gt;函数定义转换如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5731280615815255&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjy66STuYBrEAgEhJtqQ0s1VOO9lggx53D4Dryfic3ZhrT17wZG4hHSGUA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2858&quot;/&gt;&lt;/p&gt;&lt;p&gt;golang在执行前会处理变量定义，处理之后会在对应作用域对象上生成key（变量名or函数名）到expression的binding:&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7800224466891134&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjyzRcxvEKia9A3JyPHLb0UxWSPU9H27Yo55B1OSulI6T4Qibqg04AyjhFg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1782&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;go里面并不会直接访问js变量，而是访问js变量对应的expression。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1.&lt;/span&gt;js代码访问go变量 假定go提前注册了变量x和函数twoPlus：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__github&quot;&gt;&lt;pre data-lang=&quot;&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;vm &lt;/span&gt;&lt;span&gt;:=&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;New&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;vm&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Set&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&quot;x&quot;&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;10&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;vm&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Set&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&quot;twoPlus&quot;&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; func&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;call &lt;/span&gt;&lt;span&gt;FunctionCall&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;Value&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;right&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; _ &lt;/span&gt;&lt;span&gt;:=&lt;/span&gt;&lt;span&gt; call&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;Argument&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;span&gt;ToInteger&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;result&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; _ &lt;/span&gt;&lt;span&gt;:=&lt;/span&gt;&lt;span&gt; vm&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;ToValue&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; right&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; result&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;})&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;js访问golang中变量x、函数twoPlus：&lt;/p&gt;&lt;section class=&quot;code-snippet__github&quot;&gt;&lt;pre data-lang=&quot;&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;var&lt;/span&gt;&lt;span&gt; a &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; x &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;var&lt;/span&gt;&lt;span&gt; b &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; twoPlus&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span&gt;console&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;log&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&#x27;twoPlus(a): &#x27;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; b&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;js代码并没有直接执行，真正执行的是js代码对应的ast转换后的结果，golang侧注册变量实际上是把变量注册到了当前作用域的property上了：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5724770642201835&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjyo2g2QGjSHYymaf8eUzMqlmXPHicIs6FbXAvtib4xia5LBM4GibJwl7jgzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1090&quot;/&gt;&lt;/p&gt;&lt;p&gt;执行ast转换后的节点时发现需要获取identifier x对应值的时候，会从property对应的map上拿到x对应的值。函数也是如此。&lt;/p&gt;&lt;h1&gt;转换&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;从ast树的body节点开始遍历，依次执行statement转换的过程比如上图中 &lt;code&gt;1+1&lt;/code&gt;在ast树上对应的节点是ExpressionStatement，对应的会依次调用parseStatement：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.776796973518285&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjyMQsfPwEjWWpTInjpbchMr4Au5ibOHNGw8Qkk7FRckibXC5F7knXHj9Iw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1586&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;parseExpression：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8540925266903915&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjynCGiciaYsrehdzwf8pj72gNCIZIibPytmC9vNWLEBGpdiaV0wSWdZjeaYw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1686&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;ExpressionStatement内部的expression是BinaryExpression,最终会转换成如下结构&lt;/p&gt;&lt;section class=&quot;code-snippet__github&quot;&gt;&lt;pre data-lang=&quot;&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;_nodeBinaryExpression {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  operator:   token.PLUS,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  comparison: false, &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  left: &amp;amp;_nodeLiteral{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    value: Value{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      kind:  valueNumber,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      value: 1, &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }, &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  },    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  right: &amp;amp;_nodeLiteral{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    value: Value{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      kind:  valueNumber, &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      value: 1,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    },&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  },&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;处理变量声明情况处理变量声明和js的变量提升相关，在遍历完ast树之后，对于树上的变量、函数的定义，会保存到varList、functionList数组中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4684354986276304&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjyWez5nibXKXib0WGYQ3l9R3Pq8cZqkiao2CicNhlU2fCUEFCZ17PmJTFmdQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2186&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;遍历、执行&lt;/h1&gt;&lt;p&gt;&lt;code&gt;1+1&lt;/code&gt; 为例：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5752840909090909&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjyl9nEKCeCiaDicV4EmKI7l1KIz8TGbEf2xBIoic2Mbgo9TzbxibjbLdXT3Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1408&quot;/&gt;&lt;/p&gt;&lt;p&gt;遍历ast执行对应的节点时需要注意，js存在作用域的区别（全局作用域、函数作用域）。在上面的代码执行的时候，默认将代码放在全局作用域执行：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3177570093457944&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjykwy8TpoYXFYmV2Voap2wLkU08FaGia41k17xgTkuWOicHicuAaH38eKuQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1712&quot;/&gt;&lt;/p&gt;&lt;p&gt;enterGlobalScope和leaveScope对应实现如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.41834862385321103&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjyFiaiaMlUtGgQCW0Bv0NysazSQWicxOeyia3dpeSDO03oCXvSrgaAjUqZDg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1090&quot;/&gt;&lt;/p&gt;&lt;p&gt;进入globalScope的时候会把当前runtime的scope暂存在_scope.outer字段上，defer对应的匿名函数在函数执行完毕之后执行，当函数执行完之后，再把scope.outers上暂存的scope恢复回来。globalScope和functionScope的scope对象是隔离的，在非严格模式下，functionScope会是一个从globalScope深拷贝的对象。&lt;/p&gt;&lt;p&gt;接下来处理变量定义，比如&lt;code&gt;var a = 1&lt;/code&gt;变量定义 或者&lt;code&gt;function f(){}&lt;/code&gt; 函数定义，变量和函数存放的地方在当前作用域scope对象上的variable.object.property字段上，这个字段其实类型就是一个巨型map，存储的时候key为变量名，值为js对应值的包装类型。完成变量、函数定义后，遍历program下的body节点，并根据节点类型执行对应的操作：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4392605633802817&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjyxWddpiaMG2ny1DvTcQMWykFIGcw14aavtHfiaeTnGNHsIvBTFnOpiaQWA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2272&quot;/&gt;&lt;/p&gt;&lt;p&gt;接着执行ExpressionStatement中的expression，对应类型是BinaryExpression：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.38950892857142855&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjyD2aWds8a4N3gvcYEHaFIDxtw5aPXOWfYymBILoELWFf3ReOt01LO9Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1792&quot;/&gt;&lt;/p&gt;&lt;p&gt;BinaryExpression需要计算左值和右值，先计算node.left:&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.25965250965250963&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjyOicWXME1d4ExLSp4JEOKOfr9jaznSbmT1DHxgC1Gg4qfQdiavQ9icqhJg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2072&quot;/&gt;&lt;/p&gt;&lt;p&gt;再进入cmp_evaluate_nodeExpression时，此时expression类型为nodeLiteral， 直接返回node.value即可。下面根据node.operator执行对应的计算逻辑（参与的时候先对Value类型执行拆箱，获取基本类型的值后转换成float64类型参与计算，计算的结果以Value的包装类型返回）：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4697986577181208&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjyCJ4emP27zoW05uokD4HQiclsVLa4r2hOq2zJGiaRTIrnofKibWkxHLV7A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1788&quot;/&gt;&lt;/p&gt;&lt;p&gt;到这里就完成了&lt;code&gt;1+1&lt;/code&gt;的计算。&lt;/p&gt;&lt;h1&gt;总结&lt;/h1&gt;&lt;p&gt;借助现有的js代码解析库可以相对容易的实现一个js的解释器，实现思路比较明确，但是对于新语法规范支持度还是比较差，后面可以进一步扩充语法。除了本文介绍的js-in-go的实现之外，js-in-js也有一些比较有意思的玩法，比如借助js-in-js的实现，可以在js引擎屏蔽了eval、new Function情况下实现js代码的热更新。&lt;/p&gt;&lt;p&gt;福利时间&lt;/p&gt;&lt;h3&gt;字节跳动9周年徽章&lt;span&gt;2枚&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.5005861664712778&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSman8kXP3siaS08yumOfzjBXjyGPtHRtCd5HKz1dddgqAOAaB372x5mqxblfOjMaWcSibxIv2Srme4icHg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;853&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.5005861664712778&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSmamSxricJW6lXOkTfB721D5FNacujDWkuaSZng8ibNDrialJtZoGP5CnuDdw4wMlkvticiaEJNMRSXEicd1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;853&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;strong&gt;&lt;span&gt;那么如何获奖呢？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;h3&gt;获奖分为以下3步&lt;br/&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;第1步：关注本公众号「豆皮范儿」&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;第2步：转发本文到朋友圈并截图。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;第3步：在本公众号「豆皮范儿」下回复你的截图&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;抽奖和领取奖品等其他事项：&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•  &lt;/span&gt;「豆皮范儿」公众号后台回复「&lt;span&gt;加群&lt;/span&gt;」，&lt;/span&gt;&lt;span&gt;&lt;span&gt;•  &lt;/span&gt;&lt;span&gt;会在粉丝群公开抽奖过程，抽奖结果会单独发文章出来。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;The     End&lt;/p&gt;&lt;p&gt;如果你觉得这篇文章对你有帮助，有启发，我想请你帮我2个小忙：&lt;/p&gt;&lt;p&gt;1、点个「&lt;span&gt;在看&lt;/span&gt;」，让更多的人也能看到这篇文章内容；&lt;/p&gt;&lt;p&gt;2、关注公众号「&lt;span&gt;豆皮范儿&lt;/span&gt;」，公众号后台回复「&lt;span&gt;加群&lt;/span&gt;」 加入我们一起学习；&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;关注公众号的福利&lt;strong&gt;持续更新&lt;/strong&gt;，公众号后台送学习资料：&lt;/p&gt;&lt;p&gt;1、&lt;span&gt;豆皮范儿后台&lt;/span&gt;回复「&lt;span&gt;vis&lt;/span&gt;」，还可以获取更多可视化免费学习资料。&lt;/p&gt;&lt;p&gt;2、&lt;span&gt;豆皮范儿后台&lt;/span&gt;回复「&lt;span&gt;webgl&lt;/span&gt;」，还可以获取webgl免费学习资料。&lt;/p&gt;&lt;p&gt;3、&lt;span&gt;豆皮范儿后台&lt;/span&gt;回复「&lt;span&gt;算法&lt;/span&gt;」，还可以获取算法的学习资料。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、豆皮范儿后台回复「&lt;span&gt;招聘&lt;/span&gt;」，获取各种内推。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-height=&quot;NaN&quot; data-ratio=&quot;0.5&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_gif/mkcv1AwSmanPu7ZJA5vgiawicnlyTTd7zicAy0ToQfIX8sIe2IicdGPTuYurQI5f1ia64sx4FGlUibpXvgOMdYTMJpZQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;516&quot; data-width=&quot;578&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzg5NDUzMDY3Mw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/sz_mmbiz_png/mkcv1AwSmanVPr3iacbXXyDy2icV4ekTV1n2FAvsNXyNIicsNEDDIibg3F6csvwjmYt6GlV0QglaBic7icfxzQHFl6hw/0?wx_fmt=png&quot; data-nickname=&quot;豆皮范儿&quot; data-alias=&quot;&quot; data-signature=&quot;小豆皮的前端范儿&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>2f297ef10d4f87b0c41a525953dcf09d</guid>
<title>掉进数据治理无止境的坑，我是怎么爬出来的？</title>
<link>https://toutiao.io/k/qfxih79</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p class=&quot;original_area_primary&quot;&gt;
                                                                                                &lt;/p&gt;

                    
                                            &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;strong&gt;&lt;span&gt;导读：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Apache Kylin 为海量数据的多维分析提供了统一的解决方案，支持对超大规模数据进行亚秒级查询。数据分析需要高质量的数据，面对业务的海量数据和来自分析人员的繁杂冗余的数据需求的现状，如何高效率低成本地梳理数据需求，如何保证数据应用层（OLAP/Kylin）提供的数据指标的准确性，都是严峻的挑战。接下来一起看来自美团酒旅的技术专家 &lt;strong&gt;李建舒 &lt;/strong&gt;来介绍：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;美团酒旅数据治理的历程和实践经验；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;业务发展各个阶段中数据体系遇到的问题和解决方案；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据治理在现阶段的建设思路和发展方向。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;01&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;背景介绍&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;数据治理这个话题这两年非常火热，很多公司尤其大型互联网公司都在做一些数据治理的规划和动作。为什么大家都要做数据治理？我个人的理解是，从数据产生、采集、生产、存储、应用到销毁的全过程中，可能在各环节中引入各种问题。初始发展阶段，这些数据问题对我们的影响不大，大家对问题的容忍度比较高。但是，随着业务发展数据质量和稳定性要求提升，并且数据积累得越来越多，我们对一些数据的精细化要求也越来越高，就会逐渐发现有很多问题需要治理。数据开发过程中会不断引入一些问题，而数据治理就是要不断消除引入的问题，以高质量、高可用、高安全的方式为业务提供数据。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;shape type=&quot;#_x0000_t75&quot; filled=&quot;f&quot;&gt;&lt;imagedata title=&quot;image1&quot;/&gt;&lt;/shape&gt;&lt;img data-backh=&quot;311&quot; data-backw=&quot;553&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;553&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;311&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJtDqdU8dwHpKyEJu2mrkowb8gicC13l3nhQl6MRcJTFibDmmWfy0GGouQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;1. 需要治理哪些问题&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;数据治理过程中哪些问题需要治理？总结了有五大类问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;390&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;373&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJszttVhCG2m52cH5TSAQQsLicLsCyhL4bnibAmfhj0gV7WZhyKaTUAJBw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;质量问题，是最重要的问题，很多公司数据部门或者业务线组做数据治理的一个大背景就是数据质量存在很多问题，比如数仓的及时性、准确性、一致性、规范性和数据应用指标的逻辑一致性问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;成本问题，互联网行业数据膨胀速度非常快，大型互联网公司在大数据基础设施上的成本投入占比非常高，而且随着数据量的增加成本也将继续攀升。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;安全问题，尤其是业务特别关注的用户类数据，一旦泄露，对业务的影响非常大，甚至能影响整个业务的生死。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;标准化问题，当公司业务部门比较多的时候，各业务部门、开发团队的数据标准不一致，在数据打通和整合过程中会出现很多问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;效率问题，在数据开发和数据管理过程中都会遇到一些效率低的问题，很多时候是靠堆人力在做。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 美团酒旅数据现状&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;美团酒旅业务从2014年成立为独立业务部门，到2018年成为国内酒旅业务重要的在线预订平台，业务发展速度比较快，数据增长速度也非常快。2017到2018两年里，生产任务数以每年超过一倍的速度增长，数据量的增长速度每年两倍多。如果不做治理，按指数级增长趋势，未来数据生产任务的复杂性还是成本负担都非常大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对我们当时面临的情况，总结了五大类问题：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;标准化的规范缺失，开始建设的时候业务发展非常快，但多个业务线之间的标准化和规范化建设都只是以规范文档的形式存在，每个人的理解不一致，导致多个研发同学开发出来的数据标准就很难达到一致。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据质量问题比较多，突出在几个方面，第一个是数据冗余很多，从数据任务增长的速度来看，新上线人多，下线任务少，数据表的生命周期控制较少。第二个是在数据建设过程中很多应用层数据都是烟囱式建设，很多指标口径没有统一的管理规范，数据一致性无法保证。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;成本增长非常快，在某些业务线大数据存储和计算资源的机器费用占比已经超过了35%，如果不加以控制，大数据成本费用只会越来越高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据安全的控制，各业务线之间可以共用的数据比较多，而且每个业务线没有统一的数据权限管理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据管理和运维效率低，数据使用和咨询多，数据RD需要花费大量时间解答业务用户的问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;02&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;治理实践&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;2018年以前酒旅数据组也做过数据治理，从数仓建模、指标管理和应用上做优化和流程规范，当时没有做体系化的数据治理规划。从2018年以后我们基于上面提到的五个问题，我们做了一个整体的数据治理策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们把数据治理的内容划分为几大部分：组织、标准规范、技术、衡量指标。整体数据治理的实现路径是以标准化的规范和组织保障为前提，通过做技术体系整体保证数据治理策略的实现。同时会做数据治理的衡量体系，随时观测和监控数据治理的效果，保障数据治理长期向好发展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-backh=&quot;311&quot; data-backw=&quot;553&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;553&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;256&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJzxVdPR7b3yjYiaHWqR45XpyN3CroAq0ndIGItsJyYEJpiafmBGTIKsaw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 标准化和组织保障&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个公司在做数据治理时都会提到标准化，我们总体思路也没有太大区别。数据标准化包括三个方面：第一是标准制定，第二是标准执行，第三是在标准制定和执行过程中的组织保障，比如怎么让标准能在数据技术部门、业务部门和相关商业分析部门统一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;579&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;325&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJPa8icNTTBJqza7kbGzLSsqUaUKyT7YiaZ6n7hjgCXS0lvvICWWUicqyMw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从标准制定上，我们制定了一个全链路的数据标准方法，从数据采集、数仓开发、指标管理到数据生命周期管理建立了很多标准，在标准化建立过程中联合组建了一个业务部门的数据管理委员会。管理委员会是一个虚拟的组织，主要组成是技术部门和业务部门，技术部门是业务数据的开发团队，业务部门是业务数据的产品团队，这两个团队作为实现的负责人，各自对接技术团队和业务团队，比如技术团队负责协调后台开发团队、大数据平台团队、数据分析系统团队等。业务则会协调商业分析、产品运营和一些业务部门。业务各个部门分别出人把数据管理委员会运行起来，为标准制定、执行提供组织保障。让大家对标准化制定能有更加统一的认知，执行过程阻力也更小，还能定期在组织内同步信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2. 技术体系&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在执行过程中也不希望完全通过人力和组织来推动达成，总体希望以一些自动化的方式进行。下面介绍一下我们的技术体系。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;① 数据质量，数据质量是数据质量中最重要的一个问题，现在数据治理的大部分问题都属于数据质量。这里有四大问题：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据仓库的综合性比较差，虽然有一些规范文档，但更依赖个人理解去执行。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据一致性问题多，主要表现在数据指标的管理上。指标管理以前在文档中定义指标，没有系统化的统一管理逻辑和查询逻辑。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据应用非常多，使用数据的方式包括数据表同步、接口消息推送、OLAP引擎查询等，不能保证数据应用端的数据一致性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;产品非常多，业务数据产品入口有十多个，没有统一的入口，也没有人对这些产品统一把关，导致数据应用和使用方式有很多分歧。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;我们的技术实现方式是为了解决上面这四大类质量问题，首先在数据仓库规范性上进行统一，然后统一指标逻辑，在此之上统一数据服务接口，最后在产品上统一用户产品入口。从这四大方向将常见的数据质量问题管控起来，具体技术实现方式如下。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;528&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;343&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJZ76YzteDIwo0xAUhppdDnuFxawQOJyfaxzNuYQWyNnFmicM5fF04RYg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;数仓建模规范&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;统一数仓建模规范分三大部分实现，以前我们只有事前的一些标准化规范，大家按自己的理解去建模实现。在这个基础上增加了事中和事后两个部分，针对事中开发了系统化工具，做数仓配置化开发。事后做规则化验证。事前会有标准化文档给大家提前理解、宣贯，事中很多标准化的事项会通过配置化自动约束规范，事后会有上线时的检验和上线后每周定期检验，检验数据仓库的建模规范是否符合标准，把不符合标准的及时提示出来、及时改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-backh=&quot;311&quot; data-backw=&quot;553&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;553&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;286&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJMy3aSrNLEqPMpeNZhbbd6SShPAia0GAmkzaCqRs0KGLkgmAtDIu01Sg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事前的标准化规范几个方向，第一是数据仓库的设计规范，在做一个新业务或模块之前，以文档形式做一些设计规范。第二是开发规范，包括一些开发流程、代码编写规范和注释信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些形成之后还想在事中以系统化的方式进行控制，保证不会因为每个人的不同理解而对数仓的规范化构成影响。这里主要包含三部分工具：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;模型开发过程中的开发工具，主要控制模型的基础信息、数仓主题和分层以及ETL代码生成。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;命名规范工具，针对模型、表、字段、指标建了很多一些规范化的系统实现，控制这些命名的标准化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;上线规则监控工具，上线过程中会监控一些数据规范，还有一些性能监控，有问题会及时发现。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;事后会定期监控，生成报告来看每个业务线、每个组、具体每个人的数仓规范性情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于具体的实现方案，我举一个简单的例子，一个数仓开发配置化的命名规范工具。我们工具的实质还是从规范化、标准化再到工具化，所以在前期做了一些规范化、标准化，在通过工具化把标准化和规范化通过系统实现，有了工具之后，比如人在数仓时，都会统一按相同的方式来命名，即便在几千个ETL里都有这个字段也能非常快地进行定位。命名工具和数仓建模ETL工具也进行了打通，命名审核通过后，直接点击就能在ETL工具的平台中生成一段代码，只需要将查询逻辑补充进去就可以了。这样就达到了控制数仓命名规范的目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-backh=&quot;311&quot; data-backw=&quot;553&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;553&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;259&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJJLE0DYAmiaf6JQ9WEh0ia6sibQqz0pbGNwOriaibvgohCefjasCrwsQ4P8Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;统一指标管理系统&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;指标在数仓中非常重要，所有数据应用都是以指标方式使用的。指标管理系统化主要做了流程管理标准化、指标定义标准化和指标使用标准化。系统化分三层，第一层是物理表管理，第二层是模型管理，第三层是指标管理，这些信息在元数据管理中统一进行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;553&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;384&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJkd9agkkPoZ0tibC1IsmXOsVWIKtCzkA4xibibOKicHicwhayYic5PRTkZfPw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统一规范只是指标管理的第一步，除了指标管理外，所有数据应用还能通过这个工具查询数据。具体做法，一个应用无非要查询两种数据，一是维度，二是指标。在查询指标时，可能会有一些维度限制条件。在指标管理模块中通过指定指标定位到数仓模型，了解指标的获取方式（是sum还是count等）。相应的数仓模型可是能是星型模型、宽表、循环模型，从模型中解析出对应的底层物理表。解析后，结合指标、维度和筛选条件，经过不同的存储引擎，解析成不同的查询语句。这样控制好数据指标管理之后，数据应用可以通过指标管理模块获得一致性的解析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;553&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;348&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJCCXoc4SbC14x1FZqRPWZrjLHrGcVIDM7WFicYfpB1b42wpneNbeDJZg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;统一数据服务&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的数据被很多下游系统使用，比如数据产品、业务系统、运营系统、管理系统等。有些下游既需要我们提供数据表，还要提供接口，但数据组开发和维护后台接口难度较大，而且接口提供后很难把控数据的用途。所以我们做了一个统一的数据服务平台。平台目标是提高效率、提高数据准确性、提供数据监控、将整个数据仓库和数据应用链路打通。提供的方式有两种，一种是对于B端应用，提供按需使用，每天提供几万次的调用额度；一种是对于C端，通过推送的方式，比如每天推送一次最新数据。以推和拉两种方式保证服务功能的全面性，具体实现，大家可以参考下图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;553&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;352&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJIDkicD95h7mRLIOJLOQ8jiamSSwb8jj2wFibs5MIY7Zfybp5zmHA2oia7w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分为几大层次：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;统一用户产品入口&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为数据入口非常多，我们又做了一个数据入口的统一，分成三大类：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;管理者和商业分析使用的分析决策产品&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;业务销售运营用的业务销售数据产品&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据资产管理产品&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;通过这种方式，某一类用户只需要在一类入口里访问一类产品，不会出现同一类产品中的数据不一致。我们又通过数据仓库的统一建模、数据指标管理保证了三大类底层数据集市的一致，从而保证了所有数据的一致性。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-backh=&quot;311&quot; data-backw=&quot;553&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;553&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;183&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJHPWbk7icIEFnt85vttgkCaOdMgLPpFpflHib9dh5w6ticvIftZUrESibZA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;整体系统架构&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;整体的技术架构分为三层，从统一数据建模到统一指标逻辑、统一数据服务和统一产品入口，整体保障了数据的质量，同时配合数据管理的组织保障体系和流程规范，将整体数据质量相关的架构搭建起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-backh=&quot;311&quot; data-backw=&quot;553&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;553&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;297&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJCXHvL0QYFfwyJABE1pDLOkHQfYGJB5qE84uJ5uqRwdHYkwn3Yx5Jkw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;② 数据运营效率&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为数据提供方，我们有很多数据资产，但数据使用方能不能快速找到、找到怎么用、有哪些数据，有三大类问题：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于此有三大目标：找得到、看得懂、用得对。为了提效，我们选用一些智能化系统代替人工。对于运营相关的数据问题，先提供系统化的数据指南。该指南包含三大类信息：指标类、数仓模型、推荐使用方式。这个方式能解决可能60%的问题，剩下的40%再通过答疑机器人，用一些机器的方式替人回答问题，这又能解决其中60%的问题。最后还有一些还是没找到的，落到人工答疑环节就非常少了，通过自动化把需要人工做的事情降到原来的20%以下。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-backh=&quot;311&quot; data-backw=&quot;553&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;553&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;226&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJqIiboEocM0kkeRfv2b6hQcAKniaw9KsGRc2qJlylcNouqx9QWhiaCaf2A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;具体的实现方式，针对数据使用指南做了一个系统，把指标元数据、维度元数据、数据表和各种产品元数据等管理起来。用户从入口查询能够快速定位，支持分类检索和重点词检索，还会提供排序进行重点推荐，对每一个主题数据分类描述。通过数据指南能解决很多问题，不能解决的就进入答疑机器人系统，这里主要解决一些元数据里没有的问题。我们日常通讯工具上会有问答，把这些问题和答案总结成一个知识库，进行清洗和规则匹配。对这类问答的解析成一个问题对应一个答案，通过一些规则和关键字匹配后存起来。之后再查的时候只输入一个问题时，根据这个解析出来他想问的可能有几个问题，将这几个答案抛给他。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-backh=&quot;311&quot; data-backw=&quot;553&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;553&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;247&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJfmyciczekjX7BdMwMkMS4bSxwGjibsbh1Jz05ZmGRr3Oe3hexzLd5sKA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;③ 数据成本&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;美团业务的数据成本也很大，每一年的数据存储、计算相关的成本增长非常快。美团目前大概的比例是70%的计算成本、20%是存储成本、10%为采集日志。针对这三大类，我们也分别做了一些数据成本治理的方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;447&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;519&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJtibszjfN1caD8iab8VQZrgVeE6e930fSgSGW40PfibLn0d7px6ZQ29WgQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对计算类，主要做了如下事情：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;无效任务治理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;超长任务优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提高资源满用率&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;资源统一管理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;针对存储类：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;冷数据治理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重复数据治理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据生命周期管理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;存储格式压缩&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;日志采集类：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整体的方案策略方面做了精细化拆分，比如按租户（每个业务线的用户）来看，租户下有队列，队列有离线、有实时。队列下面有计算、存储、采集，计算之中又分离线、实时，有些配置量、使用量。这样可以非常容易地定位到哪些租户、哪些数仓是有问题的，对应快速治理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这方面也做了很多系统化的事情，比如有一个数据冗余判断的逻辑，每次做完数仓建模之后，会做冗余判断。元数据生成之后进行预处理，根据现有的数据做预判，看是否已存在。通过配置的对比逻辑，如果认为数据重复，会做标记并每周推送到数据治理的看板上，及时将冗余数据治理掉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;④ 数据安全&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据安全我们是以事前预防、事中监控、事后追踪三个方式来进行的。实践经验上，通过三层系统控制加五个使用原则实现。从数据产生的源头业务系统里就会将一些非常敏感的用户数据加密，数据仓库层会对各分层的数据进行脱敏和二次加密，第三层专门做一些数据审计，在数据使用全流程中提供信息提示和审计报告。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-backh=&quot;311&quot; data-backw=&quot;553&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;553&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;257&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJicdUS5RTqpEnZ2zXOHuzGTcYE8bPRdiab1HjoEiancAjlRl9M6voZaVMg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据使用过程中应当遵循的五个原则：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;密文处置原则，所有高敏感的数据都要密文传输。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最晚解密原则，在应用层产品使用的话，不要在数据仓库层解密。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最小范围提取原则，如果只用一万条数据只能对一万条数据解密。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最小授权原则，用多少给多少。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;全程审计原则，从系统流出到使用全过程都是有措施保障。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 衡量指标&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;未来能够全面的衡量数仓治理的效果，我们新建了数据衡量指标体系，总体分为五大类：质量类、成本类、安全、易用性和价值。在监控方式上分为日常监控和定期监控（周、月、季度监控），让我们知道整体数据治理是整体向好、平稳还是向坏的。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;579&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;304&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJGMqIBMLNTiaQKw1OU5GgZS1ia4I6cx1sXWLyPXMhu5Xb0shO9PrpDENQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;根据PDCA原则，将数据治理作为日常运营项目做起来，底层依赖数据指标体系进行监控，之上从发现问题到提出优化方案，然后跟进处理，再到日常监控构成一个循环。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;03&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;未来规划&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;总体来说，数据治理分为三个大阶段：被动治理、主动治理、自动治理。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;579&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;246&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/zHbzQPKIBPia7dUCU2buSDRRGMNOBfGoJDpBDVicCZCCyaicML4KWM8cHobsrcGsACl242xn8r3OBibqK7r7un6Xibg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;第一阶段我们做的是被动治理，也就是阶段性治理，没有统筹考虑，主要是基于单个问题的治理，而且治理之后过一段时间可能要做重复治理。这个阶段更多是人治，一个项目成立，协调几个人按照项目制完成，没有体系规划也没有组织保障。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;第二阶段是主动治理，有长期的统筹规划，能覆盖到数据生命周期的各个链路，在治理过程中把一些手段和经验流程化、标准化、系统化，长期解决一些数据问题，让数据治理长期可控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三阶段是自动治理，也是智能治理，希望长期规划和数据生命周期个环节链路确定好之后，把已经有的经验、流程和标准做成策略。一旦出现问题，自动监控，通过一些系统化的方式解决。自动治理的第一步还是治理方案的落地和策略化，这就非常依赖于元数据，把数据治理各个过程中的一些经验技术都沉淀起来。做完策略沉淀之后做自动化，把策略用工具的方式实现，当系统发现数据有问题时，自动去处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在酒旅的数据治理还在第二阶段和第三阶段之间，虽然有整体治理计划、技术架构和组织保障，但还需要投入很多人力去做。之后，酒旅数据也会继续朝着智能化的方向做，把自动化治理做好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span data-darkmode-bgcolor-16008590572276=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16008590572276=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-16008590572276=&quot;rgb(136, 151, 171)&quot; data-darkmode-original-color-16008590572276=&quot;rgb(63, 74, 89)&quot; data-style=&quot;color: rgb(63, 74, 89); font-family: 微软雅黑; font-size: 11pt; letter-spacing: 0.4pt; text-align: left; text-indent: 0pt; visibility: visible;&quot;&gt;今天的分享就到这里，谢谢大家。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在文末分享、点赞、在看，给个 3 连击呗~&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;hr/&gt;&lt;section&gt;&lt;span&gt;分享嘉宾：&lt;/span&gt;&lt;strong/&gt;&lt;strong/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img class=&quot;rich_pages&quot; data-cropselx1=&quot;1&quot; data-cropselx2=&quot;217&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;216&quot; data-ratio=&quot;0.992&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;500&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zHbzQPKIBPiaPgHwXyVHkgsh6wFDfHJ9hMfqE4tqcF6EceXg4aFn8zx0JsZicadKB5WU3kDhzaICh49TSicVoqlIg/640?wx_fmt=png&quot;/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;李建舒&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;美团 | 技术专家&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;李建舒，美团大数据部住宿业务数据团队负责人，超过10年的数据领域相关经验，2015年加入美团后负责酒旅相关业务的数据研发和数据治理工作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;往期案例与实践&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzAwODE3ODU5MA==&amp;amp;mid=2653082394&amp;amp;idx=1&amp;amp;sn=ff13c7a550b217f51003395044d68e5b&amp;amp;chksm=80a4adebb7d324fd7860981dab67a2aba0b6b0f3c2103c7b11c48c1233bd51042d48ed9976d0&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;Apache Kylin 3.1.2 正式发布！&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzAwODE3ODU5MA==&amp;amp;mid=2653082388&amp;amp;idx=1&amp;amp;sn=8979e680e9041016711b0cf7ebfd874b&amp;amp;chksm=80a4ade5b7d324f383ce82c2131ec827255fbc55dffaeb46a41253ea4348ea0c5cc9c185ccd4&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;Kylin Committer｜左手代码，右手家庭的劳模青年&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzAwODE3ODU5MA==&amp;amp;mid=2653082372&amp;amp;idx=1&amp;amp;sn=b1306bba3311fd8b2ef69492fd361c64&amp;amp;chksm=80a4adf5b7d324e3204d7ca5200a095fbff08fb8184d8415c5d93e3518e70d1a44c4b580ade0&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;基于 Flink Kylin Hudi 湖仓一体的大数据生态体系&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzAwODE3ODU5MA==&amp;amp;mid=2653082344&amp;amp;idx=1&amp;amp;sn=4db6667aa367ae0843b99ff25c660e75&amp;amp;chksm=80a4ac19b7d3250f5479bcff90fcd492f627509eb36343d9663f65b01923199580e6bd3d66f2&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;列存数据库，不只是列式存储&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Kylin&#x27;s Github Repo 传送门&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt; ↓↓↓ &lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;https://github.com/apache/kylin &lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;喜欢❤️ Kylin 的话，别忘了 Star 🌟 一下哟～ &lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;点击&lt;/span&gt;&lt;span&gt;&lt;strong&gt;「阅读原文」&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;下载 Apache Kylin&lt;/span&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>