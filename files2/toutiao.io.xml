<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>7b3449029cf924331cb2b7255a984759</guid>
<title>聊聊风口上的 eBPF</title>
<link>https://toutiao.io/k/53qmmzi</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText&quot;&gt;&lt;p&gt;大家好，今天分享的主题是《eBPF 探索之旅》，围绕三部分展开：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;eBPF 是什么&lt;/li&gt;&lt;li&gt;eBPF 能做什么&lt;/li&gt;&lt;li&gt;如何编写 eBPF 程序&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;认识 eBPF&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;eBPF 是什么，从字面上来看是扩展伯克利包处理器，那伯克利包处理器是什么呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-70c924dc4c4075e7711fa4d66e6668b3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;352&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-70c924dc4c4075e7711fa4d66e6668b3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;352&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-70c924dc4c4075e7711fa4d66e6668b3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-70c924dc4c4075e7711fa4d66e6668b3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在此之前先来了解一个性能优秀的常用抓包工具：tcpdump&lt;/p&gt;&lt;p&gt;&lt;b&gt;tcpdump&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74e334c6b676966f9d7d1d91c52f0485_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-74e334c6b676966f9d7d1d91c52f0485_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-74e334c6b676966f9d7d1d91c52f0485_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-74e334c6b676966f9d7d1d91c52f0485_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图中展示了两个常用指令&lt;/p&gt;&lt;p&gt;指令一：指定 IP 和端口，可以抓到 IP 为 220.173.103.227，端口为 80 的包&lt;/p&gt;&lt;p&gt;指令二：加上 grep，可以过滤出带有 route 字段的数据&lt;/p&gt;&lt;p&gt;那么 tcpdump 又是如何做到通过用户提供的规则处理网络上收到的包，再 copy 给用户的呢？如果放在用户层，就需要在系统里所有 socket 读写的时候做一层处理，把规则放上去，这样做难度太大。而 tcpdump 是基于 libpcap 库实现的，libpcap 能做到在驱动将包交给内核网络时，把包取过来，通过用户传给 libpcap 的规则将需要的网络包 copy 一份给用户，再把包传给内核网络栈，而之所以 libpcap 能做到这点全靠 BPF。&lt;/p&gt;&lt;p&gt;&lt;b&gt;BPF&lt;/b&gt;&lt;/p&gt;&lt;p&gt;BPF 是基于寄存器虚拟机实现的，支持 jit，比基于栈实现的性能高很多。它能载入用户态代码并且在内核环境下运行，内核提供 BPF 相关的接口，用户可以将代码编译成字节码，通过 BPF 接口加载到 BPF 虚拟机中，当然用户代码跑在内核环境中是有风险的，如有处理不当，可能会导致内核崩溃。因此在用户代码跑在内核环境之前，内核会先做一层严格的检验，确保没问题才会被成功加载到内核环境中。&lt;/p&gt;&lt;p&gt;&lt;b&gt;eBPF：BPF 的扩展&lt;/b&gt;&lt;/p&gt;&lt;p&gt;回到 eBPF，它作为一个 BPF 的扩展，都扩展了些什么呢？&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先在功能上，不仅仅局限于网络，它能够借助 kprobe 获取内核函数运行信息，这样调试内核就不需要 gdb 或者加入内核探点重新编译内核。&lt;/li&gt;&lt;li&gt;可以借助 uprobe 获取用户函数的运行信息，kprobe 和 uprobe 不仅能获取函数运营信息，还可以获取代码执行到了哪一行时的寄存器以及栈信息，其原理可以理解为在某个指令打断点，当 cpu 执行到这个断点的时候，cpu 会保存当前的寄存器信息，然后单步执行断点持载的 handler，也是想要在内核中执行的逻辑，执行完成后 cpu 会回到这个断点的位置，恢复寄存器的状态，然后继续运行下去。&lt;/li&gt;&lt;li&gt;支持 tracepoint，即在写代码中加入 trace 点，获取执行到这点时的信息。&lt;/li&gt;&lt;li&gt;可以嵌入到 perf_event 中。我们熟知的 XDP 以及 tc 都是基于 eBPF 实现的，并且在性能上有着不俗的表现。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;eBPF 的功能&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;系统性能监控/分析工具：能够实现性能监控工具、分析工具等常用的系统分析工具，比如 sysstate 工具集，里面提供了 vmstate，pidstat 等多种工具，一些常用的 top、netstat（netstat 可被 SS 替换掉），uptime、iostat 等这些工具多数都是从 /proc、/sys、/dev 中获取的会对系统产生一定的开销，不适合频繁的调用。比如在使用 top 的时候通过 cpu 排序可以看到 top cpu 占用也是挺高的，使用 eBPF 可以在开销相对小的情况下获取系统信息，定时将 eBPF 采集的数据 copy 到用户态，然后将其发送到分析监控平台。&lt;/li&gt;&lt;li&gt;用户程序活体分析：做用户程序活体分析，比如 openresty 中 lua 火焰图绘制，程序内存使用监控，cdn 服务异常请求分析，程序运行状态的查看，这些操作都可以在程序无感的情况下做到，可以有效提供服务质量。&lt;/li&gt;&lt;li&gt;防御攻击：比如 DDoS 攻击，DDoS 攻击主要是在第七层、第三层以及第四层。第七层的攻击如 http 攻击，需要应用服务这边处理。第四层攻击，如 tcp syn 可以通过 iptable 拒绝异常的 ip，当然前提是能发现以及难点是如何区分正常流量和攻击流量，简单的防攻击会导致一些误伤，另外 tcp syn 也可以通过内核参数保护应用服务。第 3 层攻击，如 icmp。对于攻击一般会通过一些特殊的途径去发现攻击，而攻击的防御则可以通过 XDP 直接在网络包未到网络栈之前就处理掉，性能非常的优秀。&lt;/li&gt;&lt;li&gt;流控：可以控制网络传输速率，比如 tc。&lt;/li&gt;&lt;li&gt;替换 iptable：在 k8s 中 iptable 的规则往往会相当庞大，而 iptable 规则越多，性能也越差，使用 eBP 就可以解决，关于这方面有很多开源的实践可以参考。&lt;/li&gt;&lt;li&gt;服务调优：如下图所示，在 cdn 服务中难免会出现一些指标突刺的情况，这种突刺拉高整体的指标，对于这种突刺时常会因为找不到切入点而无从下手，eBPF 存在这种潜力能帮助分析解决该问题，当 eBPF 发现网络抖动，会主动采集当时应用的运行状态。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6808b8bcc1e71126df8ef35122feaef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;210&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6808b8bcc1e71126df8ef35122feaef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;210&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6808b8bcc1e71126df8ef35122feaef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b6808b8bcc1e71126df8ef35122feaef_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;eBPF 程序实践&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;编写 eBPF 程序的内核最低也要是 3.15，此版本刚好可以支持 eBPF ，但这时 eBPF 支持的特性比较少，不建议使用，最好是 4.8 以上的内核，内核越新 eBPF 支持的功能就越成熟。另外像 kprobe、uprobe、traceport 相关的参数要开起来，否则只能用 BPF的某些特性，而无法使用eBPF 的特性，相当于是空壳。通过路径 /lib/modules/`uname-r`/source/.config 或者在 /boot/  下查找对应版本的内核 config 来查看系统是否开启了所需的参数。&lt;/p&gt;&lt;p&gt;编写 eBPF 程序的对环境也有一定的要求。eBPF 代码需要编译成 llvm 的字节码，才能够在 eBPF 及虚拟机中运行，因此需要安装 llvm 以及 clang，安装好之后可以通过 llc 来查看是否支持 BPF。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4115ea24e2d0496e1aa32f34889935d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;373&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-4115ea24e2d0496e1aa32f34889935d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;373&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-4115ea24e2d0496e1aa32f34889935d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4115ea24e2d0496e1aa32f34889935d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;eBPF 代码示例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;内核、环境都准备好后就可以开始编写工作了。如果是不借助任何工具直接手写一个 eBPF 程序会非常的困难，因为内核提供的文档对如何编写 eBPF 程序的说明是比较缺乏的。当然内核也有提供工具，在内核包中的 bpftool 工具。推荐是使用工具 bcc，它能够降低写 BPF 程序的难度，提供了python、lua 的前端。以 python 为例，只需要写好需要载入 eBPF 的 C代码，再通过 bcc 提供的 BPF 类就可以将代码载入到 eBPF 虚拟机中，执行 python 程序，代码就可以运行起来了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0f3a8eb5657f13da587efebd2da41082_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;195&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-0f3a8eb5657f13da587efebd2da41082_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;195&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-0f3a8eb5657f13da587efebd2da41082_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0f3a8eb5657f13da587efebd2da41082_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图中是 bcc 工具的使用例子，代码非常简单，导入一下 BPF，进行 BPF 初始化。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;text 是要执行的代码，里面是一个函数&lt;/li&gt;&lt;li&gt;kprobe__schedule 内容是调用 bpf_trace_printk(“hello world\n”)；return 0&lt;/li&gt;&lt;li&gt;kprobe__schedule 的含义是用 kprobe的 特性在内核调用 schedule 函数的时候调用 bpf_trace_printk，打出 hello world&lt;/li&gt;&lt;li&gt;bpf_trace_printk 会把这些输出到 /sys/kernel/debug/tracing/trace_pipe 里，后面的 trace_print 就可以把数据打印出来&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面是通过 kprobe 监控机器 tcp（ipv4）的连接状态变化。首先需要知道 tcp 状态变化时内核会调用哪些函数。除了 time-wait 状态之外，其他状态基本上是通过 tcp_set_state 设置的。在 time-wait 阶段的时候，内核会创建一个新的结构体去存 time-wait 的 socket，内核考虑到内存的开销问题，之前的 socket 会释放掉。先不考虑 time-wait。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bad7494f6662f2c2a8d832f7f1ea2b31_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;859&quot; data-rawheight=&quot;1064&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-bad7494f6662f2c2a8d832f7f1ea2b31_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;859&quot; data-rawheight=&quot;1064&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-bad7494f6662f2c2a8d832f7f1ea2b31_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bad7494f6662f2c2a8d832f7f1ea2b31_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;接下来看看具体的代码，上图中是载入到 eBPF 的 C 代码。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;最上面的 BPF_HASH 表示创建一个 BPF 提供的 HASH 表；last 是 HASH 表的名称；struct sock* 是指 key 的大小，这里表示指针大小；uint64_t 是 value 的大小，为 64 位；最后的 10240 表示 map 最多能够放多少个元素。 &lt;/li&gt;&lt;li&gt;往下是一个结构体 bcc_tcp_state，可以看到后面有一个 BPF_PERF_OUTPUT，它是利用到了 perf ring buffer 的一个特性。&lt;/li&gt;&lt;li&gt;再下面是函数 get_tcp_state_change，该函数会在内核调用 tcp_set_state 的时候调用。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过内核的几个参数，内核的结构体 socket，以及这个函数传进来的一些 state，可以获取当时 tcp 连接的状态转化情况，上图函数的第一个参数 ctx 实际上是寄存器，后面是要介入函数的两个参数。这里会把一些 tcp 的状态存起来，使用 perf_submit 将这些状态更新到 perf ring buffer 中，就可以在用户态把 perf ring buffer 东西给读出来，这就是 tcp 的一些状态变化。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8182a890da19f69cdcbb69e8c806f0b4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;758&quot; data-rawheight=&quot;830&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-8182a890da19f69cdcbb69e8c806f0b4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;758&quot; data-rawheight=&quot;830&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-8182a890da19f69cdcbb69e8c806f0b4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8182a890da19f69cdcbb69e8c806f0b4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是 python 代码。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先把 C 代码读进来，通过调用 bpf 初始化，将代码编译成 eBPF 字节码，载入到 eBPF 虚拟机中运行。&lt;/li&gt;&lt;li&gt;下面是 attach_kprobe，就是在内核调用 tcp，event 是指内核在调用 tcp_set_state 的时候，fn_name 是指内核在调用 tcp_set_state 时会执行 get_tcp_state_change 函数，就是前面 C 代码中的函数。&lt;/li&gt;&lt;li&gt;打开 perf ring buffer，即后面调用的 bpf[“state_events”].open_perf_buffer，里面的参数是一个 Callback 函数，在ring buffer 有数据的时候就会调用一次 print_state，也就是说在 C 代码中调用 perf_sumbit 时候就可以调用一次 print_tcpstats 函数，并会输出存入的数据。&lt;/li&gt;&lt;li&gt;最下面调用了 perf_buffer_poll的功能，只会在 ring buffer 有消息时被唤醒，再调用 Callback 函数，这样就不会无谓地浪费 CPU。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;利用 uprobe 查看应用服务信息&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fb5627b50d34b917a8f505096a32096c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;713&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-fb5627b50d34b917a8f505096a32096c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;713&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-fb5627b50d34b917a8f505096a32096c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fb5627b50d34b917a8f505096a32096c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是通过 uprobe 查看 nginx 请求分布的情况。首先要看 nginx 创建请求的位置，是在 ngx_http_create_request，和之前一样写一个要嵌入 eBPF 虚拟机的 C 代码，还是创建一个 HASH 表，名称是 req_distr，key 是 32 位大小，value 是 64 位，核心函数是 check_ngx_http_create_request，在 nginx 调用该函数时，会执行这个钩子函数，函数内部调用的是 count_req。把 PID 和 PID 上创建的请求次数对应起来，当 PID 调用过 ngx_http_create_request 时，请求计数就会 +1。如此也就可以看到整个请求在各个 work 上的分布情况。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d83044a7d70f4fd1de698ca445437ac2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;722&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-d83044a7d70f4fd1de698ca445437ac2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;722&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-d83044a7d70f4fd1de698ca445437ac2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d83044a7d70f4fd1de698ca445437ac2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图中是 python 代码，同样把 C 代码读进来，并调用 bbf 把代码编译成 llvm 字节码，载入到 eBPF 虚拟机中，再调用 attach_uprobe。name 是指 nginx 的一个二进制文件，sym 是指要在哪个函数中打个断点，上图是 ngx_http_create_request 函数。fn_name 是在 ngx_http_create_request 函数执行的时候需要调用的函数。另外需要注意二进制文件必须要把编译符号开放出来，比如编译的时加个 -g，否则会找不到这个函数。最下面是简单地获取 HASH 表，去输出 HASH 表的 key 和 value，这样就能看到 pid 对应的 request 数量，pid 也就会对应着 worker，如此就能够查看到运行 nginx 的请求分布情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;查看运行中的 eBPF 程序与 map&lt;/b&gt;&lt;/p&gt;&lt;p&gt;可以通过内核包中 bpftool 提供的 bpftool 工具查看，它的目录是在 /lib/modules/`uname-r`/tools/bpf/bpftool 中，需要自己编译一下，在  /lib/modules/`uname-r`/tools 下执行 make-C/bpf/bpftool 就可以了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-272dc2a55aed54d5fe2148a255198fdd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-272dc2a55aed54d5fe2148a255198fdd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-272dc2a55aed54d5fe2148a255198fdd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-272dc2a55aed54d5fe2148a255198fdd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是 bpftool 工具查看 map（前面 BPF_HASH 创建的）情况的效果，-p 参数，能够展示得好看一些。prog 参数可以把在虚拟机中跑的程序给展示出来。这样就能看到到底运行了那些 eBPF 程序以及申请的 map。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;eBPF 在又拍云的发展&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;完善 cdn 系统监控体系&lt;/li&gt;&lt;li&gt;强化 cdn 业务链路 traceing，提高服务水平，提供更多的性能分析的途径&lt;/li&gt;&lt;li&gt;解决 cdn 服务中遇到的某些难以解决的问题 注：目前通过 systemtap 可以解决&lt;/li&gt;&lt;li&gt;将 XDP 引入又拍云边缘机器，给予防范 DDoS 攻击提供帮助&lt;/li&gt;&lt;li&gt; 替换 tcpdump 工具，加快抓包效率，减少抓包时对系统性能的影响&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;演讲视频查看：&lt;/b&gt;&lt;/p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://link.zhihu.com/?target=https%3A//shangzhibo.tv/watch/10201448&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-665b3050e2ea3f93aae1032705125c52_ipico.jpg&quot; data-image-width=&quot;320&quot; data-image-height=&quot;320&quot; class=&quot;LinkCard LinkCard--hasImage&quot;&gt;&lt;span class=&quot;LinkCard-backdrop&quot;/&gt;&lt;span class=&quot;LinkCard-content&quot;&gt;&lt;span class=&quot;LinkCard-text&quot;&gt;&lt;span class=&quot;LinkCard-title&quot; data-text=&quot;true&quot;&gt;聊聊风口上的 eBPF&lt;/span&gt;&lt;span class=&quot;LinkCard-meta&quot;&gt;&lt;span&gt;​&lt;svg class=&quot;Zi Zi--InsertLink&quot; fill=&quot;currentColor&quot; viewbox=&quot;0 0 24 24&quot;&gt;&lt;path d=&quot;M13.414 4.222a4.5 4.5 0 1 1 6.364 6.364l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005a2.5 2.5 0 1 0-3.536-3.536l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005zm-6.187 6.187a.5.5 0 0 1 .638-.058l.07.058.706.707a.5.5 0 0 1 .058.638l-.058.07-3.005 3.004a2.5 2.5 0 0 0 3.405 3.658l.13-.122 3.006-3.005a.5.5 0 0 1 .638-.058l.069.058.707.707a.5.5 0 0 1 .058.638l-.058.069-3.005 3.005a4.5 4.5 0 0 1-6.524-6.196l.16-.168 3.005-3.005zm8.132-3.182a.25.25 0 0 1 .353 0l1.061 1.06a.25.25 0 0 1 0 .354l-8.132 8.132a.25.25 0 0 1-.353 0l-1.061-1.06a.25.25 0 0 1 0-.354l8.132-8.132z&quot;/&gt;&lt;/svg&gt;&lt;/span&gt;shangzhibo.tv&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-imageCell&quot;&gt;&lt;img class=&quot;LinkCard-image LinkCard-image--square&quot; alt=&quot;图标&quot; src=&quot;https://pic3.zhimg.com/v2-665b3050e2ea3f93aae1032705125c52_ipico.jpg&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;p/&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>1bd95cb265c5f43909eff10a6276c3bf</guid>
<title>下一代消息队列 Pulsar 到底是什么？</title>
<link>https://toutiao.io/k/zdb2zbb</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;h1&gt;&lt;span&gt;背景&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h1&gt;&lt;p&gt;之前琢磨了很久一直想写一篇pulsar相关的文章，但是一直知识储备不够，对于很多细节还是不了解，于是查了很多资料，总算是可以凑出一篇文章了。&lt;/p&gt;&lt;p&gt;Pulsar是一个由yahoo公司于2016年开源的消息中间件，2018年成为Apache的顶级项目。在我之前的文章中写过很多其他消息中间件的文章，比如kafka,rocketmq等等，如果大家对于消息队列不了解的可以阅读以下我之前的文章：&lt;/p&gt;&lt;p&gt;在开源的业界已经有这么多消息队列中间件了，pulsar作为一个新势力到底有什么优点呢？pulsar自从出身就不断的再和其他的消息队列(kafka,rocketmq等等)做比较，但是Pulsar的设计思想和大多数的消息队列中间件都不同，具备了高吞吐，低延迟，计算存储分离，多租户，异地复制等功能，所以pulsar也被誉为下一代消息队列中间件，接下来我会一一对其进行详细的解析。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;pulsar架构原理&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h1&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.64625&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpdPPsZbeAvrrzUdzaiaWOlGJNWAfwjkvl812I4DN1EZ0mWJmQiaHuAFGQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;br/&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6613039796782387&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicp2Z2rQo555PBQwJo0ESGSUZUj47QhaYiaficfPYabicImNjmehiaO0bNENg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1181&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;br/&gt;整体的架构和其他的消息队列中间件差别不是太大，相信大家也看到了很多熟悉的名词，接下来会给大家一一解释这些名词的含义。&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;名词解释&lt;/span&gt;&lt;/h2&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Producer:消息生产者，将消息发送到broker。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Consumer:消息消费者，从Broker读取消息到客户端，进行消费处理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Broker: 可以看作是pulsar的server,Producer和Consumer都看作是client.消息处理的节点，pulsar的Broker和其他消息中间件的都不一样，他是无状态的没有存储，所以可以无限制的扩展，这个后面也会详解讲到。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Bookie: 负责所有消息的持久化，这里采用的是Apache Bookeeper。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ZK: 和kafka一样pulsar也是使用zk保存一些元数据，比如配置管理,topic分配，租户等等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Service Discovery：可以理解为Pulsar中的nginx，只用一个url就可以和整个broker进行打交道，当然也可以使用自己的服务发现。客户端发出的读取，更新或删除主题的初始请求将发送给可能不是处理该主题的 broker 。如果这个 broker 不能处理该主题的请求，broker 将会把该请求重定向到可以处理主题请求的 broker。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不论是kafka,rocketmq还是我们的pulsar其实作为消息队列中间件最为重要的大概就是分为三个部分：&lt;/p&gt;&lt;p&gt;而我们后面也会围绕着这三个部分进行展开讲解。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;Producer生产消息&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;先简单看一下如何用代码进行消息发送：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;PulsarClient client = PulsarClient.create(&lt;span&gt;&quot;pulsar://pulsar.us-west.example.com:6650&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;Producer producer = client.createProducer(&lt;br/&gt;                &lt;span&gt;&quot;persistent://sample/standalone/ns1/my-topic&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// Publish 10 messages to the topic&lt;/span&gt;&lt;br/&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;10&lt;/span&gt;; i++) {&lt;br/&gt;    producer.send(&lt;span&gt;&quot;my-message&quot;&lt;/span&gt;.getBytes());&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;url的格式为：{persistent|non-persistent}://tenant/namespace/topic&lt;/p&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;组成&lt;/th&gt;&lt;th&gt;含义&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;persistent/non-persistent&lt;/td&gt;&lt;td&gt;Pulsar 提供持久化、非持久化两种主题，如果选择的是非持久化主题的话，所有消息都在内存中保存，如果broker重启，消息将会全部丢失。如果选择的是持久化主题，所有消息都会持久化到磁盘，重启broker，消息也可以正常消费。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;tenant&lt;/td&gt;&lt;td&gt;顾名思义就是租户，pulsar最开始在雅虎内部是作为全公司使用的中间件使用的，需要给topic指定一些层级，租户就是其中一层，比如这个可以是一个大的部门，例如电商中台租户。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;namespace&lt;/td&gt;&lt;td&gt;命名空间，可以看作是第二层的层级，比如电商中台下的订单业务组&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;topic&lt;/td&gt;&lt;td&gt;消息队列名字&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;上面三个步骤中，步骤1，2属于我们准备阶段，用于构建客户端，构建Producer，我们真的核心逻辑在send中，那这里我先提几个小问题，大家可以先想想在其他消息队列中是怎么做的，然后再对比pulsar的看一下：&lt;/p&gt;&lt;h3&gt;&lt;span&gt;发送模式&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;我们上面说了send分为async和sync两种模式，但实际上在pulsar内部sync模式也是采用的async模式，在sync模式下模拟回调阻塞，达到同步的效果，这个在kafka中也是采用的这个模式，但是在rocketmq中，所有的send都是真正的同步，都会直接请求到broker。&lt;/p&gt;&lt;p&gt;基于这个模式，在pulsar和kafka中都支持批量发送，在rocketmq中是直接发送，批量发送有什么好处呢？当我们发送的TPS特别高的时候，如果每次发送都直接和broker直连，可能会做很多的重复工作，比如压缩，鉴权，创建链接等等。比如我们发送1000条消息，那么可能会做1000次这个重复的工作，如果是批量发送的话这1000条消息合并成一次请求，相对来说压缩，鉴权这些工作就只需要做一次。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6829268292682927&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpicYSEb74hicQiajAdXicp7FAhKtwNddrnzlrZN7CzZZ7drtKEOxvIrHdBA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;615&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;有同学可能会问，批量发送会不会导致发送的时间会有一定的延误？这个其实不需要担心，在pulsar中默认定时每隔1ms发送一次batch,或者当batchsize默认到了1000都会进行发送，这个发送的频率都还是很快的。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;发送负载均衡&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;在消息队列中通常会将topic进行水平扩展，在pulsar和kafka中叫做partition,在rocketmq中叫做queue，本质上都是分区，我们可以将不同分区落在不同的broker上，达到我们水平扩展的效果。&lt;/p&gt;&lt;p&gt;在我们发送的时候可以自己制定选择partition的策略，也可以使用它默认轮训partition策略。当我们选择了partition之后，我们怎么确定哪一个partition对应哪一个broker呢？&lt;/p&gt;&lt;p&gt;可以先看看下面这个图：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5947441217150761&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpxp5CtL6ECZQiageZabTicmAwjUmOoAqPiabY9zIC1wcuMjpniciarNB5rUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;723&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step1: 我们所有的信息分区映射信息在zk和broker的缓存中都有进行存储。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step2: 我们通过查询broker，可以获取到分区和broker的关系，并且定时更新。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step3: 在pulsar中每个分区在发送端的时候都被抽象成为一个单独的Producer,这个和kafka,rocketmq都不一样，在kafka里面大概就是选择了partition之后然后再去找partition对应的broker地址，然后进行发送。pulsar将每一个partition都封装成Producer，在代码实现上就不需要去关注他具体对应的是哪个broker,所有的逻辑都在producer这个代码里面，整体来说比较干净。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.1120527306967985&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicp381RgagAa1GiaQVaV0LjgwZqKicgNSCu4JnrpYmRmktbK7D0XNkcV8ZQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1062&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;压缩消息&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;消息压缩是优化信息传输的手段之一，我们通常看见一些大型文件都会是以一个压缩包的形式提供下载，在我们消息队列中我们也可以用这种思想，我们将一个batch的消息，比如有1000条可能有1M的传输大小，但是经过压缩之后可能就只会有几十kb，增加了我们和broker的传输效率，但是与之同时我们的cpu也带来了损耗。Pulsar客户端支持多种压缩类型，如 lz4、zlib、zstd、snappy 等。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.newProducer&lt;/span&gt;()&lt;br/&gt;    &lt;span&gt;.topic&lt;/span&gt;(“&lt;span&gt;test-topic&lt;/span&gt;”)&lt;br/&gt;    &lt;span&gt;.compressionType&lt;/span&gt;(&lt;span&gt;CompressionType&lt;/span&gt;&lt;span&gt;.LZ4&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;.create&lt;/span&gt;();&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;&lt;span&gt;Broker&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;接下来我们来说说第二个比较重要的部分&lt;code&gt;Broker&lt;/code&gt;,在Broker的设计中pulsar和其他所有的消息队列差别比较大，而正是因为这个差别也成为了他的特点。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;计算和存储分离&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;首先我们来说说他最大的特点：计算和存储分离。我们在开始的说过Pulsar是下一代消息队列，就非常得益于他这个架构设计，无论是kafka还是RocketMQ,所有的计算和存储都放在同一个机器上，这个模式有几个弊端：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;扩展困难：当我们需要扩展的集群的时候，我们通常是因为cpu或者磁盘其中一个原因影响，但是我们却要申请一个可能cpu和磁盘配置都很好的机器，造成了资源浪费。并且kafka这种进行扩展，还需要进行迁移数据，过程十分繁杂。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;负载不均衡：当某些partion数据特别多的时候，会导致broker负载不均衡,如下面图，如果某个partition数据特别多，那么就会导致某个broker(轮船)承载过多的数据，但是另外的broker可能又比较空闲&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.593103448275862&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpEVU4vddk4D1d2axUczn6YuicY8AaJIibH2meTJktH4AwZRZdXwgicG1jw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;725&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;pulsar计算分离架构能够非常好的解决这个问题:&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于计算：也就是我们的broker,提供消息队列的读写,不存储任何数据，无状态对于我们扩展非常友好，只要你机器足够，就能随便上。扩容Broker往往适用于增加Consumer的吞吐，当我们有一些大流量的业务或者活动，比如电商大促，可以提前进行broker的扩容。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于存储：也就是我们的bookie,只提供消息队列的存储，如果对消息量有要求的，我们可以扩容bookie,并且我们不需要迁移数据，扩容十分方便。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;消息存储&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;名词解析：&lt;/span&gt;&lt;/h4&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5368916797488226&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpTEBtembhB7CAZzYw9A3Labib9AwibiaiamkkVXPKZrUicuOuKPeqecRibmFg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;637&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是bookie的读写架构图，里面有一些名词需要先介绍一下：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Entry,Entry是存储到bookkeeper中的一条记录，其中包含Entry ID，记录实体等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Ledger，可以认为ledger是用来存储Entry的，多个Entry序列组成一个ledger。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Journal，其实就是bookkeeper的WAL(write ahead log)，用于存bookkeeper的事务日志，journal文件有一个最大大小，达到这个大小后会新起一个journal文件。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Entry log，存储Entry的文件，ledger是一个逻辑上的概念，entry会先按ledger聚合，然后写入entry log文件中。同样，entry log会有一个最大值，达到最大值后会新起一个新的entry log文件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Index file，ledger的索引文件，ledger中的entry被写入到了entry log文件中，索引文件用于entry log文件中每一个ledger做索引，记录每个ledger在entry log中的存储位置以及数据在entry log文件中的长度。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MetaData Storage，元数据存储，是用于存储bookie相关的元数据，比如bookie上有哪些ledger，bookkeeper目前使用的是zk存储，所以在部署bookkeeper前，要先有zk集群。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.7194092827004219&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpDgRkSN5YPz4iblP9Dk1icKWib4JaVvhWVNb0I71unGicpwkKCz96kE6TJQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;474&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;整体架构上的写流程：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step1: broker发起写请求，首先对Journal磁盘写入WAL，熟悉mysql的朋友知道redolog，journal和redolog作用一样都是用于恢复没有持久化的数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step2: 然后再将数据写入index和ledger，这里为了保持性能不会直接写盘，而是写pagecache,然后异步刷盘。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step3: 对写入进行ack。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;读流程为：&lt;/p&gt;&lt;h4&gt;&lt;span&gt;如何高效读写？&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;在kafka中当我们的topic变多了之后，由于kafka一个topic一个文件，就会导致我们的磁盘IO从顺序写变成随机写。在rocketMq中虽然将多个topic对应一个写入文件，让写入变成了顺序写，但是我们的读取很容易导致我们的pagecache被各种覆盖刷新，这对于我们的IO的影响是非常大的。所以pulsar在读写两个方面针对这些问题都做了很多优化：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;写流程：顺序写 + pagecache。在写流程中我们的所有的文件都是独立磁盘，并且同步刷盘的只有Journal，Journal是顺序写一个journal-wal文件,顺序写效率非常高。ledger和index虽然都会存在多个文件，但是我们只会写入pagecache,异步刷盘，所以随机写不会影响我们的性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;读流程：broker cache + bookie cache，在pulsar中对于追尾读(tailing read)非常友好基本不会走io,一般情况下我们的consumer是会立即去拿producer发送的消息的，所以这部分在持久化之后依然在broker中作为cache存在，当然就算broker没有cache（比如broker是新建的），我们的bookie也会在memtable中有自己的cache,通过多重cache减少读流程走io。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们可以发现在最理想的情况下读写的io是完全隔离开来的，所以在Pulsar中能很容易就支持百万级topic，而在我们的kafka和rocketmq中这个是非常困难的。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;无限流式存储&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;一个Topic实际上是一个ledgers流(Segment)，通过这个设计所以Pulsar他并不是一个单纯的消息队列系统，他也可以代替流式系统，所以他也叫流原生平台,可以替代flink等系统。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.38769804287045667&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicprrSP1onDszchvSbiapf9iaft1It8BPn4oTz3MqnE6ibHh7un92nlUpRIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1073&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;br/&gt;可以看见我们的Event Stream（topic/partition），由多个Segment存储组成，而每个segment由entry组成，这个可以看作是我们每批发送的消息通常会看作是一个entry。&lt;p&gt;&lt;/p&gt;&lt;p&gt;Segment可以看作是我们写入文件的一个基本维度，同一个Segment的数据会写在同一个文件上面，不同Segment将会是不同文件，而Segment之间的在metadata中进行保存。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;1.0059171597633136&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpV5xoM9uL8KVPtWia1iae1vKYuJVqD1mmQK1QyxrFDj0Zdtp1Mvk1OFdw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;845&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;h4&gt;&lt;span&gt;分层存储&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;在kafka和rocketmq中消息是会有一定的保存时间的，因为磁盘会有空间限制，在pulsar中也提供这个功能，但是如果你想让自己的消息永久存储，那么可以使用分级存储，我们可以将一些比较老的数据，定时的刷新到廉价的存储中，比如s3,那么我们就可以无限存储我们的消息队列了。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5384615384615384&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpX9dGI1Vfa4NkTb5H2SALfUVq0RlYSM1bcADrvSIakNicNu7VvVSMAWA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;780&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;数据复制&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;在pulsar中的数据复制和kafka,rocketmq都有很大的不同，在其他消息队列中通常是其他副本主动同步，通常这个时间就会变得不可预测，而在pulsar采用了类似qurom协议，给一组可用的bookie池，然后并发的写入其中的一部分bookie,只要返回部分成功（通常大于1/2）就好。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.44237485448195574&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpvMVswByR0dpicngA7ch9sybZYvWg3AFaFfMxKqiag9gbolia1y6YibOibHw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;859&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Ensemble Size（E）决定给定 ledger 可用的 bookie 池大小。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Write Quorum Size（Qw）指定 Pulsar 向其中写入 entry 的 bookie 数量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Ack Quorum Size（Qa）指定必须 ack 写入的 bookie 数量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;采用这种并发写的方式，会更加高效的进行数据复制，尤其是当数据副本比较多的时候。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;Consumer&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;接下来我们来聊聊pulsar中最后一个比较重要的组成&lt;code&gt;consumer&lt;/code&gt;。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;订阅模式&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;订阅模式是用来定义我们的消息如何分配给不同的消费者，不同消息队列中间件都有自己的订阅模式，一般我们常见的订阅模式有：&lt;/p&gt;&lt;p&gt;在pulsar中提供了4种订阅模式，分别是独占，灾备，共享，键共享：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.7243589743589743&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicp1KMujmD0WuSzbbnN7XvW3Xn53jLYy4FHpiaLhst5TtmthL4NLt8QbgQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;936&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;独占：顾名思义只能由一个消费者独占，如果同一个集群内有第二个消费者去注册，第二个就会失败，这个适用于全局有序的消息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;灾备：加强版独占，如果独占的那个挂了，会自动的切换到另外一个好的消费者，但是还是只能由一个独占。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;共享模式：这个模式看起来有点像集群模式，一条消息也是只能被一个集群内消费者消费，但是和rocketmq不同的是，rocketmq是以partition维度，同一个Partition的数据都会被发到一个机器上。在Pulsar中消费不会以partition维度，而是轮训所有消费者进行消息发送。这有个什么好处呢？如果你有100台机器，但是你只有10个partition其实你只有10台消费者能运转，但是在pulsar中100台机器都可以进行消费处理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;键共享：类似上面说的partition维度去发送，在rocketmq中同一个key的顺序消息都会被发送到一个partition，但是这里不会有partition维度，而只是按照key的hash去分配到固定的consumer,也解决了消费者能力限制于partition个数问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;消息获取模式&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;不论是在kafka还是在rocketmq中我们都是client定时轮训我们的broker获取消息，这种模式叫做长轮训（Long-Polling）模式。这种模式有一个缺点网络开销比较大，我们来计算一下consumer被消费的时延，我们假设broker和consumer之间的一次网络延时为R,那么我们总共的时间为：&lt;/p&gt;&lt;p&gt;如果只考虑网络时延，我们可以看见我们这条消息的消费时延大概是3R，所以我们必须想点什么对其进行一些优化，有同学可能马上就能想到，我们消息来了直接推送给我们的consumer不就对了，这下我们的时延只会有一次R,这个就是我们常见的推模式，但是简单的推模式是有问题的，如果我们有生产速度远远大于消费速度，那么推送的消息肯定会干爆我们的内存，这个就是背压。那么我们怎么解决背压呢？我们就可以优化推送方式，将其变为动态推送，我们结合Long-polling,在long-polling请求时将Buffer剩余空间告知给Broker，由Broker负责推送数据。此时Broker知道最多可以推送多少条数据，那么就可以控制推送行为，不至于冲垮Consumer。&lt;/p&gt;&lt;p&gt;举个例子：&lt;/p&gt;&lt;p&gt;Consumer发起请求时Buffer剩余容量为100，Broker每次最多返回32条消息，那么Consumer的这次long-polling请求Broker将在执行3次push(共push96条消息)之后返回response给Consumer（response包含4条消息）。&lt;/p&gt;&lt;p&gt;如果采用long-polling模型，Consumer每发送一次请求Broker执行一次响应，这个例子需要进行4次long-polling交互（共4个request和4个response，8次网络操作；Dynamic Push/Pull中是1个request，三次push和一个response，共5次网络操作）。&lt;/p&gt;&lt;p&gt;所以pulsar就采用了这种消息获取模式，从consumer层进一步优化消息达到时间。我觉得这个设计非常巧妙，很多中间件的这种long-polling模式都可以参考这种思想去做一个改善。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;Apache Pulsar很多设计思想都和其他中间件不一样，但无疑于其更加贴近于未来，大胆预测一下其他的一些消息中间件未来的发展也都会向其靠拢，目前国内的Pulsar使用者也是越来越多，腾讯云提供了pulsar的云版本TDMQ，当然还有一些其他的知名公司华为，知乎，虎牙等等有都在对其做一个逐步的尝试，我相信pulsar真的是一个趋势。最后也让我想起了最近大江大河大结局的一句话：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;所有的变化,都可能伴随着痛苦和弯路,开放的道路,也不会是阔野坦途,但大江大河,奔涌向前的趋势,不是任何险滩暗礁,能够阻挡的。道之所在，虽千万人吾往矣。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我在这里其实只说了一些大概，更多的一些细节，大家可以看一下下面的学习参考资料吧：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首先大家可以去看看pulsar的官网的文档，首先了解一个大概。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;大家也可以关注pulsar的公众号，每天都会发一些pulsar相关的文章，我觉得写得非常好。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可以去B站搜索TGIP，这个是pulsar每周都会由一个项目组的成员去讲相关的资料，如果想学习可以看看这个视频。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;push or pull?: https://www.cnblogs.com/hzmark/p/mq_push_pull.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;架构决策之消息中间件-Pulsar:https://blog.csdn.net/tcy83/article/details/106731392&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;如果大家觉得这篇文章对你有帮助，你的关注和转发是对我最大的支持，O(∩_∩)O:&lt;/p&gt;&lt;/blockquote&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.75&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpLdMFV81zLYP1iaJRxCNEevut3q6tRzADYvhMoYns3ppkydeLtSowUnQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;500&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>87f6c9a1ec489a6ce684069cfed51255</guid>
<title>使用了这个神器，让我的代码 bug 少了一半</title>
<link>https://toutiao.io/k/w8zvjee</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt; 最近一段时间，我们团队在生产环境出现了几次线上问题，有部分比较严重，直接影响用户功能的使用，惹得领导不高兴了，让我想办法提升代码质量，这时候项目工程代码质量检测神器——SonarQube，出现在我们的视线当中。 &lt;/span&gt;&lt;/p&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一 sonarqube是做什么的&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;SonarQube®&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;是一种自动代码审查工具，用于检测代码中的错误，漏洞和代码味道。&lt;/span&gt;&lt;span&gt;它可以与您现有的工作流程集成，以实现跨项目分支和提取请求的连续代码检查。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;通过插件形式，可以支持包括 java, C#, C/C++, PL/SQL, Cobol, JavaScrip, Groovy 等二十几种编程语言的代码质量管理与检测。sonarqube可以从以下7个维度检测代码质量，而作为开发人员至少需要处理前5种代码质量问题。&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.1 不遵循代码标准&lt;/span&gt;&lt;br/&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;sonarqube&lt;/span&gt;可以通过CheckStyle等代码规则检测工具规范代码编写。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.2 存在的缺陷漏洞&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;sonarqube&lt;/span&gt;可以通过Findbugs等等代码规则检测工具检测出潜在的缺陷。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.3  糟糕的复杂度分布&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;文件、类、方法等，如果复杂度过高将难以改变，这会使得开发人员 难以理解它们, 且如果没有自动化的单元测试，对于程序中的任何组件的改变都将可能导致需要全面的回归测试。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.4  重复&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;显然程序中包含大量复制粘贴的代码是质量低下的，&lt;span&gt;sonarqube&lt;/span&gt;可以展示源码中重复严重的地方。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.5  注释不足或者过多&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;没有注释将使代码可读性变差，特别是当不可避免地出现人员变动 时，程序的可读性将大幅下降 而过多的注释又会使得开发人员将精力过多地花费在阅读注释上，亦违背初衷。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.6  缺乏单元测试&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;sonarqube&lt;/span&gt;可以很方便地统计并展示单元测试覆盖率。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.7  糟糕的设计&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;通过&lt;span&gt;sonarqube&lt;/span&gt;可以找出循环，展示包与包、类与类之间的相互依赖关系，可以检测自定义的架构规则 通过&lt;span&gt;sonarqube&lt;/span&gt;可以管理第三方的jar包，可以利用LCOM4检测单个任务规则的应用情况， 检测耦合。&lt;span&gt;sonarqube&lt;/span&gt;可以很方便地统计并展示单元测试覆盖率。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;总览：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.49066666666666664&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uL371281oDHeXyeG8FGbygRRUKiah6gGagUfVq3V2dLQx8pibSJrApGJwUdsZblibzB8dxo9jvPuDgem5ib8hFg3oQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在典型的开发过程中：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;开发人员在IDE中开发和合并代码（最好使用&lt;/span&gt;&lt;span&gt;&lt;span&gt;SonarLint&lt;/span&gt;&lt;/span&gt;&lt;span&gt;在编辑器中接收即时反馈），然后将其代码签入ALM。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;组织的持续集成（CI）工具可以检出，构建和运行单元测试，而集成的SonarQube扫描仪可以分析结果。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;扫描程序将结果发布到SonarQube服务器，该服务器通过SonarQube界面，电子邮件，IDE内通知（通过SonarLint）以及对拉取或合并请求的修饰（使用&lt;/span&gt;&lt;span&gt;&lt;span&gt;Developer Edition&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;及更高&lt;/span&gt;&lt;span&gt;版本&lt;/span&gt;&lt;span&gt;时）向开发人员提供反馈&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SonarQube实例包含三个组件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4880952380952381&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uL371281oDHeXyeG8FGbygRRUKiah6gGawGE0utdw7noyxRp0EH9flyeZMia99RoeEOKPC9uymCibtJU4NRwfiadMw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;924&quot;/&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;SonarQube服务器运行以下过程：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;该数据库存储以下内容：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在构建或连续集成服务器上运行的一台或多台扫描仪可以分析项目。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;二 sonarqube如何搭建&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;官网地址：https://www.sonarqube.org/，选择“文档”菜单&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.6223224351747464&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uL371281oDHeXyeG8FGbygRRUKiah6gGa3GKdd2tospOyJmpQWl5Av0ChCichJBVyibHFKb2I98TLIp2I9z0QNYCQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1774&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在出现的文档页面中可以选择版本，目前最新的版本是8.5。笔者尝试过三个版本：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;8.5：&lt;span&gt;它是目前最新的版本，需要安装JDK11，并且只支持oracle、sqlserver和PostgreSQL数据库&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;7.9：&lt;span&gt;它是一个长期支持的版本，非常文档，也&lt;/span&gt;&lt;span&gt;需要安装JDK11，并且只支持oracle、sqlserver和PostgreSQL数据库&lt;/span&gt;&lt;span&gt; 。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;7.6：&lt;span&gt;它是一个老版本，只需安装JDK8，&lt;/span&gt;&lt;span&gt;支持oracle、sqlserver和PostgreSQL数据库&lt;/span&gt;&lt;span&gt;，以及mysql数据库。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;刚开始我们为了省事，安装了 7.6的版本，因为mysql数据库我们已经在用了，无需额外安装其他数据库，并且JDK8也在使用，安装成本最小。但是后来发现，如果需要安装汉化版插件，或者mybatis插件，这些插件要求的&lt;span&gt;SonarQube&lt;/span&gt;版本必须在7.9以上，并且需要运行在JDK11以上。经过权衡之后，我们决定安装最新版的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1 安装JDK11和postgreSQL&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;   JDK下载地址：https://www.oracle.com/java/technologies/javase-jdk11-downloads.html&lt;/p&gt;&lt;p&gt;   JDK的安装比较简单，我在这里就不过多介绍了，网上有很多教程。&lt;/p&gt;&lt;p&gt;&lt;span/&gt;   &lt;span&gt;PostgreSQL&lt;/span&gt;它自己号称自己是世界上最先进的开源数据库，具有许多功能，旨在帮助开发人员构建应用程序，管理员来保护数据完整性和构建容错环境，并帮助您管理数据，无论数据集的大小。除了免费和开源之外，PostgreSQL也是高度可扩展的。例如，您可以定义自己的数据类型，构建自定义函数，甚至可以使用不同的编程语言编写代码，而无需重新编译数据库。&lt;/p&gt;&lt;p&gt;   PostgreSQL的安装与使用可以参数：https://www.jianshu.com/p/7d133efccaa4&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.3 从zip文件安装sonarqube&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SonarQube无法在&lt;/span&gt;&lt;code&gt;root&lt;/code&gt;&lt;span&gt;&lt;span&gt;基于Unix的系统上&lt;/span&gt;&lt;span&gt;运行&lt;/span&gt;&lt;span&gt;，因此，如有必要，请为SonarQube创建专用的用户帐户。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;$ SONARQUBE-HOME&lt;/em&gt;&lt;span&gt;（下面）指的是SonarQube发行版已解压缩的目录的路径。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;设置对数据库的访问&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;编辑&lt;/span&gt;&lt;em&gt;$ SONARQUBE-HOME / conf / sonar.properties&lt;/em&gt;&lt;span&gt;&lt;span&gt;以配置数据库设置。&lt;/span&gt;&lt;span&gt;模板可用于每个受支持的数据库。&lt;/span&gt;&lt;span&gt;只需取消注释并配置所需的模板，然后注释掉专用于H2的行：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Example for PostgreSQL&lt;span/&gt;&lt;br/&gt;sonar.jdbc.username=sonarqube&lt;span/&gt;&lt;br/&gt;sonar.jdbc.password=mypassword&lt;span/&gt;&lt;br/&gt;sonar.jdbc.url=jdbc:postgresql://localhost/sonarqube&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;span&gt;配置Elasticsearch存储路径&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;默认情况下，Elasticsearch数据存储在&lt;/span&gt;&lt;em&gt;$ SONARQUBE-HOME / data中&lt;/em&gt;&lt;span&gt;&lt;span&gt;，但不建议将其用于生产实例。&lt;/span&gt;&lt;span&gt;相反，您应该将此数据存储在其他位置，最好是在具有快速I / O的专用卷中。&lt;/span&gt;&lt;span&gt;除了保持可接受的性能外，这样做还可以简化SonarQube的升级。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;编辑&lt;/span&gt;&lt;em&gt;$ SONARQUBE-HOME / conf / sonar.properties&lt;/em&gt;&lt;span&gt;以配置以下设置：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sonar.path.data=/var/sonarqube/data&lt;span/&gt;&lt;br/&gt;sonar.path.temp=/var/sonarqube/temp&lt;span/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;用于启动SonarQube的用户必须具有对这些目录的读写权限。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;启动Web服务器&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;默认端口为“ 9000”，上下文路径为“ /”。&lt;/span&gt;&lt;span&gt;这些值可以在&lt;/span&gt;&lt;/span&gt;&lt;em&gt;$ SONARQUBE-HOME / conf / sonar.properties中进行更改&lt;/em&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sonar.web.host=192.0.0.1&lt;span/&gt;&lt;br/&gt;sonar.web.port=80&lt;span/&gt;&lt;br/&gt;sonar.web.context=/sonarqube&lt;span/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;执行以下脚本来启动服务器：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在Linux上：bin / linux-x86-64 / sonar.sh start&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在macOS上：bin / macosx-universal-64 / sonar.sh start&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在Windows上：bin / windows-x86-64 / StartSonar.bat&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;调整Java安装&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;如果服务器上安装了多个Java版本，则可能需要明确定义使用哪个Java版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要更改SonarQube使用的Java JVM，请编辑&lt;/span&gt;&lt;em&gt;$ SONARQUBE-HOME / conf / wrapper.conf&lt;/em&gt;&lt;span&gt;并更新以下行：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;wrapper.java.command=/path/to/my/jdk/bin/java&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;您现在可以在&lt;/span&gt;&lt;span&gt;http：// localhost：9000&lt;/span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;上&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt;浏览SonarQube &lt;/span&gt;&lt;span&gt;（默认的系统管理员凭据为&lt;/span&gt;&lt;/span&gt;&lt;code&gt;admin&lt;/code&gt;&lt;span&gt;/ &lt;/span&gt;&lt;code&gt;admin&lt;/code&gt;&lt;span&gt;）。第一次访问这个地址比较会停留在这个页面一段时间，因为&lt;span&gt;SonarQube会做一些初始化工作，包含往空数据库中建表&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.44656084656084655&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uL371281oDEowEEvveETRh2VoUr2fKLQW4QuodWicX9lV8kq6FmkCBiacH3XvVzEGl13P2RxCwTXqadNyXC1MSzg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1890&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;初始化成功后运行的页面：&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.50875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uL371281oDHeXyeG8FGbygRRUKiah6gGauib7czpQF10Wpueebbja30GrNibmAIm9AeFSJuX6WMicic6icq7Db2Q7dUg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;800&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同时会生成20多张表：&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/uL371281oDHiawYq48ZGP3FQO3CllH3MMVmYYdaUViaYHcwUBAibJW0Q8M8XoGrMyQPfcdup4MLLibCMN9kRcibhWaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.6713483146067416&quot; data-w=&quot;712&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.3 安装插件&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;根据个人需要，可以安装汉化插件，sonarqube默认是英文界面。&lt;/p&gt;&lt;p&gt;github地址：&lt;span&gt;https://github.com/SonarQubeCommunity/sonar-l10n-zh&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;将项目下载编译打包后，将jar放到&lt;span&gt;$SONARQUBE-HOME&lt;/span&gt;&lt;span&gt;\extensions&lt;/span&gt;&lt;span&gt;\plugins&lt;/span&gt;&lt;/p&gt;&lt;p&gt;目录下即可，然后执行：./sonar.sh restart命令重启sonarqube服务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此外，还有mybatis插件&lt;/p&gt;&lt;p&gt;gitee地址：&lt;span&gt;https://gitee.com/mirrors/sonar-mybatis&lt;/span&gt;&lt;/p&gt;&lt;p&gt;我个人用过，觉得作用不大，不过可以基于这个代码扩展自己需要的功能。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;三 sonarqube如何使用&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3.1 在maven项目中集成sonarqube&lt;/span&gt;&lt;/h3&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;先在maven的settings.xml文件中增加如下配置：&lt;/h3&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;xml&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;pluginGroups&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;pluginGroup&lt;/span&gt;&amp;gt;&lt;/span&gt;org.sonarsource.scanner.maven&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;pluginGroup&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;pluginGroups&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;profiles&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;profile&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;id&lt;/span&gt;&amp;gt;&lt;/span&gt;sonar&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;id&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;activation&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;activeByDefault&lt;/span&gt;&amp;gt;&lt;/span&gt;true&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;activeByDefault&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;activation&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;properties&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;sonar.host.url&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;          http://localhost:9000&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;sonar.host.url&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;properties&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;profile&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;profiles&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;然后在pom.xml文件中增加配置：&lt;/h3&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;apache&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__section&quot;&gt;&amp;lt;plugin&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__section&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;&lt;span class=&quot;code-snippet__attribute&quot;&gt;org&lt;/span&gt;.sonarsource.scanner.maven&amp;lt;/groupId&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__section&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;&lt;span class=&quot;code-snippet__attribute&quot;&gt;sonar&lt;/span&gt;-maven-plugin&amp;lt;/artifactId&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__section&quot;&gt;&amp;lt;version&amp;gt;&lt;/span&gt;&lt;span class=&quot;code-snippet__attribute&quot;&gt;3&lt;/span&gt;.3.0.603&amp;lt;/version&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__section&quot;&gt;&amp;lt;/plugin&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;在项目目录下运行代码检测命令：&lt;span&gt;  &lt;/span&gt;&lt;span&gt;mvn clean &lt;/span&gt;&lt;span&gt;complie&lt;/span&gt;&lt;span&gt; -U -Dmaven.test.skip=true sonar:sonar&lt;/span&gt;&lt;br/&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看到这几句话，就表示&lt;/span&gt;&lt;span&gt;检测成功了&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.15986769570011025&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uL371281oDHiawYq48ZGP3FQO3CllH3MMGHy3F2t47HYSpSS8ZjibPZElGMcOHlECx7SuScWAK481qe0RQ1wmyQg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1814&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后在sonar后台查看检测报告&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.4913249211356467&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uL371281oDHiawYq48ZGP3FQO3CllH3MM11R3OAaGNiaBbmcvqibbNBMKnSwibCNJZOicKrX57ycq7fbhjuJ7WJg0VQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2536&quot;/&gt;&lt;/p&gt;&lt;p&gt;报告里面包含：bug、漏洞、异味、安全热点、覆盖、重复率等，对有问题的代码能够快速定位。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;点击某个bug可以查看具体有问题代码：&lt;/p&gt;&lt;p&gt;没有关闭输入流问题：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.17018072289156627&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uL371281oDHiawYq48ZGP3FQO3CllH3MMY02fnDDb2EktMO4Cys7lMsqYKIRpOkLjgx5SicWNzplVPRRklwZibiaiaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1328&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;空指针问题：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.13949843260188088&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uL371281oDHiawYq48ZGP3FQO3CllH3MMkqQ5oySqLeay4WEIe5UpG5RECmMj3eF8qwwYdAll7TKGUGy1GmfCJw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1276&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;错误的用法：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.1821138211382114&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uL371281oDHiawYq48ZGP3FQO3CllH3MMWPxTkIWw4gcQuqOnfdXsaSC1WW9ZphCiaxQ45YhngIklY8Pwev84Liag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1230&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;SimpleDateFormat不应该被定义成static的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;检测出的代码问题类型太多，这里就不一一列举了。总之，记住一句话：sonar很牛逼。它不光可以检测出代码问题，还对一些不好的代码写法和用法有更好的建议。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;彩蛋&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;sonarqube非常强大，上面只介绍了它的基本用法。一般情况下，我们可以使用jenkins配置需要代码检测的项目，从gitlab上下载代码，执行maven编译打包代码测试命令，可直接生成报告。jenkins触发执行代码检测的时机是：1.有代码提交，或者指定比如test分支有代码提交，项目数量少可以这样做。2.定时执行，我们公司就是配置在凌晨定时执行，因为jenkins部署的项目太多了，为了不影响正常的项目部署。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，我们可以自定义代码检测的执行规则，根据实际的项目需求自己开发插件，比如：我们自己开发了mybatis插件，扫描mapper和xml文件名称不一致的情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5048840048840049&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uL371281oDHiawYq48ZGP3FQO3CllH3MMm7QQQdn6ibF70l85xicicnswSWe1MiaCXibjxMoibEm0PASA8icg7UvO4PTicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1638&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>46bfb077978831f4e41faabbf9f16d3d</guid>
<title>Spring Boot 集成 JUnit 单元测试</title>
<link>https://toutiao.io/k/60g50xw</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;entry-content&quot;&gt;&amp;#13;

&lt;p&gt;为自己的应用编写单元测试是一个很好的习惯。在Java开发中最流行的测试工具非JUnit莫属，它已经成为Java单元测试的事实标准。Spring Boot测试模块不仅集成JUnit框架，还提供了许多实用程序和注解，方便我们测试应用。&lt;/p&gt;



&lt;span id=&quot;more-103&quot;/&gt;



&lt;h3 class=&quot;has-black-color has-text-color has-background&quot; id=&quot;1-添加依赖-spring-boot-starter-test&quot;&gt;&lt;strong&gt;1. 添加依赖&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;在 pom.xml 文件中引入 spring-boot-starter-test&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${version}&amp;lt;/version&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;



&lt;p&gt;Spring Boot 2.2.x 开始集成的是JUnit 5。如果之前是使用的JUnit 4，可以使用JUnit 5中提供的老式引擎运行，需要添加 junit-vintage-engine 依赖。&lt;/p&gt;



&lt;p&gt;Spring Boot 2.2.x发布很久了，现在最新稳定版是2.4.x。旧的总要被替代，所以本篇只用JUnit 5，关于JUnit 4的文章相信网上很多，官方也有给出使用说明，请自行查找。&lt;/p&gt;



&lt;h3 class=&quot;has-black-color has-text-color has-background&quot; id=&quot;2-编写单元测试&quot;&gt;&lt;strong&gt;2. 编写单元测试&lt;/strong&gt;&lt;/h3&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;@SpringBootTest(classes = Application.class, webEnvironment = SpringBootTest.WebEnvironment.DEFINED_PORT)
public class JUnitTest {

    @Test
    public void test() {
        &lt;em&gt;// 测试代码&lt;/em&gt;
    }
}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 id=&quot;springboottest-重要参数&quot;&gt;@SpringBootTest 重要参数&lt;/h3&gt;



&lt;ul&gt;&lt;li&gt;&lt;strong&gt;args&lt;/strong&gt;&lt;br/&gt;应用程序参数，如:args = “–app.test=one”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;classes&lt;/strong&gt;&lt;br/&gt;Spring Boot应用启动入口类名，该参数不指定时由Spring Boot默认查找。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;webEnvironment&lt;/strong&gt;&lt;br/&gt;默认情况下@SpringBootTest不会启动服务器。当测试Web应用时，需指定该参数以便加载上下文环境。&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;WebEnvironment枚举值说明：&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;&lt;strong&gt;MOCK&lt;/strong&gt;&lt;br/&gt;默认值，加载WebApplicationContext并提供模拟Web环境。使用此注释时，不会启动嵌入式服务器。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;RANDOM_PORT&lt;/strong&gt;&lt;br/&gt;启动应用并随机监听一个端口。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;DEFINED_PORT&lt;/strong&gt;&lt;br/&gt;启动应用并监听自定义的端口(来自application.properties)或使用默认端口8080。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;NONE&lt;/strong&gt;&lt;br/&gt;ApplicationContext通过使用加载，SpringApplication但不提供任何网络环境(模拟或其他方式)。&lt;/li&gt;&lt;/ul&gt;



&lt;h3 id=&quot;test&quot;&gt;@Test&lt;/h3&gt;



&lt;p&gt;注意 JUnit 5 的 @Test 注解在 org.junit.jupiter.api 包下。&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator&quot;/&gt;



&lt;p&gt;如果应用使用Spring MVC和 Spring WebFlux，则优先MVC。测试WebFlux应用必须设置：&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;@SpringBootTest(properties = &quot;spring.main.web-application-type=reactive&quot;)
public class MyWebFluxTests {

}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 class=&quot;has-black-color has-text-color has-background&quot; id=&quot;3-自动装配测试&quot;&gt;&lt;strong&gt;3. 自动装配测试&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;有时候我们只需要测试框架模块集成是否正常，不需要加载整个项目。可以使用 spring-boot-test-autoconfigure 模块中一些注解。整个框架被“切片”成独立的测试模块。&lt;/p&gt;



&lt;h3 id=&quot;json-测试&quot;&gt;JSON 测试&lt;/h3&gt;



&lt;p&gt;测试JSON序列化与反序列化。如果是GSON或JSONB，使用 @GsonTester 或 @JsonbTester 注解。&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;&lt;em&gt;/**
 * @author Engr-Z
 * @since 2021/1/18
 */&lt;/em&gt;
@JsonTest
public class MyJsonTest {

    @Autowired
    private JacksonTester&amp;lt;Map&amp;gt; json;

    @Test
    void testSerialize() throws Exception {
        Map&amp;lt;String, Object&amp;gt; map = new HashMap&amp;lt;&amp;gt;();
        map.put(&quot;name&quot;, &quot;攻城狮·正&quot;);
        map.put(&quot;websit&quot;, &quot;engr-z.com&quot;);
        
        Assertions.assertThat(this.json.write(map)).isEqualToJson(&quot;expected.json&quot;);
        Assertions.assertThat(this.json.write(map)).hasJsonPathStringValue(&quot;@.make&quot;);
        Assertions.assertThat(this.json.write(map)).extractingJsonPathStringValue(&quot;@.make&quot;)
                .isEqualTo(&quot;Honda&quot;);
    }

    @Test
    void testDeserialize() throws Exception {
        String content = &quot;{\&quot;name\&quot;:\&quot;攻城狮·正\&quot;,\&quot;website\&quot;:\&quot;engr-z.com\&quot;}&quot;;
        Assertions.assertThat(this.json.parse(content));
        Assertions.assertThat(this.json.parseObject(content).get(&quot;website&quot;)).isEqualTo(&quot;engr-z.com&quot;);
    }

}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 id=&quot;spring-mvc-测试&quot;&gt;Spring MVC 测试&lt;/h3&gt;



&lt;p&gt;测试 /demo/hello 接口是否正常&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;&lt;em&gt;/**
 * @author Engr-Z
 * @since 2021/1/18
 */&lt;/em&gt;
@WebMvcTest(DemoController.class)
public class SpringMVCTest {

    @Autowired
    private MockMvc mvc;

    @Test
    void test() throws Exception {
        RequestBuilder builder = MockMvcRequestBuilders.get(&quot;/demo/hello&quot;);
        ResultActions resultActions = mvc.perform(builder);
        int status = resultActions.andReturn().getResponse().getStatus();
        Assertions.assertEquals(200, status);
    }
}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 id=&quot;spring-webflux-测试&quot;&gt;Spring WebFlux 测试&lt;/h3&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;&lt;em&gt;/**
 * @author Engr-Z
 * @since 2021/1/18
 */&lt;/em&gt;
@WebFluxTest(DemoController.class)
public class SpringWebFluxTest {

    @Autowired
    private WebTestClient webClient;

    @Test
    void test() throws Exception {
        webClient.get().uri(&quot;/demo/webflux&quot;)
                .accept(MediaType.TEXT_PLAIN)
                .exchange()
                .expectStatus().isOk();
    }
}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 id=&quot;jdbc-测试&quot;&gt;JDBC 测试&lt;/h3&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;@JdbcTest
@Transactional(propagation = Propagation.NOT_SUPPORTED)
class JdbcTransactionalTests {

}&lt;/code&gt;&lt;/pre&gt;



&lt;hr class=&quot;wp-block-separator&quot;/&gt;



&lt;p&gt;自动装配还支持 JPA，Redis，Rest Client 等模块测试。更多请参考：&lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-testing-spring-boot-applications-testing-autoconfigured-tests&quot;&gt;Auto-configured Tests&lt;/a&gt;&lt;/p&gt;



&lt;h3 class=&quot;has-black-color has-text-color has-background&quot; id=&quot;mockbean-和-spybean&quot;&gt;&lt;strong&gt;@MockBean 和 @SpyBean&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;如果一个服务依赖于远程调用的结果。为了不影响我们做单元测试，可以使用&lt;code&gt;@MockBean&lt;/code&gt;。以下是官方代码示例：&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;@SpringBootTest
class MyTests {

    @MockBean
    private RemoteService remoteService;

    @Autowired
    private Reverser reverser;

    @Test
    void exampleTest() {
        &lt;em&gt;// RemoteService has been injected into the reverser bean&lt;/em&gt;
        BDDMockito.given(this.remoteService.someCall()).willReturn(&quot;mock&quot;);
        String reverse = reverser.reverseSomeCall();
        Assertions.assertThat(reverse).isEqualTo(&quot;kcom&quot;);
    }

}&lt;/code&gt;&lt;/pre&gt;



&lt;p&gt;&lt;code&gt;@SpyBean&lt;/code&gt; 和 &lt;code&gt;@MockBean&lt;/code&gt; 不同之处是：对于未指定mock的方法，spy默认会调用真实的方法，有返回值的返回真实的返回值，而mock默认不执行，有返回值的，默认返回null&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator&quot;/&gt;



&lt;p&gt;本篇只介绍 Spring Boot 集成 JUnit 单元测试，关于 JUnit 用法会在以后篇章详细讲解。&lt;/p&gt;
&lt;hr/&gt;&lt;/div&gt;&amp;#13;
&amp;#13;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>762d5e611b573ec28af826eb9d8d1b67</guid>
<title>数据仓库组件：Hive 环境搭建和基础用法</title>
<link>https://toutiao.io/k/8igq6ef</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;h1&gt;&lt;span&gt;一、Hive基础简介&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;1、基础描述&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Hive是基于Hadoop的一个数据仓库工具，用来进行数据提取、转化、加载，是一个可以对Hadoop中的大规模存储的数据进行查询和分析存储的组件，Hive数据仓库工具能将结构化的数据文件映射为一张数据库表，并提供SQL查询功能，能将SQL语句转变成MapReduce任务来执行，使用成本低，可以通过类似SQL语句实现快速MapReduce统计，使MapReduce变得更加简单，而不必开发专门的MapReduce应用程序。hive十分适合对数据仓库进行统计分析。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、组成与架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.51640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBtMEBLgsvMJM2s5RF73CpP7PrGAmYmPLAvTCFKG1bib4nc3wEdicL4ialAaQqO6G1Bia93UdLchy0dQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用户接口&lt;/strong&gt;：ClientCLI、JDBC访问Hive、WEBUI浏览器访问Hive。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;元数据&lt;/strong&gt;：Hive将元数据存储在数据库中，如mysql、derby。Hive中的元数据包括表的名字，表的列和分区以及属性，表的属性（是否为外部表等），表的数据所在目录等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;驱动器&lt;/strong&gt;：基于解释器、编辑器、优化器完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;执行器引擎&lt;/strong&gt;：ExecutionEngine把逻辑执行计划转换成可以运行的物理计划。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hadoop底层&lt;/strong&gt;：基于HDFS进行存储，使用MapReduce进行计算，基于Yarn的调度机制。&lt;/p&gt;&lt;p&gt;Hive收到给客户端发送的交互请求，接收到操作指令(SQL)，并将指令翻译成MapReduce，提交到Hadoop中执行，最后将执行结果输出到客户端。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;二、Hive环境安装&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;1、准备安装包&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;hive-1.2，依赖Hadoop集群环境，位置放在hop01服务上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、解压重命名&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;tar&lt;/span&gt; -zxvf apache-hive-&lt;span&gt;1&lt;/span&gt;.&lt;span&gt;2&lt;/span&gt;.&lt;span&gt;1&lt;/span&gt;-bin.tar.gz&lt;br/&gt;mv apache-hive-&lt;span&gt;1&lt;/span&gt;.&lt;span&gt;2&lt;/span&gt;.&lt;span&gt;1&lt;/span&gt;-bin/ hive1.&lt;span&gt;2&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3、修改配置文件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;创建配置文件&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 conf]&lt;span&gt;# pwd&lt;/span&gt;&lt;br/&gt;/opt/hive1&lt;span&gt;.2&lt;/span&gt;/conf&lt;br/&gt;[root@hop01 conf]&lt;span&gt;# mv hive-env.sh.template hive-env.sh&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;添加内容&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 conf]&lt;span&gt;# vim hive-env.sh&lt;/span&gt;&lt;br/&gt;&lt;span&gt;export&lt;/span&gt; HADOOP_HOME=/opt/hadoop2&lt;span&gt;.7&lt;/span&gt;&lt;br/&gt;&lt;span&gt;export&lt;/span&gt; HIVE_CONF_DIR=/opt/hive1&lt;span&gt;.2&lt;/span&gt;/conf&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置内容一个是Hadoop路径，和hive配置文件路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、Hadoop配置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先启动hdfs和yarn；然后在HDFS上创建/tmp和/user/hive/warehouse两个目录并修改赋予权限。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;bin/hadoop fs -&lt;span&gt;mkdir&lt;/span&gt; /tmp&lt;br/&gt;bin/hadoop fs -&lt;span&gt;mkdir&lt;/span&gt; -p /user/hive/warehouse&lt;br/&gt;bin/hadoop fs -&lt;span&gt;chmod&lt;/span&gt; g+w /tmp&lt;br/&gt;bin/hadoop fs -&lt;span&gt;chmod&lt;/span&gt; g+w /user/hive/warehouse&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;5、启动Hive&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 hive1&lt;span&gt;.2&lt;/span&gt;]&lt;span&gt;# bin/hive&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;6、基础操作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;查看数据库&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;hive&amp;gt;&lt;/span&gt;&lt;span&gt; show databases ;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;选择数据库&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hive&amp;gt; &lt;span&gt;use&lt;/span&gt; &lt;span&gt;default&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;查看数据表&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;hive&amp;gt;&lt;/span&gt;&lt;span&gt; show tables;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;创建数据库使用&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hive&amp;gt; create database mytestdb;&lt;br/&gt;hive&amp;gt; show databases ;&lt;br/&gt;&lt;span&gt;default&lt;/span&gt;&lt;br/&gt;mytestdb&lt;br/&gt;hive&amp;gt; &lt;span&gt;use&lt;/span&gt; &lt;span&gt;mytestdb&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;创建表&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;create&lt;/span&gt; &lt;span&gt;table&lt;/span&gt; hv_user (&lt;span&gt;id&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;, &lt;span&gt;name&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;, age &lt;span&gt;int&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;查看表结构&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hive&amp;gt; desc hv_user;&lt;br/&gt;id                      &lt;span&gt;int&lt;/span&gt;                                         &lt;br/&gt;name                    &lt;span&gt;string&lt;/span&gt;                                      &lt;br/&gt;age                     &lt;span&gt;int&lt;/span&gt; &lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;添加表数据&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;insert&lt;/span&gt; &lt;span&gt;into&lt;/span&gt; hv_user &lt;span&gt;values&lt;/span&gt; (&lt;span&gt;1&lt;/span&gt;, &lt;span&gt;&quot;test-user&quot;&lt;/span&gt;, &lt;span&gt;23&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;查询表数据&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hive&amp;gt; &lt;span&gt;select&lt;/span&gt; * &lt;span&gt;from&lt;/span&gt; hv_user ;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;注意：这里通过对查询日志的观察，明显看出Hive执行的流程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;删除表&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;hive&amp;gt;&lt;/span&gt;&lt;span&gt; drop table hv_user ;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;退出Hive&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;hive&amp;gt;&lt;/span&gt;&lt;span&gt; quit;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;查看Hadoop目录&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;# hadoop fs -ls /user/hive/warehouse       &lt;/span&gt;&lt;br/&gt;/user/hive/warehouse/mytestdb.db&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过Hive创建的数据库和数据存储在HDFS上。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;三、整合MySQL5.7环境&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;这里默认安装好MySQL5.7的版本，并配置好相关登录账号，配置root用户的Host为%模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1、上传MySQL驱动包&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;将MySQL驱动依赖包上传到hive安装目录的lib目录下。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 &lt;span&gt;lib&lt;/span&gt;]&lt;span&gt;# pwd&lt;/span&gt;&lt;br/&gt;/opt/hive1&lt;span&gt;.2&lt;/span&gt;/&lt;span&gt;lib&lt;/span&gt;&lt;br/&gt;[root@hop01 &lt;span&gt;lib&lt;/span&gt;]&lt;span&gt;# ll&lt;/span&gt;&lt;br/&gt;mysql-connector-java&lt;span&gt;-5.1&lt;/span&gt;&lt;span&gt;.27&lt;/span&gt;-bin.jar&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2、创建hive-site配置&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 conf]&lt;span&gt;# pwd&lt;/span&gt;&lt;br/&gt;/opt/hive1&lt;span&gt;.2&lt;/span&gt;/conf&lt;br/&gt;[root@hop01 conf]&lt;span&gt;# touch hive-site.xml&lt;/span&gt;&lt;br/&gt;[root@hop01 conf]&lt;span&gt;# vim hive-site.xml&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3、配置MySQL存储&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&amp;lt;&lt;span&gt;configuration&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionURL&lt;span&gt;&amp;lt;/&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;jdbc:mysql://hop01:3306/metastore?createDatabaseIfNotExist=true&lt;span&gt;&amp;lt;/&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;JDBC connect string for a JDBC metastore&lt;span&gt;&amp;lt;/&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;/&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionDriverName&lt;span&gt;&amp;lt;/&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;com.mysql.jdbc.Driver&lt;span&gt;&amp;lt;/&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;Driver class name for a JDBC metastore&lt;span&gt;&amp;lt;/&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;/&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionUserName&lt;span&gt;&amp;lt;/&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;root&lt;span&gt;&amp;lt;/&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;username to use against metastore database&lt;span&gt;&amp;lt;/&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;/&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionPassword&lt;span&gt;&amp;lt;/&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;123456&lt;span&gt;&amp;lt;/&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;password to use against metastore database&lt;span&gt;&amp;lt;/&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;/&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;configuration&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置完成后，依次重启MySQL、hadoop、hive环境，查看MySQL数据库信息，多了metastore数据库和相关表。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、后台启动hiveserver2&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 hive1&lt;span&gt;.2&lt;/span&gt;]&lt;span&gt;# bin/hiveserver2 &amp;amp;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;5、Jdbc连接测试&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[&lt;span&gt;root@hop01 hive1.2&lt;/span&gt;]&lt;span&gt;# bin/beeline&lt;/span&gt;&lt;br/&gt;Beeline version &lt;span&gt;1.2&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; Apache Hive&lt;br/&gt;beeline&amp;gt; !connect jdbc:hive2:&lt;span&gt;//hop01:10000&lt;/span&gt;&lt;br/&gt;Connecting to jdbc:hive2:&lt;span&gt;//hop01:10000&lt;/span&gt;&lt;br/&gt;Enter username &lt;span&gt;for&lt;/span&gt; jdbc:hive2:&lt;span&gt;//hop01:10000: hiveroot (账户回车)&lt;/span&gt;&lt;br/&gt;Enter password &lt;span&gt;for&lt;/span&gt; jdbc:hive2:&lt;span&gt;//hop01:10000: ******   (密码123456回车)&lt;/span&gt;&lt;br/&gt;Connected to: &lt;span&gt;Apache &lt;span&gt;Hive&lt;/span&gt; (&lt;span&gt;version &lt;span&gt;1.2&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;&lt;/span&gt;)&lt;br/&gt;Driver: Hive &lt;span&gt;JDBC&lt;/span&gt; (&lt;span&gt;version &lt;span&gt;1.2&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;&lt;/span&gt;)&lt;br/&gt;0: jdbc:hive2:&lt;span&gt;//hop01:10000&amp;gt; show databases;&lt;/span&gt;&lt;br/&gt;+----------------+--+&lt;br/&gt;| database_name  |&lt;br/&gt;+----------------+--+&lt;br/&gt;| &lt;span&gt;default&lt;/span&gt;        |&lt;br/&gt;+----------------+--+&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h1&gt;&lt;span&gt;四、高级查询语法&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;1、基础函数&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;count&lt;/span&gt;(*) count_user &lt;span&gt;from&lt;/span&gt; hv_user;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;(age) sum_age &lt;span&gt;from&lt;/span&gt; hv_user;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;min&lt;/span&gt;(age) min_age,&lt;span&gt;max&lt;/span&gt;(age) max_age &lt;span&gt;from&lt;/span&gt; hv_user;&lt;br/&gt;+&lt;span&gt;----------+----------+--+&lt;/span&gt;&lt;br/&gt;| min_age  | max_age  |&lt;br/&gt;+&lt;span&gt;----------+----------+--+&lt;/span&gt;&lt;br/&gt;| 23       | 25       |&lt;br/&gt;+&lt;span&gt;----------+----------+--+&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2、条件查询语句&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;select&lt;/span&gt; * &lt;span&gt;from&lt;/span&gt; hv_user &lt;span&gt;where&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;&#x27;test-user&#x27;&lt;/span&gt; &lt;span&gt;limit&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;| hv_user.id  | hv_user.name  | hv_user.age  |&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;| 1           | test-user     | 23           |&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt; * &lt;span&gt;from&lt;/span&gt; hv_user &lt;span&gt;where&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;&amp;gt;&lt;span&gt;1&lt;/span&gt; &lt;span&gt;AND&lt;/span&gt; &lt;span&gt;name&lt;/span&gt; &lt;span&gt;like&lt;/span&gt; &lt;span&gt;&#x27;dev%&#x27;&lt;/span&gt;;&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;| hv_user.id  | hv_user.name  | hv_user.age  |&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;| 2           | dev-user      | 25           |&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;count&lt;/span&gt;(*) count_name,&lt;span&gt;name&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; hv_user &lt;span&gt;group&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;;&lt;br/&gt;+&lt;span&gt;-------------+------------+--+&lt;/span&gt;&lt;br/&gt;| count_name  |    name    |&lt;br/&gt;+&lt;span&gt;-------------+------------+--+&lt;/span&gt;&lt;br/&gt;| 1           | dev-user   |&lt;br/&gt;| 1           | test-user  |&lt;br/&gt;+&lt;span&gt;-------------+------------+--+&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3、连接查询&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;select&lt;/span&gt; t1.*,t2.* &lt;span&gt;from&lt;/span&gt; hv_user t1 &lt;span&gt;join&lt;/span&gt; hv_dept t2 &lt;span&gt;on&lt;/span&gt; t1.id=t2.dp_id;&lt;br/&gt;+&lt;span&gt;--------+------------+---------+-----------+-------------+--+&lt;/span&gt;&lt;br/&gt;| t1.id  |  t1.name   | t1.age  | t2.dp_id  | t2.dp_name  |&lt;br/&gt;+&lt;span&gt;--------+------------+---------+-----------+-------------+--+&lt;/span&gt;&lt;br/&gt;| 1      | test-user  | 23      | 1         | 技术部      |&lt;br/&gt;+&lt;span&gt;--------+------------+---------+-----------+-------------+--+&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h1&gt;&lt;span&gt;五、源代码地址&lt;/span&gt;&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;GitHub·地址&lt;br/&gt;https:&lt;span&gt;//github.com/cicadasmile/big-data-parent&lt;/span&gt;&lt;br/&gt;GitEE·地址&lt;br/&gt;https:&lt;span&gt;//gitee.com/cicadasmile/big-data-parent&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.3783359497645212&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvCjMheLZtcM2iaVMBOpIUKR4CDRCG9FLT5K6NmGXvG7exrW0TSuDjnTKJQ5PDq8j8Y7PHDd17Z3gicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1274&quot;/&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>