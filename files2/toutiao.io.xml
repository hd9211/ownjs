<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>7b3449029cf924331cb2b7255a984759</guid>
<title>聊聊风口上的 eBPF</title>
<link>https://toutiao.io/k/53qmmzi</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText&quot;&gt;&lt;p&gt;大家好，今天分享的主题是《eBPF 探索之旅》，围绕三部分展开：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;eBPF 是什么&lt;/li&gt;&lt;li&gt;eBPF 能做什么&lt;/li&gt;&lt;li&gt;如何编写 eBPF 程序&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;认识 eBPF&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;eBPF 是什么，从字面上来看是扩展伯克利包处理器，那伯克利包处理器是什么呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-70c924dc4c4075e7711fa4d66e6668b3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;352&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-70c924dc4c4075e7711fa4d66e6668b3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;352&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-70c924dc4c4075e7711fa4d66e6668b3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-70c924dc4c4075e7711fa4d66e6668b3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在此之前先来了解一个性能优秀的常用抓包工具：tcpdump&lt;/p&gt;&lt;p&gt;&lt;b&gt;tcpdump&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74e334c6b676966f9d7d1d91c52f0485_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-74e334c6b676966f9d7d1d91c52f0485_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-74e334c6b676966f9d7d1d91c52f0485_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-74e334c6b676966f9d7d1d91c52f0485_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图中展示了两个常用指令&lt;/p&gt;&lt;p&gt;指令一：指定 IP 和端口，可以抓到 IP 为 220.173.103.227，端口为 80 的包&lt;/p&gt;&lt;p&gt;指令二：加上 grep，可以过滤出带有 route 字段的数据&lt;/p&gt;&lt;p&gt;那么 tcpdump 又是如何做到通过用户提供的规则处理网络上收到的包，再 copy 给用户的呢？如果放在用户层，就需要在系统里所有 socket 读写的时候做一层处理，把规则放上去，这样做难度太大。而 tcpdump 是基于 libpcap 库实现的，libpcap 能做到在驱动将包交给内核网络时，把包取过来，通过用户传给 libpcap 的规则将需要的网络包 copy 一份给用户，再把包传给内核网络栈，而之所以 libpcap 能做到这点全靠 BPF。&lt;/p&gt;&lt;p&gt;&lt;b&gt;BPF&lt;/b&gt;&lt;/p&gt;&lt;p&gt;BPF 是基于寄存器虚拟机实现的，支持 jit，比基于栈实现的性能高很多。它能载入用户态代码并且在内核环境下运行，内核提供 BPF 相关的接口，用户可以将代码编译成字节码，通过 BPF 接口加载到 BPF 虚拟机中，当然用户代码跑在内核环境中是有风险的，如有处理不当，可能会导致内核崩溃。因此在用户代码跑在内核环境之前，内核会先做一层严格的检验，确保没问题才会被成功加载到内核环境中。&lt;/p&gt;&lt;p&gt;&lt;b&gt;eBPF：BPF 的扩展&lt;/b&gt;&lt;/p&gt;&lt;p&gt;回到 eBPF，它作为一个 BPF 的扩展，都扩展了些什么呢？&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先在功能上，不仅仅局限于网络，它能够借助 kprobe 获取内核函数运行信息，这样调试内核就不需要 gdb 或者加入内核探点重新编译内核。&lt;/li&gt;&lt;li&gt;可以借助 uprobe 获取用户函数的运行信息，kprobe 和 uprobe 不仅能获取函数运营信息，还可以获取代码执行到了哪一行时的寄存器以及栈信息，其原理可以理解为在某个指令打断点，当 cpu 执行到这个断点的时候，cpu 会保存当前的寄存器信息，然后单步执行断点持载的 handler，也是想要在内核中执行的逻辑，执行完成后 cpu 会回到这个断点的位置，恢复寄存器的状态，然后继续运行下去。&lt;/li&gt;&lt;li&gt;支持 tracepoint，即在写代码中加入 trace 点，获取执行到这点时的信息。&lt;/li&gt;&lt;li&gt;可以嵌入到 perf_event 中。我们熟知的 XDP 以及 tc 都是基于 eBPF 实现的，并且在性能上有着不俗的表现。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;eBPF 的功能&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;系统性能监控/分析工具：能够实现性能监控工具、分析工具等常用的系统分析工具，比如 sysstate 工具集，里面提供了 vmstate，pidstat 等多种工具，一些常用的 top、netstat（netstat 可被 SS 替换掉），uptime、iostat 等这些工具多数都是从 /proc、/sys、/dev 中获取的会对系统产生一定的开销，不适合频繁的调用。比如在使用 top 的时候通过 cpu 排序可以看到 top cpu 占用也是挺高的，使用 eBPF 可以在开销相对小的情况下获取系统信息，定时将 eBPF 采集的数据 copy 到用户态，然后将其发送到分析监控平台。&lt;/li&gt;&lt;li&gt;用户程序活体分析：做用户程序活体分析，比如 openresty 中 lua 火焰图绘制，程序内存使用监控，cdn 服务异常请求分析，程序运行状态的查看，这些操作都可以在程序无感的情况下做到，可以有效提供服务质量。&lt;/li&gt;&lt;li&gt;防御攻击：比如 DDoS 攻击，DDoS 攻击主要是在第七层、第三层以及第四层。第七层的攻击如 http 攻击，需要应用服务这边处理。第四层攻击，如 tcp syn 可以通过 iptable 拒绝异常的 ip，当然前提是能发现以及难点是如何区分正常流量和攻击流量，简单的防攻击会导致一些误伤，另外 tcp syn 也可以通过内核参数保护应用服务。第 3 层攻击，如 icmp。对于攻击一般会通过一些特殊的途径去发现攻击，而攻击的防御则可以通过 XDP 直接在网络包未到网络栈之前就处理掉，性能非常的优秀。&lt;/li&gt;&lt;li&gt;流控：可以控制网络传输速率，比如 tc。&lt;/li&gt;&lt;li&gt;替换 iptable：在 k8s 中 iptable 的规则往往会相当庞大，而 iptable 规则越多，性能也越差，使用 eBP 就可以解决，关于这方面有很多开源的实践可以参考。&lt;/li&gt;&lt;li&gt;服务调优：如下图所示，在 cdn 服务中难免会出现一些指标突刺的情况，这种突刺拉高整体的指标，对于这种突刺时常会因为找不到切入点而无从下手，eBPF 存在这种潜力能帮助分析解决该问题，当 eBPF 发现网络抖动，会主动采集当时应用的运行状态。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6808b8bcc1e71126df8ef35122feaef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;210&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6808b8bcc1e71126df8ef35122feaef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;210&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6808b8bcc1e71126df8ef35122feaef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b6808b8bcc1e71126df8ef35122feaef_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;eBPF 程序实践&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;编写 eBPF 程序的内核最低也要是 3.15，此版本刚好可以支持 eBPF ，但这时 eBPF 支持的特性比较少，不建议使用，最好是 4.8 以上的内核，内核越新 eBPF 支持的功能就越成熟。另外像 kprobe、uprobe、traceport 相关的参数要开起来，否则只能用 BPF的某些特性，而无法使用eBPF 的特性，相当于是空壳。通过路径 /lib/modules/`uname-r`/source/.config 或者在 /boot/  下查找对应版本的内核 config 来查看系统是否开启了所需的参数。&lt;/p&gt;&lt;p&gt;编写 eBPF 程序的对环境也有一定的要求。eBPF 代码需要编译成 llvm 的字节码，才能够在 eBPF 及虚拟机中运行，因此需要安装 llvm 以及 clang，安装好之后可以通过 llc 来查看是否支持 BPF。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4115ea24e2d0496e1aa32f34889935d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;373&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-4115ea24e2d0496e1aa32f34889935d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;373&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-4115ea24e2d0496e1aa32f34889935d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4115ea24e2d0496e1aa32f34889935d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;eBPF 代码示例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;内核、环境都准备好后就可以开始编写工作了。如果是不借助任何工具直接手写一个 eBPF 程序会非常的困难，因为内核提供的文档对如何编写 eBPF 程序的说明是比较缺乏的。当然内核也有提供工具，在内核包中的 bpftool 工具。推荐是使用工具 bcc，它能够降低写 BPF 程序的难度，提供了python、lua 的前端。以 python 为例，只需要写好需要载入 eBPF 的 C代码，再通过 bcc 提供的 BPF 类就可以将代码载入到 eBPF 虚拟机中，执行 python 程序，代码就可以运行起来了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0f3a8eb5657f13da587efebd2da41082_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;195&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-0f3a8eb5657f13da587efebd2da41082_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;195&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-0f3a8eb5657f13da587efebd2da41082_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0f3a8eb5657f13da587efebd2da41082_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图中是 bcc 工具的使用例子，代码非常简单，导入一下 BPF，进行 BPF 初始化。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;text 是要执行的代码，里面是一个函数&lt;/li&gt;&lt;li&gt;kprobe__schedule 内容是调用 bpf_trace_printk(“hello world\n”)；return 0&lt;/li&gt;&lt;li&gt;kprobe__schedule 的含义是用 kprobe的 特性在内核调用 schedule 函数的时候调用 bpf_trace_printk，打出 hello world&lt;/li&gt;&lt;li&gt;bpf_trace_printk 会把这些输出到 /sys/kernel/debug/tracing/trace_pipe 里，后面的 trace_print 就可以把数据打印出来&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面是通过 kprobe 监控机器 tcp（ipv4）的连接状态变化。首先需要知道 tcp 状态变化时内核会调用哪些函数。除了 time-wait 状态之外，其他状态基本上是通过 tcp_set_state 设置的。在 time-wait 阶段的时候，内核会创建一个新的结构体去存 time-wait 的 socket，内核考虑到内存的开销问题，之前的 socket 会释放掉。先不考虑 time-wait。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bad7494f6662f2c2a8d832f7f1ea2b31_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;859&quot; data-rawheight=&quot;1064&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-bad7494f6662f2c2a8d832f7f1ea2b31_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;859&quot; data-rawheight=&quot;1064&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-bad7494f6662f2c2a8d832f7f1ea2b31_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bad7494f6662f2c2a8d832f7f1ea2b31_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;接下来看看具体的代码，上图中是载入到 eBPF 的 C 代码。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;最上面的 BPF_HASH 表示创建一个 BPF 提供的 HASH 表；last 是 HASH 表的名称；struct sock* 是指 key 的大小，这里表示指针大小；uint64_t 是 value 的大小，为 64 位；最后的 10240 表示 map 最多能够放多少个元素。 &lt;/li&gt;&lt;li&gt;往下是一个结构体 bcc_tcp_state，可以看到后面有一个 BPF_PERF_OUTPUT，它是利用到了 perf ring buffer 的一个特性。&lt;/li&gt;&lt;li&gt;再下面是函数 get_tcp_state_change，该函数会在内核调用 tcp_set_state 的时候调用。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过内核的几个参数，内核的结构体 socket，以及这个函数传进来的一些 state，可以获取当时 tcp 连接的状态转化情况，上图函数的第一个参数 ctx 实际上是寄存器，后面是要介入函数的两个参数。这里会把一些 tcp 的状态存起来，使用 perf_submit 将这些状态更新到 perf ring buffer 中，就可以在用户态把 perf ring buffer 东西给读出来，这就是 tcp 的一些状态变化。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8182a890da19f69cdcbb69e8c806f0b4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;758&quot; data-rawheight=&quot;830&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-8182a890da19f69cdcbb69e8c806f0b4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;758&quot; data-rawheight=&quot;830&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-8182a890da19f69cdcbb69e8c806f0b4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8182a890da19f69cdcbb69e8c806f0b4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是 python 代码。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先把 C 代码读进来，通过调用 bpf 初始化，将代码编译成 eBPF 字节码，载入到 eBPF 虚拟机中运行。&lt;/li&gt;&lt;li&gt;下面是 attach_kprobe，就是在内核调用 tcp，event 是指内核在调用 tcp_set_state 的时候，fn_name 是指内核在调用 tcp_set_state 时会执行 get_tcp_state_change 函数，就是前面 C 代码中的函数。&lt;/li&gt;&lt;li&gt;打开 perf ring buffer，即后面调用的 bpf[“state_events”].open_perf_buffer，里面的参数是一个 Callback 函数，在ring buffer 有数据的时候就会调用一次 print_state，也就是说在 C 代码中调用 perf_sumbit 时候就可以调用一次 print_tcpstats 函数，并会输出存入的数据。&lt;/li&gt;&lt;li&gt;最下面调用了 perf_buffer_poll的功能，只会在 ring buffer 有消息时被唤醒，再调用 Callback 函数，这样就不会无谓地浪费 CPU。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;利用 uprobe 查看应用服务信息&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fb5627b50d34b917a8f505096a32096c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;713&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-fb5627b50d34b917a8f505096a32096c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;713&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-fb5627b50d34b917a8f505096a32096c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fb5627b50d34b917a8f505096a32096c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是通过 uprobe 查看 nginx 请求分布的情况。首先要看 nginx 创建请求的位置，是在 ngx_http_create_request，和之前一样写一个要嵌入 eBPF 虚拟机的 C 代码，还是创建一个 HASH 表，名称是 req_distr，key 是 32 位大小，value 是 64 位，核心函数是 check_ngx_http_create_request，在 nginx 调用该函数时，会执行这个钩子函数，函数内部调用的是 count_req。把 PID 和 PID 上创建的请求次数对应起来，当 PID 调用过 ngx_http_create_request 时，请求计数就会 +1。如此也就可以看到整个请求在各个 work 上的分布情况。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d83044a7d70f4fd1de698ca445437ac2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;722&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-d83044a7d70f4fd1de698ca445437ac2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;722&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-d83044a7d70f4fd1de698ca445437ac2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d83044a7d70f4fd1de698ca445437ac2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图中是 python 代码，同样把 C 代码读进来，并调用 bbf 把代码编译成 llvm 字节码，载入到 eBPF 虚拟机中，再调用 attach_uprobe。name 是指 nginx 的一个二进制文件，sym 是指要在哪个函数中打个断点，上图是 ngx_http_create_request 函数。fn_name 是在 ngx_http_create_request 函数执行的时候需要调用的函数。另外需要注意二进制文件必须要把编译符号开放出来，比如编译的时加个 -g，否则会找不到这个函数。最下面是简单地获取 HASH 表，去输出 HASH 表的 key 和 value，这样就能看到 pid 对应的 request 数量，pid 也就会对应着 worker，如此就能够查看到运行 nginx 的请求分布情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;查看运行中的 eBPF 程序与 map&lt;/b&gt;&lt;/p&gt;&lt;p&gt;可以通过内核包中 bpftool 提供的 bpftool 工具查看，它的目录是在 /lib/modules/`uname-r`/tools/bpf/bpftool 中，需要自己编译一下，在  /lib/modules/`uname-r`/tools 下执行 make-C/bpf/bpftool 就可以了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-272dc2a55aed54d5fe2148a255198fdd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-272dc2a55aed54d5fe2148a255198fdd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-272dc2a55aed54d5fe2148a255198fdd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-272dc2a55aed54d5fe2148a255198fdd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是 bpftool 工具查看 map（前面 BPF_HASH 创建的）情况的效果，-p 参数，能够展示得好看一些。prog 参数可以把在虚拟机中跑的程序给展示出来。这样就能看到到底运行了那些 eBPF 程序以及申请的 map。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;eBPF 在又拍云的发展&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;完善 cdn 系统监控体系&lt;/li&gt;&lt;li&gt;强化 cdn 业务链路 traceing，提高服务水平，提供更多的性能分析的途径&lt;/li&gt;&lt;li&gt;解决 cdn 服务中遇到的某些难以解决的问题 注：目前通过 systemtap 可以解决&lt;/li&gt;&lt;li&gt;将 XDP 引入又拍云边缘机器，给予防范 DDoS 攻击提供帮助&lt;/li&gt;&lt;li&gt; 替换 tcpdump 工具，加快抓包效率，减少抓包时对系统性能的影响&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;演讲视频查看：&lt;/b&gt;&lt;/p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://link.zhihu.com/?target=https%3A//shangzhibo.tv/watch/10201448&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-665b3050e2ea3f93aae1032705125c52_ipico.jpg&quot; data-image-width=&quot;320&quot; data-image-height=&quot;320&quot; class=&quot;LinkCard LinkCard--hasImage&quot;&gt;&lt;span class=&quot;LinkCard-backdrop&quot;/&gt;&lt;span class=&quot;LinkCard-content&quot;&gt;&lt;span class=&quot;LinkCard-text&quot;&gt;&lt;span class=&quot;LinkCard-title&quot; data-text=&quot;true&quot;&gt;聊聊风口上的 eBPF&lt;/span&gt;&lt;span class=&quot;LinkCard-meta&quot;&gt;&lt;span&gt;​&lt;svg class=&quot;Zi Zi--InsertLink&quot; fill=&quot;currentColor&quot; viewbox=&quot;0 0 24 24&quot;&gt;&lt;path d=&quot;M13.414 4.222a4.5 4.5 0 1 1 6.364 6.364l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005a2.5 2.5 0 1 0-3.536-3.536l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005zm-6.187 6.187a.5.5 0 0 1 .638-.058l.07.058.706.707a.5.5 0 0 1 .058.638l-.058.07-3.005 3.004a2.5 2.5 0 0 0 3.405 3.658l.13-.122 3.006-3.005a.5.5 0 0 1 .638-.058l.069.058.707.707a.5.5 0 0 1 .058.638l-.058.069-3.005 3.005a4.5 4.5 0 0 1-6.524-6.196l.16-.168 3.005-3.005zm8.132-3.182a.25.25 0 0 1 .353 0l1.061 1.06a.25.25 0 0 1 0 .354l-8.132 8.132a.25.25 0 0 1-.353 0l-1.061-1.06a.25.25 0 0 1 0-.354l8.132-8.132z&quot;/&gt;&lt;/svg&gt;&lt;/span&gt;shangzhibo.tv&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-imageCell&quot;&gt;&lt;img class=&quot;LinkCard-image LinkCard-image--square&quot; alt=&quot;图标&quot; src=&quot;https://pic3.zhimg.com/v2-665b3050e2ea3f93aae1032705125c52_ipico.jpg&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;p/&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>762d5e611b573ec28af826eb9d8d1b67</guid>
<title>数据仓库组件：Hive 环境搭建和基础用法</title>
<link>https://toutiao.io/k/8igq6ef</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;h1&gt;&lt;span&gt;一、Hive基础简介&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;1、基础描述&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Hive是基于Hadoop的一个数据仓库工具，用来进行数据提取、转化、加载，是一个可以对Hadoop中的大规模存储的数据进行查询和分析存储的组件，Hive数据仓库工具能将结构化的数据文件映射为一张数据库表，并提供SQL查询功能，能将SQL语句转变成MapReduce任务来执行，使用成本低，可以通过类似SQL语句实现快速MapReduce统计，使MapReduce变得更加简单，而不必开发专门的MapReduce应用程序。hive十分适合对数据仓库进行统计分析。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、组成与架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.51640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBtMEBLgsvMJM2s5RF73CpP7PrGAmYmPLAvTCFKG1bib4nc3wEdicL4ialAaQqO6G1Bia93UdLchy0dQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用户接口&lt;/strong&gt;：ClientCLI、JDBC访问Hive、WEBUI浏览器访问Hive。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;元数据&lt;/strong&gt;：Hive将元数据存储在数据库中，如mysql、derby。Hive中的元数据包括表的名字，表的列和分区以及属性，表的属性（是否为外部表等），表的数据所在目录等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;驱动器&lt;/strong&gt;：基于解释器、编辑器、优化器完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;执行器引擎&lt;/strong&gt;：ExecutionEngine把逻辑执行计划转换成可以运行的物理计划。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hadoop底层&lt;/strong&gt;：基于HDFS进行存储，使用MapReduce进行计算，基于Yarn的调度机制。&lt;/p&gt;&lt;p&gt;Hive收到给客户端发送的交互请求，接收到操作指令(SQL)，并将指令翻译成MapReduce，提交到Hadoop中执行，最后将执行结果输出到客户端。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;二、Hive环境安装&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;1、准备安装包&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;hive-1.2，依赖Hadoop集群环境，位置放在hop01服务上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、解压重命名&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;tar&lt;/span&gt; -zxvf apache-hive-&lt;span&gt;1&lt;/span&gt;.&lt;span&gt;2&lt;/span&gt;.&lt;span&gt;1&lt;/span&gt;-bin.tar.gz&lt;br/&gt;mv apache-hive-&lt;span&gt;1&lt;/span&gt;.&lt;span&gt;2&lt;/span&gt;.&lt;span&gt;1&lt;/span&gt;-bin/ hive1.&lt;span&gt;2&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3、修改配置文件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;创建配置文件&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 conf]&lt;span&gt;# pwd&lt;/span&gt;&lt;br/&gt;/opt/hive1&lt;span&gt;.2&lt;/span&gt;/conf&lt;br/&gt;[root@hop01 conf]&lt;span&gt;# mv hive-env.sh.template hive-env.sh&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;添加内容&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 conf]&lt;span&gt;# vim hive-env.sh&lt;/span&gt;&lt;br/&gt;&lt;span&gt;export&lt;/span&gt; HADOOP_HOME=/opt/hadoop2&lt;span&gt;.7&lt;/span&gt;&lt;br/&gt;&lt;span&gt;export&lt;/span&gt; HIVE_CONF_DIR=/opt/hive1&lt;span&gt;.2&lt;/span&gt;/conf&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置内容一个是Hadoop路径，和hive配置文件路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、Hadoop配置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先启动hdfs和yarn；然后在HDFS上创建/tmp和/user/hive/warehouse两个目录并修改赋予权限。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;bin/hadoop fs -&lt;span&gt;mkdir&lt;/span&gt; /tmp&lt;br/&gt;bin/hadoop fs -&lt;span&gt;mkdir&lt;/span&gt; -p /user/hive/warehouse&lt;br/&gt;bin/hadoop fs -&lt;span&gt;chmod&lt;/span&gt; g+w /tmp&lt;br/&gt;bin/hadoop fs -&lt;span&gt;chmod&lt;/span&gt; g+w /user/hive/warehouse&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;5、启动Hive&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 hive1&lt;span&gt;.2&lt;/span&gt;]&lt;span&gt;# bin/hive&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;6、基础操作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;查看数据库&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;hive&amp;gt;&lt;/span&gt;&lt;span&gt; show databases ;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;选择数据库&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hive&amp;gt; &lt;span&gt;use&lt;/span&gt; &lt;span&gt;default&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;查看数据表&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;hive&amp;gt;&lt;/span&gt;&lt;span&gt; show tables;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;创建数据库使用&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hive&amp;gt; create database mytestdb;&lt;br/&gt;hive&amp;gt; show databases ;&lt;br/&gt;&lt;span&gt;default&lt;/span&gt;&lt;br/&gt;mytestdb&lt;br/&gt;hive&amp;gt; &lt;span&gt;use&lt;/span&gt; &lt;span&gt;mytestdb&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;创建表&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;create&lt;/span&gt; &lt;span&gt;table&lt;/span&gt; hv_user (&lt;span&gt;id&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;, &lt;span&gt;name&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;, age &lt;span&gt;int&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;查看表结构&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hive&amp;gt; desc hv_user;&lt;br/&gt;id                      &lt;span&gt;int&lt;/span&gt;                                         &lt;br/&gt;name                    &lt;span&gt;string&lt;/span&gt;                                      &lt;br/&gt;age                     &lt;span&gt;int&lt;/span&gt; &lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;添加表数据&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;insert&lt;/span&gt; &lt;span&gt;into&lt;/span&gt; hv_user &lt;span&gt;values&lt;/span&gt; (&lt;span&gt;1&lt;/span&gt;, &lt;span&gt;&quot;test-user&quot;&lt;/span&gt;, &lt;span&gt;23&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;查询表数据&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hive&amp;gt; &lt;span&gt;select&lt;/span&gt; * &lt;span&gt;from&lt;/span&gt; hv_user ;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;注意：这里通过对查询日志的观察，明显看出Hive执行的流程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;删除表&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;hive&amp;gt;&lt;/span&gt;&lt;span&gt; drop table hv_user ;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;退出Hive&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;hive&amp;gt;&lt;/span&gt;&lt;span&gt; quit;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;查看Hadoop目录&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;# hadoop fs -ls /user/hive/warehouse       &lt;/span&gt;&lt;br/&gt;/user/hive/warehouse/mytestdb.db&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过Hive创建的数据库和数据存储在HDFS上。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;三、整合MySQL5.7环境&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;这里默认安装好MySQL5.7的版本，并配置好相关登录账号，配置root用户的Host为%模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1、上传MySQL驱动包&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;将MySQL驱动依赖包上传到hive安装目录的lib目录下。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 &lt;span&gt;lib&lt;/span&gt;]&lt;span&gt;# pwd&lt;/span&gt;&lt;br/&gt;/opt/hive1&lt;span&gt;.2&lt;/span&gt;/&lt;span&gt;lib&lt;/span&gt;&lt;br/&gt;[root@hop01 &lt;span&gt;lib&lt;/span&gt;]&lt;span&gt;# ll&lt;/span&gt;&lt;br/&gt;mysql-connector-java&lt;span&gt;-5.1&lt;/span&gt;&lt;span&gt;.27&lt;/span&gt;-bin.jar&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2、创建hive-site配置&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 conf]&lt;span&gt;# pwd&lt;/span&gt;&lt;br/&gt;/opt/hive1&lt;span&gt;.2&lt;/span&gt;/conf&lt;br/&gt;[root@hop01 conf]&lt;span&gt;# touch hive-site.xml&lt;/span&gt;&lt;br/&gt;[root@hop01 conf]&lt;span&gt;# vim hive-site.xml&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3、配置MySQL存储&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&amp;lt;&lt;span&gt;configuration&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionURL&lt;span&gt;&amp;lt;/&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;jdbc:mysql://hop01:3306/metastore?createDatabaseIfNotExist=true&lt;span&gt;&amp;lt;/&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;JDBC connect string for a JDBC metastore&lt;span&gt;&amp;lt;/&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;/&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionDriverName&lt;span&gt;&amp;lt;/&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;com.mysql.jdbc.Driver&lt;span&gt;&amp;lt;/&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;Driver class name for a JDBC metastore&lt;span&gt;&amp;lt;/&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;/&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionUserName&lt;span&gt;&amp;lt;/&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;root&lt;span&gt;&amp;lt;/&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;username to use against metastore database&lt;span&gt;&amp;lt;/&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;/&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionPassword&lt;span&gt;&amp;lt;/&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;123456&lt;span&gt;&amp;lt;/&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;password to use against metastore database&lt;span&gt;&amp;lt;/&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;/&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;configuration&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置完成后，依次重启MySQL、hadoop、hive环境，查看MySQL数据库信息，多了metastore数据库和相关表。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、后台启动hiveserver2&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 hive1&lt;span&gt;.2&lt;/span&gt;]&lt;span&gt;# bin/hiveserver2 &amp;amp;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;5、Jdbc连接测试&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[&lt;span&gt;root@hop01 hive1.2&lt;/span&gt;]&lt;span&gt;# bin/beeline&lt;/span&gt;&lt;br/&gt;Beeline version &lt;span&gt;1.2&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; Apache Hive&lt;br/&gt;beeline&amp;gt; !connect jdbc:hive2:&lt;span&gt;//hop01:10000&lt;/span&gt;&lt;br/&gt;Connecting to jdbc:hive2:&lt;span&gt;//hop01:10000&lt;/span&gt;&lt;br/&gt;Enter username &lt;span&gt;for&lt;/span&gt; jdbc:hive2:&lt;span&gt;//hop01:10000: hiveroot (账户回车)&lt;/span&gt;&lt;br/&gt;Enter password &lt;span&gt;for&lt;/span&gt; jdbc:hive2:&lt;span&gt;//hop01:10000: ******   (密码123456回车)&lt;/span&gt;&lt;br/&gt;Connected to: &lt;span&gt;Apache &lt;span&gt;Hive&lt;/span&gt; (&lt;span&gt;version &lt;span&gt;1.2&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;&lt;/span&gt;)&lt;br/&gt;Driver: Hive &lt;span&gt;JDBC&lt;/span&gt; (&lt;span&gt;version &lt;span&gt;1.2&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;&lt;/span&gt;)&lt;br/&gt;0: jdbc:hive2:&lt;span&gt;//hop01:10000&amp;gt; show databases;&lt;/span&gt;&lt;br/&gt;+----------------+--+&lt;br/&gt;| database_name  |&lt;br/&gt;+----------------+--+&lt;br/&gt;| &lt;span&gt;default&lt;/span&gt;        |&lt;br/&gt;+----------------+--+&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h1&gt;&lt;span&gt;四、高级查询语法&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;1、基础函数&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;count&lt;/span&gt;(*) count_user &lt;span&gt;from&lt;/span&gt; hv_user;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;(age) sum_age &lt;span&gt;from&lt;/span&gt; hv_user;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;min&lt;/span&gt;(age) min_age,&lt;span&gt;max&lt;/span&gt;(age) max_age &lt;span&gt;from&lt;/span&gt; hv_user;&lt;br/&gt;+&lt;span&gt;----------+----------+--+&lt;/span&gt;&lt;br/&gt;| min_age  | max_age  |&lt;br/&gt;+&lt;span&gt;----------+----------+--+&lt;/span&gt;&lt;br/&gt;| 23       | 25       |&lt;br/&gt;+&lt;span&gt;----------+----------+--+&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2、条件查询语句&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;select&lt;/span&gt; * &lt;span&gt;from&lt;/span&gt; hv_user &lt;span&gt;where&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;&#x27;test-user&#x27;&lt;/span&gt; &lt;span&gt;limit&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;| hv_user.id  | hv_user.name  | hv_user.age  |&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;| 1           | test-user     | 23           |&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt; * &lt;span&gt;from&lt;/span&gt; hv_user &lt;span&gt;where&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;&amp;gt;&lt;span&gt;1&lt;/span&gt; &lt;span&gt;AND&lt;/span&gt; &lt;span&gt;name&lt;/span&gt; &lt;span&gt;like&lt;/span&gt; &lt;span&gt;&#x27;dev%&#x27;&lt;/span&gt;;&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;| hv_user.id  | hv_user.name  | hv_user.age  |&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;| 2           | dev-user      | 25           |&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;count&lt;/span&gt;(*) count_name,&lt;span&gt;name&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; hv_user &lt;span&gt;group&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;;&lt;br/&gt;+&lt;span&gt;-------------+------------+--+&lt;/span&gt;&lt;br/&gt;| count_name  |    name    |&lt;br/&gt;+&lt;span&gt;-------------+------------+--+&lt;/span&gt;&lt;br/&gt;| 1           | dev-user   |&lt;br/&gt;| 1           | test-user  |&lt;br/&gt;+&lt;span&gt;-------------+------------+--+&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3、连接查询&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;select&lt;/span&gt; t1.*,t2.* &lt;span&gt;from&lt;/span&gt; hv_user t1 &lt;span&gt;join&lt;/span&gt; hv_dept t2 &lt;span&gt;on&lt;/span&gt; t1.id=t2.dp_id;&lt;br/&gt;+&lt;span&gt;--------+------------+---------+-----------+-------------+--+&lt;/span&gt;&lt;br/&gt;| t1.id  |  t1.name   | t1.age  | t2.dp_id  | t2.dp_name  |&lt;br/&gt;+&lt;span&gt;--------+------------+---------+-----------+-------------+--+&lt;/span&gt;&lt;br/&gt;| 1      | test-user  | 23      | 1         | 技术部      |&lt;br/&gt;+&lt;span&gt;--------+------------+---------+-----------+-------------+--+&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h1&gt;&lt;span&gt;五、源代码地址&lt;/span&gt;&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;GitHub·地址&lt;br/&gt;https:&lt;span&gt;//github.com/cicadasmile/big-data-parent&lt;/span&gt;&lt;br/&gt;GitEE·地址&lt;br/&gt;https:&lt;span&gt;//gitee.com/cicadasmile/big-data-parent&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.3783359497645212&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvCjMheLZtcM2iaVMBOpIUKR4CDRCG9FLT5K6NmGXvG7exrW0TSuDjnTKJQ5PDq8j8Y7PHDd17Z3gicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1274&quot;/&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>46bfb077978831f4e41faabbf9f16d3d</guid>
<title>Spring Boot 集成 JUnit 单元测试</title>
<link>https://toutiao.io/k/60g50xw</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;entry-content&quot;&gt;&amp;#13;

&lt;p&gt;为自己的应用编写单元测试是一个很好的习惯。在Java开发中最流行的测试工具非JUnit莫属，它已经成为Java单元测试的事实标准。Spring Boot测试模块不仅集成JUnit框架，还提供了许多实用程序和注解，方便我们测试应用。&lt;/p&gt;



&lt;span id=&quot;more-103&quot;/&gt;



&lt;h3 class=&quot;has-black-color has-text-color has-background&quot; id=&quot;1-添加依赖-spring-boot-starter-test&quot;&gt;&lt;strong&gt;1. 添加依赖&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;在 pom.xml 文件中引入 spring-boot-starter-test&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${version}&amp;lt;/version&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;



&lt;p&gt;Spring Boot 2.2.x 开始集成的是JUnit 5。如果之前是使用的JUnit 4，可以使用JUnit 5中提供的老式引擎运行，需要添加 junit-vintage-engine 依赖。&lt;/p&gt;



&lt;p&gt;Spring Boot 2.2.x发布很久了，现在最新稳定版是2.4.x。旧的总要被替代，所以本篇只用JUnit 5，关于JUnit 4的文章相信网上很多，官方也有给出使用说明，请自行查找。&lt;/p&gt;



&lt;h3 class=&quot;has-black-color has-text-color has-background&quot; id=&quot;2-编写单元测试&quot;&gt;&lt;strong&gt;2. 编写单元测试&lt;/strong&gt;&lt;/h3&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;@SpringBootTest(classes = Application.class, webEnvironment = SpringBootTest.WebEnvironment.DEFINED_PORT)
public class JUnitTest {

    @Test
    public void test() {
        &lt;em&gt;// 测试代码&lt;/em&gt;
    }
}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 id=&quot;springboottest-重要参数&quot;&gt;@SpringBootTest 重要参数&lt;/h3&gt;



&lt;ul&gt;&lt;li&gt;&lt;strong&gt;args&lt;/strong&gt;&lt;br/&gt;应用程序参数，如:args = “–app.test=one”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;classes&lt;/strong&gt;&lt;br/&gt;Spring Boot应用启动入口类名，该参数不指定时由Spring Boot默认查找。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;webEnvironment&lt;/strong&gt;&lt;br/&gt;默认情况下@SpringBootTest不会启动服务器。当测试Web应用时，需指定该参数以便加载上下文环境。&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;WebEnvironment枚举值说明：&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;&lt;strong&gt;MOCK&lt;/strong&gt;&lt;br/&gt;默认值，加载WebApplicationContext并提供模拟Web环境。使用此注释时，不会启动嵌入式服务器。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;RANDOM_PORT&lt;/strong&gt;&lt;br/&gt;启动应用并随机监听一个端口。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;DEFINED_PORT&lt;/strong&gt;&lt;br/&gt;启动应用并监听自定义的端口(来自application.properties)或使用默认端口8080。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;NONE&lt;/strong&gt;&lt;br/&gt;ApplicationContext通过使用加载，SpringApplication但不提供任何网络环境(模拟或其他方式)。&lt;/li&gt;&lt;/ul&gt;



&lt;h3 id=&quot;test&quot;&gt;@Test&lt;/h3&gt;



&lt;p&gt;注意 JUnit 5 的 @Test 注解在 org.junit.jupiter.api 包下。&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator&quot;/&gt;



&lt;p&gt;如果应用使用Spring MVC和 Spring WebFlux，则优先MVC。测试WebFlux应用必须设置：&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;@SpringBootTest(properties = &quot;spring.main.web-application-type=reactive&quot;)
public class MyWebFluxTests {

}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 class=&quot;has-black-color has-text-color has-background&quot; id=&quot;3-自动装配测试&quot;&gt;&lt;strong&gt;3. 自动装配测试&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;有时候我们只需要测试框架模块集成是否正常，不需要加载整个项目。可以使用 spring-boot-test-autoconfigure 模块中一些注解。整个框架被“切片”成独立的测试模块。&lt;/p&gt;



&lt;h3 id=&quot;json-测试&quot;&gt;JSON 测试&lt;/h3&gt;



&lt;p&gt;测试JSON序列化与反序列化。如果是GSON或JSONB，使用 @GsonTester 或 @JsonbTester 注解。&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;&lt;em&gt;/**
 * @author Engr-Z
 * @since 2021/1/18
 */&lt;/em&gt;
@JsonTest
public class MyJsonTest {

    @Autowired
    private JacksonTester&amp;lt;Map&amp;gt; json;

    @Test
    void testSerialize() throws Exception {
        Map&amp;lt;String, Object&amp;gt; map = new HashMap&amp;lt;&amp;gt;();
        map.put(&quot;name&quot;, &quot;攻城狮·正&quot;);
        map.put(&quot;websit&quot;, &quot;engr-z.com&quot;);
        
        Assertions.assertThat(this.json.write(map)).isEqualToJson(&quot;expected.json&quot;);
        Assertions.assertThat(this.json.write(map)).hasJsonPathStringValue(&quot;@.make&quot;);
        Assertions.assertThat(this.json.write(map)).extractingJsonPathStringValue(&quot;@.make&quot;)
                .isEqualTo(&quot;Honda&quot;);
    }

    @Test
    void testDeserialize() throws Exception {
        String content = &quot;{\&quot;name\&quot;:\&quot;攻城狮·正\&quot;,\&quot;website\&quot;:\&quot;engr-z.com\&quot;}&quot;;
        Assertions.assertThat(this.json.parse(content));
        Assertions.assertThat(this.json.parseObject(content).get(&quot;website&quot;)).isEqualTo(&quot;engr-z.com&quot;);
    }

}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 id=&quot;spring-mvc-测试&quot;&gt;Spring MVC 测试&lt;/h3&gt;



&lt;p&gt;测试 /demo/hello 接口是否正常&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;&lt;em&gt;/**
 * @author Engr-Z
 * @since 2021/1/18
 */&lt;/em&gt;
@WebMvcTest(DemoController.class)
public class SpringMVCTest {

    @Autowired
    private MockMvc mvc;

    @Test
    void test() throws Exception {
        RequestBuilder builder = MockMvcRequestBuilders.get(&quot;/demo/hello&quot;);
        ResultActions resultActions = mvc.perform(builder);
        int status = resultActions.andReturn().getResponse().getStatus();
        Assertions.assertEquals(200, status);
    }
}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 id=&quot;spring-webflux-测试&quot;&gt;Spring WebFlux 测试&lt;/h3&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;&lt;em&gt;/**
 * @author Engr-Z
 * @since 2021/1/18
 */&lt;/em&gt;
@WebFluxTest(DemoController.class)
public class SpringWebFluxTest {

    @Autowired
    private WebTestClient webClient;

    @Test
    void test() throws Exception {
        webClient.get().uri(&quot;/demo/webflux&quot;)
                .accept(MediaType.TEXT_PLAIN)
                .exchange()
                .expectStatus().isOk();
    }
}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 id=&quot;jdbc-测试&quot;&gt;JDBC 测试&lt;/h3&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;@JdbcTest
@Transactional(propagation = Propagation.NOT_SUPPORTED)
class JdbcTransactionalTests {

}&lt;/code&gt;&lt;/pre&gt;



&lt;hr class=&quot;wp-block-separator&quot;/&gt;



&lt;p&gt;自动装配还支持 JPA，Redis，Rest Client 等模块测试。更多请参考：&lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-testing-spring-boot-applications-testing-autoconfigured-tests&quot;&gt;Auto-configured Tests&lt;/a&gt;&lt;/p&gt;



&lt;h3 class=&quot;has-black-color has-text-color has-background&quot; id=&quot;mockbean-和-spybean&quot;&gt;&lt;strong&gt;@MockBean 和 @SpyBean&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;如果一个服务依赖于远程调用的结果。为了不影响我们做单元测试，可以使用&lt;code&gt;@MockBean&lt;/code&gt;。以下是官方代码示例：&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;@SpringBootTest
class MyTests {

    @MockBean
    private RemoteService remoteService;

    @Autowired
    private Reverser reverser;

    @Test
    void exampleTest() {
        &lt;em&gt;// RemoteService has been injected into the reverser bean&lt;/em&gt;
        BDDMockito.given(this.remoteService.someCall()).willReturn(&quot;mock&quot;);
        String reverse = reverser.reverseSomeCall();
        Assertions.assertThat(reverse).isEqualTo(&quot;kcom&quot;);
    }

}&lt;/code&gt;&lt;/pre&gt;



&lt;p&gt;&lt;code&gt;@SpyBean&lt;/code&gt; 和 &lt;code&gt;@MockBean&lt;/code&gt; 不同之处是：对于未指定mock的方法，spy默认会调用真实的方法，有返回值的返回真实的返回值，而mock默认不执行，有返回值的，默认返回null&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator&quot;/&gt;



&lt;p&gt;本篇只介绍 Spring Boot 集成 JUnit 单元测试，关于 JUnit 用法会在以后篇章详细讲解。&lt;/p&gt;
&lt;hr/&gt;&lt;/div&gt;&amp;#13;
&amp;#13;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>0ac0c7405df43d57a4cd8bd5c2bc8072</guid>
<title>MySQL 海量运维管理如何保障京东大促？</title>
<link>https://toutiao.io/k/1pmdtwx</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;当我们遇到海量这个词的时候，大家第一时间会想到和数据库相关的哪些内容？比如海量的数据量、大规模的数据库的节点数、高并发的业务访问。海量的数据带来的是存储和弹性扩展的问题，大规模的数据库节点给我们带来的是批量运维的困扰，高并发访问带来的是性能的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我认为，解决大部分的海量数据的问题，一般有三种通用的方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以说今天我的议题也是从里面找了几个点，来给大家分享。通过海量运维的概述，给大家介绍一下我们是怎么去做数据生态管控的，以及我们一些数据库管控组件的功能介绍。其次想给大家介绍一下在面临大规模的数据库节点运维的时候，我们如何去搭建高可用的容灾体系，或者说如何去做高可用解决方案的选型。接下来会通过介绍资源的管理和告警信息的管理，告诉大家我们的一些自动化运维的思想是什么。最后就是我们会把海量运维的管理思想在大促备战中进行应用和实践。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;一、海量运维概述&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;314&quot; data-backw=&quot;558&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;328&quot; data-ratio=&quot;0.5618811881188119&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/GpR9scLygItRDxiapoqXB3mj7JNdudRx4ZXUCeoxAS6MianQbW7OZU6UVbiak2QrWibIxtbyXAftLWM8IbbyEjBicLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;808&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先整体来说这是我们公司的一个数据库运维拓扑图，中间是整个数据库集群，不管是单库还是水平拆分的，应用都是通过智能DNS或者vip访问数据库的，如果是单库就直接连到主从架构，如果是水平拆分就是通过Sharding-Sphere或者CDS数据库中间件产品访问后面的数据节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这里我们可以在中间件这层实现数据加密和脱敏的数据管控目标。如果你要是单库的话，我们这个数据加密和脱敏是放在应用的代码里面，如果你要是用水平拆分的话，分布式中间件天然就支持加密脱敏的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来数据写入到数据库之后，左右两侧其实就是数据的一些流转功能。DBRep和DTS主要指的是实现数据流转到AP的查询平台，流转到一些运营后台的其他业务逻辑的查询数据库里面去。左边Archiver是数据归档平台，实现数据冷热分离。还有PillBOX是备份管控的平台，可以把数据库的备份按照一定的规则策略传入到Hadoop，再传到磁带库里，这样整体来说数据库备份的整个生命周期可以得到很好的管控。从online环境传输到nearline环境，最后进入到offline的磁带库中，再结合备份保留策略以及逆向的恢复功能，备份平台可以覆盖数据库备份恢复的所有需求功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面就是DBA运维的一些管控。DBCM就是一个建模平台，所有数据库的建库建表逻辑要通过这个平台来创建，如果不通过这个平台，大家可以想到，在这种大数据后期的一些建设中，你就会发现你的数据的质量会有很严重的问题，不管是元数据还是业务数据都或多或少出现数据质量问题，所以说通过建模平台我们做到了从建模源头开始规范和引导研发的业务模型设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次是查询平台，研发在做开发的时候，包括业务运营人员需要对数据库进行一些数据查询、获取，查询平台里面会包含一些加密、脱敏、查询记录条数和导出的一些管控限制的功能，通过这种方式我们能够很好的做到企业级安全合规的管控和限制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;CleverDB是性能管控平台，我们可以给研发\DBA还有一些其他想关注数据库的人员一个非常友好的可视化平台，对于研发用户来说数据库就是一个黑盒产品，通过这种可视化的管理，可以讲一些专业化的性能指标转换为数字化，以可视化的解决展示给我们的需求方，这样可以驱动他们自主管理各自业务数据库。在大规模运维体系中，研发自驱管理数据库和数据库自助化服务逐渐成为新生的运维力量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;OnLine平台是一个流程管控平台，不管做变更也好，做大规模的架构调整也好，都需要一个企业级的合规流程才能完成这个动作。最后就是自动化运维平台，我们在管理上万台服务器的时候，就是通过这些平台工具提升运维效率的，总之拥有一个完整的数据库生态的工具平台，然后基于这个平台逐渐实现自动化、流程化&lt;span&gt;、&lt;/span&gt;&lt;span&gt;智能化，&lt;/span&gt;是驾驭海量运维场景必经之路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;二、海量运维的高可用体系&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;312&quot; data-backw=&quot;558&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;312&quot; data-ratio=&quot;0.5592592592592592&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/GpR9scLygItRDxiapoqXB3mj7JNdudRx4oYZXbJRegH7NSibKXsV3NpibyZS78lUuO2VSOQrHw9TgEPNwJYJCEvEw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;810&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次我想说的是通过高可用体系的介绍，让大家去了解如何在这种海量的节点运维过程中，如何做这种容灾体系的建设或者去做选型这块的逻辑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1、优质的容灾服务质量&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提供优质的容灾服务质量，RTO&amp;lt;10s。它主要的逻辑流程通过秒级监控可以快速感知故障，然后通过的哨兵探测逻辑，可以验证监控结果的准确性，第三步调用核心切换模块，进行切换环境检查、数据一致性校验、主从切换、vip映射关系变更、元数据信息变更、切换消息通知等。最终实现容灾管控自动化，实现故障自愈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2、良好的兼容性和适配性&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二点我们要考虑到容灾体系的兼容性和适配性，因为在一个企业里面其实你的数据库的架构并不完全标准的一模一样。比如说业务会分等级，分等级之后主库从库的数量会随着业务等级的不一样会有一些变化，还有有些业务会做跨机房的容灾，还会做多活、多中心的架构。所以高可用容灾体系要具备良好的兼容性和适配性，比如要兼容不同的架构，不同的版本，不同接入方式和不同的资源环境。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;3、可靠的切换决策模型&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当故障发生时，切换之前的故障探测、故障场景的分析以及切换决策的逻辑，这些方面要远远比切换本身重要。所以这个模型能帮助我们辨识极端场景，避免错误切换或者脑裂问题。举个例子，比如有一个人突然间身体发生了状况，首先最重要的是要及时发现他有问题，第二及时送到医院，接下来医生要及时判别他到底是什么样的问题，最后才能做紧急的治疗和抢救措施。所以说这个决策模型其实做的就是发现和诊断的过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;4、服务自身的可用性保障&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四点就是服务自身的可用性保障。也就是说如果真的出现机房级别的宕机时，其实高可用服务也是挂了的，你如何能够在另外一个机房把你的高可用服务拉起来，然后在高可用服务启动之后才能去做机房级的容灾，所以这种能力也是需要大家再去考虑的一个点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;5、平台自动化的管控&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第五点就是平台自动化的管控。通过配置的统一管理，包括切换进度、历史查询的这些功能，可以帮助我们在大规模数据库运维背景下去提高我们容灾的效率，同时丰富的API接口和可视化信息，能够提供一些非常良好的兼容性和适配性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;6、丰富的容灾类型&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后就是丰富的容灾类型。我们一般情况下都会做主库容灾，像MHA是一个主库容灾的能力，其实它不能提供从库的容灾。然后在容灾类型上面，也要考虑手动切换、自动切换，因为我们会做一些切换演练，比如我们做大促准备的时候经常做一些切换演练，主从切换、主备切换、跨机房的批量切换，这种能力都是需要在高可用体系里面去体现出来的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;三、海量资源管理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;313&quot; data-backw=&quot;558&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;329&quot; data-ratio=&quot;0.5604938271604938&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/GpR9scLygItRDxiapoqXB3mj7JNdudRx4O5hdTCRXwNCUzzup6FAKWgKX6UCPV2B7cZKTnH36M99YgagAYXJ32Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;810&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;资源管理其实就是以前我们在规模非常小的时候用Excel管理数据库资源，但是现在公司的规模越来越大，数据库的节点数越来越多，自动化平台建立起来之后我们会发现有很多维度的元数据需要我们做管控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1、资源自动上报&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先资源节点自动上报，例如公司采购了一百台机器，这些机器怎么录入到这个系统里面？我们是通过给每台机器装一个agent端，它会自动上报它的IP，还有这些机器所在的网段、机房、机柜等信息是通过跟IT运维系统去进行对接，通过他们提供的API接口把这些信息抓过来，这样你的信息才能健全。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2、服务器使用状态的管理&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二点就是服务器使用状态的管理，比如这个服务器到底有什么样的业务在使用，有没有报错，有没有报修，它的维修进度是什么，这些都需要在我们的系统里记录。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们在以前就出现过类似的问题，比如说我们要给这台机器去做维修了，因为一些元数据的不准确，可能那台服务器上还有一些其他业务运行，导致那个业务就因为关机而中断了服务，所以元数据的准确性也非常重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;3、数据库与业务研发匹配&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，数据库跟业务这种两个视角的同步和串联的问题。也就是说我的数据库只记录了它是什么样的架构，它跟业务的对应关系没有建立起来，是两个业务的数据库，这个数据库又被哪些业务所访问，包括这些业务是哪些研发负责人去负责的，我们需要把这些相关的信息串联起来，最后形成一个血缘关系，或者知识拓扑图，让大家能够很清晰地了解到我们的元数据的信息是什么样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;4、元数据变更管理&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第四，元数据的变更，比如你做了主从的切换，服务器的维修，包括一些服务器的名字的变更，所有这样的事情。以及比如说研发负责人、公司组织架构调整、部门信息的调整，对应到数据库的管控里面，元数据都会涉及到一系列的变更。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;5、资产管理&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第五就是资产的管理。作为DBA要能够给到各个业务部门提供数据库服务器使用情况，能够告诉业务部门负责人，这个季度或者这半年服务器资产使用的情况，这种所谓的报表或者视图的信息，也是需要提供的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;6、API服务&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后就是API服务，因为作为一个数据库来说，它只是在IT系统里面其中一个平台，所以它要跟其他的平台去进行信息的交互，通过信息的交互，才能够把所有运维体系的数据串联起来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;四、海量告警管理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;314&quot; data-backw=&quot;558&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;364&quot; data-ratio=&quot;0.5618811881188119&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/GpR9scLygItRDxiapoqXB3mj7JNdudRx4pNTfnHqqyIVfKiaROTuZVRaV06ZXbaGVJ4c1asXgXUQ0d6VDsauJxwA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;808&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;告警管理也是运维体系中非常关键的管理维度，在我们机器非常多的情况下，每天会收到很多告警。许多人私底下聊天的时候经常表达今天收到好几千条告警，以此来证明他们公司数据库规模有多庞大。其实我觉得这是不对的，应该告诉大家，我们数据库规模非常大，但是我们每天只收几十条告警。以此来证明我们有非常强大的运维管控能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;怎么做到的？其实就是通过告警的管理，通过一系列的方法去实现告警数量的降低，有效告警能够很直接，很清晰的暴露出来，而不会被海量的告警信息所淹没。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1、触发告警&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们现在很多公司的监控告警体系都停留在第一阶段，就是我们制定各种指标的告警基线，设置告警级别，通过这种方式去给相关的业务负责人，相关的运维人员发告警短信。在这种情况下其实是没有任何过滤信息的，只要你触发了这个基线，你就会收到告警信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际情况是什么样的？给大家举个例子，主从延时这件事，当你做一个大事务的时候，重复延时可能是相当长的时间，有可能是半小时或者一个小时，半个小时之内可能每隔两三分钟就收一条告警，其实对于运维人员来说，他是不在意的，他知道这是一个大事务，他知道这个事务要继续做下去，所以就会有第二个方法，就是汇总分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2、汇总分析&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;汇总分析是什么？其实说白了就是一个告警的收敛，我们会把一些连续重复的告警进行一个收敛，然后减少接收人员接收到的告警条数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再一个就是单因多果的分析，比如说这台机器宕机了，你会收到一条宕机的告警，同时你会收到一堆其他的告警，比如连接数访问异常，还有主从中断，你会收到一堆这样的告警，其实最有用的一条告警就是机器宕机。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以我们要通过单因多果的关联分析，最终找到根因点是什么，这也是一个我们在运维里面根因分析的一种方法，通过这个模型我们可以去把最根本的原因找出来，然后发给相关的运维人员，避免有用的信息被海量的告警信息所淹没这种情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;3、以点推面&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三个就是以点推面，这里有两个场景：一个就是场景就像我刚才说的在主库执行一个大事务，我肯定能够预判到在之后的未来的半个小时之内，所有的从库都会有延时，这个时候运维人员可以干预一下告警决策，告诉他半个小时之内这些从库可以不发延时告警。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再一个比如我们在大促之前会做切换容灾演练，主从切换的时候势必也会发一些告警，这些告警一般都是在夜里做容灾切换演练的，所以如果这个时候去发告警，会影响好多人的休息，比如相关、不相关的业务人员，他都会收到机器切换的告警。所以在计划内的一些切换的时候，其实我们也是可以预判到的，然后提前将这些告警信息进行一个参数的调整，去避免这样的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;4、调节基线&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再一个就是基线的调整。比如像大促的时候，双十一、双十二的时候，高峰之前的时候，我们能预判到整个告警基线，或者告警参数需要进行一个很大的调整。比如说并发数，比如说事务的超时时间，我们可能都要做一个调整，来满足大促峰值的冲击压力，不至于大促来临那一刻，你的手机都有可能接收过多的短信。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt;&lt;span data-bgopacity=&quot;25%&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;5、精确告警&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过一系列的调整和模型的建设，最后达到的效果就是减少无用的告警，减少运维人员和研发人员的感官的疲劳，同时他也能够减少告警短信的成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;五、大促备战分享&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;314&quot; data-backw=&quot;558&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;335&quot; data-ratio=&quot;0.5631188118811881&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/GpR9scLygItRDxiapoqXB3mj7JNdudRx45guziaLDPfHRsOY86iaNQg8W7kic6cBXLHWwt80bDeuLUsE3QoGXZvElg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;808&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后给大家分享一下我们大促的整个过程，其实这个过程就分为三个部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先是备战部分，备战之前基本上是提前一个月到一个半月的时候开始准备，接下来主要介绍一下在面对多大规模的服务器的时候，我们不可能把所有的数据库节点都one by one管理起来，那我们如何去做运维呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在这些点上如果作为DBA能够很好的管控的话，其实整个大促的过程应该还是相对比较轻松的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图就是大促过程中比较核心要去关注的几个点，如果你要去支持一个数据库的大促运维，或者说去做一些数据库的巡检，你应该从哪几个方面去看或者去检查你的数据库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;312&quot; data-backw=&quot;558&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;323&quot; data-ratio=&quot;0.5585696670776819&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/GpR9scLygItRDxiapoqXB3mj7JNdudRx43oCXLu1ZEqeiaV5CibaxVbiahxz2Z4cr3KYrpNYFmuj0uejeeMe9pic9Ag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;811&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主要有几个点可以让研发去做，通过巡检报告、可视化平台，可以推给研发相应的信息。比如像自增信息、表分区信息、慢查询，其实你可以发给他，由他们自己去做一些相应的调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作为DBA来说，最主要一点是要关注最后一条“业务梳理”，帮助研发梳理业务跟数据库之间到底是不是一个强依赖的关系，一个事务到底读写操作会有多少条，上下游逻辑是什么，能不能做熔断处理。一旦业务系统出现问题是否会影响别人的系统，这些需要DBA做检查。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;再一个就是硬件和机房的巡检，我们在大促过程中主要出的问题可能硬件比较多，硬件出的问题最多的就是磁盘和Raid卡，经常Raid充放电的一瞬间可能会让数据库卡顿几秒钟甚至半分钟，如果这种情况在大促的时候出现那就是灾难级的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;314&quot; data-backw=&quot;558&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;325&quot; data-ratio=&quot;0.562962962962963&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/GpR9scLygItRDxiapoqXB3mj7JNdudRx4Hc3EcnqxW1yz9V9GF0nfP2riaUG5CHibLAO6rZqibsheCwNDHqjdkZJVw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;810&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后做一个总结，不管你前面做了什么样的准备，这六点是你在大促之前必须要关注的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>1bd95cb265c5f43909eff10a6276c3bf</guid>
<title>下一代消息队列 Pulsar 到底是什么？</title>
<link>https://toutiao.io/k/zdb2zbb</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;h1&gt;&lt;span&gt;背景&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h1&gt;&lt;p&gt;之前琢磨了很久一直想写一篇pulsar相关的文章，但是一直知识储备不够，对于很多细节还是不了解，于是查了很多资料，总算是可以凑出一篇文章了。&lt;/p&gt;&lt;p&gt;Pulsar是一个由yahoo公司于2016年开源的消息中间件，2018年成为Apache的顶级项目。在我之前的文章中写过很多其他消息中间件的文章，比如kafka,rocketmq等等，如果大家对于消息队列不了解的可以阅读以下我之前的文章：&lt;/p&gt;&lt;p&gt;在开源的业界已经有这么多消息队列中间件了，pulsar作为一个新势力到底有什么优点呢？pulsar自从出身就不断的再和其他的消息队列(kafka,rocketmq等等)做比较，但是Pulsar的设计思想和大多数的消息队列中间件都不同，具备了高吞吐，低延迟，计算存储分离，多租户，异地复制等功能，所以pulsar也被誉为下一代消息队列中间件，接下来我会一一对其进行详细的解析。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;pulsar架构原理&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h1&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.64625&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpdPPsZbeAvrrzUdzaiaWOlGJNWAfwjkvl812I4DN1EZ0mWJmQiaHuAFGQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;br/&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6613039796782387&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicp2Z2rQo555PBQwJo0ESGSUZUj47QhaYiaficfPYabicImNjmehiaO0bNENg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1181&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;br/&gt;整体的架构和其他的消息队列中间件差别不是太大，相信大家也看到了很多熟悉的名词，接下来会给大家一一解释这些名词的含义。&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;名词解释&lt;/span&gt;&lt;/h2&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Producer:消息生产者，将消息发送到broker。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Consumer:消息消费者，从Broker读取消息到客户端，进行消费处理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Broker: 可以看作是pulsar的server,Producer和Consumer都看作是client.消息处理的节点，pulsar的Broker和其他消息中间件的都不一样，他是无状态的没有存储，所以可以无限制的扩展，这个后面也会详解讲到。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Bookie: 负责所有消息的持久化，这里采用的是Apache Bookeeper。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ZK: 和kafka一样pulsar也是使用zk保存一些元数据，比如配置管理,topic分配，租户等等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Service Discovery：可以理解为Pulsar中的nginx，只用一个url就可以和整个broker进行打交道，当然也可以使用自己的服务发现。客户端发出的读取，更新或删除主题的初始请求将发送给可能不是处理该主题的 broker 。如果这个 broker 不能处理该主题的请求，broker 将会把该请求重定向到可以处理主题请求的 broker。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不论是kafka,rocketmq还是我们的pulsar其实作为消息队列中间件最为重要的大概就是分为三个部分：&lt;/p&gt;&lt;p&gt;而我们后面也会围绕着这三个部分进行展开讲解。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;Producer生产消息&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;先简单看一下如何用代码进行消息发送：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;PulsarClient client = PulsarClient.create(&lt;span&gt;&quot;pulsar://pulsar.us-west.example.com:6650&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;Producer producer = client.createProducer(&lt;br/&gt;                &lt;span&gt;&quot;persistent://sample/standalone/ns1/my-topic&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// Publish 10 messages to the topic&lt;/span&gt;&lt;br/&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;10&lt;/span&gt;; i++) {&lt;br/&gt;    producer.send(&lt;span&gt;&quot;my-message&quot;&lt;/span&gt;.getBytes());&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;url的格式为：{persistent|non-persistent}://tenant/namespace/topic&lt;/p&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;组成&lt;/th&gt;&lt;th&gt;含义&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;persistent/non-persistent&lt;/td&gt;&lt;td&gt;Pulsar 提供持久化、非持久化两种主题，如果选择的是非持久化主题的话，所有消息都在内存中保存，如果broker重启，消息将会全部丢失。如果选择的是持久化主题，所有消息都会持久化到磁盘，重启broker，消息也可以正常消费。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;tenant&lt;/td&gt;&lt;td&gt;顾名思义就是租户，pulsar最开始在雅虎内部是作为全公司使用的中间件使用的，需要给topic指定一些层级，租户就是其中一层，比如这个可以是一个大的部门，例如电商中台租户。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;namespace&lt;/td&gt;&lt;td&gt;命名空间，可以看作是第二层的层级，比如电商中台下的订单业务组&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;topic&lt;/td&gt;&lt;td&gt;消息队列名字&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;上面三个步骤中，步骤1，2属于我们准备阶段，用于构建客户端，构建Producer，我们真的核心逻辑在send中，那这里我先提几个小问题，大家可以先想想在其他消息队列中是怎么做的，然后再对比pulsar的看一下：&lt;/p&gt;&lt;h3&gt;&lt;span&gt;发送模式&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;我们上面说了send分为async和sync两种模式，但实际上在pulsar内部sync模式也是采用的async模式，在sync模式下模拟回调阻塞，达到同步的效果，这个在kafka中也是采用的这个模式，但是在rocketmq中，所有的send都是真正的同步，都会直接请求到broker。&lt;/p&gt;&lt;p&gt;基于这个模式，在pulsar和kafka中都支持批量发送，在rocketmq中是直接发送，批量发送有什么好处呢？当我们发送的TPS特别高的时候，如果每次发送都直接和broker直连，可能会做很多的重复工作，比如压缩，鉴权，创建链接等等。比如我们发送1000条消息，那么可能会做1000次这个重复的工作，如果是批量发送的话这1000条消息合并成一次请求，相对来说压缩，鉴权这些工作就只需要做一次。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6829268292682927&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpicYSEb74hicQiajAdXicp7FAhKtwNddrnzlrZN7CzZZ7drtKEOxvIrHdBA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;615&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;有同学可能会问，批量发送会不会导致发送的时间会有一定的延误？这个其实不需要担心，在pulsar中默认定时每隔1ms发送一次batch,或者当batchsize默认到了1000都会进行发送，这个发送的频率都还是很快的。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;发送负载均衡&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;在消息队列中通常会将topic进行水平扩展，在pulsar和kafka中叫做partition,在rocketmq中叫做queue，本质上都是分区，我们可以将不同分区落在不同的broker上，达到我们水平扩展的效果。&lt;/p&gt;&lt;p&gt;在我们发送的时候可以自己制定选择partition的策略，也可以使用它默认轮训partition策略。当我们选择了partition之后，我们怎么确定哪一个partition对应哪一个broker呢？&lt;/p&gt;&lt;p&gt;可以先看看下面这个图：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5947441217150761&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpxp5CtL6ECZQiageZabTicmAwjUmOoAqPiabY9zIC1wcuMjpniciarNB5rUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;723&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step1: 我们所有的信息分区映射信息在zk和broker的缓存中都有进行存储。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step2: 我们通过查询broker，可以获取到分区和broker的关系，并且定时更新。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step3: 在pulsar中每个分区在发送端的时候都被抽象成为一个单独的Producer,这个和kafka,rocketmq都不一样，在kafka里面大概就是选择了partition之后然后再去找partition对应的broker地址，然后进行发送。pulsar将每一个partition都封装成Producer，在代码实现上就不需要去关注他具体对应的是哪个broker,所有的逻辑都在producer这个代码里面，整体来说比较干净。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.1120527306967985&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicp381RgagAa1GiaQVaV0LjgwZqKicgNSCu4JnrpYmRmktbK7D0XNkcV8ZQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1062&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;压缩消息&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;消息压缩是优化信息传输的手段之一，我们通常看见一些大型文件都会是以一个压缩包的形式提供下载，在我们消息队列中我们也可以用这种思想，我们将一个batch的消息，比如有1000条可能有1M的传输大小，但是经过压缩之后可能就只会有几十kb，增加了我们和broker的传输效率，但是与之同时我们的cpu也带来了损耗。Pulsar客户端支持多种压缩类型，如 lz4、zlib、zstd、snappy 等。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.newProducer&lt;/span&gt;()&lt;br/&gt;    &lt;span&gt;.topic&lt;/span&gt;(“&lt;span&gt;test-topic&lt;/span&gt;”)&lt;br/&gt;    &lt;span&gt;.compressionType&lt;/span&gt;(&lt;span&gt;CompressionType&lt;/span&gt;&lt;span&gt;.LZ4&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;.create&lt;/span&gt;();&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;&lt;span&gt;Broker&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;接下来我们来说说第二个比较重要的部分&lt;code&gt;Broker&lt;/code&gt;,在Broker的设计中pulsar和其他所有的消息队列差别比较大，而正是因为这个差别也成为了他的特点。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;计算和存储分离&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;首先我们来说说他最大的特点：计算和存储分离。我们在开始的说过Pulsar是下一代消息队列，就非常得益于他这个架构设计，无论是kafka还是RocketMQ,所有的计算和存储都放在同一个机器上，这个模式有几个弊端：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;扩展困难：当我们需要扩展的集群的时候，我们通常是因为cpu或者磁盘其中一个原因影响，但是我们却要申请一个可能cpu和磁盘配置都很好的机器，造成了资源浪费。并且kafka这种进行扩展，还需要进行迁移数据，过程十分繁杂。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;负载不均衡：当某些partion数据特别多的时候，会导致broker负载不均衡,如下面图，如果某个partition数据特别多，那么就会导致某个broker(轮船)承载过多的数据，但是另外的broker可能又比较空闲&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.593103448275862&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpEVU4vddk4D1d2axUczn6YuicY8AaJIibH2meTJktH4AwZRZdXwgicG1jw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;725&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;pulsar计算分离架构能够非常好的解决这个问题:&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于计算：也就是我们的broker,提供消息队列的读写,不存储任何数据，无状态对于我们扩展非常友好，只要你机器足够，就能随便上。扩容Broker往往适用于增加Consumer的吞吐，当我们有一些大流量的业务或者活动，比如电商大促，可以提前进行broker的扩容。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于存储：也就是我们的bookie,只提供消息队列的存储，如果对消息量有要求的，我们可以扩容bookie,并且我们不需要迁移数据，扩容十分方便。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;消息存储&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;名词解析：&lt;/span&gt;&lt;/h4&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5368916797488226&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpTEBtembhB7CAZzYw9A3Labib9AwibiaiamkkVXPKZrUicuOuKPeqecRibmFg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;637&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是bookie的读写架构图，里面有一些名词需要先介绍一下：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Entry,Entry是存储到bookkeeper中的一条记录，其中包含Entry ID，记录实体等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Ledger，可以认为ledger是用来存储Entry的，多个Entry序列组成一个ledger。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Journal，其实就是bookkeeper的WAL(write ahead log)，用于存bookkeeper的事务日志，journal文件有一个最大大小，达到这个大小后会新起一个journal文件。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Entry log，存储Entry的文件，ledger是一个逻辑上的概念，entry会先按ledger聚合，然后写入entry log文件中。同样，entry log会有一个最大值，达到最大值后会新起一个新的entry log文件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Index file，ledger的索引文件，ledger中的entry被写入到了entry log文件中，索引文件用于entry log文件中每一个ledger做索引，记录每个ledger在entry log中的存储位置以及数据在entry log文件中的长度。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MetaData Storage，元数据存储，是用于存储bookie相关的元数据，比如bookie上有哪些ledger，bookkeeper目前使用的是zk存储，所以在部署bookkeeper前，要先有zk集群。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.7194092827004219&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpDgRkSN5YPz4iblP9Dk1icKWib4JaVvhWVNb0I71unGicpwkKCz96kE6TJQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;474&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;整体架构上的写流程：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step1: broker发起写请求，首先对Journal磁盘写入WAL，熟悉mysql的朋友知道redolog，journal和redolog作用一样都是用于恢复没有持久化的数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step2: 然后再将数据写入index和ledger，这里为了保持性能不会直接写盘，而是写pagecache,然后异步刷盘。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step3: 对写入进行ack。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;读流程为：&lt;/p&gt;&lt;h4&gt;&lt;span&gt;如何高效读写？&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;在kafka中当我们的topic变多了之后，由于kafka一个topic一个文件，就会导致我们的磁盘IO从顺序写变成随机写。在rocketMq中虽然将多个topic对应一个写入文件，让写入变成了顺序写，但是我们的读取很容易导致我们的pagecache被各种覆盖刷新，这对于我们的IO的影响是非常大的。所以pulsar在读写两个方面针对这些问题都做了很多优化：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;写流程：顺序写 + pagecache。在写流程中我们的所有的文件都是独立磁盘，并且同步刷盘的只有Journal，Journal是顺序写一个journal-wal文件,顺序写效率非常高。ledger和index虽然都会存在多个文件，但是我们只会写入pagecache,异步刷盘，所以随机写不会影响我们的性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;读流程：broker cache + bookie cache，在pulsar中对于追尾读(tailing read)非常友好基本不会走io,一般情况下我们的consumer是会立即去拿producer发送的消息的，所以这部分在持久化之后依然在broker中作为cache存在，当然就算broker没有cache（比如broker是新建的），我们的bookie也会在memtable中有自己的cache,通过多重cache减少读流程走io。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们可以发现在最理想的情况下读写的io是完全隔离开来的，所以在Pulsar中能很容易就支持百万级topic，而在我们的kafka和rocketmq中这个是非常困难的。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;无限流式存储&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;一个Topic实际上是一个ledgers流(Segment)，通过这个设计所以Pulsar他并不是一个单纯的消息队列系统，他也可以代替流式系统，所以他也叫流原生平台,可以替代flink等系统。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.38769804287045667&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicprrSP1onDszchvSbiapf9iaft1It8BPn4oTz3MqnE6ibHh7un92nlUpRIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1073&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;br/&gt;可以看见我们的Event Stream（topic/partition），由多个Segment存储组成，而每个segment由entry组成，这个可以看作是我们每批发送的消息通常会看作是一个entry。&lt;p&gt;&lt;/p&gt;&lt;p&gt;Segment可以看作是我们写入文件的一个基本维度，同一个Segment的数据会写在同一个文件上面，不同Segment将会是不同文件，而Segment之间的在metadata中进行保存。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;1.0059171597633136&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpV5xoM9uL8KVPtWia1iae1vKYuJVqD1mmQK1QyxrFDj0Zdtp1Mvk1OFdw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;845&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;h4&gt;&lt;span&gt;分层存储&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;在kafka和rocketmq中消息是会有一定的保存时间的，因为磁盘会有空间限制，在pulsar中也提供这个功能，但是如果你想让自己的消息永久存储，那么可以使用分级存储，我们可以将一些比较老的数据，定时的刷新到廉价的存储中，比如s3,那么我们就可以无限存储我们的消息队列了。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5384615384615384&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpX9dGI1Vfa4NkTb5H2SALfUVq0RlYSM1bcADrvSIakNicNu7VvVSMAWA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;780&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;数据复制&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;在pulsar中的数据复制和kafka,rocketmq都有很大的不同，在其他消息队列中通常是其他副本主动同步，通常这个时间就会变得不可预测，而在pulsar采用了类似qurom协议，给一组可用的bookie池，然后并发的写入其中的一部分bookie,只要返回部分成功（通常大于1/2）就好。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.44237485448195574&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpvMVswByR0dpicngA7ch9sybZYvWg3AFaFfMxKqiag9gbolia1y6YibOibHw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;859&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Ensemble Size（E）决定给定 ledger 可用的 bookie 池大小。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Write Quorum Size（Qw）指定 Pulsar 向其中写入 entry 的 bookie 数量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Ack Quorum Size（Qa）指定必须 ack 写入的 bookie 数量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;采用这种并发写的方式，会更加高效的进行数据复制，尤其是当数据副本比较多的时候。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;Consumer&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;接下来我们来聊聊pulsar中最后一个比较重要的组成&lt;code&gt;consumer&lt;/code&gt;。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;订阅模式&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;订阅模式是用来定义我们的消息如何分配给不同的消费者，不同消息队列中间件都有自己的订阅模式，一般我们常见的订阅模式有：&lt;/p&gt;&lt;p&gt;在pulsar中提供了4种订阅模式，分别是独占，灾备，共享，键共享：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.7243589743589743&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicp1KMujmD0WuSzbbnN7XvW3Xn53jLYy4FHpiaLhst5TtmthL4NLt8QbgQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;936&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;独占：顾名思义只能由一个消费者独占，如果同一个集群内有第二个消费者去注册，第二个就会失败，这个适用于全局有序的消息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;灾备：加强版独占，如果独占的那个挂了，会自动的切换到另外一个好的消费者，但是还是只能由一个独占。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;共享模式：这个模式看起来有点像集群模式，一条消息也是只能被一个集群内消费者消费，但是和rocketmq不同的是，rocketmq是以partition维度，同一个Partition的数据都会被发到一个机器上。在Pulsar中消费不会以partition维度，而是轮训所有消费者进行消息发送。这有个什么好处呢？如果你有100台机器，但是你只有10个partition其实你只有10台消费者能运转，但是在pulsar中100台机器都可以进行消费处理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;键共享：类似上面说的partition维度去发送，在rocketmq中同一个key的顺序消息都会被发送到一个partition，但是这里不会有partition维度，而只是按照key的hash去分配到固定的consumer,也解决了消费者能力限制于partition个数问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;消息获取模式&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;不论是在kafka还是在rocketmq中我们都是client定时轮训我们的broker获取消息，这种模式叫做长轮训（Long-Polling）模式。这种模式有一个缺点网络开销比较大，我们来计算一下consumer被消费的时延，我们假设broker和consumer之间的一次网络延时为R,那么我们总共的时间为：&lt;/p&gt;&lt;p&gt;如果只考虑网络时延，我们可以看见我们这条消息的消费时延大概是3R，所以我们必须想点什么对其进行一些优化，有同学可能马上就能想到，我们消息来了直接推送给我们的consumer不就对了，这下我们的时延只会有一次R,这个就是我们常见的推模式，但是简单的推模式是有问题的，如果我们有生产速度远远大于消费速度，那么推送的消息肯定会干爆我们的内存，这个就是背压。那么我们怎么解决背压呢？我们就可以优化推送方式，将其变为动态推送，我们结合Long-polling,在long-polling请求时将Buffer剩余空间告知给Broker，由Broker负责推送数据。此时Broker知道最多可以推送多少条数据，那么就可以控制推送行为，不至于冲垮Consumer。&lt;/p&gt;&lt;p&gt;举个例子：&lt;/p&gt;&lt;p&gt;Consumer发起请求时Buffer剩余容量为100，Broker每次最多返回32条消息，那么Consumer的这次long-polling请求Broker将在执行3次push(共push96条消息)之后返回response给Consumer（response包含4条消息）。&lt;/p&gt;&lt;p&gt;如果采用long-polling模型，Consumer每发送一次请求Broker执行一次响应，这个例子需要进行4次long-polling交互（共4个request和4个response，8次网络操作；Dynamic Push/Pull中是1个request，三次push和一个response，共5次网络操作）。&lt;/p&gt;&lt;p&gt;所以pulsar就采用了这种消息获取模式，从consumer层进一步优化消息达到时间。我觉得这个设计非常巧妙，很多中间件的这种long-polling模式都可以参考这种思想去做一个改善。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;Apache Pulsar很多设计思想都和其他中间件不一样，但无疑于其更加贴近于未来，大胆预测一下其他的一些消息中间件未来的发展也都会向其靠拢，目前国内的Pulsar使用者也是越来越多，腾讯云提供了pulsar的云版本TDMQ，当然还有一些其他的知名公司华为，知乎，虎牙等等有都在对其做一个逐步的尝试，我相信pulsar真的是一个趋势。最后也让我想起了最近大江大河大结局的一句话：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;所有的变化,都可能伴随着痛苦和弯路,开放的道路,也不会是阔野坦途,但大江大河,奔涌向前的趋势,不是任何险滩暗礁,能够阻挡的。道之所在，虽千万人吾往矣。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我在这里其实只说了一些大概，更多的一些细节，大家可以看一下下面的学习参考资料吧：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首先大家可以去看看pulsar的官网的文档，首先了解一个大概。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;大家也可以关注pulsar的公众号，每天都会发一些pulsar相关的文章，我觉得写得非常好。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可以去B站搜索TGIP，这个是pulsar每周都会由一个项目组的成员去讲相关的资料，如果想学习可以看看这个视频。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;push or pull?: https://www.cnblogs.com/hzmark/p/mq_push_pull.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;架构决策之消息中间件-Pulsar:https://blog.csdn.net/tcy83/article/details/106731392&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;如果大家觉得这篇文章对你有帮助，你的关注和转发是对我最大的支持，O(∩_∩)O:&lt;/p&gt;&lt;/blockquote&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.75&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpLdMFV81zLYP1iaJRxCNEevut3q6tRzADYvhMoYns3ppkydeLtSowUnQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;500&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>