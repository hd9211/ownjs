<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>3993bbe28ee4164e43abb808086c8393</guid>
<title>30 岁的程序员出路在哪里？| 码农周刊第 321 期</title>
<link>https://toutiao.io/k/qdeuemt</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;body class=&quot;issue&quot; id=&quot;readabilityBody&quot;&gt;
        &lt;h1&gt;30 岁的程序员出路在哪里？| 码农周刊第 321 期&lt;/h1&gt;
        &lt;h2&gt;码农周刊第321期（2020-10-15）&lt;/h2&gt;
        &lt;p&gt;☞ &lt;a href=&quot;https://weekly.manong.io/bounce?nid=321&amp;amp;aid=19568&amp;amp;url=https%3A%2F%2Fvip.manong.io%2F%3F3210&quot; target=&quot;_blank&quot;&gt;薪资翻番如何实现？程序员的涨薪秘诀&lt;/a&gt;&lt;br/&gt;&amp;#13;
&lt;a href=&quot;https://weekly.manong.io/bounce?nid=321&amp;amp;aid=19568&amp;amp;url=https%3A%2F%2Fvip.manong.io%2F%3F3210&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_321.png&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;br/&gt;&amp;#13;
&lt;small&gt;&lt;a href=&quot;https://weekly.manong.io/bounce?nid=321&amp;amp;aid=19185&amp;amp;url=https%3A%2F%2Fjinshuju.net%2Ff%2FV7DxN9&quot; target=&quot;_blank&quot;&gt;商务合作&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;程序设计&quot;&gt;程序设计&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;「码农周刊 VIP 会员专属邮件周报」每周五发送，自订购之日算起，全年 52 期。&lt;/p&gt;
        
        &lt;p&gt;最佳实践&lt;/p&gt;
        
        &lt;p&gt;偏好模型在贝壳的应用&lt;/p&gt;
        
        &lt;p&gt;实战经验&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_3041.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
        &lt;h3 id=&quot;VIP会员专区&quot;&gt;VIP会员专区&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;工作地点：成都 | 薪资：15-30K | 简历投递邮箱：xiexiaofang@huobi.com&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;共包含 9 种英伟达开发的图像及视频合成方法&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;以 DDD 思想为基础，融合中台核心要素，赋能中台建设。&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;开箱即用的中后台前端/设计解决方案&lt;/p&gt;
        &lt;h3 id=&quot;工具资料&quot;&gt;工具资料&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;「码农周刊 VIP 会员专属邮件周报」每周五发送，自订购之日算起，全年 52 期。&lt;/p&gt;
        
        &lt;p&gt;详解&lt;/p&gt;
        
        &lt;p&gt;详细介绍&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;经验分享&lt;/p&gt;
        
        &lt;p&gt;供参考&lt;/p&gt;
        
        &lt;p&gt;经验分享&lt;/p&gt;
        
        &lt;p&gt;详细介绍&lt;/p&gt;
        
        &lt;p&gt;一步步教你&lt;/p&gt;
        
        &lt;p&gt;细致讲解&lt;/p&gt;
        
        &lt;p&gt;无废话&lt;/p&gt;
        
        &lt;p&gt;详细介绍&lt;/p&gt;
        
        &lt;p&gt;适合入门&lt;/p&gt;
        
        &lt;p&gt;多维度看问题&lt;/p&gt;
        
        &lt;p&gt;&lt;a href=&quot;https://github.com/streamnative/mop&quot; target=&quot;_blank&quot;&gt;GitHub 地址&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_3041.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
        &lt;h3 id=&quot;编程语言&quot;&gt;编程语言&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;「码农周刊 VIP 会员专属邮件周报」每周五发送，自订购之日算起，全年 52 期。&lt;/p&gt;
        
        &lt;p&gt;通俗易懂&lt;/p&gt;
        
        &lt;p&gt;适合新手&lt;/p&gt;
        
        &lt;p&gt;供参考&lt;/p&gt;
        
        &lt;p&gt;详细介绍&lt;/p&gt;
        
        &lt;p&gt;详解&lt;/p&gt;
        
        &lt;p&gt;完备分析&lt;/p&gt;
        
        &lt;p&gt;结合代码&lt;/p&gt;
        
        &lt;p&gt;代码示例&lt;/p&gt;
        
        &lt;p&gt;通俗易懂&lt;/p&gt;
        
        &lt;p&gt;经验分享&lt;/p&gt;
        
        &lt;p&gt;详解&lt;/p&gt;
        
        &lt;p&gt;细致分析&lt;/p&gt;
        &lt;h3 id=&quot;每周独家号推荐&quot;&gt;每周独家号推荐&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;一线互联网工程师，分享Linux C++ Go Python等后端开发技术。&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 444675 即可&lt;/p&gt;
        
        &lt;p&gt;老年程序猿，工作15年以上。以前极其不擅长写作，最近决定对着弱点迎难而上，写写原创的经验、心得。&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 426740 即可&lt;/p&gt;
        
        &lt;p&gt;分享一些在 ThinkJS 项目开发过程中总结的一些经验以及问题&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 253319 即可&lt;/p&gt;
        
        &lt;p&gt;专注互联网金融&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 26661 即可&lt;/p&gt;
        
        &lt;p&gt;主要是分享作为一个机器学习算法工程师的工作学习生活方面的内容，包括Python编程、机器学习和深度学习算法知识，偶尔可能分享一些计算机基础方面的知识，以及一些练习项目等&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 1584 即可&lt;/p&gt;
        &lt;h3 id=&quot;每周一书&quot;&gt;每周一书&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;本书介绍了 Kotlin 的基本语法、常用类型、面向对象编程以及一些高阶的知识。欢迎到&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;兑换阅读。&lt;/p&gt;
        &lt;h3 id=&quot;编程之外&quot;&gt;编程之外&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;天无绝程序员之路&lt;/p&gt;
        
        &lt;p&gt;供参考&lt;/p&gt;
        
        &lt;p&gt;经验之谈&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_3041.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
        &lt;p&gt;
        &lt;/p&gt;
        
        
        
        
        &lt;div class=&quot;qrcode&quot;&gt;
  &lt;img src=&quot;https://img.toutiao.io/ads/vip_qrcode.png&quot; alt=&quot;Qrcode 258&quot;/&gt;&lt;span&gt;加入码农周刊VIP会员&lt;/span&gt;
&lt;/div&gt;
    &lt;/body&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e05bb3d938e289331f69f30778018f35</guid>
<title>记一次对端机器宕机后的 TCP 行为</title>
<link>https://toutiao.io/k/2abl3q4</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;h1&gt;解Bug之路-记一次对端机器宕机后的tcp行为&lt;/h1&gt;&lt;h2&gt;前言&lt;/h2&gt;&lt;p&gt;机器一般过质保之后，就会因为各种各样的问题而宕机。而这一次的宕机，让笔者观察到了平常观察不到的tcp在对端宕机情况下的行为。经过详细跟踪分析原因之后，发现可以通过调整内核tcp参数来减少宕机造成的影响。&lt;/p&gt;&lt;h2&gt;Bug现场&lt;/h2&gt;&lt;p&gt;笔者所在的公司用某个中间件的古老版本做消息转发，此中间件在线上运行有些年头了，大约刚开始部署的时候机器还是全新的，现在都已经过保了。机器的宕机导致了一些诡异的现象。如下图所示:&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5424028268551236&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEficzNQ6w9S1Wv5HTgItLAPQ1yTCgM2HCxH95WibsPjypTicP4d5Tc0K17w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1132&quot;/&gt;&lt;br/&gt;在中间件所在机器宕机之后，出现了调用中间件超时的现象。抛开各种业务细节，会发现出现了时间很长的超时。其中一波在821s之后报出了Connection reset异常，还有一波在940s之后报出了Connection timed out(Read failed)异常。&lt;/p&gt;&lt;h2&gt;线索追查&lt;/h2&gt;&lt;p&gt;发现出bug的时间点很微妙,有将近10个请求是在22:32:22.300左右集中报错，并且这个时间点有Connection reset。&lt;br/&gt;另一波是在22:34.11.450左右集中报错,并且这个时间点由Connection timed out(Read failed)。&lt;br/&gt;于是笔者看了下此中间件client的网络模型,如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.4825174825174825&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfmA5DicN5ibK9qhyic5el0fYZWfkU0xOsY04AZf3DzfocgkKyfRiaia80v5w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1430&quot;/&gt;&lt;br/&gt;这就很容易理解，为何请求为何都是在同一时刻超时，因为是顺序请求，后面的几个请求还没发送出去，就由于第一个请求超时而导致后面的所有请求报错。如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.2684659090909091&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfPgicbNTHaHRcXWrdrrU7Pch9DtfkAFY6wE9WuOMply0IbW7UABNxD7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1408&quot;/&gt;&lt;br/&gt;进一步推出，真正的socket超时时间是请求1(最长)的超时时间。&lt;br/&gt;即对应&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Connection reset的821s&lt;br/&gt;Connection timed out(Read failed)的940s&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;client设置了socket.soTimeOut为0&lt;/h3&gt;&lt;p&gt;这个中间件采用了bio模型，并且socket没有设置超时时间，其业务超时时间通过业务层的future来控制。但是这个超时时间只有在真正发送请求的时间起作用，每个请求之前还会有其它的一段交互，如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.33646112600536193&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfvfXHe69xhsPt65GxfVia95C2ibWpN6Kk0g1ticMUMfpfx8hmT4jclNBpA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1492&quot;/&gt;&lt;br/&gt;至此，问题原因已经很明显了，在(do something)的那个过程由于socket设置soTimeOut为0，导致卡住了相当长的一段时间。代码如下图所示:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;.....&lt;br/&gt;protected int soTimeout;&lt;br/&gt;......&lt;br/&gt;protected void initialiseSocket(Socket sock) throws SocketException, IllegalArgumentException {&lt;br/&gt;     ......&lt;br/&gt;      // 默认是0&lt;br/&gt;      sock.setSoTimeout(soTimeout);&lt;br/&gt;      ......&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;socket设置soTimeOut为0的表现&lt;/h3&gt;&lt;p&gt;问题本身的查找是比较简单的，如果仅仅只有这些的话，笔者也不会将其写成一篇博客。&lt;br/&gt;由于socket设置timeout(&amp;gt;0)是一种常识，很少遇到设置为0的情况。于是其引起的现象引起了笔者的兴趣。我们看看socket设置timeout为0后jdk源码的描述:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;    /**&lt;br/&gt;      * ......&lt;br/&gt;     *  A timeout of zero is interpreted as an infinite timeout.&lt;br/&gt;     * ......&lt;br/&gt;     */&lt;br/&gt;    public synchronized void setSoTimeout(int timeout) throws SocketException {&lt;br/&gt;        if (isClosed())&lt;br/&gt;            throw new SocketException(&quot;Socket is closed&quot;);&lt;br/&gt;        if (timeout &amp;lt; 0)&lt;br/&gt;          throw new IllegalArgumentException(&quot;timeout can&#x27;t be negative&quot;);&lt;br/&gt;&lt;br/&gt;        getImpl().setOption(SocketOptions.SO_TIMEOUT, new Integer(timeout));&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;里面有这么一段话&lt;/p&gt;&lt;pre&gt;&lt;code&gt;A timeout of zero is interpreted as an infinite timeout&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;按上述字母解释为如果设置为0的话，应该是等待无限长的时间(直到进程重启)。&lt;br/&gt;可是按照线上业务的表现，确是有超时时间的，只不过时间很长。最长的达到了940s，即15分钟多。&lt;br/&gt;这就引起了笔者的兴趣，到底是什么让这个无限的超时时间被打断呢？我们继续分析。&lt;/p&gt;&lt;h2&gt;Connection reset&lt;/h2&gt;&lt;p&gt;首先我们聚焦于第一个异常报错Connection reset(22:32分), 笔者本身阅读过tcp协议栈源码，知道基本上所有Connection reset都由对端发出。所以笔者料定在22:32分的时候，机器肯定又活过来了，但是对应的中间件进程确没有起来，所以没有对应的端口，进而当包过来的时候，发送tcp reset包回去(即使当前中间件起来了也会发送reset,因为tcp本身的seq序列号校验失败)。如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.3932432432432432&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfkjiccib3LYK1vqClKOAeIicQHQmGCRkjAT2Q6AiaWA1nBf1V6nu1XJ9ib9A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1480&quot;/&gt;&lt;br/&gt;然后了解到在22:32左右，为了拷贝宿主机内部的消息记录，运维确实将宕掉的机器重新给拉起来了，这进一步印证了我的想法。但是按照笔者的推论，在22:32分新发出重传的所有的请求都被Connection reset了，为何在将近两分钟之后(准确的说是在1分49s之后由又报了一波错？)继续往下分析。&lt;br/&gt;(注意22:32分和22:34分报错的是不同的socket连接)&lt;/p&gt;&lt;h2&gt;Connection timed out(Read failed)&lt;/h2&gt;&lt;p&gt;这个错误很少遇到。不知道是在哪种情况下触发。具体的异常栈为:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Caused by: java.net.SocketException: Connection timed out(Read failed)&lt;br/&gt;         at java.net.SocketInputStream.socketRead0(Native Method) ~[?1.8.0_121]&lt;br/&gt;         at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[?:1.8.0_121]&lt;br/&gt;         ......&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;于是用sublime搜索Connection timed out,发现其只在Java_java_net_PlainSocketImpl_socketConnect出现，和上面的异常栈明显不符合。&lt;br/&gt;那么就从socketRead0入手，我们详细看看源代码:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;JNIEXPORT jint JNICALL&lt;br/&gt;Java_java_net_SocketInputStream_socketRead0(JNIEnv *env, jobject this,&lt;br/&gt;                                            jobject fdObj, jbyteArray data,&lt;br/&gt;                                            jint off, jint len, jint timeout)&lt;br/&gt;{&lt;br/&gt;    ......&lt;br/&gt;     nread = NET_Read(fd, bufP, len);&lt;br/&gt;&lt;br/&gt;    if (nread &amp;lt;= 0) {&lt;br/&gt;        if (nread &amp;lt; 0) {&lt;br/&gt;&lt;br/&gt;            switch (errno) {&lt;br/&gt;                case ECONNRESET:&lt;br/&gt;                case EPIPE:&lt;br/&gt;                    JNU_ThrowByName(env, &quot;sun/net/ConnectionResetException&quot;,&lt;br/&gt;                        &quot;Connection reset&quot;);&lt;br/&gt;                    break;&lt;br/&gt;&lt;br/&gt;                case EBADF:&lt;br/&gt;                    JNU_ThrowByName(env, JNU_JAVANETPKG &quot;SocketException&quot;,&lt;br/&gt;                        &quot;Socket closed&quot;);&lt;br/&gt;                    break;&lt;br/&gt;&lt;br/&gt;                case EINTR:&lt;br/&gt;                     JNU_ThrowByName(env, JNU_JAVAIOPKG &quot;InterruptedIOException&quot;,&lt;br/&gt;                           &quot;Operation interrupted&quot;);&lt;br/&gt;                     break;&lt;br/&gt;&lt;br/&gt;                default:&lt;br/&gt;                    NET_ThrowByNameWithLastError(env,&lt;br/&gt;                        JNU_JAVANETPKG &quot;SocketException&quot;, &quot;Read failed&quot;);&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;    ......&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;答案就在NET_ThrowByNameWithLastError里面，其最后调用的是os::stderr来获取kernel返回的error字符串。&lt;br/&gt;查了下linux stderr手册，发现是ETIMEDOUT对应了Connection timed out。&lt;br/&gt;但是后面的Connection timed out(Read failed)中的(Read failed)不应该拼接在后面，因为其逻辑是kernel返回error就用kernel的error,否则用defaultDetail即(Read failed和errno的组合)。具体原因，笔者并没有在openJdk源码中找到，猜测可能是版本的原因或者oracleJdk和openJdk之间细微的差别。&lt;/p&gt;&lt;h2&gt;ETIMEDOUT&lt;/h2&gt;&lt;p&gt;既然是linux kernel返回的，笔者就立马翻了linux源码。&lt;br/&gt;(这其中有个插曲，就是笔者一开始看的是2.6.24内核源码，发现怎么计算都对不上数据。后来看到线上用的是2.6.32内核版本，翻了对应版本的源码，才搞定)&lt;br/&gt;既然是sockRead0返回的，那肯定不是socket创建连接阶段(SYN)，肯定到了establish的send/rcv阶段。这个错误最有可能就是在重传失败的时候返回的错误。于是翻了下重传的源代码:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;static void tcp_retransmit_timer(struct sock *sk)&lt;br/&gt;{&lt;br/&gt;    ......&lt;br/&gt;    // 检查当前重传是否已经超过最大时间&lt;br/&gt;    if (tcp_write_timeout(sk))&lt;br/&gt;        goto out;&lt;br/&gt;    ......&lt;br/&gt;    icsk-&amp;gt;icsk_backoff++;&lt;br/&gt;    icsk-&amp;gt;icsk_retransmits++;&lt;br/&gt;out_reset_timer:&lt;br/&gt;    // 重新重传定时器，rto最大为TCP_RTO_MAX即为120s&lt;br/&gt;    icsk-&amp;gt;icsk_rto = min(icsk-&amp;gt;icsk_rto &amp;lt;&amp;lt; 1, TCP_RTO_MAX);&lt;br/&gt;    inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS, icsk-&amp;gt;icsk_rto, TCP_RTO_MAX);&lt;br/&gt;    if (retransmits_timed_out(sk, sysctl_tcp_retries1 + 1))&lt;br/&gt;        __sk_dst_reset(sk);&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上面逻辑是首先判定是否超时，如果未超时则设置下一个超时时间。逻辑如下图所示：&lt;br/&gt;&lt;img data-ratio=&quot;0.45468509984639016&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfnbLm2eUyiakIiciaSqIBkbBiaGiaI3QPUKWicM3SLWg6H8Qu3xTBoUhZ9uHg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1302&quot;/&gt;&lt;br/&gt;我们再看下tcp_write_timeout:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;static int tcp_write_timeout(struct sock *sk){&lt;br/&gt;    ...&lt;br/&gt;    // 对SYN，即创建连接过程中的处理&lt;br/&gt;    ...&lt;br/&gt;    // retry即使kernel中的tcp_retries2&lt;br/&gt;    // 即cat /proc/sys/net/ipv4/tcp_retries2即是15&lt;br/&gt;    retry_until = sysctl_tcp_retries2;&lt;br/&gt;    // 下面就是超时判断的过程&lt;br/&gt;     if (retransmits_timed_out(sk, retry_until)) {&lt;br/&gt;        /* Has it gone just too far? */&lt;br/&gt;        // 如果超过最大时间，则调用tcp_write_err&lt;br/&gt;        tcp_write_err(sk);&lt;br/&gt;        return 1;&lt;br/&gt;    }&lt;br/&gt;    return 0;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;tcp_write_err确实返回了ETIMEDOUT,如下面源码所示:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;static void tcp_write_err(struct sock *sk)&lt;br/&gt;{&lt;br/&gt;    sk-&amp;gt;sk_err = sk-&amp;gt;sk_err_soft ? : ETIMEDOUT;&lt;br/&gt;    // 返回ETIMEDOUT&lt;br/&gt;    sk-&amp;gt;sk_error_report(sk);&lt;br/&gt;&lt;br/&gt;    tcp_done(sk);&lt;br/&gt;    NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPABORTONTIMEOUT);&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;至此，基本可以判定就是tcp_write_timeout超时了，也即其中的&lt;br/&gt;retransmits_timed_out判定超时。&lt;br/&gt;很明显为什么940s的时候没有Connection reset，就是由于先判断了tcp_write_timeout超时导致没有发送下一个重传包，而直接time_out,如果发了，那就是Connection reset。&lt;/p&gt;&lt;h2&gt;retransmits_timed_out的计算过程&lt;/h2&gt;&lt;p&gt;这个计算过程直接上源码:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;static inline bool retransmits_timed_out(struct sock *sk,&lt;br/&gt;                     unsigned int boundary)&lt;br/&gt;{&lt;br/&gt;    unsigned int timeout, linear_backoff_thresh;&lt;br/&gt;    unsigned int start_ts;&lt;br/&gt;&lt;br/&gt;    if (!inet_csk(sk)-&amp;gt;icsk_retransmits)&lt;br/&gt;        return false;&lt;br/&gt;&lt;br/&gt;    if (unlikely(!tcp_sk(sk)-&amp;gt;retrans_stamp))&lt;br/&gt;        start_ts = TCP_SKB_CB(tcp_write_queue_head(sk))-&amp;gt;when;&lt;br/&gt;    else&lt;br/&gt;        start_ts = tcp_sk(sk)-&amp;gt;retrans_stamp;&lt;br/&gt;&lt;br/&gt;    linear_backoff_thresh =&lt;br/&gt;(TCP_RTO_MAX/TCP_RTO_MIN);&lt;br/&gt;&lt;br/&gt;    if (boundary &amp;lt;= linear_backoff_thresh)&lt;br/&gt;        timeout = ((2 &amp;lt;&amp;lt; boundary) - 1) * TCP_RTO_MIN;&lt;br/&gt;    else&lt;br/&gt;        timeout = ((2 &amp;lt;&amp;lt; linear_backoff_thresh) - 1) * TCP_RTO_MIN +&lt;br/&gt;              (boundary - linear_backoff_thresh) * TCP_RTO_MAX;&lt;br/&gt;&lt;br/&gt;    return (tcp_time_stamp - start_ts) &amp;gt;= timeout;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上述源码中,boundary = 15，那么&lt;br/&gt;TCP_RTO_MAX=120s,TCP_RTO_MIN=200ms&lt;br/&gt;linear_backoff_thresh = ilog2(120s/200ms)=ilog2(600)=ilog2(1001011000二进制),ilog的实现为:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;#define ilog2(n)&lt;br/&gt;(                        \&lt;br/&gt;    __builtin_constant_p(n) ? (        \&lt;br/&gt;        (n) &amp;lt; 1 ? ____ilog2_NaN() :    \&lt;br/&gt;        (n) &amp;amp; (1ULL &amp;lt;&amp;lt; 63) ? 63 :    \&lt;br/&gt;        ......&lt;br/&gt;        (n) &amp;amp; (1ULL &amp;lt;&amp;lt;  9) ?  9 :    \&lt;br/&gt;        /* 即(1001011000 &amp;amp; 1000000000)=1=&amp;gt;返回9 */&lt;br/&gt;        ......&lt;br/&gt;)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;由于boundary=15 &amp;gt; linear_backoff_thresh(9)所以，计算超时时间为:&lt;br/&gt;timeout = ((2 &amp;lt;&amp;lt; linear_backoff_thresh) - 1) &lt;em&gt;TCP_RTO_MIN +(boundary - linear_backoff_thresh)&lt;/em&gt;TCP_RTO_MAX;&lt;br/&gt;即(TCP_RTO_MIN=200ms,TCP_RTO_MAX=120s)&lt;br/&gt;timeout = ((2 &amp;lt;&amp;lt; 9 - 1) &lt;em&gt;0.2s + (15 - 9) &lt;/em&gt;120s=924.6s&lt;/p&gt;&lt;p&gt;值得注意的是，由上面的代码逻辑，我们tcp_retries=15指的并不是重传15次，而是在rto初始值为200ms的情况下计算一个最终超时时间，实际重传次数和15并没有直接的关系。&lt;/p&gt;&lt;h2&gt;重传最终超时的上下界&lt;/h2&gt;&lt;h3&gt;重传最终超时的下界&lt;/h3&gt;&lt;p&gt;由上面的计算可知,&lt;br/&gt;即在重传后的tcp_time_stamp（当前时间戳）- start_ts(第一次重传时间戳)&amp;gt;=924.6s的时候,即抛出异常，那么重传最终超时的下界就是924.6s，如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.39718804920913886&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfIRFeiaOmlbnlMIjwQ9YibVD5BoHCXwCEGKsGxicsgV6icBY0YznfOoOVCw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1138&quot;/&gt;&lt;/p&gt;&lt;h3&gt;重传最终超时的上界&lt;/h3&gt;&lt;p&gt;我们假设在第N次的时候tcp_time_stamp - start_ts=924.5999s时候进行超时判定，那么势必会进行下一次重传，并在924.5999+120=1044.5999s后超时，如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.4656160458452722&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfEt2icACH7o22ibHpzG9f24ELsWsSVWOooWChf5icjvcB0BwYfq7BqzCZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1396&quot;/&gt;&lt;br/&gt;那么，重传最终超时的上界就是1044.6s&lt;br/&gt;最终结论:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;重传最终超时的上下界是:&lt;br/&gt;[924.6,1044.6]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;用不同的rto计算下最终超时&lt;/h2&gt;&lt;p&gt;由上面代码可知，重传rto是不停的*2,一直到TCP_RTO_MAX(120s)为止,阅读linux代码可知,在笔者的线上情况下,初始rto=srtt&amp;gt;&amp;gt;3 + rttvar(TCP_RTO_MIN)(当然了，实际比这个复杂的多,计算暂以TCP_RTO_MIN代替),即初始rto=200ms+(一个计算出来的值)&lt;br/&gt;笔者写了个模拟程序:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;public class RetransSimulate {&lt;br/&gt;&lt;br/&gt;    public static void timeOutCaclulate(double rto) {&lt;br/&gt;        double initialRto = rto;&lt;br/&gt;        double sum = 0;&lt;br/&gt;        while (true) {&lt;br/&gt;            sum += rto;&lt;br/&gt;            if (sum &amp;gt; 924600) {&lt;br/&gt;                break;&lt;br/&gt;            }&lt;br/&gt;            rto = rto * 2;&lt;br/&gt;            rto = rto &amp;lt; 120000 ? rto : 120000;&lt;br/&gt;        }&lt;br/&gt;        // 以50ms作为误差&lt;br/&gt;        if(Math.abs(sum - 939997) &amp;lt; 50){&lt;br/&gt;            System.out.println(&quot;rto=&quot;+initialRto+&quot;,timeout=&quot; + sum);&lt;br/&gt;            System.out.println();&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    public static void main(String[] args) {&lt;br/&gt;        // rtt &amp;gt; 3 + rttval(这个计算有点复杂，这边可以直接用TCP_RTO_MIN做计算)&lt;br/&gt;        // 以0.01ms为精度&lt;br/&gt;        double rto =  0.01 + 200;// 0.01 for random rtt &amp;gt; 3（初始扰动）,200 for TCP_RTO_MIN&lt;br/&gt;        // 最多计算到300&lt;br/&gt;        for (int i = 0; i &amp;lt; 10000; i++) {&lt;br/&gt;            timeOutCaclulate(rto);&lt;br/&gt;            rto += 0.01 ;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;发现距离线上真实表现超时时间最近的是:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;rto=215.00999999998635,timeout=939955.229999986&lt;br/&gt;&lt;br/&gt;rto=215.01999999998634,timeout=939965.459999986&lt;br/&gt;&lt;br/&gt;rto=215.02999999998633,timeout=939975.689999986&lt;br/&gt;&lt;br/&gt;rto=215.03999999998632,timeout=939985.919999986&lt;br/&gt;&lt;br/&gt;rto=215.0499999999863,timeout=939996.1499999859&lt;br/&gt;&lt;br/&gt;rto=215.0599999999863,timeout=940006.3799999859&lt;br/&gt;&lt;br/&gt;rto=215.0699999999863,timeout=940016.609999986&lt;br/&gt;&lt;br/&gt;rto=215.07999999998628,timeout=940026.839999986&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样，基本就能基本确定在宕机的时候，用的rto是215了&lt;br/&gt;题外话:&lt;br/&gt;之前博客里面笔者想当然的将rto认为成rtt，导致之前的模拟程序在rto的初始值没有加上200ms,我们同事在复现现场的时候，发现第一次重传包确实是200ms左右，和笔者的推理并不一样。&lt;br/&gt;使得笔者重新阅读了rto源码，发现其rto初始就要加上TCP_RTO_MIN(其实是rttvar,细节有点复杂,在此略过不表),感谢那位同事，也向之前阅读过笔者此篇博客的人道歉,笔者犯了想当然的毛病。&lt;/p&gt;&lt;h2&gt;机器响应的时间窗口&lt;/h2&gt;&lt;p&gt;由于到了800s/900s的时候，肯定已经到了TCP_RTO_MAX(120s),所以我们可以根据两个socket的报错时间计算一下机器响应的时间窗口。在这里为了简便分析，我们忽略包在网络中的最长存活时间,如下图所示:&lt;br/&gt;&lt;img data-ratio=&quot;0.5212620027434842&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/yiaiaFLiaflYRSnOMwkovogv7LsFqichPhEfflCBjU5icFzw1lfcTxqcN8HE1FVTIgBgpwabiaOrCQ44rpVtnPwcuT4A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1458&quot;/&gt;&lt;br/&gt;即机器开始应答的时间应该在22:32:11至22:32:22之间。&lt;br/&gt;当然了，很难获取到机器真正开始应答的精确时间来证实笔者的计算。但是这个计算的意义在于如果两者的应答窗口没有交叠，那么笔者的上述推论就是错的，需要推倒重来。存在这个时间窗口，可以让笔者的推测在逻辑上自洽。&lt;/p&gt;&lt;p&gt;学习tcp最好的实战书籍无疑是&lt;/p&gt;&lt;section&gt;&lt;mpcps frameborder=&quot;0&quot; class=&quot;js_editor_cps&quot; data-datakey=&quot;1591402899899_0.07650296701936377&quot; data-uid=&quot;1591402899897&quot; data-type=&quot;1&quot; data-product=&quot;&quot; data-templateid=&quot;list&quot; data-pid=&quot;23989588&quot; data-packid=&quot;&quot; data-smartnum=&quot;&quot; data-categoryid=&quot;3&quot; data-appid=&quot;wx831660fe3ded4389&quot; data-report=&quot;s0%3D0%26s1%3D0%26s2%3D0%26s3%3Dtcp%252Fip%25E8%25AF%25A6%25E8%25A7%25A3%26s4%3D10%26s5%3D10%26s6%3Did_1591402953483_940825%26s7%3D%26s8%3D%26s9%3D%26s10%3D%26pid%3Dwx831660fe3ded4389_23989588%26uuid%3D32997630781785286764%26title%3DTCP%252FIP%25E8%25AF%25A6%25E8%25A7%25A3%2B%25E5%258D%25B71%25EF%25BC%259A%25E5%258D%258F%25E8%25AE%25AE%25EF%25BC%2588%25E5%258E%259F%25E4%25B9%25A6%25E7%25AC%25AC2%25E7%2589%2588%25EF%25BC%2589%26sid%3D3%26cid%3D3%26ratio%3D17.00%2525%26price%3D119.80%26&quot;/&gt;&lt;/section&gt;&lt;section&gt;里面各种对于tcp本身特性的实验数据，毕竟实践出真知，笔者也在其中获得了大量宝贵的知识和经验。&lt;br/&gt;&lt;/section&gt;&lt;h2&gt;后续改进&lt;/h2&gt;&lt;p&gt;将tcp_retries2减少。soTimeOut在这个中间件client代码里面由于其它问题不建议设置。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;机器宕机虽然不讨人喜欢，但是观察宕机后线上的种种表现可是一次难得机会，能够发现平时注意不到的坑。另外，定量分析其实蛮有意思的，尤其是种种数据都对上的时刻，挺有成就感^_^。&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>6310784f29aaaf9e27568f153cfe015b</guid>
<title>大家用过 API 网关吗?</title>
<link>https://toutiao.io/k/rwvdh2x</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p&gt;今天和大家说说API网关，根据字面含义，和API接口相关，同时又是服务入口。不知道大家所在公司有没有用过，如果用过，是开源的呢？还是自研？或者是云服务厂商的产品？&lt;/p&gt;&lt;p&gt;早在2012年我第二次在sina的时候，就维护过一个API网关产品，当时领导还让我看了一本API书籍，不过讲的是API基础设施和API经济，不得不说，领导还是很有战略眼光的。&lt;/p&gt;&lt;p&gt;使用PHP做了一个网关层，怕别人说性能问题，我一直底气不足，后来发现大家还挺爱用的，原因就是它提供了接口的数据统计功能，就这么一个功能，使用的人却挺多。&lt;/p&gt;&lt;p&gt;所以说，和一个产品一样，功能再多，技术实现方式再牛，也不一定有用，重要的是提供了价值。&lt;/p&gt;&lt;p&gt;意思就是API网关大家不要理解为一个纯技术的产品，而是要以更开阔的视角去看它。&lt;/p&gt;&lt;p&gt;在我看来，API网关提供了两大核心功能：&lt;/p&gt;&lt;p&gt;1：分层，相比SLB的反向代理和负载均衡，API网关提供了更多的功能，从而简化后端服务，并清晰定义哪些应该是API网关做的，哪些是后端服务做的。&lt;/p&gt;&lt;p&gt;也就是说API网关应该是可编程的。&lt;/p&gt;&lt;p&gt;2：API治理&lt;/p&gt;&lt;p&gt;标准化了整个API生命周期，大家不要小看它，如果一开始就规范化，API开发、维护、生产的效率将会极大提升。&lt;/p&gt;&lt;p&gt;对于大公司来说，可能热衷于自己实现或者二次开发API网关，其实它对于性能和稳定性要求极高，所以使用云厂商的服务相对靠谱一些。&lt;/p&gt;&lt;p&gt;阿里云API网关的核心功能：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;568&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.9830729166666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5Wib5Wh04ugw5LWKr2gge4hdVWH4Ut7Lia3XTqxnyLjPyzAKOiamfxicZ2lt2diaRrEGOqP1YZGHq5NovNSgCF67RTw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;768&quot;/&gt;&lt;/p&gt;&lt;p&gt;那么如何接入API网关呢？它不像其他的云服务，不会很快看到效果，需要很长的时间才能体现它的价值；同时涉及面也比较广，大家只有统一思想，才能用好它。&lt;/p&gt;&lt;p&gt;如果你一开始就用它，包袱会小很多，如果中途接入它，需要面临兼容性的问题。&lt;/p&gt;&lt;p&gt;那它的重要性在哪儿呢？因为不管你用分布式架构还是微服务，内部不管怎么玩，对外基本上还是API接口，所以说API网关永远不过时，这也是我们在选型或者自研产品时候要注意的，一定要选择哪些基础，有长期存在价值的技术服务。&lt;/p&gt;&lt;p&gt;你们公司用了吗？&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_reward_qrcode&quot;&gt;
                                &lt;p class=&quot;tips_global&quot;&gt;Long-press QR code to transfer me a reward&lt;/p&gt;
                                                                &lt;p class=&quot;reward_tips&quot;&gt;觉得写得还不错？就鼓励一下吧！&lt;/p&gt;
                                &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; id=&quot;js_reward_qrcode_img&quot;/&gt;&lt;/span&gt;
                                &lt;p class=&quot;tips_global&quot;&gt;As required by Apple&#x27;s new policy, the Reward feature has been disabled on Weixin for iOS. You can still reward an Official Account by transferring money via QR code.&lt;/p&gt;
                            &lt;/div&gt;
                                                                            
                              
            &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>05cc57e1baf5881b6301b86c0c82df02</guid>
<title>HTTP keep-alive 和 TCP keepalive 的区别，你了解吗？</title>
<link>https://toutiao.io/k/630ifsg</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;文章目录
一、简介
  1.1、TCP协议简介
  1.2、HTTP协议简介
二、TCP keepalive
  2.1、简介
  2.2、实验
  2.3、扩展
三、HTTP keep-alive
  3.1、简介
  3.2、实验
    3.2.1、实验一：禁用keep-alive的http请求
    3.2.2、实验二：启用keep-alive的http请求
  3.3、扩展
四、总结
五、彩蛋&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;1、从文中找出我的IP&lt;br/&gt;2、http请求中是客服端还是服务端主动关闭的tcp连接？ &lt;br/&gt; 请阅读到最后的彩蛋部分&lt;/blockquote&gt;&lt;p&gt;HTTP和TCP都是老生常谈的知识点，本文不进行铺开赘述。我们可能在HTTP和TCP中都听说“长连接”的说法，也听过HTTP中有keep-alive，TCP中有keepalive。那么，HTTP和TCP的长连接有何区别？HTTP中的keep-alive和TCP中keepalive又有什么区别？&lt;/p&gt;&lt;p&gt;&lt;b&gt;Tips：&lt;/b&gt;HTTP中是keep-alive，TCP中是keepalive，HTTP中是带中划线的。大小写无所谓。&lt;/p&gt;&lt;h2&gt;一、简介&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-737aab4fcedf20a05584443221508141_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;860&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-737aab4fcedf20a05584443221508141_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;860&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-737aab4fcedf20a05584443221508141_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-737aab4fcedf20a05584443221508141_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上面是我先前做TCP协议分享时整理的一张表格，从上面可以看出：不管是在OSI七层网络模型还是在TCP/IP五层网络模型中，&lt;b&gt;TCP是传输层的一种协议，而HTTP是应用层的一种协议&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;HTTP和TCP的理论和实现还是相当复杂的，下面只简单介绍和本文主题相关的知识点。&lt;/p&gt;&lt;h2&gt;1.1、TCP协议简介&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TCP协议&lt;/b&gt;也叫传输控制协议（TCP，Transmission Control Protocol）是一种面向连接的、可靠的、基于字节流的传输层通信协议。使用TCP的两个程序（客户端和服务端）在交换数据前，通过三次握手来建立TCP连接，建立连接后就可以进行基于字节流的双工通讯，由TCP内部实现保证通讯的可靠性，完全通讯完成后，通过四次挥手断开连接。&lt;/p&gt;&lt;p&gt;在客户端和服务端间的网络一切正常、且双方都没主动发起关闭连接的请求时，此TCP连接理论上可以永久保持。但是，网络情况是及其复杂的，&lt;b&gt;在双方长时间未通讯时，如何得知对方还活着？如何得知这个TCP连接是健康且具有通讯能力的？&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;1.2、HTTP协议简介&lt;/h2&gt;&lt;p&gt;&lt;b&gt;HTTP协议&lt;/b&gt;是Hyper Text Transfer Protocol（超文本传输协议）的缩写。HTTP是万维网的数据通信的基础。HTTP是一个应用层协议，&lt;b&gt;通常&lt;/b&gt;运行在TCP协议之上。它由请求和响应构成，是一个标准的客户端服务器模型（C/S模型）。HTTP是一个&lt;b&gt;无状态&lt;/b&gt;的协议。&lt;/p&gt;&lt;p&gt;&lt;b&gt;无状态&lt;/b&gt;怎么解释？HTTP协议永远都是客户端发起请求，服务器回送响应。每次连接只处理一个请求，当服务器返回本次请求的应答后便立即关闭连接，下次请求客户端再重新建立连接。也就无法实现在客户端没有发起请求的时候，服务器主动将消息推送给客户端。&lt;/p&gt;&lt;p&gt;HTTP协议运行在TCP协议之上，它无状态会导致客户端的每次请求都需要重新建立TCP连接，接受到服务端响应后，断开TCP连接。对于每次建立、断开TCP连接，还是有相当的性能损耗的。&lt;b&gt;那么，如何才能尽可能的减少性能损耗呢？&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;二、TCP keepalive&lt;/h2&gt;&lt;h2&gt;2.1、简介&lt;/h2&gt;&lt;p&gt;正如上面提出的问题：&lt;b&gt;在双方长时间未通讯时，如何得知对方还活着？如何得知这个TCP连接是健康且具有通讯能力的？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TCP的保活机制就是用来解决此类问题，这个机制我们也可以称作：keepalive。保活机制默认是关闭的，TCP连接的任何一方都可打开此功能。有三个主要配置参数用来控制保活功能。&lt;/p&gt;&lt;p&gt;如果在一段时间（&lt;b&gt;保活时间：tcp_keepalive_time&lt;/b&gt;）内此连接都不活跃，开启保活功能的一端会向对端发送一个保活探测报文。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;若对端正常存活，且连接有效，对端必然能收到探测报文并进行响应。此时，发送端收到响应报文则证明TCP连接正常，重置保活时间计数器即可。&lt;/li&gt;&lt;li&gt;若由于网络原因或其他原因导致，发送端无法正常收到保活探测报文的响应。那么在一定&lt;b&gt;探测时间间隔（tcp_keepalive_intvl）&lt;/b&gt;后，将继续发送保活探测报文。直到收到对端的响应，或者达到配置的&lt;b&gt;探测循环次数上限（tcp_keepalive_probes）&lt;/b&gt;都没有收到对端响应，这时对端会被认为不可达，TCP连接随存在但已失效，需要将连接做中断处理。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在探测过程中，对端主机会处于以下四种状态之一：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-837ba2a1eb7beb10c036ca468f7db69f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1420&quot; data-rawheight=&quot;590&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-837ba2a1eb7beb10c036ca468f7db69f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1420&quot; data-rawheight=&quot;590&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-837ba2a1eb7beb10c036ca468f7db69f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-837ba2a1eb7beb10c036ca468f7db69f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;2.2、实验&lt;/h2&gt;&lt;p&gt;这里，强烈推荐《TCP/IP详解 卷1:协议》的第二版（这里一定是第二版）， &lt;b&gt;第17章：TCP保活机制&lt;/b&gt;。这里建议17章都看，17.1和17.2小节就涵盖了我上面介绍的内容。&lt;/p&gt;&lt;p&gt;17.2.1 小节中还通过实验的方式详细验证了“对端主机会处于以下四种状态”以及对于这四种状态TCP都是如何去处理。&lt;/p&gt;&lt;p&gt;这本书中的实验已经比较通俗易懂了，我暂且没有亲自动手去模拟实践，后续时间充足，会亲自动手进行实验。&lt;/p&gt;&lt;h2&gt;2.3、扩展&lt;/h2&gt;&lt;p&gt;上面提到了三个参数&lt;b&gt;保活时间：tcp_keepalive_time、探测时间间隔：tcp_keepalive_intvl、探测循环次数：tcp_keepalive_probes&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;这三个参数，在linux上可以在&lt;code&gt;/proc/sys/net/ipv4/&lt;/code&gt;路径下找到，或者通过&lt;code&gt;sysctl -a | grep keepalive&lt;/code&gt;命令查看当前内核运行参数。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@vm01 ~&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# cd /proc/sys/net/ipv4&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@vm01 ipv4&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# pwd&lt;/span&gt;
/proc/sys/net/ipv4
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@vm01 ipv4&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# cat /proc/sys/net/ipv4/tcp_keepalive_time&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;7200&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@vm01 ipv4&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# cat /proc/sys/net/ipv4/tcp_keepalive_probes&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@vm01 ipv4&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# cat /proc/sys/net/ipv4/tcp_keepalive_intvl&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;75&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@vm01 ipv4&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# sysctl -a | grep keepalive&lt;/span&gt;
net.ipv4.tcp_keepalive_time &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;7200&lt;/span&gt;
net.ipv4.tcp_keepalive_probes &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;
net.ipv4.tcp_keepalive_intvl &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;75&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;保活时间（tcp_keepalive_time）默认：7200秒&lt;/li&gt;&lt;li&gt;保活时间间隔（tcp_keepalive_intvl）默认：75秒&lt;/li&gt;&lt;li&gt;探测循环次数（tcp_keepalive_probes）默认：9次&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;也就是默认情况下一条TCP连接在2小时（7200秒）都没有报文交换后，会开始进行保活探测，若再经过9*75秒=11分钟15秒的循环探测都未收到探测响应，即共计：2小时11分钟15秒后会自动断开TCP连接。&lt;/p&gt;&lt;p&gt;别走开，还有一个骚操作&lt;/p&gt;&lt;p&gt;Linux平台下我们还可以借助&lt;code&gt;man&lt;/code&gt;命令查看TCP协议的一些描述和参数定义。下面两个命令的效果相同：&lt;/p&gt;&lt;p&gt;&lt;b&gt;数字7&lt;/b&gt;的含义是：&lt;code&gt;man&lt;/code&gt;命令使用手册共9章，TCP的帮助手册位于第7章。不知道在第几章也无所谓，使用&lt;code&gt;man tcp&lt;/code&gt;也可，弹出的手册左上角也有写第几章。(&lt;code&gt;man ls&lt;/code&gt;等同于&lt;code&gt;man 1 ls&lt;/code&gt;、&lt;code&gt;man ip&lt;/code&gt;等同于&lt;code&gt;man 8 ip&lt;/code&gt;，可以自己尝试使用 )。&lt;/p&gt;&lt;p&gt;下面我们看下&lt;code&gt;man tcp&lt;/code&gt;下的和我们本文有关的几个点： &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cded699db2d7191f62647ff0e084f901_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;966&quot; data-rawheight=&quot;303&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-cded699db2d7191f62647ff0e084f901_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;966&quot; data-rawheight=&quot;303&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-cded699db2d7191f62647ff0e084f901_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-cded699db2d7191f62647ff0e084f901_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e02739510ac2d09f731bff3fe55a646f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;963&quot; data-rawheight=&quot;386&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-e02739510ac2d09f731bff3fe55a646f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;963&quot; data-rawheight=&quot;386&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-e02739510ac2d09f731bff3fe55a646f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e02739510ac2d09f731bff3fe55a646f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e5045b618e763becad284a6ced8e1748_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2004&quot; data-rawheight=&quot;598&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-e5045b618e763becad284a6ced8e1748_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2004&quot; data-rawheight=&quot;598&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-e5045b618e763becad284a6ced8e1748_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e5045b618e763becad284a6ced8e1748_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上面介绍的三个参数&lt;b&gt;tcp_keepalive_time、tcp_keepalive_intvl、tcp_keepalive_probes&lt;/b&gt;都是系统级别的，针对整个系统生效。下面介绍针对单条Socket连接细粒度设置的三个选项参数：&lt;b&gt;保活时间：TCP_KEEPIDLE、保活探测时间间隔：TCP_KEEPINTVL、探测循环次数：TCP_KEEPCNT&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8df1e46e9de14df0c9724ca5d3e3c2ff_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2096&quot; data-rawheight=&quot;374&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-8df1e46e9de14df0c9724ca5d3e3c2ff_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2096&quot; data-rawheight=&quot;374&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-8df1e46e9de14df0c9724ca5d3e3c2ff_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8df1e46e9de14df0c9724ca5d3e3c2ff_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e9d468b62f99b86e32530daf1643251a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;998&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-e9d468b62f99b86e32530daf1643251a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;998&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-e9d468b62f99b86e32530daf1643251a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e9d468b62f99b86e32530daf1643251a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt; 在我们的Netty的框架中可以看到针对Socket选项的配置，如使用epoll的IO模型中&lt;code&gt;EpollSocketChannelConfig&lt;/code&gt;类中的配置：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb8cc0241c2127abbc5721f028c23403_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2186&quot; data-rawheight=&quot;1276&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-bb8cc0241c2127abbc5721f028c23403_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2186&quot; data-rawheight=&quot;1276&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-bb8cc0241c2127abbc5721f028c23403_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bb8cc0241c2127abbc5721f028c23403_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;更多细节，等你挖掘。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;三、HTTP keep-alive&lt;/h2&gt;&lt;h2&gt;3.1、简介&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/224595048/edit#commonResp&quot; class=&quot;internal&quot;&gt;HTTP协议简介&lt;/a&gt;中提到http协议是一个运行在TCP协议之上的无状态的应用层协议。它的特点是：客户端的每一次请求都要和服务端创建TCP连接，服务器响应后，断开TCP连接。下次客户端再有请求，则重新建立连接。&lt;/p&gt;&lt;p&gt;在早期的http1.0中，默认就是上述介绍的这种“请求-应答”模式。这种方式频繁的创建连接和销毁连接无疑是有一定性能损耗的。&lt;/p&gt;&lt;p&gt;所以引入了&lt;b&gt;keep-alive&lt;/b&gt;机制。http1.0默认是关闭的，通过http请求头设置“connection: keep-alive”进行开启；http1.1中默认开启，通过http请求头设置“connection: close”关闭。&lt;/p&gt;&lt;p&gt;&lt;b&gt;keep-alive&lt;/b&gt;机制：若开启后，在一次http请求中，服务器进行响应后，不再直接断开TCP连接，而是将TCP连接维持一段时间。在这段时间内，如果同一客户端再次向服务端发起http请求，便可以复用此TCP连接，向服务端发起请求，并重置timeout时间计数器，在接下来一段时间内还可以继续复用。这样无疑省略了反复创建和销毁TCP连接的损耗。&lt;/p&gt;&lt;h2&gt;3.2、实验&lt;/h2&gt;&lt;p&gt;下面用两组实验证明&lt;b&gt;HTTP keep-alive&lt;/b&gt;的存在。&lt;/p&gt;&lt;p&gt;实验工具：Wireshark&lt;/p&gt;&lt;p&gt;客户端IP：*.*.3.52&lt;/p&gt;&lt;p&gt;服务端IP：*.*.17.254&lt;/p&gt;&lt;h3&gt;3.2.1、实验一：禁用keep-alive的http请求&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8918cdcba83bd7d33d7e3df07a962b32_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2622&quot; data-rawheight=&quot;1658&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-8918cdcba83bd7d33d7e3df07a962b32_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2622&quot; data-rawheight=&quot;1658&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-8918cdcba83bd7d33d7e3df07a962b32_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-8918cdcba83bd7d33d7e3df07a962b32_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p&gt;从上图请求列表区中，我们可以发现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;106、107、108三个请求是TCP建立连接三次握手的请求&lt;/li&gt;&lt;li&gt;109、110两个请求分别是：http的请求报文和http的响应报文&lt;/li&gt;&lt;li&gt;111、112、120、121这四个请求是TCP断开连接四次挥手的请求&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;（由于一台机器上网络请求较多，我加了筛选条件，仅显示客户端和服务端通信的网络请求，所以请求的序号是不连续的）&lt;/p&gt;&lt;p&gt;从上图中间的请求数据解析区，可以确定：此次http请求的请求头中有“Connection: close”，即keep-alive是关闭的。&lt;/p&gt;&lt;p&gt;结论：禁用keep-alive的http请求时，会先建立TCP连接，然后发送报文、响应报文、最后断开TCP连接。&lt;/p&gt;&lt;h3&gt;3.2.2、实验二：启用keep-alive的http请求&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-24904bb774a38233f254f4f6a86515ac_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2622&quot; data-rawheight=&quot;1658&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-24904bb774a38233f254f4f6a86515ac_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2622&quot; data-rawheight=&quot;1658&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-24904bb774a38233f254f4f6a86515ac_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-24904bb774a38233f254f4f6a86515ac_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-08c42b6f274a0f6a3465e171271f9689_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2678&quot; data-rawheight=&quot;1052&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-08c42b6f274a0f6a3465e171271f9689_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2678&quot; data-rawheight=&quot;1052&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-08c42b6f274a0f6a3465e171271f9689_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-08c42b6f274a0f6a3465e171271f9689_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt; 这次实验请求较多，一张图放不下，两张图是连续的，图1的第二块绿色区域和图2的第一块绿色区域是重叠的（注意看第一列的No.编号）&lt;/p&gt;&lt;p&gt;先说下我的操作：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;开启keep-alive前提下发起第一次http请求&lt;/li&gt;&lt;li&gt;7秒左右时，同样的机器同样的http请求，再重新调用一次&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们根据图中抓包，分析下网络请求：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;197、198、199请求：三次握手建立TCP建立连接&lt;/li&gt;&lt;li&gt;200、203请求：http的请求报文和http的响应报文&lt;/li&gt;&lt;li&gt;212请求：可以通过Protocol列看到它是一条TCP报文。我的理解是：在keep-alive这种机制下，客户端收到服务端响应报文后，需要告知服务端“已收到”。由于要复用TCP连接，所以会多一层保障机制，类似TCP的握手和挥手&lt;/li&gt;&lt;li&gt;459-1965请求（图1中的第一块黑色区域中）：6秒内（第二列代表Time），每隔1秒，发生一对TCP请求的来回，用来维护TCP连接的可用性。保证和等待该TCP连接被复用&lt;/li&gt;&lt;li&gt;1743、1744、1745、1755请求：其中的1743和1745是我第二次发起http请求的请求报文和响应报文。1744请求是：客户端发起请求时，服务端先回复客户端“已收到，马上处理”。紧接着1745将结果响应给客户端。1755则是客户端收到响应后，回复服务端“已收到响应，多谢”。&lt;/li&gt;&lt;li&gt;2028-3903请求：10秒内，每隔1秒，发生一对TCP请求的来回，用来维护TCP连接的可用性。保证和等待该TCP连接被复用&lt;/li&gt;&lt;li&gt;4127-4131请求：10秒内我没再发起http请求，四次挥手断开TCP连接。长时间没被复用，也没必要一直维持下去，浪费资源，还可能造成网络拥堵。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;注意：10秒无请求，TCP连接在断开，10秒也不是默认的，只是环境的配置。是Httpd守护进程，提供的keep-alive timeout时间设置参数。比如nginx的keepalive_timeout，和Apache的KeepAliveTimeout。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;3.3、扩展&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eec576264dafecb673cd8ce958cc526f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1384&quot; data-rawheight=&quot;1510&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-eec576264dafecb673cd8ce958cc526f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1384&quot; data-rawheight=&quot;1510&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-eec576264dafecb673cd8ce958cc526f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-eec576264dafecb673cd8ce958cc526f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt; 其实对于HTTP keep-alive机制可以总结为上图所示。&lt;/p&gt;&lt;p&gt;启用HTTP keep-Alive的优缺点：  优点：keep-alive机制避免了频繁建立和销毁连接的开销。 同时，减少服务端TIME_WAIT状态的TCP连接的数量(因为由服务端进程主动关闭连接) 缺点：若keep-alive timeout设置的时间较长，长时间的TCP连接维持，会一定程度的浪费系统资源。&lt;/p&gt;&lt;p&gt;总体而言，HTTP keep-Alive的机制还是利大于弊的，只要合理使用、配置合理的timeout参数。&lt;/p&gt;&lt;h2&gt;四、总结&lt;/h2&gt;&lt;p&gt;回到文章开头提出的问题：&lt;b&gt;HTTP和TCP的长连接有何区别？HTTP中的keep-alive和TCP中keepalive又有什么区别？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1、TCP连接往往就是我们广义理解上的长连接，因为它具备双端连续收发报文的能力；开启了keep-alive的HTTP连接，也是一种长连接，但是它由于协议本身的限制，服务端无法主动发起应用报文。&lt;/p&gt;&lt;p&gt;2、TCP中的keepalive是用来保鲜、保活的；HTTP中的keep-alive机制主要为了让支撑它的TCP连接活的的更久，所以通常又叫做：HTTP persistent connection（持久连接） 和 HTTP connection reuse（连接重用）。&lt;/p&gt;&lt;h2&gt;五、彩蛋&lt;/h2&gt;&lt;p&gt;&lt;b&gt;彩蛋一&lt;/b&gt;&lt;/p&gt;&lt;p&gt;你能从文中找出我在HTTP keep-alive实验中客户端和服务端的完整IP吗？&lt;/p&gt;&lt;p&gt;如能找出，说明对网络协议的了解已如火纯青。&lt;/p&gt;&lt;p&gt;&lt;b&gt;彩蛋二&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在HTTP请求中，到底是「服务端」还是「客户端」主动关闭连接呢？&lt;/p&gt;&lt;p&gt;看到过很多文章，有人说服务端、有人说客户端、有人说分情况（keep-alive的开启与否）既可能是客户端也可能是服务端。你信谁？最后翻来覆去发现各个网站的各种文章基本类似，只有观点，没有论据。&lt;/p&gt;&lt;p&gt;HTTP keep-alive章节的实验结果：&lt;b&gt;无论开启keep-alive与否，最终由服务端主动断开TCP连接。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;但是我给出问题的答案是：通常&lt;b&gt;由服务端主动关闭连接&lt;/b&gt;。没有写“肯定由服务端主动关闭连接”的原因是，我没遇到客户端主动关闭连接的场景，并不代表没有。网络和协议博大精深，等待我们继续去探索。&lt;/p&gt;&lt;p&gt;这个彩蛋的目的由两个：&lt;/p&gt;&lt;p&gt;1、告诉大家：网上的文章、他人的观点，还是要思辨的看待。&lt;/p&gt;&lt;p&gt;2、我确实想知道什么情况下，客户端主动关闭连接？欢迎大家私信讨论，一定要有真凭实据&lt;/p&gt;&lt;p&gt;&lt;b&gt;彩蛋三&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Wireshark&lt;/b&gt;是一款功能强大的网络封包分析可视化软件。《TCP/IP详解 卷1:协议》第二版相比第一版，书中的抓包工具也将&lt;b&gt;tcpdump&lt;/b&gt;改为&lt;b&gt;&lt;i&gt;*Wireshark。*&lt;/i&gt;&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 个人观点：《TCP/IP详解 卷1:协议》第一版和第二版结合起来看效果更好。第一版的TCP阻塞控制将的更通俗易懂，第二版的TCP保活机制讲的更清晰。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d37d97c6a11dc8b344326d4602cc53e1</guid>
<title>Linux 机器 CPU 毛刺问题排查</title>
<link>https://toutiao.io/k/v3b4fgl</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.1575&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/j3gficicyOvasIjZpiaTNIPReJVWEJf7UGpmokI3LL4NbQDb8fO48fYROmYPXUhXFN8IdDqPcI1gA6OfSLsQHxB4w/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;作者：jasonzxpan，腾讯 IEG 运营开发工程师&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;本文排查一个&lt;strong&gt;Linux 机器 CPU 毛刺&lt;/strong&gt;问题，排查过程中&lt;strong&gt;不变更进程状态、也不会影响线上服务&lt;/strong&gt;，最后还对 CPU 毛刺带来的&lt;strong&gt;风险&lt;/strong&gt;进行了分析和验证。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文中提到 CPU 统计和产生 core 文件的工具详见 &lt;a href=&quot;https://github.com/panzhongxian/simple-perf-tools/blob/master/cpu&quot; data-linktype=&quot;2&quot;&gt;simple-perf-tools&lt;/a&gt; 仓库。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;问题描述&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;某服务所在机器统计显示，其 CPU 使用率在高峰时段出现毛刺。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;暂时未收服务调用方的不良反馈。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.32106854838709675&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkOX0oLxB3kSgyscOdFk03hgXbfEtKXDkoRXYJ49XT39qz7GdzuibKrBLw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1984&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;初步排查&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;查看 CPU 1 分钟平均负载，发现 1 分钟平均负载有高有低，波动明显。说明机器上有些进程使用 CPU 波动很大。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3204030226700252&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkOBVGNsicvulrMJRIGCpNHfibibNff1JyBeXQwPcXx5Iiaj7D0CkibubicfibIg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1985&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;登录机器排查进程，使用&lt;code&gt;top&lt;/code&gt;指令。因为 CPU 会明显上升，重点怀疑使用 CPU 总时间高的进程，在打开 top 后，使用&lt;code&gt;shift&lt;/code&gt; +&lt;code&gt;t&lt;/code&gt;可以按照 CPU TIME 进行排序。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3089005235602094&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkOsgUUX6G6K0iaCkmENO3wwibWkjrdEu4QZ2He1icE5QHmpPYHJVfc9Y27g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2101&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;直观的看，有几个 spp_worker 相关的进程使用 CPU TIME 相对较高。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一个进程因为启动的时间比较长，所以 CPU TIME 也比较大。可以使用下面的脚本，计算各个进程从各自拉起后 CPU 使用率：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;uptime=`awk &lt;span&gt;&#x27;{print $1}&#x27;&lt;/span&gt; /proc/uptime` &lt;span&gt;# why is it too slow indocker?&lt;/span&gt;&lt;br/&gt;hertz=`zcat /proc/config.gz | grep CONFIG_HZ= |awk -F&lt;span&gt;&quot;=&quot;&lt;/span&gt; &lt;span&gt;&#x27;{print $2}&#x27;&lt;/span&gt;`&lt;br/&gt;awk -v uptime=&lt;span&gt;$uptime&lt;/span&gt; -v hertz=&lt;span&gt;$hertz&lt;/span&gt; -- &lt;span&gt;&#x27;{printf(&quot;%d\t%s\t%11.3f\n&quot;, $1, $2, (100 *($14 + $15) / (hertz * uptime - $22)));}&#x27;&lt;/span&gt; /proc/*/&lt;span&gt;stat&lt;/span&gt; 2&amp;gt; /dev/null | sort  -gr -k +3 | head -n 20&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到的也是这些 spp_worker 使用 CPU 相对要高一些：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6714801444043321&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkOVXxK8V35l1ThF7Mdr2q7HbZ3YEk0zqVI21TJzWtYqib3IibkjczvrIow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;选其中的一个 PID 为 45558 的 Worker 进程监控器 CPU 使用率：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.9963459196102314&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkOvrJ4aABTYDf0vhicAz746b4wYmjNlTUTVTHAILo2elBRmjOp0Shv9Lg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;821&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以发现其 CPU 大部分情况很低，但是在某一个时间点会升高，持续 1 秒左右。而且大部分时间是耗费在用户态，而非系统调用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而《&lt;a href=&quot;http://km.oa.com/group/568/articles/show/197164&quot; data-linktype=&quot;2&quot;&gt;Linux Agent 采集项说明 - CPU 使用率&lt;/a&gt;》中描述的 CPU 使用率的采样策略为：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Linux Agent 每分钟会采集 4 次 15 秒内的 CPU 平均使用率。为了避免漏采集 CPU 峰值，网管 Agent 取这一分钟内四次采集的最大值上报。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为采样可能采到高点或者低点，当 1 分钟内出现 CPU 飙升，则会表现为尖峰；如果四次都没有出现飙升，则表现为低谷。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至此，已经能确认是这批 Worker 进程引起了这种毛刺，但具体是哪部分代码有问题还需要进一步排查。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;进一步排查&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前边确认了没有太多的系统调用，所以不必使用&lt;code&gt;strace&lt;/code&gt;工具。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;使用&lt;code&gt;perf&lt;/code&gt;工具&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用&lt;code&gt;perf&lt;/code&gt;工具进行查看。具体的命令是&lt;code&gt;perf top -p 45558&lt;/code&gt;，在低 CPU 使用率的时候：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3238231098430813&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkOLoHE8KNboPWYj5Hfmasdp7D6VTevbYvPyOIxALqxcUlSp6plqasQ9g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2103&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是当 CPU 飚上去的时候，&lt;code&gt;perf&lt;/code&gt;采样的位置变成如下这样：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6312056737588653&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkOrZiceq7d3pTMZcTpcjS7qSv6FibG5hF6uzL3rH6Gia2fkCibM1MfcaHR5Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2115&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看一下红框的位置，可以发现可能是配置更新部分有问题，因为：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;这个地方 Protobuf 特别多的地方，在做更新的操作（有&lt;code&gt;MergeFrom&lt;/code&gt;，有&lt;code&gt;Delete&lt;/code&gt;）&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;有大量的用到了&lt;code&gt;std::map&lt;/code&gt;（有&lt;code&gt;std::_Rb_tree&lt;/code&gt;，有字符串比较）&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过观察&lt;code&gt;perf&lt;/code&gt;结果的方法，虽然能够猜测大计算量的位置，但是有两个不便之处：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;如果 CPU 高的情况发生概率很低，人为观察比较耗时&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;不能明确的知道，具体在哪个文件的哪个函数&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;使用&lt;code&gt;gcore&lt;/code&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最初统计的时候，发现 CPU 高的情况会出现 1 秒多的时间，如果发现 CPU 高负载时，直接调用&lt;code&gt;gcore {pid}&lt;/code&gt;的命令，可以保留堆栈信息，明确具体高负载的位置。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;将使用 gcore 的指令，添加到统计工具中取，设置 CPU 上门限触发。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过&lt;code&gt;gdb&lt;/code&gt;看了几个 coredump 文件，发现堆栈和函数调用基本一致。可以明确的看到，大量的耗时发生在了&lt;code&gt;AddActInfoV3&lt;/code&gt;这一函数中：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5163120567375886&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkOf873QfdBzib6Y81GsmQcsgicaPvAZ4ia6AoRYfsA4jerjeZ17vEFiaZ0tQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2115&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到此位置，我们明确了高计算量发生的具体位置。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;风险点&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CPU 突然飙升是否存在风险呢？是不是计算资源充足的时候，就不会有问题呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个例子中，使用的是 SPP 微线程功能，每个 Worker 进程只启用一个线程。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.10930787589498807&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkOJMd09LiaCJsOV6aibD0ic0qTpSwzYDmqFajlgGpnc0AJf63MFVBV9bibQg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2095&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果仅仅是因为高计算量卡住 CPU，正常处理请求的逻辑将很难被调度到。这样势必会造成处理请求的延迟增大，甚至有超时返回的风险。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;使用 spp 的&lt;code&gt;cost_stat_tool&lt;/code&gt;工具&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;利用 spp 自带的统计工具印证这一风险点，查看 worker 处理前端请求时延统计信息，执行命令&lt;code&gt;./cost_stat_tool -r 1&lt;/code&gt;：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.0528455284552845&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkOhomPe7UicjxejFOiaNwThsya1COORPcH8rgnmxWFbCRq11VticYU2Iz0A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;738&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上边的例子中，统计发生配置更新前后的 5 秒钟内，worker 处理的 231 个请求中，有 3 个请求的处理时间超过 500ms，远高于普通请求。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;使用&lt;code&gt;tcpdump&lt;/code&gt;抓包确认&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因该服务没有打开详细的日志，想要进一步验证超过 500ms 的这些请求也是正常处理的请求，而非异常请求，可以通过抓包来分析。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;tcpdump -i any tcp port 20391 -Xs0 -c 5000 -w service_spp.pcap&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过 wireshark 打开，需要过滤出&lt;strong&gt;返回时间 - 请求时间 &amp;gt; 500ms&lt;/strong&gt;的相关请求。翻译成 wireshark 过滤器的表达式则是：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;tcp.time_delta &amp;gt; 0.5 &amp;amp;&amp;amp; tcp.dstport != 20391&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;过滤出一条符合条件的请求：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.07466918714555766&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkOqFprlbz9zDiaQk5guzlibfH94FuPyIjqmZPHdgOrmKAfGmxw0gficfmfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2116&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在该条记录上&lt;strong&gt;右键 -&amp;gt; Follow -&amp;gt; TCP Stream&lt;/strong&gt;，可以查看该请求前后的 IP 包：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.10369318181818182&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkO58NEW5zPibCMtItsZibu9RBZ8LLcibkZwib4vVwpphfZywsusDhIJsnKxA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2112&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上边 4 个包分别是：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;+0ms 客户端发送请求至服务端&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;+38ms 服务端回复 ACK，无数据&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;+661ms 服务端发送返回至客户端&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;+662ms 客户端回复 ACK&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;详细看了包中的内容为一条普通请求，逻辑简单，应该在 20ms 内返回。而此时的该进程使用 CPU 也确实为高负载的情况：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6623931623931624&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvauxBj2ERdu3icmmEQK49YhkOfsZXn3YzF5CuRkbf9eulUicskr2icKAV8XeJmI93GVnR5PCVuyCyxVzg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;702&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上述统计相互印证：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;CPU 高时，正常的网络请求也会被阻塞住（回复 ACK 需要 38ms，低于 40ms，与&lt;strong&gt;TCP 延迟确认&lt;/strong&gt;无关）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;平时只需要 20ms 能返回的请求，耗时了 660ms&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;CPU 突然飚高有风险，需要认真对待。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;2.9212962962962963&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/j3gficicyOvas6pwmV3uJkq5743PD7xdhgSpjeMRVQVpA1QwOlFCqgdDUQXyibhDl6Hcwnm2KaichXs0kVQtHBqWYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;欢迎关注我们的视频号：腾讯程序员&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_iframe&quot; data-pluginname=&quot;videosnap&quot; data-id=&quot;export/UzFfAgtgekIEAQAAAAAAqH0WReF1EgAAAAstQy6ubaLX4KHWvLEZgBPEx6EwJkhHT6L5zNPgMItSRNKrAt6Gsw0ShaWLH3DR&quot; data-url=&quot;https://findermp.video.qq.com/251/20350/stodownload?encfilekey=jEXicia3muM3GjTlk1Z3kYCefzc4VU4EAS349rsIhicRvwqMY1rPNVs7Mr3Zw2uQVyb2m8ASiaPO2kP67BJ4uzUWPzmqibPJLc4rLesJ7PmbCL84RImw611wYdnksbbvLCM1nF2EFKiafW44PT54iabG7F4a1icG6qZ3ibHyODd6oY3kobK0&amp;amp;bizid=1023&amp;amp;dotrans=0&amp;amp;hy=SH&amp;amp;idx=1&amp;amp;m=a6dea7fde49f377219ff2eab5724d45f&amp;amp;token=x5Y29zUxcibDHxWfF8R3ao4chzK6fic8ia8Sg2QicCXWCq1OyVicC2aAtwRWgeymwzDEo&quot; data-headimgurl=&quot;http://wx.qlogo.cn/finderhead/I7awtksbibjQe7RZAy84xEecUymmic8cw4v7Y2zbnVDuo/0&quot; data-username=&quot;v2_060000231003b20faec8c6e08e1ac1d4cf06ea31b07760a16cba92d83444bd9a5d9d55ffaede@finder&quot; data-nickname=&quot;腾讯程序员&quot; data-desc=&quot;拍照也能助力光盘行动？关于节约粮食，大家有什么妙招呢？  @腾讯公益  @微信派 #光盘行动#  #世界粮食日#  #节约粮食#  #技术公益# &quot; data-nonceid=&quot;4871113052233066306&quot; data-type=&quot;video&quot;/&gt;&lt;/section&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_iframe&quot; data-pluginname=&quot;videosnap&quot; data-id=&quot;export/UzFfAgtgekIEAQAAAAAAC-0xEoRGcgAAAAstQy6ubaLX4KHWvLEZgBPEz6EcbAlWUtD5zNPgMIvF1LAmdQI1LCEv8Hoyl1We&quot; data-url=&quot;https://findermp.video.qq.com/251/20350/stodownload?encfilekey=RBfjicXSHKCOONJnTbRmmlD8cOQPXE48ibOlvTmK7LEKvD2bWprDQphTTo5pmDWF1rojEF9RxjhKu8EyNrshNMFgnsvSAxV2POjzSUcFeCQvX1yqFpLXIgY4J15kdL9ZKysGqFKYRpkptZDLDfsOI4ibjKFfzwHRTB0ib0I0QnqiaBA4&amp;amp;bizid=1023&amp;amp;dotrans=0&amp;amp;hy=SH&amp;amp;idx=1&amp;amp;m=f2f8f8e1228b86995b7f97ecadaa9cbb&amp;amp;token=cztXnd9GyrGqKjnmm8EjsDQ81jgmDmwe86NGickDa3Ffzy8omkM4cjB9oEYx2c5FM&quot; data-headimgurl=&quot;http://wx.qlogo.cn/finderhead/I7awtksbibjQe7RZAy84xEecUymmic8cw4v7Y2zbnVDuo/0&quot; data-username=&quot;v2_060000231003b20faec8c6e08e1ac1d4cf06ea31b07760a16cba92d83444bd9a5d9d55ffaede@finder&quot; data-nickname=&quot;腾讯程序员&quot; data-desc=&quot;用代码带你梦回大唐，花好月圆。即将到来的中秋和国庆在同一天，一个世纪仅有 4 次，关于中秋你有什么想说的，留言区告诉我吧。#微信视频号创造营# #程序员# #央视中秋晚会#&amp;#10; @微信视频号创造营 @微信派 @几米映画 &quot; data-nonceid=&quot;16186019876485686968&quot; data-type=&quot;video&quot;/&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>