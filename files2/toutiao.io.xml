<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>c193198bb5a187e5f0146e32766bc3e9</guid>
<title>[译] Kubernetes 调度详解</title>
<link>https://toutiao.io/k/w17gmb0</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section&gt;&lt;span&gt;Kubernetes Scheduler 是 Kubernetes 控制平面的核心组件之一。它在控制平面上运行，将 Pod 分配给节点，同时平衡节点之间的资源利用率。将 Pod 分配给新节点后，在该节点上运行的 kubelet 会在 Kubernetes API 中检索 Pod 定义，根据节点上的 Pod 规范创建资源和容器。换句话说，&lt;strong&gt;Scheduler 在控制平面内运行，并将工作负载分配给 Kubernetes 集群&lt;/strong&gt;。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;本文将对 Kubernetes Scheduler 进行深入研究，首先概述一般的调度以及具有亲和力（affinity）和 taint 的驱逐调度，然后讨论调度程序的瓶颈以及生产中可能遇到的问题，最后研究如何微调调度程序的参数以适合集群。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;调度简介&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Kubernetes 调度是将 Pod 分配给集群中匹配节点的过程。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Scheduler 监控新创建的 Pod，并为其分配最佳节点。它会根据 Kubernetes 的调度原则和我们的配置选项选择最佳节点。&lt;/span&gt;&lt;span&gt;最简单的配置选项是直接在 &lt;/span&gt;&lt;code&gt;&lt;span&gt;PodSpec&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 设置 nodeName：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;496&quot; data-backw=&quot;486&quot; data-ratio=&quot;1.0205761316872428&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGvQ5fCgEdeE2YHzQrXVE78lsCNeYkyZ0UrBMia6qvBTBvZbXe7Ssg8cA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;486&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;上面的 nginx pod 默认情况下将在 node-01 上运行，但是 nodeName 有许多限制导致无法正常运行 Pod，例如云中节点名称未知、资源节点不足以及节点网络间歇性问题等。因此，除了测试或开发期间，我们最好不使用 nodeName。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果要在一组特定的节点上运行 Pod，可以使用 nodeSelector。我们在 &lt;/span&gt;&lt;code&gt;&lt;span&gt;PodSpec&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 中将 nodeSelector 定义为一组键值对：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;542&quot; data-backw=&quot;444&quot; data-ratio=&quot;1.2207207207207207&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGlCNuib1s4oCJYXJuhD9laj0sDBytoCHg7UUVwDsxGibPhCWmcBDHfh8g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;444&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;对于上面的 nginx pod，Kubernetes Scheduler 将找到一个磁盘类型为 ssd 的节点。当然，该节点可以具有其他标签。我们可以在 Kubernetes 参考文档中查看标签的完整列表。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;地址：&lt;/span&gt;&lt;span&gt;https://kubernetes.io/docs/reference/kubernetes-api/labels-annotations-taints/&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;使用 &lt;/span&gt;&lt;code&gt;&lt;span&gt;nodeSelector&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 有约束 Pod 可以在有特定标签的节点上运行。但它的使用仅受标签及其值限制。Kubernetes 中有两个更全面的功能来表达更复杂的调度需求：节点亲和力（node affinity），标记容器以将其吸引到一组节点上；taint 和 toleration，标记节点以排斥 Pod。这些功能将在下面讨论。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;节点亲和力&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;节点亲和力&lt;span&gt;（Node Affinity）&lt;/span&gt;是在 Pod 上定义的一组约束，用于确定哪些节点适合进行调度，即使用亲和性规则为 Pod 的节点分配定义硬性要求和软性要求。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;例如可以将 Pod 配置为仅运行带有 GPU 的节点，并且最好使用 NVIDIA_TESLA_V100 运行深度学习工作负载。Scheduler 会评估规则，并在定义的约束内找到合适的节点。与 &lt;/span&gt;&lt;code&gt;&lt;span&gt;nodeSelectors&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 相似，节点亲和性规则可与节点标签一起使用，但它比 &lt;/span&gt;&lt;code&gt;&lt;span&gt;nodeSelectors&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 更强大。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;我们可以为 podspec 添加四个相似性规则：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;requiredDuringSchedulingIgnoredDuringExecution&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;requiredDuringSchedulingRequiredDuringExecution&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;preferredDuringSchedulingIgnoredDuringExecution&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;preferredDuringSchedulingRequiredDuringExecution&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;这四个规则由两个条件组成：必需或首选条件，以及两个阶段：计划和执行。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;以 required 开头的规则描述了必须满足的严格要求。以 preferred 开头的规则是软性要求，将强制执行但不能保证。调度阶段是指将 Pod 首次分配给节点。执行阶段适用于在调度分配后节点标签发生更改的情况。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果规则声明为 IgnoredDuringExecution，Scheduler 在第一次分配后不会检查其有效性。但如果使用 RequiredDuringExecution 指定了规则，Scheduler 会通过将容器移至合适的节点来确保规则的有效性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以下是示例：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;589&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;674&quot; data-ratio=&quot;1.0193236714975846&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGofCRibndVXu77KHaoictKkeDibhgmuywiblyjw26V5jr2h6wzeWWz6Qliag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1242&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;上面的 Nginx Pod 具有节点亲和性规则，该规则让 Kubernetes Scheduler 将 Pod 放置在 us-east 的节点上。第二条规则指示优先使用 us-east-1 或 us-east-2。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;使用亲和性规则，我们可以让 Kubernetes 调度决策适用于自定义需求。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Taint 与 Toleration&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;集群中并非所有 Kubernetes 节点都相同。某些节点可能具有特殊的硬件，例如 GPU、磁盘或网络功能。同样，我们可能需要将一些节点专用于测试、数据保护或用户组。我们可以将 Taint 添加到节点以排斥 Pod，如以下示例所示：&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;code&gt;&lt;span&gt;kubectl taint nodes node1 test-environment=true:NoSchedule&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;使用 &lt;/span&gt;&lt;code&gt;&lt;span&gt;test-environment=true:NoScheduletaint&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 时，除非在 podspec 具有匹配的 toleration，否则 Kubernetes Scheduler 将不会分配任何 pod ：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;553&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;673&quot; data-ratio=&quot;0.9575757575757575&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGicbLayoIBkdqkfx5eVguIcJLiaLtZgWTicGTicAGoW1kqKurth41yIzWog/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;660&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;taint 和 tolerations 共同发挥作用，让 Kubernetes Scheduler 专用于某些节点并分配特定 Pod。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;调度瓶颈&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;尽管 Kubernetes Scheduler 能选择最佳节点，但是在 Pod 开始运行之后，“最佳节点”可能会改变。所以从长远来看，Pod 的资源使用及其节点分配可能存在问题。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;资源请求（Request）和限制（Limit）：“Noisy Neighbor”&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;“Noisy Neighbor”并不特定于 Kubernetes。任何多租户系统都是它们的潜在地。假设有两个容器 A 和 B，它们在同一节点上运行。如果 Pod B 试图通过消耗所有 CPU 或内存来创造 noise，Pod A 将出现问题。如果我们为容器设置了资源请求和限制就能控制住 neighbor。Kubernetes 将确保为容器安排其请求的资源，并且不会消耗超出其资源限制的资源。如果在生产中运行 Kubernetes，最好设置资源请求和限制以确保系统可靠。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;系统进程资源不足&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Kubernetes 节点主要是连接到 Kubernetes 控制平面的虚拟机。因此，节点上也有自己的操作系统和相关进程。如果 Kubernetes 工作负载消耗了所有资源，则这些节点将无法运行，并会发生各种问题问题。我们需要在 kubelet 中使用 –system -reserved 设置保留资源，以防止发生这种情况。&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;抢占或调度 Pod&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果 Kubernetes Scheduler 无法将 Pod 调度到可用节点，则可以从节点抢占（preempt）或驱逐（evict）一些 Pod 以分配资源。如果看到 Pod 在集群中移动而没有发现特定原因，可以使用优先级类对其进行定义。同样，如果没有调度好 Pod，并且正在等待其他 Pod，也需要检查其优先级。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以下是示例：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;181&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;235&quot; data-ratio=&quot;0.31337047353760444&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGCOy36sR7upNEKu71SbXfnVgEzSzEb31LmQKnlgcV8dKCs0jzHicGLVQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1436&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;可以通过以下方式在 podspec 中为分配优先级：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;257&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;328&quot; data-ratio=&quot;0.4452423698384201&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGtdyKGib5R2OxMm4npCcnbN8rDfZNd3ib0HeD32sYdHX88Md2XIJDJmDg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1114&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;调度框架&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;Kubernetes Scheduler 具有可插拔的调度框架架构，可向框架添加一组新的插件。插件实现 Plugin API，并被编译到调度程序中。下面我们将讨论调度框架的工作流、扩展点和 Plugin API。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;工作流和扩展点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;调度 Pod 包括两个阶段：调度周期（scheduling cycle）和绑定周期（binding cycle）。在调度周期中，Scheduler 会找到一个可用节点，然后在绑定过程中，将决策应用于集群。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下图说明了阶段和扩展点的流程：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;305&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5283203125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGcmsVyMOa9e4SQnkCaokDFCdJtUQkDTx1oApezIm6hKq2IRbQicic4O0A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;调度工作流（来源：Kubernetes 文档）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;工作流中的以下几点对插件扩展开放：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;QueueSort：对队列中的 Pod 进行排序&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;PreFilter：检查预处理 Pod 的相关信息以安排调度周期&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Filter：过滤不适合该 Pod 的节点&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;PostFilter：如果找不到可用于 Pod 的可行节点，调用该插件&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;PreScore：运行 PreScore 任务以生成一个可共享状态供 Score 插件使用&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Score：通过调用每个 Score 插件对过滤的节点进行排名&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;NormalizeScore：合并分数并计算节点的最终排名&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Reserve：在绑定周期之前选择保留的节点&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Permit：批准或拒绝调度周期结果&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;PreBind：执行任何先决条件工作，例如配置网络卷&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Bind：将 Pod 分配给 Kubernetes API 中的节点&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;PostBind：通知绑定周期的结果&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;插件扩展实现了 Plugin API，是 Kubernetes Scheduler 的一部分。我们可以在 Kubernetes 存储库中检查。插件应使用以下名称进行注册：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;98&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;148&quot; data-ratio=&quot;0.17002518891687657&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGP6uWJQmoHvPNW2bS3cN6wewfpTmLnPJyjTYLACyQVYeA3wiaJL9IMlQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1588&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;插件还实现了相关的扩展点，如下所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;127&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;191&quot; data-ratio=&quot;0.2197265625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGDkicliaRR19tIpibpSTiaibMpFqiaIO5icN3DbHQmllCFnCjGzNfErozonYuQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2048&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Scheduler 性能调整&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;Kubernetes Scheduler 有一个工作流来查找和绑定 Pod 的可行节点。当集群中的节点数量非常多时，Scheduler 的工作量将成倍增加。在大型集群中，可能需要很长时间才能找到最佳节点，因此要微调调度程序的性能，以在延迟和准确性之间找到折中方案。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;percentageOfNodesToScore 将限制节点的数量来计算自己的分数。默认情况下，Kubernetes 在 100 节点集群的 50％ 和 5000 节点集群的 10％ 之间设置线性阈值。默认最小值为 5％，它要确保至少考虑集群中 5％ 节点的调度。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面的示例展示了如何通过性能调整 kube-scheduler 来手动设置阈值：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;163&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;257&quot; data-ratio=&quot;0.28186714542190305&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcG4glTLP1jy7so5frMxNRlibgevFPXHcibcpg8C3QlapxEmtDnl1f1XjQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1114&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果有一个庞大的集群并且 Kubernetes 工作负载不能承受 Kubernetes Scheduler 引起的延迟，那么更改百分比是个好主意。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;本文涵盖了 Kubernetes 调度的大多方面，从 Pod 和节点的配置开始，包括 nodeSelector、亲和性规则、taint 和 toleration，然后介绍了 Kubernetes Scheduler 框架、扩展点、API 以及可能发生的与资源相关的瓶颈，最后展示了性能调整设置。尽管 Kubernetes Scheduler 能简单地将 Pod 分配给节点，但是了解其动态性并对其进行配置以实现可靠的生产级 Kubernetes 设置至关重要。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;原文链接：&lt;/span&gt;&lt;span&gt;https://thenewstack.io/a-deep-dive-into-kubernetes-scheduling/&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b2653ba887af1e6490e0f2992f2fb074</guid>
<title>Netflix 是怎样做系统监控的？</title>
<link>https://toutiao.io/k/n38vxll</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section&gt;&lt;span&gt;作为知名的流媒体巨头，Netflix 在全球拥有近 2 亿订阅用户，服务遍及多个国家。本文阐述了 Netflix 的系统监控实践：自研 Telltale，成功运行并监控着 Netflix 100 多个生产应用程序的运行状况。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;1 难忘的经历&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;相信很多运维人都有过这样的经历：&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;监控系统某个指标超过阈值，触发告警。大半夜里，你被紧急召唤。半睁着眼，你满脸疑惑：“系统真出问题了吗，还是仅仅需要调整下告警？上一次有人调整我们的告警阈值是在什么时候？有没有可能是上游或者下游的服务出现了问题？”&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;鉴于这是一次非常重要的应用告警，因此你不得不从床上爬起来，迅速打开电脑，然后浏览监控仪表盘来追踪问题源头。忙了半天，你还没确认这个告警是来自于系统的问题，但也意识到，从海量数据中寻找线索时，时间正在流逝。你必须尽快定位告警的原因，并祈祷系统稳定运行。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;对我们的用户来讲，稳健的 Netflix 服务至关重要。当你坐下来看《养虎为患》时，你肯定希望它能顺利播放。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多年来，我们从经常在深夜被召唤的工程师那里了解到应用程序监控的痛点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;过多的告警&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;太多滚动浏览的仪表盘&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;太多的配置&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;过多的维护&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://netflixtechblog.com/full-cycle-developers-at-netflix-a08c31f83249&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2 Telltale&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我们的流媒体团队需要一个全新的监控系统，可以让团队成员快速地诊断和修复问题；因为在系统告警的紧急情况下，每一秒都至关重要！我们的 Node 团队 需要一个仅需一小撮人就能运维大型集群的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，我们构建了 Telltale。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.392&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJFFcu949wWgyibjHWbObeib9Ar0hiac5ibW8EGT6ayJYiauoJljCpE6qI5vaQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 监控时间轴&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt; Telltale 的特性&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;1. 汇集监控数据源，创建整体监控视图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 汇集了各种监控数据源，从而能创建关于应用程序运行状况的整体监控视图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 多维度判断应用程序的健康状况&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 可以通过多个维度判断一个应用程序的健康情况，而无需根据单一指标频繁调整告警阈值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 及时告警&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为我们知道应用程序在什么情况下是正常的，所以能在应用程序有异常趋势时及时通知应用程序的所有者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 显示关键数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;指标是了解应用程序运行状态的关键。但很多时候，你拥有太多的指标、太多的图表以及太多的监控仪表盘。而 Telltale 仅显示应用程序中有用的相关数据及其上游和下游服务的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 用颜色区分问题的严重程度&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用不同的颜色来表示问题的严重程度（除选择颜色之外，还可以让 Telltale 显示不同的数字），以便运维人员一眼就能判断出应用程序的运行状况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6. 高亮提示&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还会对一些监控事件进行高亮提示，比如局部区域的网络流量疏散及就近的 服务部署，这些信息对于全面了解服务的健康情况至关重要，尤其是在真正发生系统故障的情况下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是我们的 Telltale 监控。它现已成功运行并提供监控服务，监控着 Netflix 100 多个生产应用程序的运行状况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.8022857142857143&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJF7jMpgsRQZn473Pa3G9CZvyaiaNxHByfVDCbdy9s54rBAuTPicKeicibxiag/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;3应用程序健康评估模型&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;微服务并非是孤立存在和运行的。它需要特定的依赖，与其他服务进行数据交互，甚至位于不同的AWS区域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面的调用图是一个相对简单的图，其中涉及许多服务，实际的调用链可能会更深更复杂。一个应用程序是系统生态的一部分，它的运行状态可能会受到相关属性变化的微弱影响，也有可能会受到区域范围内某些事件的影响从而发生根本性改变。canary的启动可能会对应用程序产生一定影响。在一定程度上，上游或下游服务的部署同样也可以带来一定的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://netflixtechblog.com/automated-canary-analysis-at-netflix-with-kayenta-3260bc7acc69&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 通过使用多个维度的数据源构建一个不断自我优化的模型来监控应用程序的健康度：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Atlas 时序指标&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;区域网络流量疏散&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Mantis 实时流数据&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;基础架构变更事件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Canary 部署及使用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;上、下游服务的运行状况&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;表征 QoE 的相关指标&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;告警平台发出的报警&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同的数据源对应用程序健康度的影响权重不同。例如，与错误率增加相比，响应时间的增加对应用程序的影响要小很多；错误代码有很多，但是某些特定的错误代码的影响要比其他错误代码的影响大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在服务下游部署 canary 可能不如在上游部署带来的效果明显&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;区域网络流量转移意味着某个区域的网络流量降为零而另一个区域的网络流量会加倍。你可以感受下不同的指标对于监控的影响。监控指标的具体含义决定了我们应该如何科学有效地使用它来进行监控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://netflixtechblog.com/project-nimble-region-evacuation-reimagined-d0d0568254d4&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在构建应用程序健康状况视图时，Telltale 考虑了所有这些因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应用程序健康评估模型是 Telltale 的核心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;4智能监控&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;每个服务运维人员都知道告警阈值调整的难度。将阈值设置得太低，你会收到大量虚假告警。如果过度补偿并放宽告警阈值，就会错过重要的异常警告。这样导致的最终结果是对告警缺乏信任。Telltale 可以帮助你免除不断调整相关配置的繁琐工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过提供准确的和严格管理的数据源，我们能让应用程序所有者的设置和配置过程变得更加容易。这些数据源通过按照一定的组合应用到程序的配置中，以实现最常见的服务类型配置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 可以自动追踪服务之间的依赖关系，以构建应用程序健康评估模型中的拓扑。通过数据源管理以及拓扑监测，在不用付出很大的努力情况下就能使配置保持最新状态。那些需要手动实践的一些场景仍然支持手动配置和调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没有任何一个独立的算法可以适用我们所有的监控场景。因此，我们采用了混合算法，包括统计算法、基于规则的算法和机器学习算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不久后，我们将在 Netflix Tech Blog 上发表一篇针对我们监控算法的文章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 还具有分析器，可用于趋势探测或内存泄漏监测。智能监控意味着我们的用户可以信赖我们的监控结果。这表明故障发生时，用户能更快地定位和解决系统异常问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;5智能告警&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;智能监控必然会促进智能告警。当 Telltale 检测到应用程序中的运行异常时，就会产生异常事件。团队可以选择通过 Slack、电子邮件或 PagerDuty（均由我们的内部告警系统提供支持）进行告警。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果该异常问题是由上游或下游系统引起的，则 Telltale 的上下文感知路由会提醒服务对应的维护团队。智能告警还意味着运维团队针对特定异常只会收到一个通知，也就是说，告警风暴已经成为过去式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.4940828402366864&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;676&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJFpv5YEJvVDfp4piaZ7L3RxGTbDAYDV152iacDMwiciaibAv593LWibibNAdpCg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Slack 中的 Telltale 通知示例&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在系统出现问题时，掌握准确的信息至关重要。我们的 Slack 告警程序还会启动一个包含有关事件上下文信息的线程，提供 Telltale 识别到的异常问题信息及问题产生的原因。正确的上下文可以方便我们了解应用程序的当前状态，以便值班运维的工程师能有针对性的定位和修复问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;异常告警事件会不断发展而且拥有自己的生命周期，因此及时更新事件状态至关重要。告警异常是好转了还是恶化了？是否要考虑新的监控信息或事件？Telltale 在当前事件发生改变时会更新 Slack 线程。系统返回正常状态后，该线程将被标记为“已解决”，因此用户一眼就能知道哪些异常事件正在处理中，哪些异常事件已成功修复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些 Slack 线程不仅仅适用于 Telltale。团队还可以用它们来共享有关事件的其他数据，方便进一步观察、理论分析和讨论。异常信息数据和讨论全部集中在一个线程中，方便达成针对当前异常的共识，有利于更快提出问题的解决方案以及异常事件的事后分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们致力于提高 Telltale 告警的质量。一种方法是向我们的用户学习。因此，我们在 Slack 消息中提供了反馈按钮。用户可以告诉我们以后某些情况不需要再发生告警，或提供某些告警不合理的原因。智能告警意味着用户可以信赖我们的告警。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5233968804159446&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;577&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJFQknyUSYJImrDt3RVA5pWGKticNCGLYFMOAJFH6jxyJGz1oSGVRxCiamw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Slack 的 Telltale 通知中描述异常详细信息的一个示例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt; 为什么我的应用服务运行状态欠佳？&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;各种类型的监控数据、应用程序相关知识以及跨多种服务数据的相关性，有助于 Telltale 检测分析应用程序运行健康度降低的原因。这些原因包括实例异常、相关依赖的监测和部署异常、数据库异常或者网络流量高峰等。突出高亮显示这些可能的原因可以帮助运维人员节省大量宝贵的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;6异常事件管理&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.6765714285714286&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJFxVtwF0IgQv8O409rMAiavflDHtNyz2hzVib129Mln6RbbtKZ7tDKQDGw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 异常事件摘要的一个示例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当 Telltale 发送告警时，它还会创建一个快照，其中引用了不正常的监控信号数据。随着新监控信息的到来，会将其添加到此快照中。这简化了团队的很多事后审查流程。当需要复查过去的异常问题时，“应用程序事件摘要”功能可以从各个方面显示当前的问题，包括一些关键指标，比如总停机时间和 MTTR（平均解决时间）。我们希望帮助我们的团队了解更多的异常事件的模式，以便提高我们服务的整体可用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.8294701986754967&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;604&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJFUaxfpiaGyLGVERw3nV6FYSrzKWRqyBKpiaqUaqNxI0GlQHf0Dg1VTeIQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;集群视图下将相似异常事件分组&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;7部署监控&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;可以看出，Telltale 的应用程序健康评估模型及其智能监控功能非常强大，所以我们也会将其应用于安全部署方面。我们从开放源码交付平台 Spinnaker 开始测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;https://spinnaker.io/&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着 Spinnaker 逐渐推出新版本，我们使用 Telltale 连续监监控运行新版本实例的运行状态。持续监控意味着新部署在问题出现时能自行停止并进行回滚操作。这意味着部署存在问题时的影响半径较小，持续时间更短。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.8361111111111111&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJFyhvxeQj5F99suvQBZ0anw0iaCiaHeHJhfzQjFwmVpVsk5hSibUk4h0czQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;8 持续优化&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;在复杂的系统中，运行微服务非常具有挑战性。Telltale 的智能监控和告警功能可以帮助我们运维人员提高系统可用性、降低运维人员的劳动强度并减少工作人员大半夜被叫醒的频率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们为 Telltale 做到的这些功能提升感到高兴。但是远没有结束，我们仍在不断探索新算法，以提高告警的准确性。我们将在以后的 Netflix Tech Blog 文章中详细介绍我们的工作进展&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们仍然在对应用程序健康评估模型进行进一步评估和改进。我们相信服务运行日志和跟踪数据中会包含更多有价值的信息，这样我们就能采集到更有用的指标数据。我们很期待与平台其他团队进行合作，共同开发这些新功能。将新应用监控引入 Telltale 可以享受到很好的服务体验，但是无法很好的进行扩展，所以我们绝对可以优化和提高自服务的用户界面。我们确信，有更好的启发式方法能帮助用户找出影响服务健康度的一些因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 简化了应用程序的监控。&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4d7f079c79e9fcc94b4724d557f796ba</guid>
<title>API 与 SDK：有什么区别？</title>
<link>https://toutiao.io/k/wfho1cn</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p&gt;&lt;img data-ratio=&quot;0.4255555555555556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/1skeHK2Gybz4EOycqR6dyly2ZAsoZlT1ncnlHcgicX6Ec1Rb80QJrKPFaNhnjXTh7z7AEn87uwYtyGHpEgIFianQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;900&quot; title=&quot;null&quot;/&gt;&lt;/p&gt;&lt;h2&gt;前言&lt;/h2&gt;&lt;p&gt;什么是 API？&lt;/p&gt;&lt;p&gt;什么是 SDK？&lt;/p&gt;&lt;p&gt;两者之间有何关系？&lt;/p&gt;&lt;p&gt;欢迎来到本次的每周一问系列。&lt;/p&gt;&lt;p&gt;既然点进来了，相信你或多或少都听说过这两个名词了，因此，在为你解答之前，让我们先从一个例子出发。假如你想开发一个 OCR 应用（通俗的说就是文字识别应用），他的功能是识别用户上传的一张图片，然后将图片中的文字识别出来返回给用户。如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5044642857142857&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/1skeHK2Gybz4EOycqR6dyly2ZAsoZlT1Jsc3vJ12vSWfic1GAtyic5rVvKvN2iblslYuDKVxcJo79ibZ9JF0AnvCow/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1792&quot; title=&quot;null&quot;/&gt;&lt;/p&gt;&lt;p&gt;通常，OCR 应用的后端服务都会部署在云上，那么我们应该如何在移动应用程序与基于云的服务之间进行通信呢？&lt;/p&gt;&lt;p&gt;这就是 API 和 SDK 的用武之地了。&lt;/p&gt;&lt;h2&gt;API&lt;/h2&gt;&lt;h3&gt;API 的特点&lt;/h3&gt;&lt;h3&gt;通信&lt;/h3&gt;&lt;p&gt;首先我们要明白的是 API 是和&lt;strong&gt;通信&lt;/strong&gt;有关的，是用于应用（服务）与其他应用（服务）对话所定义的协议。在上述例子中，你可以简单理解为 API 是 OCR 应用和云端服务之间沟通的桥梁。&lt;/p&gt;&lt;p&gt;那么 API 到底是什么？&lt;/p&gt;&lt;p&gt;API 全称 Application Programming Interface，即&lt;strong&gt;「应用程序接口」&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;一般是指一些预先定义的&lt;strong&gt;函数&lt;/strong&gt;，目的是供应用程序与开发人员基于某软件或硬件得以访问一组程序的能力，而又无需访问源码，或理解内部工作机制的细节。&lt;/p&gt;&lt;p&gt;以 Java 为例，当你想要实现一个数组排序的功能时，你是会先手写一个排序算法，还是直接使用&lt;code&gt;Arrays.sort()&lt;/code&gt;函数？我想你心里是有答案的。&lt;/p&gt;&lt;h3&gt;抽象&lt;/h3&gt;&lt;p&gt;其次，我们要理解，API 的另一个重要特点——&lt;strong&gt;抽象。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;抽象指的又是什么？&lt;/p&gt;&lt;p&gt;还是以这个 OCR 应用为例，当我们在使用云端提供的文字识别能力时（比如百度文字识别），他的背后可能会有成千上万的代码，比如提供识别能力的机器学习的代码、提供 Web 能力的后端代码等等。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.28820375335120646&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/1skeHK2Gybz4EOycqR6dyly2ZAsoZlT1WJmzO4q7X9k8ok0Ooo541XkMFDnovGJImvFibSOrDazMa4zcpqcQqMA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1492&quot; title=&quot;null&quot;/&gt;&lt;/p&gt;&lt;p&gt;但是你作为一个 APP 的开发者，你需要去看这些代码是怎么写的吗？难道不知道背后的源码就不能调用百度提供的文字识别能力了吗？当然不是。&lt;/p&gt;&lt;p&gt;通常服务商已经给你提供了文档，告诉你如何去调用相应服务，只要你按照他的要求来即可。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5338606030647554&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/1skeHK2Gybz4EOycqR6dyly2ZAsoZlT1cLwQVvruBhlxF78oW2qhIGuahIkK0g9JQep94ApC9P8oAoRzxzicUKQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;2023&quot; title=&quot;null&quot;/&gt;&lt;/p&gt;&lt;p&gt;因此，在你的 APP 和 OCR 服务之间，API 抽象出所有复杂的逻辑，&lt;strong&gt;简化了调用过程&lt;/strong&gt;，这使得你只需要考虑获取所需的数据即可。&lt;/p&gt;&lt;h3&gt;标准化&lt;/h3&gt;&lt;p&gt;API 是标准化的，这意味着存在有关如何定义 API 的行业标准，比如 SOAP、REST、GraphQL 等。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;我在&lt;span&gt;《你的第一本 SpringBoot 书》&lt;sup&gt;[1]&lt;/sup&gt;&lt;/span&gt;中写到什么是 RESTful API，有兴趣的小伙伴可以点击阅读，这是我正在写的一本 SpringBoot 入门教程，目前还没完工，欢迎读者们不要吝啬自己的建议 🙏。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3&gt;API 的构成要素&lt;/h3&gt;&lt;p&gt;那么，API 通常由什么组成呢？&lt;/p&gt;&lt;p&gt;首先，我们要发送一些数据到云端，即所谓的「请求」。&lt;/p&gt;&lt;p&gt;从本地应用发请求到云端，我们需要分几步完成，以 REST 为例。&lt;/p&gt;&lt;p&gt;对于 REST API 调用请求，第一步是指定传输的方法，通常是和 HTTP 方法对应的，如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.20812182741116753&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/1skeHK2Gybz4EOycqR6dyly2ZAsoZlT1gOIvjufnj3hQD7KKn7NAbszUaBpXU0IgHpCsreqXb6gicrFvZAE4a1w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1970&quot; title=&quot;null&quot;/&gt;&lt;/p&gt;&lt;p&gt;当你想要上传一张图片时，通常会使用 POST 方法，然后是传递一些参数，包括请求的内容（图像本身）。然后加上需要请求的地址，即可构成一个完整的请求。如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.4082352941176471&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/1skeHK2Gybz4EOycqR6dyly2ZAsoZlT1agghzNA6zAnL5wN2rnqcwKtOb4ojVPT6FsicD3C26jrbPBRicQvUUSfA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1700&quot; title=&quot;null&quot;/&gt;&lt;/p&gt;&lt;p&gt;之后，服务器再以 JSON 等形式将数据返还给你，在你使用的云服务的文档中也会有所标注。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.3460591133004926&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/1skeHK2Gybz4EOycqR6dyly2ZAsoZlT1BA4GZQWnI6N4NtQWlnrxtCKn1700BsronwkBegDY8PGTuFdxmL4nXw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1624&quot; title=&quot;null&quot;/&gt;&lt;/p&gt;&lt;h2&gt;SDK&lt;/h2&gt;&lt;p&gt;说了这么多，你应该对 API 有所了解了，那么这时候问题就来了，作为开发人员，你如何在实际的项目中调用 API？&lt;/p&gt;&lt;p&gt;你要自己构造 HTTP 请求、拼接 URL、添加需要的参数、处理返回的 JSON 对象，麻烦吗？&lt;/p&gt;&lt;p&gt;麻烦。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.740139211136891&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/1skeHK2Gybz4EOycqR6dyly2ZAsoZlT1FQibMH4c0BicSicv5IibcMGHVz6Evbkff1Jd1yJxthU9tXCgR6icWwYF0gw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;862&quot; title=&quot;null&quot;/&gt;&lt;/p&gt;&lt;p&gt;那有没有什么好的办法简化这些操作，使得我只需要给一张图片然后就给我返回结果的呢？&lt;/p&gt;&lt;p&gt;自然是有的，这就是接下来我们要说的 SDK 了。&lt;/p&gt;&lt;p&gt;SDK 全称 Software Development Kit，&lt;strong&gt;软件开发工具包&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;一般都是一些软件工程师为特定的软件包、软件框架、硬件平台、操作系统等建立应用软件时的开发工具的集合。&lt;/p&gt;&lt;p&gt;通俗来讲就是&lt;strong&gt;第三方服务商提供的实现产品软件某项功能的工具包&lt;/strong&gt;。例如 JDK 就是一种 SDK。&lt;/p&gt;&lt;p&gt;还是以上面的 OCR 应用为例，如果使用了某厂商的 SDK 服务，那么我们连 HTTP 请求的构建都不需要了，仅调用一个方法，可能的代码如下图所示。&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre data-lang=&quot;java&quot;&gt;&lt;code&gt;&lt;span&gt;OCRResult&lt;/span&gt; res = ocrClient.ocr(&lt;span&gt;&quot;pic.jpg&quot;&lt;/span&gt;).getResult();&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;通过调用这行代码，SDK 会自动封装 API 请求，而且作为响应，你获得的结果也不一定是 JSON 对象，也有可能是代码，例如上述代码段里的&lt;code&gt;OCRResult&lt;/code&gt;，这是因为 SDK 也已经将 JSON 对象&lt;strong&gt;反序列化&lt;/strong&gt;成你需要的对象，比如一个 Java Model。&lt;/p&gt;&lt;p&gt;SDK 相当于开发集成工具环境，API 就是数据接口。API 可以在 SDK 提供的“环境”里请求。同样的，这里的“环境”也是一个抽象的概念。如果不使用 SDK，也可以直接调用 API，只不过，这个环境就要由开发者自己实现了。&lt;/p&gt;&lt;h2&gt;区别&lt;/h2&gt;&lt;p&gt;其实从上面的内容，我们也已了解到，API 在更多场合下更像是 SDK 的一个子集，他们的区别如下：&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;API 通常是一个函数，有特定的功能；而 SDK 是一个很多功能函数的&lt;strong&gt;集合体&lt;/strong&gt;，更像是一个工具包。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;API 通常扮演数据接口的形象，SDK 相当于一个工具环境，通常是需要在 SDK 的环境下调用 APl。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;SDK 相较于 API 封装层次更高。&lt;/span&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;以上就是本篇文章的全部内容了，如果你觉得文章对你有所帮助，随手点个关注转发给你的小伙伴们，这对我真的很重要，你们的支持是我继续更文的动力，谢谢大家！&lt;/p&gt;&lt;h3&gt;References&lt;/h3&gt;&lt;p&gt;&lt;code&gt;[1]&lt;/code&gt; 《你的第一本 SpringBoot 书》: &lt;em&gt;https://book.liangyueyong.cn/00-1/01&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>ca4d3568f2c4898293875aadc2f6b8a7</guid>
<title>深度解析 Raft 分布式一致性协议</title>
<link>https://toutiao.io/k/am8mql2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9517241379310345&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6rxOmdqsWFX4xjLOnOqvByPwoIk8q8ypLYj9HScINibBWT3VEmaFwTAVCAiccGz3TGxsuKXK8eaIhSA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2465&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;笔者期望通过一篇权威靠谱、清晰易懂的系统性文章，帮助读者深入理解 Raft 算法，并能付诸于工程实践中，同时解读不易理解或容易误解的关键点。&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文是 Raft 实战系列理论内容的整合篇，我们结合 Raft 论文讲解 Raft 算法思路，并遵循 Raft 的模块化思想对难理解及容易误解的内容抽丝剥茧。算法方面讲解：选主机制、基于日志实现状态机机制、安全正确维护状态机机制；工程实现方面讲解：集群成员变更防脑裂策略、解决数据膨胀及快速恢复状态机策略、线性一致读性能优化策略等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;注：本篇内容较多，建议在大屏 PC 或平板阅读，效果更佳。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 概述&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.1 Raft 是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;Raft is a consensus algorithm for managing a replicated log. It produces a result equivalent to (multi-)Paxos, and it is as efficient as Paxos, but its structure is different from Paxos; this makes Raft more understandable than Paxos and also provides a better foundation for building practical systems.&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;--《In Search of an Understandable Consensus Algorithm》&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在分布式系统中，为了消除单点提高系统可用性，通常会使用副本来进行容错，但这会带来另一个问题，即如何保证多个副本之间的一致性？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;这里我们只讨论强一致性，即线性一致性。弱一致性涵盖的范围较广，涉及根据实际场景进行诸多取舍，不在 Raft 系列的讨论目标范围内。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;所谓的强一致性（线性一致性）并不是指集群中所有节点在任一时刻的状态必须完全一致，而是指一个目标，即让一个分布式系统看起来只有一个数据副本，并且读写操作都是原子的，这样应用层就可以忽略系统底层多个数据副本间的同步问题。也就是说，我们可以将一个强一致性分布式系统当成一个整体，一旦某个客户端成功的执行了写操作，那么所有客户端都一定能读出刚刚写入的值。即使发生网络分区故障，或者少部分节点发生异常，整个集群依然能够像单机一样提供服务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;共识算法（Consensus Algorithm）就是用来做这个事情的，它保证即使在小部分（≤ (N-1)/2）节点故障的情况下，系统仍然能正常对外提供服务。共识算法通常基于状态复制机（Replicated State Machine）模型，也就是所有节点从同一个 state 出发，经过同样的操作 log，最终达到一致的 state。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.6139288417865254&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6rxOmdqsWFX4xjLOnOqvByPcnSpqicVPNjmOW0icVDAOTvZ8QklZ5j8GicYK1iawOu0zickAu1vxCmqicVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1321&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：Replicated State Machine&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;共识算法是构建强一致性分布式系统的基石，Paxos 是共识算法的代表，而 Raft 则是其作者在博士期间研究 Paxos 时提出的一个变种，主要优点是容易理解、易于实现，甚至关键的部分都在论文中给出了伪代码实现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.2 谁在使用 Raft&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;采用 Raft 的系统最著名的当属 etcd 了，可以认为 etcd 的核心就是 Raft 算法的实现。作为一个分布式 kv 系统，etcd 使用 Raft 在多节点间进行数据同步，每个节点都拥有全量的状态机数据。我们在学习了 Raft 以后将会深刻理解为什么 etcd 不适合大数据量的存储（for the most critical data）、为什么集群节点数不是越多越好、为什么集群适合部署奇数个节点等问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;作为一个微服务基础设施，consul 底层使用 Raft 来保证 consul server 之间的数据一致性。在阅读完第六章后，我们会理解为什么 consul 提供了 default、consistent、stale 三种一致性模式（Consistency Modes）、它们各自适用的场景，以及 consul 底层是如何通过改变 Raft 读模型来支撑这些不同的一致性模式的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;TiKV 同样在底层使用了 Raft 算法。虽然都自称是“分布式 kv 存储”，但 TiKV 的使用场景与 etcd 存在区别。其目标是支持 100TB+ 的数据，类似 etcd 的单 Raft 集群肯定无法支撑这个数据量。因此 TiKV 底层使用 Multi Raft，将数据划分为多个 region，每个 region 其实还是一个标准的 Raft 集群，对每个分区的数据实现了多副本高可用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前 Raft 在工业界已经开始大放异彩，对于其各类应用场景这里不再赘述，感兴趣的读者可以参考 https://raft.github.io/，下方有列出各种语言的大量 Raft 实现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.3 Raft 基本概念&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Raft 使用 Quorum 机制来实现共识和容错，我们将对 Raft 集群的操作称为提案，每当发起一个提案，必须得到大多数（&amp;gt; N/2）节点的同意才能提交。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;这里的“提案”我们可以先狭义地理解为对集群的读写操作，“提交”理解为操作成功。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;那么当我们向 Raft 集群发起一系列读写操作时，集群内部究竟发生了什么呢？我们先来概览式地做一个整体了解，接下来再分章节详细介绍每个部分。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;首先，Raft 集群必须存在一个主节点（leader），我们作为客户端向集群发起的所有操作都必须经由主节点处理。所以 Raft 核心算法中的第一部分就是&lt;strong&gt;选主（Leader election）&lt;/strong&gt;——没有主节点集群就无法工作，先票选出一个主节点，再考虑其它事情。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其次，主节点需要承载什么工作呢？它会负责接收客户端发过来的操作请求，将操作包装为日志同步给其它节点，在保证大部分节点都同步了本次操作后，就可以安全地给客户端回应响应了。这一部分工作在 Raft 核心算法中叫&lt;strong&gt;日志复制（Log replication）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;然后，因为主节点的责任是如此之大，所以节点们在选主的时候一定要谨慎，只有符合条件的节点才可以当选主节点。此外主节点在处理操作日志的时候也一定要谨慎，为了保证集群对外展现的一致性，不可以&lt;strong&gt;覆盖或删除&lt;/strong&gt;前任主节点已经处理成功的操作日志。所谓的“谨慎处理”，其实就是在选主和提交日志的时候进行一些限制，这一部分在 Raft 核心算法中叫&lt;strong&gt;安全性（Safety）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Raft 核心算法其实就是由这三个子问题组成的：选主（Leader election）、日志复制（Log replication）、安全性（Safety）。这三部分共同实现了 Raft 核心的共识和容错机制。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;除了核心算法外，Raft 也提供了几个工程实践中必须面对问题的解决方案。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第一个是关于日志无限增长的问题。Raft 将操作包装成为了日志，集群每个节点都维护了一个不断增长的日志序列，状态机只有通过重放日志序列来得到。但由于这个日志序列可能会随着时间流逝不断增长，因此我们必须有一些办法来避免无休止的磁盘占用和过久的日志重放。这一部分叫&lt;strong&gt;日志压缩（Log compaction）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第二个是关于集群成员变更的问题。一个 Raft 集群不太可能永远是固定几个节点，总有扩缩容的需求，或是节点宕机需要替换的时候。直接更换集群成员可能会导致严重的&lt;strong&gt;脑裂&lt;/strong&gt;问题。Raft 给出了一种安全变更集群成员的方式。这一部分叫&lt;strong&gt;集群成员变更（Cluster membership change）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此外，我们还会额外讨论&lt;strong&gt;线性一致性&lt;/strong&gt;的定义、为什么 &lt;strong&gt;Raft 不能与线性一致划等号&lt;/strong&gt;、&lt;strong&gt;如何基于 Raft 实现线性一致&lt;/strong&gt;，以及在如何&lt;strong&gt;保证线性一致的前提下进行读性能优化&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上便是理论篇内将会讨论到的大部分内容的概要介绍，这里我们对 Raft 已经有了一个宏观上的认识，知道了各个部分大概是什么内容，以及它们之间的关系。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来我们将会详细讨论 Raft 算法的每个部分。让我们先从第一部分&lt;strong&gt;选主&lt;/strong&gt;开始。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. 选主&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.1 什么是选主&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;选主（Leader election）就是在分布式系统内抉择出一个主节点来负责一些特定的工作。在执行了选主过程后，集群中每个节点都会识别出一个特定的、唯一的节点作为 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们开发的系统如果遇到选主的需求，通常会直接基于 zookeeper 或 etcd 来做，把这部分的复杂性收敛到第三方系统。然而作为 etcd 基础的 Raft 自身也存在“选主”的概念，这是两个层面的事情：基于 etcd 的选主指的是利用第三方 etcd 让集群对谁做主节点的决策达成一致，技术上来说利用的是 etcd 的一致性状态机、lease 以及 watch 机制，这个事情也可以改用单节点的 MySQL/Redis 来做，只是无法获得高可用性；而 Raft 本身的选主则指的是在 Raft 集群自身内部通过票选、心跳等机制来协调出一个大多数节点认可的主节点作为集群的 leader 去协调所有决策。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;当你的系统利用 etcd 来写入谁是主节点的时候，这个决策也在 etcd 内部被它自己集群选出的主节点处理并同步给其它节点。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.2 Raft 为什么要进行选主？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;按照论文所述，原生的 Paxos 算法使用了一种点对点（peer-to-peer）的方式，所有节点地位是平等的。在理想情况下，算法的目的是制定&lt;strong&gt;一个决策&lt;/strong&gt;，这对于简化的模型比较有意义。但在工业界很少会有系统会使用这种方式，当有一系列的决策需要被制定的时候，先选出一个 leader 节点然后让它去协调所有的决策，这样算法会更加简单快速。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此外，和其它一致性算法相比，Raft 赋予了 leader 节点更强的领导力，称之为 &lt;strong&gt;Strong Leader&lt;/strong&gt;。比如说日志条目只能从 leader 节点发送给其它节点而不能反着来，这种方式简化了日志复制的逻辑，使 Raft 变得更加简单易懂。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.3 Raft 选主过程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.3.1 节点角色&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raft 集群中每个节点都处于以下三种角色之一：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Leader&lt;/strong&gt;: 所有请求的处理者，接收客户端发起的操作请求，写入本地日志后同步至集群其它节点。 &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Follower&lt;/strong&gt;: 请求的被动更新者，从 leader 接收更新请求，写入本地文件。如果客户端的操作请求发送给了 follower，会首先由 follower 重定向给 leader。 &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Candidate&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;: 如果 follower 在一定时间内没有收到 leader 的心跳，则判断 leader 可能已经故障，此时启动 leader election 过程，本节点切换为 candidate 直到选主结束。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.3.2 任期&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;每开始一次新的选举，称为一个&lt;strong&gt;任期（term）&lt;/strong&gt;，每个 term 都有一个严格递增的整数与之关联。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;每当 candidate 触发 leader election 时都会增加 term，如果一个 candidate 赢得选举，他将在本 term 中担任 leader 的角色。但并不是每个 term 都一定对应一个 leader，有时候某个 term 内会由于选举超时导致选不出 leader，这时 candicate 会递增 term 号并开始新一轮选举。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.40350877192982454&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6rxOmdqsWFX4xjLOnOqvByPYKbo5lQ6GVGWdxA6VYrbO4DZTlZUZZbRIl8gnp9a1iaQmibc6Y0CSKBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1824&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Term 更像是一个&lt;strong&gt;逻辑时钟（logic clock）&lt;/strong&gt;的作用，有了它，就可以发现哪些节点的状态已经过期。每一个节点都保存一个 current term，在通信时带上这个 term 号。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;节点间通过 RPC 来通信，主要有两类 RPC 请求：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.3.3 节点状态转换&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们知道集群每个节点的状态都只能是 leader、follower 或 candidate，那么节点什么时候会处于哪种状态呢？下图展示了一个节点可能发生的状态转换：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.4429868819374369&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6rxOmdqsWFX4xjLOnOqvByP8WLyTK7wohqV434Gb7bx0k24GSn4m26ATu6NPWJ8ZhOzXPkicythfww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1982&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来我们详细讨论下每个转换所发生的场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.3.3.1 Follower 状态转换过程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raft 的选主基于一种心跳机制，集群中每个节点刚启动时都是 follower 身份（&lt;strong&gt;Step: starts up&lt;/strong&gt;），leader 会周期性的向所有节点发送心跳包来维持自己的权威，那么首个 leader 是如何被选举出来的呢？方法是如果一个 follower 在一段时间内没有收到任何心跳，也就是选举超时，那么它就会主观认为系统中没有可用的 leader，并发起新的选举（&lt;strong&gt;Step: times out, starts election&lt;/strong&gt;）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里有一个问题，即这个“选举超时时间”该如何制定？如果所有节点在同一时刻启动，经过同样的超时时间后同时发起选举，整个集群会变得低效不堪，极端情况下甚至会一直选不出一个主节点。Raft 巧妙的使用了一个随机化的定时器，让每个节点的“超时时间”在一定范围内随机生成，这样就大大的降低了多个节点同时发起选举的可能性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9453883495145631&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IibQudy5jM3BSsoCVdBmAuBF5GicxWzoHDIm7rPDNgk7pgKhNBrPmkohQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：一个五节点 Raft 集群的初始状态，所有节点都是 follower 身份，term 为 1，且每个节点的选举超时定时器不同&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;若 follower 想发起一次选举，follower 需要先增加自己的当前 term，并将身份切换为 candidate。然后它会向集群其它节点发送“请给自己投票”的消息（RequestVote RPC）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9493365500603136&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IZ5wBibSsQqrmnQNRctqJ7JYq4iazvKkyz7fkib443cpGTQqG2oxcsZWng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;829&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S1 率先超时，变为 candidate，term + 1，并向其它节点发出拉票请求&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.3.3.2 Candicate 状态转换过程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Follower 切换为 candidate 并向集群其他节点发送“请给自己投票”的消息后，接下来会有三种可能的结果，也即上面&lt;strong&gt;节点状态图中 candidate 状态向外伸出的三条线&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 选举成功（Step: receives votes from majority of servers）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当candicate从整个集群的&lt;strong&gt;大多数&lt;/strong&gt;（N/2+1）节点获得了针对同一 term 的选票时，它就赢得了这次选举，立刻将自己的身份转变为 leader 并开始向其它节点发送心跳来维持自己的权威。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9538834951456311&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IicoZwfdqrciaaDqQnQ88Hd9lyJkuiaRBypgD50rlXd6fHN7ibCG51rjQYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：“大部分”节点都给了 S1 选票&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9503030303030303&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36I07e2icJdKHTxHxKeXx9prMgKehj9DsRSFnDupl3UKEeIHdVtiaq1TgZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S1 变为 leader，开始发送心跳维持权威&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;每个节点针对每个 term 只能投出一张票，并且按照先到先得的原则。这个规则确保只有一个 candidate 会成为 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 选举失败（Step: discovers current leader or new term）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Candidate 在等待投票回复的时候，可能会突然收到其它自称是 leader 的节点发送的心跳包，如果这个心跳包里携带的 term &lt;strong&gt;不小于&lt;/strong&gt; candidate 当前的 term，那么 candidate 会承认这个 leader，并将身份切回 follower。这说明其它节点已经成功赢得了选举，我们只需立刻跟随即可。但如果心跳包中的 term 比自己小，candidate 会拒绝这次请求并保持选举状态。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9423769507803121&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IFe5HlnlBicWBbZMWqNlZqjwhBbfEld9dsh6ibBrCKWV6ZUT0g5dVFxBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S4、S2 依次开始选举&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9466019417475728&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IbaVAOgRjSvib9QGJw8KqBecDV0NnTdGgwia88cvHKqAvcadf5lbTRlPQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S4 成为 leader，S2 在收到 S4 的心跳包后，由于 term 不小于自己当前的 term，因此会立刻切为 follower 跟随 S4&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 选举超时（Step: times out, new election）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第三种可能的结果是 candidate 既没有赢也没有输。如果有多个 follower 同时成为 candidate，选票是可能被瓜分的，如果没有任何一个 candidate 能得到大多数节点的支持，那么每一个 candidate 都会超时。此时 candidate 需要增加自己的 term，然后发起新一轮选举。如果这里不做一些特殊处理，选票可能会一直被瓜分，导致选不出 leader 来。这里的“特殊处理”指的就是前文所述的&lt;strong&gt;随机化选举超时时间&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9498164014687882&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IqrGEBica93t0aq0s1SR3BWU8Tx8RLYW6g5DfZ6priaibxxSk1ib3uBuj9A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;817&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S1 ~ S5 都在参与选举&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9503030303030303&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IDWx8pyu0Oickqc3v8CnkV55pKovmUGd9kYrPw1aRRWG9PTMOspJ7r6w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：没有任何节点愿意给他人投票&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9444444444444444&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36I8LZ2W7GSZslzK0XW5M3sIAJLRg7lGJxPSicO7Lv5QCAMUvJTc2AZkHg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;828&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：如果没有随机化超时时间，所有节点将会继续同时发起选举……&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上便是 candidate 三种可能的选举结果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.3.3.3 Leader 状态转换过程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;节点状态图中的最后一条线是：&lt;strong&gt;discovers server with higher term&lt;/strong&gt;。想象一个场景：当 leader 节点发生了宕机或网络断连，此时其它 follower 会收不到 leader 心跳，首个触发超时的节点会变为 candidate 并开始拉票（由于随机化各个 follower 超时时间不同），由于该 candidate 的 term 大于原 leader 的 term，因此所有 follower 都会投票给它，这名 candidate 会变为新的 leader。一段时间后原 leader 恢复了，收到了来自新leader 的心跳包，发现心跳中的 term 大于自己的 term，此时该节点会立刻切换为 follower 并跟随的新 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上述流程的动画模拟如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9514563106796117&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IS8uluhyInDbaH7fMV3gxfINQX9aXiaiagw2q9pYCM2b0YSbGcknnHo8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S4 作为 term2 的 leader&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9418181818181818&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IAL1iasZypk4ia200LC86GLKYyY9Mm2N6TlBczEe4XdnWC6aibicy5gQfHg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图：S4 宕机，S5 即将率先超时&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9406060606060606&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IdpiajFEyIdfSFDejic9kznSH2DDH5XmyKPduPt59kv1v5m2Dickia7XNIg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S5 当选 term3 的 leader&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9387019230769231&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36Ig7mGNMj5cFic2Q7XvubZPibnHh1iaUpQPLSNoXoX81RtSjQbwTTuT3aXg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;832&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S4 宕机恢复后收到了来自 S5 的 term3 心跳&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.935251798561151&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IddsvkChAaN32ib3ibib6XP3eTBwGZSs97LM1U1z0picxJ8nwjoFBxP7Wog/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;834&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S4 立刻变为 S5 的 follower&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上就是 Raft 的选主逻辑，但还有一些细节（譬如是否给该 candidate 投票还有一些其它条件）依赖算法的其它部分基础，我们会在后续“安全性”一章描述。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当票选出 leader 后，leader 也该承担起相应的责任了，这个责任是什么？就是下一章将介绍的“日志复制”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3. 日志复制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.1 什么是日志复制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在前文中我们讲过：共识算法通常基于&lt;strong&gt;状态复制机（Replicated State Machine）&lt;/strong&gt;模型，所有节点从&lt;strong&gt;同一个 state&lt;/strong&gt; 出发，经过一系列&lt;strong&gt;同样操作 log&lt;/strong&gt; 的步骤，最终也必将达到&lt;strong&gt;一致的 state&lt;/strong&gt;。也就是说，只要我们保证集群中所有节点的 log 一致，那么经过一系列应用（apply）后最终得到的状态机也就是一致的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raft 负责保证集群中所有节点 &lt;strong&gt;log 的一致性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外我们还提到过：Raft 赋予了 leader 节点更强的领导力（&lt;strong&gt;Strong Leader&lt;/strong&gt;）。那么 Raft 保证 log 一致的方式就很容易理解了，即所有 log 都必须交给 leader 节点处理，并由 leader 节点复制给其它节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个过程，就叫做&lt;strong&gt;日志复制（Log replication）&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.2 Raft 日志复制机制解析&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.2.1 整体流程解析&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;一旦 leader 被票选出来，它就承担起领导整个集群的责任了，开始接收客户端请求，并将操作包装成日志，并复制到其它节点上去。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;整体流程如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Leader 为客户端提供服务，客户端的每个请求都包含一条即将被状态复制机执行的指令。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Leader 把该指令作为一条新的日志附加到自身的日志集合，然后向其它节点发起&lt;strong&gt;附加条目请求（AppendEntries RPC）&lt;/strong&gt;，来要求它们将这条日志附加到各自本地的日志集合。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当这条日志已经确保被&lt;strong&gt;安全的复制&lt;/strong&gt;，即大多数（N/2+1）节点都已经复制后，leader 会将该日志 &lt;strong&gt;apply&lt;/strong&gt; 到它本地的状态机中，然后把操作成功的结果返回给客户端。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;整个集群的日志模型可以宏观表示为下图（x ← 3 代表 x 赋值为 3）：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.7560283687943262&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17Jl4utBzmsa1XUIa0h9lwXkibms0XWfibNcpzrZ9EDgUHHib8kVI5P37mw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1410&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;每条日志除了存储状态机的操作指令外，还会拥有一个&lt;strong&gt;唯一的整数索引值（log index）&lt;/strong&gt;来表明它在日志集合中的位置。此外，每条日志还会存储一个 &lt;strong&gt;term&lt;/strong&gt; 号（日志条目方块最上方的数字，相同颜色 term 号相同），该 term 表示 leader 收到这条指令时的当前任期，term 相同的 log 是由同一个 leader 在其任期内发送的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当一条日志被 leader 节点认为可以安全的 apply 到状态机时，称这条日志是 &lt;strong&gt;committed&lt;/strong&gt;（上图中的 &lt;strong&gt;committed entries&lt;/strong&gt;）。那么什么样的日志可以被 commit 呢？答案是：&lt;strong&gt;当 leader 得知这条日志被集群过半的节点复制成功时&lt;/strong&gt;。因此在上图中我们可以看到 (term3, index7) 这条日志以及之前的日志都是 committed，尽管有两个节点拥有的日志并不完整。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raft 保证所有 committed 日志都已经被&lt;strong&gt;持久化&lt;/strong&gt;，且“&lt;strong&gt;最终&lt;/strong&gt;”一定会被状态机apply。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;注：这里的“最终”用词很微妙，它表明了一个特点：Raft 保证的只是集群内日志的一致性，而我们真正期望的集群对外的状态机一致性需要我们做一些额外工作，这一点在《线性一致性与读性能优化》一章会着重介绍。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;3.2.2 日志复制流程图解&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们通过 Raft 动画来模拟常规日志复制这一过程：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5317460317460317&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17iaVIy9WiaGOQqcwc34YIARSREnF1rIc4boJic1tfic2b9Evcag4zZZZvTw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1512&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;如上图，S1 当选 leader，此时还没有任何日志。我们模拟客户端向 S1 发起一个请求。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5253333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17a7A9ad4okMRRzZpD1Dy7nlJRox4m2mlibBpS3PU2J4mEx4njYXvpwFw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1500&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;S1 收到客户端请求后新增了一条日志 (term2, index1)，然后并行地向其它节点发起 AppendEntries RPC。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5266666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17bndJsTOj2C5gDDwcKTYaaa7EiarMic1w2lhbZ2hOmUpSz0t6c1XZyI1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1500&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;S2、S4 率先收到了请求，各自附加了该日志，并向 S1 回应响应。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.523936170212766&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17AkE76iauFHz9eBJlNQiczkVnmU3Dpk4w8pd8XFC5pL5XafQQrDx8IUjg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1504&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所有节点都附加了该日志，但由于 leader 尚未收到任何响应，因此暂时还不清楚该日志到底是否被成功复制。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.521970705725699&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17ico1kLywianZrG4a22Nup6lWQzEZDAfWjV5C84zULAD3iayBfLTqMCZiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1502&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 S1 收到&lt;strong&gt;2个节点&lt;/strong&gt;的响应时，该日志条目的边框就已经变为实线，表示该日志已经&lt;strong&gt;安全的复制&lt;/strong&gt;，因为在5节点集群中，2个 follower 节点加上 leader 节点自身，副本数已经确保过半，此时 &lt;strong&gt;S1 将响应客户端的请求&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5206391478029294&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17G64Ev75FZafF5YasPYI68Yvy2fOOZJbd1ibAuEayJGQaZxfkiazBCNicQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1502&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;leader 后续会持续发送心跳包给 followers，心跳包中会携带当前&lt;strong&gt;已经安全复制（我们称之为 committed）的日志索引&lt;/strong&gt;，此处为 (term2, index1)。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5202388852023888&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17I3wiaoTMKupYyJQZVxGpiceMPYu6DPamprcHQMm65jETq7kLjPxNReuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1507&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所有 follower 都通过心跳包得知 (term2, index1) 的 log 已经成功复制 （committed），因此所有节点中该日志条目的边框均变为实线。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.2.3 对日志一致性的保证&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;前边我们使用了 (term2, index1) 这种方式来表示一条日志条目，这里为什么要带上 term，而不仅仅是使用 index？原因是 term 可以用来检查不同节点间日志是否存在不一致的情况，阅读下一节后会更容易理解这句话。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raft 保证：&lt;strong&gt;如果不同的节点日志集合中的两个日志条目拥有相同的 term 和 index，那么它们一定存储了相同的指令&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为什么可以作出这种保证？因为 Raft 要求 leader 在一个 term 内针对同一个 index 只能创建一条日志，并且永远不会修改它。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同时 Raft 也保证：&lt;strong&gt;如果不同的节点日志集合中的两个日志条目拥有相同的 term 和 index，那么它们之前的所有日志条目也全部相同&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这是因为 leader 发出的 AppendEntries RPC 中会额外携带&lt;strong&gt;上一条&lt;/strong&gt;日志的 (term, index)，如果 follower 在本地找不到相同的 (term, index) 日志，则&lt;strong&gt;拒绝接收这次新的日志&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以，只要 follower 持续正常地接收来自 leader 的日志，那么就可以通过归纳法验证上述结论。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.2.4 可能出现的日志不一致场景&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在所有节点正常工作的时候，leader 和 follower的日志总是保持一致，AppendEntries RPC 也永远不会失败。然而我们总要面对任意节点随时可能宕机的风险，如何在这种情况下继续保持集群日志的一致性才是我们真正要解决的问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.6763848396501457&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6qAPI6WrC0YUAjNfyQ0CjuDbPnDO9kSV3pgFlE23IT4BPFDbqhWVVFqPcwsQJmMWQeU2cNeyJhYMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1372&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上图展示了一个 term8 的 leader 刚上任时，集群中日志可能存在的混乱情况。例如 follower 可能缺少一些日志（a ~ b），可能多了一些未提交的日志（c ~ d），也可能既缺少日志又多了一些未提交日志（e ~ f）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;注：Follower 不可能比 leader 多出一些已提交（committed）日志，这一点是通过选举上的限制来达成的，会在下一章《安全性》介绍。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们先来尝试复现上述 a ~ f 场景，最后再讲 Raft 如何解决这种不一致问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;场景a~b. Follower 日志落后于 leader&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种场景其实很简单，即 &lt;strong&gt;follower 宕机了一段时间&lt;/strong&gt;，follower-a 从收到 (term6, index9) 后开始宕机，follower-b 从收到 (term4, index4) 后开始宕机。这里不再赘述。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;场景c. Follower 日志比 leader 多 term6&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 term6 的 leader 正在将 (term6, index11) 向 follower 同步时，该 leader 发生了宕机，且此时只有 follower-c 收到了这条日志的 AppendEntries RPC。然后经过一系列的选举，term7 可能是选举超时，也可能是 leader 刚上任就宕机了，最终 term8 的 leader 上任了，成就了我们看到的场景 c。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;场景d. Follower 日志比 leader 多 term7&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 term6 的 leader 将 (term6, index10) 成功 commit 后，发生了宕机。此时 term7 的 leader 走马上任，连续同步了两条日志给 follower，然而还没来得及 commit 就宕机了，随后集群选出了 term8 的 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;场景e. Follower 日志比 leader 少 term5 ~ 6，多 term4&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 term4 的 leader 将 (term4, index7) 同步给 follower，且将 (term4, index5) 及之前的日志成功 commit 后，发生了宕机，紧接着 follower-e 也发生了宕机。这样在 term5~7 内发生的日志同步全都被 follower-e 错过了。当 follower-e 恢复后，term8 的 leader 也刚好上任了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;场景f. Follower 日志比 leader 少 term4 ~ 6，多 term2 ~ 3&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 term2 的 leader 同步了一些日志（index4 ~ 6）给 follower 后，尚未来得及 commit 时发生了宕机，但它很快恢复过来了，又被选为了 term3 的 leader，它继续同步了一些日志（index7~11）给 follower，但同样未来得及 commit 就又发生了宕机，紧接着 follower-f 也发生了宕机，当 follower-f 醒来时，集群已经前进到 term8 了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.2.5 如何处理日志不一致&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过上述场景我们可以看到，真实世界的集群情况很复杂，那么 Raft 是如何应对这么多不一致场景的呢？其实方式很简单暴力，想想 &lt;strong&gt;Strong Leader&lt;/strong&gt; 这个词。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Raft 强制要求 follower 必须复制 leader 的日志集合来解决不一致问题。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;也就是说，follower 节点上任何与 leader 不一致的日志，都会被 leader 节点上的日志所覆盖。这并不会产生什么问题，因为某些选举上的限制，如果 follower 上的日志与 leader 不一致，那么该日志在 follower 上&lt;strong&gt;一定是未提交的&lt;/strong&gt;。未提交的日志并不会应用到状态机，也不会被外部的客户端感知到。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;要使得 follower 的日志集合跟自己保持完全一致，leader 必须先找到二者间&lt;strong&gt;最后一次&lt;/strong&gt;达成一致的地方。因为一旦这条日志达成一致，在这之前的日志一定也都一致（回忆下前文）。这个确认操作是在 AppendEntries RPC 的一致性检查步骤完成的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Leader 针对每个 follower 都维护一个 &lt;strong&gt;next index&lt;/strong&gt;，表示下一条需要发送给该follower 的日志索引。当一个 leader 刚刚上任时，它初始化所有 next index 值为自己最后一条日志的 index+1。但凡某个 follower 的日志跟 leader 不一致，那么下次 AppendEntries RPC 的一致性检查就会失败。在被 follower 拒绝这次 Append Entries RPC 后，leader 会减少 next index 的值并进行重试。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最终一定会存在一个 next index 使得 leader 和 follower 在这之前的日志都保持一致。极端情况下 next index 为1，表示 follower 没有任何日志与 leader 一致，leader 必须从第一条日志开始同步。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;针对每个 follower，一旦确定了 next index 的值，leader 便开始从该 index 同步日志，follower 会删除掉现存的不一致的日志，保留 leader 最新同步过来的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;整个集群的日志会在这个简单的机制下自动趋于一致。此外要注意，&lt;strong&gt;leader 从来不会覆盖或者删除自己的日志&lt;/strong&gt;，而是强制 follower 与它保持一致。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这就要求集群票选出的 leader 一定要具备“日志的正确性”，这也就关联到了前文提到的：选举上的限制。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;下一章我们将对此详细讨论。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4. 安全性及正确性&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;前面的章节我们讲述了 Raft 算法是如何选主和复制日志的，然而到目前为止我们描述的&lt;strong&gt;这套机制还不能保证每个节点的状态机会严格按照相同的顺序 apply 日志&lt;/strong&gt;。想象以下场景：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Leader 将一些日志复制到了大多数节点上，进行 commit 后发生了宕机。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;某个 follower 并没有被复制到这些日志，但它参与选举并当选了下一任 leader。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新的 leader 又同步并 commit 了一些日志，这些日志覆盖掉了其它节点上的上一任 committed 日志。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;各个节点的状态机可能 apply 了不同的日志序列，出现了不一致的情况。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此我们需要对“选主+日志复制”这套机制加上一些额外的限制，来保证&lt;strong&gt;状态机的安全性&lt;/strong&gt;，也就是 Raft 算法的正确性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4.1 对选举的限制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们再来分析下前文所述的 committed 日志被覆盖的场景，根本问题其实发生在第2步。Candidate 必须有足够的资格才能当选集群 leader，否则它就会给集群带来不可预料的错误。Candidate 是否具备这个资格可以在选举时添加一个小小的条件来判断，即：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;每个 candidate 必须在 RequestVote RPC 中携带自己本地日志的最新 (term, index)，如果 follower 发现这个 candidate 的日志还没有自己的新，则拒绝投票给该 candidate。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Candidate 想要赢得选举成为 leader，必须得到集群大多数节点的投票，那么&lt;strong&gt;它的日志就一定至少不落后于大多数节点&lt;/strong&gt;。又因为一条日志只有复制到了大多数节点才能被 commit，因此&lt;strong&gt;能赢得选举的 candidate 一定拥有所有 committed 日志&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此前一篇文章我们才会断定地说：Follower 不可能比 leader 多出一些 committed 日志。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;比较两个 (term, index) 的逻辑非常简单：如果 term 不同 term 更大的日志更新，否则 index 大的日志更新。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4.2 对提交的限制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;除了对选举增加一点限制外，我们还需对 commit 行为增加一点限制，来完成我们 Raft 算法核心部分的最后一块拼图。&lt;/p&gt;&lt;p&gt;回忆下什么是 commit：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;当 leader 得知某条日志被集群过半的节点复制成功时，就可以进行 commit，committed 日志一定最终会被状态机 apply。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所谓 commit 其实就是对日志简单进行一个标记，表明其可以被 apply 到状态机，并针对相应的客户端请求进行响应。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;然而 leader 并不能在任何时候都随意 commit 旧任期留下的日志，即使它已经被复制到了大多数节点。Raft 论文给出了一个经典场景：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.4641269841269841&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6ojLgVaS2nEfNX5CEmHIym1KPOOaOaaPA6NIoicMfOJGG2GdkE6TqJXWG9iaEY1D16vuPjMRBpxPjTg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1575&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上图从左到右按时间顺序模拟了问题场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段a&lt;/strong&gt;：S1 是 leader，收到请求后将 (term2, index2) 只复制给了 S2，尚未复制给 S3 ~ S5。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段b&lt;/strong&gt;：S1 宕机，S5 当选 term3 的 leader（S3、S4、S5 三票），收到请求后保存了 (term3, index2)，尚未复制给任何节点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段c&lt;/strong&gt;：S5 宕机，S1 恢复，S1 重新当选 term4 的 leader，继续将 (term2, index2) 复制给了 S3，已经满足大多数节点，我们将其 commit。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段d&lt;/strong&gt;：S1 又宕机，S5 恢复，S5 重新当选 leader（S2、S3、S4 三票），将 (term3, inde2) 复制给了所有节点并 commit。注意，此时发生了致命错误，已经 committed 的 (term2, index2) 被 (term3, index2) 覆盖了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了避免这种错误，我们需要添加一个额外的限制：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Leader 只允许 commit 包含当前 term 的日志。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;针对上述场景，问题发生在阶段c，即使作为 term4 leader 的 S1 将 (term2, index2) 复制给了大多数节点，它也不能直接将其 commit，而是必须等待 term4 的日志到来并成功复制后，一并进行 commit。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段e&lt;/strong&gt;：在添加了这个限制后，要么 (term2, index2) 始终没有被 commit，这样 S5 在阶段d将其覆盖就是安全的；要么 (term2, index2) 同 (term4, index3) 一起被 commit，这样 S5 根本就无法当选 leader，因为大多数节点的日志都比它新，也就不存在前边的问题了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上便是对算法增加的两个小限制，它们对确保状态机的安全性起到了至关重要的作用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;至此我们对 Raft 算法的核心部分，已经介绍完毕。下一章我们会介绍两个同样描述于论文内的辅助技术：集群成员变更和日志压缩，它们都是在 Raft 工程实践中必不可少的部分。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;5. 集群成员变更与日志压缩&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;尽管我们已经通过前几章了解了 Raft 算法的核心部分，但相较于算法理论来说，在工程实践中仍有一些现实问题需要我们去面对。Raft 非常贴心的在论文中给出了两个常见问题的解决方案，它们分别是：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;集群成员变更&lt;/strong&gt;：如何安全地改变集群的节点成员。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;日志压缩&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：如何解决日志集合无限制增长带来的问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;本文我们将分别讲解这两种技术。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2 data-id=&quot;heading-26&quot;&gt;&lt;strong&gt;&lt;span&gt;5.1 集群成员变更&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在前文的理论描述中我们都假设了集群成员是不变的，然而在实践中有时会需要替换宕机机器或者改变复制级别（即增减节点）。一种最简单暴力达成目的的方式就是：停止集群、改变成员、启动集群。这种方式在执行时会导致集群整体不可用，此外还存在手工操作带来的风险。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了避免这样的问题，Raft 论文中给出了一种无需停机的、自动化的改变集群成员的方式，其实本质上还是利用了 Raft 的核心算法，将集群成员配置作为一个特殊日志从 leader 节点同步到其它节点去。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.1.1 直接切换集群成员配置&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;先说结论：&lt;strong&gt;所有将集群从旧配置直接完全切换到新配置的方案都是不安全的&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此我们不能想当然的将新配置直接作为日志同步给集群并 apply。因为我们不可能让集群中的全部节点在“&lt;strong&gt;同一时刻&lt;/strong&gt;”&lt;strong&gt;原子地&lt;/strong&gt;切换其集群成员配置，所以在切换期间不同的节点看到的集群视图可能存在不同，最终可能导致集群存在多个 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了理解上述结论，我们来看一个实际出现问题的场景，下图对其进行了展现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.34332425068119893&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6q0eyr7icJ0wbzhpZoWsZcE8eL3z8cz8ibTEk83PFjd0C2RePlowLnE457H6e6KjqdfwdPicwILR5Spw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1835&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图5-1&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段a&lt;/strong&gt;. 集群存在 S1 ~ S3 三个节点，我们将该成员配置表示为 C-old，绿色表示该节点当前视图（成员配置）为 C-old，其中红边的 S3 为 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段b&lt;/strong&gt;. 集群新增了 S4、S5 两个节点，该变更从 leader 写入，我们将 S1 ~ S5 的五节点新成员配置表示为 C-new，蓝色表示该节点当前视图为 C-new。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段c&lt;/strong&gt;. 假设 S3 短暂宕机触发了 S1 与 S5 的超时选主。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段d&lt;/strong&gt;. S1 向 S2、S3 拉票，S5 向其它全部四个节点拉票。由于 S2 的日志并没有比 S1 更新，因此 S2 可能会将选票投给 S1，S1 两票当选（因为 S1 认为集群只有三个节点）。而 S5 肯定会得到 S3、S4 的选票，因为 S1 感知不到 S4，没有向它发送 RequestVote RPC，并且 S1 的日志落后于 S3，S3 也一定不会投给 S1，结果 S5 三票当选。最终集群出现了多个主节点的致命错误，也就是所谓的脑裂。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.7048799380325329&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6q0eyr7icJ0wbzhpZoWsZcE8ibLCMiaRKKiaFMrDZibSWvqhCE8opGjZf5wClWF0xXuib2kicQEmFGibnyWJg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1291&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图5-2&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上图来自论文，用不同的形式展现了和图5-1相同的问题。颜色代表的含义与图5-1是一致的，在 &lt;strong&gt;problem: two disjoint majorities&lt;/strong&gt; 所指的时间点，集群可能会出现两个 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但是，多主问题并不是在任何新老节点同时选举时都一定可能出现的，社区一些文章在举多主的例子时可能存在错误，下面是一个案例（笔者学习 Raft 协议也从这篇文章中受益匪浅，应该是作者行文时忽略了。文章很赞，建议大家参考学习）：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5916955017301038&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/JfuVbKibIl6qkfsd3Z6Z3PRtzXfEMFJOukfQyWCGjz8YOM5xC06JFewssTFzkUBqMfshYhNma148NrLicf9RzibWQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1156&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图5-3 &lt;em&gt;来源：https://zhuanlan.zhihu.com/p/27207160&lt;/em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该假想场景类似图5-1的阶段d，模拟过程如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;S1 为集群原 leader，集群新增 S4、S5，该配置被推给了 S3，S2 尚未收到。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;此时 S1 发生短暂宕机，S2、S3 分别触发选主。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最终 S2 获得了 S1 和自己的选票，S3 获得了 S4、S5 和自己的选票，集群出现两个 leader。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;图5-3过程看起来好像和图5-1没有什么大的不同，只是参与选主的节点存在区别，然而事实是&lt;strong&gt;图5-3的情况是不可能出现的&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;注意：Raft 论文中传递集群变更信息也是通过日志追加实现的，所以也受到选主的限制。很多读者对选主限制中比较的日志是否必须是 committed 产生疑惑，回看下在《安全性》一文中的描述：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;每个 candidate 必须在 RequestVote RPC 中携带自己本地日志的最新 (term, index)，如果 follower 发现这个 candidate 的日志还没有自己的新，则拒绝投票给该 candidate。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里再帮大家明确下，论文里确实间接表明了，&lt;strong&gt;选主时比较的日志是不要求 committed 的，只需比较本地的最新日志就行&lt;/strong&gt;！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;回到图5-3，不可能出现的原因在于，S1 作为原 leader 已经第一个保存了新配置的日志，而 S2 尚未被同步这条日志，根据上一章《安全性》我们讲到的&lt;strong&gt;选主限制&lt;/strong&gt;，&lt;strong&gt;S1 不可能将选票投给 S2&lt;/strong&gt;，因此 S2 不可能成为 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;5.1.2 两阶段切换集群成员配置&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raft 使用一种两阶段方法平滑切换集群成员配置来避免遇到前一节描述的问题，具体流程如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段一&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;客户端将 C-new 发送给 leader，leader 将 C-old 与 C-new 取&lt;strong&gt;并集&lt;/strong&gt;并立即 apply，我们表示为 &lt;strong&gt;C-old,new&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Leader 将 C-old,new 包装为日志同步给其它节点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Follower 收到 C-old,new 后立即 apply，当 **C-old,new 的大多数节点（即 C-old 的大多数节点和 C-new 的大多数节点）**都切换后，leader 将该日志 commit。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段二&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Leader 接着将 C-new 包装为日志同步给其它节点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Follower 收到 C-new 后立即 apply，如果此时发现自己不在 C-new 列表，则主动退出集群。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Leader 确认 &lt;strong&gt;C-new 的大多数节点&lt;/strong&gt;都切换成功后，给客户端发送执行成功的响应。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5042125729099157&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6q0eyr7icJ0wbzhpZoWsZcE8V1icvK2N7ImVSjVqJEicaicJOsTe8ibmsk4NJudvicNMDd03ZriciayNBRMTQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1543&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上图展示了该流程的时间线。虚线表示已经创建但尚未 commit 的成员配置日志，实线表示 committed 的成员配置日志。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为什么该方案可以保证不会出现多个 leader？我们来按流程逐阶段分析。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段1. C-old,new 尚未 commit&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该阶段所有节点的配置要么是 C-old，要么是 C-old,new，但无论是二者哪种，只要原 leader 发生宕机，新 leader 都&lt;strong&gt;必须得到大多数 C-old 集合内节点的投票&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以图5-1场景为例，S5 在阶段d根本没有机会成为 leader，因为 C-old 中只有 S3 给它投票了，不满足大多数。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段2. C-old,new 已经 commit，C-new 尚未下发&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该阶段 C-old,new 已经 commit，可以确保已经被 C-old,new 的大多数节点（&lt;strong&gt;再次强调：C-old 的大多数节点和 C-new 的大多数节点&lt;/strong&gt;）复制。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此当 leader 宕机时，新选出的 leader 一定是已经拥有 C-old,new 的节点，不可能出现两个 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段3. C-new 已经下发但尚未 commit&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该阶段集群中可能有三种节点 C-old、C-old,new、C-new，但由于已经经历了阶段2，因此 C-old 节点不可能再成为 leader。而无论是 C-old,new 还是 C-new 节点发起选举，都需要经过大多数 C-new 节点的同意，因此也不可能出现两个 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段4. C-new 已经 commit&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该阶段 C-new 已经被 commit，因此只有 C-new 节点可以得到大多数选票成为 leader。此时集群已经安全地完成了这轮变更，可以继续开启下一轮变更了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上便是对该两阶段方法可行性的分步验证，Raft 论文将该方法称之为&lt;strong&gt;共同一致（Joint Consensus）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;关于集群成员变更另一篇更详细的论文还给出了其它方法，简单来说就是论证&lt;strong&gt;一次只变更一个节点的的正确性&lt;/strong&gt;，并给出解决可用性问题的优化方案。感兴趣的同学可以参考《Consensus: Bridging Theory and Practice》：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;Consensus: Bridging Theory and Practice&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://github.com/ongardie/dissertation&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;5.2 日志压缩&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们知道 Raft 核心算法维护了日志的一致性，通过 apply 日志我们也就得到了一致的状态机，客户端的操作命令会被包装成日志交给 Raft 处理。然而在实际系统中，客户端操作是连绵不断的，但日志却不能无限增长，首先它会占用很高的存储空间，其次每次系统重启时都需要完整回放一遍所有日志才能得到最新的状态机。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此 Raft 提供了一种机制去清除日志里积累的陈旧信息，叫做&lt;strong&gt;日志压缩&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;快照（Snapshot）&lt;/strong&gt;是一种常用的、简单的日志压缩方式，ZooKeeper、Chubby 等系统都在用。简单来说，就是将某一时刻系统的状态 dump 下来并落地存储，这样该时刻之前的所有日志就都可以丢弃了。所以大家对“压缩”一词不要产生错误理解，我们并没有办法将状态机快照“解压缩”回日志序列。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;注意，&lt;strong&gt;在 Raft 中我们只能为 committed 日志做 snapshot&lt;/strong&gt;，因为只有 committed 日志才是确保最终会应用到状态机的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.662777129521587&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6qkfsd3Z6Z3PRtzXfEMFJOue9Fdv8yyjUvrKUbBLI5ibnfpjgQB4ib6OHR1FicvECQmQ9Xy5HftIZOcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1714&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上图展示了一个节点用快照替换了 (term1, index1) ~ (term3, index5) 的日志。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;快照一般包含以下内容：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 leader 需要给某个 follower 同步一些旧日志，但这些日志已经被 leader 做了快照并删除掉了时，leader 就需要把该快照发送给 follower。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同样，当集群中有新节点加入，或者某个节点宕机太久落后了太多日志时，leader 也可以直接发送快照，大量节约日志传输和回放时间。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同步快照使用一个新的 RPC 方法，叫做 &lt;strong&gt;InstallSnapshot RPC&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;至此我们已经将 Raft 论文中的内容基本讲解完毕了。《In Search of an Understandable Consensus Algorithm (Extended Version)》 毕竟只有18页，更加侧重于理论描述而非工程实践。如果你想深入学习 Raft，或自己动手写一个靠谱的 Raft 实现，《Consensus: Bridging Theory and Practice》 是你参考的不二之选。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;In Search of an Understandable Consensus Algorithm (Extended Version)&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://raft.github.io/raft.pdf&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;Consensus: Bridging Theory and Practice&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://github.com/ongardie/dissertation&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来我们将额外讨论一下关于线性一致性和 Raft 读性能优化的内容。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6. 线性一致性与读性能优化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.1 什么是线性一致性？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在该系列首篇《基本概念》中我们提到过：在分布式系统中，为了消除单点提高系统可用性，通常会使用副本来进行容错，但这会带来另一个问题，即如何保证多个副本之间的&lt;strong&gt;一致性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;什么是一致性？所谓一致性有很多种模型，不同的模型都是用来评判一个并发系统正确与否的不同程度的标准。而我们今天要讨论的是&lt;strong&gt;强一致性（Strong Consistency）&lt;/strong&gt;模型，也就是&lt;strong&gt;线性一致性（Linearizability）&lt;/strong&gt;，我们经常听到的 CAP 理论中的 C 指的就是它。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其实我们在第一篇就已经简要描述过何为线性一致性：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;所谓的强一致性（线性一致性）并不是指集群中所有节点在任一时刻的状态必须完全一致，而是指一个目标，即让一个分布式系统看起来只有一个数据副本，并且读写操作都是原子的，这样应用层就可以忽略系统底层多个数据副本间的同步问题。也就是说，我们可以将一个强一致性分布式系统当成一个整体，一旦某个客户端成功的执行了写操作，那么所有客户端都一定能读出刚刚写入的值。即使发生网络分区故障，或者少部分节点发生异常，整个集群依然能够像单机一样提供服务。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“&lt;strong&gt;像单机一样提供服务&lt;/strong&gt;”从感官上描述了一个线性一致性系统应该具备的特性，那么我们该如何判断一个系统是否具备线性一致性呢？通俗来说就是不能读到旧（stale）数据，但具体分为两种情况：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;只要根据上述两条规则即可判断一个系统是否具备线性一致性。下面我们来看一个非线性一致性系统的例子。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.7196428571428571&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pUUFc3dfInRmvjJzEuuJE6fCyvPMHzgy9kFW1Vw4a4WKWqA80uCCjLyJjibFMrfREnEHc6HicfEENw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1120&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;本节例图均来自《Designing Data-Intensive Application》，作者 Martin Kleppmann&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如上图所示，裁判将世界杯的比赛结果写入了主库，Alice 和 Bob 所浏览的页面分别从两个不同的从库读取，但由于存在主从同步延迟，Follower 2 的本次同步延迟高于 Follower 1，最终导致 Bob 听到了 Alice 的惊呼后刷新页面看到的仍然是比赛进行中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;虽然线性一致性的基本思想很简单，只是要求&lt;strong&gt;分布式系统看起来只有一个数据副本&lt;/strong&gt;，但在实际中还是有很多需要关注的点，我们继续看几个例子。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.31261101243339257&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pUUFc3dfInRmvjJzEuuJE6ugz40Pdue0wfWibK6oEh101IjIosPLzDQHsNKib9iabtM6bAx2hKyWrpQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1126&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上图从客户端的&lt;strong&gt;外部视角&lt;/strong&gt;展示了多个用户同时请求读写一个系统的场景，每条柱形都是用户发起的一个请求，左端是请求发起的时刻，右端是收到响应的时刻。由于网络延迟和系统处理时间并不固定，所以柱形长度并不相同。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;x 最初的值为 0，Client C 在某个时间段将 x 写为 1。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Client A 第一个读操作位于 Client C 的写操作之前，因此必须读到原始值 0。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Client A 最后一个读操作位于 Client C 的写操作之后，如果系统是线性一致的，那么必须读到新值 1。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;其它与写操作重叠的所有读操作，既可能返回 0，也可能返回 1，因为我们并不清楚写操作在哪个时间段内哪个精确的点生效，这种情况下读写是并发的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;仅仅是这样的话，仍然不能说这个系统满足线性一致。假设 Client B 的第一次读取返回了 1，如果 Client A 的第二次读取返回了 0，那么这种场景并不破坏上述规则，但这个系统仍不满足线性一致，因为客户端在写操作执行期间看到 x 的值在新旧之间来回翻转，这并不符合我们期望的“看起来只有一个数据副本”的要求。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以我们需要额外添加一个约束，如下图所示。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.30905861456483125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pUUFc3dfInRmvjJzEuuJE6GmH2gCuIGCQoxPEG5DTll5bhDfFibStI3a7MCEkZTWlBQQbfHSNCfpw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1126&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在任何一个客户端的读取返回新值后，所有客户端的后续读取也必须返回新值，这样系统便满足线性一致了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们最后来看一个更复杂的例子，继续细化这个时序图。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.49644128113879005&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pUUFc3dfInRmvjJzEuuJE6ITUeicICQRqYdkW2ppNyHyz8uP9xaZROVHDIQ1qE9K6rLF1Sklv8D9Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1124&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如上图所示，每个读写操作在某个特定的时间点都是&lt;strong&gt;原子性的生效&lt;/strong&gt;，我们在柱形中用竖线标记出生效的时间点，将这些标记按时间顺序连接起来。那么线性一致的要求就是：&lt;strong&gt;连线总是按照时间顺序向右移动，而不会向左回退&lt;/strong&gt;。所以这个连线结果必定是一个&lt;strong&gt;有效的寄存器读写序列&lt;/strong&gt;：任何客户端的每次读取都必须返回该条目最近一次写入的值。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;线性一致性并非限定在分布式环境下，在单机单核系统中可以简单理解为“寄存器”的特性。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Client B 的最后一次读操作并不满足线性一致，因为在连线向右移动的前提下，它读到的值是错误的（因为Client A 已经读到了由 Client C 写入的 4）。此外这张图里还有一些值得指出的细节点，可以解开很多我们在使用线性一致系统时容易产生的误解：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上述现象在线性一致的语义下都是合理的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以&lt;strong&gt;线性一致性（Linearizability）&lt;/strong&gt;除了叫&lt;strong&gt;强一致性（Strong Consistency）&lt;/strong&gt;外，还叫做&lt;strong&gt;原子一致性（Atomic Consistency）&lt;/strong&gt;、&lt;strong&gt;立即一致性（Immediate Consistency）&lt;/strong&gt;或&lt;strong&gt;外部一致性（External Consistency）&lt;/strong&gt;，这些名字看起来都是比较贴切的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.2 Raft 线性一致性读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在了解了什么是线性一致性之后，我们将其与 Raft 结合来探讨。首先需要明确一个问题，使用了 Raft 的系统都是线性一致的吗？不是的，Raft 只是提供了一个基础，要实现整个系统的线性一致还需要做一些额外的工作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;假设我们期望基于 Raft 实现一个线性一致的分布式 kv 系统，让我们从最朴素的方案开始，指出每种方案存在的问题，最终使整个系统满足线性一致性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.2.1 写主读从缺陷分析&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;写操作并不是我们关注的重点，如果你稍微看了一些理论部分就应该知道，所有写操作都要作为提案从 leader 节点发起，当然所有的写命令都应该简单交给 leader 处理。真正关键的点在于&lt;strong&gt;读操作的处理方式，这涉及到整个系统关于一致性方面的取舍&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在该方案中我们假设读操作直接简单地向 follower 发起，那么由于 Raft 的 Quorum 机制（大部分节点成功即可），针对某个提案在某一时间段内，集群可能会有以下两种状态：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上每个场景客户端都可能读到&lt;strong&gt;过时的数据&lt;/strong&gt;，整个系统显然是不满足线性一致的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.2.2 写主读主缺陷分析&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在该方案中我们限定，所有的读操作也必须经由 leader 节点处理，读写都经过 leader 难道还不能满足线性一致？是的！！并且该方案存在不止一个问题！！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问题一：状态机落后于 committed log 导致脏读&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;回想一下前文讲过的，我们在解释什么是 commit 时提到了写操作什么时候可以响应客户端：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;所谓 commit 其实就是对日志简单进行一个标记，表明其可以被 apply 到状态机，并针对相应的客户端请求进行响应。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;也就是说一个提案只要被 leader commit 就可以响应客户端了，Raft 并没有限定提案结果在返回给客户端前必须先应用到状态机。所以从客户端视角当我们的某个写操作执行成功后，下一次读操作可能还是会读到旧值。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这个问题的解决方式很简单，在 leader 收到读命令时我们只需记录下当前的 commit index，当 apply index 追上该 commit index 时，即可将状态机中的内容响应给客户端。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问题二：网络分区导致脏读&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;假设集群发生网络分区，旧 leader 位于少数派分区中，而且此刻旧 leader 刚好还未发现自己已经失去了领导权，当多数派分区选出了新的 leader 并开始进行后续写操作时，连接到旧 leader 的客户端可能就会读到旧值了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此，仅仅是直接读 leader 状态机的话，系统仍然不满足线性一致性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.2.3 Raft Log Read&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了确保 leader 处理读操作时仍拥有领导权，我们可以将读请求同样作为一个提案走一遍 Raft 流程，当这次读请求对应的日志可以被应用到状态机时，leader 就可以读状态机并返回给用户了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种读方案称为 &lt;strong&gt;Raft Log Read&lt;/strong&gt;，也可以直观叫做 &lt;strong&gt;Read as Proposal&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为什么这种方案满足线性一致？因为该方案根据 commit index 对所有读写请求都一起做了线性化，这样每个读请求都能感知到状态机在执行完前一写请求后的最新状态，将读写日志一条一条的应用到状态机，整个系统当然满足线性一致。但该方案的缺点也非常明显，那就是&lt;strong&gt;性能差&lt;/strong&gt;，读操作的开销与写操作几乎完全一致。而且由于所有操作都线性化了，我们无法并发读状态机。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.3 Raft 读性能优化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来我们将介绍几种优化方案，它们在不违背系统线性一致性的前提下，大幅提升了读性能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.3.1 Read Index&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与 Raft Log Read 相比，Read Index 省掉了同步 log 的开销，&lt;strong&gt;能够大幅提升读的吞吐，一定程度上降低读的时延&lt;/strong&gt;。其大致流程为：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Leader 在收到客户端读请求时，记录下当前的 commit index，称之为 read index。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Leader 向 followers 发起一次心跳包，这一步是为了确保领导权，避免网络分区时少数派 leader 仍处理请求。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;等待状态机&lt;strong&gt;至少&lt;/strong&gt;应用到 read index（即 apply index &lt;strong&gt;大于等于&lt;/strong&gt; read index）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;执行读请求，将状态机中的结果返回给客户端。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里第三步的 apply index &lt;strong&gt;大于等于&lt;/strong&gt; read index 是一个关键点。因为在该读请求发起时，我们将当时的 commit index 记录了下来，只要使客户端读到的内容在该 commit index 之后，那么结果&lt;strong&gt;一定都满足线性一致&lt;/strong&gt;（如不理解可以再次回顾下前文线性一致性的例子以及2.2中的问题一）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.3.2 Lease Read&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与 Read Index 相比，Lease Read 进一步省去了网络交互开销，因此更能&lt;strong&gt;显著降低读的时延&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;基本思路是 leader 设置一个&lt;strong&gt;比选举超时（Election Timeout）更短的时间作为租期&lt;/strong&gt;，在租期内我们可以相信其它节点一定没有发起选举，集群也就一定不会存在脑裂，所以在这个时间段内我们直接读主即可，而非该时间段内可以继续走 Read Index 流程，Read Index 的心跳包也可以为租期带来更新。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Lease Read 可以认为是 Read Index 的时间戳版本，额外依赖时间戳会为算法带来一些不确定性，如果时钟发生漂移会引发一系列问题，因此需要谨慎的进行配置。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.3.3 Follower Read&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在前边两种优化方案中，无论我们怎么折腾，核心思想其实只有两点：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这两个保证分别对应2.2节所描述的两个问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其实无论是 Read Index 还是 Lease Read，最终目的都是为了解决第二个问题。换句话说，读请求最终一定都是由 leader 来承载的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那么读 follower 真的就不能满足线性一致吗？其实不然，这里我们给出一个可行的读 follower 方案：&lt;strong&gt;Follower 在收到客户端的读请求时，向 leader 询问当前最新的 commit index，反正所有日志条目最终一定会被同步到自己身上，follower 只需等待该日志被自己 commit 并 apply 到状态机后，返回给客户端本地状态机的结果即可&lt;/strong&gt;。这个方案叫做 &lt;strong&gt;Follower Read&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;注意：Follower Read 并不意味着我们在读过程中完全不依赖 leader 了，在保证线性一致性的前提下完全不依赖 leader 理论上是不可能做到的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上就是 Raft 算法的核心内容及工程实践最需要考虑的内容。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果你坚持看了下来，相信已经对 Raft 算法的理论有了深刻的理解。当然，理论和工程实践之间存在的鸿沟可能比想象的还要大，实践中有众多的细节问题需要去面对。在后续的源码分析及实践篇中，我们会结合代码讲解到许多理论部分没有提到的这些细节点，并介绍基础架构设计的诸多经验，敬请期待！&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d95feae1a8e1e6ddbd2d60f69e74237f</guid>
<title>布隆过滤器 (Bloom Filter) 详解</title>
<link>https://toutiao.io/k/imtmhh8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p&gt;&lt;span&gt;布隆过滤器是由 Burton Bloom 在 1970 年提出，因此也称为 Bloom Filter。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span/&gt;&lt;span&gt;实现&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;优点&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;缺点&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;使用场景&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;防止缓存击穿&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Web 拦截器&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;网页爬虫对 URL 去重&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;反垃圾邮件，判断某个邮箱是否是垃圾邮&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;......&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 实现原理&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;    &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当需要判断一个元素是否在某个集合中时，我们首先想到的是使用集合类（链表、树、散列表等）来实现。&lt;/span&gt;&lt;span&gt;但是使用集合类，我们是直接将所有元素保存在集合中，随着集合中元素数量的增加，集合所需要的存储空间也会线性增长，同时查询速度也会越来越慢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.39893617021276595&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/R038zOh2jPJdt6orVzowHMla2liatLebZvpDZcK6vXzh02wU0jBM5WUGOw6HRGqtKCic2TDLFeUrbiakibrfWeHibvw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;752&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;使用数组或列表时，插入项的位置和要插入的值没有对应关系，这样当需要查找某个值时就必须遍历已有的元素；当数组或列表中存在的元素数据很多时，就会影响查询效率。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;针对上述数组查询问题，我们改为使用哈希表。哈希表通过对“值”进行哈希计算，然后模哈希桶大小，得到存放该值的列表索引位置。查询时根据值的哈希值快速定位到存放该值的索引位置，然后在索引位置列表中进行查找该值是否存在，这样缩小了查询范围，提高了查询的效率。因为我们是将所有值存放在哈希表中，所以当存放值的数量变多时，会占用大量的存储空间，从而影响查询效率或者发生内存溢出。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这时，我们可以使用布隆过滤器（Bloom Filter）。不管是集合类还是布隆过滤器，都用到了哈希函数（Hash Function），我们先来看看哈希函数的定义。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;哈希函数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;哈希函数，也称为散列函数，给定一个输入值 &lt;span&gt;x&lt;/span&gt;，那么经过哈希函数计算输出 &lt;span&gt;H(x)&lt;/span&gt;，这个计算结果我们称为哈希值或者散列值。哈希函数具有以下特征：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;输入 &lt;span&gt;x&lt;/span&gt; 可以任意长度&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;输出结果 &lt;/span&gt;&lt;span&gt;H(x)&lt;/span&gt;&lt;span&gt; 的长度固定&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;计&lt;/span&gt;&lt;span&gt;算 &lt;/span&gt;&lt;span&gt;H(x)&lt;/span&gt;&lt;span&gt; 过程高效，长度为 &lt;/span&gt;&lt;span&gt;n&lt;/span&gt;&lt;span&gt; 的 &lt;/span&gt;&lt;span&gt;x&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;H(x)&lt;/span&gt;&lt;span&gt; 的时间复杂度应为 &lt;/span&gt;&lt;span&gt;O(n)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;单向散列：&lt;/span&gt;&lt;span&gt;当两个散列值不相同时，那么计算它们的输入值一定也不相同&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;散列碰撞：&lt;/span&gt;&lt;span&gt;当两个散列值相同，但是计算它们&lt;/span&gt;&lt;span&gt;的输入值不相同时，我们称这种情况为散列碰撞&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;隐&lt;/span&gt;&lt;span&gt;匿性：&lt;/span&gt;&lt;span&gt;通过 &lt;/span&gt;&lt;span&gt;H(x)&lt;/span&gt;&lt;span&gt; 结果，不能从计算上逆向推导出 &lt;/span&gt;&lt;span&gt;x&lt;/span&gt;&lt;span&gt;，不存在比穷举法更好的方法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;布隆过滤器数据结构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;布隆过滤器（Bloom Filter）本质上是一个长度为 &lt;span&gt;m&lt;/span&gt; 的位向量或位列表，仅包含二进制的 &lt;span&gt;0&lt;/span&gt; 或 &lt;span&gt;1&lt;/span&gt;。最初所有的值均为 &lt;span&gt;0&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.2088998763906057&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/R038zOh2jPJdt6orVzowHMla2liatLebZCGYjIQibobEUPhkQ0xWTBqQqpAGzIRkDZdYB3TRg57vQ0djSibibvWWzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;809&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;为了减少哈希碰撞，布隆过滤器使用 &lt;span&gt;K&lt;/span&gt; 个不同的哈希函数，并将哈希结果对应的位置为 &lt;span&gt;1&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.33250927070457353&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/R038zOh2jPJdt6orVzowHMla2liatLebZ1RVPm0amlmUnQCOGmPq7e2qZAdSN1TD2Pkiaz5dwamJic5cAeApwztiaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;809&quot;/&gt;&lt;/p&gt;&lt;p&gt;如上图所示：当输入 &lt;span&gt;January&lt;/span&gt; 时，通过设置当 3 个哈希函数计算得到索引位置 1、4、6，我们将这 3 个索引位置置为 &lt;span&gt;1&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.33250927070457353&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/R038zOh2jPJdt6orVzowHMla2liatLebZJCBYFsZ1NKMib4qlLtzsL67heYpvVGJybvFkRXfhkfjoiaEXNobGACYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;809&quot;/&gt;&lt;/p&gt;&lt;p&gt;然后再输入 &lt;span&gt;February&lt;/span&gt;，根据哈希函数得到索引位置 1、5、8。因为索引位 1 上已经是 &lt;span&gt;1&lt;/span&gt;，因此只需要将 5、8 索引位置 &lt;span&gt;1&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当查询某个值是否存在时，同样通过设置的哈希函数计算出索引位置，如果相应索引位置上都是 &lt;span&gt;1&lt;/span&gt; 则说明该值已存在（存在误判的情况），否则该值一定不存在。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;布隆过滤器为什么不能删除？如上所示，我们如果删除 &lt;span&gt;February&lt;/span&gt;，则将索引位置 1、5、8 置 &lt;span&gt;0&lt;/span&gt;。此时我们再来判断查询 &lt;span&gt;January&lt;/span&gt; 是否存在，因为索引位 1 已经置 0，根据判断规则，则判定 January 不存在。因此在布隆过滤器中删除元素会导致其他已存在元素的误判。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. Guava Bloom Filter 实现&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Google 的 Guava 库中提供了 Bloom Filter 的实现。我们使用它来实现一个从 1000 万数据中判断随机的 10000 条数据是否存在。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;-&lt;/span&gt; 引入 guava 库&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;xml&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;com.google.guava&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;guava&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;30.1-jre&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;-&lt;/span&gt; 代码示例&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;import&lt;/span&gt; com.google.common.base.Charsets;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;import&lt;/span&gt; com.google.common.hash.BloomFilter;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;import&lt;/span&gt; com.google.common.hash.Funnels;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;import&lt;/span&gt; java.util.Random;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__class&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;BloomFilterDemo&lt;/span&gt; {&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; total = &lt;span class=&quot;code-snippet__number&quot;&gt;10000000&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        BloomFilter&amp;lt;CharSequence&amp;gt; bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8), total);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; i = &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;; i &amp;lt; total; i++) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            bloomFilter.put(&lt;span class=&quot;code-snippet__string&quot;&gt;&quot;&quot;&lt;/span&gt; + i);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt; startTime = System.currentTimeMillis();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; count1 = &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; count2 = &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; i = &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;; i &amp;lt; &lt;span class=&quot;code-snippet__number&quot;&gt;10000&lt;/span&gt;; i++) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            &lt;span class=&quot;code-snippet__keyword&quot;&gt;int&lt;/span&gt; num = &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; Random().nextInt(&lt;span class=&quot;code-snippet__number&quot;&gt;100000000&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (num &amp;lt; total) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                count1++;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            String numStr = num + &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;&quot;&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (bloomFilter.mightContain(numStr)) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                count2++;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        System.out.println(&lt;span class=&quot;code-snippet__string&quot;&gt;&quot;匹配数据:&quot;&lt;/span&gt; + count2 + &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;条，耗时&quot;&lt;/span&gt; + (System.currentTimeMillis() - startTime) + &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;ms&quot;&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;if&lt;/span&gt; (count1 != count2) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            System.out.println(&lt;span class=&quot;code-snippet__string&quot;&gt;&quot;误判:&quot;&lt;/span&gt; + Math.&lt;span class=&quot;code-snippet__built_in&quot;&gt;abs&lt;/span&gt;(count2 - count1) + &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;条&quot;&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;-&lt;/span&gt; 代码输出&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;css&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;匹配数据&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:1276&lt;/span&gt;条，耗时9&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;ms&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;误判&lt;span class=&quot;code-snippet__selector-pseudo&quot;&gt;:286&lt;/span&gt;条&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;如上代码所示，布隆过滤器存在误判率，使用 Guava Bloom Filter 时，我们可以在创建布隆过滤器时设置误判率 FPP 来提高匹配准确度。如将上述代码中 BloomFilter 的创建语句改为：&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;xml&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;BloomFilter&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;CharSequence&lt;/span&gt;&amp;gt;&lt;/span&gt; bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8), total, 0.0001);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;Guava BloomFilter 默认误判率 fpp 为 &lt;/span&gt;&lt;span&gt;`0.03D`&lt;/span&gt;&lt;span&gt;，fpp 越小，匹配精度越高，相应的需要的存储空间越大，所以在实际应用中根据实际业务情况在误判率和存储空间之间选取一个合适的值。&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>