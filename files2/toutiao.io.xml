<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>d248b35f484177c7e4ebe8cd3174cc04</guid>
<title>Redis 字符串命令不止 SET 与 GET</title>
<link>https://toutiao.io/k/75rtacx</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;weui-dialog&quot;&gt;
      &lt;p class=&quot;weui-dialog__hd&quot;&gt;&lt;strong class=&quot;weui-dialog__title&quot;&gt;&quot;Top Stories&quot; is disabled&lt;/strong&gt;&lt;/p&gt;
      &lt;p class=&quot;weui-dialog__bd&quot;&gt;
        Enable &quot;Top Stories&quot; in &quot;Settings&quot; &amp;gt; &quot;General&quot; &amp;gt; &quot;Manage Discover&quot;      &lt;/p&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>7256f7e04f58895a0986f2394ba5c8e1</guid>
<title>大数据之分布式协调神器：Zookeeper 选举</title>
<link>https://toutiao.io/k/ex5k7x0</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzI4MjU4MzkwOQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/2gY1hzDz7dRCmOAs1H8E7QUDiaFQv0m4w2P7f4EkiacNxALJM0S7jPa7uL2a9sibAsHC6SzKZjZvylEhm4feUjlTQ/0?wx_fmt=png&quot; data-nickname=&quot;大数据左右手&quot; data-alias=&quot;ykc20161218&quot; data-signature=&quot;大数据开发工作者。致力于大数据技术学习与工作。实时，离线，面试与总结，或者生活小矫情类文章，总有适合你的那一篇。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6933333333333334&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2gY1hzDz7dS2icMOy4y8Q4XFY1rTPIlxm1qjRWKVXFRoKibdQBZeB3jRIe0ibq6dtuM3aTaoHZRHYam7QIQn4icRjg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分布式系统设计成主从节点主要是为了保障数据一致性，主从设计是一种最直观的数据一致性保障机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;span/&gt;&lt;span&gt;比&lt;/span&gt;&lt;span&gt;如主从复制，主节点负责写，从节点负责读，提高读的性能。从节点定期通过心跳与主节点沟通，一旦主节点挂掉了，从节点马上接手主节点的任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;但是主节点暂时失去响应，如瞬时负载过高，网络拥塞或者其他原因导致主节点暂时失去响应，超过响应超时时间，这个时候从节点启动，承担起leader的职责，但是原先的主节点又恢复了服务。&lt;/span&gt;&lt;span&gt;这个时候，如果没有选举机制（不能仅仅自己宣告自己是leader，还要广而告之，让其他服务器或者客户端知道自己是leader），有可能会存在两个leader节点，导致集群发生混乱。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;所以有了以下关于大数据框架主从选举的总结，赶快收藏吧！总有一个不经意时刻你会用到。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;mpcpc js_editor_cpcad=&quot;&quot; class=&quot;js_cpc_area cpc_iframe&quot; src=&quot;/cgi-bin/readtemplate?t=tmpl/cpc_tmpl#1626685445103&quot; data-category_id_list=&quot;1|11|16|17|22|24|26|27|28|29|3|31|32|35|36|37|39|41|42|43|45|46|47|48|49|5|50|51|52|53|54|55|6|7|8&quot; data-id=&quot;1626685445103&quot;/&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Zookeeper选举&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;Zookeeper介绍&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Zookeeper从设计模式角度来理解，是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生了变化，Zookeeper就负责通知已经在Zookeeper上注册的那些观察者做出相应的反应。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;Zookeeper特点&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;集群种只要有半数以上节点存活，Zookeeper集群就能正常提供服务。所以这就是选举机制的奇数原则（Zookeeper适合安装奇数台服务）。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一个领导者Leaders和多个跟随者Follower组成的集群。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;Zookeeper的选举机制&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;全新集群选举&lt;span/&gt;&lt;/h6&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.31057563587684067&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2gY1hzDz7dS2icMOy4y8Q4XFY1rTPIlxmHg4ytQX6WkG8P3tfDuia88RtEM6B6xiazQmKTJxRNVCOsDTB3WEAiaibUQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;747&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假设有五台服务器组成的Zookeeper集群，它们的id从Service1到Service5，同时它们都是最新启动的，也就是没有历史数据，在存放数据量这一点上，都是一样的。假设这些服务器依序启动，来看看会发生什么。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;服务器1启动，发起一次选举。服务器1投自己一票。此时服务器1票数一票，不够半数以上（3票），选举无法完成，服务器1状态保持为LOOKING；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;服务器2启动，再发起一次选举。服务器1和2分别投自己一票并交换选票信息：此时服务器1发现服务器2的ID比自己目前投票推举的（服务器1）大，更改选票为推举服务器2。此时服务器1票数0票，服务器2票数2票，没有半数以上结果，选举无法完成，服务器1，2状态保持LOOKING。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;服务器3启动，发起一次选举。此时服务器1和2都会更改选票为服务器3。此次投票结果：服务器1为0票，服务器2为0票，服务器3为3票。此时服务器3的票数已经超过半数，服务器3当选Leader。服务器1，2更改状态为FOLLOWING，服务器3更改状态为LEADING。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;服务器4启动，发起一次选举。此时服务器1，2，3已经不是LOOKING状态，不会更改选票信息。交换选票信息结果：服务器3为3票，服务器4为1票。此时服务器4服从多数，更改选票信息为服务器3，并更改状态为FOLLOWING。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;服务器5启动，同第4步一样当FOLLOWING。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;非全新集群选举&lt;span/&gt;&lt;/h6&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于运行正常的zookeeper集群，中途有机器down掉，需要重新选举时，选举过程就需要加入数据ID、服务器ID、和逻辑时钟。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;逻辑时钟：这个值从0开始，每次选举必须一致。小的选举结果被忽略，重新投票（除去选举次数不完整的服务器）。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据id：数据新的version大，数据每次更新都会更新version。数据id大的胜出（选出数据最新的服务器）。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;服务器id：即myid。数据id相同的情况下，服务器id大的胜出（数据相同的情况下，选择服务器id最大，即权重最大的服务器）。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;Kafka依赖Zookeeper的选举&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6043956043956044&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2gY1hzDz7dS2icMOy4y8Q4XFY1rTPIlxmVMGE6grniaxbBWLfrBX5Oicq4F9bt0DscOeXsBtOv1YRjZ3TT54YJicpg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;637&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;Kafka依赖ZK做了哪些事&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ZooKeeper 作为给分布式系统提供协调服务的工具被 kafka 所依赖。在分布式系统中，消费者需要知道有哪些生产者是可用的，而如果每次消费者都需要和生产者建立连接并测试是否成功连接，那效率也太低了，显然是不可取的。而通过使用 ZooKeeper 协调服务，Kafka 就能将 Producer，Consumer，Broker 等结合在一起，同时借助 ZooKeeper，Kafka 就能够将所有组件在无状态的条件下建立起生产者和消费者的订阅关系，实现负载均衡。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;Kafka选举&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Leader维护了一个动态的in-sync replica set (ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给follower发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此这个集合中的任何一个节点随时都可以被选为leader。ISR在ZooKeeper中维护。ISR中有f+1个节点（follow+leader），就可以允许在f个节点down掉的情况下不会丢失消息并正常提供服。ISR的成员是动态的，如果一个节点被淘汰了，当它重新达到“同步中”的状态时，他可以重新加入ISR。因此如果leader宕了，直接从ISR中选择一个follower就行。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4990859232175503&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2gY1hzDz7dS2icMOy4y8Q4XFY1rTPIlxmOiclXoUUZaOVpbWaczLIoGVZdAAGt12nXBvBmO4YmpyXibibFEqn0FYrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;547&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果全挂呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一旦所有节点都down了，Kafka不会保证数据的不丢失。所以当副本都down掉时，必须及时作出反应。等待ISR中的任何一个节点恢复并担任leader。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;附：Kafka为什么要放弃ZK&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;本身就是一个分布式系统，但是需要另一个分布式系统来管理，复杂性无疑增加了。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;部署的时候必须要部署两套系统，的运维人员必须要具备的运维能力。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Controller故障处理：依赖一个单一节点跟进行交互，如果这个节点发生了故障，就需要从中选择新的，新的选举成功后，会重新从拉取元数据进行初始化，并且需要通知其他所有的更新。老的需要关闭监听、事件处理线程和定时任务。分区数非常多时，这个过程非常耗时，而且这个过程中集群是不能工作的。&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5117370892018779&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2gY1hzDz7dS2icMOy4y8Q4XFY1rTPIlxm5HzejSrkicflSKQVibytSIyiccW19oyD7zzfwM2NesMcO2OjzCcdYbsLw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;639&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;当分区数增加时，保存的元数据变多，集群压力变大&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;基于ZooKeeper的Hadoop高可用&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;HDFS 高可用&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;介绍&lt;span/&gt;&lt;/h6&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个典型的HA集群，NameNode会被配置在两台独立的机器上，在任何时间上，一个NameNode处于活动状态，而另一个NameNode处于备份状态，活动状态的NameNode会响应集群中所有的客户端，备份状态的NameNode只是作为一个副本，保证在必要的时候提供一个快速的转移。所以对于HDFS来说，高可用其实就是针对NameNode的高可用。因为NameNode保存着集群的元数据信息，一旦丢失整个集群将不复存在。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主备切换控制器 ZKFailoverController：ZKFC 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。&lt;/p&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;原理&lt;span/&gt;&lt;/h6&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当HDFS的两台NN启动时，ZKFC（Zookeeper FailoverController）也会启动，ZKFC会向ZK上写一个临时序列化的节点（默认节点名是：/hadoop-ha）并取得和ZK的连接，一旦NN挂掉，那么ZKFC也会挂掉，该节点会被ZK自动删除掉，ZKFC有Watcher机制（当子节点发生变化时触动），另一个伴随着NN启动的ZKFC发现子节点变化了，是不是排在第一位，是，就通知第二台NN开始接管，向JN同步数据（下载IDS文件并和FImage合并，并生成新的FImage），将元数据都变成最新的，若是挂掉的NN重新启动，那么ZKFC还会向ZK写个节点，等现接管的NN挂掉后再接管成为Master。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;什么是ZKFC？&lt;span/&gt;&lt;/h5&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;ZKFC是一个Zookeeper的客户端，它主要用来监测和管理NameNodes的状态，每个NameNode机器上都会运行一个ZKFC程序，它的职责主要有：一是健康监控。ZKFC间歇性的ping NameNode，得到NameNode返回状态，如果NameNode失效或者不健康，那么ZKFS将会标记其为不健康；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Zookeeper会话管理。当本地NaneNode运行良好时，ZKFC将会持有一个Zookeeper session，如果本地NameNode为Active，它同时也持有一个“排他锁”znode，如果session过期，那么次lock所对应的znode也将被删除；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;选举。当集群中其中一个NameNode宕机，Zookeeper会自动将另一个激活。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;内部操作与原理&lt;span/&gt;&lt;/h5&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5134529147982063&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2gY1hzDz7dS2icMOy4y8Q4XFY1rTPIlxm4b3lRcutQc7XiaQa3y8xEQbGsCLBlSHXLPZVDiaw6vibcesusibL6zrYdQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;892&quot;/&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;HealthMonitor 初始化完成之后会启动内部的线程来定时调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法，对 NameNode 的健康状态进行检测。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;HealthMonitor 如果检测到 NameNode 的健康状态发生变化，会回调 ZKFailoverController 注册的相应方法进行处理。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果 ZKFailoverController 判断需要进行主备切换，会首先使用 ActiveStandbyElector 来进行自动的主备选举。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ActiveStandbyElector 与 Zookeeper 进行交互完成自动的主备选举。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ActiveStandbyElector 在主备选举完成后，会回调 ZKFailoverController 的相应方法来通知当前的 NameNode 成为主 NameNode 或备 NameNode。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ZKFailoverController 调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法将 NameNode 转换为 Active 状态或 Standby 状态。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;几句话描述就是：ZooKeeper提供了简单的机制来实现Acitve Node选举，如果当前Active失效，Standby将会获取一个特定的排他锁，那么获取锁的Node接下来将会成为Active。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;Yarn高可用&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;介绍&lt;span/&gt;&lt;/h6&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;YARN ResourceManager 的高可用与 HDFS NameNode 的高可用类似但是 ResourceManager 不像 NameNode ，没有那么多的元数据信息需要维护，所以它的状态信息可以直接写到 Zookeeper 上，并依赖 Zookeeper 来进行主备选举。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6049382716049383&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2gY1hzDz7dS2icMOy4y8Q4XFY1rTPIlxmoI63NTMmDGOq2Ic05aUe3hnlY9Imnhf7VkibIbgxP9rVlt2PYl94DUg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;486&quot;/&gt;&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;内部操作与原理&lt;span/&gt;&lt;/h5&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;在ZooKeeper上会有一个/yarn-leader-election/yarn1的锁节点，所有的ResourceManager在启动的时候，都会去竞争写一个Lock子节点：/yarn-leader-election/yarn1/ActiveBreadCrumb，该节点是临时节点。ZooKeepr能够保证最终只有一个ResourceManager能够创建成功。创建成功的那个ResourceManager就切换为Active状态，没有成功的那些ResourceManager则切换为Standby状态。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;RM会把job的信息存放在zookeeper的/rmstore目录下，active RM会向这个目录写app的信息。当active RM挂掉之后，standby RM会通过zkfc切换为active状态，然后从zookeeper的/rmstore目录下读取相应的作业信息。重新构建作业的内存信息，启动内部服务，开始接受NM的心跳信息，构建集群的资源信息，并且接受客户端的作业提交请求。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;其他与总结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在大数据领域，还有许多框架依赖与Zookeeper去选择主从：比如Hbase集群，Kudu集群，Impala集群等等，最底层的原理大径相同。&lt;/p&gt;&lt;h6 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结&lt;span/&gt;&lt;/h6&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;选举：Zookeeper能够很容易的实现集群管理的功能，若有多台Server组成一个服务集群，则必须要一个leader知道集群中每台机器的服务状态，从而做出调整重新分配服务策略。当集群中增加一台或多台Server时，leader同样需要知道。Zookeeper不仅能够维护当前的集群中机器的服务状态，而且能够选出一个leader来管理集群。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;HA(分布式锁的应用)：Master挂掉之后迅速切换到slave节点。&lt;span/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我要去大厂专题 往期回顾&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4MjU4MzkwOQ==&amp;amp;mid=2247484713&amp;amp;idx=1&amp;amp;sn=b1c6fb7cedcfbfa6fb22d2e02e8b375c&amp;amp;chksm=eb96f323dce17a35fb5f81996199cffb0a1d6797be3feae3ccc61d051a0f9acd88fd07535276&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Flink吐血总结，学习与面试收藏这一篇就够了！！！&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4MjU4MzkwOQ==&amp;amp;mid=2247484735&amp;amp;idx=1&amp;amp;sn=8f910ab0c7b48f1b699207eb22fbf14a&amp;amp;chksm=eb96f335dce17a23e569ec4187d2f323b8747132d62c4611665e6d028a71e26234ef5f950a6a&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;你的数据倾斜了吗？一文帮你数据处理再均衡&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4MjU4MzkwOQ==&amp;amp;mid=2247484677&amp;amp;idx=1&amp;amp;sn=00ce05f7cb76cad7af960e47172154f4&amp;amp;chksm=eb96f30fdce17a191919b43e99893d15e3f04017681d64aa09e6c7a6d8108ccd2e051fafff7e&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Kafka面试准备，收藏这一篇就够了！！！&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4MjU4MzkwOQ==&amp;amp;mid=2247484635&amp;amp;idx=1&amp;amp;sn=17436dd8178800fe0d2e2e2cb1768a7a&amp;amp;chksm=eb96f2d1dce17bc7279c457551a682382b9d10f3bbafac5ee66a72d1d5e505b2338fc6f9e8bb&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;查询引擎怎么选？7000字解析所有开源引擎的秘密&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4MjU4MzkwOQ==&amp;amp;mid=2247484632&amp;amp;idx=1&amp;amp;sn=c99cb782ed0a2f3c82d6f92478a55aa5&amp;amp;chksm=eb96f2d2dce17bc464e9d1c2a84b95f024aec2f97e7f1da05848c57923d320e95640b5a08e7e&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;大数据调度系统选得好,下班回家早;调度用得对,半夜安心睡&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4MjU4MzkwOQ==&amp;amp;mid=2247484600&amp;amp;idx=1&amp;amp;sn=53420bb2919e200e95fd320e37b7b487&amp;amp;chksm=eb96f2b2dce17ba48b6857af63ba70a91a12f8b12d5a106a58c32b58367449b6f67de601ab9f&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;六千字总结:大数据框架(分区，分桶，分片),建议收藏&lt;/a&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzI4MjU4MzkwOQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/2gY1hzDz7dRCmOAs1H8E7QUDiaFQv0m4w2P7f4EkiacNxALJM0S7jPa7uL2a9sibAsHC6SzKZjZvylEhm4feUjlTQ/0?wx_fmt=png&quot; data-nickname=&quot;大数据左右手&quot; data-alias=&quot;ykc20161218&quot; data-signature=&quot;大数据开发工作者。致力于大数据技术学习与工作。实时，离线，面试与总结，或者生活小矫情类文章，总有适合你的那一篇。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;同&lt;/span&gt;&lt;span&gt;学&lt;/span&gt;&lt;span&gt;共进，点赞，转发，在看，关注，是我学习之动力。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;和我联系吧，交流大数据知识,一起成长~~~&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>12afbc1d01ccf8d0df6eb7a944495076</guid>
<title>使用稀疏推理加速移动和 Web 上的神经网络</title>
<link>https://toutiao.io/k/vsf8leu</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;神经网络的设备端推理以低延迟和注重隐私的方式支持各种实时应用，如姿势估计和背景模糊。使用带有XNNPACK ML 加速库的TensorFlow Lite等 ML 推理框架，工程师通过找到模型大小、推理速度和预测质量之间的最佳点来优化他们的模型以在各种设备上运行。&lt;/p&gt;&lt;p&gt;来优化模型的一种方法是通过使用稀疏神经网络[的1，2，3 ]，其具有它们的权重设为零的显著部分。一般来说，这是一种理想的质量，因为它不仅通过压缩减小了模型大小，而且还可以跳过大部分乘加运算，从而加快推理速度。此外，可以增加模型中的参数数量，然后对其进行稀疏化以匹配原始模型的质量，同时仍然受益于加速推理。然而，这种技术在生产中的使用仍然受到限制，这主要是由于缺乏稀疏流行卷积架构的工具，以及对在设备上运行这些操作的支持不足。&lt;/p&gt;&lt;p&gt;今天，我们宣布为XNNPACK 加速库和 TensorFlow Lite发布一组新功能，这些新功能可实现稀疏网络的高效推理，以及有关如何稀疏化神经网络的指南，目的是帮助研究人员开发自己的设备上稀疏楷模。在合作开发DeepMind，这些工具提供动力的新一代实时感知经验，包括手跟踪在MediaPipe和后台功能在 Google Meet 中，将推理速度从 1.2 倍提高到 2.4 倍，同时将模型大小减少一半。在这篇文章中，我们提供了稀疏神经网络的技术概述——从在训练期间引入稀疏性到设备上部署——并提供一些关于研究人员如何创建自己的稀疏模型的想法。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eG1jA7faiceHDAwzMibNWRLEVNtL9TgUB0XXzb1ibiaALZgcsicD1EzVqEQfbrAiacStBMUMXD2k89qSdOHUkaQmPJrg/640?wx_fmt=png&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;em&gt;稀疏化神经网络&lt;/em&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;许多现代深度学习架构，如MobileNet和EfficientNetLite，主要由具有小空间内核的深度卷积和线性组合输入图像特征的1x1 卷积组成。虽然此类架构有许多潜在的稀疏化目标，包括在许多网络开始时经常出现的完整2D 卷积或深度卷积，但以推理时间衡量，1x1 卷积是最昂贵的算子。由于它们占总计算量的 65% 以上，因此它们是稀疏化的最佳目标。&lt;/p&gt;&lt;p&gt;建筑学 推理时间 移动网 85% 移动网络V2 71% 移动网络V3 71% EfficientNet-Lite 66% 现代移动架构中专用于 1x1 卷积的推理时间的比较（以百分比为单位）。&lt;/p&gt;&lt;p&gt;在现代设备端推理引擎中，如 XNNPACK，深度学习模型中 1x1 卷积的实现以及其他操作依赖于 HWC 张量布局，其中张量维度对应于高度、宽度和通道（例如，输入图像的红色、绿色或蓝色）。这种张量配置允许推理引擎并行处理对应于每个空间位置（即图像的每个像素）的通道。然而，张量的这种排序不太适合稀疏推理，因为它将通道设置为张量的最内维，并且使得访问的计算成本更高。&lt;/p&gt;&lt;p&gt;我们对 XNNPACK 的更新使其能够检测模型是否稀疏。如果是，则从其标准密集推理模式切换到稀疏推理模式，它采用 CHW（通道、高度、宽度）张量布局。张量的这种重新排序允许加速实现稀疏的 1x1 卷积核，原因有两个：1）当在单个条件检查后相应的通道权重为零时，可以跳过张量的整个空间切片，而不是逐像素测试; 2) 当通道权重不为零时，通过将相邻像素加载到同一内存单元中可以提高计算效率。这使我们能够同时处理多个像素，同时还可以跨多个线程并行执行每个操作。当至少 80% 的权重为零时，这些变化一起导致 1.8 倍到 2.3 倍的加速。&lt;/p&gt;&lt;p&gt;为了避免在每次操作后在最适合稀疏推理的 CHW 张量布局和标准 HWC 张量布局之间来回转换，XNNPACK在 CHW 布局中提供了几个 CNN 算子的有效实现。&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;em&gt;训练稀疏神经网络的指南&lt;/em&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;要创建稀疏神经网络，此版本中包含的指南建议从密集版本开始，然后在训练期间逐渐将其权重的一部分设置为零。这个过程称为修剪。在许多可用的剪枝技术中，我们建议使用幅度剪枝（可在TF 模型优化工具包中获得）或最近引入的RigL方法。随着训练时间的适度增加，这两种方法都可以成功地稀疏深度学习模型而不会降低其质量。生成的稀疏模型可以以压缩格式有效存储，与密集等效模型相比，该格式将大小减少了两倍。&lt;/p&gt;&lt;p&gt;稀疏网络的质量受几个超参数的影响，包括训练时间、学习率和修剪时间表。该TF修剪API提供了如何选择这些，还有一些技巧训练这种模式一个很好的例子。我们建议运行超参数搜索以找到适合您的应用程序的最佳位置。&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;em&gt;应用&lt;/em&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;我们证明可以稀疏分类任务、密集分割（例如，满足背景模糊）和回归问题（MediaPipe Hands），这为用户提供了切实的好处。例如，在 Google Meet 的案例中，稀疏化将模型的推理时间降低了 30%，这为更多用户提供了访问更高质量模型的机会。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eG1jA7faiceHDAwzMibNWRLEVNtL9TgUB01cDMCNd4etOE8Kaq7iacStiaZyPdAmbUKyHnhGTFybeAAMSFfibReSzIw/640?wx_fmt=png&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;此处描述的稀疏方法最适用于基于反向残差块的架构，例如MobileNetV2、MobileNetV3和EfficientNetLite。. 网络中的稀疏程度会影响推理速度和质量。从固定容量的密集网络开始，我们发现即使在 30% 的稀疏度下也能获得适度的性能提升。随着稀疏度的增加，模型的质量保持相对接近于密集基线，直到达到 70% 的稀疏度，超过 70% 时，准确度下降更为明显。然而，可以通过将基础网络的大小增加 20% 来补偿 70% 稀疏度时精度的降低，从而在不降低模型质量的情况下加快推理时间。运行稀疏模型不需要进一步的更改，因为 XNNPACK 可以识别并自动启用稀疏推理。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eG1jA7faiceHDAwzMibNWRLEVNtL9TgUB08MMzMSNTRMmTBlU9pYQoAwqoSiaStv0Xr9ibgkwe6yOWw1RdwU2DKM3A/640?wx_fmt=png&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;em&gt;稀疏性作为蒸馏的自动替代方案&lt;/em&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Google Meet 中的背景模糊使用基于带有注意块的修改后的 MobileNetV3 主干的分割模型。通过应用 70% 的稀疏化，我们能够将模型速度提高 30%，同时保持前景蒙版的质量。我们检查了稀疏和密集模型对来自 17 个地理子区域的图像的预测，没有发现显着差异，并在相关的模型卡中发布了详细信息。&lt;/p&gt;&lt;p&gt;类似地，MediaPipe Hands使用基于 EfficientNetLite 主干的模型在移动设备和网络上实时预测手部地标。这个主干模型是手动蒸馏的来自大型密集模型，这是一个计算成本高的迭代过程。使用密集模型的稀疏版本而不是蒸馏模型，我们能够保持相同的推理速度，但没有从密集模型中提取的劳动密集型过程。与密集模型相比，稀疏模型将推理提高了两倍，实现了与蒸馏模型相同的地标质量。从某种意义上说，稀疏化可以被认为是非结构化模型蒸馏的一种自动方法，它可以在不进行大量人工操作的情况下提高模型性能。我们评估的geodiverse数据集稀疏模式并取得了模卡公开可用的。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eG1jA7faiceHDAwzMibNWRLEVNtL9TgUB0NhSHC6dPLqgBe4WM37ajFyPuoibicHWGticMORNOIF1gEa6pzjsSkpoUQ/640?wx_fmt=png&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;em&gt;未来的工作&lt;/em&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;我们发现稀疏化是一种简单而强大的技术，可以改善神经网络的 CPU 推理。稀疏推理允许工程师运行更大的模型而不会产生显着的性能或大小开销，并为研究提供了一个有前途的新方向。我们将继续扩展 XNNPACK，为 CHW 布局中的操作提供更广泛的支持，并正在探索如何将其与其他优化技术（如量化）相结合。我们很高兴看到您可以使用这项技术构建什么！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_weapp_entry&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/eG1jA7faiceHDAwzMibNWRLEVNtL9TgUB0rZ5nU3cPhzpicTWTicEBJulDqBmpp8iaFK61RDou7hvneCtxM4IvDLosg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;430&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>39ebdde5518ad72fc709061d6b7d35c1</guid>
<title>Go 语言如何操纵 Kafka 保证无消息丢失</title>
<link>https://toutiao.io/k/r6p3osc</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;背景&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目前一些互联网公司会使用消息队列来做核心业务，因为是核心业务，所以对数据的最后一致性比较敏感，如果中间出现数据丢失，就会引来用户的投诉，年底绩效就变成325了。之前和几个朋友聊天，他们的公司都在用&lt;code&gt;kafka&lt;/code&gt;来做消息队列，使用&lt;code&gt;kafka&lt;/code&gt;到底会不会丢消息呢？如果丢消息了该怎么做好补偿措施呢？本文我们就一起来分析一下，并介绍如何使用&lt;code&gt;Go&lt;/code&gt;操作&lt;code&gt;Kafka&lt;/code&gt;可以不丢失数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文操作&lt;code&gt;kafka&lt;/code&gt;基于：https://github.com/Shopify/sarama&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;初识&lt;code&gt;kafka&lt;/code&gt;架构&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;维基百科对&lt;code&gt;kafka&lt;/code&gt;的介绍：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;Kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。该项目的目标是为处理实时数据提供一个统一、高吞吐、低延迟的平台。其持久化层本质上是一个“按照分布式事务日志架构的大规模发布/订阅消息队列”，这使它作为企业级基础设施来处理流式数据非常有价值。此外，Kafka可以通过Kafka Connect连接到外部系统（用于数据输入/输出），并提供了Kafka Streams——一个Java]流式处理库。该设计受事务日志的影响较大。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;kafka&lt;/strong&gt;的整体架构比较简单，主要由&lt;code&gt;producer&lt;/code&gt;、&lt;code&gt;broker&lt;/code&gt;、&lt;code&gt;consumer&lt;/code&gt;组成：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5933660933660934&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CqB2u93NwBibbdIf4ZdWxvCVNB3uXmJAu2cdp1eibNCW4k8CsU7ZbCSr1ScHHdNqv6o3VOrUqfdT9HdEjJ1YibYrA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1628&quot;/&gt;&lt;figcaption&gt;截屏2021-09-12 上午10.00.13&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对架构图我们解释一个各个模块：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Producer&lt;/strong&gt;：数据的生产者，可以将数据发布到所选择的&lt;code&gt;topic&lt;/code&gt;中。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Consumer&lt;/strong&gt;：数据的消费者，使用&lt;strong&gt;Consumer Group&lt;/strong&gt;进行标识，在&lt;code&gt;topic&lt;/code&gt;中的每条记录都会被分配给订阅消费组中的一个消费者实例，消费者实例可以分布在多个进程中或者多个机器上。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Broker&lt;/strong&gt;：消息中间件处理节点（服务器），一个节点就是一个broker，一个Kafka集群由一个或多个broker组成。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有些概念我们也介绍一下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;topic&lt;/strong&gt;：可以理解为一个消息的集合，topic存储在broker中，一个topic可以有多个partition分区，一个topic可以有多个Producer来push消息，一个topic可以有多个消费者向其pull消息，一个topic可以存在一个或多个broker中。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;partition&lt;/strong&gt;：其是topic的子集，不同分区分配在不同的broker上进行水平扩展从而增加kafka并行处理能力，同topic下的不同分区信息是不同的，同一分区信息是有序的；每一个分区都有一个或者多个副本，其中会选举一个&lt;code&gt;leader&lt;/code&gt;，&lt;code&gt;fowller&lt;/code&gt;从&lt;code&gt;leader&lt;/code&gt;拉取数据更新自己的log（每个分区逻辑上对应一个log文件夹），消费者向leader中pull信息。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;kafka丢消息的三个节点&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;生产者push消息节点&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先看一下producer的大概写入流程：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;producer先从kafka集群找到该partition的leader&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;producer将消息发送给leader，leader将该消息写入本地&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;follwers从leader pull消息，写入本地log后leader发送ack&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;leader 收到所有 ISR 中的 replica 的 ACK 后，增加high watermark，并向 producer 发送 ack&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4105145413870246&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CqB2u93NwBibbdIf4ZdWxvCVNB3uXmJAuY0m6FpHNhmf87NAAA1K0ZPoDZBZdEKicI0el8Fg2icowdxhtibMuwcNKQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1788&quot;/&gt;&lt;figcaption&gt;截屏2021-09-12 上午11.16.43&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过这个流程我们可以看到kafka最终会返回一个ack来确认推送消息结果，这里kafka提供了三种模式：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;NoResponse RequiredAcks = &lt;span&gt;0&lt;/span&gt;&lt;br/&gt;WaitForLocal RequiredAcks = &lt;span&gt;1&lt;/span&gt;&lt;br/&gt;WaitForAll RequiredAcks = &lt;span&gt;-1&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;NoResponse RequiredAcks = 0&lt;/code&gt;：这个代表的就是数据推出的成功与否都与我无关了&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;WaitForLocal RequiredAcks = 1&lt;/code&gt;：当local(leader)确认接收成功后，就可以返回了&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;WaitForAll RequiredAcks = -1&lt;/code&gt;：当所有的leader和follower都接收成功时，才会返回&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以根据这三种模式我们就能推断出生产者在push消息时有一定几率丢失的，分析如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;如果我们选择了模式&lt;code&gt;1&lt;/code&gt;，这种模式丢失数据的几率很大，无法重试&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果我们选择了模式&lt;code&gt;2&lt;/code&gt;，这种模式下只要leader不挂，就可以保证数据不丢失，但是如果leader挂了，follower还没有同步数据，那么就会有一定几率造成数据丢失&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果选择了模式&lt;code&gt;3&lt;/code&gt;，这种情况不会造成数据丢失，但是有可能会造成数据重复，假如leader与follower同步数据是网络出现问题，就有可能造成数据重复的问题。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以在生产环境中我们可以选择模式2或者模式3来保证消息的可靠性，具体需要根据业务场景来进行选择，在乎吞吐量就选择模式2，不在乎吞吐量，就选择模式3，要想完全保证数据不丢失就选择模式3是最可靠的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;kafka集群自身故障造成&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;kafka集群接收到数据后会将数据进行持久化存储，最终数据会被写入到磁盘中，在写入磁盘这一步也是有可能会造成数据损失的，因为写入磁盘的时候操作系统会先将数据写入缓存，操作系统将缓存中数据写入磁盘的时间是不确定的，所以在这种情况下，如果&lt;code&gt;kafka&lt;/code&gt;机器突然宕机了，也会造成数据损失，不过这种概率发生很小，一般公司内部kafka机器都会做备份，这种情况很极端，可以忽略不计。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;消费者pull消息节点&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;push消息时会把数据追加到Partition并且分配一个偏移量，这个偏移量代表当前消费者消费到的位置，通过这个Partition也可以保证消息的顺序性，消费者在pull到某个消息后，可以设置自动提交或者手动提交commit，提交commit成功，offset就会发生偏移:&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4832116788321168&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CqB2u93NwBibbdIf4ZdWxvCVNB3uXmJAulZ6JGrddsiadickdPHOYYmNeKC1uu4ft33biclibC9jIibMRUrLvYz5rZeQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1370&quot;/&gt;&lt;figcaption&gt;截屏2021-09-12 下午3.37.33&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以自动提交会带来数据丢失的问题，手动提交会带来数据重复的问题，分析如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;在设置自动提交的时候，当我们拉取到一个消息后，此时offset已经提交了，但是我们在处理消费逻辑的时候失败了，这就会导致数据丢失了&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在设置手动提交时，如果我们是在处理完消息后提交commit，那么在commit这一步发生了失败，就会导致重复消费的问题。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比起数据丢失，重复消费是符合业务预期的，我们可以通过一些幂等性设计来规避这个问题。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;实战&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;完整代码已经上传github：https://github.com/asong2020/Golang_Dream/tree/master/code_demo/kafka_demo&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;解决push消息丢失问题&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主要是通过两点来解决：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;通过设置&lt;code&gt;RequiredAcks&lt;/code&gt;模式来解决，选用&lt;code&gt;WaitForAll&lt;/code&gt;可以保证数据推送成功，不过会影响时延时&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;引入重试机制，设置重试次数和重试间隔&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此我们写出如下代码（摘出创建client部分）：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;NewAsyncProducer&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;sarama&lt;/span&gt;.&lt;span&gt;AsyncProducer&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; cfg := sarama.NewConfig()&lt;br/&gt; version, err := sarama.ParseKafkaVersion(VERSION)&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt;{&lt;br/&gt;  log.Fatal(&lt;span&gt;&quot;NewAsyncProducer Parse kafka version failed&quot;&lt;/span&gt;, err.Error())&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt; }&lt;br/&gt; cfg.Version = version&lt;br/&gt; cfg.Producer.RequiredAcks = sarama.WaitForAll &lt;span&gt;// 三种模式任君选择&lt;/span&gt;&lt;br/&gt; cfg.Producer.Partitioner = sarama.NewHashPartitioner&lt;br/&gt; cfg.Producer.Return.Successes = &lt;span&gt;true&lt;/span&gt;&lt;br/&gt; cfg.Producer.Return.Errors = &lt;span&gt;true&lt;/span&gt;&lt;br/&gt; cfg.Producer.Retry.Max = &lt;span&gt;3&lt;/span&gt; &lt;span&gt;// 设置重试3次&lt;/span&gt;&lt;br/&gt; cfg.Producer.Retry.Backoff = &lt;span&gt;100&lt;/span&gt; * time.Millisecond&lt;br/&gt; cli, err := sarama.NewAsyncProducer([]&lt;span&gt;string&lt;/span&gt;{ADDR}, cfg)&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt;{&lt;br/&gt;  log.Fatal(&lt;span&gt;&quot;NewAsyncProducer failed&quot;&lt;/span&gt;, err.Error())&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt; }&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; cli&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;解决pull消息丢失问题&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个解决办法就比较粗暴了，直接使用自动提交的模式，在每次真正消费完之后在自己手动提交offset，但是会产生重复消费的问题，不过很好解决，使用幂等性操作即可解决。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;代码示例：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;NewConsumerGroup&lt;/span&gt;&lt;span&gt;(group &lt;span&gt;string&lt;/span&gt;)&lt;/span&gt; &lt;span&gt;sarama&lt;/span&gt;.&lt;span&gt;ConsumerGroup&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; cfg := sarama.NewConfig()&lt;br/&gt; version, err := sarama.ParseKafkaVersion(VERSION)&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt;{&lt;br/&gt;  log.Fatal(&lt;span&gt;&quot;NewConsumerGroup Parse kafka version failed&quot;&lt;/span&gt;, err.Error())&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt; cfg.Version = version&lt;br/&gt; cfg.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategyRange&lt;br/&gt; cfg.Consumer.Offsets.Initial = sarama.OffsetOldest&lt;br/&gt; cfg.Consumer.Offsets.Retry.Max = &lt;span&gt;3&lt;/span&gt;&lt;br/&gt; cfg.Consumer.Offsets.AutoCommit.Enable = &lt;span&gt;true&lt;/span&gt; &lt;span&gt;// 开启自动提交，需要手动调用MarkMessage才有效&lt;/span&gt;&lt;br/&gt; cfg.Consumer.Offsets.AutoCommit.Interval = &lt;span&gt;1&lt;/span&gt; * time.Second &lt;span&gt;// 间隔&lt;/span&gt;&lt;br/&gt; client, err := sarama.NewConsumerGroup([]&lt;span&gt;string&lt;/span&gt;{ADDR}, group, cfg)&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;  log.Fatal(&lt;span&gt;&quot;NewConsumerGroup failed&quot;&lt;/span&gt;, err.Error())&lt;br/&gt; }&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; client&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面主要是创建ConsumerGroup部分，细心的读者应该看到了，我们这里使用的是自动提交，说好的使用手动提交呢？这是因为我们这个kafka库的特性不同，这个自动提交需要与MarkMessage()方法配合使用才会提交(有疑问的朋友可以实践一下，或者看一下源码)，否则也会提交失败，因为我们在写消费逻辑时要这样写：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(e EventHandler)&lt;/span&gt; &lt;span&gt;ConsumeClaim&lt;/span&gt;&lt;span&gt;(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim)&lt;/span&gt; &lt;span&gt;error&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; msg := &lt;span&gt;range&lt;/span&gt; claim.Messages() {&lt;br/&gt;  &lt;span&gt;var&lt;/span&gt; data common.KafkaMsg&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; err := json.Unmarshal(msg.Value, &amp;amp;data); err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;   &lt;span&gt;return&lt;/span&gt; errors.New(&lt;span&gt;&quot;failed to unmarshal message err is &quot;&lt;/span&gt; + err.Error())&lt;br/&gt;  }&lt;br/&gt;  &lt;span&gt;// 操作数据，改用打印&lt;/span&gt;&lt;br/&gt;  log.Print(&lt;span&gt;&quot;consumerClaim data is &quot;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;// 处理消息成功后标记为处理, 然后会自动提交&lt;/span&gt;&lt;br/&gt;  session.MarkMessage(msg,&lt;span&gt;&quot;&quot;&lt;/span&gt;)&lt;br/&gt; }&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;或者直接使用手动提交方法来解决，只需两步：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一步：关闭自动提交：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;consumerConfig.Consumer.Offsets.AutoCommit.Enable = &lt;span&gt;false&lt;/span&gt;  &lt;span&gt;// 禁用自动提交，改为手动&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二步：消费逻辑中添加如下代码，手动提交模式下，也需要先进行标记，在进行commit&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;session.MarkMessage(msg,&lt;span&gt;&quot;&quot;&lt;/span&gt;)&lt;br/&gt;session.Commit()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;完整代码可以到github上下载并进行验证！&lt;/strong&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文我们主要说明了两个知识点：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Kafka会产生消息丢失&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用Go操作Kafka如何配置可以不丢失数据&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;日常业务开发中，很多公司都喜欢拿消息队列进行解耦，那么你就要注意了，使用Kafka做消息队列无法保证数据不丢失，需要我们自己手动配置补偿，别忘记了，要不又是一场P0事故。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;素质三连（分享、点赞、在看）都是笔者持续创作更多优质内容的动力！我是&lt;code&gt;asong&lt;/code&gt;，我们下期见。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;创建了一个Golang学习交流群，欢迎各位大佬们踊跃入群，我们一起学习交流。入群方式：关注公众号获取。更多学习资料请到公众号领取。&lt;/strong&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzkyNzI1NzM5NQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/CqB2u93NwB96zTfSmymj9jWokyhvSIXMRcLRAfFJsrB4uz6HBsml4T6iaia3yyCSB4aicX97icT7xBUCgw4O1PsKFQ/0?wx_fmt=png&quot; data-nickname=&quot;Golang梦工厂&quot; data-alias=&quot;AsongDream&quot; data-signature=&quot;asong是一名后端程序员，目前就职于一家电商公司，专注于Golang技术，定期分享Go语言、MySQL、Redis、Elasticsearch、计算机基础、微服务架构设计、面试等知识。这里不仅有技术，还有故事！&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4d099970f228be031efa15e1c07ad5b4</guid>
<title>JUC 常用 4 大并发工具类</title>
<link>https://toutiao.io/k/8ef0b5i</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;什么是JUC?&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;4大常用并发工具类:&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;CountDownLatch:&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;CyclicBarrier:&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Semaphore:&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Exchanger:&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;什么是JUC?&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;JUC就是java.util.concurrent包,这个包俗称JUC,里面都是解决并发问题的一些东西&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该包的位置位于java下面的rt.jar包下面&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;4大常用并发工具类:&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CountDownLatch&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CyclicBarrier&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Semaphore&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ExChanger&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CountDownLatch,俗称闭锁,作用是类似加强版的Join,是让一组线程等待其他的线程完成工作以后才执行&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就比如在启动框架服务的时候,我们主线程需要在环境线程初始化完成之后才能启动,这时候我们就可以实现使用CountDownLatch来完成&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;/**&lt;br/&gt;     * Constructs a {@code CountDownLatch} initialized with the given count.&lt;br/&gt;     *&lt;br/&gt;     * @param count the number of &lt;span&gt;times&lt;/span&gt; {@link &lt;span&gt;#countDown} must be invoked&lt;/span&gt;&lt;br/&gt;     *        before threads can pass through {@link &lt;span&gt;#await}&lt;/span&gt;&lt;br/&gt;     * @throws IllegalArgumentException &lt;span&gt;if&lt;/span&gt; {@code count} is negative&lt;br/&gt;     */&lt;br/&gt;    public CountDownLatch(int count) {&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (count &amp;lt; 0) throw new IllegalArgumentException(&lt;span&gt;&quot;count &amp;lt; 0&quot;&lt;/span&gt;);&lt;br/&gt;        this.sync = new Sync(count);&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在源码中可以看到,创建CountDownLatch时,需要传入一个int类型的参数,将决定在执行次扣减之后,等待的线程被唤醒&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6271186440677966&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia04oPHkc1mY76tdSW4uyt2ichGkSjHPCiaekgUNiaibncfzOGFgUjyJdb6907mQgnhZHj6kibF3OIqpFHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;472&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过这个类图就可以知道其实CountDownLatch并没有多少东西&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;方法介绍:&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CountDownLatch:初始化方法&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;await:等待方法,同时带参数的是超时重载方法&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;countDown:每执行一次,计数器减一,就是初始化传入的数字,也代表着一个线程完成了任务&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;getCount:获取当前值&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;toString:这个就不用说了&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;里面的Sync是一个内部类,外面的方法其实都是操作这个内部类的,这个内部类继承了AQS,实现的标准方法,AQS将在后面的章节写&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.8569206842923794&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia04oPHkc1mY76tdSW4uyt2icph8ib6vR5ia2lcg9kbxyP4KApPXLiaucOgc7mSGrctF7mlcSJqHNWkIDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;643&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主线程中创建CountDownLatch(3),然后主线程await阻塞,然后线程A,B,C各自完成了任务,调用了countDown,之后,每个线程调用一次计数器就会减一,初始是3,然后A线程调用后变成2,B线程调用后变成1,C线程调用后,变成0,这时就会唤醒正在await的主线程,然后主线程继续执行&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说一千道一万,不如代码写几行,上代码:&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;休眠工具类,之后的代码都会用到&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;package org.dance.tools;&lt;br/&gt;&lt;br/&gt;import java.util.concurrent.TimeUnit;&lt;br/&gt;&lt;br/&gt;/**&lt;br/&gt; * 类说明：线程休眠辅助工具类&lt;br/&gt; */&lt;br/&gt;public class SleepTools {&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 按秒休眠&lt;br/&gt;     * @param seconds 秒数&lt;br/&gt;     */&lt;br/&gt;    public static final void second(int seconds) {&lt;br/&gt;        try {&lt;br/&gt;            TimeUnit.SECONDS.sleep(seconds);&lt;br/&gt;        } catch (InterruptedException e) {&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 按毫秒数休眠&lt;br/&gt;     * @param seconds 毫秒数&lt;br/&gt;     */&lt;br/&gt;    public static final void ms(int seconds) {&lt;br/&gt;        try {&lt;br/&gt;            TimeUnit.MILLISECONDS.sleep(seconds);&lt;br/&gt;        } catch (InterruptedException e) {&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;package org.dance.day2.util;&lt;br/&gt;&lt;br/&gt;import org.dance.tools.SleepTools;&lt;br/&gt;&lt;br/&gt;import java.util.concurrent.CountDownLatch;&lt;br/&gt;&lt;br/&gt;/**&lt;br/&gt; * CountDownLatch的使用,有五个线程,6个扣除点&lt;br/&gt; * 扣除完成后主线程和业务线程,才能执行工作&lt;br/&gt; *  扣除点一般都是大于等于需要初始化的线程的&lt;br/&gt; * @author ZYGisComputer&lt;br/&gt; */&lt;br/&gt;public class UseCountDownLatch {&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 设置为6个扣除点&lt;br/&gt;     */&lt;br/&gt;    static CountDownLatch countDownLatch = new CountDownLatch(6);&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 初始化线程&lt;br/&gt;     */&lt;br/&gt;    private static class InitThread implements Runnable {&lt;br/&gt;&lt;br/&gt;        @Override&lt;br/&gt;        public void &lt;span&gt;&lt;span&gt;run&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;&lt;br/&gt;            System.out.println(&lt;span&gt;&quot;thread_&quot;&lt;/span&gt; + Thread.currentThread().getId() + &lt;span&gt;&quot; ready init work .....&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;            // 执行扣减 扣减不代表结束&lt;br/&gt;            countDownLatch.countDown();&lt;br/&gt;&lt;br/&gt;            &lt;span&gt;for&lt;/span&gt; (int i = 0; i &amp;lt; 2; i++) {&lt;br/&gt;                System.out.println(&lt;span&gt;&quot;thread_&quot;&lt;/span&gt; + Thread.currentThread().getId() + &lt;span&gt;&quot;.....continue do its work&quot;&lt;/span&gt;);&lt;br/&gt;            }&lt;br/&gt;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 业务线程&lt;br/&gt;     */&lt;br/&gt;    private static class BusiThread implements Runnable {&lt;br/&gt;&lt;br/&gt;        @Override&lt;br/&gt;        public void &lt;span&gt;&lt;span&gt;run&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;&lt;br/&gt;            // 业务线程需要在等初始化完毕后才能执行&lt;br/&gt;            try {&lt;br/&gt;                countDownLatch.await();&lt;br/&gt;                &lt;span&gt;for&lt;/span&gt; (int i = 0; i &amp;lt; 3; i++) {&lt;br/&gt;                    System.out.println(&lt;span&gt;&quot;BusiThread &quot;&lt;/span&gt; + Thread.currentThread().getId() + &lt;span&gt;&quot; do business-----&quot;&lt;/span&gt;);&lt;br/&gt;                }&lt;br/&gt;            } catch (InterruptedException e) {&lt;br/&gt;                e.printStackTrace();&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    public static void main(String[] args) {&lt;br/&gt;&lt;br/&gt;        // 创建单独的初始化线程&lt;br/&gt;        new &lt;span&gt;&lt;span&gt;Thread&lt;/span&gt;&lt;/span&gt;(){&lt;br/&gt;            @Override&lt;br/&gt;            public void &lt;span&gt;&lt;span&gt;run&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;                SleepTools.ms(1);&lt;br/&gt;                System.out.println(&lt;span&gt;&quot;thread_&quot;&lt;/span&gt; + Thread.currentThread().getId() + &lt;span&gt;&quot; ready init work step 1st.....&quot;&lt;/span&gt;);&lt;br/&gt;                // 扣减一次&lt;br/&gt;                countDownLatch.countDown();&lt;br/&gt;                System.out.println(&lt;span&gt;&quot;begin stop 2nd.....&quot;&lt;/span&gt;);&lt;br/&gt;                SleepTools.ms(1);&lt;br/&gt;                System.out.println(&lt;span&gt;&quot;thread_&quot;&lt;/span&gt; + Thread.currentThread().getId() + &lt;span&gt;&quot; ready init work step 2nd.....&quot;&lt;/span&gt;);&lt;br/&gt;                // 扣减一次&lt;br/&gt;                countDownLatch.countDown();&lt;br/&gt;&lt;br/&gt;            }&lt;br/&gt;        }.start();&lt;br/&gt;        // 启动业务线程&lt;br/&gt;        new Thread(new BusiThread()).start();&lt;br/&gt;        // 启动初始化线程&lt;br/&gt;        &lt;span&gt;for&lt;/span&gt; (int i = 0; i &amp;lt;= 3; i++) {&lt;br/&gt;            new Thread(new InitThread()).start();&lt;br/&gt;        }&lt;br/&gt;        // 主线程进入等待&lt;br/&gt;        try {&lt;br/&gt;            countDownLatch.await();&lt;br/&gt;            System.out.println(&lt;span&gt;&quot;Main do ites work.....&quot;&lt;/span&gt;);&lt;br/&gt;        } catch (InterruptedException e) {&lt;br/&gt;            e.printStackTrace();&lt;br/&gt;        }&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;返回结果:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;thread_13 ready init work .....&lt;br/&gt;thread_13.....continue &lt;span&gt;do&lt;/span&gt; its work&lt;br/&gt;thread_13.....continue &lt;span&gt;do&lt;/span&gt; its work&lt;br/&gt;thread_14 ready init work .....&lt;br/&gt;thread_14.....continue &lt;span&gt;do&lt;/span&gt; its work&lt;br/&gt;thread_14.....continue &lt;span&gt;do&lt;/span&gt; its work&lt;br/&gt;thread_15 ready init work .....&lt;br/&gt;thread_15.....continue &lt;span&gt;do&lt;/span&gt; its work&lt;br/&gt;thread_11 ready init work step 1st.....&lt;br/&gt;begin stop 2nd.....&lt;br/&gt;thread_16 ready init work .....&lt;br/&gt;thread_16.....continue &lt;span&gt;do&lt;/span&gt; its work&lt;br/&gt;thread_16.....continue &lt;span&gt;do&lt;/span&gt; its work&lt;br/&gt;thread_15.....continue &lt;span&gt;do&lt;/span&gt; its work&lt;br/&gt;thread_11 ready init work step 2nd.....&lt;br/&gt;Main &lt;span&gt;do&lt;/span&gt; ites work.....&lt;br/&gt;BusiThread 12 &lt;span&gt;do&lt;/span&gt; business-----&lt;br/&gt;BusiThread 12 &lt;span&gt;do&lt;/span&gt; business-----&lt;br/&gt;BusiThread 12 &lt;span&gt;do&lt;/span&gt; business-----&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过返回结果就可以很直接的看到业务线程是在初始化线程完全跑完之后,才开始执行的&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;CyclicBarrier:&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CyclicBarrier,俗称栅栏锁,作用是让一组线程到达某个屏障,被阻塞,一直到组内的最后一个线程到达,然后屏障开放,接着,所有的线程继续运行&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个感觉和CountDownLatch有点相似,但是其实是不一样的,所谓的差别,将在下面详解&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CyclicBarrier的构造参数有两个&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;/**&lt;br/&gt;     * Creates a new {@code CyclicBarrier} that will trip when the&lt;br/&gt;     * given number of parties (threads) are waiting upon it, and&lt;br/&gt;     * does not perform a predefined action when the barrier is tripped.&lt;br/&gt;     *&lt;br/&gt;     * @param parties the number of threads that must invoke {@link &lt;span&gt;#await}&lt;/span&gt;&lt;br/&gt;     *        before the barrier is tripped&lt;br/&gt;     * @throws IllegalArgumentException &lt;span&gt;if&lt;/span&gt; {@code parties} is less than 1&lt;br/&gt;     */&lt;br/&gt;    public CyclicBarrier(int parties) {&lt;br/&gt;        this(parties, null);&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;/**&lt;br/&gt;     * Creates a new {@code CyclicBarrier} that will trip when the&lt;br/&gt;     * given number of parties (threads) are waiting upon it, and &lt;span&gt;which&lt;/span&gt;&lt;br/&gt;     * will execute the given barrier action when the barrier is tripped,&lt;br/&gt;     * performed by the last thread entering the barrier.&lt;br/&gt;     *&lt;br/&gt;     * @param parties the number of threads that must invoke {@link &lt;span&gt;#await}&lt;/span&gt;&lt;br/&gt;     *        before the barrier is tripped&lt;br/&gt;     * @param barrierAction the &lt;span&gt;command&lt;/span&gt; to execute when the barrier is&lt;br/&gt;     *        tripped, or {@code null} &lt;span&gt;if&lt;/span&gt; there is no action&lt;br/&gt;     * @throws IllegalArgumentException &lt;span&gt;if&lt;/span&gt; {@code parties} is less than 1&lt;br/&gt;     */&lt;br/&gt;    public CyclicBarrier(int parties, Runnable barrierAction) {&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (parties &amp;lt;= 0) throw new IllegalArgumentException();&lt;br/&gt;        this.parties = parties;&lt;br/&gt;        this.count = parties;&lt;br/&gt;        this.barrierCommand = barrierAction;&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很明显能感觉出来,上面的构造参数调用了下面的构造参数,是一个构造方法重载&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先这个第一个参数也树Int类型的,传入的是执行线程的个数,这个数量和CountDownLatch不一样,这个数量是需要和线程数量吻合的,CountDownLatch则不一样,CountDownLatch可以大于等于,而CyclicBarrier只能等于,然后是第二个参数,第二个参数是barrierAction,这个参数是当屏障开放后,执行的任务线程,如果当屏障开放后需要执行什么任务,可以写在这个线程中&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6170212765957447&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1QxwhpDy7ia04oPHkc1mY76tdSW4uyt2ic3OW3YhDy5wHnwtRj20xvgJHKP8dtzh3Qq9dkPibHBAKb33YhO3BmuTg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;799&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主线程创建CyclicBarrier(3,barrierAction),然后由线程开始执行,线程A,B执行完成后都调用了await,然后他们都在一个屏障前阻塞者,需要等待线程C也,执行完成,调用await之后,然后三个线程都达到屏障后,屏障开放,然后线程继续执行,并且barrierAction在屏障开放的一瞬间也开始执行&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上代码:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;package org.dance.day2.util;&lt;br/&gt;&lt;br/&gt;import org.dance.tools.SleepTools;&lt;br/&gt;&lt;br/&gt;import java.util.Map;&lt;br/&gt;import java.util.Random;&lt;br/&gt;import java.util.concurrent.BrokenBarrierException;&lt;br/&gt;import java.util.concurrent.ConcurrentHashMap;&lt;br/&gt;import java.util.concurrent.CyclicBarrier;&lt;br/&gt;&lt;br/&gt;/**&lt;br/&gt; * CyclicBarrier的使用&lt;br/&gt; *&lt;br/&gt; * @author ZYGisComputer&lt;br/&gt; */&lt;br/&gt;public class UseCyclicBarrier {&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 存放子线程工作结果的安全容器&lt;br/&gt;     */&lt;br/&gt;    private static ConcurrentHashMap&amp;lt;String, Long&amp;gt; resultMap = new ConcurrentHashMap&amp;lt;&amp;gt;();&lt;br/&gt;&lt;br/&gt;    private static CyclicBarrier cyclicBarrier = new CyclicBarrier(5,new CollectThread());&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 结果打印线程&lt;br/&gt;     * 用来演示CyclicBarrier的第二个参数,barrierAction&lt;br/&gt;     */&lt;br/&gt;    private static class CollectThread implements Runnable {&lt;br/&gt;&lt;br/&gt;        @Override&lt;br/&gt;        public void &lt;span&gt;&lt;span&gt;run&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;&lt;br/&gt;            StringBuffer result = new StringBuffer();&lt;br/&gt;&lt;br/&gt;            &lt;span&gt;for&lt;/span&gt; (Map.Entry&amp;lt;String, Long&amp;gt; workResult : resultMap.entrySet()) {&lt;br/&gt;                result.append(&lt;span&gt;&quot;[&quot;&lt;/span&gt; + workResult.getValue() + &lt;span&gt;&quot;]&quot;&lt;/span&gt;);&lt;br/&gt;            }&lt;br/&gt;&lt;br/&gt;            System.out.println(&lt;span&gt;&quot;the result = &quot;&lt;/span&gt; + result);&lt;br/&gt;            System.out.println(&lt;span&gt;&quot;do other business.....&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 工作子线程&lt;br/&gt;     * 用于CyclicBarrier的一组线程&lt;br/&gt;     */&lt;br/&gt;    private static class SubThread implements Runnable {&lt;br/&gt;&lt;br/&gt;        @Override&lt;br/&gt;        public void &lt;span&gt;&lt;span&gt;run&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;&lt;br/&gt;            // 获取当前线程的ID&lt;br/&gt;            long id = Thread.currentThread().getId();&lt;br/&gt;&lt;br/&gt;            // 放入统计容器中&lt;br/&gt;            resultMap.put(String.valueOf(id), id);&lt;br/&gt;&lt;br/&gt;            Random random = new Random();&lt;br/&gt;&lt;br/&gt;            try {&lt;br/&gt;                &lt;span&gt;if&lt;/span&gt; (random.nextBoolean()) {&lt;br/&gt;                    Thread.sleep(1000 + id);&lt;br/&gt;                    System.out.println(&lt;span&gt;&quot;Thread_&quot;&lt;/span&gt;+id+&lt;span&gt;&quot;..... do something&quot;&lt;/span&gt;);&lt;br/&gt;                }&lt;br/&gt;                System.out.println(id+&lt;span&gt;&quot; is await&quot;&lt;/span&gt;);&lt;br/&gt;                cyclicBarrier.await();&lt;br/&gt;                Thread.sleep(1000+id);&lt;br/&gt;                System.out.println(&lt;span&gt;&quot;Thread_&quot;&lt;/span&gt;+id+&lt;span&gt;&quot;.....do its business&quot;&lt;/span&gt;);&lt;br/&gt;            } catch (InterruptedException e) {&lt;br/&gt;                e.printStackTrace();&lt;br/&gt;            } catch (BrokenBarrierException e) {&lt;br/&gt;                e.printStackTrace();&lt;br/&gt;            }&lt;br/&gt;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    public static void main(String[] args) {&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;for&lt;/span&gt; (int i = 0; i &amp;lt;= 4; i++) {&lt;br/&gt;            Thread thread = new Thread(new SubThread());&lt;br/&gt;            thread.start();&lt;br/&gt;        }&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;返回结果:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;11 is await&lt;br/&gt;14 is await&lt;br/&gt;15 is await&lt;br/&gt;Thread_12..... &lt;span&gt;do&lt;/span&gt; something&lt;br/&gt;12 is await&lt;br/&gt;Thread_13..... &lt;span&gt;do&lt;/span&gt; something&lt;br/&gt;13 is await&lt;br/&gt;the result = [11][12][13][14][15]&lt;br/&gt;&lt;span&gt;do&lt;/span&gt; other business.....&lt;br/&gt;Thread_11.....do its business&lt;br/&gt;Thread_12.....do its business&lt;br/&gt;Thread_13.....do its business&lt;br/&gt;Thread_14.....do its business&lt;br/&gt;Thread_15.....do its business&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过返回结果可以看出前面的11 14 15三个线程没有进入if语句块,在执行到await的时候进入了等待,而另外12 13两个线程进入到了if语句块当中,多休眠了1秒多,然后当5个线程同时到达await的时候,屏障开放,执行了barrierAction线程,然后线程组继续执行&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;解释一下CountDownLatch和CyclicBarrier的却别吧!&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先就是CountDownLatch的构造参数传入的数量一般都是大于等于线程,数量的,因为他是有第三方控制的,可以扣减多次,然后就是CyclicBarrier的构造参数第一个参数传入的数量一定是等于线程的个数的,因为他是由一组线程自身控制的&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;区别&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CountDownLatch　　CyclicBarrier&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;控制　　    第三方控制　　　　  自身控制&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;传入数量　　大于等于线程数量    等于线程数量&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Semaphore:&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Semaphore,俗称信号量,作用于控制同时访问某个特定资源的线程数量,用在流量控制&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一说特定资源控制,那么第一时间就想到了数据库连接..&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前用等待超时模式写了一个数据库连接池,打算用这个Semaphone也写一个&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;/**&lt;br/&gt;     * Creates a {@code Semaphore} with the given number of&lt;br/&gt;     * permits and nonfair fairness setting.&lt;br/&gt;     *&lt;br/&gt;     * @param permits the initial number of permits available.&lt;br/&gt;     *        This value may be negative, &lt;span&gt;in&lt;/span&gt; &lt;span&gt;which&lt;/span&gt; &lt;span&gt;case&lt;/span&gt; releases&lt;br/&gt;     *        must occur before any acquires will be granted.&lt;br/&gt;     */&lt;br/&gt;    public Semaphore(int permits) {&lt;br/&gt;        sync = new NonfairSync(permits);&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在源码中可以看到在构建Semaphore信号量的时候,需要传入许可证的数量,这个数量就是资源的最大允许的访问的线程数&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下里用信号量实现一个数据库连接池&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;连接对象&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;package org.dance.day2.util.pool;&lt;br/&gt;&lt;br/&gt;import org.dance.tools.SleepTools;&lt;br/&gt;&lt;br/&gt;import java.sql.*;&lt;br/&gt;import java.util.Map;&lt;br/&gt;import java.util.Properties;&lt;br/&gt;import java.util.concurrent.Executor;&lt;br/&gt;&lt;br/&gt;/**&lt;br/&gt; * 数据库连接&lt;br/&gt; * @author ZYGisComputer&lt;br/&gt; */&lt;br/&gt;public class SqlConnection implements Connection {&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 获取数据库连接&lt;br/&gt;     * @&lt;span&gt;return&lt;/span&gt;&lt;br/&gt;     */&lt;br/&gt;    public static final Connection &lt;span&gt;&lt;span&gt;fetchConnection&lt;/span&gt;&lt;/span&gt;(){&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; new SqlConnection();&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void commit() throws SQLException {&lt;br/&gt;        SleepTools.ms(70);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public Statement createStatement() throws SQLException {&lt;br/&gt;        SleepTools.ms(1);&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public PreparedStatement prepareStatement(String sql) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public CallableStatement prepareCall(String sql) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public String nativeSQL(String sql) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void setAutoCommit(boolean autoCommit) throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public boolean getAutoCommit() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void rollback() throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void close() throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public boolean isClosed() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public DatabaseMetaData getMetaData() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void setReadOnly(boolean readOnly) throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public boolean isReadOnly() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void setCatalog(String catalog) throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public String getCatalog() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void setTransactionIsolation(int level) throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public int getTransactionIsolation() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; 0;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public SQLWarning getWarnings() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void clearWarnings() throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public Statement createStatement(int resultSetType, int resultSetConcurrency) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public PreparedStatement prepareStatement(String sql, int resultSetType, int resultSetConcurrency) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public CallableStatement prepareCall(String sql, int resultSetType, int resultSetConcurrency) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public Map&amp;lt;String, Class&amp;lt;?&amp;gt;&amp;gt; getTypeMap() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void setTypeMap(Map&amp;lt;String, Class&amp;lt;?&amp;gt;&amp;gt; map) throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void setHoldability(int holdability) throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public int getHoldability() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; 0;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public Savepoint setSavepoint() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public Savepoint setSavepoint(String name) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void rollback(Savepoint savepoint) throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void releaseSavepoint(Savepoint savepoint) throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public Statement createStatement(int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public PreparedStatement prepareStatement(String sql, int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public CallableStatement prepareCall(String sql, int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public PreparedStatement prepareStatement(String sql, int autoGeneratedKeys) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public PreparedStatement prepareStatement(String sql, int[] columnIndexes) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public PreparedStatement prepareStatement(String sql, String[] columnNames) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public Clob createClob() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public Blob createBlob() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public NClob createNClob() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public SQLXML createSQLXML() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public boolean isValid(int timeout) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void setClientInfo(String name, String value) throws SQLClientInfoException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void setClientInfo(Properties properties) throws SQLClientInfoException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public String getClientInfo(String name) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public Properties getClientInfo() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public Array createArrayOf(String typeName, Object[] elements) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public Struct createStruct(String typeName, Object[] attributes) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void setSchema(String schema) throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public String getSchema() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void abort(Executor executor) throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public void setNetworkTimeout(Executor executor, int milliseconds) throws SQLException {&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public int getNetworkTimeout() throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; 0;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public &amp;lt;T&amp;gt; T unwrap(Class&amp;lt;T&amp;gt; iface) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; null;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    @Override&lt;br/&gt;    public boolean isWrapperFor(Class&amp;lt;?&amp;gt; iface) throws SQLException {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;连接池对象&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;package org.dance.day2.util.pool;&lt;br/&gt;&lt;br/&gt;import java.sql.Connection;&lt;br/&gt;import java.util.ArrayList;&lt;br/&gt;import java.util.HashSet;&lt;br/&gt;import java.util.Iterator;&lt;br/&gt;import java.util.LinkedList;&lt;br/&gt;import java.util.concurrent.Semaphore;&lt;br/&gt;&lt;br/&gt;/**&lt;br/&gt; * 使用信号量控制数据库的链接和释放&lt;br/&gt; *&lt;br/&gt; * @author ZYGisComputer&lt;br/&gt; */&lt;br/&gt;public class DBPoolSemaphore {&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 池容量&lt;br/&gt;     */&lt;br/&gt;    private final static int POOL_SIZE = 10;&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * useful 代表可用连接&lt;br/&gt;     * useless 代表已用连接&lt;br/&gt;     *  为什么要使用两个Semaphore呢?是因为,在连接池中不只有连接本身是资源,空位也是资源,也需要记录&lt;br/&gt;     */&lt;br/&gt;    private final Semaphore useful, useless;&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 连接池&lt;br/&gt;     */&lt;br/&gt;    private final static LinkedList&amp;lt;Connection&amp;gt; POOL = new LinkedList&amp;lt;&amp;gt;();&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 使用静态块初始化池&lt;br/&gt;     */&lt;br/&gt;    static {&lt;br/&gt;        &lt;span&gt;for&lt;/span&gt; (int i = 0; i &amp;lt; POOL_SIZE; i++) {&lt;br/&gt;            POOL.addLast(SqlConnection.fetchConnection());&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    public &lt;span&gt;&lt;span&gt;DBPoolSemaphore&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;        // 初始可用的许可证等于池容量&lt;br/&gt;        useful = new Semaphore(POOL_SIZE);&lt;br/&gt;        // 初始不可用的许可证容量为0&lt;br/&gt;        useless = new Semaphore(0);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 获取数据库连接&lt;br/&gt;     *&lt;br/&gt;     * @&lt;span&gt;return&lt;/span&gt; 连接对象&lt;br/&gt;     */&lt;br/&gt;    public Connection takeConnection() throws InterruptedException {&lt;br/&gt;        // 可用许可证减一&lt;br/&gt;        useful.acquire();&lt;br/&gt;        Connection connection;&lt;br/&gt;        synchronized (POOL) {&lt;br/&gt;            connection = POOL.removeFirst();&lt;br/&gt;        }&lt;br/&gt;        // 不可用许可证数量加一&lt;br/&gt;        useless.release();&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; connection;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 释放链接&lt;br/&gt;     *&lt;br/&gt;     * @param connection 连接对象&lt;br/&gt;     */&lt;br/&gt;    public void returnConnection(Connection connection) throws InterruptedException {&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt;(null!=connection){&lt;br/&gt;            // 打印日志&lt;br/&gt;            System.out.println(&lt;span&gt;&quot;当前有&quot;&lt;/span&gt;+useful.getQueueLength()+&lt;span&gt;&quot;个线程等待获取连接,,&quot;&lt;/span&gt;&lt;br/&gt;                    +&lt;span&gt;&quot;可用连接有&quot;&lt;/span&gt;+useful.availablePermits()+&lt;span&gt;&quot;个&quot;&lt;/span&gt;);&lt;br/&gt;            // 不可用许可证减一&lt;br/&gt;            useless.acquire();&lt;br/&gt;            synchronized (POOL){&lt;br/&gt;                POOL.addLast(connection);&lt;br/&gt;            }&lt;br/&gt;            // 可用许可证加一&lt;br/&gt;            useful.release();&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;测试类:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;package org.dance.day2.util.pool;&lt;br/&gt;&lt;br/&gt;import org.dance.tools.SleepTools;&lt;br/&gt;&lt;br/&gt;import java.sql.Connection;&lt;br/&gt;import java.util.Random;&lt;br/&gt;&lt;br/&gt;/**&lt;br/&gt; * 测试Semaphore&lt;br/&gt; * @author ZYGisComputer&lt;br/&gt; */&lt;br/&gt;public class UseSemaphore {&lt;br/&gt;&lt;br/&gt;    /**&lt;br/&gt;     * 连接池&lt;br/&gt;     */&lt;br/&gt;    public static final DBPoolSemaphore pool = new DBPoolSemaphore();&lt;br/&gt;&lt;br/&gt;    private static class BusiThread extends Thread{&lt;br/&gt;        @Override&lt;br/&gt;        public void &lt;span&gt;&lt;span&gt;run&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;            // 随机数工具类 为了让每个线程持有连接的时间不一样&lt;br/&gt;            Random random = new Random();&lt;br/&gt;            long start = System.currentTimeMillis();&lt;br/&gt;            try {&lt;br/&gt;                Connection connection = pool.takeConnection();&lt;br/&gt;                System.out.println(&lt;span&gt;&quot;Thread_&quot;&lt;/span&gt;+Thread.currentThread().getId()+&lt;br/&gt;                        &lt;span&gt;&quot;_获取数据库连接耗时[&quot;&lt;/span&gt;+(System.currentTimeMillis()-start)+&lt;span&gt;&quot;]ms.&quot;&lt;/span&gt;);&lt;br/&gt;                // 模拟使用连接查询数据&lt;br/&gt;                SleepTools.ms(100+random.nextInt(100));&lt;br/&gt;                System.out.println(&lt;span&gt;&quot;查询数据完成归还连接&quot;&lt;/span&gt;);&lt;br/&gt;                pool.returnConnection(connection);&lt;br/&gt;            } catch (InterruptedException e) {&lt;br/&gt;                e.printStackTrace();&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    public static void main(String[] args) {&lt;br/&gt;        &lt;span&gt;for&lt;/span&gt; (int i = 0; i &amp;lt; 50; i++) {&lt;br/&gt;            BusiThread busiThread = new BusiThread();&lt;br/&gt;            busiThread.start();&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;测试返回结果:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;Thread_11_获取数据库连接耗时[0]ms.&lt;br/&gt;Thread_12_获取数据库连接耗时[0]ms.&lt;br/&gt;Thread_13_获取数据库连接耗时[0]ms.&lt;br/&gt;Thread_14_获取数据库连接耗时[0]ms.&lt;br/&gt;Thread_15_获取数据库连接耗时[0]ms.&lt;br/&gt;Thread_16_获取数据库连接耗时[0]ms.&lt;br/&gt;Thread_17_获取数据库连接耗时[0]ms.&lt;br/&gt;Thread_18_获取数据库连接耗时[0]ms.&lt;br/&gt;Thread_19_获取数据库连接耗时[0]ms.&lt;br/&gt;Thread_20_获取数据库连接耗时[0]ms.&lt;br/&gt;查询数据完成归还连接&lt;br/&gt;当前有40个线程等待获取连接,,可用连接有0个&lt;br/&gt;Thread_21_获取数据库连接耗时[112]ms.&lt;br/&gt;查询数据完成归还连接&lt;br/&gt;...................&lt;br/&gt;查询数据完成归还连接&lt;br/&gt;当前有2个线程等待获取连接,,可用连接有0个&lt;br/&gt;Thread_59_获取数据库连接耗时[637]ms.&lt;br/&gt;查询数据完成归还连接&lt;br/&gt;当前有1个线程等待获取连接,,可用连接有0个&lt;br/&gt;Thread_60_获取数据库连接耗时[660]ms.&lt;br/&gt;查询数据完成归还连接&lt;br/&gt;当前有0个线程等待获取连接,,可用连接有0个&lt;br/&gt;查询数据完成归还连接&lt;br/&gt;...................&lt;br/&gt;当前有0个线程等待获取连接,,可用连接有8个&lt;br/&gt;查询数据完成归还连接&lt;br/&gt;当前有0个线程等待获取连接,,可用连接有9个&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过执行结果可以很明确的看到,一上来就有10个线程获取到了连接,,然后后面的40个线程进入阻塞,然后只有释放链接之后,等待的线程就会有一个拿到,然后越后面的线程等待的时间就越长,然后一直到所有的线程执行完毕&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后打印的可用连接有九个不是因为少了一个是因为在释放之前打印的,不是错误&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从结果中可以看到,我们对连接池中的资源的到了控制,这就是信号量的流量控制&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;Exchanger:&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Exchanger,俗称交换器,用于在线程之间交换数据,但是比较受限,因为只能两个线程之间交换数据&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;/**&lt;br/&gt;     * Creates a new Exchanger.&lt;br/&gt;     */&lt;br/&gt;    public &lt;span&gt;&lt;span&gt;Exchanger&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;        participant = new Participant();&lt;br/&gt;    }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个构造函数没有什么好说的,也没有入参,只有在创建的时候指定一下需要交换的数据的泛型即可,下面看代码&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;package org.dance.day2.util;&lt;br/&gt;&lt;br/&gt;import java.util.HashSet;&lt;br/&gt;import java.util.Set;&lt;br/&gt;import java.util.concurrent.Exchanger;&lt;br/&gt;&lt;br/&gt;/**&lt;br/&gt; * 线程之间交换数据&lt;br/&gt; * @author ZYGisComputer&lt;br/&gt; */&lt;br/&gt;public class UseExchange {&lt;br/&gt;&lt;br/&gt;    private static final Exchanger&amp;lt;Set&amp;lt;String&amp;gt;&amp;gt; exchanger = new Exchanger&amp;lt;&amp;gt;();&lt;br/&gt;&lt;br/&gt;    public static void main(String[] args) {&lt;br/&gt;&lt;br/&gt;        new &lt;span&gt;&lt;span&gt;Thread&lt;/span&gt;&lt;/span&gt;(){&lt;br/&gt;            @Override&lt;br/&gt;            public void &lt;span&gt;&lt;span&gt;run&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;                Set&amp;lt;String&amp;gt; aSet = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;                aSet.add(&lt;span&gt;&quot;A&quot;&lt;/span&gt;);&lt;br/&gt;                aSet.add(&lt;span&gt;&quot;B&quot;&lt;/span&gt;);&lt;br/&gt;                aSet.add(&lt;span&gt;&quot;C&quot;&lt;/span&gt;);&lt;br/&gt;                try {&lt;br/&gt;                    Set&amp;lt;String&amp;gt; exchange = exchanger.exchange(aSet);&lt;br/&gt;                    &lt;span&gt;for&lt;/span&gt; (String s : exchange) {&lt;br/&gt;                        System.out.println(&lt;span&gt;&quot;aSet&quot;&lt;/span&gt;+s);&lt;br/&gt;                    }&lt;br/&gt;                } catch (InterruptedException e) {&lt;br/&gt;                    e.printStackTrace();&lt;br/&gt;                }&lt;br/&gt;            }&lt;br/&gt;        }.start();&lt;br/&gt;&lt;br/&gt;        new &lt;span&gt;&lt;span&gt;Thread&lt;/span&gt;&lt;/span&gt;(){&lt;br/&gt;            @Override&lt;br/&gt;            public void &lt;span&gt;&lt;span&gt;run&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;                Set&amp;lt;String&amp;gt; bSet = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;                bSet.add(&lt;span&gt;&quot;1&quot;&lt;/span&gt;);&lt;br/&gt;                bSet.add(&lt;span&gt;&quot;2&quot;&lt;/span&gt;);&lt;br/&gt;                bSet.add(&lt;span&gt;&quot;3&quot;&lt;/span&gt;);&lt;br/&gt;                try {&lt;br/&gt;                    Set&amp;lt;String&amp;gt; exchange = exchanger.exchange(bSet);&lt;br/&gt;                    &lt;span&gt;for&lt;/span&gt; (String s : exchange) {&lt;br/&gt;                        System.out.println(&lt;span&gt;&quot;bSet&quot;&lt;/span&gt;+s);&lt;br/&gt;                    }&lt;br/&gt;                } catch (InterruptedException e) {&lt;br/&gt;                    e.printStackTrace();&lt;br/&gt;                }&lt;br/&gt;            }&lt;br/&gt;        }.start();&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;执行结果:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;bSetA&lt;br/&gt;bSetB&lt;br/&gt;bSetC&lt;br/&gt;aSet1&lt;br/&gt;aSet2&lt;br/&gt;aSet3&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过执行结果可以清晰的看到,两个线程中的数据发生了交换,这就是Exchanger的线程数据交换了&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上就是JUC的4大常用并发工具类了&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>