<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>2ee9f6222fa110d9e3f034bd3e6ee7c0</guid>
<title>云计算的全球变局与中国故事</title>
<link>https://toutiao.io/k/9z6dese</link>
<content:encoded>&lt;div&gt;&lt;body id=&quot;readabilityBody&quot;&gt;
&lt;p id=&quot;app&quot;/&gt;
&lt;img src=&quot;https://static001.infoq.cn/static/infoq/img/logo-121-75.yuij86g.png&quot; alt=&quot;云计算的全球变局与中国故事_云原生_刘燕_InfoQ精选文章&quot;/&gt;





    

&lt;/body&gt;
&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>eb316818b048377a71f5cf41df051011</guid>
<title>介绍一个数据血缘的项目 OpenLineage</title>
<link>https://toutiao.io/k/pb9ns85</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;h4&gt;&lt;span&gt;背景&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;“大数据”这个概念逐渐深入人心，很多公司都面临的着：&lt;/p&gt;&lt;p&gt;总的来说，就是“大数据”中的“大”不仅仅是数据量大，也指的是数据种类多、数据来源复杂，不同的数据被各式各样的人使用。如何发现数据，确定数据的来龙去脉就成了一个急迫的问题。&lt;/p&gt;&lt;p&gt;OpenLineage 应运而生。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;介绍 OpenLineage&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;OpenLineage 可以翻译成开源血缘。按照这个项目的发起者 Julien Le Dem 的说法，“数据血缘需要遵循开源社区贡献者商定的标准，以保证其各自解决方案生成的元数据的兼容性和一致性。”&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Data lineage needs to follow a standard agreed upon by contributors to the open source community to guarantee the compatibility and consistency of the metadata produced by their respective solutions.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;它回答的问题是：“谁生产数据？它是如何转变的？谁在使用它？数据血缘是 DataOps 的支柱，它提供了对组织内数据旅程中系统和数据集交互的可见性。”&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Data lineage is the backbone of DataOps, providing visibility into the interaction of systems and datasets across the journey of data within an organization.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;也给出了一个可用的数据血缘应该满足什么样的要求。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它不仅需要捕获正在生成的数据集之间的依赖关系，还需要捕获生成和转换它们的业务逻辑&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这些数据集和程序中的每一个都需要有一种统一命名的形式，以便可以轻松识别并跨不同域统一访问&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这些数据集和程序中的所有变化都需要以细粒度和自动方式进行跟踪和版本控制，以更好地了解整个生态系统随时间的演变&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;考虑到它需要支持的各种用例，描述这些数据集和程序的元数据需要灵活且可扩展&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现在的 OpenLineage 的参与者包括了下面的一些开源项目：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Airflow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Amundsen&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Datahub&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;dbt&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Egeria&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Great Expectations&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Iceberg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Marquez&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Pandas&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Parquet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Prefect&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Spark&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Superset&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;&lt;span&gt;OpenLineage 概览&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;正如上面列举的参与 OpenLineage 的项目，它们都有着独特的设计理念和实现思路，让数据发现平台去和这些计算引擎一对一对接的话，就会变成复杂的网状的的链路。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4766666666666667&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;300&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAiclJSTyNpeJk78iaJ0Rqq1dZCsGGIk8y4N8gcwlmdRK1HRaqDGW3p76Jg/640?wx_fmt=png&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;而 OpenLineage 起到了中间件的作用，负责沟通上下游。&lt;br/&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5154639175257731&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;291&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAicWqJwbOOa81hSs1JwSicX0CvFEr1XyUCgw7yyGUkdjJ8bIP5kqH6MbqA/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;&lt;p&gt;作为一个中间件，就是抛去所有花里胡哨的特性，直击本质。也就是上面提到的三个问题：&lt;/p&gt;&lt;p&gt;OpenLineage 的回答就是它的核心数据模型&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6382978723404256&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;940&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAicY1o085MZ2RofngfeQXLOicKpYXlfC6GGlsMHo5RVF5WqfjCrg30WXdQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;Run 和 Job 回答的是“它是如何转变的？”，Inputs/Outputs 回答的是“谁生产数据”/“谁在使用它”。在  OpenLineage 的核心数据模型设计中，它没有选择实现更细节，也更麻烦的列级别血缘，而是只做到了表级别的血缘。在我看来，这个选择是非常棒的，因为要选择实现列级别的血缘，每一种特定类型的 SQL 势必要绑定对应的 SQL 解释器，这就让 OpenLineage 变得复杂，就谈不上通用的标准了。&lt;/p&gt;&lt;p&gt;OpenLineage 的表达方式选择了 Json 格式，具体细节可以参考：https://github.com/OpenLineage/OpenLineage/blob/main/spec/OpenLineage.md&lt;/p&gt;&lt;pre&gt;&lt;code&gt;{&lt;br/&gt;  &lt;span&gt;&quot;eventType&quot;&lt;/span&gt;: &lt;span&gt;&quot;START&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;eventTime&quot;&lt;/span&gt;: &lt;span&gt;&quot;2020-12-09T23:37:31.081Z&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;run&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;runId&quot;&lt;/span&gt;: &lt;span&gt;&quot;3b452093-782c-4ef2-9c0c-aafe2aa6f34d&quot;&lt;/span&gt;,&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;&quot;job&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;namespace&quot;&lt;/span&gt;: &lt;span&gt;&quot;my-scheduler-namespace&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;name&quot;&lt;/span&gt;: &lt;span&gt;&quot;myjob.mytask&quot;&lt;/span&gt;,&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;&quot;inputs&quot;&lt;/span&gt;: [&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;namespace&quot;&lt;/span&gt;: &lt;span&gt;&quot;my-datasource-namespace&quot;&lt;/span&gt;,&lt;br/&gt;      &lt;span&gt;&quot;name&quot;&lt;/span&gt;: &lt;span&gt;&quot;instance.schema.table&quot;&lt;/span&gt;,&lt;br/&gt;    }&lt;br/&gt;  ],&lt;br/&gt;  &lt;span&gt;&quot;outputs&quot;&lt;/span&gt;: [&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;namespace&quot;&lt;/span&gt;: &lt;span&gt;&quot;my-datasource-namespace&quot;&lt;/span&gt;,&lt;br/&gt;      &lt;span&gt;&quot;name&quot;&lt;/span&gt;: &lt;span&gt;&quot;instance.schema.output_table&quot;&lt;/span&gt;,&lt;br/&gt;    }&lt;br/&gt;  ],&lt;br/&gt;  &lt;span&gt;&quot;producer&quot;&lt;/span&gt;: &lt;span&gt;&quot;https://github.com/OpenLineage/OpenLineage/blob/v1-0-0/client&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;schemaURL&quot;&lt;/span&gt;: &lt;span&gt;&quot;https://openlineage.io/spec/1-0-0/OpenLineage.json#/definitions/RunEvent&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;&lt;span&gt;介绍 Marquez&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;空有标准，没有实现是没有意义的，OpenLineage 官方推荐的实现是 Marquez。它和 Databub、Amundsen 类似，长得像下面这样。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6084745762711864&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1180&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAicsD7iaO8eAF0dVN3QQmQQqD6icezS7kWUc6EzkbPE3t5UCLL21zNJqJFA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.53&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1800&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAicXicmVfHs4icSrsu3eAjQeCsOcY4EuEhFiaMp0JwcDUoLGRpuIONzPBYjg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;OpenLineage 是一个有野心的项目，它想和 HDFS 变成了分布式文件系统通用标准一样，变成数据血缘的通用标准。但是 OpenLineage 从 2020 年发布到现在，Databub、Amundsen 并没有受到 OpenLineage 的影响，依旧在按照项目自身的发展路径前进。&lt;/p&gt;&lt;p&gt;从个人实践来看，我很喜欢这个项目。国内很多谈数据治理的文章，都是在讲规章制度和规范这些，至于具体的落实，基本上很少会涉及，特别是像把数据血缘做成标准，可以让各种各样的数据计算引擎以同一套标准接入，就几乎上没有了。毕竟光讲理念、规章和制度，不去谈实现，略有“好高骛远”的嫌疑。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;参考链接&lt;/span&gt;&lt;/h4&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://datakin.com/introducing-openlineage/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://github.com/OpenLineage/OpenLineage&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://openlineage.io/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8b16dc0d9fec58f267ee028d502dfd85</guid>
<title>刨根问底: Kafka 到底会不会丢数据？</title>
<link>https://toutiao.io/k/909ukbu</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;em&gt;&lt;span/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;阅读本文大约需要 30 分钟。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;那么 Kafka 到底会不会丢数据呢？如果丢数据，究竟该怎么解决呢？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;只有掌握了这些， 我们才能处理好 Kafka 生产级的一些故障，从而更稳定地服务业务。&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;认真读完这篇文章，我相信你会对Kafka 如何解决丢数据问题，有更加深刻的理解。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;这篇文章干货很多，希望你可以耐心读完。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.599290780141844&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgDMV2ZHaB5kf106rAXEfTHvztibRqyYzYzTAaQYxlxRk7aNbGzsA0ZDEw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1410&quot;/&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;01 总体概述&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;越来越多的互联网公司使用消息队列来支撑自己的核心业务。由于是核心业务，一般都会要求消息传递过程中最大限度的做到不丢失，如果中间环节出现数据丢失，就会引来用户的投诉，年底绩效就要背锅了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么使用 Kafka 到底会不会丢数据呢？如果丢数据了该怎么解决呢？为了避免类似情况发生，除了要做好补偿措施，我们更应该在系统设计的时候充分考虑系统中的各种异常情况，从而设计出一个稳定可靠的消息系统。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家都知道 Kafka 的整个架构非常简洁，是分布式的架构，主要由 Producer、Broker、Consumer 三部分组成，后面剖析丢失场景会从这三部分入手来剖析。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4658730158730159&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoy608FibvOZ3G3oUeCm1weLtKg0t7fed0PZGTjX3rAkv0rjeyPnNs5FCoiakrj3dObYvwGU1FAmib8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1260&quot;/&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;02 消息传递语义剖析&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在深度剖析消息丢失场景之前，我们先来聊聊&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;消息传递语义&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;&lt;span&gt;到底是个什么玩意？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所谓的消息传递语义是 Kafka 提供的 Producer 和 Consumer 之间的消息传递过程中消息传递的保证性。主要分为三种， 如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.30466666666666664&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgD5VoCylicDO5Jhy4CTTL9RM4MgVrDXOic1FXWgibOVcxUGsFTC2tjyJBnA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1500&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）首先当 Producer 向 Broker 发送数据后，会进行 commit，&lt;span&gt;如果 commit 成功，&lt;/span&gt;由于 Replica 副本机制的存在，则意味着消息不会丢失，但是 Producer 发送数据给 Broker 后，遇到网络问题而造成通信中断，那么 Producer 就无法准确判断该消息是否已经被提交（commit），这就可能造成 at least once 语义&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）在 Kafka 0.11.0.0 之前， 如果 Producer 没有收到消息 commit 的响应结果，它只能重新发送消息，确保消息已经被正确的传输到 Broker，重新发送的时候会将消息再次写入日志中；而在 0.11.0.0 版本之后， Producer 支持幂等传递选项，保证重新发送不会导致消息在日志出现重复&lt;/span&gt;。&lt;span&gt;为了实现这个, Broker 为 Producer 分配了一个ID，并通过每条消息的序列号进行去重。也支持了类似事务语义来保证将消息发送到多个 Topic 分区中，保证所有消息要么都写入成功，要么都失败，这个主要用在 Topic 之间的 exactly once 语义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;其中启用幂等传递的方法配置&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：enable.idempotence = true。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;启用事务支持的方法配置&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：设置属性 transcational.id = &quot;指定值&quot;。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）从 Consumer 角度来剖析, 我们知道 Offset 是由 Consumer 自己来维护的, 如果 Consumer 收到消息后更新 Offset， 这时 Consumer 异常 crash 掉， 那么新的 Consumer 接管后再次重启消费，就会造成 at most once 语义（消息会丢，但不重复）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4) 如果 Consumer 消费消息完成后, 再更新 Offset， 如果这时 Consumer crash 掉，那么新的 Consumer 接管后重新用这个 Offset 拉取消息， 这时就会造成 at least once 语义（消息不丢，但被多次重复处理）。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;总结：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;默认 Kafka 提供 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;at least once&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;span&gt;语义的消息传递&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;&lt;span&gt;允许用户通过在处理消息之前保存 Offset 的方式提供 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;at most once&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt; 语义。如果我们可以自己实现消费幂等，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;理想情况下这个系统的消息传递就是严格的&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;exactly once&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」, &lt;/span&gt;&lt;span&gt;也就是保证不丢失、且只会被精确的处理一次，但是这样是很难做到的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 Kafka 整体架构图我们可以得出有三次消息传递的过程：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1）Producer 端发送消息给 Kafka Broker 端。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）Kafka Broker 将消息进行同步并持久化数据。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）&lt;strong&gt;&lt;span&gt;Consumer 端从 &lt;/span&gt;&lt;/strong&gt;Kafka Broker 将消息拉取并进行消费。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在以上这三步中每一步都可能会出现丢失数据的情况， 那么 Kafka 到底在什么情况下才能保证消息不丢失呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;通过上面三步，我们可以得出：Kafka 只对 &lt;/span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」的消息做&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;最大限度的持久化保证不丢失&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;怎么理解上面这句话呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）首先是 &lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」的消息：当 Kafka 中 &lt;span&gt;N&lt;/span&gt; 个 Broker 成功的收到一条消息并写入到日志文件后，它们会告诉 Producer 端这条消息已成功提交了，那么这时该消息在 Kafka 中就变成 &lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;已提交消息&quot;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;N &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;个 Broker &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们怎么理解呢？这主要取决于对 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;已提交&quot;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 的定义， 这里可以选择只要一个 Broker 成功保存该消息就算已提交，也可以是所有 Broker 都成功保存该消息才算是已提交&lt;span/&gt;&lt;/span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;span&gt;&lt;span/&gt;。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）其次是 &lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;最大限度的持久化保证不丢失&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，也就是说 Kafka 并不能保证在任何情况下都能做到数据不丢失。即 Kafka 不丢失数据是有前提条件的。假如这时你的消息保存在 N 个 Broker 上，那么前提条件就是这 N 个 Broker 中至少有1个是存活的，就可以保证你的消息不丢失。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说 Kafka 是能做到不丢失数据的， 只不过这些消息必须是 &lt;span&gt;「&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;的消息，且还要满足一定的条件才可以。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;了解了 Kafka 消息传递语义以及什么情况下可以保证不丢失数据，下面我们来详细剖析每个环节为什么会丢数据，以及如何最大限度的避免丢失数据。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;03 消息丢失场景剖析&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Producer 端丢失场景剖析&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在剖析 Producer 端数据丢失之前，我们先来了解下 Producer 端发送消息的流程，对于不了解 Producer 的读者们，可以查看 &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTcxMDgxNA==&amp;amp;mid=2247488849&amp;amp;idx=1&amp;amp;sn=febda095589f02553d9191528f271c07&amp;amp;chksm=cefb3c60f98cb576fd9c58d760b9a5e4ae32a0c001e2049b591297d904a0401646448999c78a&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;聊聊 Kafka Producer 那‍点事&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;聊聊 Kafka Producer 那点事&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5580969807868252&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j83KibYlWcyceJicnUBWdByYTAibzaQsQ90c1IKpZhfXTVOJ1Mj4ErYMPzLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1093&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;消息发送流程如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）首先我们要知道一点就是 Producer 端是直接与 Broker 中的 Leader Partition 交互的，所以在 Producer 端初始化中就需要通过 Partitioner 分区器从 Kafka 集群中获取到相关 Topic 对应的 Leader Partition 的元数据 &lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）待获取到 Leader Partition 的元数据后直接将消息发送过去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）Kafka Broker 对应的 Leader Partition 收到消息会先写入 Page Cache，定时刷盘进行持久化（顺序写入磁盘）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4) Follower Partition 拉取 Leader Partition 的消息并保持同 Leader Partition 数据一致，待消息拉取完毕后需要给 Leader Partition 回复 ACK 确认消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5）待 Kafka Leader 与 Follower Partition 同步完数据并收到所有 ISR 中的 Replica 副本的 ACK 后，Leader Partition 会给 Producer 回复 ACK 确认消息。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;根据上图以及消息发送流程可以得出：Producer 端为了提升发送效率，减少IO操作，发送数据的时候是将多个请求合并成一个个 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;RecordBatch&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，并将其封装转换成 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;Request&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; 请求&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;异步&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;将数据发送出去（也可以按时间间隔方式，达到时间间隔自动发送），&lt;/span&gt;&lt;span&gt;&lt;strong&gt;所以 Producer 端消息丢失更多是因为消息根本就没有发送到 Kafka Broker 端&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;导致 Producer 端消息没有发送成功有以下原因：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外 Kafka Producer 端也可以通过配置来确认消息是否生产成功：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4184818481848185&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j83ibHEc1zjbRF13jNcgcN8j7ichWjVY4lXXQOPDw6Uvy4GA9PIebBUfhVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1515&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;在 Kafka Producer 端的 acks 默认配置为1， 默认级别是 at least once 语义, 并不能保证 exactly once 语义。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5719360568383659&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgDWN00EfxZVYY8KN1XElAQibuzibDZibZiaicCJY8L7NOwBhkJC9icavRGt0SA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;563&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然 Producer 端发送数据有 ACK 机制, 那么这里就可能会丢数据的&lt;strong&gt;!!!&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;acks = 0：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;由于发送后就自认为发送成功，&lt;/span&gt;&lt;span&gt;这时如果发生网络抖动， Producer 端并不会校验 ACK 自然也就丢了，且无法重试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;acks = 1：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;消息发送 Leader Parition 接收成功就表示发送成功，这时&lt;/span&gt;&lt;span&gt;只要 Leader Partition 不 Crash 掉，就可以保证 Leader Partition 不丢数据，但是如果 Leader Partition 异常 Crash 掉了， Follower Partition 还未同步完数据且没有 ACK，这时就会丢数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;acks = -1 或者 all：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 消息发送需要等待 ISR 中 Leader Partition 和 所有的 Follower Partition 都确认收到消息才算发送成功, 可靠性最高, 但也不能保证不丢数据,比如当 ISR 中只剩下 Leader Partition 了, 这样就变成 acks = 1 的情况了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Broker 端丢失场景剖析&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;接下来我们来看看 Broker 端持久化存储丢失场景， 对于不了解 Broker 的读者们，可以先看看 &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTcxMDgxNA==&amp;amp;mid=2247488847&amp;amp;idx=1&amp;amp;sn=fe2dace4ebf39001062fa331711606ba&amp;amp;chksm=cefb3c7ef98cb5689c91b02edb345cc75751ae7e2daf27d8de9a47f9ecc3eedaf3551eead037&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;聊聊 Kafka Brok‍er 那点事&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;聊聊 Kafka Broker 那点事&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;，&lt;span&gt;数据存储过程如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8770614692653673&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpohQngGEXiaejib1KGW2yCL7iarBhb6BMv1k68TN9yicVfl0VbPU2byKSIicoOkYIEawkKKbpJae7YDcKw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;667&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kafka Broker 集群接收到数据后会将数据进行持久化存储到磁盘，为了提高吞吐量和性能，采用的是&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;异步批量刷盘的策略&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，也就是说按照一定的消息量和间隔时间进行刷盘。首先会将数据存储到 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;PageCache&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt; 中，至于什么时候将 Cache 中的数据刷盘是由&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;操作系统&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;根据自己的策略决定或者调用 fsync 命令进行强制刷盘，如果此时 Broker 宕机 Crash 掉，且选举了一个落后 Leader Partition 很多的 Follower Partition 成为新的 Leader Partition，那么落后的消息数据&lt;span&gt;就会丢失&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;                &lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5719360568383659&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgDWN00EfxZVYY8KN1XElAQibuzibDZibZiaicCJY8L7NOwBhkJC9icavRGt0SA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;563&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然 Broker 端消息存储是通过异步批量刷盘的，那么这&lt;span&gt;里就可能会丢数据的&lt;/span&gt;&lt;strong&gt;!!!&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Consumer 端丢失场景剖析&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;接下来我们来看看 Consumer 端消费数据丢失场景，对于不了解 Consumer 的读者们，可以先看看 &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTcxMDgxNA==&amp;amp;mid=2247488851&amp;amp;idx=1&amp;amp;sn=987824e5ba607e2e33ae0c64adb77d84&amp;amp;chksm=cefb3c62f98cb574d3932d5898dd1da3c20772e1d1885fc90d9b9f4bb5cdf8f34d4e0c7ff7ad&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;聊聊 Kafka‍ ‍Consumer 那点事&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;聊聊 Kafka Consumer 那点事&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;, &lt;span&gt;我们先来看看消费流程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5238095238095238&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j83viczAKDtc5fufr0K3ME0Oas26TkdMNG1fwib5ZGGnoa792cPVFFb52bw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1302&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4313304721030043&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j8354hIicJUibMVspQ7pMLgmm4EEBFBqp4l1QeEyADkGUFIt1HthRSq45bg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1398&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）Consumer 拉取数据之前跟 Producer 发送数据一样, 需要通过订阅关系获取到集群元数据, &lt;/span&gt;找到&lt;span&gt;相关 Topic 对应的 Leader Partition 的元数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）然后 Consumer 通过 Pull 模式主动的去 Kafka 集群中拉取消息。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）在这个过程中，有个消费者组的概念（&lt;/span&gt;&lt;strong&gt;&lt;span&gt;不了解的可以看上面链接文章&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;），多个 Consumer 可以组成一个消费者组即 Consumer Group，每个消费者组都有一个Group-Id。同一个 Consumer Group 中的 Consumer 可以消费同一个 Topic 下不同分区的数据，但是不会出现多个 Consumer 去消费同一个分区的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4）拉取到消息后进行业务逻辑处理，待处理完成后，会进行 ACK 确认，即提交 Offset 消费位移进度记录。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5）最后 Offset 会被保存到 Kafka Broker 集群中的 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;__consumer_offsets&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 这个 Topic 中，且每个 Consumer 保存自己的 Offset 进度。 &lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;根据上图以及消息消费流程可以得出消费主要分为两个阶段：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;                       &lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5719360568383659&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgDWN00EfxZVYY8KN1XElAQibuzibDZibZiaicCJY8L7NOwBhkJC9icavRGt0SA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;563&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然 Consumer 拉取后消息最终是要提交 Offset， 那么这&lt;span&gt;里就可能会丢数据的&lt;/span&gt;&lt;strong&gt;!!!&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;拉取消息后&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;先提交 Offset，后处理消息&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;，如果此时处理消息的时候异常宕机，由于 Offset 已经提交了,  待 Consumer 重启后，会从之前已提交的 Offset 下一个位置重新开始消费， 之前未处理完成的消息不会被再次处理，对于该 Consumer 来说消息就丢失了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;拉取消息后&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;先处理消息，在进行提交 Offset&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;， 如果此时在提交之前发生异常宕机，由于没有提交成功 Offset， 待下次 Consumer 重启后还会从上次的 Offset 重新拉取消息，不会出现消息丢失的情况， 但是会出现重复消费的情况，这里只能业务自己保证幂等性。&lt;/span&gt;        &lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;04 消息丢失解决方案&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;上面带你从 Producer、Broker、Consumer 三端剖析了可能丢失数据的场景，下面我们就来看看如何解决才能最大限度的&lt;span&gt;保证消息不丢失。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Producer 端解决方案&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在剖析&lt;span&gt; Producer 端&lt;/span&gt;丢失场景的时候， 我们得出其是通过&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;异步&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」方式进行发送的，所以如果此时是使用&lt;/span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;发后即焚&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;」的方式发送，即&lt;/span&gt;&lt;span&gt;调用 Producer.send(msg) 会立即返回，由于没有回调，可能因网络原因导致 Broker 并没有收到消息，此时就丢失了。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此我们可以从以下几方面进行解决 Producer 端消息丢失问题：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.1.1 更换调用方式：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;弃用调用发后即焚的方式，使用带回调通知函数的方法进行发送消息，即 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;Producer.send(msg, callback)&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;, 这样一旦发现发送失败， 就可以做针对性处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;kotlin&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;Future&amp;lt;RecordMetadata&amp;gt; send(ProducerRecord&amp;lt;K, V&amp;gt; record, Callback callback);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; Future&amp;lt;RecordMetadata&amp;gt; send(ProducerRecord&amp;lt;K, V&amp;gt; record, Callback callback) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        ProducerRecord&amp;lt;K, V&amp;gt; interceptedRecord = &lt;span class=&quot;code-snippet__keyword&quot;&gt;this&lt;/span&gt;.interceptors == &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; ? record : &lt;span class=&quot;code-snippet__keyword&quot;&gt;this&lt;/span&gt;.interceptors.onSend(record);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; doSend(interceptedRecord, callback);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;）网络抖动&lt;/span&gt;&lt;span&gt;导致消息丢失，Producer 端可以进行重试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）消息大小不合格，可以进行适当调整，符合 Broker 承受范围再发送。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过以上方式可以保证最大限度消息可以发送成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.1.2 ACK 确认机制：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;该参数代表了对&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;已提交&quot;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;消息的定义。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;需要将 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;request.required.acks 设置为 -1/ all&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，-1/all 表示有多少个副本 Broker 全部收到消息，才认为是消息提交成功的标识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;acks = -1/ all &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;, 这里有两种非常典型的情况：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;（1）数据发送到 Leader Partition， 且所有的 ISR 成员全部同步完数据， 此时，Leader Partition 异常 Crash 掉，那么会选举新的 Leader Partition，数据不会丢失， 如下图所示&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6088534107402032&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbypdvf0k7OrsblGBGmIXwIIedLVUEYL2aVWTplEiaKYB2SjSw0DCaEibXBOUCdWXdvAASqpbQkhrgwBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1378&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;（2）数据发送到&lt;strong&gt;&lt;span&gt; Leader Partition&lt;/span&gt;&lt;/strong&gt;，部分 ISR 成员同步完成，此时 Leader Partition 异常 Crash， 剩下的 Follower &lt;span&gt;Partition&lt;/span&gt; 都可能被选举成新的 Leader Partition，会给 Producer 端发送失败标识， 后续会重新发送数据，数据可能会重复， 如下图所示：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6083086053412463&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbypdvf0k7OrsblGBGmIXwIIe0n7XoQWXSxHU5q2zpFH9Ric5jFdKcSeaNMIojr9UurYicAspAQtKwR2g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1348&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此通过上面分析，我们还需要通过其他参数配置来进行保证：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;replication.factor &amp;gt;= 2&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;min.insync.replicas &amp;gt; 1&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是 Broker 端的配置，下面会详细介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.1.3 重试次数 retries：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示 Producer 端发送消息的重试次数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;需要将 retries 设置为大于0的数， 在 Kafka 2.4 版本中默认设置为&lt;/span&gt;&lt;span&gt;Integer.MAX_VALUE。另外如果需要保证发送消息的顺序性，配置如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;retries &lt;span&gt;=&lt;/span&gt; Integer&lt;span&gt;.&lt;/span&gt;&lt;span&gt;MAX_VALUE&lt;/span&gt;&lt;br/&gt;max&lt;span&gt;.&lt;/span&gt;in&lt;span&gt;.&lt;/span&gt;flight&lt;span&gt;.&lt;/span&gt;requests&lt;span&gt;.&lt;/span&gt;per&lt;span&gt;.&lt;/span&gt;connection &lt;span&gt;=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这样 Producer 端就会一直进行重试直到 Broker 端返回 ACK 标识，同时只有一个连接向 Broker 发送数据保证了消息的顺序性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.1.4 重试时间 retry.backoff.ms：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示消息发送超时后&lt;/span&gt;&lt;strong&gt;&lt;span&gt;两次重试之间的间隔时间&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，避免无效的频繁重试，默认值为100ms,  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;推荐设置为300ms&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Broker 端解决方案&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在剖析 Broker 端丢失场景的时候， 我们得出其是通过&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;异步批量刷盘&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」的策略，先将数据存储到 &lt;/span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;PageCache&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;」，再进行异步刷盘， 由于没有提供 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;同&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;步刷盘&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」策略， 因此 Kafka 是通过&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;多分区多副本&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;的方式来&lt;span&gt;最大限度的&lt;/span&gt;保证数据不丢失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以通过以下参数配合来保证：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.2.1 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;unclean.leader.election.enable&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示&lt;/span&gt;&lt;strong&gt;&lt;span&gt;有哪些 Follower 可以有资格被选举为 Leader&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; , 如果一个 Follower 的数据落后 Leader 太多，那么一旦它被选举为新的 Leader， 数据就会丢失，因此我们要将其设置为false，防止此类情况发生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;4.2.2 &lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;replication.factor&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示分区副本的个数。建议设置 &lt;strong&gt;&lt;strong&gt;&lt;span&gt;replication.factor &amp;gt;=3&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;, 这样如果 Leader 副本异常 Crash 掉，Follower 副本会被选举为新的 Leader 副本继续提供服务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;4.2.3 &lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;min.insync.replicas&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示消息至少要被写入成功到 ISR 多少个副本才算&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;已提交&quot;，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;建议&lt;/span&gt;&lt;span&gt;设置&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;min.insync.replicas &amp;gt; 1, &lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;这样才可以提升消息持久性，保证数据不丢失。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外我们还需要确保一下 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;replication.factor &amp;gt; min.insync.replicas&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;, 如果相等，只要有一个副本异常 Crash 掉，整个分区就无法正常工作了，因此推荐设置成： &lt;strong&gt;&lt;span&gt;replication.factor = min.insync.replicas +1&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;, 最大限度保证系统可用性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Consumer 端解决方案&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在剖析 Consumer 端丢失场景的时候，我们得出其拉取完消息后是需要提交 Offset 位移信息的，因此为了不丢数据，正确的做法是：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;拉取数据、&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;业务逻辑处理、&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;提交消费 Offset 位移信息。&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;我们还需要设置参数 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;enable.auto.commit = false, 采用手动提交位移的方式。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外对于消费消息重复的情况，业务自己保证幂等性, &lt;/span&gt;&lt;strong&gt;&lt;span&gt;保证只成功消费一次即可&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;05 总结&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里，我们一起来总结一下这篇文章的重点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、从 Kafka 整体架构上概述了可能发生数据丢失的环节。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、带你剖析了&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;消息传递语义&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;的概念， 确定了 Kafka 只对&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;的消息做&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;最大限度的持久化保证不丢失&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、带你剖析了 Producer、Broker、Consumer 三端可能导致数据丢失的场景以及具体的高可靠解决方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果我的文章对你有所帮助，还请帮忙&lt;/span&gt;&lt;strong&gt;点赞、在看、转发&lt;/strong&gt;&lt;span&gt;一下，非常感谢！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;坚持总结, 持续输出高质量文章&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;  关注我: 华仔聊技&lt;span data-raw-text=&quot;术&quot; data-textnode-index=&quot;537&quot; data-index=&quot;7642&quot;&gt;术&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;br/&gt;&lt;/h1&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzg3MTcxMDgxNA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyp4CYMexUiagvdYANIhY2ibiaibtqichibk92kiaMvHTJmavuepu4yZWC2OqwCVz834X916B5txFNYY7KgXw/0?wx_fmt=png&quot; data-nickname=&quot;华仔聊技术&quot; data-alias=&quot;&quot; data-signature=&quot;聊聊后端技术架构以及中间件源码&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>fab35e5893ba196e27a1c5855a39f500</guid>
<title>快用上PerformanceObserver，别再手动计算首屏时间了</title>
<link>https://toutiao.io/k/tbxln35</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天给大家介绍一个非常好用的浏览器api：&lt;strong&gt;PerformanceObserver&lt;/strong&gt; ， 我们可以用它来获取首屏、白屏的时间，就不用再麻烦地手动去计算了。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7795275590551181&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvyww1AOVtJHd7BDEictrZgXjI1b3hKJ4QHRZFhbrzUono2YYfmQtiaFIDQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;254&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;介绍&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;PerformanceObserver&lt;/strong&gt; 可用于获取性能相关的数据，例如&lt;strong&gt;首帧fp&lt;/strong&gt;、&lt;strong&gt;首屏fcp&lt;/strong&gt;、&lt;strong&gt;首次有意义的绘制 fmp&lt;/strong&gt;等等。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;构造函数&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;PerformanceObserver()&lt;/code&gt;创建并返回一个新的 PerformanceObserver 对象。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;提供的方法&lt;/span&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;PerformanceObserver.observe()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当记录的性能指标在指定的 entryTypes 之中时，将调用性能观察器的回调函数。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;PerformanceObserver.disconnect()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;停止性能观察者回调接收到性能指标。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;PerformanceObserver.takeRecords()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;返回存储在性能观察器中的性能指标的列表，并将其清空。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;重点我们看看observer.observe(options);&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;options&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个只装了单个键值对的对象，该键值对的键名规定为 &lt;strong&gt;entryTypes&lt;/strong&gt;。e&lt;strong&gt;ntryTypes&lt;/strong&gt; 的取值要求如下:&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;entryTypes 的值：一个放字符串的数组，字符串的有效值取值在性能条目类型 中有详细列出。如果其中的某个字符串取的值无效，浏览器会自动忽略它。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另：若未传入 options 实参，或传入的 options 实参为空数组，会抛出 TypeError。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;2&lt;/span&gt;&lt;/span&gt;&lt;span&gt;实例&lt;/span&gt;&lt;/h2&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&amp;lt;script&amp;gt;&lt;br/&gt; &lt;span&gt;const&lt;/span&gt; observer = &lt;span&gt;new&lt;/span&gt; PerformanceObserver(&lt;span&gt;(&lt;span&gt;list&lt;/span&gt;) =&amp;gt;&lt;/span&gt; {&lt;br/&gt;  &lt;span&gt;for&lt;/span&gt;(&lt;span&gt;const&lt;/span&gt; entry &lt;span&gt;of&lt;/span&gt; list.getEntries()){&lt;br/&gt;   &lt;span&gt;console&lt;/span&gt;.groupCollapsed(entry.name);&lt;br/&gt;   &lt;span&gt;console&lt;/span&gt;.log(entry.entryType);&lt;br/&gt;   &lt;span&gt;console&lt;/span&gt;.log(entry.startTime);&lt;br/&gt;   &lt;span&gt;console&lt;/span&gt;.log(entry.duration);&lt;br/&gt;   &lt;span&gt;console&lt;/span&gt;.groupEnd(entry.name);&lt;br/&gt;  }&lt;br/&gt; }) &lt;br/&gt; observer.observe({&lt;span&gt;entryTypes&lt;/span&gt;:[&lt;span&gt;&#x27;longtask&#x27;&lt;/span&gt;,&lt;span&gt;&#x27;frame&#x27;&lt;/span&gt;,&lt;span&gt;&#x27;navigation&#x27;&lt;/span&gt;,&lt;span&gt;&#x27;resource&#x27;&lt;/span&gt;,&lt;span&gt;&#x27;mark&#x27;&lt;/span&gt;,&lt;span&gt;&#x27;measure&#x27;&lt;/span&gt;,&lt;span&gt;&#x27;paint&#x27;&lt;/span&gt;]});&lt;br/&gt;&amp;lt;&lt;span&gt;/script&amp;gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;获取结果&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7601522842639594&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvy9S9BZEibqp5smUeWNuoEvm7zjmVRlgbsDCIiaPzVEwH42FT81icTOREQg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;788&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据打印结果我们可以推测出来：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;entryTypes里的值其实就是我们告诉PerformanceObserver，我们想要获取的某一方面的性能值。例如传入&lt;strong&gt;paint&lt;/strong&gt;，就是说我们想要得到fcp和fp。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以我们看打印，它打印出来了fp和fcp&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2964071856287425&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvywXmOzGYvwKHbVP95xj64Z5iaQic5erYNOS1HIhDesibFgZcJI0DZTicsJQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;668&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里有必要解释一下什么是fp，fcp，fpm&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;TTFB：Time To First Byte，首字节时间&lt;br/&gt;FP：First Paint，首次绘制，绘制Body&lt;br/&gt;FCP：First Contentful Paint，首次有内容的绘制，第一个dom元素绘制完成&lt;br/&gt;FMP：First Meaningful Paint，首次有意义的绘制&lt;br/&gt;TTI：Time To Interactive，可交互时间，整个内容渲染完成&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvyyneHZpsEibq7RaJBvkKwhcH2FQ1S6icjMEFLY1Xq6gA2icOuXbZKrGpBw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;270&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不懂？看图！&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.35789473684210527&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvyRArb0GharyamZNnPAA1WRczKLl534Bseh9XvFHZQWUwbicVtbmSxAGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;665&quot;/&gt;&lt;/figure&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;FP仅有一个div根节点&lt;br/&gt;FCP包含页面的基本框架，但没有数据内容&lt;br/&gt;FMP包含页面的所有元素及数据&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Wow！恍然大悟！&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;3&lt;/span&gt;&lt;/span&gt;&lt;span&gt;实际使用&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，我们在实际项目中怎么取获取呢？可以看看我的实现参考一下下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;  &lt;span&gt;// 使用 PerformanceObserver 监听 fcp&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (!!PerformanceObserver){&lt;br/&gt;    &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;      &lt;span&gt;const&lt;/span&gt; type = &lt;span&gt;&#x27;paint&#x27;&lt;/span&gt;;&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; ((PerformanceObserver.supportedEntryTypes || []).includes(type)) {&lt;br/&gt;        observer = &lt;span&gt;new&lt;/span&gt; PerformanceObserver(&lt;span&gt;(&lt;span&gt;entryList&lt;/span&gt;)=&amp;gt;&lt;/span&gt;{&lt;br/&gt;          &lt;span&gt;for&lt;/span&gt;(&lt;span&gt;const&lt;/span&gt; entry &lt;span&gt;of&lt;/span&gt; entryList.getEntriesByName(&lt;span&gt;&#x27;first-contentful-paint&#x27;&lt;/span&gt;)){&lt;br/&gt;            &lt;span&gt;const&lt;/span&gt; { startTime,duration } = entry;&lt;br/&gt;            &lt;span&gt;console&lt;/span&gt;.log(&lt;span&gt;&#x27;[assets-load-monitor] PerformanceObserver fcp:&#x27;&lt;/span&gt;, startTime+&lt;span&gt;durati&lt;/span&gt;&lt;span&gt;on&lt;/span&gt;);&lt;br/&gt;            &lt;br/&gt;            &lt;span&gt;// 上报startTime操作&lt;/span&gt;&lt;br/&gt;          }&lt;br/&gt;        });&lt;br/&gt;        observer.observe({&lt;br/&gt;          &lt;span&gt;entryTypes&lt;/span&gt;: [type],&lt;br/&gt;        });&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt;;&lt;br/&gt;      }&lt;br/&gt;    } &lt;span&gt;catch&lt;/span&gt; (e) {&lt;br/&gt;      &lt;span&gt;// ios 不支持这种entryTypes，会报错 https://caniuse.com/?search=PerformancePaintTiming&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;console&lt;/span&gt;.warn(&lt;span&gt;&#x27;[assets-load-monitor] PerformanceObserver error:&#x27;&lt;/span&gt;, (e || {}).message ? e.message : e);&lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里用了判断是否可以使用PerformanceObserver，不能使用的话，我们是用其他方法的，例如MutationObserver，这个我们我们后面再讲。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8733333333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvyC9BYibejt6iaLuXKnDMhUmBNwE4FLicCwaQJejnycialvM64zK4lV4l7dQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;150&quot;/&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4139749505603164&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvyz1NnBZOkqbKnXtocxPAgdsocNMkZINp1SJwWQ6BZSWAibEE7cLunFyQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1517&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;4&lt;/span&gt;&lt;/span&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;https://blog.csdn.net/weixin_40970987/article/details/108121988 https://developer.mozilla.org/zh-CN/docs/Web/API/PerformanceObserver/observe&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>636604cf3bafaa693fd8adda37eb2188</guid>
<title>Airbnb复盘微服务</title>
<link>https://toutiao.io/k/eqbc7zj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 面临着架构解决方案的挑战，不但要解决现在的问题，同时要支持未来的扩张；这就是质量工程要解决的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 采用了增量和迭代过程：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;定义问题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;找到改进的解决方案&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;使用解决方案&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;提高解决方案采用率&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;处理解决方案的扩展挑战&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;这种方法能够分离每个问题的关注点，找到结构化的解决方案并在以后扩展它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45714285714285713&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3YTuicoOpRUHyvgUzgPdT3L5PXRlZzm2iaURwOvIwpkgf4244IaAKsKrQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 在采用上述方法过程中实施了以下做法：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;提供基础设施即代码以提高开发人员的生产力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;明确所有权并通过工具和可观察性进行改进&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;定义由组织和方法支持的新架构&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;引入一个弃用工作组以加速迁移&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;让我们看看前述问题是如何解决的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;提供基础设施即代码以提高开发人员的生产力&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;当业务变革能力依赖于软件时，缓慢和错误的软件开发直接影响公司的竞争力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;凭借在微服务架构方面的经验，Airbnb 投资了自动化和工具化。但在一系列不断发展的技术中需要更快的迭代周期。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5478571428571428&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3EEEgSROqOP0Du4MqY23A2ydksndKx0If4iaAoia2ynibdbHlG5kGGiaxicg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;务实的解决方案是在单个仓库中投资基础设施即代码，从而逐步并行提升各个服务的采用率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;当运行更多服务时，就会出现理解这种复杂性的扩展挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;明确所有权并通过工具和可观察性进行改进&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;有太多的微服务相互捆绑；即使很小的变化也会导致相互依赖的变化和影响，掌握起来很复杂。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5671875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa34sVCEX6dU8dJEa4RHAf2RhZNJAzbbwygtSQN3F5svJ0PDDWKUc0oug/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 投资于提高生产力，重点支持三个领域的新架构：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;1、所有权&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 部署了“Scry Ownership”，它是技术组件所有权数据（如所有者、维护者、通信渠道）的应用管理者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.42686567164179107&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3TkJvohbbZ7OiatxRkLnE91Ax6e8fhQIwsg1bdCsibE5WHY8O5WV6mtGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1340&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;2、可观察性&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 设置了一系列可观察性仪表板，以系统地审查实施过程。下面是一个仪表板示例，用于跟踪正在设置的所有权：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5859598853868195&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3ib5syrRVermdic2GZ3qia5cVusDxfgCGNWpiaFfKFuPl0Ftiaon5Lx55zXg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;698&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;3、工具&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;数据空间仍然存在挑战。定制的 Thrift[2] 模式是有用的序列化器和数据描述符，但它们需要其他组件来检索产品中的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 利用 GraphQL 构建了统一的数据访问层，直接提供查询能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.42714285714285716&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3qY16HgaRVAXc1ZEQV8hJ8ICiaypevosNSKl5zgJLxuE8oJxKS3VGIWA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;代码生成是提高开发人员生产力的最后一步。随着技术的增加，Airbnb 为每一层的标准组件提供了模板。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;通过设计指明数据类型和访问类型的代码注释，数据的访问甚至直接就被嵌入在了代码中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3442857142857143&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3mia0iahrjma3HC0eqQ8YBxia3UpHQFF2IJOQ7OUBicFLrR3tk7icFZ0QDkQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;当星号看起来对齐时，就会出现另一个速度问题。这一次，中央数据聚合器组件成为了限制因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;定义由组织和方法支持的新架构&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;中央数据聚合器的构建和部署时间太慢，团队无法按时迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;即使提高了生产力，累积的结构复杂性仍然太高而无法在中央组件中处理。需要一个新的组织。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;熵是系统随着时间的推移变得更加复杂的自然趋势，需要支持和反作用力来平衡生态系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;质量工程力量在架构、组织和方法领域发挥作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;1、支持增长的架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;太复杂了，团队必须对不同领域执行缓慢且成本高昂的影响分析，协调多个团队并纠正副作用错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;让我们分析一下“纯微服务架构”级联问题树：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;复杂性过度分布在细粒度服务中&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;这些细粒度的微服务缺乏稳定的协作点&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;缺失的粘合剂最终分布在组件和团队之间&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;即使是很小的变化也往往会导致混合影响&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;核心问题是缺乏城市化，导致单体或微服务架构缺乏模块化和关注点分离。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 采用了一种新的架构风格 Micro macroservices：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.37714285714285717&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3ktNiaMudwSq9niaiatibFtOPj1L0piazq1SM253qqm4tiaceibG0MmicBw5cNQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;在这样的架构中，每种类型的复杂性分布是一个清晰的层：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;统一 API是支持产品快速迭代的微服务&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;中央数据聚合器是具有紧密耦合的稳定单体&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;服务块外观 API抽象了提供实体块的微服务。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;阅读本文[3]，了解有关速度和质量架构的价值的更多信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;2、组织一致性支持新架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旨在支持业务目标的组织可以改变游戏规则。这种调整对于 Airbnb 的加速发展至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;该组织与不断发展的架构保持一致，产品团队在统一 API 之上工作，数据聚合团队在中央数据层（即“胶水”），以及每个数据方面的域平台团队（预留、用户）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.455&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3Ks1zbsc9O1hgoU4fOcABdQO43YicA0enWDHTjuDouDSmy6B1ibDfCrjw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;3、方法强制通往新架构的铺平道路&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;架构审查、IT 委员会、工艺治理——这些都是用于根据当前环境和未来架构审查提出的解决方案的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;这种方法的价值在于作为一种反力量，在由其他目标驱动的项目环境之外，以平衡选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 使用这些方法为 Micro macroservices 架构铺平了道路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5157142857142857&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa34jnficibqeaem1SMlLMKibR99QYqHkUU3BEmlibVzua7q5ZsvVwK21IJ1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;即使不包括在内，Airbnb 的管理层肯定对领导转型和发展新模式的文化以及发展技能产生了巨大影响，从而完成了 MAMOS 的范围。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;有了这些变化，Airbnb 能够引领平行的迁移轨道。但是弃用 Monolith 仍然需要太多时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;引入弃用工作组加速迁移&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;单独更改我们的银行账户已经是一场噩梦。当需要数年时间与多个团队协调才能完成时，这项任务就更加复杂了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 就像许多其他拥有遗留系统和持续业务的组织一样：他们无法在建造新房子的同时炸毁他们居住的房子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;一个特定的组织单位致力于加速从单体架构中迁移出来，领导以下工作：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;移动应用程序弃用达12个月以上&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;提升和跟踪整体债务以获得可见性&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;日落低使用率的终端以加速删除&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;迁移的长期所有权&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;认识到折旧对估值有影响&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;这个团体有游说的反击力量，但对于实现迁移目标至关重要。反对单体应用不能是“每个人的责任”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;当这项任务完成时，将面临其他挑战。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.541015625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa34Rdh4jLrRfpH13uIeMNBiaVjbG9jicTialIOBowjlQPqqPaVYJ6bgDibwA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>