<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>6042538f0474403a28e93784414314ab</guid>
<title>后台开发面试必看：后台服务器开发高性能最佳实践</title>
<link>https://toutiao.io/k/w76nnho</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;post-topic-des nc-post-content&quot;&gt;
&lt;h2&gt;前言&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;在互联网公司技术面试上，除了&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;和网络、操作系统这种基础之外，还有一类&lt;/span&gt;&lt;strong&gt;系统设计和优化&lt;/strong&gt;的问题。这类问题需要你有一个全局的技术视野，以及熟悉一些常用的系统优化方法论，也就是工程上的一些 &lt;strong&gt;Best Practice&lt;/strong&gt;，而不至于自己临时拍脑袋瞎设计。&lt;/p&gt; 
&lt;p&gt;在互联网公司，经常面临一个“三高”问题：&lt;/p&gt; 
 
&lt;p&gt;这篇文章将总结一下后台服务器开发中有哪些常用的解决“三高”问题的方法和思想。&lt;/p&gt; 
&lt;p&gt;希望这些知识，能够给你一丝启发和帮助，助力你收割 各大公司 Offer~&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;先上本文思维导图:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;如何解决三高&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873447931_007S8ZIlgy1gifsdthgvpj315p0u0aia.jpg&quot;/&gt;&lt;/p&gt; 
&lt;h2&gt;正文&lt;/h2&gt; 
&lt;h3&gt;一、缓存&lt;/h3&gt; 
&lt;p&gt;什么是缓存？看看维基百科怎么说：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;In computing, a cache is a hardware or software component that stores data so that future requests for that data can be served faster; the data stored in a cache might be the result of an earlier computation or a copy of data stored elsewhere.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;在计算机中，&lt;strong&gt;缓存&lt;/strong&gt;是存储数据的硬件或软件组件，以便可以更快地满足将来对该数据的请求。 存储在缓存中的数据可能是之前&lt;strong&gt;计算结果&lt;/strong&gt;，也可能是存储在其他位置的&lt;strong&gt;数据副本&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;缓存本质来说是使用&lt;strong&gt;空间换时间&lt;/strong&gt;的思想，它在计算机世界中无处不在， 比如 CPU 就自带 L1、L2、L3 Cache，这个一般应用开发可能关注较少。但是在一些实时系统、大规模计算模拟、图像处理等追求极致性能的领域，就特别注重编写&lt;strong&gt;缓存友好&lt;/strong&gt;的代码。&lt;/p&gt; 
&lt;p&gt;什么是缓存友好？简单来说，就是代码在访问数据的时候，尽量使用缓存命中率高的方式。这个后面可以单独写一篇 CPU 缓存系统以及如何编写缓存友好代码的文章。&lt;/p&gt; 
&lt;h4&gt;1.1 缓存为什么有效？&lt;/h4&gt; 
&lt;p&gt;缓存之所以能够大幅提高系统的性能，关键在于数据的访问具有&lt;strong&gt;局部性&lt;/strong&gt;，也就是二八定律：「百分之八十的数据访问是集中在 20% 的数据上」。这部分数据也被叫做&lt;strong&gt;热点数据。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;缓存一般使用内存作为存储，内存读写速度快于磁盘，但容量有限，十分宝贵，不可能将所有数据都缓存起来。&lt;/p&gt; 
&lt;p&gt;如果应用访问数据没有热点，不遵循二八定律，即大部分数据访问并没有集中在小部分数据上，那么缓存就没有意义，因为大部分数据还没有被再次访问就已经被挤出缓存了。每次访问都会回源到数据库查询，那么反而会降低数据访问效率。&lt;/p&gt; 
&lt;h4&gt;1.2 缓存分类&lt;/h4&gt; 
 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;2. 分布式缓存:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;当缓存的数据量增大以后，单机不足以承载缓存服务时，就要考虑对缓存服务做&lt;strong&gt;水平扩展&lt;/strong&gt;，引入缓存集群。&lt;/p&gt; &lt;p&gt;将数据分片后分散存储在不同机器中，如何决定每个数据分片存放在哪台机器呢？一般是采用&lt;strong&gt;&lt;span&gt;一致性 Hash &lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，它能够保证在缓存集群动态调整，不断增加或者减少机器后，&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;访问时依然能够根据 key 访问到数据。&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;一致性 Hash &lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;也是值得用一篇文章来讲的，如果暂时还不懂的话可以去搜一下。&lt;/span&gt;&lt;/p&gt; &lt;p&gt;常用的组件有 &lt;strong&gt;Memcache&lt;/strong&gt;、 &lt;strong&gt;Redis Cluster&lt;/strong&gt; 等，第二个是在高性能内存存储 Redis 的基础上，提供分布式存储的解决方案。&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;h4&gt;1.3 缓存使用指南&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;1. 适合缓存的场景：&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;读多写少：&lt;/strong&gt; &lt;/p&gt; &lt;p&gt;比如电商里的商品详情页面，访问频率很高，但是一般写入只在店家上架商品和修改信息的时候发生。如果把热点商品的信息缓存起来，这将拦截掉很多对数据库的访问，提高系统整体的吞吐量。&lt;/p&gt; &lt;p&gt;因为一般数据库的 QPS 由于有「ACID」约束、并且数据是持久化在硬盘的，所以比 Redis 这类基于内存的 NoSQL 存储低不少。常常是一个系统的瓶颈，如果我们把大部分的查询都在 Redis 缓存中命中了，那么系统整体的 QPS 也就上去了。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;计算耗时大，且实时性不高：&lt;/strong&gt;&lt;br/&gt;比如王者荣耀里的全区排行榜，一般一周更新一次，并且计算的数据量也比较大，所以计算后缓存起来，请求排行榜直接从缓存中取出，就不用实时计算了。&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. 不适合缓存的场景&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;写多读少，频繁更新。&lt;/strong&gt; &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;对数据一致性要求严格：&lt;/strong&gt; 因为缓存会有更新策略，所以很难做到和数据库实时同步。 &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;数据访问完全随机：&lt;/strong&gt; 因为这样会导致缓存的命中率极低。 &lt;/li&gt;
&lt;/ul&gt; 
&lt;h4&gt;1.4 缓存更新的策略&lt;/h4&gt; 
&lt;p&gt;如何更新缓存其实已经有总结得非常好的「最佳实践」，我们按照套路来，大概率不会犯错。&lt;/p&gt; 
&lt;p&gt;主要分为两类 &lt;strong&gt;Cache-Aside&lt;/strong&gt; 和 &lt;strong&gt;Cache-As-SoR。&lt;/strong&gt; SoR 即「System Of Record，记录系统」，表示数据源，一般就是指数据库。&lt;/p&gt; 
&lt;h5&gt;1、Cache-Aside：&lt;/h5&gt; 
&lt;p&gt;&lt;img alt=&quot;Cache-Aside架构图&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873447897_007S8ZIlgy1gifjt5j889j31540tuq5x.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;这应该是最容易想到的模式了，获取数据时先从缓存读，如果 &lt;strong&gt;cache hit&lt;/strong&gt; 则直接返回，没命中就从数据源获取，然后更新缓存。&lt;/p&gt; 
&lt;p&gt;写数据的时候则先更新数据源，然后设置缓存失效，下一次获取数据的时候必然 &lt;strong&gt;cache miss&lt;/strong&gt;，然后触发&lt;strong&gt;回源&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;直接看伪代码：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;Cache-Aside 代码示范&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873447891_007S8ZIlgy1gift5f4ajcj30u00wmgvc.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;可以看到这种方式对于缓存的使用者是&lt;strong&gt;不透明&lt;/strong&gt;的，需要使用者手动维护缓存。&lt;/p&gt; 
&lt;h5&gt;2、Cache-As-SoR：&lt;/h5&gt; 
&lt;p&gt;&lt;img alt=&quot;Cache-As-SoR架构图&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873447929_007S8ZIlgy1gifj60t7g9j319w0tuta8.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;从字面上来看，就是把 Cache 当作 SoR，也就是数据源，所以一切读写操作都是针对 Cache 的，由 &lt;strong&gt;Cache 内部自己维护和数据源的一致性。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这样对于使用者来说就和直接操作 SoR 没有区别了，完全感知不到 Cache 的存在。&lt;/p&gt; 
&lt;p&gt;CPU 内部的 L1、L2、L3 Cache 就是这种方式，作为数据的使用方应用程序，是完全感知不到在内存和我们之间还存在几层的 Cache，但是我们之前又提到编写 “缓存友好”的代码，不是透明的吗？这是不是冲突呢？&lt;/p&gt; 
&lt;p&gt;其实不然，缓存友好是指我们通过学习了解缓存内部实现、更新策略之后，通过调整数据访问顺序提高缓存的命中率。&lt;/p&gt; 
&lt;p&gt;Cache-As-SoR 又分为以下三种方式:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Read Through&lt;/strong&gt;：这种方式和 Cache-Aside 非常相似，都是在查询时发生 cache miss 去更新缓存，但是区别在于 Cache-Aside 需要调用方手动更新缓存，而 Cache-As-SoR 则是由缓存内部实现自己负责，对应用层透明。 &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;Write Through&lt;/strong&gt;： 直写式，就是在将数据写入缓存的同时，缓存也去更新后面的数据源，并且必须等到数据源被更新成功后才可返回。这样保证了缓存和数据库里的&lt;strong&gt;数据一致性&lt;/strong&gt;。 &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;Write Back&lt;/strong&gt;：回写式，数据写入缓存即可返回，缓存内部会异步的去更新数据源，这样好处是&lt;strong&gt;写操作特别快&lt;/strong&gt;，因为只需要更新缓存。并且缓存内部可以合并对相同数据项的多次更新，但是带来的问题就是&lt;strong&gt;数据不一致&lt;/strong&gt;，可能发生写丢失。 &lt;/li&gt;
&lt;/ul&gt; 
&lt;h3&gt;二、预处理和延后处理&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;预先延后&lt;/strong&gt;，这其实是一个事物的两面，不管是预先还是延后核心思想都是将本来该在实时链路上处理的事情剥离，要么提前要么延后处理。&lt;strong&gt;降低实时链路的路径长度，&lt;/strong&gt; 这样能有效提高系统性能。&lt;/p&gt; 
&lt;h4&gt;2.1 预处理&lt;/h4&gt; 
&lt;p&gt;举个我们团队实际中遇到的问题：&lt;/p&gt; 
&lt;p&gt;前两个月支付宝联合杭州市政府发放消费劵，但是要求只有杭州市常驻居民才能领取，那么需要在抢卷请求进入后台的时候就判断一下用户是否是杭州常驻居民。&lt;/p&gt; 
&lt;p&gt;而判断用户是否是常驻居民这个是另外一个微服务接口，如果直接实时的去调用那个接口，短时的高并发很有可能把这个服务也拖挂，最终导致整个系统不可用，并且 RPC 本身也是比较耗时的，所以就考虑在这里进行优化。&lt;/p&gt; 
&lt;p&gt;那么该怎么做呢？很简单的一个思路，&lt;strong&gt;提前将杭州所有常驻居民的 user_id 存到缓存中，&lt;/strong&gt;&lt;span&gt; 比如可以直接存到 Redis。大概就是千万量级，这样，当请求到来的时候我们直接通过缓存可以快速判断是否来自杭州常驻居民。如果不是则直接在这里返回&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%89%8D%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;前端&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;这里通过预先处理减少了实时链路上的 RPC 调用，既减少了系统的外部依赖，也极大的提高了系统的吞吐量。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;预处理在 CPU 和操作系统中也广泛使用，比如 CPU 基于历史访存信息，将内存中的&lt;strong&gt;指令和数据预取&lt;/strong&gt;到 Cache 中，这样可以大大提高&lt;strong&gt;Cache 命中率。&lt;/strong&gt; 还比如在 Linux 文件系统中，预读算***预测即将访问的 page，然后批量加载比当前读请求更多的数据缓存在 page cache 中，这样当下次读请求到来时可以直接从 cache 中返回，大大减少了访问磁盘的时间。&lt;/p&gt; 
&lt;h4&gt;2.2 延后处理&lt;/h4&gt; 
&lt;p&gt;还是支付宝，上栗子：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;集五福活动&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448256_007S8ZIlgy1gifje6vocvj30iy0s0qhh.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;这是支付宝春节集五福活动开奖当晚，不过，作为非酋的我一般是不屑于参与这种活动的。&lt;/p&gt; 
&lt;p&gt;大家发现没有，这类活动中奖奖金一般会显示 &lt;strong&gt;「稍后到账」&lt;/strong&gt;，为什么呢？那当然是到账这个操作不简单！&lt;/p&gt; 
&lt;p&gt;到账即转账，A 账户给 B 账户转钱，A 减钱， B 就必须要同时加上钱，也就是说不能 A 减了钱但 B 没有加上，这就会导致资金损失。资金安全是支付业务的生命线，这可不行。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;这两个动作必须一起成功或是一起都不成功，不能只成功一半，这是保证数据一致性。&lt;/strong&gt; 保证两个操作同时成功或者失败就需要用到&lt;strong&gt;事务&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;如果去实时的做到账，那么大概率数据库的 &lt;strong&gt;TPS（每秒处理的事务数）&lt;/strong&gt; 会是瓶颈。通过产品提示，将到账操作延后处理，解决了数据库 TPS 瓶颈。&lt;/p&gt; 
&lt;p&gt;延后处理还有一个非常著名的例子，&lt;strong&gt;COW（Copy On Write，写时复制）。&lt;/strong&gt; Linux 创建进程的系统调用 fork，fork 产生的子进程只会创建虚拟地址空间，而不会分配真正的物理内存，子进程共享父进程的物理空间，只有当某个进程需要写入的时候，才会真正分配物理页，拷贝该物理页，通过 COW 减少了很多不必要的数据拷贝。&lt;/p&gt; 
&lt;h3&gt;三、池化&lt;/h3&gt; 
&lt;p&gt;后台开发过程中你一定离不开各种 &lt;strong&gt;「池子」：&lt;/strong&gt; 内存池、连接池、线程池、对象池......&lt;/p&gt; 
&lt;p&gt;内存、连接、线程这些都是资源，创建线程、分配内存、数据库连接这些操作都有一个特征， 那就是&lt;strong&gt;创建和销毁过程都会涉及到很多系统调用或者网络 IO。&lt;/strong&gt; 每次都在请求中去申请创建这些资源，就会增加请求处理耗时，但是如果我们用一个 &lt;strong&gt;容器（池）&lt;/strong&gt; 把它们保存起来，下次需要的时候，直接拿出来使用，避免重复创建和销毁浪费的时间。&lt;/p&gt; 
&lt;h4&gt;3.1 内存池&lt;/h4&gt; 
&lt;p&gt;在 C/C++ 中，经常使用 malloc、new 等 API 动态申请内存。由于申请的内存块大小不一，如果频繁的申请、释放会导致大量的&lt;strong&gt;内存碎片&lt;/strong&gt;，并且这些 API 底层依赖系统调用，会有额外的开销。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;内存池就是在使用内存前，先向系统申请一块空间留做备用，使用者需要内池时向内存池申请，用完后还回来。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;内存池的思想非常简单，实现却不简单，难点在于以下几点:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;如何快速分配内存&lt;/strong&gt; &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;降低内存碎片率&lt;/strong&gt; &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;维护内存池所需的额外空间尽量少&lt;/strong&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;&lt;span&gt;如果不考虑效率，我们完全可以将内存分为不同大小的块，然后用&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%93%BE%E8%A1%A8&quot; target=&quot;_blank&quot;&gt;链表&lt;/a&gt;连接起来，分配的时候找到大小最合适的返回，释放的时候直接添加进&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%93%BE%E8%A1%A8&quot; target=&quot;_blank&quot;&gt;链表&lt;/a&gt;。如:&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;空闲链表&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448286_007S8ZIlgy1gifk4wterkj31ii0s6abs.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;当然这只是玩具级别的实现，业界有性能非常好的实现了，我们可以直接拿来学习和使用。&lt;/p&gt; 
&lt;p&gt;比如 Google 的 「tcmalloc」 和 Facebook 的 「jemalloc」。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;限于篇幅我们不在这里详细讲解它们的实现原理，如果感兴趣可以搜来看看，也推荐去看看被誉为神书的 CSAPP（《深入理解计算机系统》）第 10 章，那里也讲到了动态内存分配&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;h4&gt;3.2 线程池&lt;/h4&gt; 
&lt;p&gt;线程是干嘛的？线程就是我们&lt;strong&gt;程序执行的实体&lt;/strong&gt;。在服务器开发领域，我们经常会为每个请求分配一个线程去处理，但是线程的创建销毁、调度都会带来额外的开销，线程太多也会导致系统整体性能下降。在这种场景下，我们通常会提前创建若干个线程，通过线程池来进行管理。当请求到来时，只需从线程池选一个线程去执行处理任务即可。&lt;/p&gt; 
&lt;p&gt;线程池常常和&lt;strong&gt;队列&lt;/strong&gt;一起使用来实现&lt;strong&gt;任务调度&lt;/strong&gt;，主线程收到请求后将创建对应的任务，然后放到队列里，线程池中的工作线程等待队列里的任务。&lt;/p&gt; 
&lt;p&gt;线程池实现上一般有四个核心组成部分:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;管理器（Manager）:&lt;/strong&gt; 用于创建并管理线程池。 &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;工作线程（Worker）:&lt;/strong&gt; 执行任务的线程。 &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;任务接口（Task）:&lt;/strong&gt; 每个具体的任务必须实现任务接口，工作线程将调用该接口来完成具体的任务。 &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;任务队列（TaskQueue）:&lt;/strong&gt; 存放还未执行的任务。 &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;线程池模型&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448290_007S8ZIlgy1gifknuico6j31er0u0u0x.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;线程池在 C、C++ 中没有具体的实现，需要应用开发者手动实现上诉几个部分。&lt;/p&gt; 
&lt;p&gt;在 Java 中 &lt;strong&gt;「ThreadPoolExecutor」&lt;/strong&gt; 类就是线程池的实现。后续我也会写文章分析 C++ 如何写一个简单的线程池以及 Java 中线程池是如何实现的。&lt;/p&gt; 
&lt;h4&gt;3.3 连接池&lt;/h4&gt; 
&lt;p&gt;顾名思义，连接池是创建和管理连接的。&lt;/p&gt; 
&lt;p&gt;大家最熟悉的莫过于数据库连接池，这里我们简单分析下如果不用数据库连接池，一次 SQL 查询请求会经过哪些步骤:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;和 MySQL server 建立 TCP 连接:&lt;/strong&gt;
   &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;MySQL 权限认证：&lt;/strong&gt;
  &lt;ul&gt; 
   &lt;li&gt;Server 向 Client 发送 密钥 &lt;/li&gt;
   &lt;li&gt;Client 使用密钥加密用户名、密码等信息，将加密后的报文发送给 Server &lt;/li&gt;
   &lt;li&gt;Server 根据 Client 请求包，验证是否是合法用户，然后给 Client 发送认证结果 &lt;/li&gt;
  &lt;/ul&gt; &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;Client 发送 SQL 语句&lt;/strong&gt; &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;Server 返回语句执行结果&lt;/strong&gt; &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;MySQL 关闭&lt;/strong&gt; &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;TCP 连接断开&lt;/strong&gt;
   &lt;/li&gt;
&lt;/ol&gt; 
&lt;p&gt;可以看出不使用连接池的话，为了执行一条 SQL，会花很多时间在安全认证、网络IO上。&lt;/p&gt; 
&lt;p&gt;如果使用连接池，执行一条 SQL 就省去了建立连接和断开连接所需的额外开销。&lt;/p&gt; 
&lt;p&gt;还能想起哪里用到了连接池的思想吗？我认为 &lt;strong&gt;HTTP 长链接&lt;/strong&gt;也算一个变相的链接池，虽然它本质上只有一个连接，但是思想却和连接池不谋而合，都是为了复用同一个连接发送多个 HTTP 请求，避免建立和断开连接的开销。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;池化实际上是预处理和延后处理的一种应用场景，通过池子将各类资源的创建提前和销毁延后。&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;四、同步变异步&lt;/h3&gt; 
&lt;p&gt;对于处理耗时的任务，如果采用同步的方式，那么会增加任务耗时，降低系统并发度。&lt;/p&gt; 
&lt;p&gt;可以通过将同步任务变为异步进行优化。&lt;/p&gt; 
&lt;p&gt;举个例子，比如我们去 KFC 点餐，遇到排队的人很多，当点完餐后，大多情况下我们会隔几分钟就去问好了没，反复去问了好几次才拿到，在这期间我们也没法干活了，这时候我们是这样的：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;同步写法&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448286_007S8ZIlgy1gifvfsljxrj30u018ijyn.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;这个就叫&lt;strong&gt;同步轮训，&lt;/strong&gt; 这样效率显然太低了。&lt;/p&gt; 
&lt;p&gt;服务员被问烦了，就在点完餐后给我们一个号码牌，每次准备好了就会在服务台叫号，这样我们就可以在被叫到的时候再去取餐，中途可以继续干自己的事。&lt;/p&gt; 
&lt;p&gt;这就叫异步,在很多编程语言中有异步编程的库，比如 C++ std::future、Python asyncio 等，但是异步编程往往需要&lt;strong&gt;回调函数（Callback function）&lt;/strong&gt;，如果回调函数的层级太深，这就是&lt;strong&gt;回调地狱（Callback hell）&lt;/strong&gt;。回调地狱如何优化又是一个庞大的话题。。。。&lt;/p&gt; 
&lt;p&gt;这个例子相当于函数调用的异步化，还有的是情况是处理流程异步化，这个会在接下来消息队列中讲到。&lt;/p&gt; 
&lt;h3&gt;五、消息队列&lt;/h3&gt; 
&lt;p&gt;&lt;img alt=&quot;消息队列示意图&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448360_007S8ZIlgy1gifwp4n129j31880lwmy6.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;这是一个非常简化的消息队列模型，上游生产者将消息通过队列发送给下游消费者。在这之间，消息队列可以发挥很多作用，比如：&lt;/p&gt; 
&lt;h4&gt;5.1 服务解耦&lt;/h4&gt; 
&lt;p&gt;有些服务被其它很多服务依赖，比如一个论坛网站，当用户成功发布一条帖子有一系列的流程要做，有积分服务计算积分，推送服务向发布者的粉丝推送一条消息..... 对于这类需求，常见的实现方式是直接调用：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;直接调用&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448525_007S8ZIlgy1gifwm2nlw8j313e0k675u.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;这样如果需要新增一个&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90&quot; target=&quot;_blank&quot;&gt;数据分析&lt;/a&gt;的服务，那么又得改动发布服务，这违背了&lt;/span&gt;&lt;strong&gt;依赖倒置原则&lt;/strong&gt;，&lt;strong&gt;即上层服务不应该依赖下层服务，那么怎么办呢？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;发布订阅模式&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448603_007S8ZIlgy1gifwo36vdzj319e0k8765.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;引入消息队列作为中间层，当帖子发布完成后，发送一个事件到消息队列里，而关心&lt;strong&gt;帖子发布成功&lt;/strong&gt;这件事的下游服务就可以订阅这个事件，这样即使后续继续增加新的下游服务，只需要订阅该事件即可，完全不用改动发布服务，完成系统解耦。&lt;/p&gt; 
&lt;h4&gt;5.2 异步处理&lt;/h4&gt; 
&lt;p&gt;有些业务涉及到的处理流程非常多，但是很多步骤并不要求实时性。那么我们就可以通过消息队列异步处理。比如淘宝下单，一般包括了&lt;strong&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A3%8E%E6%8E%A7&quot; target=&quot;_blank&quot;&gt;风控&lt;/a&gt;、锁库存、生成订单、短信/邮件通知&lt;/span&gt;&lt;/strong&gt;等步骤。但是&lt;strong&gt;&lt;span&gt;核心的就&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A3%8E%E6%8E%A7&quot; target=&quot;_blank&quot;&gt;风控&lt;/a&gt;和锁库存，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 只要&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A3%8E%E6%8E%A7&quot; target=&quot;_blank&quot;&gt;风控&lt;/a&gt;和扣减库存成功，那么就可以返回结果通知用户成功下单了。&lt;/span&gt;&lt;strong&gt;后续的生成订单，短信通知都可以通过消息队列发送给下游服务异步处理。大大提高了系统响应速度。&lt;/strong&gt; &lt;/p&gt; 
&lt;p&gt;这就是处理流程异步化。&lt;/p&gt; 
&lt;h4&gt;5.3 流量削峰&lt;/h4&gt; 
&lt;p&gt;一般像秒杀、抽奖、抢卷这种活动都伴随着&lt;strong&gt;短时间海量的请求，&lt;/strong&gt; 一般超过后端的处理能力，那么我们就可以在接入层将请求放到消息队列里，后端根据自己的处理能力不断从队列里取出请求进行业务处理。&lt;/p&gt; 
&lt;p&gt;就像最近长江汛期，上游短时间大量的洪水汇聚直奔下游，但是通过三峡大坝将这些水缓存起来，然后匀速的向下游释放，起到了很好的削峰作用。&lt;/p&gt; 
&lt;p&gt;起到了平均流量的作用。&lt;/p&gt; 
&lt;h4&gt;5.4 总结&lt;/h4&gt; 
&lt;p&gt;消息队列的核心思想就是把同步的操作变成异步处理，异步处理会带来相应的好处，比如:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;服务解耦 &lt;/li&gt;
 &lt;li&gt;提高系统的并发度，将非核心操作异步处理，不会阻塞住主流程 &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;但是软件开发没有银弹，所有的方案选择都是一种 &lt;strong&gt;trade-off。&lt;/strong&gt; 同样，异步处理也不全是好处，也会导致一些问题：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;降低了数据一致性，从强一致性变为最终一致性 &lt;/li&gt;
 &lt;li&gt;有消息丢失的风险，比如宕机，需要有容灾机制 &lt;/li&gt;
&lt;/ul&gt; 
&lt;h3&gt;六、批量处理&lt;/h3&gt; 
&lt;p&gt;在涉及到网络连接、IO等情况时，将操作批量进行处理能够有效提高系统的传输速率和吞吐量。&lt;/p&gt; 
&lt;p&gt;在前后端通信中，&lt;strong&gt;通过合并一些频繁请求的小资源可以获得更快的加载速度。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;比如我们后台 RPC 框架，经常有更新数据的需求，而有的数据更新的接口往往只接受一项，这个时候我们往往会优化下更新接口，&lt;/p&gt; 
&lt;p&gt;使其能够接受批量更新的请求，这样可以将批量的数据一次性发送，大大缩短网络 RPC 调用耗时。&lt;/p&gt; 
&lt;h3&gt;七、数据库&lt;/h3&gt; 
&lt;p&gt;我们常把后台开发调侃为「CRUD」，数据库在整个应用开发过程中的重要性不言而喻。&lt;/p&gt; 
&lt;p&gt;而且很多时候系统的瓶颈也往往处在数据库这里，慢的原因也有很多，比如可能是没用索引、没用对索引、读写锁冲突等等。&lt;/p&gt; 
&lt;p&gt;那么如何使用数据才能又快又好呢？下面这几点需要重点关注：&lt;/p&gt; 
&lt;h4&gt;7.1 索引&lt;/h4&gt; 
&lt;p&gt;索引可能是我们平时在使用数据库过程中接触得最多的优化方式。索引好比图书馆里的书籍索引号，想象一下，如果我让你去一个没有书籍索引号的图书馆找《人生》这本书，你是什么样的感受？当然是怀疑人生，同理，你应该可以理解当你查询数据，却不用索引的时候数据库该有多崩溃了吧。&lt;/p&gt; 
&lt;p&gt;数据库表的索引就像图书馆里的书籍索引号一样，可以提高我们检索数据的效率。索引能提高查找效率，可是你有没有想过为什么呢？&lt;strong&gt;&lt;span&gt;这是因为索引一般而言是一个&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;列表，&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;意味着可以基于二分思想进行查找，将查询时间复杂度做到 O(log(N))，快速的支持等值查询和范围查询。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;二叉搜索树查询效率无疑是最高的，因为平均来说每次比较都能缩小一半的搜索范围，但是一般在数据库索引的实现上却会选择 B 树或 B+ 树而不用二叉搜索树，为什么呢？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;这就涉及到数据库的存储介质了，数据库的数据和索引都是存放在磁盘，并且是 InnoDB 引擎是以页为基本单位管理磁盘的，一页一般为 16 KB。AVL 或&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%BA%A2%E9%BB%91%E6%A0%91&quot; target=&quot;_blank&quot;&gt;红黑树&lt;/a&gt;搜索效率虽然非常高，&lt;/span&gt;&lt;strong&gt;但是同样数据项，它也会比 B、B+ 树更高，高就意味着平均来说会访问更多的节点，即磁盘IO次数！&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;根据 Google 工程师 Jeff Dean 的统计，访问内存数据耗时大概在 100 ns，访问磁盘则是 10,000,000 ns。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;所以表面上来看我们使用 B、B+ 树没有 二叉查找树效率高，但是实际上由于 B、B+ 树降低了树高，减少了磁盘 IO 次数，反而大大提升了速度。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;这也告诉我们，没有绝对的快和慢，系统分析要抓主要矛盾，先分析出决定系统瓶颈的到底是什么，然后才是针对瓶颈的优化。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;其实关于索引想写的也还有很多，但还是受限于篇幅，以后再单独写。&lt;/p&gt; 
&lt;p&gt;先把我认为索引必知必会的知识列出来，大家可以查漏补缺:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;主键索引和普通索引，以及它们之间的区别&lt;/strong&gt; &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;最左前缀匹配原则&lt;/strong&gt; &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;索引下推&lt;/strong&gt; &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;覆盖索引、联合索引&lt;/strong&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;h4&gt;7.2 读写分离&lt;/h4&gt; 
&lt;p&gt;一般业务刚上线的时候，直接使用单机数据库就够了，但是随着用户量上来之后，系统就面临着大量的写操作和读操作，单机数据库处理能力有限，容易成为系统瓶颈。&lt;/p&gt; 
&lt;p&gt;由于存在读写锁冲突，并且很多大型互联网业务往往&lt;strong&gt;读多写少&lt;/strong&gt;，读操作会首先成为数据库瓶颈，我们希望消除读写锁冲突从而提升数据库整体的读写能力。&lt;/p&gt; 
&lt;p&gt;那么就需要采用读写分离的数据库集群方式，一主多从，主库会同步数据到从库。写操作都到主库，读操作都去从库。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;读写分离&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448685_007S8ZIlgy1gifs6y545lj317m0tygpu.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;读写分离到之后就避免了读写锁争用，这里解释一下，什么叫读写锁争用：&lt;/p&gt; 
&lt;p&gt; MySQL 中有两种锁: &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;排它锁( X 锁)：&lt;/strong&gt; 事务 T 对数据 A 加上 X 锁时，&lt;strong&gt;只允许事务 T 读取和修改数据 A。&lt;/strong&gt; &lt;/li&gt;
 &lt;li&gt;&lt;strong&gt;共享锁( S 锁)：&lt;/strong&gt; 事务 T 对数据 A 加上 S 锁时，&lt;strong&gt;其他事务只能再对数据 A 加 S 锁，而不能加 X 锁，直到 T 释放 A 上的 S 锁。&lt;/strong&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;读写分离解决问题的同时也会带来新问题，比如主库和从库数据不一致&lt;/p&gt; 
&lt;p&gt;MySQL 的主从同步依赖于 binlog，binlog(二进制日志)是 MySQL Server 层维护的一种二进制日志，是独立于具体的存储引擎。它主要存储对数据库更新(insert、delete、update)的 SQL 语句，由于记录了完整的 SQL 更新信息，所以 binlog 是可以用来数据恢复和主从同步复制的。&lt;/p&gt; 
&lt;p&gt;从库从主库拉取 binlog 然后依次执行其中的 SQL 即可达到复制主库的目的，由于从库拉取 binlog 存在网络延迟等，所以主从数据存在延迟问题。&lt;/p&gt; 
&lt;p&gt;那么这里就要看业务是否允许短时间内的数据不一致，如果不能容忍，那么可以通过如果读从库没获取到数据就去主库读一次来解决。&lt;/p&gt; 
&lt;h4&gt;7.3 分库分表&lt;/h4&gt; 
&lt;p&gt;如果用户越来越多，写请求暴涨，对于上面的单 Master 节点肯定扛不住，那么该怎么办呢？多加几个 Master？不行，这样会带来更多的数据不一致的问题，增加系统的复杂度。那该怎么办？就只能对库表进行拆分了。&lt;/p&gt; 
&lt;p&gt;常见的拆分类型有&lt;strong&gt;垂直拆分和水平拆分。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;考虑拼夕夕电商系统，一般有 &lt;strong&gt;订单表、用户表、支付表、商品表、商家表等，&lt;/strong&gt; 最初这些表都在一个数据库里。&lt;br/&gt;后来随着砍一刀带来的海量用户，拼夕夕后台扛不住了! 于是紧急从阿狸粑粑那里挖来了几个 P8、P9 大佬对系统进行重构。&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;P9 大佬第一步先对数据库进行垂直分库，&lt;br/&gt;&lt;strong&gt;根据业务关联性强弱，将它们分到不同的数据库，&lt;/strong&gt; 比如订单库，商家库、支付库、用户库。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;第二步是对一些大表进行垂直分表，&lt;strong&gt;将一个表按照字段分成多表，每个表存储其中一部分字段。&lt;/strong&gt; 比如商品详情表可能最初包含了几十个字段，但是往往最多访问的是商品名称、价格、产地、图片、介绍等信息，所以我们将不常访问的字段单独拆成一个表。&lt;/p&gt; &lt;/li&gt;
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;由于垂直分库已经按照业务关联切分到了最小粒度，数据量任然非常大，&lt;strong&gt;P9 大佬开始水平分库，比如可以把订单库分为订单1库、订单2库、订单3库......&lt;/strong&gt;&lt;span&gt; 那么如何决定某个订单放在哪个订单库呢？可以考虑对主键通过哈希&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;计算放在哪个库。 &lt;/span&gt;&lt;/li&gt;
 &lt;li&gt;分完库，单表数据量任然很大，查询起来非常慢，&lt;strong&gt;P9 大佬决定按日或者按月将订单分表，叫做日表、月表。&lt;/strong&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;分库分表同时会带来一些问题，比如平时单库单表使用的主键自增特性将作废，因为某个分区库表生成的主键无法保证全局唯一，这就需要引入全局 UUID 服务了。&lt;/p&gt; 
&lt;p&gt;经过一番大刀阔斧的重构，拼夕夕恢复了往日的活力，大家又可以愉快的在上面互相砍一刀了。&lt;/p&gt; 
&lt;p&gt;(分库分表会引入很多问题，并没有一一介绍，这里只是为了讲解什么是分库分表)&lt;/p&gt; 
&lt;h3&gt;八、具体技法&lt;/h3&gt; 
&lt;h4&gt;8.1 零拷贝&lt;/h4&gt; 
&lt;p&gt;高性能的服务器应当避免不必要数据复制，特别是在&lt;strong&gt;用户空间和内核空间之间的数据复制。&lt;/strong&gt; 比如 HTTP 静态服务器发送静态文件的时候，一般我们会这样写:&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;发送文件&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448662_007S8ZIlgy1gifp0trcwkj31ix0u0qbr.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;如果了解 Linux IO 的话就知道这个过程包含了内核空间和用户空间之间的多次拷贝：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;IO示意图&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448748_007S8ZIlgy1gifp2f3hmgj319m0to0vo.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;内核空间和用户空间之间数据拷贝需要 CPU 亲自完成，但是对于这类&lt;strong&gt;数据不需要在用户空间进行处理&lt;/strong&gt;的程序来说，这样的两次拷贝显然是浪费。什么叫 &lt;strong&gt;「不需要在用户空间进行处理」？&lt;/strong&gt; &lt;/p&gt; 
&lt;p&gt;比如 FTP 或者 HTTP 静态服务器，它们的作用只是将文件从磁盘发送到网络，不需要在中途对数据进行编解码之类的计算操作。&lt;/p&gt; 
&lt;p&gt;如果能够直接将数据在内核缓存之间移动，那么除了减少拷贝次数以外，还能避免内核态和用户态之间的上下文切换。&lt;/p&gt; 
&lt;p&gt;而这正是零拷贝（Zero copy）干的事，主要就是利用各种零拷贝技术，减少不必要的数据拷贝，将 CPU 从数据拷贝这样简单的任务解脱出来，让 CPU 专注于别的任务。&lt;/p&gt; 
&lt;p&gt;常用的零拷贝技术:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;mmap&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&amp;lt;kbd&amp;gt;mmap&amp;lt;/kbd&amp;gt; 通过内存映射，将文件映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。这样，在进行网络传输时，就可以减少内核空间到用户空间的拷贝次数。&lt;/p&gt; &lt;/li&gt;
&lt;/ol&gt; 
&lt;p&gt;&lt;img alt=&quot;mmap&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448841_007S8ZIlgy1gifpjzd2fqj319b0u0tbk.jpg&quot;/&gt;&lt;/p&gt; 
&lt;ol start=&quot;2&quot;&gt; 
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;sendfile&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&amp;lt;kbd&amp;gt;sendfile&amp;lt;/kbd&amp;gt; 是 Linux2.1 版本提供的，数据不经过用户态，直接从页缓存拷贝到 socket 缓存，同时由于和用户态完全无关，就减少了一次上下文切换。&lt;/p&gt; &lt;p&gt;在 Linux 2.4 版本，对 sendfile 进行了优化，直接通过 DMA 将磁盘文件数据读取到 socket 缓存，真正实现了 ”0” 拷贝。前面 mmap 和 2.1 版本的 sendfile 实际上只是消除了用户空间和内核空间之间拷贝，而页缓存和 socket 缓存之间的拷贝依然存在。&lt;/p&gt; &lt;/li&gt;
&lt;/ol&gt; 
&lt;h4&gt;8.2 无锁化&lt;/h4&gt; 
&lt;p&gt;在多线程环境下，为了避免 &lt;strong&gt;竞态条件（race condition），&lt;/strong&gt; 我们通常会采用加锁来进行并发控制，锁的代价也是比较高的，锁会导致上线文切换，甚至被挂起直到锁被释放。&lt;/p&gt; 
&lt;p&gt;基于硬件提供的原子操作 &lt;strong&gt;CAS(Compare And Swap)&lt;/strong&gt; 实现一些高性能无锁的数据结构，比如无锁队列，可以在保证并发安全的情况下，提供更高的性能。&lt;/p&gt; 
&lt;p&gt;首先需要理解什么是 CAS，CAS 有三个操作数，内存里当前值M，预期值 E，修改的新值 N，CAS 的语义就是：&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如果当前值等于预期值，则将内存修改为新值，否则不做任何操作&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;用 C 语言来表达就是:&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;CAS&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448878_007S8ZIlgy1gifr9ideb7j31oo0u0dot.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;注意，上面 CAS 函数实际上是一条原子指令，那么是如何用的呢？&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;假设我需要实现这样一个功能：&lt;/p&gt; 
&lt;p&gt; 对一个全局变量 global 在两个不同线程分别对它加 100 次，这里多线程访问一个全局变量存在 race condition，所以我们需要采用线程同步操作，下面我分别用锁和CAS的方法来实现这个功能。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;CAS和锁示范&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20201120/652587393_1605873448874_007S8ZIlgy1gifrq8av5vj30u014z1dw.jpg&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;通过使用原子操作大大降低了锁冲突的可能性，提高了程序的性能。&lt;/p&gt; 
&lt;p&gt;除了 CAS，还有一些硬件原子指令：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fetch-And-Add，对变量原子性 + 1 &lt;/li&gt;
 &lt;li&gt;&lt;span&gt;Test-And-Set，这是各种锁&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;的核心，在 AT&amp;amp;T/GNU 汇编语法下，叫 xchg 指令，我会单独写一篇如何使用 xchg 实现各种锁。 &lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt; 
&lt;h4&gt;8.3 序列化与反序列化&lt;/h4&gt; 
&lt;p&gt;先看看维基百科怎么定义的序列化：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;In computing, serialization (US spelling) or serialisation (UK spelling) is the process of translating a data structure or object state into a format that can be stored (for example, in a file or memory data buffer) or transmitted (for example, across a computer network) and reconstructed later (possibly in a different computer environment). When the resulting series of bits is reread according to the serialization format, it can be used to create a semantically identical clone of the original object. For many complex objects, such as those that make extensive use of references, this process is not straightforward. Serialization of object-oriented objects does not include any of their associated methods with which they were previously linked.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;我相信你大概率没有看完上面的英文描述，其实我也不爱看英文资料，总觉得很慢，但是计算机领域一手的学习资料都是美帝那边的，所以没办法，必须逼自己去试着读一些英文的资料。&lt;/p&gt; 
&lt;p&gt;实际上也没有那么难，熟悉常用的几百个专业名词，句子都是非常简单的一些从句。没看的话，再倒回去看看？&lt;/p&gt; 
&lt;p&gt;这里我就不做翻译了，主要是水平太低，估计做到「信达雅」的信都很难。&lt;/p&gt; 
&lt;p&gt;扯远了，还是回到序列化来。&lt;/p&gt; 
&lt;p&gt;所有的编程一定是围绕数据展开的，而数据呈现形式往往是结构化的，比如&lt;strong&gt;结构体（Struct）、类（Class）。&lt;/strong&gt; 但是当我们 &lt;strong&gt;通过网络、磁盘等传输、存储数据的时候却要求是二进制流。&lt;/strong&gt; 比如 TCP 连接，它提供给上层应用的是面向连接的可靠字节流服务。那么如何将这些结构体和类转化为可存储和可传输的字节流呢？这就是序列化要干的事情，反之，从字节流如何恢复为结构化的数据就是反序列化。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;序列化解决了对象持久化和跨网络数据交换的问题。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;序列化一般按照序列化后的结果是否可读，可分为以下两类：&lt;/p&gt; 
 
&lt;p&gt;还有 Java 、Go 这类语言内置了序列化方式，比如在 Java 里实现了 Serializable 接口即表示该对象可序列化。&lt;/p&gt; 
&lt;p&gt;说到这让我想起了大一写的的两个程序，一个是用刚 C 语言写的公交管理系统，当时需要将公交线路、站点信息持久化保存，当时的方案就是每个公交线路写在一行，用 &quot;|&quot;分割信息，比如：&lt;/p&gt; 
&lt;pre class=&quot;prettyprint&quot; from-niu=&quot;default&quot;&gt;5|6:00-22:00|大学城｜南山站｜北京站
123|6:30-23:00｜南湖大道｜茶山刘｜世界&lt;/pre&gt;
&lt;p&gt;第一列就是线路编号、第二项是发车时间、后面就是途径的站点。是不是非常原始？实际上这也是一种序列化方式，只是效率很低，也不通用。而且存在一个问题就是如果信息中包含 “｜”怎么办？当然是用转义。&lt;/p&gt; 
&lt;p&gt;第二个程序是用 Java 写的网络五子棋，当时需要通过网络传输表示棋子位置的对象，查了一圈最后发现只需要实现 Serializable 接口，自己什么都不用干，就能自己完成对象的序列化，然后通过网络传输后反序列化。当时哪懂得这就叫序列化，只觉得牛逼、神奇！&lt;/p&gt; 
&lt;p&gt;最后完成了一个可以网络五子棋，拉着隔壁室友一起玩。。。真的是成就感满满哈哈哈。&lt;/p&gt; 
&lt;p&gt;说来在编程方面，已经很久没有这样的成就感了。&lt;/p&gt; 
&lt;h2&gt;总结&lt;/h2&gt; 
&lt;p&gt;这篇文章主要是粗浅的介绍了一些系统设计、系统优化的套路和最佳实践。&lt;/p&gt; 
&lt;p&gt;不知道你发现没有，从缓存到消息队列、CAS......，很多看起来很牛逼的架构设计其实都来源于操作系统、体系结构。&lt;/p&gt; 
&lt;p&gt;所以我非常热衷学习一些底层的基础知识，这些看似古老的技术是经过时间洗礼留下来的好东西。现在很多的新技术、框架看似非常厉害，实则不少都是新瓶装旧酒，每几年又会被淘汰一批。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;来自我的&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%89%9B%E5%AE%A2&quot; target=&quot;_blank&quot;&gt;牛客&lt;/a&gt;博客:&lt;/span&gt;&lt;br/&gt;&lt;a href=&quot;https://blog.nowcoder.net/n/8de2902353c5438eafe95ce8f475cdbd&quot; target=&quot;_blank&quot; from-niu=&quot;default&quot;&gt;后台服务器高性能架构设计&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;最后说一句（求赞）&lt;/h2&gt; 
&lt;p&gt;小伙伴们如果觉得写得不错, 顺便帮我点个赞呗~&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>fa9378bfcfa4d1df5e8535c009ee905a</guid>
<title>[推荐] 中后台领域低代码搭建设计与实践</title>
<link>https://toutiao.io/k/9mznc2m</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;108&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.1859375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPiadQyCOHNzUdyYbWTfk32WkUfq4DV9FJsfiatfYcicXiaL0Dwm8UdSDemw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;前言&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;2021年5月22日，哈啰技术沙龙-大前端的探索与实践，在杭州成功举办。&lt;br/&gt;以下是由 @杜诗晨（庙爷）分享的主题&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.6666666666666666&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPLliaW0A8SjYmsv7pEaOPNziaeRGVLSBoNw1HJHhKQuVAea3h433s7oFA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1620&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;什么是低代码搭建&lt;/span&gt;&lt;/h1&gt;&lt;blockquote&gt;&lt;p&gt;通过提供一种可视化的应用开发环境，降低或去除对原生代码编写的需求量快速构建应用程序。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;传统开发交付一个产品的流程，首先产品输出 prd，然后设计 ui 设计进行设计，设计完成给到前端，前端再去开发。如果是个新项目可能还要这种配置各种复杂环境。同时后端也在开发，然后联调、测试。其实现在大部分的公司都是这种开发流程。那这种缺点就很明显，涉及到的人非常多，开发周期也变得非常长。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPtOS1u4Cl3aOgShwe38SfJeVNeUwxzkrkjOXKymScEr02cesdiaouVEA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;p&gt;低代码搭建是一个什么样的流程？如果是一个成熟的配置搭建平台，只需要提供一个配置平台，开发人员不论是刚毕业的大学生或者是前端小白，甚至可能是一个后端开发，都可以通过这个配置平台搭建，快速生成网页。&lt;/p&gt;&lt;p&gt;关于低代码的市场规模和衍生的历史大家可以从下图中了解一下，这里提供两份报告作为延伸学习：海比研究报告 | 艾瑞咨询&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPMicFWOGIhnFvY0kibU57uAwpHmQQf4YDqhIialSRibhZyJDQD3T6giaD03A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;概念衍生历史&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;低代码这个概念其实很早就有了，80年代的时候提出了第四代编程语言，这个第四代是什么意思呢，第一代是机器语言，第二代汇编语言，第三代高级语言。前三代都是操作语言，需要编程指出怎么做，一步一步的写运行步骤，这样是有学习成本的，并且项目开发周期长，出于商业需要第四代语言被软件厂商提出，在一定程度上只需要说明做什么，有什么目的，不需要写出怎么做的过程。&lt;/p&gt;&lt;p&gt;2000 年 vpl 被提出，可视化编程语言，意思就是用户用过图形化操作程序元素而不是通过文本制定来创建程序，基于流的概念比如虚幻引擎，还有一些运用在3D编程，音乐合成，信号处理，物联网嵌入式等等领域。&lt;/p&gt;&lt;p&gt;2014年知名咨询公司提出了低代码/零代码的概念，在这之前国外有很多低代码产品出现并且商业化&lt;/p&gt;&lt;p&gt;2016年，国内相继发布这些低代码的平台。国内知名的像阿里百度腾讯，他们都有这种搭建平台。&lt;/p&gt;&lt;p&gt;在今年（2021），整个中国市场已经形成了完整的低代码无代码的生态体系。就比如说像现在这种 aPass 平台或者是 Sass 平台之类的，平台会包含的低代码去快速搭建这种应用。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPoAWlumsz3iaE2bEv1YfoNdrA4MCet3TFKBohYH9ibhPkJW0m5yaOkuibA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;市场规模&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;投资界似乎也发现了这种趋势，全球规模在去年的时候已经达到了八十四亿美元。预计今年超过百亿。23年超过200亿。&lt;/p&gt;&lt;p&gt;比如说二月份的时候，就有一家创业公司，他们融了大概上亿美元，估值也有几十亿。所以说这一块从全球的低代码的市场规模来说，低代码还是非常有潜力的。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPyYa4lGG9S22xhiaGbZoibdicDq5icOg2UGCwSB2tW394djib3Dwz1k1v1hQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;搭建分类&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;现在市场上基本上分为两类搭建类型，一类是营销类搭建 no code，一类是通用类搭建，就是我们所说的 low code 和 pro code。营销类 no node 无需编码，直接生成营销活动，前端资源紧缺的时候，后端开发人员也可通过 low code 可搭建中台领域的页面，前端这边为了避免各种工程环境，减低门槛也可通过 pro code 的形式来去搭建。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPUTtjuEjyaH1S3gBm6wwBYsBh8asSEg8NysWooFMXXhS4fqiaZl3YASg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;面向人群&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;那么这么分类我认为是面向的人群不同，一个特别通用的搭建平台，可能复杂度就上升了很高，所以说我们要做这个低代码搭建平台的时候，一定要想好我们面向的人群是什么？&lt;br/&gt;营销类 no node 无需编码，直接生成营销活动，前端资源紧缺的时候，后端开发人员也可通过 low code 可搭建中台领域的页面，前端这边为了避免各种工程环境，减低门槛也可通过 pro code 的形式来去搭建&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPQyMUSThEYuXTFOveibzCLxWLUwQvibpOdvqAzPHLPbloDarBBdzPhVmA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;中后台领域痛点&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;首先交互不统一，比如说有一些很相似的页面，但是由不同的产品或者设计师出的图。&lt;br/&gt;那实际上他们想要达到的效果是很相似的。但是交互不同，不同的前端开发出来的效果也不一样。不同职级的开发可维护性就会差一点，代码可能会复杂一些，会出现不同的编码风格。中台还有一个痛点的就是中台的系统非常多，业务重，人员有缺口。我之前负责的那个域，前后端比例当时是有 1：7 的样子，借人也好，招人也好，都是很难去补上这个缺口。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPQd03Ta3ibMkOAVibnGRwQsICj1P5xjS3R35FbyXcicwvMicAEHk1H5o7fg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;设定目标&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;所以我们设定了三个目标，一个是提效降本。我们怎么样去把这一块的研发效能提上来。&lt;br/&gt;第二个目标是部分生产力可转移后端，让后端也有能力输出前端页面&lt;br/&gt;第三点就是抽象中后台的系统基础组件。前端在组件化的过程中逐渐沉淀，复用这些能力，赋能到搭建平台中。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;如何做？波塞冬建站平台&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;有了这些目标，促使我们做了波塞冬建站平台，通过可视化操作 + 部分编码(或者不编码)生成中后台系统。让前端业务开发变成组件开发，逐渐沉淀可复用组件，让简单业务少编码甚至不编码。为前端增效，为后端赋能。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPvpiaBRx4ViaRSNRWYhxRxMHEh08I0zxKR9mA5vL4mjeficcOLDiaVMhkcg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;使用数据&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;这个平台上线之后，线上的有117个页面在运行，共发布了870次，其中已经设计了6个团队，提升的人效也很显著，假设我们平均开发一个增量页面需要3人日，用波塞冬只需要一人日，老页面迭代修改配置也只需要0.5d&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPOhSrM6IIQicQAldHHsMMUuiaUCYo4htAYSNQHjOiakVZHvwHvK0HQibGKg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;平台流程&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;给大家讲解下平台原理，比如说一个创建者，他首先要去波塞冬平台创建页面，生成一份 schema ，这份 schema 被波塞冬后端保存在SQL中，我们的用户，也就是页面访问者，通过业务平台网站获取页面，这里边相当于业务平台网站有个sdk，他直接取拉波塞冬保存的schema，sdk通过 schema 渲染组件 和 业务数据的接口，这样一个页面就展示出来了&lt;br/&gt;那我们这边也有很多组件贡献者，如果创建者不满足需求的，贡献者这边去维护组件这样就能贡献生态&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPZ08hKMr6JKFcwUYgkXXJ3xIWiaW9GicWrRicxf567r3RNUqsB45x3BrvA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;平台架构&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;整个平台的架构是这样的：&lt;br/&gt;底层我们是拿vue搭建，不过这块技术选型哪个框架都可以，只要定义好 schema，react + antd 也能搞&lt;br/&gt;组件这一块就是根据固定的 schema 进行封装，未来可能还有一些业务组件接入&lt;br/&gt;渲染这一层主要是提供给开发者用来丰富组件库或一些其他业务场景&lt;br/&gt;平台能力也就是我们要提供的这个界面，主要是一些用户可以操作的功能，这些功能想一下入手还有一点小成本，我们提供了文档，视频等，可以做到边接入边开发，还提供了一些实例供配置方借鉴&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPTCUSNfcjCVy43TEss2hvkOcxw5xN1xuLSl5xEGicTGhKNOxCNzCdAyg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;接入方式&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;我们的解析方式有三种，一种是 sdk直接引入，这样方便升级，也方便二次开发，sdk的引入方式非常灵活。&lt;br/&gt;还有一种是 ifame 引入，这样只需引入一个标签即可，剩下的都在波塞冬里配置。&lt;br/&gt;一键建站的方式，相当于站点维度，没有项目的概念，域名菜单权限页面，都是在波塞冬里完成的，不需要本地环境，这种比较适合后端开发人员&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPYIFicTOAKdIugLe0eumicq90LiaUkuKJIWDxiaJXhqrQRvRsGiaicJLj99Hw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;渲染引擎&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;展示一下 sdk 的引用，我们可能会在不同开发环境中引入，这里提供环境变量的配置&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPA65kczibOWUc6vy7J6ZTPXtjlguSqGCm9WLkm6mF0Dp4xuB3jZuDYtg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;一键建站&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;刚才有介绍我们有三种引入方式，给大家看下第三种一键建站是怎么做的，我们加强了应用管理，一个应用就是一个站点，菜单，域名都是在平台里申请，这样用户通过页面访问就是配置的界面，完全不需要再去申请工程，这里我们用了代理的方式进行一个转发，转发的目标是一个基座，类似微前端的那个基座，只不过这个基座我们通过当前域名拉取配置，最终提供给用户。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPVfuBTLcG5rzYZDNTb4qxRJVGTKbGgGfib1ZONpekgDfAh8xr7IycdXw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;页面布局&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;带大家看一下创建页面的布局，最左侧是组件区，目前是基础组件，这里未来可能会做组件分类，把业务组件和自定义组件也接进来，中间是布局设计区，比如说列表页有固定三个区域，筛选项，中部功能区，列表，表单页不做限制，右侧为配置区，可以配置绑定字段和文案还有一些额外属性，组件的交互，像select这种option是接口调用的数据，还可以配置远程接口&lt;/p&gt;&lt;h5&gt;&lt;span&gt;模型设计（JSON SCHEMA）&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;我们创建页面后，会生成一份 schema ，什么是 json schema ，简单介绍一下，json shema 是 json 的一种约束，用来定义json的数据结构和验证格式，我们在这里用来保证数据的一致性&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPLkXHvc0UVVl9icYwlXNBz40Rsq1PhIygKvza4SrQ7kpGEe5oMFMZH6Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;p&gt;每个页面有一个主体，用来描述版本和一些原信息，body就是他的内容&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPHdTia1gbvHAoF8TJQj1Bw8ZaYwz5qUFT8P06MChLSmJtXUTpjq2xcqA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;JSON SCHEMA&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;我们目前页面分为两种，一种就是列表页面，一种是 form 页，但是他们的描述协议都是一样的，那基本的组件描述我们定义好了，这样其实简单的需求就能实现了，但是前端避免不了交互这一层，比如说一个选择框，当我选择了 A，B会触发一个事件，并且B还要拿到A所携带的入参信息&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPmB9USaibXAe33MWt5L43sUCMaHXcwgHOibp7TaibfvsKMoZ8gj7XXYqicA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;操作事件&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;我们这边做了一个操作事件功能，我们只需要把组件的 ref 设置好，操作事件这一块就可以定义他的出参入参，方便交互&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPt5rtLJC35qWP1DEBPKNxQCGLiaVMLPkNaiaTIxCq6bp7q6TzIqNPUaOQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;数据中心&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;接口配置这里，比如说一个 select 从远程接口获取到一个枚举，就可以存下来，给其他组件消费&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPkeaNNJc9kRU3FOaicR5FEichfT9Cl0SYPRlErhRKLQTDO8ao1s0DjpLQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;自定义插槽&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;比如说平台目前有不支持的组件或交互，还没有维护在平台里的，这里可以利用 vue 的 slot 进行二次开发，只需要拖入一个 slot&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPwyViaJdGAkBanhSENuGH0hNl8f7X1wD0jDNYGEgNlibFZCrQ3wIicB5TQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;自定义插槽-编码&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;slot 里的组件可以获取到配置里的 ref 和想要拿到的 scope，做任何你想做的事儿&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPgN4Of1tWWJpE94mLUVEjDKyU1jVqWflfrmdVgicKlNJ6UibeTIHI04IQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;480&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;稳定性&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;我们做低代码平台，归根到底是一个渲染引擎渲染一组 schema ，那么稳定性也得考虑，我们每次修改线上配置，可能心情如图，那我发布时怎么保证准确性，传统开发我们会有一个review 的过程，我们就把这个过程也搬上来了&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPYuGtczw1hRcH849icrwiaG54LBopoUMdkHiavde2v8G1aibeTQS5Vvhd0Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;SCHEMA DIFF &amp;amp; 版本对比&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;schema diff 每次发布时，需要选择版本来确认我改了什么，大大降低了风险。&lt;br/&gt;发布时也要进行二次确认&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPmmTb0uyDmKlibyxiaq1gZtdVtiaggp3tlH7BnH83pE4ZY6CgurMxS7Ztg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;未来规划&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xdDaByDutCjAmyLtEqTAMsib5OJh6S6mPJsKkXnlxN4Jht7eWpWTV04ultiblzntWyBpvFBXciaY9KC85VzAHTHnw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;h5&gt;&lt;span&gt;AUTO-CODE&lt;/span&gt;&lt;/h5&gt;&lt;p&gt;我们目前的能力，在版本对比这一块希望能做到 merge，并且提供可视化，也就是说你不一定非要看 schema 这种东西，组件这里继续丰富，能承载更多的需求，low-code 目标就做到 no-code 让非开发人员直接生成页面，不需要写一点代码，最终这个生产力就可以转移，终极目标就是做成 auto-code ，利用机器学习识别设计图，直接生成网站，抹去大部分配置，auto-code 目前业界有很多公司已经实现，我们也在慢慢摸索。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p data-darkmode-color-16057140139831=&quot;rgb(162, 162, 162)&quot; data-darkmode-original-color-16057140139831=&quot;rgb(68, 68, 68)&quot; data-style=&quot;padding-top: 7px; padding-bottom: 7px; color: rgb(68, 68, 68); font-size: 14px; line-height: 1.8; font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, &amp;quot;Lucida Grande&amp;quot;, Arial, &amp;quot;Hiragino Sans GB&amp;quot;, 微软雅黑, &amp;quot;WenQuanYi Micro Hei&amp;quot;, STHeiti, SimSun, sans-serif; text-align: center;&quot;&gt;&lt;span&gt;The End&lt;/span&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-darkmode-color-16057140139831=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16057140139831=&quot;rgb(0,0,0)&quot; data-style=&quot;padding-right: 10px; padding-left: 10px; font-size: 16px; color: black; line-height: 1.6; letter-spacing: 0px; word-break: break-word; text-align: left; font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif;&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot; data-darkmode-color-16057140139831=&quot;rgb(141, 141, 141)&quot; data-darkmode-original-color-16057140139831=&quot;rgb(89, 89, 89)&quot; data-style=&quot;padding-top: 8px; padding-bottom: 8px; line-height: 26px; color: rgb(89, 89, 89);&quot;&gt;&lt;span&gt;如果你觉得这篇内容对你挺有启发，请你轻轻点下小手指，帮我两个小忙呗：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot; data-darkmode-color-16057140139831=&quot;rgb(141, 141, 141)&quot; data-darkmode-original-color-16057140139831=&quot;rgb(89, 89, 89)&quot; data-style=&quot;padding-top: 8px; padding-bottom: 8px; line-height: 26px; color: rgb(89, 89, 89);&quot;&gt;&lt;span&gt;1、点亮&lt;strong data-darkmode-color-16057140139831=&quot;rgb(71, 193, 168)&quot; data-darkmode-original-color-16057140139831=&quot;rgb(71, 193, 168)&quot;&gt;「在看」&lt;/strong&gt;，让更多的人看到这篇满满干货的内容；&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot; data-darkmode-color-16057140139831=&quot;rgb(141, 141, 141)&quot; data-darkmode-original-color-16057140139831=&quot;rgb(89, 89, 89)&quot; data-style=&quot;padding-top: 8px; padding-bottom: 8px; line-height: 26px; color: rgb(89, 89, 89);&quot;&gt;&lt;span&gt;2、关注公众号「哈啰技术团队」，可第一时间收到最新技术推文。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot; data-darkmode-color-16057140139831=&quot;rgb(141, 141, 141)&quot; data-darkmode-original-color-16057140139831=&quot;rgb(89, 89, 89)&quot; data-style=&quot;padding-top: 8px; padding-bottom: 8px; line-height: 26px; color: rgb(89, 89, 89);&quot;&gt;&lt;span&gt;如果喜欢就点个👍喔，有您的喜欢⛽️，我们会更有动力输出有价值的技术分享滴；&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3365323096609085&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/xdDaByDutCja1wGKtp4IvKFbKKgKS8L0kQO9PzXxFoTia27KOzppMGsiba5RdY3TAY6XTpIDGsLJLrYCBRCKMKnw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1563&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>2bd1853983d81bad07bef6afff30b30b</guid>
<title>[推荐] 徒手用 Go 写个 Redis 服务器</title>
<link>https://toutiao.io/k/t9ic9wp</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.66640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xBgIbW1vdNPWkD6xmM3YDpLKRk9icwRvyvo6aWc1Pz3duHADKROA748khObVndvFBt9tZwTqMfIKZ876WHEDibww/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;span&gt;作者：HDT3213&lt;br/&gt;&lt;/span&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天给大家带来的开源项目是 Godis：一个用 Go 语言实现的 Redis 服务器。支持：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;5 种数据结构（string、list、hash、set、sortedset）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;自动过期（TTL）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;发布订阅、地理位置、持久化等功能&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2294736842105263&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/xBgIbW1vdNPWkD6xmM3YDpLKRk9icwRvyyIuib3RuttVFnsljC8XwPgicGkL1zibBcKKAhTERZRwKnzEaesYZhcfXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1900&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你或许不需要自己实现 Redis 服务，但你是否厌烦了每天都是写增删改查的业务代码，想提高编程水平试图从零写个项目打开 IDE 却发现无从下手？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;动手造轮子一定是提高编程能力的好办法，下面就带大家用 Go 从零开始写一个 Redis 服务器（Godis），从中你将学到：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;如何编写 Go 语言 TCP 服务器&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;设计并实现安全可靠的通信协议（redis 协议）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如何使用 Go 语言开发高并发程序&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;设计和实现分布式集群以及分布式事务&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;熟悉链表、哈希表、跳表以及时间轮等常用数据结构&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;千万不要担心内容太难！！虽然示例代码是 Go，但就算你不会 Go 语言也不会影响你理解 Redis 的原理和底层协议以及高性能的秘密。而且作者为了照顾到广大读者，对技术的讲解做了优化。示例代码在原项目基础上做了简化，并逐行地加了注释。如果是高级玩家，请直接访问项目阅读源码：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;https://github.com/HDT3213/godis&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面让我们一起拨开 Redis 的迷雾。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一、写个 TCP 服务器&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;众所周知 Redis 是 C/S 模型，使用 TCP 协议进行通信。接下来就从实现 TCP 服务端开始。作为广泛用于服务端的编程语言 Golang 提供了非常简洁的 TCP 接口，所以实现起来十分方便。示例代码：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;ListenAndServe&lt;/span&gt;&lt;span&gt;(address &lt;span&gt;string&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    &lt;span&gt;// 绑定监听地址&lt;/span&gt;&lt;br/&gt;    listener, err := net.Listen(&lt;span&gt;&quot;tcp&quot;&lt;/span&gt;, address)&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;        log.Fatal(fmt.Sprintf(&lt;span&gt;&quot;listen err: %v&quot;&lt;/span&gt;, err))&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;defer&lt;/span&gt; listener.Close()&lt;br/&gt;    log.Println(fmt.Sprintf(&lt;span&gt;&quot;bind: %s, start listening...&quot;&lt;/span&gt;, address))&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;// Accept 会一直阻塞直到有新的连接建立或者listen中断才会返回&lt;/span&gt;&lt;br/&gt;        conn, err := listener.Accept()&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;            &lt;span&gt;// 通常是由于listener被关闭无法继续监听导致的错误&lt;/span&gt;&lt;br/&gt;            log.Fatal(fmt.Sprintf(&lt;span&gt;&quot;accept err: %v&quot;&lt;/span&gt;, err))&lt;br/&gt;        }&lt;br/&gt;        &lt;span&gt;// 开启新的 goroutine 处理该连接&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;go&lt;/span&gt; Handle(conn)&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;Handle&lt;/span&gt;&lt;span&gt;(conn net.Conn)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    reader := bufio.NewReader(conn)&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;// ReadString 会一直阻塞直到遇到分隔符 &#x27;\n&#x27;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 遇到分隔符后 ReadString 会返回上次遇到分隔符到现在收到的所有数据&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 若在遇到分隔符之前发生异常, ReadString 会返回已收到的数据和错误信息&lt;/span&gt;&lt;br/&gt;        msg, err := reader.ReadString(&lt;span&gt;&#x27;\n&#x27;&lt;/span&gt;)&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;            &lt;span&gt;// 通常遇到的错误是连接中断或被关闭，用io.EOF表示&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; err == io.EOF {&lt;br/&gt;                log.Println(&lt;span&gt;&quot;connection close&quot;&lt;/span&gt;)&lt;br/&gt;            } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;                log.Println(err)&lt;br/&gt;            }&lt;br/&gt;            &lt;span&gt;return&lt;/span&gt;&lt;br/&gt;        }&lt;br/&gt;        b := []&lt;span&gt;byte&lt;/span&gt;(msg)&lt;br/&gt;        &lt;span&gt;// 将收到的信息发送给客户端&lt;/span&gt;&lt;br/&gt;        conn.Write(b)&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    ListenAndServe(&lt;span&gt;&quot;:8000&quot;&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;👌 至此只用了 40 行代码就搞定服务端啦！启动上面的 TCP 服务后，在终端中输入 &lt;code&gt;telnet 127.0.0.1 8000&lt;/code&gt; 就可以连接到刚写好的服务器，它会将你发送的消息原样返回给你（所以请不要骂它）：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.2675925925925926&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/xBgIbW1vdNPWkD6xmM3YDpLKRk9icwRvyuibu0TPqyuw0zws5DwMnC0m4dRic0QxoiaqrxVsC3ZxU93z9qGVx6licKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个 TCP 服务器的非常简单，主协程调用 accept 函数来监听端口，接受新连接后开启一个 Goroutine 来处理它。这种简单的阻塞 IO 模型有些类似于早期的 Tomcat/Apache 服务器。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阻塞 IO 模型是使用&lt;strong&gt;一个线程处理一个连接&lt;/strong&gt;，在没有收到新数据时监听线程处于阻塞状态，直到数据就绪后线程被唤醒进行处理。因为阻塞 IO 模型需要开启大量线程并且频繁地进行上下文切换，所以它的效率很低。而 Redis 使用的 epoll 技术（IO 多路复用）用&lt;strong&gt;一个线程处理大量连接&lt;/strong&gt;，极大地提高了吞吐量。那么我们的 TCP 服务器会比 Redis 慢很多吗？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然不会，Golang 利用 Goroutine 调度开销远远小于线程调度开销的优势封装出 &lt;code&gt;goroutine-per-connection&lt;/code&gt; 风格的极简接口，而且 net/tcp 库将 epoll 封装成了阻塞 IO 的样子，在享受 epoll 高性能的同时避免了原生 epoll 接口所需的复杂异步代码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在作者的电脑上 Redis 每秒可以响应 10.6k 个 PING 命令，而 Godis（完整代码） 的吞吐量为 9.2 kqps 相差并不大。想了解更多 Golang 高性能的㊙️密，可以搜索 &lt;code&gt;go netpoller&lt;/code&gt; 或者 &lt;code&gt;go 语言 网络轮询器&lt;/code&gt; 关键字&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，合格的 TCP 的服务器在关闭的时候不应该一停了之，而需要完成响应已接收的请求、释放 TCP 连接等必要的清理工作。这个功能我们一般称为 &lt;code&gt;优雅关闭&lt;/code&gt; 或者 &lt;code&gt;graceful shutdown&lt;/code&gt;，优雅关闭步骤：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;首先，关闭 listener 停止接受新连接&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;然后，遍历所有存活连接逐个关闭&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优雅关闭的代码比较多，这里就不完整贴出了。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;二、透视 Redis 协议&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在解决完通信后，下一步就是搞清楚 Redis 的协议，其实就是一套序列化协议类似 JSON、Protocol Buffers，你看底层其实也就是一些基础的知识。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;自 Redis 2.0 以后的通信统一为 RESP 协议（REdis Serialization Protocol)，该协议易于实现不仅可以高效的被程序解析，还能够被人类读懂容易调试。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RESP 是一个二进制安全的文本协议，工作于 TCP 协议上。RESP 以行作为单位，客户端和服务器发送的命令或数据一律以 &lt;code&gt;\r\n&lt;/code&gt;（CRLF）作为换行符。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;二进制安全是指允许协议中出现任意字符而不会导致故障。比如 C 语言的字符串以 &lt;code&gt;\0&lt;/code&gt; 作为结尾不允许字符串中间出现 &lt;code&gt;\0&lt;/code&gt;，而 Go 语言的 string 则允许出现 &lt;code&gt;\0&lt;/code&gt;，我们说 Go 语言的 string 是二进制安全的，而 C 语言字符串不是二进制安全的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RESP 的二进制安全性允许我们在 key 或者 value 中包含 &lt;code&gt;\r&lt;/code&gt; 或者 &lt;code&gt;\n&lt;/code&gt; 这样的特殊字符。在使用 Redis 存储 protobuf、msgpack 等二进制数据时，二进制安全性尤为重要。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RESP 定义了 5 种格式：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;简单字符串（Simple String）：服务器用来返回简单的结果，比如 &quot;OK&quot; 非二进制安全，且不允许换行&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;错误信息（Error）：服务器用来返回简单的错误信息，比如 &quot;ERR Invalid Synatx&quot; 非二进制安全，且不允许换行&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;整数（Integer）：llen、scard 等命令的返回值，64 位有符号整数&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;字符串（Bulk String）：二进制安全字符串，比如 get 等命令的返回值&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数组（Array，又称 Multi Bulk Strings）：Bulk String 数组，客户端发送指令以及 lrange 等命令响应的格式&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RESP 通过第一个字符来表示格式：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;简单字符串：以&quot;+&quot; 开始， 如：&quot;+OK\r\n&quot;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;错误：以&quot;-&quot; 开始，如：&quot;-ERR Invalid Synatx\r\n&quot;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;整数：以&quot;:&quot;开始，如：&quot;:1\r\n&quot;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;字符串：以 &lt;code&gt;$&lt;/code&gt; 开始&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数组：以 &lt;code&gt;*&lt;/code&gt; 开始&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面让我们通过一些实际例子来理解协议。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.1 字符串&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;字符串（Bulk String）有两行，第一行为 &lt;code&gt;$&lt;/code&gt;+正文长度，第二行为实际内容。如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;$3&lt;/span&gt;\r\nSET\r\n&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;字符串（Bulk String）是二进制安全的，就是说可以在 Bulk String 内部包含 &quot;\r\n&quot; 字符（行尾的 CRLF 被隐藏）：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;$4&lt;/span&gt;&lt;br/&gt;a\r\nb&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2 空&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;$-1&lt;/code&gt; 表示 nil，比如使用 get 命令查询一个不存在的 key 时，响应即为 &lt;code&gt;$-1&lt;/code&gt;。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3 数组&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数组（Array）格式第一行为 &quot;*&quot;+数组长度，其后是相应数量的 字符串（Bulk String）。比如 &lt;code&gt;[&quot;foo&quot;, &quot;bar&quot;]&lt;/code&gt; 的报文（传输时的内容）：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;*2&lt;br/&gt;&lt;span&gt;$3&lt;/span&gt;&lt;br/&gt;foo&lt;br/&gt;&lt;span&gt;$3&lt;/span&gt;&lt;br/&gt;bar&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;客户端也使用 数组（Array）格式向服务端发送指令。命令本身将作为第一个参数，比如 &lt;code&gt;SET key value&lt;/code&gt; 指令的 RESP 报文：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;*3&lt;br/&gt;&lt;span&gt;$3&lt;/span&gt;&lt;br/&gt;SET&lt;br/&gt;&lt;span&gt;$3&lt;/span&gt;&lt;br/&gt;key&lt;br/&gt;&lt;span&gt;$5&lt;/span&gt;&lt;br/&gt;value&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;将换行符打印出来：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;*3\r\n$3\r\nSET\r\n$3\r\nkey\r\n$5\r\nvalue\r\n&lt;/code&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.4 解析预备&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;知道常用的 RESP 报文内容后，就可以开始着手解析了。但需要注意的是 RESP 是 &lt;code&gt;二进制安全&lt;/code&gt; 的协议，它允许在正文中使用 &lt;code&gt;\r\n&lt;/code&gt; 字符。举例来说 Redis 可以正确接收并执行 &lt;code&gt;SET &quot;a\r\nb&quot; hellogithub&lt;/code&gt; 指令，这条指令的正确报文是这样的：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;*3  &lt;br/&gt;&lt;span&gt;$3&lt;/span&gt;&lt;br/&gt;SET&lt;br/&gt;&lt;span&gt;$4&lt;/span&gt;&lt;br/&gt;a\r\nb &lt;br/&gt;&lt;span&gt;$11&lt;/span&gt;&lt;br/&gt;hellogithub&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当 &lt;code&gt;ReadBytes&lt;/code&gt; 读取到第五行 &quot;a\r\nb\r\n&quot; 时会将其误认为两行：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;*3  &lt;br/&gt;&lt;span&gt;$3&lt;/span&gt;&lt;br/&gt;SET&lt;br/&gt;&lt;span&gt;$4&lt;/span&gt;&lt;br/&gt;a  // 错误的分行&lt;br/&gt;b // 错误的分行&lt;br/&gt;&lt;span&gt;$11&lt;/span&gt;&lt;br/&gt;hellogithub&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此当读取到第四行 &lt;code&gt;$4&lt;/code&gt; 后，不应该继续使用 &lt;code&gt;ReadBytes(&#x27;\n&#x27;)&lt;/code&gt; 读取下一行，应使用 &lt;code&gt;io.ReadFull(reader, msg)&lt;/code&gt; 方法来读取指定长度的内容。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;msg = &lt;span&gt;make&lt;/span&gt;([]&lt;span&gt;byte&lt;/span&gt;, &lt;span&gt;4&lt;/span&gt; + &lt;span&gt;2&lt;/span&gt;) &lt;span&gt;// 正文长度4 + 换行符长度2&lt;/span&gt;&lt;br/&gt;_, err = io.ReadFull(reader, msg)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5 编写 RESP 协议解析器&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;解决完上面内容包含 &quot;\r\n&quot; 的问题，我们就可以开始放手编写 Redis 协议解析器啦！&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; Payload &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt; Data redis.Reply&lt;br/&gt; Err  error&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// ParseStream 通过 io.Reader 读取数据并将结果通过 channel 将结果返回给调用者&lt;/span&gt;&lt;br/&gt;&lt;span&gt;// 流式处理的接口适合供客户端/服务端使用&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;ParseStream&lt;/span&gt;&lt;span&gt;(reader io.Reader)&lt;/span&gt; &amp;lt;-&lt;span&gt;chan&lt;/span&gt; *&lt;span&gt;Payload&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; ch := &lt;span&gt;make&lt;/span&gt;(&lt;span&gt;chan&lt;/span&gt; *Payload)&lt;br/&gt; &lt;span&gt;go&lt;/span&gt; parse0(reader, ch)&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; ch&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于解析器的代码比较多，这里只简单地介绍一下核心流程。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;parse0&lt;/span&gt;&lt;span&gt;(reader io.Reader, ch &lt;span&gt;chan&lt;/span&gt;&amp;lt;- *Payload)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    &lt;span&gt;// 初始化读取状态&lt;/span&gt;&lt;br/&gt;    readingMultiLine := &lt;span&gt;false&lt;/span&gt;&lt;br/&gt;    expectedArgsCount := &lt;span&gt;0&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;var&lt;/span&gt; args [][]&lt;span&gt;byte&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;var&lt;/span&gt; bulkLen &lt;span&gt;int64&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;// 上文中我们提到 RESP 是以行为单位的&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 因为行分为简单字符串和二进制安全的 BulkString，我们需要封装一个 readLine 函数来兼容&lt;/span&gt;&lt;br/&gt;        line, err = readLine(reader, bulkLen)&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; { &lt;br/&gt;            &lt;span&gt;// 处理错误&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;return&lt;/span&gt;&lt;br/&gt;        }&lt;br/&gt;        &lt;span&gt;// 接下来我们对刚刚读取的行进行解析&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 我们简单的将 Reply 分为两类:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 单行: StatusReply, IntReply, ErrorReply&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 多行: BulkReply, MultiBulkReply&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; !readingMultiLine {&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; isMulitBulkHeader(line) {&lt;br/&gt;                &lt;span&gt;// 我们收到了 MulitBulkReply 的第一行&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;// 获得 MulitBulkReply 中 BulkString 的个数&lt;/span&gt;&lt;br/&gt;                expectedArgsCount = parseMulitBulkHeader(line)&lt;br/&gt;                &lt;span&gt;// 等待 MulitBulkReply 后续行&lt;/span&gt;&lt;br/&gt;                readingMultiLine = &lt;span&gt;true&lt;/span&gt;&lt;br/&gt;            } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; isBulkHeader(line) {&lt;br/&gt;                &lt;span&gt;// 我们收到了 BulkReply 的第一行&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;// 获得 BulkReply 第二行的长度, 通过 bulkLen 告诉 readLine 函数下一行 BulkString 的长度&lt;/span&gt;&lt;br/&gt;                bulkLen = parseBulkHeader()&lt;br/&gt;                &lt;span&gt;// 这个 Reply 中一共有 1 个 BulkString&lt;/span&gt;&lt;br/&gt;                expectedArgsCount = &lt;span&gt;1&lt;/span&gt; &lt;br/&gt;                &lt;span&gt;// 等待 BulkReply 后续行&lt;/span&gt;&lt;br/&gt;                readingMultiLine = &lt;span&gt;true&lt;/span&gt;&lt;br/&gt;            } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;                &lt;span&gt;// 处理 StatusReply, IntReply, ErrorReply 等单行 Reply&lt;/span&gt;&lt;br/&gt;                reply := parseSingleLineReply(line)&lt;br/&gt;                &lt;span&gt;// 通过 ch 返回结果&lt;/span&gt;&lt;br/&gt;                emitReply(ch)&lt;br/&gt;            }&lt;br/&gt;        } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;            &lt;span&gt;// 进入此分支说明我们正在等待 MulitBulkReply 或 BulkReply 的后续行&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;// MulitBulkReply 的后续行有两种，BulkHeader 或者 BulkString&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; isBulkHeader(line) {&lt;br/&gt;                bulkLen = parseBulkHeader()&lt;br/&gt;            } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;                &lt;span&gt;// 我们正在读取一个 BulkString, 它可能是 MulitBulkReply 或 BulkReply &lt;/span&gt;&lt;br/&gt;                args = &lt;span&gt;append&lt;/span&gt;(args, line)&lt;br/&gt;            }&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; &lt;span&gt;len&lt;/span&gt;(args) == expectedArgsCount { &lt;span&gt;// 我们已经读取了所有后续行&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;// 通过 ch 返回结果&lt;/span&gt;&lt;br/&gt;                emitReply(ch)&lt;br/&gt;                &lt;span&gt;// 重置状态, 准备解析下一条 Reply&lt;/span&gt;&lt;br/&gt;                readingMultiLine = &lt;span&gt;false&lt;/span&gt;&lt;br/&gt;                expectedArgsCount = &lt;span&gt;0&lt;/span&gt;&lt;br/&gt;                args = &lt;span&gt;nil&lt;/span&gt;&lt;br/&gt;                bulkLen = &lt;span&gt;0&lt;/span&gt;&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;三、实现内存数据库&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至此我们已经搞定数据接收和解析的部分了，剩下就是我们应该把数据存在哪里了？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;抛开持久化部分，作为基于内存的 KV 数据库 Redis 的所有数据需要都存储在内存中的哈希表，而这个哈希表就是我们今天需要编写的最后一个组件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;与单线程的 Redis 不同我们实现的 Redis（godis）是并行工作的，所以我们必须考虑各种并发安全问题。常见的并发安全哈希表设计有几种：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;code&gt;sync.map&lt;/code&gt;：Golang 官方提供的并发哈希表，适合读多写少的场景。但是在 &lt;code&gt;m.dirty&lt;/code&gt; 刚被提升后会将 &lt;code&gt;m.read&lt;/code&gt; 复制到新的 &lt;code&gt;m.dirty&lt;/code&gt; 中，在数据量较大的情况下复制操作会阻塞所有协程，存在较大的隐患。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;code&gt;juc.ConcurrentHashMap&lt;/code&gt;：Java 的并发哈希表采用分段锁实现。在进行扩容时访问哈希表线程都将协助进行 rehash 操作，在 rehash 结束前所有的读写操作都会阻塞。因为缓存数据库中键值对数量巨大且对读写操作响应时间要求较高，使用 juc 的策略是不合适的。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;code&gt;memcached hashtable&lt;/code&gt;：在后台线程进行 rehash 操作时，主线程会判断要访问的哈希槽是否已被 rehash 从而决定操作 old_hashtable 还是操作 new_hashtable。这种设计被称为&lt;strong&gt;渐进式 rehash&lt;/strong&gt; 它的优点是 rehash 操作基本不会阻塞主线程的读写，是最理想的的方案。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但渐进式 rehash 的实现非常复杂，所以 godis 采用 Golang 社区广泛使用的分段锁策略（非上面的三种），就是将 key 分散到固定数量的 shard 中避免进行整体 rehash 操作。shard 是有锁保护的 map，当 shard 进行 rehash 时会阻塞 shard 内的读写，但不会对其他 shard 造成影响。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5855728429985856&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/xBgIbW1vdNPWkD6xmM3YDpLKRk9icwRvyAgDiaNQU6ny3uGJqrZIhKlT4MLibuX6BWDeHwaAN5BdbYBs7XRhhawgg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;707&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; ConcurrentDict &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt;    table []*Shard&lt;br/&gt;    count &lt;span&gt;int32&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;type&lt;/span&gt; Shard &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt;    m     &lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;interface&lt;/span&gt;{}&lt;br/&gt;    mutex sync.RWMutex&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(dict *ConcurrentDict)&lt;/span&gt; &lt;span&gt;spread&lt;/span&gt;&lt;span&gt;(hashCode &lt;span&gt;uint32&lt;/span&gt;)&lt;/span&gt; &lt;span&gt;uint32&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; tableSize := &lt;span&gt;uint32&lt;/span&gt;(&lt;span&gt;len&lt;/span&gt;(dict.table))&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; (tableSize - &lt;span&gt;1&lt;/span&gt;) &amp;amp; &lt;span&gt;uint32&lt;/span&gt;(hashCode)&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(dict *ConcurrentDict)&lt;/span&gt; &lt;span&gt;getShard&lt;/span&gt;&lt;span&gt;(index &lt;span&gt;uint32&lt;/span&gt;)&lt;/span&gt; *&lt;span&gt;Shard&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; dict.table[index]&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(dict *ConcurrentDict)&lt;/span&gt; &lt;span&gt;Get&lt;/span&gt;&lt;span&gt;(key &lt;span&gt;string&lt;/span&gt;)&lt;/span&gt; &lt;span&gt;(val &lt;span&gt;interface&lt;/span&gt;{}, exists &lt;span&gt;bool&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; hashCode := fnv32(key)&lt;br/&gt; index := dict.spread(hashCode)&lt;br/&gt; shard := dict.getShard(index)&lt;br/&gt; shard.mutex.RLock()&lt;br/&gt; &lt;span&gt;defer&lt;/span&gt; shard.mutex.RUnlock()&lt;br/&gt; val, exists = shard.m[key]&lt;br/&gt; &lt;span&gt;return&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(dict *ConcurrentDict)&lt;/span&gt; &lt;span&gt;Put&lt;/span&gt;&lt;span&gt;(key &lt;span&gt;string&lt;/span&gt;, val &lt;span&gt;interface&lt;/span&gt;{})&lt;/span&gt; &lt;span&gt;(result &lt;span&gt;int&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; dict == &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;  &lt;span&gt;panic&lt;/span&gt;(&lt;span&gt;&quot;dict is nil&quot;&lt;/span&gt;)&lt;br/&gt; }&lt;br/&gt; hashCode := fnv32(key)&lt;br/&gt; index := dict.spread(hashCode)&lt;br/&gt; shard := dict.getShard(index)&lt;br/&gt; shard.mutex.Lock()&lt;br/&gt; &lt;span&gt;defer&lt;/span&gt; shard.mutex.Unlock()&lt;br/&gt;&lt;br/&gt; &lt;span&gt;if&lt;/span&gt; _, ok := shard.m[key]; ok {&lt;br/&gt;  shard.m[key] = val&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;br/&gt; } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;  shard.m[key] = val&lt;br/&gt;  dict.addCount()&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;ConcurrentDict&lt;/code&gt; 可以保证对单个 key 操作的并发安全性，但是仍然无法满足并发安全的需求，举例来说：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Incr 命令需要完成：&lt;code&gt;读取 -&amp;gt; 做加法 -&amp;gt; 写入&lt;/code&gt; 三步操作，读取和写入两步操作不是原子性的&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;MSETNX 命令当且仅当所有给定键都不存在时所有给定键设置值，我们需要保证「检查多个key是否存在」以及「写入多个key」这两个操作的原子性&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此我们需要实现 &lt;code&gt;db.Locker&lt;/code&gt; 用于锁定一个或一组 key 直到我们完成所有操作后再释放。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实现 &lt;code&gt;db.Locker&lt;/code&gt; 最直接的想法是使用一个 &lt;code&gt;map[string]*sync.RWMutex&lt;/code&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;加锁过程分为两步：初始化 mutex -&amp;gt; 加锁&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;解锁过程也分为两步: 解锁 -&amp;gt; 释放mutex&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么存在一个无法解决的并发问题：&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;时间&lt;/th&gt;&lt;th&gt;协程A&lt;/th&gt;&lt;th&gt;协程B&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;&lt;br/&gt;&lt;/td&gt;&lt;td&gt;locker[&quot;a&quot;].Unlock()&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;locker[&quot;a&quot;] = &amp;amp;sync.RWMutex{}&lt;/td&gt;&lt;td&gt;&lt;br/&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;&lt;br/&gt;&lt;/td&gt;&lt;td&gt;delete(locker[&quot;a&quot;])&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;locker[&quot;a&quot;].Lock()&lt;/td&gt;&lt;td&gt;&lt;br/&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于 t3 时协程 B 释放了锁，t4 时协程 A 试图加锁会失败。若协程B在解锁时不执行 &lt;code&gt;delete(locker[&quot;a&quot;])&lt;/code&gt; 就可以避免该异常的发生，但是这样会造成严重的内存泄露。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们注意到哈希槽的数量远少于 key 的数量，反过来说多个键可以共用一个哈希槽。所以我们不再直接对 key 进行加锁而是锁定 key 所在的哈希槽也可以保证安全，另一方面哈希槽数量较少即使不释放也不会消耗太多内存。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; Locks &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt;    table []*sync.RWMutex&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;Make&lt;/span&gt;&lt;span&gt;(tableSize &lt;span&gt;int&lt;/span&gt;)&lt;/span&gt; *&lt;span&gt;Locks&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    table := &lt;span&gt;make&lt;/span&gt;([]*sync.RWMutex, tableSize)&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; tableSize; i++ {&lt;br/&gt;        table[i] = &amp;amp;sync.RWMutex{}&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &amp;amp;Locks{&lt;br/&gt;        table: table,&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(locks *Locks)&lt;/span&gt;&lt;span&gt;Lock&lt;/span&gt;&lt;span&gt;(key &lt;span&gt;string&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    index := locks.spread(fnv32(key))&lt;br/&gt;    mu := locks.table[index]&lt;br/&gt;    mu.Lock()&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;(locks *Locks)&lt;/span&gt;&lt;span&gt;UnLock&lt;/span&gt;&lt;span&gt;(key &lt;span&gt;string&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;    index := locks.spread(fnv32(key))&lt;br/&gt;    mu := locks.table[index]&lt;br/&gt;    mu.Unlock()&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在锁定多个 key 时需要注意，若 协程A 持有 键a 的锁试图获得 键b 的锁，此时 协程B 持有 键b 的锁试图获得 键a 的锁则会形成死锁。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;解决方法是所有协程都按照相同顺序加锁，若两个协程都想获得 键a 和 键b 的锁，那么必须先获取 键a 的锁后获取 键b 的锁，这样就可以避免循环等待。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到目前为止构建 Redis 服务器所需的基本组件已经备齐，只需要将 TCP 服务器、协议解析器与哈希表组装起来我们的 Redis 服务器就可以开始工作啦。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，以上代码均简化自我写的 Godis：一个开源仅用 Go 语言实现的 Redis 服务器。期待您的关注和 Star：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;项目地址：https://github.com/HDT3213/godis&lt;/p&gt;&lt;/blockquote&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;四、结束&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很多朋友的日常工作主要是编写业务代码，对于框架、数据库、中间件这些“架构”、“底层代码” 有一些恐惧感。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但本文我们只写了 3 个组件，共计几百行代码就实现了一个基本的 Redis 服务器。所以底层的技术并不难，只要你对技术感兴趣由浅入深、从简到繁，“底层代码”也并不神秘。&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;span&gt;- END -&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzA5MzYyNzQ0MQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/xBgIbW1vdNOqkqThUJBICyFBlvLvTyOCgBpibwWotSxGExfnOYFfPiaL9yn3GMUOCEVYN2RNslGCdQwgZy6ticdyA/0?wx_fmt=png&quot; data-nickname=&quot;HelloGitHub&quot; data-alias=&quot;GitHub520&quot; data-signature=&quot;分享 GitHub 上有趣、入门级的开源项目。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;兴趣是最好的老师，&lt;strong&gt;HelloGitHub&lt;/strong&gt; 发现编程的乐趣&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9c7843f24a6b6679741d205cb88bddf2</guid>
<title>[推荐] 这可能是最轻量高效的运维监控工具：开源 WGCLOUD</title>
<link>https://toutiao.io/k/l55l3jp</link>
<content:encoded>&lt;div&gt;&lt;div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>f47a160e354d1f67c2d3624da57ac34e</guid>
<title>[推荐] Redis 最佳实践：7 个维度 + 43 条使用规范，带你彻底玩转 Redis（附实践清单）</title>
<link>https://toutiao.io/k/kkvemjf</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;&lt;span&gt;这篇文&lt;/span&gt;&lt;span&gt;章我想和你聊一聊 Redis 的最佳实践。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你的项目或许已经使用 Redis 很长时间了，但在使用过程中，你可能还会或多或少地遇到以下问题：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;我的 Redis 内存为什么增长这么快？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;为什么我的 Redis 操作延迟变大了？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如何降低 Redis 故障发生的频率？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;日常运维 Redis 需要注意什么？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;部署 Redis 时，如何做好资源规划？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Redis 监控重点要关注哪些指标？&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;尤其是当你的项目越来越依赖 Redis 时，这些问题就变得尤为重要。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时，你迫切需要一份&lt;strong&gt;「最佳实践指南」&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这篇文章，我将从以下七个维度，带你「全面」分析 Redis 的最佳实践优化：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在文章的最后，我还会给你一个完整的最佳实践清单，不管你是业务开发人员，还是 DBA 运维人员，这个清单将会帮助你更加「优雅」地用好 Redis。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;这篇文章干货很多，希望你可以耐心读完。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5761589403973509&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyx7AWsPEBcwibhCgk78ibcYPOJrBMEjvclD1wYHibyjNg0OsKnKFapTBbyQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;453&quot;/&gt;&lt;/figure&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如何使用 Redis 更节省内存？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，我们来看一下 Redis 内存方面的优化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;众所周知，Redis 的性能之所以如此之高，原因就在于它的数据都存储在「内存」中，所以访问 Redis 中的数据速度极快。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但从资源利用率层面来说，机器的内存资源相比于磁盘，还是比较昂贵的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当你的业务应用在 Redis 中存储数据很少时，你可能并不太关心内存资源的使用情况。但随着业务的发展，你的业务存储在 Redis 中的数据就会越来越多。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果没有提前制定好内存优化策略，那么等业务开始增长时，Redis 占用的内存也会开始膨胀。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，提前制定合理的内存优化策略，对于资源利用率的提升是很有必要的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那在使用 Redis 时，怎样做才能更节省内存呢？这里我给你总结了 6 点建议，我们依次来看：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;1) 控制 key 的长度&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最简单直接的内存优化，就是控制 key 的长度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在开发业务时，你需要提前预估整个 Redis 中写入 key 的数量，如果 key 数量达到了百万级别，那么，过长的 key 名也会占用过多的内存空间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，你需要保证 key 在简单、清晰的前提下，尽可能把 key 定义得短一些。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如，原有的 key 为 user:book:123，则可以优化为 u:bk:123。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样一来，你的 Redis 就可以节省大量的内存，这个方案对内存的优化非常直接和高效。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;2) 避免存储 bigkey&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了控制 key 的长度之外，你同样需要关注 value 的大小，如果大量存储 bigkey，也会导致 Redis 内存增长过快。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除此之外，客户端在读写 bigkey 时，还有产生性能问题（下文会具体详述）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，你要避免在 Redis 中存储 bigkey，我给你的建议是：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;String：大小控制在 10KB 以下&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;List/Hash/Set/ZSet：元素数量控制在 1 万以下&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;3) 选择合适的数据类型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 提供了丰富的数据类型，这些数据类型在实现上，也对内存使用做了优化。具体来说就是，一种数据类型对应多种数据结构来实现：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.7314974182444062&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyxDPJAlJj31DWQxBtUc4qCyqPt5SEWNpY1JpDyibcJxo1rhVBmqMjIw9g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;581&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如，String、Set 在存储 int 数据时，会采用整数编码存储。Hash、ZSet 在元素数量比较少时（可配置），会采用压缩列表（ziplist）存储，在存储比较多的数据时，才会转换为哈希表和跳表。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作者这么设计的原因，就是为了进一步节约内存资源。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么你在存储数据时，就可以利用这些特性来优化 Redis 的内存。这里我给你的建议如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;String、Set：尽可能存储 int 类型数据&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Hash、ZSet：存储的元素数量控制在转换阈值之下，以压缩列表存储，节约内存&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;4) 把 Redis 当作缓存使用&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 数据存储在内存中，这也意味着其资源是有限的。你在使用 Redis 时，要把它当做缓存来使用，而不是数据库。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，你的应用写入到  Redis 中的数据，尽可能地都设置「过期时间」。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;业务应用在 Redis 中查不到数据时，再从后端数据库中加载到 Redis 中。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5591647331786543&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyx4t8UZ34WMpePuN9IFbicJlvRyuZFrXTAZSemoQV44KSmZLvt8AYqE7A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;431&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;采用这种方案，可以让 Redis 中只保留经常访问的「热数据」，内存利用率也会比较高。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;5) 实例设置 maxmemory + 淘汰策略&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然你的 Redis key 都设置了过期时间，但如果你的业务应用写入量很大，并且过期时间设置得比较久，那么短期间内 Redis 的内存依旧会快速增长。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果不控制 Redis 的内存上限，也会导致使用过多的内存资源。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于这种场景，你需要提前预估业务数据量，然后给这个实例设置 maxmemory 控制实例的内存上限，这样可以避免 Redis 的内存持续膨胀。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;配置了 maxmemory，此时你还要设置数据淘汰策略，而淘汰策略如何选择，你需要结合你的业务特点来决定：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;volatile-lru / allkeys-lru：优先保留最近访问过的数据&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;volatile-lfu / allkeys-lfu：优先保留访问次数最频繁的数据（4.0+版本支持）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;volatile-ttl ：优先淘汰即将过期的数据&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;volatile-random / allkeys-random：随机淘汰数据&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;6) 数据压缩后写入 Redis&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上方案基本涵盖了 Redis 内存优化的各个方面。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你还想进一步优化 Redis 内存，你还可以在业务应用中先将数据压缩，再写入到 Redis 中（例如采用 snappy、gzip 等压缩算法）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然，压缩存储的数据，客户端在读取时还需要解压缩，在这期间会消耗更多 CPU 资源，你需要根据实际情况进行权衡。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上就是「节省内存资源」方面的实践优化，是不是都比较简单？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我们来看「性能」方面的优化。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如何持续发挥 Redis 的高性能？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当你的系统决定引入 Redis 时，想必看中它最关键的一点就是：&lt;strong&gt;性能&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们知道，一个单机版 Redis 就可以达到 10W QPS，这么高的性能，也意味着如果在使用过程中发生延迟情况，就会与我们的预期不符。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，在使用 Redis 时，如何持续发挥它的高性能，避免操作延迟的情况发生，也是我们的关注焦点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这方面，我给你总结了 13 条建议：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;1) 避免存储 bigkey&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;存储 bigkey 除了前面讲到的使用过多内存之外，对 Redis 性能也会有很大影响。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于 Redis 处理请求是单线程的，当你的应用在写入一个 bigkey 时，更多时间将消耗在「内存分配」上，这时操作延迟就会增加。同样地，删除一个 bigkey 在「释放内存」时，也会发生耗时。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而且，当你在读取这个 bigkey 时，也会在「网络数据传输」上花费更多时间，此时后面待执行的请求就会发生排队，Redis 性能下降。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3168469860896445&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyx7J5WTib2UYFNWSPaP7UMOulkISC5KQ0syDoibcouL0iaiay0vzLPbNQSJg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;647&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，你的业务应用尽量不要存储 bigkey，避免操作延迟发生。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如果你确实有存储 bigkey 的需求，你可以把 bigkey 拆分为多个小 key 存储。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;2) 开启 lazy-free 机制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你无法避免存储 bigkey，那么我建议你开启 Redis 的 lazy-free 机制。（4.0+版本支持）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当开启这个机制后，Redis 在删除一个 bigkey 时，释放内存的耗时操作，将会放到后台线程中去执行，这样可以在最大程度上，避免对主线程的影响。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4406196213425129&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyxhrumCSKsfLUgVaAWxicFawP6ZbMrCyGSAL6Tas29Wue76gNLSHEIesA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;581&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;3) 不使用复杂度过高的命令&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 是单线程模型处理请求，除了操作 bigkey 会导致后面请求发生排队之外，在执行复杂度过高的命令时，也会发生这种情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为执行复杂度过高的命令，会消耗更多的 CPU 资源，主线程中的其它请求只能等待，这时也会发生排队延迟。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，你需要避免执行例如 SORT、SINTER、SINTERSTORE、ZUNIONSTORE、ZINTERSTORE 等聚合类命令。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于这种聚合类操作，我建议你把它放到客户端来执行，不要让 Redis 承担太多的计算工作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;4) 执行 O(N) 命令时，关注 N 的大小&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;规避使用复杂度过高的命令，就可以高枕无忧了么？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答案是否定的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当你在执行 O(N) 命令时，同样需要注意 N 的大小。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果一次性查询过多的数据，也会在网络传输过程中耗时过长，操作延迟变大。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，对于容器类型（List/Hash/Set/ZSet），在元素数量未知的情况下，一定不要无脑执行 LRANGE key 0 -1 / HGETALL / SMEMBERS / ZRANGE key 0 -1。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在查询数据时，你要遵循以下原则：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;先查询数据元素的数量（LLEN/HLEN/SCARD/ZCARD）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;元素数量较少，可一次性查询全量数据&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;元素数量非常多，分批查询数据（LRANGE/HASCAN/SSCAN/ZSCAN）&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;5) 关注 DEL 时间复杂度&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你没看错，在删除一个 key 时，如果姿势不对，也有可能影响到 Redis 性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;删除一个 key，我们通常使用的是 DEL 命令，回想一下，你觉得 DEL 的时间复杂度是多少？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;O(1) ？其实不一定。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当你删除的是一个 String 类型 key 时，时间复杂度确实是 O(1)。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但当你要删除的 key 是 List/Hash/Set/ZSet 类型，它的复杂度其实为 O(N)，N 代表元素个数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;也就是说，删除一个 key，其元素数量越多，执行 DEL 也就越慢！&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;原因在于，删除大量元素时，需要依次回收每个元素的内存，元素越多，花费的时间也就越久！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而且，这个过程默认是在主线程中执行的，这势必会阻塞主线程，产生性能问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那删除这种元素比较多的 key，如何处理呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我给你的建议是，分批删除：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;List类型：执行多次 LPOP/RPOP，直到所有元素都删除完成&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Hash/Set/ZSet类型：先执行 HSCAN/SSCAN/SCAN 查询元素，再执行 HDEL/SREM/ZREM 依次删除每个元素&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;没想到吧？一个小小的删除操作，稍微不小心，也有可能引发性能问题，你在操作时需要格外注意。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;6) 批量命令代替单个命令&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当你需要一次性操作多个 key 时，你应该使用批量命令来处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;批量操作相比于多次单个操作的优势在于，可以显著减少客户端、服务端的来回网络 IO 次数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以我给你的建议是：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;String / Hash 使用 MGET/MSET 替代 GET/SET，HMGET/HMSET 替代 HGET/HSET&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;其它数据类型使用 Pipeline，打包一次性发送多个命令到服务端执行&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.8656429942418427&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyxjWasaOIYSbt5M6jhuURC6qRiabvsCQa5UwNZL8uk06ulNicxrXVkCNNA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;521&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;7) 避免集中过期 key&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 清理过期 key 是采用定时 + 懒惰的方式来做的，而且这个过程都是在主线程中执行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你的业务存在大量 key 集中过期的情况，那么 Redis 在清理过期 key 时，也会有阻塞主线程的风险。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.22901849217638692&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyxZicHACvFNPU8gXS3VK2mDhfVJVnuTD5FSo5fTQdOABSrpYVrndge37A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;703&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;想要避免这种情况发生，你可以在设置过期时间时，增加一个随机时间，把这些 key 的过期时间打散，从而降低集中过期对主线程的影响。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;8) 使用长连接操作 Redis，合理配置连接池&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你的业务应该使用长连接操作 Redis，避免短连接。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当使用短连接操作 Redis 时，每次都需要经过 TCP 三次握手、四次挥手，这个过程也会增加操作耗时。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同时，你的客户端应该使用连接池的方式访问 Redis，并设置合理的参数，长时间不操作 Redis 时，需及时释放连接资源。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;9) 只使用 db0&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;尽管 Redis 提供了 16 个 db，但我只建议你使用 db0。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么呢？我总结了以下 3 点原因：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;在一个连接上操作多个 db 数据时，每次都需要先执行 SELECT，这会给 Redis 带来额外的压力&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;使用多个 db 的目的是，按不同业务线存储数据，那为何不拆分多个实例存储呢？拆分多个实例部署，多个业务线不会互相影响，还能提高 Redis 的访问性能&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Redis Cluster 只支持 db0，如果后期你想要迁移到 Redis Cluster，迁移成本高&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;10) 使用读写分离 + 分片集群&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你的业务读请求量很大，那么可以采用部署多个从库的方式，实现读写分离，让 Redis 的从库分担读压力，进而提升性能。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6519721577726219&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyxjLxTKDdPHc6GLHiaKF4iaialXGwoicYRCjUSLibnqR4GTaGO3yTMMotawng/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;431&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你的业务写请求量很大，单个 Redis 实例已无法支撑这么大的写流量，那么此时你需要使用分片集群，分担写压力。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.501466275659824&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyxw0H7LsTOpeAUpREmuyZQBAelbaMGY6oOHzvyf1jKMTyxiagkYYZqCkw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;682&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;11) 不开启 AOF 或 AOF 配置为每秒刷盘&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果对于丢失数据不敏感的业务，我建议你不开启 AOF，避免 AOF 写磁盘拖慢 Redis 的性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果确实需要开启 AOF，那么我建议你配置为 appendfsync everysec，把数据持久化的刷盘操作，放到后台线程中去执行，尽量降低 Redis 写磁盘对性能的影响。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;12) 使用物理机部署 Redis&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 在做数据持久化时，采用创建子进程的方式进行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而创建子进程会调用操作系统的 fork 系统调用，这个系统调用的执行耗时，与系统环境有关。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虚拟机环境执行 fork 的耗时，要比物理机慢得多，所以你的 Redis 应该尽可能部署在物理机上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;13) 关闭操作系统内存大页机制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Linux 操作系统提供了内存大页机制，其特点在于，每次应用程序向操作系统申请内存时，申请单位由之前的 4KB 变为了 2MB。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这会导致什么问题呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当 Redis 在做数据持久化时，会先 fork 一个子进程，此时主进程和子进程共享相同的内存地址空间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当主进程需要修改现有数据时，会采用写时复制（Copy On Write）的方式进行操作，在这个过程中，需要重新申请内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果申请内存单位变为了 2MB，那么势必会增加内存申请的耗时，如果此时主进程有大量写操作，需要修改原有的数据，那么在此期间，操作延迟就会变大。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.9879663056558363&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyxNz0n0fpaMdYViaibYjWb0Kjx1PZ7Cdu651ib4LSHm1TAJGX5UEQLEOMfA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;831&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，为了避免出现这种问题，你需要在操作系统上关闭内存大页机制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，以上这些就是 Redis 「高性能」方面的实践优化。如果你非常关心 Redis 的性能问题，可以结合这些方面针对性优化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们再来看 Redis 「可靠性」如何保证。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如何保证 Redis 的可靠性？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我想提醒你的是，保证 Redis 可靠性其实并不难，但难的是如何做到「持续稳定」。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我会从「资源隔离」、「多副本」、「故障恢复」这三大维度，带你分析保障 Redis 可靠性的最佳实践。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;1) 按业务线部署实例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提升可靠性的第一步，就是「资源隔离」。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你最好按不同的业务线来部署 Redis 实例，这样当其中一个实例发生故障时，不会影响到其它业务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种资源隔离的方案，实施成本是最低的，但成效却是非常大的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;2) 部署主从集群&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你只使用单机版 Redis，那么就会存在机器宕机服务不可用的风险。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，你需要部署「多副本」实例，即主从集群，这样当主库宕机后，依旧有从库可以使用，避免了数据丢失的风险，也降低了服务不可用的时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在部署主从集群时，你还需要注意，主从库需要分布在不同机器上，避免交叉部署。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这么做的原因在于，通常情况下，Redis 的主库会承担所有的读写流量，所以我们一定要优先保证主库的稳定性，即使从库机器异常，也不要对主库造成影响。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而且，有时我们需要对 Redis 做日常维护，例如数据定时备份等操作，这时你就可以只在从库上进行，这只会消耗从库机器的资源，也避免了对主库的影响。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3) 合理配置主从复制参数&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在部署主从集群时，如果参数配置不合理，也有可能导致主从复制发生问题：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这方面我给你的建议有以下 2 点：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;设置合理的 repl-backlog 参数：过小的 repl-backlog 在写流量比较大的场景下，主从复制中断会引发全量复制数据的风险&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;设置合理的 slave client-output-buffer-limit：当从库复制发生问题时，过小的 buffer 会导致从库缓冲区溢出，从而导致复制中断&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;4) 部署哨兵集群，实现故障自动切换&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;只部署了主从节点，但故障发生时是无法自动切换的，所以，你还需要部署哨兵集群，实现故障的「自动切换」。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而且，多个哨兵节点需要分布在不同机器上，实例为奇数个，防止哨兵选举失败，影响切换时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上这些就是保障 Redis「高可靠」实践优化，你应该也发现了，这些都是部署和运维层的优化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除此之外，你可能还会对 Redis 做一些「日常运维」工作，这时你要注意哪些问题呢？&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;日常运维 Redis 需要注意什么？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果你是 DBA 运维人员，在平时运维 Redis 时，也需要注意以下 6 个方面。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;1) 禁止使用 KEYS/FLUSHALL/FLUSHDB 命令&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;执行这些命令，会长时间阻塞 Redis 主线程，危害极大，所以你必须禁止使用它。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果确实想使用这些命令，我给你的建议是：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;SCAN 替换 KEYS&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;4.0+版本可使用 FLUSHALL/FLUSHDB ASYNC，清空数据的操作放在后台线程执行&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;2) 扫描线上实例时，设置休眠时间&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不管你是使用 SCAN 扫描线上实例，还是对实例做 bigkey 统计分析，我建议你在扫描时一定记得设置休眠时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;防止在扫描过程中，实例 OPS 过高对 Redis 产生性能抖动。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3) 慎用 MONITOR 命令&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有时在排查 Redis 问题时，你会使用 MONITOR 查看 Redis 正在执行的命令。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但如果你的 Redis OPS 比较高，那么在执行 MONITOR 会导致 Redis 输出缓冲区的内存持续增长，这会严重消耗 Redis 的内存资源，甚至会导致实例内存超过 maxmemory，引发数据淘汰，这种情况你需要格外注意。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3315972222222222&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyxmZvibuS8oeZibfl9TDvwmAx5mleOmpUtYcprib55awsF3Dh8vTBen7teg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;576&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以你在执行 MONITOR 命令时，一定要谨慎，尽量少用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;4) 从库必须设置为 slave-read-only&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你的从库必须设置为 slave-read-only 状态，避免从库写入数据，导致主从数据不一致。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除此之外，从库如果是非 read-only 状态，如果你使用的是 4.0 以下的 Redis，它存在这样的 Bug：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;从库写入了有过期时间的数据，不会做定时清理和释放内存。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这会造成从库的内存泄露！这个问题直到 4.0 版本才修复，你在配置从库时需要格外注意。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;5) 合理配置 timeout 和 tcp-keepalive 参数&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果因为网络原因，导致你的大量客户端连接与 Redis 意外中断，恰好你的 Redis 配置的 maxclients 参数比较小，此时有可能导致客户端无法与服务端建立新的连接（服务端认为超过了 maxclients）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;造成这个问题原因在于，客户端与服务端每建立一个连接，Redis 都会给这个客户端分配了一个 client fd。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;当客户端与服务端网络发生问题时，服务端并不会立即释放这个 client fd。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;什么时候释放呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 内部有一个定时任务，会定时检测所有 client 的空闲时间是否超过配置的 timeout 值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果 Redis 没有开启 tcp-keepalive 的话，服务端直到配置的 timeout 时间后，才会清理释放这个 client fd。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在没有清理之前，如果还有大量新连接进来，就有可能导致 Redis 服务端内部持有的 client fd 超过了 maxclients，这时新连接就会被拒绝。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对这种情况，我给你的优化建议是：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;不要配置过高的 timeout：让服务端尽快把无效的 client fd 清理掉&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Redis 开启 tcp-keepalive：这样服务端会定时给客户端发送 TCP 心跳包，检测连接连通性，当网络异常时，可以尽快清理僵尸 client fd&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;6) 调整 maxmemory 时，注意主从库的调整顺序&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Redis 5.0 以下版本存在这样一个问题：&lt;strong&gt;从库内存如果超过了 maxmemory，也会触发数据淘汰。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在某些场景下，从库是可能优先主库达到 maxmemory 的（例如在从库执行 MONITOR 命令，输出缓冲区占用大量内存），那么此时从库开始淘汰数据，主从库就会产生不一致。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要想避免此问题，在调整 maxmemory 时，一定要注意主从库的修改顺序：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;调大 maxmemory：先修改从库，再修改主库&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;调小 maxmemory：先修改主库，再修改从库&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;直到 Redis 5.0，Redis 才增加了一个配置 replica-ignore-maxmemory，默认从库超过 maxmemory 不会淘汰数据，才解决了此问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，以上这些就是「日常运维」Redis 需要注意的，你可以对各个配置项查漏补缺，看有哪些是需要优化的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来，我们来看一下，保障 Redis「安全」都需要注意哪些问题。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Redis 安全如何保证？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;无论如何，在互联网时代，安全问题一定是我们需要随时警戒的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你可能听说过 Redis 被注入可执行脚本，然后拿到机器 root 权限的安全问题，都是因为在部署 Redis 时，没有把安全风险注意起来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对这方面，我给你的建议是：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;不要把 Redis 部署在公网可访问的服务器上&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;部署时不使用默认端口 6379&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;以普通用户启动 Redis 进程，禁止 root 用户启动&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;限制 Redis 配置文件的目录访问权限&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;推荐开启密码认证&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;禁用/重命名危险命令（KEYS/FLUSHALL/FLUSHDB/CONFIG/EVAL）&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;只要你把这些做到位，基本上就可以保证 Redis 的安全风险在可控范围内。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至此，我们分析了 Redis 在内存、性能、可靠性、日常运维方面的最佳实践优化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除了以上这些，你还需要做到提前「预防」。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如何预防 Redis 问题？&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要想提前预防 Redis 问题，你需要做好以下两个方面：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;合理的资源规划&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;完善的监控预警&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先来说资源规划。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在部署 Redis 时，如果你可以提前做好资源规划，可以避免很多因为资源不足产生的问题。这方面我给你的建议有以下 3 点：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;保证机器有足够的 CPU、内存、带宽、磁盘资源&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;提前做好容量规划，主库机器预留一半内存资源，防止主从机器网络故障，引发大面积全量同步，导致主库机器内存不足的问题&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;单个实例内存建议控制在 10G 以下，大实例在主从全量同步、RDB 备份时有阻塞风险&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再来看监控如何做。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;监控预警是提高稳定性的重要环节，完善的监控预警，可以把问题提前暴露出来，这样我们才可以快速反应，把问题最小化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这方面我给你的建议是：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;做好机器 CPU、内存、带宽、磁盘监控，资源不足时及时报警，任意资源不足都会影响 Redis 性能&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;设置合理的 slowlog 阈值，并对其进行监控，slowlog 过多及时报警&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;监控组件采集 Redis INFO 信息时，采用长连接，避免频繁的短连接&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;做好实例运行时监控，重点关注 expired_keys、evicted_keys、latest_fork_usec 指标，这些指标短时突增可能会有阻塞风险&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，总结一下，这篇文章我带你全面分析了 Redis 最佳实践的优化路径，其中包括内存资源、高性能、高可靠、日常运维、资源规划、监控、安全 7 个维度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我画成了思维导图，方便你在实践时做参考。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-backh=&quot;491&quot; data-backw=&quot;568&quot; data-ratio=&quot;0.8651419558359621&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyxoZ9Qog3MIZmVibbhozjUdiaAvXZzBQwecWskzfluZ0FWQoiaPDI69NGNw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2536&quot;/&gt;&lt;span&gt;我还&lt;/span&gt;&lt;span&gt;把这些实践优化，按照「业务开发」和「运维」两个维度，进一步做了划分。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;并且以「强制」、「推荐」、「参考」3 个级别做了标注，这样你在实践优化时，就会更明确哪些该做，哪些需要结合实际的业务场景进一步分析。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这些级&lt;/span&gt;&lt;span&gt;别的实施规则如下：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;强制：需严格遵守，否则危害极大&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;推荐：推荐遵守，可提升性能、降低内存、便于运维&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;参考：根据业务特点参考实施&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你是业务开发人员，你需要了解 Redis 的运行机制，例如各个命令的执行时间复杂度、数据过期策略、数据淘汰策略等，使用合理的命令，并结合业务场景进行优化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-backh=&quot;568&quot; data-backw=&quot;568&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyx4KzYB53twzEqX99WuDzqTEZcTB2ZPAib4iayicx6woZDKGYF6wtd4DHPQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1490&quot;/&gt;&lt;span&gt;如果你是 DBA 运&lt;/span&gt;&lt;span&gt;维人员，你需要在资源规划、运维、监控、安全层面做到位，&lt;span&gt;做到未雨绸缪。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;img data-backh=&quot;656&quot; data-backw=&quot;568&quot; data-ratio=&quot;1.1548582995951417&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gB9Yvac5K3OSCEIQBtroLfFiaMMWzJpyxvHiaHzsZjBhn2KS2Eq2xSrfYZiaCiaGhicruGN6ENHrEpxcmcmlZalGia3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1976&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;后记&lt;/span&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你能耐心地读到这里，应该对如何「用好」Redis 有了新的认识。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这篇文章我们主要讲的是 Redis 最佳实践，对于「最佳实践」这个话题，我想再和你多聊几句。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;如果你面对的不是 Redis，而是其它中间件，例如 MySQL、Kafka，你在使用这些组件时，会有什么优化思路吗？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你也可以沿用这篇文章的这几个维度来分析：&lt;/p&gt;&lt;section&gt;你可以思考一下，MySQL 和 Kafka 在这几个维度，需要注意哪些问题。&lt;br/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，从学习技能的角度来讲，我们在软件开发过程中，要尽可能地去思考和探索「最佳实践」的方式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;因为只有这样，我们才会不断督促自己去思考，对自己提出更高的要求，做到持续进步。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;hr/&gt;&lt;p&gt;往期推荐&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3ODkzMDA2Mw==&amp;amp;mid=2247483874&amp;amp;idx=1&amp;amp;sn=2fc108a4495ebea67e72ba01f2ea4fea&amp;amp;chksm=fd6c9502ca1b1c14985958ca223ef7d4031a7041464c8131a76499a541da1c92f397790d3902&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;彻底搞懂事件驱动模型 - Reactor&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3ODkzMDA2Mw==&amp;amp;mid=2247483865&amp;amp;idx=1&amp;amp;sn=7f758aa084e30195d32d51f67dacc5d8&amp;amp;chksm=fd6c9539ca1b1c2f322fd00bd683e0ecfdb084b082a632a1011c98790e3a04081298a6417f81&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;如何科学破解慢SQL?&lt;/a&gt;&lt;/p&gt;&lt;p&gt;最后，欢迎大家关注Kaito和铁柱，一起成长。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/bymGBmLC3zGuqeeB9CXfeY68KDuHKbP2e0tu0b3IdRH4xAT5FwcUNoVIIFibkQr1LSahlnw08SCLia9zN6QMVTyw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;258&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>