<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>62d56bf908b707331fe0e0aafc0d3b32</guid>
<title>有赞 TCP 网络编程最佳实践</title>
<link>https://toutiao.io/k/a7bxrhs</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section class=&quot;post-content&quot;&gt;
&lt;h1 id=&quot;&quot;&gt;概述&lt;/h1&gt;

&lt;p&gt;本文是根据有赞中间件团队多年的TCP网络编程实践经验总结而来，目的是为了避免应用因各种网络异常而出现各种非预期行为，从而造成非预期的影响，影响系统稳定性与可靠性。&lt;/p&gt;

&lt;p&gt;本文不会涉及TCP的各个基础知识点，主要是总结一些TCP网络编程实践中可能碰到的一些问题，以及相应的经过实践验证的解决方案等。虽然本文档很多细节主要是针对于Linux系统，不过，大部分建议适合于所有系统。&lt;/p&gt;

&lt;p&gt;本文共总结了&lt;strong&gt;16&lt;/strong&gt;项建议，下面逐一进行介绍。&lt;/p&gt;

&lt;h1 id=&quot;1so_reuseaddr&quot;&gt;1. 服务端监听设置SO_REUSEADDR选项&lt;/h1&gt;

&lt;p&gt;当我们重启服务端程序的时候可能会碰到“address already in use”这样的报错信息，即地址已被使用，导致程序无法快速成功重启。老的进程关闭退出了，为什么还会报地址已被使用呢？&lt;/p&gt;

&lt;p&gt;我们先来理解如下两点：  &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TCP连接主动关闭方存在持续2MSL的&lt;code&gt;TIME_WAIT&lt;/code&gt;状态；  &lt;/li&gt;
&lt;li&gt;TCP连接由是由四元组&amp;lt;本地地址，本地端口，远程地址，远程端口&amp;gt;来确定的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们先简单回顾一下TCP连接关闭过程中的&lt;code&gt;TIME_WAIT&lt;/code&gt;状态，如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/content/images/2021/05/tcp_close.png&quot; align=&quot;center&quot;/&gt;&lt;/p&gt;

&lt;p&gt;（图片来源：&lt;a href=&quot;https://en.wikipedia.org/wiki/Transmission_Control_Protocol&quot;&gt;Wikipedia&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;TIME_WAIT存在的意义主要有两点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;维护连接状态，使TCP连接能够可靠地关闭。如果连接主动关闭端发送的最后一条ACK丢失，连接被动关闭端会重传FIN报文。因此，主动关闭方必须维持连接状态，以支持收到重传的FIN后再次发送ACK。如果没有&lt;code&gt;TIME_WAIT&lt;/code&gt;，并且最后一个ACK丢失，那么此时被动关闭端还会处于&lt;code&gt;LAST_ACK&lt;/code&gt;一段时间，并等待重传；如果此时主动关闭方又立即创建新TCP连接且恰好使用了相同的四元组，连接会创建失败，会被对端重置。  &lt;/li&gt;
&lt;li&gt;等待网络中所有此连接老的重复的、走失的报文消亡，避免此类报文对新的相同四元组的TCP连接造成干扰，因为这些报文的序号可能恰好落在新连接的接收窗口内。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因为每个TCP报文最大存活时间为MSL，一个往返最大是2*MSL，所以&lt;code&gt;TIME_WAIT&lt;/code&gt;需要等待2MSL。&lt;/p&gt;

&lt;p&gt;当进程关闭时，进程会发起连接的主动关闭，连接最后会进入&lt;code&gt;TIME_WAIT&lt;/code&gt;状态。当新进程bind监听端口时，就会报错，因为有对应本地端口的连接还处于&lt;code&gt;TIME_WAIT&lt;/code&gt;状态。&lt;/p&gt;

&lt;p&gt;实际上，只有当新的TCP连接和老的TCP连接四元组完全一致，且老的迷走的报文序号落在新连接的接收窗口内时，才会造成干扰。为了使用&lt;code&gt;TIME_WAIT&lt;/code&gt;状态的端口，现在大部分系统的实现都做了相关改进与扩展：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;新连接SYN告知的初始序列号，要求一定要比&lt;code&gt;TIME_WAIT&lt;/code&gt;状态老连接的序列号大，可以一定程度保证不会与老连接的报文序列号重叠。&lt;/li&gt;
&lt;li&gt;开启TCP &lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc6191&quot;&gt;timestamps扩展选项&lt;/a&gt;后，新连接的时间戳要求一定要比&lt;code&gt;TIME_WAIT&lt;/code&gt;状态老连接的时间戳大，可以保证老连接的报文不会影响新连接。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，在开启了TCP timestamps扩展选项的情况下（&lt;code&gt;net.ipv4.tcp_timestamps = 1&lt;/code&gt;），可以放心的设置&lt;code&gt;SO_REUSEADDR&lt;/code&gt;选项，支持程序快速重启。&lt;/p&gt;

&lt;p&gt;注意不要与&lt;code&gt;net.ipv4.tcp_tw_reuse&lt;/code&gt;系统参数混淆，该参数仅在客户端调用connect创建连接时才生效，可以使用&lt;code&gt;TIME_WAIT&lt;/code&gt;状态超过1秒的端口（防止最后一个ACK丢失）；而&lt;code&gt;SO_REUSEADDR&lt;/code&gt;是在bind端口时生效，一般用于服务端监听时，可以使用本地非&lt;code&gt;LISTEN&lt;/code&gt;状态的端口（另一个端口也必须设置&lt;code&gt;SO_REUSEADDR&lt;/code&gt;），不仅仅是&lt;code&gt;TIME_WAIT&lt;/code&gt;状态端口。&lt;/p&gt;

&lt;h1 id=&quot;2&quot;&gt;2. 建立并遵守应用监听端口规范&lt;/h1&gt;

&lt;p&gt;每个应用、每个通信协议要有固定统一的监听端口，便于在公司内部形成共识，降低协作成本，提升运维效率。如对于一些网络ACL控制，规范统一的端口会给运维带来极大的便利。&lt;/p&gt;

&lt;p&gt;应用监听端口不能在&lt;code&gt;net.ipv4.ip_local_port_range&lt;/code&gt;区间内，这个区间是操作系统用于本地端口号自动分配的（bind或connect时没有指定端口号），Linux系统默认值为[32768, 60999]。现在一个应用服务器实例（无论是VM还是K8S Pod等），本地不仅仅会包含应用进程自身，还可能会包括监控采集、sidecar代理等进程。如果选了&lt;code&gt;net.ipv4.ip_local_port_range&lt;/code&gt;这个范围内的端口作为监听端口，你的应用进程启动前，对应的端口很可能已经被自动分配给其他进程的TCP连接，就会导致监听端口绑定失败，从而导致进程启动失败；当然，如果已经分配的端口设置了&lt;code&gt;SO_REUSEADDR&lt;/code&gt;也不会导致你的应用监听端口绑定失败，但这些临时端口一般都不会设置&lt;code&gt;SO_REUSEADDR&lt;/code&gt;。如果确实有需求监听&lt;code&gt;net.ipv4.ip_local_port_range&lt;/code&gt;区间内的端口（如保留三方系统的默认端口），可以设置&lt;code&gt;net.ipv4.ip_local_reserved_ports&lt;/code&gt;系统参数进行预留，预留的端口不会被自动分配出去；但这样会给运维增加系统的交付难度，所以，一般不建议这样做。&lt;/p&gt;

&lt;p&gt;有赞的&lt;code&gt;net.ipv4.ip_local_port_range&lt;/code&gt;系统值设置为[9000, 65535]，并且对所有类型的应用、通信协议监听端口都进行了统一规范，监听端口都小于9000。&lt;/p&gt;

&lt;h1 id=&quot;3&quot;&gt;3. 应用服务端口与管理端口分离&lt;/h1&gt;

&lt;p&gt;服务端口即业务请求的处理端口，管理端口为框架或应用的管理请求处理端口（如服务注册上线、下线）。以Spring Boot为例，应用端口对应&lt;code&gt;server.port&lt;/code&gt;，管理端口对应&lt;code&gt;management.port&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;应用的服务端口与管理端口分离有如下意义：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;避免业务请求与管理请求互相影响，如线程池等。&lt;/li&gt;
&lt;li&gt;更好地进行权限管理、ACL控制等。管理端口一般可以控制应用的核心行为，需要进行严格的权限管理、ACL控制，比如通过防火墙仅允许特定IP访问管理端口等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有赞线上曾经碰到过一个问题：一个Dubbo业务应用提供HTTP服务和Dubbo服务，HTTP服务端口与HTTP管理端口是同一个，该应用的一个实例因内部逻辑问题发生了死锁，造成请求阻塞超时，但这时服务注册的健康保活线程仍然正常，所以该异常服务实例还是在线的，客户端仍在发送请求到该实例。这时想将该实例进行服务注册下线操作但保留进程以便排查问题，但由于业务线程阻塞导致HTTP线程池所有线程阻塞，进而导致管理模块无线程可处理HTTP服务注册下线请求，最终无法正常下线。有赞Dubbo框架已经对应用服务端口与管理端口进行了分离，并进行了线程池隔离，避免再出现类似的问题。当然，熔断等其他机制也有助于应对个别实例异常问题，这里我们主要关注端口分离问题。&lt;/p&gt;

&lt;h1 id=&quot;4&quot;&gt;4. 建立连接设置超时时间&lt;/h1&gt;

&lt;p&gt;网络拥塞、IP不可达、握手队列满时，都可能会导致建立连接阻塞与超时，为了避免不可控的阻塞时间对应用造成难以预知的影响，建议在建立连接时设置超时时间，进行超时控制。如果没有主动进行设置，超时时间是由系统默认行为进行控制的，而系统的默认行为肯定是无法满足所有应用场景的。（注：握手队列满时，如果设置了系统参数&lt;code&gt;net.ipv4tcp_abort_on_overflow&lt;/code&gt;，连接会立刻被重置）&lt;/p&gt;

&lt;p&gt;我们看一下系统默认是如何控制连接建立超时时间的？&lt;/p&gt;

&lt;p&gt;TCP三次握手的第一个SYN报文没有收到ACK，系统会自动对SYN报文进行重试，最大重试次数由系统参数&lt;code&gt;net.ipv4.tcp_syn_retries&lt;/code&gt;控制，默认值为6。初始RTO为1s，如果一直收不到SYN ACK，依次等待1s、2s、4s、8s、16s、32s发起重传，最后一次重传等待64s后放弃，最终在127s后才会返回ETIMEOUT超时错误。&lt;/p&gt;

&lt;p&gt;建议根据整个公司的业务场景，调整&lt;code&gt;net.ipv4.tcp_syn_retries&lt;/code&gt;系统参数进行兜底。有赞将该参数设为3，即最大15s左右可返回超时错误。&lt;/p&gt;

&lt;h1 id=&quot;5&quot;&gt;5. 使用应用层心跳对连接进行健康检查&lt;/h1&gt;

&lt;p&gt;当TCP连接有异常时，我们需要尽快感知到，然后进行相应的异常处理与恢复。对于FIN或RST这种连接关闭、重置场景，应用层是可以快速感知到的。但是对于对端机器掉电、网线脱落、网络设备异常等造成的假连接，如果没有特殊措施，应用层很长时间都感知不到。&lt;/p&gt;

&lt;p&gt;提到网络异常检测，大家可能首先想到的是TCP Keepalive。系统TCP Keepalive相关的三个参数为&lt;code&gt;net.ipv4.tcp_keepalive_time&lt;/code&gt;、&lt;code&gt;net.ipv4.tcp_keepalive_intvl&lt;/code&gt;、&lt;code&gt;net.ipv4.tcp_keepalive_probes&lt;/code&gt;，默认值分别为7200s、75s、9，即如果7200s没有收到对端的数据，就开始发送TCP Keepalive报文，如果75s内，没有收到响应，会继续重试，直到重试9次都失败后，返回应用层错误信息。&lt;/p&gt;

&lt;p&gt;为什么需要实现应用层的心跳检查呢？系统的TCP Keepalive满足不了需求吗？是的，系统的TCP Keepalive只能作为一个最基本的防御方案，而满足不了高稳定性、高可靠性场景的需求。原因有如下几点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TCP Keepalive是扩展选项，不一定所有的设备都支持；&lt;/li&gt;
&lt;li&gt;TCP Keepalive报文可能被设备特意过滤或屏蔽，如运营商设备；&lt;/li&gt;
&lt;li&gt;TCP Keepalive无法检测应用层状态，如进程阻塞、死锁、TCP缓冲区满等情况；&lt;/li&gt;
&lt;li&gt;TCP Keepalive容易与TCP重传控制冲突，从而导致失效。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于TCP状态无法反应应用层状态问题，这里稍微介绍几个场景。第一个是TCP连接成功建立，不代表对端应用感知到了该连接，因为TCP三次握手是内核中完成的，虽然连接已建立完成，但对端可能根本没有Accept；因此，一些场景仅通过TCP连接能否建立成功来判断对端应用的健康状况是不准确的，这种方案仅能探测进程是否存活。另一个是，本地TCP写操作成功，但数据可能还在本地写缓冲区中、网络链路设备中、对端读缓冲区中，并不代表对端应用读取到了数据。&lt;/p&gt;

&lt;p&gt;这里重点解释一下TCP KeepAlive与TCP重传的冲突问题。Linux系统通过&lt;code&gt;net.ipv4.tcp_retries2&lt;/code&gt;参数控制TCP的超时重传次数，即影响TCP超时时间。初始RTO为&lt;code&gt;TCP_RTO_MIN&lt;/code&gt;（200ms），RTO进行指数退让，最大RTO为&lt;code&gt;TCP_RTO_MAX&lt;/code&gt;（2min），&lt;code&gt;net.ipv4.tcp_retries2&lt;/code&gt;默认为15，大概924.6s超时。详细重传次数、RTO、超时时间关系，如下表所示。&lt;/p&gt;

&lt;table border=&quot;1&quot;&gt;  
&lt;tr&gt;  
&lt;th&gt;重传次数&lt;/th&gt;  
&lt;th&gt;RTO（毫秒）&lt;/th&gt;  
&lt;th colspan=&quot;2&quot;&gt;总超时时间&lt;/th&gt;  
&lt;/tr&gt;  
&lt;tr&gt; &lt;td&gt; 1&lt;/td&gt; &lt;td&gt;   200&lt;/td&gt; &lt;td&gt;  0.2 秒&lt;/td&gt; &lt;td&gt;0.0 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 2&lt;/td&gt; &lt;td&gt;   400&lt;/td&gt; &lt;td&gt;  0.6 秒&lt;/td&gt; &lt;td&gt;0.0 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 3&lt;/td&gt; &lt;td&gt;   800&lt;/td&gt; &lt;td&gt;  1.4 秒&lt;/td&gt; &lt;td&gt;0.0 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 4&lt;/td&gt; &lt;td&gt;  1600&lt;/td&gt; &lt;td&gt;  3.0 秒&lt;/td&gt; &lt;td&gt;0.1 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 5&lt;/td&gt; &lt;td&gt;  3200&lt;/td&gt; &lt;td&gt;  6.2 秒&lt;/td&gt; &lt;td&gt;0.1 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 6&lt;/td&gt; &lt;td&gt;  6400&lt;/td&gt; &lt;td&gt; 12.6 秒&lt;/td&gt; &lt;td&gt;0.2 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 7&lt;/td&gt; &lt;td&gt; 12800&lt;/td&gt; &lt;td&gt; 25.4 秒&lt;/td&gt; &lt;td&gt;0.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 8&lt;/td&gt; &lt;td&gt; 25600&lt;/td&gt; &lt;td&gt; 51.0 秒&lt;/td&gt; &lt;td&gt;0.9 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 9&lt;/td&gt; &lt;td&gt; 51200&lt;/td&gt; &lt;td&gt;102.2 秒&lt;/td&gt; &lt;td&gt;1.7 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;10&lt;/td&gt; &lt;td&gt;102400&lt;/td&gt; &lt;td&gt;204.6 秒&lt;/td&gt; &lt;td&gt;3.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;11&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;324.6 秒&lt;/td&gt; &lt;td&gt;5.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;12&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;444.6 秒&lt;/td&gt; &lt;td&gt;7.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;13&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;564.6 秒&lt;/td&gt; &lt;td&gt;9.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;14&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;684.6 秒&lt;/td&gt; &lt;td&gt;11.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;15&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;804.6 秒&lt;/td&gt; &lt;td&gt;13.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;16&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;924.6 秒&lt;/td&gt; &lt;td&gt;15.4 分钟&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/table&gt;

&lt;p&gt;如果TCP发送缓冲区中有数据未发送成功，TCP会进行超时重传，而不会触发TCP Keepalive。也就是说，即使应用设置了很小的TCP Keepalive参数，如time=10s、interval=10s、probes=3，在&lt;code&gt;net.ipv4.tcp_retries2&lt;/code&gt;默认配置下，可能还是一直等到15min左右才能感知到网络异常。可能有的人不理解为什么Keepalive会被重传干扰，其实这里就是个优先级的问题。TCP最大重传次数的作用高于Keepalive参数的作用，未达到最大重传次数，不会向应用层报告网络错误信息。如果Keepalive不受重传影响，同样也会对关注重传的人造成干扰，比如为什么还没达到最大重传次数就放弃重传并关闭连接了？我们可以通过&lt;code&gt;netstat -ot&lt;/code&gt;或&lt;code&gt;ss -ot&lt;/code&gt;命令查看当前连接的计时器信息。&lt;/p&gt;

&lt;p&gt;建议根据实际情况调低&lt;code&gt;net.ipv4.tcp_retries2&lt;/code&gt;参数。RFC 1122建议对应的超时时间不低于100s，即至少为8，有赞系统该参数默认为10。&lt;/p&gt;

&lt;p&gt;因此，想实现一个网络健壮的应用，应用层心跳必不可少。对于&lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc7540#section-6.7&quot;&gt;HTTP2&lt;/a&gt;、&lt;a href=&quot;https://github.com/grpc/grpc/blob/master/doc/keepalive.md&quot;&gt;gRPC&lt;/a&gt;、&lt;a href=&quot;https://dubbo.apache.org/zh/docs/v2.7/dev/implementation/#%E5%8D%8F%E8%AE%AE%E5%A4%B4%E7%BA%A6%E5%AE%9A&quot;&gt;Dubbo&lt;/a&gt;等协议都支持心跳，如果是基于这些协议开发的应用，可以直接使用这些协议的特性来实现应用层心跳。&lt;/p&gt;

&lt;p&gt;实现应用层心跳需要考虑如下点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;心跳间隔不能太小也不能太大。间隔太小心可能会对轻微抖动过于敏感，造成过度反应，反而会影响稳定性，同时也有一定的性能开销；间隔太大会导致异常检测延迟比较高。可以严格地定期发送心跳，也可以一段时间内没有收到对端数据才发起心跳。建议心跳间隔为5s~20s。&lt;/li&gt;
&lt;li&gt;设置连续失败阈值，避免瞬间抖动造成误判等。建议连续失败阈值为2~5。&lt;/li&gt;
&lt;li&gt;不要使用独立的TCP连接进行心跳检查，因为不同连接的网络路径、TCP缓冲区等都不同，无法真实反映业务通信连接的真实状态。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;6&quot;&gt;6. 连接重连需要增加退让与窗口抖动&lt;/h1&gt;

&lt;p&gt;当网络异常恢复后，大量客户端可能会同时发起TCP重连及进行应用层请求，可能会造成服务端过载、网络带宽耗尽等问题，从而导致客户端连接与请求处理失败，进而客户端触发新的重试。如果没有退让与窗口抖动机制，该状况可能会一直持续下去，很难快速收敛。&lt;/p&gt;

&lt;p&gt;建议增加指数退让，如1s、2s、4s、8s...，同时必须限制最大退让时间（如64s），否则重试等待时间可能越来越大，同样导致无法快速收敛。同时，为了降低大量客户端同时建连并请求，也需要增加窗口抖动，窗口大小可以与退让等待时间保持一致，如:
nextRetryWaitTime = backOffWaitTime + rand(0.0, 1.0) * backOffWaitTime。&lt;/p&gt;

&lt;p&gt;在进行网络异常测试或演练时，需要把网络异常时间变量考虑进来，因为不同的时长，给应用带来的影响可能会完全不同。&lt;/p&gt;

&lt;h1 id=&quot;7&quot;&gt;7. 服务端需要限制最大连接数&lt;/h1&gt;

&lt;p&gt;一个服务端口，理论上能接收的最大TCP连接数是多少呢？TCP四元组中的服务端IP、服务端端口已经固定了，理论上的上限就是客户端可用IP数量*客户端可用端口数量。去除一些IP分类、端口保留等细节，理论上限就是2^32 * 2 ^16 = 2^48。&lt;/p&gt;

&lt;p&gt;当然，目前现实中肯定达不到理论上限的瓶颈。一个TCP socket所关联的主要资源有内存缓冲区、文件描述符等，因此，实际限制主要取决于系统内存大小与文件描述符数量限制。&lt;/p&gt;

&lt;p&gt;服务端限制最大连接数，主要有两个目的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;避免服务过载导致CPU、内存耗尽；&lt;/li&gt;
&lt;li&gt;避免文件描述符耗尽。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每个TCP连接的socket都占用一个FD，每个进程以及整个系统的FD数量都是有限制的。Linux系统下，通过&lt;code&gt;ulimit -n&lt;/code&gt;可以查看单个用户的进程运行打开的FD最大数量，通过&lt;code&gt;cat /proc/sys/fs/file-max&lt;/code&gt;可以查看所有进程运行打开的最大FD数量，如果不符合应用的需求，那就需要进行相应的调整。&lt;/p&gt;

&lt;p&gt;达到FD上限会有什么影响呢？首先，肯定是无法接收新TCP连接了；其次，除了TCP连接占用的FD外，你的应用肯定还有内部场景占用或需要分配新的FD，比如日志文件发生轮转创建新日志文件时，如果日志文件创建失败，对于依赖本地存储的应用（如KV、MQ等存储型应用），就导致服务不可用了。所以，要在系统限制的基础上，根据应用的特性预留一定数量的FD，而不能把所有的FD都给客户端TCP连接使用。&lt;/p&gt;

&lt;p&gt;有赞在线上压测时，一个应用就碰到过类似的一个问题。压测期间，压力比较高，导致磁盘IO压力增高，请求处理延迟增高，导致客户端超时。客户端发现超时关闭连接，创建新连接重试，但此时服务端由于IO阻塞带来的延迟并未能够及时回收连接关闭（CLOSE_WAIT）的socket以及FD，导致FD消耗越来越多，最终导致FD耗尽，新日志文件创建失败，而该应用又是存储类型应用，强依赖于日志落盘，最终导致服务不可用。&lt;/p&gt;

&lt;p&gt;除了服务端限制最大连接数外，如果应用有对应的客户端SDK，最好也在客户端SDK也做一层保护。&lt;/p&gt;

&lt;h1 id=&quot;8&quot;&gt;8. 尽量不要依赖中心化四层负载均衡器&lt;/h1&gt;

&lt;p&gt;LVS是一个经典的中心化四层负载均衡解决方案，也有各种云厂商提供的类似LVS的产品，原理大多是一致的。它们的优点这里我们就不谈了。使用该类方案可能会面临如下问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每次应用伸缩容，需要变更后端实例列表配置，运维成本高、风险高；&lt;/li&gt;
&lt;li&gt;中心化的组件可伸缩性较差，容易触达瓶颈，如网络带宽瓶颈等；&lt;/li&gt;
&lt;li&gt;中心化的组件可用性较差，一旦负载均衡器出问题，整个服务受影响；&lt;/li&gt;
&lt;li&gt;四层健康检查对后端实例异常不敏感，无法进行应用层健康检查；&lt;/li&gt;
&lt;li&gt;负载均衡器的拆分、迁移对应用影响较大，需要应用配合更新配置、发布等，使用成本较高；&lt;/li&gt;
&lt;li&gt;负载均衡器会可能丢弃一段时间内没有通信的空闲连接，给应用带来非预期的影响；&lt;/li&gt;
&lt;li&gt;客户端访问服务端需经过负载均衡器中转，可能对RT有一定影响。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;建议通过分布式的动态服务注册与发现以及客户端负载均衡来替代中心化负载均衡方案，如微服务架构中的服务注册、服务发现、负载均衡等解决方案。&lt;/p&gt;

&lt;p&gt;在不得不使用中心化负载均衡器的场景下，也需要注意以下问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;注意选择合适的负载均衡算法，避免长连接分布不均衡。比如，如果选择了轮询负载均衡算法，正常情况下各个后端实例的连接数是均衡的，但当某个实例重启后，该实例的连接断开后，客户端会发起重连，重连就大概率转移其他实例上，导致最近启动的实例连接数较少，最早启动的实例连接数较多。可以考虑最少连接数负载均衡，长连接增加TTL限制等。&lt;/li&gt;
&lt;li&gt;注意空闲超时，超时后负载均衡器可能不会给两端发送Close或Reset信号，从而导致无法通信的假连接，如果客户端与服务端双方都没有心跳、空闲超时等，假连接会一直存在，占用系统资源；应用层或TCP层的健康检查周期需要小于负载均衡器的空闲超时。&lt;/li&gt;
&lt;li&gt;注意摘除后端实例时保证平滑，如果直接移除后端实例，可能不会给两端发送Close或Reset信号，从而导致无法通信的假连接，且客户端和服务端无法及时感知到。一般先将实例权重调整为0，保证新连接不再分配到该实例，然后等待已有的连接释放，最后再完全移除后端实例。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有赞线上环境曾多次碰到过LVS引起的相关问题，也正在研发分布式的四层代理。&lt;/p&gt;

&lt;h1 id=&quot;9close_wait&quot;&gt;9. 警惕大量CLOSE_WAIT&lt;/h1&gt;

&lt;p&gt;先介绍曾经碰到的一个问题。线上环境告警提示有服务器发生较高的TCP重传，经抓包分析重传包都是FIN包，且目标IP已不存在。查看连接状态发现大量&lt;code&gt;CLOSE_WAIT&lt;/code&gt;状态连接。该问题并不是一直持续，时有时无。经过对应用日志与应用代码分析，发现某个场景应用读取到EOF时，未关闭本地socket。进一步分析，原因是客户端应用是K8S部署的，发布后，旧实例下线，作为客户端发起主动关闭连接，并且旧实例的IP很快会被回收；服务端未关闭的socket，在几分钟后GC时（Go语言应用）才会进行socket回收关闭操作，但此时，客户端IP已不存在，因此，最后一个FIN报文不断重传，一直到超过最大重传次数，从而问题恢复。等到再次有客户端应用发布时，又会出现。该问题对于没有GC机制的编程语言开发的应用，可能会造成更严重的后果，socket不断泄露，导致FD耗尽、内存耗尽等问题。&lt;/p&gt;

&lt;p&gt;因此，一定要警惕大量CLOSE_WAIT状态连接的出现，这种情况出现时，首先要排除一些相关代码。同时，开发过程中，一定要注意正确关闭socket，通过一些语言特性进行兜底处理，如Go语言的&lt;code&gt;defer&lt;/code&gt;，Java语言的&lt;code&gt;try...catch...finally&lt;/code&gt;，C++语言的&lt;code&gt;RAII&lt;/code&gt;机制等。&lt;/p&gt;

&lt;h1 id=&quot;10ttl&quot;&gt;10. 合理设置长连接TTL&lt;/h1&gt;

&lt;p&gt;长连接减少了像短连接频繁建立连接的开销，包括三次握手开销、慢启动开销等。但也有一定的弊端：长连接的持续时间过长，可能会导致一些负载均衡问题，以及其他一些长时间难以收敛的问题。比如LVS场景，随着后端应用实例的重启，对于一些负载均衡算法（如轮询），会导致最新启动的实例连接数最少，最早启动的实例连接数最多。对于一些客户端负载均衡方案，当只需要连接后端集群中的一个节点时，长连接也会出现类似的问题，比如类似Etcd watch的场景。有赞内部有很多使用Etcd的场景，早期运维每次变更Etcd集群的时候都特别谨慎，避免连接的不均衡。&lt;/p&gt;

&lt;p&gt;有赞中间件团队规定任何应用的TCP长连接TTL不能超过2小时。当然，这已经是一个很保守的时长了，建议根据应用场景，合理设置TTL。&lt;/p&gt;

&lt;h1 id=&quot;11dns&quot;&gt;11. 通过域名访问服务需定期解析DNS&lt;/h1&gt;

&lt;p&gt;DNS是一种服务发现机制，应用通过配置DNS访问其他服务，本意是为了解决其他服务实例IP变动带来的影响，但如果处理不当还是会有问题。通过域名访问其他服务时，需要定时更新域名解析，如果解析有更新，则需要重新建立连接，避免后端实例迁移（IP有变化）时导致难以收敛。千万不要只在应用启动的时候进行一次域名解析，这种情况在DNS变更后想实现快速收敛，只能重启或发布所有相关应用了。一些语言内置了DNS相关的实现，需要注意对应的一些参数以及行为是否符合预期。&lt;/p&gt;

&lt;p&gt;另外，某些应用提供了获取最新集群成员列表的接口，如Etcd、Redis，这样即使客户端启动的时候只进行一次域名解析，只要定期从服务端同步服务集群的成员列表也能支持服务端集群成员的动态变化。&lt;/p&gt;

&lt;h1 id=&quot;12&quot;&gt;12. 降低网络读写系统调用次数&lt;/h1&gt;

&lt;p&gt;当我们调用read/write系统函数从socket读写数据时，每次调用都至少进行两次用户态与内核态的上下文切换，成本比较高。针对该问题，一般有两种优化思路：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;使用读写缓冲区；读数据时，先一次性从socket读入缓冲区，然后再按需要分次从缓冲区读取；写数据时，先分次写入缓冲区，缓冲区满时或所有写操作完成时，一次性写入socket。&lt;/li&gt;
&lt;li&gt;当不方便将数据合并到连续内存时，使用readv/writev一次性读取/写入多段内存数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于批量写操作还有一个优点，就是可以避免&lt;a href=&quot;https://en.wikipedia.org/wiki/Nagle%27s_algorithm&quot;&gt;Nagle算法&lt;/a&gt;带来的延迟（一般也不建议开启Nagle算法）。假如当前写缓冲区中没有数据，我们先通过write写4个字节，这时TCP协议栈将其发送出去，然后再通过write写96个字节，这时，由于前面发送了一个报文，还没有收到ACK，并且当前可发送数据未达到MSS，Nagle算法不允许继续发送报文，必须等到前一个报文的ACK回来才能继续发送数据，大大降低了吞吐量并且提高了延迟。如果接收端开启了&lt;a href=&quot;https://en.wikipedia.org/wiki/TCP_delayed_acknowledgment&quot;&gt;延迟ACK&lt;/a&gt;，影响更大。&lt;/p&gt;

&lt;p&gt;因此，应该尽量批量读写网络数据，以提升性能。&lt;/p&gt;

&lt;h1 id=&quot;13tcp&quot;&gt;13. 谨慎设置TCP缓冲区大小&lt;/h1&gt;

&lt;p&gt;一般来说我们不需要更改TCP默认缓冲区大小，如果我们确实有需求设置，也需要谨慎考虑与评估。&lt;/p&gt;

&lt;p&gt;TCP缓冲区大小设置为多少合适呢？我们知道，TCP 的传输速度，受制于发送窗口与接收窗口大小，以及网络传输能力。其中，两个窗口由缓冲区大小决定，如果缓冲区大小与网络传输能力匹配，那么缓冲区的利用率就是最高的。&lt;/p&gt;

&lt;p&gt;带宽时延积（缩写为 BDP，&lt;a href=&quot;https://en.wikipedia.org/wiki/Bandwidth-delay_product&quot;&gt;Bandwidth-delay Product&lt;/a&gt;）是用来描述网络传输能力的。如最大带宽是 100MB/s、网络时延是 10ms 时，客户端到服务端之间的网络一共可以存放 100MB/s * 0.01s = 1MB 的字节，这个 1MB 是带宽与时延的乘积，也就是带宽时延积。这 1MB 字节存在于飞行中的 TCP 报文，它们就在网络线路、路由器等网络设备上。如果飞行报文超过了 1MB，就一定会让网络过载，最终导致丢包。&lt;/p&gt;

&lt;p&gt;由于发送缓冲区决定了发送窗口的上限，而发送窗口又决定了已发送但未确认的飞行报文的上限，因此，发送缓冲区不能超过带宽时延积，因为超出的部分没有办法用于有效的网络传输，且飞行字节大于带宽时延积还会导致丢包，从而触发网络拥塞避免；而且，缓冲区也不能小于带宽时延积，否则无法发挥出高速网络的价值。&lt;/p&gt;

&lt;p&gt;总结而言：缓冲区太小，会降低TCP吞吐量，无法高效利用网络带宽，导致通信延迟升高；缓冲区太大，会导致TCP连接内存占用高以及受限于带宽时延积的瓶颈，从而造成内存浪费。如果缓冲区过小，如2K，还可能会导致&lt;a href=&quot;https://en.wikipedia.org/wiki/TCP_congestion_control#Fast_retransmit&quot;&gt;快速重传&lt;/a&gt;无法生效，因为未确认的报文可能最多只有2个，不会出现3个重复的ACK。&lt;/p&gt;

&lt;p&gt;Linux系统是可以根据系统状态自动调节缓冲区大小的，相关参数由&lt;code&gt;net.ipv4.tcp_wmem&lt;/code&gt;和&lt;code&gt;net.ipv4.tcp_rmem&lt;/code&gt;控制，参数是一个3元组&lt;min default=&quot;&quot; max=&quot;&quot;&gt;，即最大值、初始默认值、最大值。但如果在 socket 上直接设置 SO&lt;em&gt;SNDBUF 或者 SO&lt;/em&gt;RCVBUF，这样会关闭缓冲区的系统动态调整功能，这样操作前务必要进行充分的评估。 &lt;br/&gt;
因此，除非非常明确自己的需求，以及进行充分的评估与验证，否则，不要轻易设置TCP缓冲区大小。&lt;/min&gt;&lt;/p&gt;

&lt;h1 id=&quot;14&quot;&gt;14. 网络相关参数支持灵活配置&lt;/h1&gt;

&lt;p&gt;当应用可能有多种部署环境、部署场景时，需要根据使用场景、网络环境等因素，调整合适的网络相关参数。LAN和WAN的网络状况差别很大，会涉及到诸多参数的调整。&lt;/p&gt;

&lt;p&gt;比如对于有赞的服务代理组件&lt;a href=&quot;https://tech.youzan.com/service-meshzai-you-zan-de-shi-jian-yu-fa-zhan/&quot;&gt;Tether&lt;/a&gt;，既有数据中心内的sidecar部署场景，又有跨公网的网关部署场景，这时就需要按需调整对应的参数，否则难以适应不同的网络环境。如连接超时、读写超时、健康检查超时、健康检查失败阈值等都应该支持灵活配置。&lt;/p&gt;

&lt;h1 id=&quot;15&quot;&gt;15. 合理设置连接池大小&lt;/h1&gt;

&lt;p&gt;对于不同类型的协议，连接池的设计也不同。我们将协议是否支持连接多路复用划分为两类：非多路复用协议和多路复用协议。非多路复用协议，一个连接发送请求后，必须等待响应返回后，该连接才能发送新的请求，如HTTP1.1、Redis等；多路复用协议，支持同一个连接同时发送多个请求，如HTTP2、gRPC、Dubbo等。&lt;/p&gt;

&lt;p&gt;我们先看一下非多路复用协议如何设置连接池大小。连接池涉及到的参数一般有：最小连接数、最大连接数、最大空闲时间、连接获取超时时间、连接获取超时重试次数等。应用与连接池主要交互逻辑如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/content/images/2021/05/conn_pool-1.png&quot; align=&quot;center&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我们主要讨论最小连接数和最大连接数。之所以不是固定连接数，是因为流量有高峰、有低谷；固定连接数太小，流量高峰期容易导致请求等待时间过长；固定连接数太大，流量低谷期容易造成资源浪费。因此，最小连接数对应的就是流量低谷期连接数多少为合适，最大连接数对应的就是流量高峰期连接数多少为合适，也就是连接数与流量大小是相关的。除了流量大小，还需要考虑请求RT，即每个请求占用连接的时间。所需要的连接数其实就是请求并发数，这里我们可以利用著名的利特尔法则（&lt;a href=&quot;https://en.wikipedia.org/wiki/Little%27s_law&quot;&gt;Little&#x27;s law&lt;/a&gt;）来计算，&lt;em&gt;L=λW&lt;/em&gt;，在该场景即：并发数 = 请求QPS * 请求RT。比如流量低谷期请求QPS为100，请求RT为0.05s，则并发数为5，所需连接数为5；流量高峰期请求QPS为500，请求RT为0.1s，则并发数为50，所需连接数为50。这类问题其实与&lt;a href=&quot;https://en.wikipedia.org/wiki/Queueing_theory&quot;&gt;排队论&lt;/a&gt;相关，不过我们这里不做过多讨论，如果有更复杂的需求场景，可以参考更多排队论相关资料。&lt;/p&gt;

&lt;p&gt;接下来我们继续看一下多路复用协议如何设置连接池大小。连接池涉及到的参数一般有：最小连接数、最大连接数、单连接并发请求数高水位、单连接并发请求数低水位。当单连接并发请求数高于高水位时，如果连接池未达到最大连接数，进行连接池扩容，创建连接；当单连接并发请求数低于低水位时，如果连接池未达到最小连接数，进行连接池缩容，释放连接（释放过程需要做到平滑）。由于每个请求不独占连接，请求是可以选择任意连接的，所以这里也面临负载均衡的问题，需要尽可能的确保每个连接上的处理中的请求数接近平均值。一般使用最少请求数负载均衡，但最少请求数负载均衡时间复杂度可能比较高，最简单的实现需要扫描整个连接池。我们可以使用其近似的优化实现，随机选择两个连接，选择Pending请求数少的连接；为了更加近似最少请求，可以选择3个、5个，甚至更多个连接，取其中Pending请求数最少的连接。&lt;/p&gt;

&lt;h1 id=&quot;16&quot;&gt;16. 完善网络指标监控&lt;/h1&gt;

&lt;p&gt;需要对各个关键网络指标进行监控与告警，包括但不限于：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TCP连接建立失败数&lt;/li&gt;
&lt;li&gt;TCP报文重传率&lt;/li&gt;
&lt;li&gt;TCP各个状态连接数（尤其是&lt;code&gt;ESTABLISHED&lt;/code&gt;、&lt;code&gt;TIME_WAIT&lt;/code&gt;、&lt;code&gt;CLOSE_WAIT&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;TCP主动关闭连接数&lt;/li&gt;
&lt;li&gt;TCP被动关闭连接数&lt;/li&gt;
&lt;li&gt;连接健康检查失败数&lt;/li&gt;
&lt;li&gt;系统及进程FD使用数&lt;/li&gt;
&lt;li&gt;连接池大小 &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果能尽早发现这些指标的异常，那么就可以尽快发现问题，从而降低问题影响面。&lt;/p&gt;

&lt;h1 id=&quot;&quot;&gt;总结&lt;/h1&gt;

&lt;p&gt;本文根据有赞TCP网络编程实践经验总结了&lt;strong&gt;16&lt;/strong&gt;项建议，希望能够在TCP网络编程方面帮助大家提升应用的健壮性、可靠性，减少线上问题与故障。&lt;/p&gt;

&lt;h1 id=&quot;&quot;&gt;参考资料&lt;/h1&gt;



&lt;p&gt;`&lt;/p&gt;
                    &lt;p class=&quot;break-line&quot;&gt;欢迎关注我们的公众号&lt;/p&gt;
                    &lt;img src=&quot;https://tech.youzan.com/static_image/coder_qrcode.png&quot;/&gt;
&lt;/section&gt;

&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>aeafe577ac04ad691d942a5d08d27f71</guid>
<title>618 临阵磨刀：Flink 容器化与平台化建设少走弯路</title>
<link>https://toutiao.io/k/hv256a2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzkwOTIxNDQ3OA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8YRIaicYx5pzj5Cxwick8DamnOgbTJu96QTibKyHEDZt1815yOV1r27oZ6HgoYTEYWYLRz4jIV4iasHgg/0?wx_fmt=png&quot; data-nickname=&quot;dbaplus社群&quot; data-alias=&quot;dbaplus&quot; data-signature=&quot;围绕Database、BigData、AIOps的企业级专业社群。资深大咖、技术干货，每天精品原创文章推送，每周线上技术分享，每月线下技术沙龙，每季度Gdevops&amp;amp;DAMS行业大会.&quot; data-from=&quot;0&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-id=&quot;7&quot; data-tools=&quot;135编辑器&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;本文根据王康老师在〖deeplus直播第268期〗线上分享演讲内容整理而成。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;（文末有获取本期PPT&amp;amp;回放的方式，不要错过）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;39&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-ratio=&quot;1.0277778&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8ZW8c3PG3N67MO2vqa4ibG9NqRAxXr9owC8OOt2xyKAn7lncXmPFcNiaarxsLQ6kdRW6YPWfWHa3SlA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;180&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;王康&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;唯品会 数据平台 高级开发工程师&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;自2017年起，为保障内部业务在平时和大促期间的平稳运行，我们唯品会就开始基于Kubernetes深入打造高性能、稳定、可靠、易用的实时计算平台，我们现在的平台支持Flink、Spark、Storm等主流框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文将分为五个方面，分享唯品会Flink的容器化实践应用以及产品化经验：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;261&quot; data-backw=&quot;518&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5038610038610039&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTkicQ0988DHgeTGs17kgiadUN2eVzrtQeRyaviatb622WpUaiaPzvLJ3HbA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;518&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;一、发展概览&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1、集群规模&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;308&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5424083769633508&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTib9mRgjicLRUIOUDl4ukTR7axxW6vmRvKsAcb9hdGwpoic4qYa7QU4Mrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;955&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在集群规模方面，我们有2000+的物理机，主要部署Kubernetes异地双活的集群利用Kubernetes的namespaces、labels和taints等实现业务隔离以及初步的计算负载隔离。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Flink任务数、Flink SQL任务数、Storm任务数、Spark任务数，这些线上实时应用加起来有1000多个，目前我们主要在支持Flink SQL这一块，SQL化是一个趋势，所以我们要支持SQL任务的上线平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2、平台架构&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;321&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5646186440677966&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTF1PrcOZgx6spTiaeo7CWpF17UzWFjAxlbRPOCvVR95C6qkiahtiauxPmQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;944&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们从下往上进行解析实时计算平台的整体架构：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;p&gt;&lt;span&gt;实际上是用&lt;/span&gt;&lt;span&gt;deployment的模式运行Kubernetes上，平台虽然是支持yarn调度，但是yarn调度是与批任务共享资源，所以主流任务还是运行在Kubernetes上的。并且，yarn调度这一层主要是跟离线部署的一套yarn集群，在2017年的时候，我们自研了Flink on Kubernetes的一套方案，因为底层调度分了两层，所以在大促资源紧张的时候，实时跟离线就可以做一个资源的借调。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;p&gt;&lt;span&gt;主要用来支持公司内部基于&lt;/span&gt;&lt;span&gt;Kafka实时数据vms，基于binlog的vdp数据和原生Kafka作为消息总线，状态存储在hdfs上，数据主要存入Redis，MySQL，HBase，Kudu，HDFS，ClickHouse等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;p&gt;&lt;span&gt;主要是Flink、Storm、Spark，目前主推的是Flink这一块，每个框架会都会支持几个版本的镜像以满足不同的业务需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;/section&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;p&gt;&lt;span&gt;主要提供作业配置、调度、版本管理、容器监控、job监控、告警、日志等功能，提供多租户的资源管理（quota，label管理），提供Kafka监控。资源配置也分为大促日和平常日，大促的资源和平常的资源是不一样的，资源的权限管控也是不一样的。在Flink 1.11版本之前，平台自建元数据管理系统为Flink SQL管理schema，1.11版本开始，通过hive metastore与公司元数据管理系统融合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;p&gt;&lt;span&gt;主要是支持实时大屏、推荐、实验平台、实时监控和实时数据清洗的一些场景。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;二、Flink容器化实践&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1、容器化方案&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5544973544973545&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTYDrO7rFuvlUAAAIaD8kWdhOHibaz3TQEuia3RoI13DoLcZSfYZTDR5gw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;945&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面是实时平台Flink容器化的架构图。Flink容器化其实是基于standalone模式部署的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的部署模式共有client、job manager、task manager三个角色，每一个角色都会有一个deployment来控制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用户通过平台上传任务jar包、配置等，存储于hdfs上。同时由平台维护的配置、依赖等也存储在hdfs上，当pod启动时，就会进行拉取等初始化操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; client中主进程是一个由go开发的agent，当client启动时，会首先检查集群状态，当集群准备好后，从hdfs上拉取jar包，再向这个集群提交任务，client的主要任务是做容错，它主要功能还有监控任务状态，做savepoint等操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过部署在每台物理机上的smart-agent采集容器的指标写入m3，以及通过Flink暴漏的接口将metrics写入prometheus，结合grafana展示。同样通过部署在每台物理机上的vfilebeat采集挂载出来的相关日志写入es，在dragonfly可以实现日志检索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1）Flink 平台化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;在实践过程中，一定要结合具体场景和易用性，再去考虑做平台化工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;140&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.24698133918770582&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUT4lZl57KAp23qIZyqvN9V40vgIaEnvMcoiaBGiaM69VHAvHLMeRcVgkIg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;911&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2）Flink稳定性&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;在我们应用部署以及运行过程中，异常肯定是不可避免的，这时候我们平台就需要做一些保证任务在出现异常状况后，保持稳定性的一些策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;p&gt;&lt;span&gt;是由livenessProbe和readinessProbe检&lt;/span&gt;&lt;span&gt;测的，同时指定pod的重启策略，Kubernetes本身是可以做一个pod的拉起。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt; Flink有自已本身的一套restart策略和failover机制，这是它第一层的保障。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在client中会定时监控Flink状态，同时将最新的checkpoint地址更新到自己的缓存中，并汇报到平台，固化到MySQL中。当Flink无法再重启时，由client重新从最新的成功checkpoint提交任务。这是它的第二层保障。这一层将checkpoint固化到MySQL中后，就不再使用Flink HA机制了，少了zk的组件依赖。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;当前两层无法重启时或集群出现异常时，由平台自动从固化到MySQL中的最新checkpoint重新拉起一个集群，提交任务，这是它的第三层保障。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2、Kafka监控方案&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;Kafka监控是我们的任务监控里非常重要的一个环节，整体的流程如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;310&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5456453305351522&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTyIAxYic4U5H6MYGVSWellN67aete8MYzpKHCiaeOI3QJNPpFKN3qkbgg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;953&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;平台提供监控Kafka 堆积，用户在界面上，可以配置自己的Kafka监控，告知在怎样的集群，以及用户消费message等配置信息，可以从MySQL中将用户Kafka监控配置提取后，再通过jmx监控Kafka，这样的信息采集之后，写入下游Kafka，再通过另一个Flink任务实时监控告警，同时将这些数据同步写入ck里面，从而反馈给我们的用户（这里也可以不用ck，也可以用Prometheus去做监控，都是可以的，但ck会更加适合），最后再用Grafana组件去展示给用户。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;三、Flink SQL平台化建设&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;有了前面Flink的容器化方案之后，那么就要开始Flink SQL平台化建设了。大家都知道，这样流失的api开发起来，还是有一定的成本的， Flink肯定是比Storm快的，也相对比较稳定、容易一些，但是对于一些用户，特别是Java开发的一些同学来说，做这个是有一定门槛的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kubernetes的Flink容器化实现以后，方便了Flink api 应用的发布，但是对于Flink SQL的任务仍然不够便利。于是平台提供了更加方便的在线编辑发布、SQL管理等一栈式开发平台。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1、 Flink SQL方案&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;305&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.53717277486911&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTlFKx7GOZhB9CicbDia1T8C9Fo43Oicn7xBDRsQm6Zw2iamLMpgfXPpUlgA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;955&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;平台的Flink SQL方案如上图所示，任务发布系统与元数据管理系统是完全解耦的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1）Flink SQL 任务发布平台化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在实践过程中，需要考虑易用性，做平台化工作，主操作界面如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我们看一个用户界面配置的一个例子：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;354&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6239316239316239&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTYXLcShmYqrlxxJaciaicMRIsp9KKUmy30F8p6XbL2TGkVic0pZhLVuEMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;702&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是集群配置的一个范例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;393&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6923076923076923&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTzm9RWsiaWuFmJ67PicymVsahcFKEujUC2Jf1j6gUYcTdYneZ3bfNpIug/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;702&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2）元数据管理&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;平台在1.11之前通过构建自己的元数据管理系统UDM，MySQL存储Kafka，Redis等schema，通过自定义catalog打通Flink与UDM，从而实现元数据管理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在1.11之后，Flink集成hive逐渐完善，平台重构了Flink SQL框架，并通过部署一个SQL-gateway service服务，中间调用自己维护的sql-client jar包，从而与离线元数据打通，实现了实时离线元数据的统一，为之后的流批一体打好了基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在元数据管理系统创建的Flink表操作界面如下图所示：创建Flink表的元数据，持久化到hive里，Flink SQL启动时从hive里读取对应表的table schema信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;312&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5487571701720841&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUT8JTicImmF1n0dowD1lpwZ4ibVaCiafWTvfWdicBltNushYHAmSeiau3T7AQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2、Flink SQL相关实践&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;平台对于官方原生支持或者不支持的connector进行整合和开发，镜像和connector，format等相关依赖进行解耦，可以快捷的进行更新与迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1）Flink SQL相关实践&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;Flink SQL主要分为以下三层：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持VDP connector读取source数据源；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持Redis string、hash等数据类型的sink&amp;amp;维表关联；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持kudu connector&amp;amp;catalog&amp;amp;维表关联；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持protobuf format解析实时清洗数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持vms connector读取source数据源；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;支持ClickHouse connector sink分布式表&amp;amp;本地表高TPS写入；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Hive connector支持数坊Watermark Commit Policy分区提交策略&amp;amp;array&amp;lt;string&amp;gt;、decimal等复杂数据类型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;主要支持拓扑图执行计划修改；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;维表关联keyBy优化cache提升查询性能；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;维表关联延迟join。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2）拓扑图执行计划修改&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对现阶段SQL生成的stream graph并行度无法修改等问题，平台提供可修改的拓扑预览修改相关参数。平台会将解析后的FlinkSQL的excution plan json提供给用户，利用uid保证算子的唯一性，修改每个算子的并行度，chain策略等，也为用户解决反压问题提供方法。例如针对ClickHouse sink 小并发大批次的场景，我们支持修改ClickHouse sink并行度，source并行度=72，sink 并行度=24，提高ClickHouse sink tps。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;307&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5401529636711281&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTX5Yg7JC4kFZAxVCLXTCvDlEjBhcBNicuWsqYkX4HkyAgT2uibjI9QgNA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3）维表关联keyBy优化cache&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对维表关联的情况，为了降低IO请求次数，降低维表数据库读压力，从而降低延迟，提高吞吐，有以下三种措施：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;298&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5255102040816326&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTzFicjY1picMTylXyzK0tHNDPUTYSqmf7TZz12ib4akflfVJPyQeTxy3ZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;980&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是维表关联KeyBy优化cache的图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;308&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5431034482758621&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTt3z00BvDh9rh1Cv6gKjfco1MdxvHr97UkZ6ZZm290heXTvVzWHewjA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1044&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;   &lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在优化之前的时候，维表关联LookupJoin算子和正常算子chain在一起，优化之间维表关联Lookup Join算子和正常算子不chain在一起，将join key 作为hash策略的key。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采用这种方式优化后，例如原来的3000W 数据量维表，10个TM节点，每个节点都要缓存3000W的数据，总共需要缓存3亿的量。而经过keyBy优化之后，每个TM节点只需要缓存3000W/10 =300W的数据量，总共缓存的数据量只有3000W，这非常大程度减少了缓存数据量。&lt;/span&gt;&lt;/p&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4）维表关联延迟join&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;维表关联中，有很多业务场景，在维表数据新增数据之前，主流数据已经发生join操作，会出现关联不上的情况。因此，为了保证数据的正确，将关联不上的数据进行缓存，进行延迟join。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最简单的做法是，在维表关联的function里设置重试次数和重试间隔，这个方法会增大整个流的延迟，但主流qps不高的情况下，可以解决问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;增加延迟join的算子，当join维表未关联时，先缓存起来，根据设置重试次数和重试间隔从而进行延迟的join。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;四、应用案例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1、实时数仓&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1）实时数据入仓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;308&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5422264875239923&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTdg2QF8aAZmZahsQZA2tx7lgU5FTPicahfQCJXNR3W4icTzFsO6gI3Reg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1042&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实时数仓主要分为三个过程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;流量数据一级Kafka进行实时数据清洗后，可以写到二级清洗Kafka，主要是protobuf格式，再通过Flink SQL写入hive 5min表，以便做后续的准实时ETL，加速ods层数据源的准备时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MySQL 业务库的数据，通过VDP解析形成binlog cdc消息流，再通过Flink SQL写入hive 5min表，同时会提交到自定义分区，再把分区状态汇报到服务接口，最后再做一个离线的调度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;业务系统通过VMS API产生业务Kafka消息流，通过Flink SQL解析之后写入hive 5min表。可以支持string、json、csv等消息格式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用 Flink SQL做流式数据入仓是非常方便的，而且 1.12 版本已经可以支持了小文件的自动合并，解决了小文件的问题，解决了大数据层一个非常普遍的痛点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们自定义分区提交策略，当前分区ready时候会调一下实时平台的分区提交api，在离线调度定时调度通过这个api检查分区是否ready。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采用Flink SQL统一入仓方案以后，我们可获得以下成果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2）实时指标计算&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;302&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5313092979127134&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTWaPLS9FYAiaSJZWpicpZtzsmCTQXq5icAWZ96k30cO065pXsmrue5yDsA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1054&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以往指标计算通常采用Storm方式，这个方式需要通过api定制化开发，采用这样Flink方案以后，我们可以获得了一下成果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-role=&quot;list&quot;/&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3）实时离线一体化ETL数据集成&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体的流程如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;305&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5374280230326296&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTtYibWteMWj01Yxp2pBcsAlOLdjI50GkCXziaANBBy9XQr2J6wzCeLZfw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1042&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Flink SQL 在最近的版本中持续强化了维表 join 的能力，不仅可以实时关联数据库中的维表数据，现在还能关联 Hive 和 Kafka 中的维表数据，能灵活满足不同工作负载和时效性的需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于 Flink 强大的流式 ETL 的能力，我们可以统一在实时层做数据接入和数据转换，然后将明细层的数据回流到离线数仓中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们通过将presto内部使用的HyperLogLog( 后面简称HLL) 实现引入到Spark UDAF函数里，打通HLL对象在Spark SQL与presto引擎之间的互通，如Spark SQL通过prepare函数生成的HLL对象，不仅可以在Spark SQL里merge查询而且可以在presto里进行merge查询。具体流程如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;202&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.35545023696682465&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTfyP9EJ7GUD2Ric7ay2iaxVENcn6nDibPktm4hGUicACXfxpfokVwibmTVvw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1055&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;UV近似计算示例: &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;464&quot; data-backw=&quot;456&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.0175438596491229&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTrtOicwiaLXKW5sSKVna8Vmk8btNdzeCTAvK6VL7KJ8oFqYY4kcdAiaazQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;456&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以基于实时离线一体化ETL数据集成的架构，我们可获得以下成果:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2、实验平台（Flink实时数据入OLAP）&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;唯品会实验平台是通过配置多维度分析和下钻分析，提供海量数据的A/B-test实验效果分析的一体化平台。一个实验是由一股流量（比如用户请求）和在这股流量上进行的相对对比实验的修改组成。实验平台对于海量数据查询有着低延迟、低响应、超大规模数据(百亿级)的需求。整体数据架构如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;307&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5401529636711281&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUT7G6FTicOEzlgMDDeh2wicmpo9FN05XKv3IX8fOEobHGibWNA6vZh4h2FQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;业务数据流如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;318&quot; data-backw=&quot;568&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.560377358490566&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ufWcjcomw8a1ab7OPvDZpHwgjeqpQAUTuTTrBSBvNBiaPVpqbYrhyq0MOXsRLZUGMLpnFhfqOZPfdb472xb4ROg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1060&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;业务数据流可以给大家简单介绍一下，我们的实验平台有一个很重要的ES场景，我们上线一个应用场景，我想看效果如何，上线产生的曝光、点击、加购、收藏是怎样的。我们需要把每一个数据的明细，比如说分流的一些数据，需要根据场景分区，写到ck里面去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们通过Flink SQL Redis connector，支持Redis的sink 、source维表关联等操作，可以很方便地读写Redis，实现维表关联，维表关联内可配置cache ，极大提高应用的TPS。通过Flink SQL 实现实时数据流的pipeline，最终将大宽表sink到CK 里，并按照某个字段粒度做murmurHash3_64 存储，保证相同用户的数据都存在同一shard 节点组内，从而使得ck大表之间的join 变成 local本地表之间的join，减少数据shuffle操作，提升join查询效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86122&quot; data-custom=&quot;#138bde&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;五、未来规划&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;1、提高Flink SQL易用性&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先我们会提高Flink的一个易用性，主要因为Flink SQL对于hive用户来说，使用起来还是有一点不一样的地方。不管是是hive，还是Spark SQL，都是批量处理的一个场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以当前我们的Flink SQL 调试起来仍有很多不方便的地方，对于做离线hive用户来说还有一定的使用门槛，例如手动配置Kafka监控、任务的压测调优，所以如何能让用户的使用门槛降至最低，让用户只需要懂SQL或者懂业务，把Flink SQL里面的概念对用户屏蔽掉，简化用户的使用流程，是一个比较大的挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将来我们考虑做一些智能监控，告诉用户当前任务存在的问题，不需要用户去学习太多的东西，尽可能自动化并给用户一些优化建议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;86152&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span data-bgopacity=&quot;40%&quot;/&gt; &lt;span data-bgopacity=&quot;25%&quot;/&gt; &lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;2、数据湖CDC分析方案落地&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一方面，我们做数据湖主要是为了解决我们binlog实时更新的场景，目前我们的VDP binlog消息流，通过Flink SQL写入到hive ods层，以加速ods层数据源的准备时间，但是会产生大量重复消息去重合并。我们会考虑Flink + 数据湖的cdc入仓方案来做增量入仓。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另一方面我们希望通过数据湖，来替代我们Kudu，我们这边一部分重要的业务在用Kudu，虽然Kudu没有大量的使用，但鉴于Kudu的运维比一般的数据库运维复杂得多、比较小众，并且像订单打宽之后的Kafka消息流、以及聚合结果都需要非常强的实时upsert能力，所以我们就开始调研CDC+数据湖这种解决方案，用这种方案的增量upsert能力来替换kudu增量upsert场景。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p data-brushtype=&quot;text&quot;&gt;&lt;span&gt;&lt;strong&gt;Q&amp;amp;A&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q1：vdp connector 是 MySQL binlog读取吗？和canal是一种工具吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A1 ：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;vdp是公司binlog同步的一个组件，将binlog解析之后发送到Kafka。是基于canal二次开发的。我们定义了一个cdc format可以对接公司的vdp Kafka数据源，与Canal CDC format有点类似。目前没有开源，使我们公司用的 binlog的一个同步方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q2 : uv数据输出到hbase，销售数据输出到kudu，输出到了不同的数据源，主要是因为什么采取的这种策略？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A2 ：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;kudu的应用场景没有hbase这么广泛。uv实时写入的TPS比较高，hbase比较适合单条查询的场景，写入hbase 高吞吐+低延迟，小范围查询延迟低；kudu的话具备一些OLAP的特性，可以存订单类明细，列存加速，结合Spark、presto等做OLAP分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q3 : 请问一下，你们怎么解决的ClickHouse的数据更新问题？比如数据指标更新。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A3 : &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;ck的更新是异步merge，只能在同一shard同一节点同一分区内异步merge，是弱一致性。对于指标更新场景不太建议使用ck。如果在ck里有更新强需求的场景，可以尝试 AggregatingMergeTree解决方案，用insert 替换update，做字段级的merge。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q4：binlog写入怎么保证数据的去重和一致性？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A4 : &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;binlog目前还没有写入ck的场景，这个方案看起来不太成熟。不建议这么做，可以用采用CDC + 数据湖的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q5 : 如果ck各个节点写入不均衡，怎么去监控，怎么解决？怎么样看数据倾斜呢？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A5 ：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;可以通过ck的system.parts本地表监控每台机器每个表每个分区的写入数据量以及size，来查看数据分区，从而定位到某个表某台机器某个分区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q6 : 你们存在实时平台是如何做任务监控或者健康检查的？又是如何在出错后自动恢复的？现在用的是yarn-application模式吗？存在一个yarn application对应多个Flink job的情况吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A6 : &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对于Flink 1.12+版本，支持了PrometheusReporter方式暴露一些Flink metrics指标，比如算子的watermark、checkpoint相关的指标如size、耗时、失败次数等关键指标，然后采集、存储起来做任务监控告警。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Flink原生的restart策略和failover机制，&lt;strong&gt;作为第一层的保证。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在client中会定时监控Flink状态，同时将最新的checkpoint地址更新到自己的缓存中，并汇报到平台，固化到MySQL中。当Flink无法再重启时，由client重新从最新的成功checkpoint提交任务。&lt;strong&gt;作为第二层保证。&lt;/strong&gt;这一层将checkpoint固化到MySQL中后，就不再使用Flink HA机制了，少了zk的组件依赖。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当前两层无法重启时或集群出现异常时，由平台自动从固化到MySQL中的最新chekcpoint重新拉起一个集群，提交任务，&lt;strong&gt;作为第三层保证。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们支持yarn-per-job模式，主要基于Flink on Kubernetes模式部署standalone集群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q7 : 目前你们大数据平台上所有的组件都是容器化的还是混合的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A7 ：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;目前我们实时这一块的组件Flink、Spark 、Storm、Presto等计算框架实现了容器化，详情可看上文1.2平台架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q8 :kudu不是在Kubernetes上跑的吧？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A8 ：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;kudu不是在Kubernetes上运行，这个目前还没有特别成熟的方案。并且kudu 是基于cloudera manager 运维的，没有上Kubernetes的必要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Q9 : Flink实时数仓维度表存到ck中，再去查询ck的话，这样方案可以吗？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;A9：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这是可以的，是可以值得尝试的。事实表与维度表数据都可以存，可以按照某个字段做哈希（比如user_id），从而实现local join的效果。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>97ef15b62e7bb34b05a16e20fdb12f84</guid>
<title>要将 RocketMQ 中台化，有点小激动</title>
<link>https://toutiao.io/k/wxygtif</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-tools=&quot;新媒体排版&quot; data-id=&quot;3529480&quot; data-style-type=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-tools=&quot;新媒体排版&quot; data-id=&quot;3356876&quot; data-style-type=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzIwMDY0Nzk2Mw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/WRLYshvT39ykfC4Jy6mnxuibX6vJOmVCNF49BAQXbX3dKVmHVjpF89LmQhvdd6GbaQAbwrKSeaMu3Q41SnmOpxA/0?wx_fmt=png&quot; data-nickname=&quot;猿天地&quot; data-alias=&quot;cxytiandi&quot; data-signature=&quot;猿天地由《Spring Cloud微服务-全栈技术与案例解析》, 《Spring Cloud微服务 入门 实战与进阶》作者尹吉欢创建。 资深Java技术专家和微服务技术专家，在Spring Cloud和微服务方面有丰富的经验。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tools=&quot;新媒体排版&quot; data-id=&quot;3335002&quot; data-style-type=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;span&gt;本文字数：&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;4223&lt;/strong&gt;&lt;/span&gt;字&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;预计阅读时间：&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;13&lt;/strong&gt;&lt;/span&gt;分钟&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一、RocketMQ简介&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;RocketMQ是一个高可用、高性能、高可靠的分布式消息队列，相对于kafka更适合处理业务系统之间的消息。&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;它具有很多特性，例如：&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;发布订阅&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;顺序、事务、定时消息&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;消息堆积、重试，回溯等等&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;它通过&lt;strong&gt;同步刷盘&lt;/strong&gt;和&lt;strong&gt;同步双写&lt;/strong&gt;等技术手段来实现高可靠，保证如下情况消息不丢：&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;可恢复性故障：broker或OS crash等&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;不可恢复性故障：磁盘损坏等&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;它采用多项技术优化来满足性能要求：&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;顺序IO&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;PageCache和mmap&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;内存预热和锁定&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;异步提交和刷盘&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;堆外内存缓冲等等&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;所以，它的本质决定的其架构一定是复杂的，参考RocketMQ官方架构图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.415158371040724&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzTPlvHG9a4687r8XBAvff8vwRfBSdM7Hr1liawGaHFIxz9hmlHlfzPnQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;884&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这里不再介绍各个组件的含义，可以参考RocketMQ架构设计。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;RocketMQ经过阿里多年双十一的检验，其稳定性不言而喻。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;可作为搜狐视频的消息中台，还需要很长一段路要走，为什么这么说呢？&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;二、运维之痛&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;早在2014年我们就引入了RocketMQ作为消息中间件，其附带了基本的命令行工具。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;但是命令行运维此等庞然大物会让人感到力不从心，好在社区提供了一个web控制台：RocketMQ-Console。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在初期，简单的控制台已经能满足基本的需求。但是随着各个业务逐渐接入，需求也纷至沓来。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们在RocketMQ-Console的修修补补已经无法满足了，主要体现在如下几点：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;从业务方的角度：&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;偏重运维，一般业务用户不关心集群的数据和状态，无法聚焦。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;使用起来繁琐，且直接操作集群，易误操作。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;没有监控预警功能。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;无法满足业务用户的需求，包括但不限于：&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;一些隐性问题无法解决。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;从管理员维度：&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;无用户概念，任何人都能直接操作集群，易误操作且比较危险。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;无集群管理功能，日常更新或机器替换需要手动部署，非常耗时、麻烦且易出错。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;无相关数据统计，监控，预警等，往往有问题不能及时发现。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;另外，RocketMQ有一些潜在约定、使用规范、最佳实践、bug或优化等等，用文档说明也无济于事。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;所以与其写文档不如将经验和实践转换为产品，能够更好的服务于业务及运维集群，于是MQCloud应运而生。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;三、MQCloud诞生&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;先看一下MQCloud的定位：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.8294930875576036&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzJFlGqCxk4nQ1cKeibhNibdFyG8wa51nu3m5qQPJE5Ac7K6ZocroiaiaIow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;434&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;它是集客户端SDK，监控预警，集群运维于一体的一站式服务平台。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;MQCloud的系统架构如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.5965417867435159&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHz2lib5kWiaGRYoU20pZ9GR609a6TmEpTNOBicP0By7zfKjjNib1R6mfjNyA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;694&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;下面来分别说明一下MQCloud如何解决上面提到的痛点。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;业务端和运维端分离，使业务用户只聚焦于业务数据。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了实现这个目的，引入了用户，资源两大维度。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;针对用户和资源加以控制，使不同的用户只聚焦于自己的数据。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4650145772594752&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzC6kfL8emhO1Q2bPd2PQK5YMIJIUInftribaIDYUyuJpFORdEMVz6woQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;686&quot;/&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;/&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;对于生产者来说，他关心的是topic配置，消息的发送数据，谁在消费等等问题，这样只对他展示相应的数据即可；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;对于消费者来说，只关心消费状况，有没有堆积，消费失败等情况；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;对于管理员来说，可以进行部署，监控，统一配置，审批等日常运维；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;清晰明了的操作&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;通过对不同角色展示不同的视图，使用户可以进行的操作一目了然。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;规范和安全&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了保障集群操作的安全性和规范性，所有的操作都会以申请单的形式进入后台审批系统，管理员来进行相关审批，安全性大大提升。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;多维的数据统计和监控预警&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;MQCloud核心功能之一就是&lt;strong&gt;监控&lt;/strong&gt;，要想做监控，必须先做统计，为了更好的知道RocketMQ集群的运行状况，MQCloud做了大量的统计工作，主要包括如下几项：&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;每分钟topic的生产流量：用于绘制topic生产流量图及监控预警。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;每分钟消费者流量：用于绘制消费流量图及监控预警。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;每10分钟topic生产流量：用于按照流量展示topic排序。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;每分钟broker生产、消费流量：用于绘制broker生产消费流量图。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;每分钟broker集群生产、消费流量：用于绘制broker集群的生产流量图。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;每分钟生产者百分位耗时、异常统计：以ip维度绘制每个生产者的耗时流量图及监控预警。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;机器的cpu，内存，io，网络流量，网络连接等统计：用于服务器的状况图和监控预警。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;下面来分别介绍每项统计是如何收集的：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;每分钟topic的生产流量&lt;/span&gt;&lt;span&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;此数据来自于RocketMQ broker端BrokerStatsManager，其提供了统计功能，统计项如下：&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;TOPIC_PUT_NUMS：某topic消息生产条数，向某个topic写入消息成功才算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;写入成功包括四种状态：PUT_OK，FLUSH_DISK_TIMEOUT，FLUSH_SLAVE_TIMEOUT，SLAVE_NOT_AVAILABLE&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;TOPIC_PUT_SIZE：某topic消息生产大小，向某个topic写入消息成功才算&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;RocketMQ实现的统计逻辑较为精巧，这里做简单描述，首先介绍几个对象：&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;StatsItemSet主要字段及方法如下：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;p&gt;&lt;span&gt;ConcurrentMap&amp;lt;String/* statsKey */, StatsItem&amp;gt; statsItemTable; // statsKey&amp;lt;-&amp;gt;StatsItem&lt;br/&gt;// 针对某个数据项进行记录&lt;br/&gt;public void addValue(final String statsKey, final int incValue, final int incTimes) {&lt;br/&gt;    StatsItem statsItem = this.getAndCreateStatsItem(statsKey);&lt;br/&gt;    statsItem.getValue().addAndGet(incValue);&lt;br/&gt;    statsItem.getTimes().addAndGet(incTimes);&lt;br/&gt;}&lt;br/&gt;// 获取并创建StatsItem&lt;br/&gt;public StatsItem getAndCreateStatsItem(final String statsKey) {&lt;br/&gt;    StatsItem statsItem = this.statsItemTable.get(statsKey);&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (null == statsItem) {&lt;br/&gt;        statsItem = new StatsItem(this.statsName, statsKey);&lt;br/&gt;        this.statsItemTable.put(statsKey, statsItem);&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; statsItem;&lt;br/&gt;}&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;StatsItem主要字段及方法如下：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;p&gt;&lt;span&gt;AtomicLong value; // 统计数据：比如消息条数，消息大小&lt;br/&gt;AtomicLong &lt;span&gt;times&lt;/span&gt;; // 次数&lt;br/&gt;LinkedList&amp;lt;CallSnapshot&amp;gt; csListMinute; // 每分钟快照数据&lt;br/&gt;LinkedList&amp;lt;CallSnapshot&amp;gt; csListHour; // 每小时快照数据&lt;br/&gt;LinkedList&amp;lt;CallSnapshot&amp;gt; csListDay; // 每天快照数据&lt;br/&gt;// 分钟采样&lt;br/&gt;public void &lt;span&gt;samplingInSeconds&lt;/span&gt;() {&lt;br/&gt;    synchronized (csListMinute) {&lt;br/&gt;        csListMinute.add(new CallSnapshot(System.currentTimeMillis(), times.get(), value.get()));&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (csListMinute.size() &amp;gt; 7) {&lt;br/&gt;            csListMinute.removeFirst();&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;// 小时采样&lt;br/&gt;public void &lt;span&gt;samplingInMinutes&lt;/span&gt;() {&lt;br/&gt;  // ...代码省略&lt;br/&gt;}&lt;br/&gt;// 天采样&lt;br/&gt;public void &lt;span&gt;samplingInHour&lt;/span&gt;() {&lt;br/&gt;  // ...代码省略&lt;br/&gt;}&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;CallSnapshot主要字段如下：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;p&gt;&lt;span&gt;long &lt;span&gt;times&lt;/span&gt;; // 次数快照&lt;br/&gt;long value; // 统计数据快照&lt;br/&gt;long timestamp; //快照时间戳&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;上面三个对象如何配合进行数据统计呢？举个例子，比如统计topic名字为test_topic的消息生产大小：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;只要进行类似如下调用即可：&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;p&gt;&lt;span&gt;StatsItemSet.addValue(&lt;span&gt;&quot;test_topic&quot;&lt;/span&gt;, 123125123, 1)&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;即表示发送了1次消息到test_topic，消息大小为123125123。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;那如何进行数据采样呢？StatsItemSet内置了定时任务，比如其每10秒调用一次StatsItem.samplingInSeconds()。这样StatsItem就会持有60秒的数据，类似如下结构：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.8214285714285714&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzKRIOibrLJDo0L1qNArl0KgnQcfZojMwb4fwFIP6qG4nlNZN7joqIyuA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;224&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;那么，最后一个10秒的快照 - 第一个10秒的快照 = 当前60秒的数据，根据时间戳差值可以得到耗时。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;类似，小时数据每10分钟进行一次快照，类似如下结构：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.8340807174887892&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHza5XeafpKbYK8mH17tOnMv9I2WQqfGOleEbDwI9KBwHUCkwa1m15Sjg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;223&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;天数据每1小时进行一次快照，类似如下结构：&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.88&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzzdT5MZQBR202tBZ3IoIJteFPo7ibGfiaeSrDH4d5eYgzwbzicNFicOXcIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;225&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;MQCloud每分钟遍历查询集群下所有broker来查询RocketMQ统计好的分钟数据，然后进行存储。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;每分钟消费者流量&lt;/span&gt;&lt;span&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;与每分钟topic的生产流量一样，也采用RocketMQ统计好的数据。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;每10分钟topic生产流量&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;采用数据库已经统计好的每分钟topic流量进行累加，统计出10分钟流量。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;每分钟broker生产、消费流量&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;由于统计1.每分钟topic的生产流量和2.每分钟消费者流量时是跟broker交互获取的，所以知道broker ip，故直接按照broker维度存储一份数据即可。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;每分钟broker集群生产、消费流量&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;采用4.每分钟broker生产、消费流量数据，按照集群求和即可。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;每分钟生产者百分位耗时、异常统计&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;由于RocketMQ并没有提供生产者的流量统计（&lt;em&gt;只提供了topic，但是并不知道每个生产者的情况&lt;/em&gt;），所以MQCloud实现了对生产者数据进行统计（&lt;em&gt;通过RocketMQ的回调钩子实现&lt;/em&gt;）:&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.5135135135135135&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzUQGQOffrRmSxvz3a0CibTRph80dg4Rz6J7TjVuBrRY3l9h4HD95DuFw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;370&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;主要统计如下信息：&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端ip-&amp;gt;broker ip&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;发送消息耗时&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;消息数量&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;发送异常&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;统计完成后，定时发送到MQCloud进行存储，并做实时监控和展示。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;关于统计部分有一点说明，一般耗时统计有最大，最小和平均值，而通常99%(即99%的请求耗时都低于此数值)的请求的耗时情况才能反映真实响应情况。99%请求耗时统计最大的问题是如何控制内存占用，因为需要对某段时间内所有的耗时做排序后才能统计出这段时间的99%的耗时状况。而对于流式数据做这样的统计是有一些算法和数据结构的，例如t-digest，但是MQCloud采用了非精确的但是较为简单的分段统计的方法，具体如下：&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;创建一个按照最大耗时预哈希的时间跨度不同的&lt;strong&gt;耗时分段数组&lt;/strong&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;优点：此种分段方法占用内存是固定的，比如最大耗时如果为3500ms，那么只需要空间大小为96的数组即可&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;缺点：分段精度需要提前设定好，且不可更改&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;第一段：耗时范围0ms~10ms，时间跨度为1ms。&lt;/span&gt;&lt;/p&gt;&lt;figure/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.3888888888888889&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzZcatctS2UfVONfOOEfUf797wnDcEiaVLjds8Rh9WxsAZ6xXPvNFhaiaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;288&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;第二组：耗时范围11ms~100ms，时间跨度5ms。&lt;/span&gt;&lt;/p&gt;&lt;figure/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.1958762886597938&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzR2yvhwWUW16ZpS9S5icMM4RKM8yNnIia95u1eoR51YnBwW7027tsYeDg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;582&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;第三组：耗时范围101ms~3500ms，时间跨度50ms。&lt;/span&gt;&lt;/p&gt;&lt;figure/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.19420783645655879&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzhHyAA22ZQp7XvSyMa084hrsYt4QdjXpiaMDG9962mot1HFSkvlicXxmg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;587&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;优点：此种分段方法占用内存是固定的，比如最大耗时如果为3500ms，那么只需要空间大小为96的数组即可&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;缺点：分段精度需要提前设定好，且不可更&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;针对上面的分段数组，创建一个大小对应的AtomicLong的&lt;strong&gt;计数数组&lt;/strong&gt;，支持并发统计：&lt;/span&gt;&lt;/p&gt;&lt;figure/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.1035031847133758&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzl9OjoRB8w3YrqzEMUC6ZxBQVCvcdRYVWVo0kfFaJu37WDflvqHZE9Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;628&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;耗时统计时，计算耗时对应的&lt;strong&gt;耗时分段数组&lt;/strong&gt;下标，然后调用&lt;strong&gt;计数数组&lt;/strong&gt;进行统计即可，参考下图：&lt;/span&gt;&lt;/p&gt;&lt;figure/&gt;&lt;p&gt;&lt;span&gt;这样，从&lt;strong&gt;计数数组&lt;/strong&gt;就可以得到实时耗时统计，类似如下：&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.47393364928909953&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzOehickUaVOONbZwAicVNUQibxfqo9gwnCMRvJswPIJWfdkjxCQxibaibzfQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;633&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;例如某次耗时为18ms，首先找到它所属的区间，即归属于[16~20]ms之间，对应的数组下标为12。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;根据第一步找到的数组下标12，获取对应的计数数组下标12。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;获取对应的计数器进行+1操作，即表示18ms发生了一次调用。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;这样，从&lt;strong&gt;计数数组&lt;/strong&gt;就可以得到实时耗时统计，类似如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.22869955156950672&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzRvSS8OscNM7zQ5ZW4piciavazNhmP2APqEBaUmw1jicSia5ToxqicNibO1Kg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;669&quot;/&gt;&lt;/p&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;然后定时采样任务会每分钟对&lt;strong&gt;计数数组&lt;/strong&gt;进行快照，产生如下&lt;strong&gt;耗时数据&lt;/strong&gt;：&lt;/span&gt;&lt;/p&gt;&lt;figure/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.15970149253731344&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0SJow0NBbJD1dCJibMdeGHzLfbnGbKAmfMlDaNwmiayz8SVfbqNtb5OicN9icYY3lhKHkEodia7v2AWzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;670&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;由于上面的&lt;strong&gt;耗时数据&lt;/strong&gt;天然就是排好序的，可以很容易计算99%、90%、平均耗时等数据了。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;另外提一点，由于RocketMQ 4.4.0新增的trace功能也使用hook来实现，与MQCloud的统计有冲突，MQCloud已经做了兼容。&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;em&gt;Trace和统计是两种维度，trace反映的是消息从生产-&amp;gt;存储-&amp;gt;消费的流程，而MQCloud做的是针对生产者状况的统计，有了这些统计数据，才可以做到生产耗时情况展示，生产异常情况预警等功能。&lt;/em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;机器统计&lt;/span&gt;&lt;span&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于集群状况收集主要采用了将nmon自动放置到/tmp目录，定时采用ssh连接到机器执行nmon命令，解析返回的数据，然后进行存储。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面这些工作就为监控和预警奠定了坚实的数据基础。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;单独定制的客户端&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.7945205479452054&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0ciasIFmiba0qb9GMVqy7UJjbqd2KYtPpWAOeZdeExszsCe7EqkTRMH3TvToplbTuAwFxJoT3oyXxQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;365&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;针对客户端的一些需求，mq-client在rocketmq-client的基础上进行了开发定制：&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;多集群支持&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MQCloud储存了生产者、消费者和集群的关系，通过路由适配，客户端可以自动路由到目标集群上，使客户端对多集群透明。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;trace&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过搭建单独的trace集群和定制客户端，使trace数据能够发往独立的集群，防止影响主集群。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;序列化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过集成不同的序列化机制，配合MQCloud，客户端无需关心序列化问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前支持的序列化为protobuf和json，并且通过类型检测支持在线修改序列化方式。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;流控&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过提供令牌桶和漏桶限流机制，自动开启流控机制，防止消息洪峰冲垮业务端。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;隔离降级&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用hystrix提供隔离降级策略，使业务端在broker故障时可以避免拖累。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;埋点监控&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过对客户端数据进行统计，收集，在MQCloud里进行监控，使客户端任何风吹草动都能及时得知。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;规范问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过编码保障，使某些约定，规范和最佳实践得以实现。包括但不限于：&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;命名规范&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;消费组全局唯一，防止重复导致消费问题&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;重试消息跳过&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;安全关闭等等&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;更完善的重试机制&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;自动化运维&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;部署&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;手动部署一台broker实例没什么问题，但是当实例变多时，手动部署极易出错且耗时耗力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MQCloud提供了一套自动化部署机制，并支持配置模板功能，支持一键部署。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;机器运维&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MQCloud提供了一整套机器的运维机制，包括上下线，机器状况收集、监控、预警等等，大大提升了生产力。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;安全性加固&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;一、开启管理员权限&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RocketMQ从4.4.0开始支持ACL，但是默认没有开启，也就是&lt;strong&gt;任何人使用管理工具或API就可以直接操纵线上集群&lt;/strong&gt;。但是开启ACL对现有业务影响太大，针对这种情况MQCloud进行专门定制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;借鉴RocketMQ ACL机制，只针对RocketMQ管理员操作加固权限校验：&lt;/span&gt;&lt;/p&gt;&lt;figure/&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;2.4474885844748857&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qMicvibdvl7p0ciasIFmiba0qb9GMVqy7UJjC9CzOuQMEu46jn26NgMCaptAEmmZzcgqaG3Dn5k3UW2j19mth7MgCw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;219&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并且支持自定义和热加载管理员请求码，使得非法操作RocketMQ集群成为不可能，安全性大大提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;二、broker通信加固&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;broker同步数据代码由于没有校验，存在安全隐患，只要连接master监听的slave通信端口，发送数据大于8个字节，就可能导致同步偏移量错误，代码如下：&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;if&lt;/span&gt; ((this.byteBufferRead.position() - this.processPostion) &amp;gt;= 8) {&lt;br/&gt;  int pos = this.byteBufferRead.position() - (this.byteBufferRead.position() % 8);&lt;br/&gt;  long readOffset = this.byteBufferRead.getLong(pos - 8);&lt;br/&gt;  this.processPostion = pos;&lt;br/&gt;  HAConnection.this.slaveAckOffset = readOffset;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (HAConnection.this.slaveRequestOffset &amp;lt; 0) {&lt;br/&gt;      HAConnection.this.slaveRequestOffset = readOffset;&lt;br/&gt;      log.info(&lt;span&gt;&quot;slave[&quot;&lt;/span&gt; + HAConnection.this.clientAddr + &lt;span&gt;&quot;] request offset &quot;&lt;/span&gt; + readOffset);&lt;br/&gt;  }&lt;br/&gt;  HAConnection.this.haService.notifyTransferSome(HAConnection.this.slaveAckOffset);&lt;br/&gt;}&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;MQCloud通过验证数据首包的策略，保障了通信的安全性。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;目前MQCloud运维规模如下：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;服务器：50台+&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;集群：5个+&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;topic：700个+&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;生产消费消息量/日：4亿条+&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;生产消费消息大小/日：400G+&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;MQCloud在充分考虑和吸收实际业务的需求后，以各个角色聚焦为核心，以全面监控为目标，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以满足各业务端需求为己任，在不断地发展和完善。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在MQCloud逐渐成熟之后，秉承着服务于社区和吸收更多经验的理念，我们开放了源代码。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;四、开源之路&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;开放源代码说不难也不难，说难也难。为什么这么说？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;不难就是因为代码已经有了，只是换个仓库而已。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;而难点就是需要进行抽象设计，剥离不能开源的代码（内部模块，代码，地址等等）。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;经过设计和拆分，MQCloud于18年开源了，从第一个版本release到现在已经过去两年了，&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;期间随着更新迭代大大小小一共release了20多个版本。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;其中不但包含功能更新、bug修复、wiki说明等，而且每个大版本都经过详细的测试和内部的运行。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;之后很多小伙伴跃跃欲试，来试用它，并提出一些建议和意见，我们根据反馈来进一步完善它。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们将一直遵循我们的目标，坚定的走自己的开源之路：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;为业务提供可监控，可预警，可满足其各种需求的稳定的MQ服务。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;积累MQ领域经验，将经验转化为产品，更好的服务业务。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;pre&gt;&lt;p&gt;&lt;span&gt;后台回复 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;学习资料&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;领取学习视频&lt;/span&gt;&lt;/p&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section data-mpa-template-id=&quot;112&quot; data-mpa-category=&quot;quote&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.511002444987775&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WRLYshvT39zWmaics1nAAwT4NCD77uDcf6vcXE1DAHybibTY0V3XDmf4YX1q9qYibIwz9xmRVTkEvTjP87gaKEZrQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;818&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如有收获，点个在看，诚挚感谢&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e2586e331331cbe96dd5c877e0c4d200</guid>
<title>多年老 C++ 程序员在静态数组这里翻船了</title>
<link>https://toutiao.io/k/xrkhat1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzg5ODI2MTEwNg==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/RNfZGZNpL1ApdamSCLJUhObeTmib5J7icNXWMw4fdEgv9HqGu5kc787JKMyVEJB65TFNO7l5b1UTKeMZHnao2T8A/0?wx_fmt=png&quot; data-nickname=&quot;cpp加油站&quot; data-alias=&quot;xy13640954449&quot; data-signature=&quot;专注分享linux下c/c++开发经验，做有质量和温度的公众号&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;h4&gt;&lt;span&gt;事情的起因&lt;/span&gt;&lt;br/&gt;&lt;/h4&gt;&lt;p&gt;事情是这样子滴，有一次我在代码评审的时候，发现有同事想使用运行时才能够获取到的值，去改变一个静态数组的元素个数，我当时就很诧异，因为我心里知道这样是不可行的，静态数组的元素个数在编译时就需要是固定不变的，一般只能是常量或者宏定义，否则编译就不能通过。&lt;/p&gt;&lt;p&gt;但是当时我提出来以后，把原因说了，包括写出这个代码的人和另外一位同事都没理解，弄得我有点怀疑自己了，难道是我搞错了？&lt;/p&gt;&lt;p&gt;我左思右想，最后我写了下面的代码来证实一下：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;using&lt;/span&gt; &lt;span&gt;namespace&lt;/span&gt; &lt;span&gt;std&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;get&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;int&lt;/span&gt; size = &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;&quot;please input a num:&quot;&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;cin&lt;/span&gt; &amp;gt;&amp;gt; size;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; size;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;int&lt;/span&gt; size = &lt;span&gt;1000&lt;/span&gt;;&lt;br/&gt;    size = get();&lt;br/&gt;    &lt;span&gt;int&lt;/span&gt; arr[size] = {&lt;span&gt;0&lt;/span&gt;};&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;&quot;arr&#x27;s size is &quot;&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;sizeof&lt;/span&gt;(arr)/&lt;span&gt;sizeof&lt;/span&gt;(arr[&lt;span&gt;0&lt;/span&gt;]) &amp;lt;&amp;lt; &lt;span&gt;endl&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我打心底认为，这段程序肯定是编译不通过的，但是结果打脸了。编译后执行显示如下：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;please&lt;/span&gt; input a num:&lt;span&gt;10000&lt;/span&gt;&lt;br/&gt;arr&lt;span&gt;&#x27;s size is 10000&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;不仅编译通过了，而且数组大小还在运行时修改了，可是我明明定义的是一个静态数组呀，而且就算我这里不给size赋初始值1000，结果也还是一样的。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;探索的过程&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;简直是见了鬼了，我把代码看了又看，认为是我代码写错了，但是这么简单的一段代码，我不可能写错呀。后来我突然想到，会不会是有了新的语法？&lt;/p&gt;&lt;p&gt;因为我现在的gcc编译器，大家都知道是7.1.0的版本，基本上连c++17都能支持了，我就试了一下之前保留的gcc4.1.2的版本，结果报错啦，如下：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;test.cpp: In function ‘int main()’:&lt;br/&gt;test.cpp:15: 错误：可变大小的对象 ‘arr’ 不能被初始化&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;所以很显然，我的记忆没有错误，之前静态数组的元素个数它就必须是个不可变的，否则编译就会出错。&lt;/p&gt;&lt;p&gt;然后我又看了下生产上用的编译器，是gcc4.8.5的版本，它也是支持c++11的，难道这个新的特性是c++11支持的吗？然后我去cppreference把c++11的新特性从头到尾翻了一遍，并没有对这个修改有说明，并且网上搜索，所有的文章都在说c和c++想使用变长数组，就必须要使用动态数组，我一度陷入了僵局，但是我并没有死心，继续探索。&lt;/p&gt;&lt;p&gt;后来我忽然想到，假如不是c++的新特性，那是不是c语言的新特性呢，想到这里，我把代码做了如下修改：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;get&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;int&lt;/span&gt; size = &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;printf&lt;/span&gt;(&lt;span&gt;&quot;please input a num:&quot;&lt;/span&gt;);&lt;br/&gt;    &lt;span&gt;scanf&lt;/span&gt;(&lt;span&gt;&quot;%d&quot;&lt;/span&gt;, &amp;amp;size);&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; size;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;int&lt;/span&gt; size = &lt;span&gt;1000&lt;/span&gt;;&lt;br/&gt;    size = get();&lt;br/&gt;    &lt;span&gt;int&lt;/span&gt; arr[size] = {&lt;span&gt;0&lt;/span&gt;};&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;printf&lt;/span&gt;(&lt;span&gt;&quot;arr&#x27;s size is %d\n&quot;&lt;/span&gt;, &lt;span&gt;sizeof&lt;/span&gt;(arr)/&lt;span&gt;sizeof&lt;/span&gt;(arr[&lt;span&gt;0&lt;/span&gt;]));&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后直接使用gcc命令编译，而没有使用g++，结果跟上面那段代码是一模一样的，到这里我大致上就明白了，这就是c语言里面的新特性。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;欣喜的找到了结果&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;最后我在cppreference这个链接里面看到了对于c99的说明：&lt;/p&gt;&lt;blockquote&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;新特性：&lt;em&gt;Bool 、 long long 、 stdint.h 、 inttypes.h 、 restrict 、复合字面量、&lt;strong&gt;变长度数组&lt;/strong&gt;、伸缩数组成员、指派初始化器、 fenv.h 、变参数宏、复数、 &lt;strong&gt;func&lt;/strong&gt; 、十六进制浮点格式（ %a ）、 lconv 的货币格式化、 isblank 、窄与宽字符串字面量的连接、枚举的尾逗号、类函数宏的空参数、 STDC&lt;/em&gt;* pragma 、 va_copy 、 tmpnam 的空返回、 setvbuf 中的空指针、 printf 的 hh 与 ll 长度指定符、 snprintf 、 _Exit 、 tgmath.h 、仿 POSIX strftime 说明符&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;来自 C++ ：inline 、声明与代码混合、 for 循环的 init 子句中的声明、 &lt;code&gt;&lt;strong&gt;//&lt;/strong&gt;&lt;/code&gt; 注释、源代码中的通用字符名&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;移除隐式函数声明和隐式 int&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;p&gt;看看，是不是明确说明了新特性是变长度数组，并且是c语言99年的标准，有点灯下黑了，以后如果再看到有人说c语言和c++的静态数组都只支持固定长度，要想变长就必须要使用malloc和new，就可以唾弃一下啦。&lt;/p&gt;&lt;p&gt;另外有一点需要注意的是，如果我们的场景真的是需要使用固定大小的数组，那么最好使用常量和宏定义，再不然，就使用c++11里面新增加的array。&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzg5ODI2MTEwNg==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/RNfZGZNpL1ApdamSCLJUhObeTmib5J7icNXWMw4fdEgv9HqGu5kc787JKMyVEJB65TFNO7l5b1UTKeMZHnao2T8A/0?wx_fmt=png&quot; data-nickname=&quot;cpp加油站&quot; data-alias=&quot;xy13640954449&quot; data-signature=&quot;专注分享linux下c/c++开发经验，做有质量和温度的公众号&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;好了，有关我和静态数组的故事就介绍到这里了，因为没有留言功能，如果有问题需要咨询的，可以通过公众号菜单【联系作者】获取作者联系方式进行咨询哈。&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>f0a7902417f53f109740723f92409604</guid>
<title>Go 凭什么不支持三元运算符？</title>
<link>https://toutiao.io/k/pt0q5vx</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，我是煎鱼。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是一个很多其他语言工程师转 Go 语言的时间节点，这就难免不论一番比较。其中一个经典的运算上的就是 “三元运算符”：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4231578947368421&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KVl0giak5ib4iaLoqX7Cp17TQxQoFTpy8O00pcccIsAX9egvSvp65icA1gKpNLsYsT6z7ic7JjEWm5Uvib9gnEux4YFA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;950&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么 Go 语言不支持三元运算符，Go 不支持三元运算符就是设计的不好，是历史在开倒车吗？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天就由煎鱼来和大家一起摸索为什么。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;三元运算符是什么&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;三元运算符，在典型的数学意义上，或者从解析器的角度来看，是一个需要三个参数的运算符。而我们日常中，最常见的是二元运算符：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;x + y&lt;br/&gt;x / y&lt;br/&gt;x * y&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有一元运算符：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;-a&lt;br/&gt;~b&lt;br/&gt;!c&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以及今天的男主角 “三元运算符”。在 C/C++ 等多种语言中，我们可以根据条件声明和初始化变量的习惯来选择性使用三元条件运算符：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;int&lt;/span&gt; index = val &amp;gt; &lt;span&gt;0&lt;/span&gt; ? val : -val&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Go 使用三元运算符&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;想在 Go 语言里也使用三元运算符时，发现居然没有...想要实现与上面相同的代码段的方式似乎只能：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;var&lt;/span&gt; index &lt;span&gt;int&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;if&lt;/span&gt; val &amp;gt; &lt;span&gt;0&lt;/span&gt; {&lt;br/&gt;    index = val&lt;br/&gt;} &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;    index = -val&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看上去十分的冗余，不够简洁。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;为什么 Go 没有三元运算符&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么 Go 没有 &lt;code&gt;?:&lt;/code&gt; 操作符，没有的话，官方推荐的方式是怎么样的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过 Go FAQ 我们可以得知：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3413566739606127&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KVl0giak5ib4iaLoqX7Cp17TQxQoFTpy8O0gNQ6eO8iawGYcficfzEIfMTZeYexzAxicr0lSxTmx2dapOKjS0iashcmiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1828&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go 官方就是推荐我们使用前面提到的方式来替代，并且明确了如下态度：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Go 中没有 &lt;code&gt;?:&lt;/code&gt; 的原因是语言的设计者看到这个操作经常被用来创建难以理解的复杂表达式。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在替代方案上，if-else 形式虽然较长，但无疑是更清晰的。一门语言只需要一个条件控制流结构。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整体来讲，Go 语言的设计者是为了考虑&lt;strong&gt;可读性&lt;/strong&gt;拒绝了实现三元运算符，&quot;less is more.&quot; 也是标榜台词了。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;社区争议&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Go 语言的一些点与众不同，基本是大家皆知的。无论是 if err != nil，又或是本次的三元运算符，要大家用 if-else 替代：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;if&lt;/span&gt; expr {&lt;br/&gt;    n = trueVal&lt;br/&gt;} &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;    n = falseVal&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;反对和同意&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;反对&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此有社区小伙伴给出了反对，基本分为如下几类：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;认为 if-else 也有以类似情况能被滥用，设计者的理由不够充分，认为是 “借口”。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;认为三元运算符的 “丑陋” 问题，是开发者的编码问题，而不是语言问题。三元在各种语言中很常见，它们是正常的，Go 语言也应该要有。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;认为用 if-else 替代三元运算符也很麻烦，让开发者多读了 3-4 行和额外的缩进级别。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;同意&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;认可这个决策的也有不少，为此给出了大量的真实工程案例。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般来讲，我们用三元运算符是希望这么用：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;cond ? true_value : false_value&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你可能见过这么用：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;cond ? value_a + value_b : value_c * value_d&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还见过这样：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;(((cond_a ? val_one) : cond_b) ? val_two) : val_three&lt;br/&gt;&lt;br/&gt;cond_a ? (val_one : (cond_b ? (val_two : val_three)))&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还能嵌套三元运算符：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;int a = cond_a ? val_one :&lt;br/&gt;    cond_b ? val_two :&lt;br/&gt;    cond_c ? val_three : val_four;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也能出现可读性更差的：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;void rgb_to_lightness_(&lt;br/&gt;  const double re, const double gr, const double bl, double &amp;amp;li)&lt;br/&gt;{&lt;br/&gt;  li=((re &amp;lt; gr) ? ((gr &amp;lt; bl) ? bl : gr) : ((re &amp;lt; bl) ? bl : re) +&lt;br/&gt;                            (gr &amp;lt; re)&lt;br/&gt;                          ? ((bl &amp;lt; gr) ? bl : gr)&lt;br/&gt;                          : ((bl &amp;lt; re) ? bl : re)) / 2.0;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说白了就是真实的代码工程中，大家见到过大量三元运算符滥用的场景，纷纷给出了大量的难理解的例子，让大家困扰不堪。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这篇文章中，首先针对 “三元运算符” 做了基本的介绍。紧接着根据 Go 语言不支持三元的态度进行了说明，且面向社区的争议我们分为了正反方面的基本诠释。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实际上一个简单的 &lt;code&gt;?:&lt;/code&gt; 既整洁又实用，但是没有很好又高效的办法方法可以防止丑陋的嵌套，也就是排除可读性的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在真实的业务工程中，常常能看到一个三元运算符，&lt;strong&gt;一开始只是很简单。后面嵌套越加越深，逻辑越写越复杂，从而带来了许多维护上的问题&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;给大家抛出如下问题：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;你认为 Go 语言是否要有三元运算符呢？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果要有，复杂嵌套的三元运算符又如何考虑呢？&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;欢迎大家在评论区留言和交流 ：）&lt;/strong&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;参考&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;What is the idiomatic Go equivalent of C&#x27;s ternary operator?&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;What is the reasoning behind Go not having a ternary conditional operator?&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Should Go have a Ternary Operator? Or was it left out intentionally?&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;We don&#x27;t need a ternary operator&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzUxMDI4MDc1NA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/KVl0giak5ib4iac2xQZIq5icSiaTepuae8zLIUMiaxibbUM8ic735ewo6e89GRtjGbUBlgNYibwCjAicglQcvz6dCQ6yTKOw/0?wx_fmt=png&quot; data-nickname=&quot;脑子进煎鱼了&quot; data-alias=&quot;eddycjy&quot; data-signature=&quot;分享计算机基础、Go 语言、微服务架构和系统设计；著有图书《Go 语言编程之旅》。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;关注煎鱼，吸取他的知识 👆&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img data-ratio=&quot;0.07106598984771574&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/486RHs1WbcgGib6o96dHbvGUGGwPicd8wusUGH1cXR29tM4bO0lNzialzkQhvU6m5ZUdaKibmcF2OQayjMe9Bia6iaXQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;394&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;你好，我是煎鱼。高一折腾过前端，参加过国赛拿了奖，大学搞过 PHP。现在整 Go，在公司负责微服务架构等相关工作推进和研发。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;从大学开始靠自己赚生活费和学费，到出版 Go 畅销书《Go 语言编程之旅》，再到获得 GOP（Go 领域最有观点专家）荣誉，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUxMDI4MDc1NA==&amp;amp;mid=2247483854&amp;amp;idx=1&amp;amp;sn=ec422fbf4d846975f2930ddeb5e81373&amp;amp;chksm=f9041493ce739d85a4b987eece14da627206cdad798f645cc770868312e4a22b6df24804f186&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;点击蓝字查看我的出书之路&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;点击蓝字查看我的出书之路&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;日常分享高质量文章，输出 Go 面试、工作经验、架构设计，&lt;span&gt;加微信拉读者交流群，记得点赞！&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>