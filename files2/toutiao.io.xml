<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>634c528ea186c919777566cc0b133cb8</guid>
<title>再来一篇！看 JDK 源码大师亲自操刀编写的集合源码</title>
<link>https://toutiao.io/k/n0jv6j3</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;blockquote&gt;
&lt;p&gt;本文首发于公众号【看点代码再上班】，欢迎围观，第一时间获取最新文章。&lt;/p&gt;

&lt;p&gt;全文共计1959字18图，预计阅读时间13分钟&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;大家好，我是tin，这是我的第8篇原创文章&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/945096f3d1114e69bd3cf3fc4070466a%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;iShot2021-03-06 16.00.36.png&quot;/&gt;​&lt;/p&gt;

&lt;p&gt;[](&amp;lt;&amp;gt; &quot;点击并拖拽以移动&quot;)&lt;/p&gt;

&lt;p&gt;这个图拍摄于老家县城一售楼处。作为外出上班的一族，一年365天在家的时间常常不超过十天。&lt;/p&gt;

&lt;p&gt;在侃技术前，聊一聊自己对&lt;strong&gt;家乡变化&lt;/strong&gt;的感慨。&lt;/p&gt;

&lt;p&gt;最大的感慨莫过于，我们县城要通高铁了，以后老家和工作之地的距离将变成2小时！想想就觉得这是一件多么幸福的事。&lt;/p&gt;

&lt;p&gt;今年过年回家趁着假期和家人又新购置了一套新商品期房，就买高铁站片区边上。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/576011ee1a234cc8a7e2092f3e2685a4%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;iShot2021-03-06 16.54.41.png&quot;/&gt;​&lt;/p&gt;

&lt;p&gt;[](&amp;lt;&amp;gt; &quot;点击并拖拽以移动&quot;)&lt;/p&gt;

&lt;p&gt;在家买房的最大特点就是，房子面积要大的，动不动都一百多两百平，在深圳这个地方就不敢想啦。&lt;/p&gt;

&lt;p&gt;房子本来最早于2019年已打算购置，但当时时间仓促没看好，加之2020年过年刚好遇上疫情，足不出户，一耽搁就到了2021年。&lt;/p&gt;

&lt;p&gt;或许刚好是疫情的原因，今年房价特价销售（也就是降价了），相对2019年降了500-1000元/㎡。在这种七八线城市，房价本就几千块一平，这个降价幅度是异常高的（打心里认为，2021年是小城购房最佳时机之一）。&lt;/p&gt;

&lt;p&gt;其实，这里唠嗑只是想感慨一下小城市的变化之大！但是我们很多人却容易忽略身边最亲近的事与物。比如我，我竟然不知我们县城的政务中心都搬迁了，整个县城南片区规划建设已相当完善，商品房、幼儿园、中小学校区、超宽大道等等随处可见，新医院、新行政办公楼、高铁站等这些似乎在缩小与大城市的差距。&lt;/p&gt;

&lt;p&gt;这些年，国家对农村建设力度也很大，肉眼可见的变化常常被我们谈及。普遍被提到的一个变化是路变好了。村村通公路、水泥路，每年外出回家的人一定能感受到。路变好，相应的是，车也就多了。买车的人越来越多，每家都会有一辆代步小轿车。&lt;/p&gt;

&lt;p&gt;除了车，家里爸爸妈妈们网上购物更加频繁，比起以往，老人们都可以自行网上购物，自行取快递，这种线上体验的场景规模越来越空大，所以，农村通宽带也已不是什么新鲜事。&lt;/p&gt;

&lt;p&gt;朋友们，你们觉得呢，你们家乡还有哪些变化？&lt;/p&gt;

&lt;h1&gt;&lt;strong&gt;ConcurrentHashMap&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;我们打开ConcurrentHashMap源码，类开头鲜明地标着作者： &lt;em&gt;@author Doug Lea&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/98328a2460384adabaf3e8ed75b09457%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;image.png&quot;/&gt;​&lt;/p&gt;

&lt;p&gt;[](&amp;lt;&amp;gt; &quot;点击并拖拽以移动&quot;)&lt;/p&gt;

&lt;p&gt;Doug Lea是谁？以前也有提到过，他是一位大学老师，同时也是世界上对Java影响最大的人之一。JDK源码中java.util.concurrent 包就是他创作的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5297d80a7a894a9c9ab148c174d19597%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;image.png&quot;/&gt;​&lt;/p&gt;

&lt;p&gt;[](&amp;lt;&amp;gt; &quot;点击并拖拽以移动&quot;)&lt;/p&gt;

&lt;p&gt;我们找到jdk1.7的源码，ConcurrentHashMap中的get方法还能看到Doug Lea的代码（下图源码截图基于jdk7-b147）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d7fbbd25af7f4dbeb351c3765088abaa%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;image.png&quot;/&gt;​&lt;/p&gt;

&lt;p&gt;[](&amp;lt;&amp;gt; &quot;点击并拖拽以移动&quot;)&lt;/p&gt;

&lt;p&gt;我们知道，HashMap 是线程不安全的，并发情况下使用hashmap有cpu飙升的风险。为了使用线程安全的 HashMap，我们常使用 ConcurrentHashMap。&lt;/p&gt;

&lt;p&gt;本文基于jdk1.7讲解，所以concurrenthashmap还是采用分段锁。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/721fafbc7ebc46d3baa0472dddefcbfe%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;image.png&quot;/&gt;​&lt;/p&gt;

&lt;p&gt;[](&amp;lt;&amp;gt; &quot;点击并拖拽以移动&quot;)&lt;/p&gt;

&lt;p&gt;ConcurrentHashmap默认有16个Segment，最多支持65536个Segment，这是可以通过ConcurrentHashMap的构造器指定的。默认情况下ConcurrencyLevel等于16&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dc1b8cf547f74db5b5a89c1fa3e83fca%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;image.png&quot;/&gt;​&lt;/p&gt;

&lt;p&gt;[](&amp;lt;&amp;gt; &quot;点击并拖拽以移动&quot;)&lt;/p&gt;

&lt;p&gt;如果指定ConcurrencyLevel，最大只能等于65535&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/088e7186b28842eda0fcd2badd79371e%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;image.png&quot;/&gt;​&lt;/p&gt;

&lt;p&gt;[](&amp;lt;&amp;gt; &quot;点击并拖拽以移动&quot;)&lt;/p&gt;

&lt;p&gt;Segment通过继承ReentrantLock来进行加锁，每次锁住一个segment来保证每个Segment内的操作的线程安全性从而实现全局线程安全。&lt;/p&gt;

&lt;p&gt;定位一个元素的过程需要进行两次Hash操作，第一次Hash定位到Segment，第二次Hash定位到元素所在的链表的头部。看看get方法的源码：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d71dcd3409394acfbd3445ae1b10e809%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;image.png&quot;/&gt;​&lt;/p&gt;

&lt;p&gt;[](&amp;lt;&amp;gt; &quot;点击并拖拽以移动&quot;)&lt;/p&gt;

&lt;p&gt;ConcurrentHashMap定义了一个Segment数组segments，Segment则定义了一个HashEntry数组table。&lt;/p&gt;

&lt;p&gt;这种两级定位的结构带来的副作用是hash过程要比普通的HashMap要长，但是带来的好处是更大的，写操作可以只对元素所在的Segment进行加锁即可，不会影响到其他的Segment，这样，ConcurrentHashMap可以支持最大Segment数量的并发量，吞吐量就比HashMap大了很多。&lt;/p&gt;

&lt;p&gt;细心的你可能已经发现，代码截图中使用到了&lt;em&gt;UNSAFE.getObjectVolatile(segments, u)&lt;/em&gt; ，这个是什么意思呢？&lt;/p&gt;

&lt;p&gt;getObjectVolatile是为保证并发访问数组的第 k 个元素可以显式 volatile 读取，为了值的可见性。&lt;/p&gt;

&lt;p&gt;说到Unsafe，这玩意儿咋一看感觉很高大上，因为我们平常编程几乎没见过。但是，Unsafe现在在Java里面是一个“擦边球”，基本处于一个“不推荐使用”的状态。&lt;/p&gt;

&lt;p&gt;Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等。因为可以访问系统资源、可以自主操作内存空间，这无疑增加了程序发生指针问题的风险，Java的垃圾回收器本来很大一个原因是为了解决这个问题，使用Unsafe类会使得程序出错的概率变大，Java官方也不建议开发者使用它。&lt;/p&gt;

&lt;p&gt;R大有一篇回答，关于Unsafe，&lt;a href=&quot;https://www.zhihu.com/question/29266773/answer/43757304&quot; title=&quot;为什么JUC中大量使用了sun.misc.Unsafe 这个类，但官方却不建议开发者使用？ - 知乎&quot;&gt;为什么JUC中大量使用了sun.misc.Unsafe 这个类，但官方却不建议开发者使用？ - 知乎&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;我是tin，一个在努力让自己变得更优秀的普通攻城狮。自己阅历有限、学识浅薄，如有发现文章不妥之处，非常欢迎加我提出，我一定细心推敲加以修改。&lt;/p&gt;

&lt;p&gt;看到这里请安排个“三连”（分享、点赞、在看）再走吧，坚持原创不容易，不要白嫖，你的正反馈是我坚持输出的最强大动力，谢谢！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/76634669ae5d460a9884c9eb5810a938%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;20190911181805AMQR5B8FDFDAXGLA.gif&quot;/&gt;​&lt;/p&gt;

&lt;p&gt;[](&amp;lt;&amp;gt; &quot;点击并拖拽以移动&quot;)&lt;/p&gt;

&lt;p&gt;最后别忘了关注我哦！⏬⏬⏬&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c8d628406e734674aed6e1cbfd7e1aba%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;qrcode_for_gh_e635d95b89a2_258-2.jpg&quot;/&gt;​&lt;/p&gt;

&lt;p&gt;[](&amp;lt;&amp;gt; &quot;点击并拖拽以移动&quot;)&lt;/p&gt;

&lt;p&gt;​&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9594666ca08f43b68ef1e23f4e6be9bf</guid>
<title>听说你还不会分阶段构建 Docker 镜像？</title>
<link>https://toutiao.io/k/04n9rda</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100001175&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4255555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/oiccOczwQpF8NiaIWebEZhnlGRPxCvtWSTIS2jTicg9nicWzCFanySZoYHCibAyATyrtqokPTClL1eU4a0wR106yDYw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;900&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用 Go 语言开发的程序打包后就一个可执行的二进制文件，一般情况下是不需要什么环境依赖就能执行运行跑起来，如果拿到 Docker 里面跑，是非常有优势的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在都 2021 年了，啥都喜欢搞微服务、分布式概念，今天咱们迈出第一步，先把自己的 Go 程序打包成镜像后期再更怎么上传到阿里云的私有仓库里面。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我们将会使用到分阶段构建镜像，来减小我们最后输出的镜像大小。&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzAxMDM4OTE4Ng==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/oiccOczwQpFibibo18fyFiayicVL4FZV4ic7vibkR4NkVichWgwlZ3uURnJTGBrHNFpGafadfoQic1XOPPtgawW3kQuvNNA/0?wx_fmt=png&quot; data-nickname=&quot;GoLang全栈&quot; data-alias=&quot;GolangStackDev&quot; data-signature=&quot;我们专注于以go语言为核心，go名库，go框架，go+，go ORM，GRPC应用，设计模式，数据结构与算法，K8S，Docker，微服务的系列文章分享。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;编写程序&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我就快速用 Gin 写一个服务：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我们会用到 go mod，使用它来安装 Gin 依赖，命令如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;go get github.com/gin-gonic/gin&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后就是写服务代码了：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br/&gt; &lt;span&gt;&quot;github.com/gin-gonic/gin&quot;&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&quot;net/http&quot;&lt;/span&gt;&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; r := gin.New()&lt;br/&gt; r.Handle(&lt;span&gt;&quot;GET&quot;&lt;/span&gt;,&lt;span&gt;&quot;/&quot;&lt;/span&gt;, &lt;span&gt;&lt;span&gt;func&lt;/span&gt;&lt;span&gt;(c *gin.Context)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt;  c.JSON(http.StatusOK, gin.H{&lt;span&gt;&quot;code&quot;&lt;/span&gt;: &lt;span&gt;200&lt;/span&gt;})&lt;br/&gt; })&lt;br/&gt; r.Run(&lt;span&gt;&quot;:80&quot;&lt;/span&gt;)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;跑起来大概是这样的，这里我们就不去处理异常等细节的：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100001173&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6410635155096012&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/oiccOczwQpF8NiaIWebEZhnlGRPxCvtWST5hSL9ic8bOCV998vAVuIpiayKmC6UETicveaAhy6koBxGcX87NDPYdYZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1354&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;编写 Dockerfile&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;什么是 Dockerfile ？&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你对这块不了的话，可以给我留言，人多了，我们可以考虑出一个 Dockerfile  的系列教程。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;第一阶段构建&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了使我们最后构建出来的镜像尽量的小，我们最好是分阶段构建。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一个阶段我们在 go 环境下，编译出我们的可执行二进制文件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;构建配置如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;FROM&lt;/span&gt; golang:&lt;span&gt;1.17&lt;/span&gt;-alpine3.&lt;span&gt;13&lt;/span&gt; as builder&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; mkdir /src&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; sed -i &lt;span&gt;&#x27;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&#x27;&lt;/span&gt; /etc/apk/repositories&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# 安装依赖库 GCC 这些，根据实际情况考虑是否安装&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; apk add build-base&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ADD&lt;/span&gt;&lt;span&gt; . /src&lt;/span&gt;&lt;br/&gt;&lt;span&gt;WORKDIR&lt;/span&gt;&lt;span&gt; /src&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; go env -w GOPROXY=https://goproxy.cn,direct &amp;amp;&amp;amp; go mod tidy&lt;/span&gt;&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; GOPROXY=https://goproxy.cn go build -o app main.go  &amp;amp;&amp;amp; chmod +x app&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关键点解释：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;From 基于那个基础镜像，这里我们基于 go 的 1.17 版本构建，这里最好和你本地开发环境的 go 版本保持一致。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;RUN go env 这一行是设置 go mod 的代理，以及根据 go.mod 文件安装依赖&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其他的应该都不难理解，有问题欢迎留言。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;第二阶段构建&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一阶段构建完毕，我们就能得到一个可执行的二进制文件 app 了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时我们就需要进入第二阶段构建，真正的构建出生产用的镜像，直接上代码：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;FROM&lt;/span&gt; alpine:&lt;span&gt;3.12&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ENV&lt;/span&gt; ZONEINFO=/app/zoneinfo.zip&lt;br/&gt;&lt;span&gt;RUN&lt;/span&gt;&lt;span&gt; mkdir /app&lt;/span&gt;&lt;br/&gt;&lt;span&gt;WORKDIR&lt;/span&gt;&lt;span&gt; /app&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; --from=builder /usr/&lt;span&gt;local&lt;/span&gt;/go/lib/time/zoneinfo.zip /app&lt;/span&gt;&lt;br/&gt;&lt;span&gt;COPY&lt;/span&gt;&lt;span&gt; --from=builder /src/app /app&lt;/span&gt;&lt;br/&gt;&lt;span&gt;ENTRYPOINT&lt;/span&gt;&lt;span&gt;  [&lt;span&gt;&quot;./app&quot;&lt;/span&gt;]&lt;/span&gt;&lt;br/&gt;&lt;span&gt;EXPOSE&lt;/span&gt; &lt;span&gt;80&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关键点解释：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;第一个 COPY 是复制第一阶段里面的时区，可以根据实际情况选择是否复制。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第二个 COPY 是把 app 二进制文件复制到这个镜像里面。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;注意这两个 COPY 都是 --from=builder ，这里的 builder 和第一阶段的 as builder 是一一对应的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后把以上两个阶段的构建代码都复制到 Dockerfile 里面就结束了。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100001172&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5269230769230769&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/oiccOczwQpF8NiaIWebEZhnlGRPxCvtWSTu9Aysnyds26F75XyoOQYwE5GA70uh7GtXUncwcGPj6tod4noxaP9UA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1300&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;打包镜像&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;配置文件好了，剩下就是构建镜像了，直接基于 Dockerfile 文件用 docker 打包即可！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以&lt;strong&gt;需要在安装好 docker 环境的机器上才能构建 docker 镜像&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;命令如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;docker build -t gin-deom:v1 .&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的 gin-deom:v1 就是你的镜像名字了，我这里是随便写的，实际生产中肯定是域名 + 镜像名字 &lt;span&gt;+ &lt;/span&gt;&lt;span&gt;版本号这样的格式。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当你看到如下所示的 Successfully 就表示打包成功了：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100001171&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5042881646655232&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/oiccOczwQpF8NiaIWebEZhnlGRPxCvtWSTxImPzk0iadsMmCB9NGAuL0JmEdTwQiae3kt4oFicfdIu9CdO6aJTwwOuA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;583&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时你看下本地的镜像里面就会多出一个名为 gin-deom:v1 的镜像。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100001170&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.13346814964610718&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/oiccOczwQpF8NiaIWebEZhnlGRPxCvtWSTgQ7TUd1icKkyFGDP0n3jIKEJuO84EmnQWZWECTYibwy76PysibOIBz1QA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;989&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到这里这篇文章的使命就完成了，下一篇我们考虑把他上传到阿里云的私有镜像仓库！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有问题欢迎给我留言！&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b8b8735b5a1caddaf1a7ae11d9b60275</guid>
<title>Flink 企业级优化全面总结</title>
<link>https://toutiao.io/k/gd7rj7b</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1、资源配置调优&lt;/span&gt;&lt;span/&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;         Flink性能调优的第一步，就是为任务分配合适的资源，在一定范围内，增加资源的分配与性能的提升是成正比的，实现了最优的资源配置后，在此基础上再考虑进行后面论述的性能调优策略。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;         提交方式主要是&lt;code&gt;yarn-per-job&lt;/code&gt;，资源的分配在使用脚本提交Flink任务时进行指定。标准的Flink任务提交脚本（Generic CLI 模式）从1.11开始，增加了通用客户端模式，参数使用-D &lt;code&gt;&amp;lt;property=value&amp;gt;&lt;/code&gt;指定。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;bin/flink run&lt;br/&gt;-t yarn-per-job&lt;br/&gt;-d&lt;br/&gt;-p 5 \ 指定并行度&lt;br/&gt;-Dyarn.application.queue=test \ 指定yarn队列&lt;br/&gt;-Djobmanager.memory.process.size=1024mb \ 指定JM的总进程大小&lt;br/&gt;-Dtaskmanager.memory.process.size=1024mb \ 指定每个TM的总进程大小&lt;br/&gt;-Dtaskmanager.numberOfTaskSlots=2 \ 指定每个TM的slot数&lt;br/&gt;-c com.atguigu.app.dwd.LogBaseApp&lt;br/&gt;/opt/module/gmall-flink/gmall-realtime-1.0-SNAPSHOT-jar-with-dependencies.jar&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.1 内存设置&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;bin/flink run&lt;br/&gt;-t yarn-per-job&lt;br/&gt;-d&lt;br/&gt;-p 5 \ 指定并行度&lt;br/&gt;-Dyarn.application.queue=test \ 指定yarn队列&lt;br/&gt;-Djobmanager.memory.process.size=2048mb \ JM2~4G足够&lt;br/&gt;-Dtaskmanager.memory.process.size=6144mb \ 单个TM2~8G足够&lt;br/&gt;-Dtaskmanager.numberOfTaskSlots=2 \ 与容器核数1core：1slot或1core：2slot&lt;br/&gt;-c com.atguigu.app.dwd.LogBaseApp&lt;br/&gt;/opt/module/gmall-flink/gmall-realtime-1.0-SNAPSHOT-jar-with-dependencies.jar&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;         Flink是实时流处理，关键在于资源情况能不能抗住高峰时期每秒的数据量，通常用QPS/TPS来描述数据情况。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.2 并行度设置&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.2.1 最优并行度计算&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;开发完成后，先进行压测。任务并行度给10以下，测试单个并行度的处理上限。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;然后 总QPS/单并行度的处理能力 = 并行度&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不能只从QPS去得出并行度，因为有些字段少、逻辑简单的任务，单并行度一秒处理几万条数据。而有些数据字段多，处理逻辑复杂，单并行度一秒只能处理1000条数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最好根据高峰期的QPS压测，&lt;strong&gt;并行度*1.2倍&lt;/strong&gt;，富余一些资源。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.2.2 source端并行度的配置&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;**数据源端是 Kafka，Source的并行度设置为Kafka对应Topic的分区数。**如果已经等于 Kafka 的分区数，消费速度仍跟不上数据生产速度，考虑下Kafka 要扩大分区，同时调大并行度等于分区数。Flink 的一个并行度可以处理一至多个分区的数据，如果并行度多于 Kafka 的分区数，那么就会造成有的并行度空闲，浪费资源。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.2.3 Transform端并行度的配置&lt;span/&gt;&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;Keyby之前的算子&lt;/p&gt;&lt;p&gt;一般不会做太重的操作，都是比如map、filter、flatmap等处理较快的算子，并行度可以和source保持一致。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;Keyby之后的算子&lt;/p&gt;&lt;p&gt;如果并发较大，建议设置并行度为 2 的整数次幂，例如：128、256、512；&lt;/p&gt;&lt;p&gt;小并发任务的并行度不一定需要设置成 2 的整数次幂；&lt;/p&gt;&lt;p&gt;大并发任务如果没有 KeyBy，并行度也无需设置为 2 的整数次幂；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.2.4 Sink端并行度的配置&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Sink 端是数据流向下游的地方，可以根据 Sink 端的数据量及下游的服务抗压能力进行评估。如果Sink端是Kafka，可以设为Kafka对应Topic的分区数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Sink 端的数据量小，比较常见的就是监控告警的场景，并行度可以设置的小一些。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Source 端的数据量是最小的，拿到 Source 端流过来的数据后做了细粒度的拆分，数据量不断的增加，到 Sink 端的数据量就非常大。那么在 Sink 到下游的存储中间件的时候就需要提高并行度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外 Sink 端要与下游的服务进行交互，并行度还得根据下游的服务抗压能力来设置，如果在 Flink Sink 这端的数据量过大的话，且 Sink 处并行度也设置的很大，但下游的服务完全撑不住这么大的并发写入，可能会造成下游服务直接被写挂，所以最终还是要在 Sink 处的并行度做一定的权衡。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.3 RocksDB大状态调优&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RocksDB 是基于 LSM Tree 实现的（类似HBase），写数据都是先缓存到内存中，所以RocksDB 的写请求效率比较高。RocksDB 使用内存结合磁盘的方式来存储数据，每次获取数据时，先从内存中 blockcache 中查找，如果内存中没有再去磁盘中查询。优化后差不多单并行度 TPS 5000 record/s，性能瓶颈主要在于 RocksDB 对磁盘的读请求，所以当处理性能不够时，仅需要横向扩展并行度即可提高整个Job 的吞吐量。以下几个调优参数：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在&lt;code&gt;flink-conf.yaml&lt;/code&gt;中配置：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;state.backend.rocksdb.localdir: /data1/flink/rocksdb,/data2/flink/rocksdb,/data3/flink/rocksdb&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;注意&lt;/strong&gt;：不要配置单块磁盘的多个目录，务必将目录配置到多块不同的磁盘上，让多块磁盘来分担压力。当设置多个 RocksDB 本地磁盘目录时，Flink 会随机选择要使用的目录，所以就可能存在三个并行度共用同一目录的情况。如果服务器磁盘数较多，一般不会出现该情况，但是如果任务重启后吞吐量较低，可以检查是否发生了多个并行度共用同一块磁盘的情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当一个 TaskManager 包含 3 个 slot 时，那么单个服务器上的三个并行度都对磁盘造成频繁读写，从而导致三个并行度的之间相互争抢同一个磁盘 io，这样务必导致三个并行度的吞吐量都会下降。设置多目录实现三个并行度使用不同的硬盘从而减少资源竞争。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下所示是测试过程中磁盘的 IO 使用率，可以看出三个大状态算子的并行度分别对应了三块磁盘，这三块磁盘的 IO 平均使用率都保持在 45% 左右，IO 最高使用率几乎都是 100%，而其他磁盘的 IO 平均使用率相对低很多。由此可见使用 RocksDB 做为状态后端且有大状态的频繁读取时， 对磁盘IO性能消耗确实比较大。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009664&quot; data-ratio=&quot;0.21951219512195122&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S6RiaicAVaJicpc6XSyCXficvgIlpMAAicHzT4gn37ia2cSzyCthzt6clCDDtQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;943&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下图所示，其中两个并行度共用了 sdb 磁盘，一个并行度使用 sdj磁盘。可以看到 sdb 磁盘的 IO 使用率已经达到了 91.6%，就会导致 sdb 磁盘对应的两个并行度吞吐量大大降低，从而使得整个 Flink 任务吞吐量降低。如果每个服务器上有一两块 SSD，强烈建议将 RocksDB 的本地磁盘目录配置到 SSD 的目录下，从 HDD 改为 SSD 对于性能的提升可能比配置 10 个优化参数更有效。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009665&quot; data-ratio=&quot;0.29055441478439425&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S62LyOBdibfUwS6Xlvqyz9ib8EUAXoibnXzzDLTR5m0FldBZ28dUiaRiawb9w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;974&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;state.backend.incremental&lt;/strong&gt;**：开启增量检查点，默认false，改为true。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;state.backend.rocksdb.predefined-options&lt;/strong&gt;：SPINNING_DISK_OPTIMIZED_HIGH_MEM设置为机械硬盘+内存模式，有条件上SSD，指定为FLASH_SSD_OPTIMIZED&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;state.backend.rocksdb.block.cache-size&lt;/strong&gt;: 整个 RocksDB 共享一个 block cache，读数据时内存的 cache 大小，该参数越大读数据时缓存命中率越高，默认大小为 8 MB，建议设置到 64 ~ 256 MB。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;state.backend.rocksdb.thread.num&lt;/strong&gt;: 用于后台 flush 和合并 sst 文件的线程数，默认为 1，建议调大，机械硬盘用户可以改为 4 等更大的值。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;state.backend.rocksdb.writebuffer.size&lt;/strong&gt;: RocksDB 中，每个 State 使用一个 Column Family，每个 Column Family 使用独占的 write buffer，建议调大，例如：32M&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;state.backend.rocksdb.writebuffer.count&lt;/strong&gt;: 每个 Column Family 对应的 writebuffer 数目，默认值是 2，对于机械磁盘来说，如果内存⾜够大，可以调大到 5 左右&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;state.backend.rocksdb.writebuffer.number-to-merge&lt;/strong&gt;: 将数据从 writebuffer 中 flush 到磁盘时，需要合并的 writebuffer 数量，默认值为 1，可以调成3。.&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;state.backend.local-recovery&lt;/strong&gt;: 设置本地恢复，当 Flink 任务失败时，可以基于本地的状态信息进行恢复任务，可能不需要从 hdfs 拉取数据&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.4 Checkpoint设置&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般我们的 Checkpoint 时间间隔可以设置为分钟级别，例如 1 分钟、3 分钟，对于状态很大的任务每次 Checkpoint 访问 HDFS 比较耗时，可以设置为 5~10 分钟一次Checkpoint，并且调大两次 Checkpoint 之间的暂停间隔，例如设置两次Checkpoint 之间至少暂停 4或8 分钟。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果 Checkpoint 语义配置为 EXACTLY_ONCE，那么在 Checkpoint 过程中还会存在 barrier 对齐的过程，可以通过 Flink Web UI 的 Checkpoint 选项卡来查看 Checkpoint 过程中各阶段的耗时情况，从而确定到底是哪个阶段导致 Checkpoint 时间过长然后针对性的解决问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;RocksDB相关参数在1.3中已说明，可以在flink-conf.yaml指定，也可以在Job的代码中调用API单独指定，这里不再列出。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt; &lt;span&gt;// 使⽤ RocksDBStateBackend 做为状态后端，并开启增量 Checkpoint&lt;/span&gt;&lt;br/&gt; RocksDBStateBackend rocksDBStateBackend = &lt;span&gt;new&lt;/span&gt;  RocksDBStateBackend(&lt;span&gt;&quot;hdfs://node01:8020/flink/checkpoints&quot;&lt;/span&gt;, &lt;span&gt;true&lt;/span&gt;);&lt;br/&gt; env.setStateBackend(rocksDBStateBackend);&lt;br/&gt;&lt;br/&gt; &lt;span&gt;// 开启Checkpoint，间隔为 3 分钟&lt;/span&gt;&lt;br/&gt; env.enableCheckpointing(TimeUnit.MINUTES.toMillis(&lt;span&gt;3&lt;/span&gt;));&lt;br/&gt; &lt;span&gt;// 配置 Checkpoint&lt;/span&gt;&lt;br/&gt; CheckpointConfig checkpointConf = env.getCheckpointConfig();&lt;br/&gt; checkpointConf.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE)&lt;br/&gt; &lt;span&gt;// 最小间隔 4分钟&lt;/span&gt;&lt;br/&gt; checkpointConf.setMinPauseBetweenCheckpoints(TimeUnit.MINUTES.toMillis(&lt;span&gt;4&lt;/span&gt;))&lt;br/&gt; &lt;span&gt;// 超时时间 10分钟&lt;/span&gt;&lt;br/&gt; checkpointConf.setCheckpointTimeout(TimeUnit.MINUTES.toMillis(&lt;span&gt;10&lt;/span&gt;));&lt;br/&gt; &lt;span&gt;// 保存checkpoint&lt;/span&gt;&lt;br/&gt; checkpointConf.enableExternalizedCheckpoints(&lt;br/&gt; CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.5 使用 Flink ParameterTool 读取配置&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在实际开发中，有各种环境（&lt;code&gt;开发&lt;/code&gt;、&lt;code&gt;测试&lt;/code&gt;、&lt;code&gt;预发&lt;/code&gt;、&lt;code&gt;生产&lt;/code&gt;），作业也有很多的配置：算子的并行度配置、Kafka 数据源的配置（broker 地址、topic 名、group.id）、Checkpoint 是否开启、状态后端存储路径、数据库地址、用户名和密码等各种各样的配置，可能每个环境的这些配置对应的值都是不一样的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你是直接在代码⾥⾯写死的配置，每次换个环境去运行测试作业，都要重新去修改代码中的配置，然后编译打包，提交运行，这样就要花费很多时间在这些重复的劳动力上了。在 Flink 中可以通过使用 ParameterTool 类读取配置，它可以读取环境变量、运行参数、配置文件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;ParameterTool 是可序列化的，所以你可以将它当作参数进行传递给算子的自定义函数类。&lt;/strong&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.5.1 读取运行参数&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以在Flink的提交脚本添加运行参数，格式：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 Flink 程序中可以直接使用 &lt;code&gt;ParameterTool.fromArgs(args)&lt;/code&gt; 获取到所有的参数，也可以通过 &lt;code&gt;parameterTool.get(“username”)&lt;/code&gt; 方法获取某个参数对应的值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;举例：通过运行参数指定jobname&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;bin/flink run&lt;br/&gt;-t yarn-per-job&lt;br/&gt;-d&lt;br/&gt;-p 5 \ 指定并行度&lt;br/&gt;-Dyarn.application.queue=test \ 指定yarn队列&lt;br/&gt;-Djobmanager.memory.process.size=1024mb \ 指定JM的总进程大小&lt;br/&gt;-Dtaskmanager.memory.process.size=1024mb \ 指定每个TM的总进程大小&lt;br/&gt;-Dtaskmanager.numberOfTaskSlots=2 \ 指定每个TM的slot数&lt;br/&gt;-c com.atguigu.app.dwd.LogBaseApp&lt;br/&gt;/opt/module/gmall-flink/gmall-realtime-1.0-SNAPSHOT-jar-with-dependencies.jar&lt;br/&gt;–jobname dwd-LogBaseApp //参数名自己随便起，代码里对应上即可&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在代码里获取参数值：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;ParameterTool parameterTool = ParameterTool.fromArgs(args);&lt;br/&gt;String myJobname = parameterTool.get(&lt;span&gt;&quot;jobname&quot;&lt;/span&gt;);  &lt;span&gt;//参数名对应&lt;/span&gt;&lt;br/&gt;env.execute(myJobname);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.5.2 读取系统属性&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;arameterTool 还⽀持通过 ParameterTool.fromSystemProperties() 方法读取系统属性。做个打印：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;ParameterTool parameterTool = ParameterTool.fromSystemProperties();&lt;br/&gt;System.out.println(parameterTool.toMap().toString());&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.5.3 读取配置文件&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以使用&lt;code&gt;ParameterTool.fromPropertiesFile(&quot;/application.properties&quot;)&lt;/code&gt;读取 properties 配置文件。可以将所有要配置的地方（比如并行度和一些 Kafka、MySQL 等配置）都写成可配置的，然后其对应的 key 和 value 值都写在配置文件中，最后通过 ParameterTool 去读取配置文件获取对应的值。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.5.4 注册全局参数&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在ExecutionConfig 中可以将 ParameterTool 注册为全作业参数的参数，这样就可以被 JobManager 的web 端以及用户⾃定义函数中以配置值的形式访问。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); env.getConfig().setGlobalJobParameters(ParameterTool.fromArgs(args));&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以不用将ParameterTool当作参数传递给算子的自定义函数，直接在用户⾃定义的Rich 函数中直接获取到参数值了。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;env.addSource(&lt;span&gt;new&lt;/span&gt; RichSourceFunction() { &lt;br/&gt;&lt;span&gt;@Override&lt;/span&gt; &lt;br/&gt;&lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;run&lt;/span&gt;&lt;span&gt;(SourceContext sourceContext)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt; &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;) { &lt;br/&gt; ParameterTool parameterTool = (ParameterTool)getRuntimeContext().getExecutionConfig().getGlobalJobParameters();&lt;br/&gt;   }&lt;br/&gt;  } &lt;br/&gt;&lt;br/&gt;  &lt;span&gt;@Override&lt;/span&gt; &lt;br/&gt;  &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;cancel&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;  }&lt;br/&gt;})&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1.6 压测方式&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;压测的方式很简单，先在kafka中积压数据，之后开启Flink任务，出现反压，就是处理瓶颈。相当于水库先积水，一下子泄洪。数据可以是自己造的模拟数据，也可以是生产中的部分数据。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;span/&gt;&lt;span&gt;2、反压处理&lt;/span&gt;&lt;span/&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;反压（BackPressure）通常产生于这样的场景：短时间的负载高峰导致系统接收数据的速率远高于它处理数据的速率。许多日常问题都会导致反压，例如，垃圾回收停顿可能会导致流入的数据快速堆积，或遇到大促、秒杀活动导致流量陡增。反压如果不能得到正确的处理，可能会导致资源耗尽甚至系统崩溃。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;反压机制是指系统能够自己检测到被阻塞的 Operator，然后自适应地降低源头或上游数据的发送速率，从而维持整个系统的稳定。Flink 任务一般运行在多个节点上，数据从上游算子发送到下游算子需要网络传输，若系统在反压时想要降低数据源头或上游算子数据的发送速率，那么肯定也需要网络传输。所以下面先来了解一下 Flink 的网络流控（Flink 对网络数据流量的控制）机制。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.1 反压现象及定位&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Flink 的反压太过于天然了，导致无法简单地通过监控 BufferPool 的使用情况来判断反压状态。Flink 通过对运行中的任务进行采样来确定其反压，如果一个 Task 因为反压导致处理速度降低了，那么它肯定会卡在向 LocalBufferPool 申请内存块上。那么该 Task 的 stack trace 应该是这样：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;java.lang.Object.wait(Native Method)&lt;br/&gt;o.a.f.[...].LocalBufferPool.requestBuffer(LocalBufferPool.java:&lt;span&gt;163&lt;/span&gt;) o.a.f.[...].LocalBufferPool.requestBufferBlocking(LocalBufferPool.java:&lt;span&gt;133&lt;/span&gt;) [...]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;监控对正常的任务运行有一定影响，因此只有当 Web 页面切换到 Job 的 BackPressure 页面时，JobManager 才会对该 Job 触发反压监控。默认情况下，JobManager 会触发 100 次 stack trace 采样，每次间隔 50ms 来确定反压。Web 界面看到的比率表示在内部方法调用中有多少 stack trace 被卡在LocalBufferPool.requestBufferBlocking()，例如: 0.01 表示在 100 个采样中只有 1 个被卡在LocalBufferPool.requestBufferBlocking()。采样得到的比例与反压状态的对应关系如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;OK: 0 &amp;lt;= 比例 &amp;lt;= 0.10&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;LOW: 0.10 &amp;lt; 比例 &amp;lt;= 0.5&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;HIGH: 0.5 &amp;lt; 比例 &amp;lt;= 1&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Task 的状态为 OK 表示没有反压，HIGH 表示这个 Task 被反压。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.1.1 利用Flink Web UI定位产生反压的位置&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 Flink Web UI 中有 BackPressure 的页面，通过该页面可以查看任务中 subtask 的反压状态，如下两图所示，分别展示了状态是 OK 和 HIGH 的场景。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;排查的时候，先把operator chain禁用，方便定位。&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009666&quot; data-ratio=&quot;0.41612483745123535&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S6ulpVEJ8MJVWVWZs2tziaouicZbnbkMjuoELayZMkm3N33GM5tpxBiaicNw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;769&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009663&quot; data-ratio=&quot;0.46029609690444145&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S6uITwPic0n4SiaFwyButicBu1rHV4510FcJ4oOZ4VERaZS8UAZSDictHzmQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;743&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;利用Metrics定位反压位置&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当某个 Task 吞吐量下降时，基于 Credit 的反压机制，上游不会给该 Task 发送数据，所以该 Task 不会频繁卡在向 Buffer Pool 去申请 Buffer。反压监控实现原理就是监控 Task 是否卡在申请 buffer 这一步，所以遇到瓶颈的 Task 对应的反压⻚⾯必然会显示 OK，即表示没有受到反压。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果该 Task 吞吐量下降，造成该Task 上游的 Task 出现反压时，必然会存在：该 Task 对应的 InputChannel 变满，已经申请不到可用的Buffer 空间。如果该 Task 的 InputChannel 还能申请到可用 Buffer，那么上游就可以给该 Task 发送数据，上游 Task 也就不会被反压了，所以说遇到瓶颈且导致上游 Task 受到反压的 Task 对应的InputChannel 必然是满的（这⾥不考虑⽹络遇到瓶颈的情况）。从这个思路出发，可以对该 Task 的 InputChannel 的使用情况进行监控，如果 InputChannel 使用率 100%，那么该 Task 就是我们要找的反压源。Flink 1.9 及以上版本inPoolUsage 表示 inputFloatingBuffersUsage 和inputExclusiveBuffersUsage 的总和。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009667&quot; data-ratio=&quot;0.5404224326292789&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S6k7whMicyHDvRFkYIbhPWu5HyStoQLbC1ib7prPDxNgywLWUPplKN6ZSA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1373&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;反压时，可以看到&lt;strong&gt;遇到瓶颈的该Task的inPoolUage为1&lt;/strong&gt;。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2 反压的原因及处理&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先检查基本原因，然后再深入研究更复杂的原因，最后找出导致瓶颈的原因。下面列出从最基本到比较复杂的一些反压潜在原因。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;注意&lt;/strong&gt;：反压可能是暂时的，可能是由于负载高峰、CheckPoint 或作业重启引起的数据积压而导致反压。如果反压是暂时的，应该忽略它。另外，请记住，断断续续的反压会影响我们分析和解决问题。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2.1 系统资源&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;检查涉及服务器基本资源的使用情况，如CPU、网络或磁盘I/O，目前 Flink 任务使用最主要的还是内存和 CPU 资源，本地磁盘、依赖的外部存储资源以及网卡资源一般都不会是瓶颈。如果某些资源被充分利用或大量使用，可以借助分析工具，分析性能瓶颈（JVM Profiler+ FlameGraph生成火焰图）。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;针对特定的资源调优Flink&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;通过增加并行度或增加集群中的服务器数量来横向扩展&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;减少瓶颈算子上游的并行度，从而减少瓶颈算子接收的数据量（不建议，可能造成整个Job数据延迟增大）&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2.2 垃圾回收（GC）&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;长时间GC暂停会导致性能问题。可以通过打印调试GC日志（通过-XX:+PrintGCDetails）或使用某些内存或 GC 分析器（GCViewer工具）来验证是否处于这种情况。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;在Flink提交脚本中,设置JVM参数，打印GC日志：&lt;/p&gt;&lt;pre&gt;&lt;span/&gt;&lt;code&gt;bin/flink run&lt;br/&gt;-t yarn-per-job&lt;br/&gt;-d&lt;br/&gt;-p 5 \ 指定并行度&lt;br/&gt;-Dyarn.application.queue=test \ 指定yarn队列&lt;br/&gt;-Djobmanager.memory.process.size=1024mb \ 指定JM的总进程大小&lt;br/&gt;-Dtaskmanager.memory.process.size=1024mb \ 指定每个TM的总进程大小&lt;br/&gt;-Dtaskmanager.numberOfTaskSlots=2 \ 指定每个TM的slot数&lt;br/&gt;-Denv.java.opts=&quot;-XX:+PrintGCDetails -XX:+PrintGCDateStamps&quot;&lt;br/&gt;-c com.atguigu.app.dwd.LogBaseApp&lt;br/&gt;/opt/module/gmall-flink/gmall-realtime-1.0-SNAPSHOT-jar-with-dependencies.jar&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;因为是on yarn模式，运行的节点一个一个找比较麻烦。可以打开WebUI，选择JobManager或者TaskManager，点击Stdout，即可看到GC日志，点击下载按钮即可将GC日志通过HTTP的方式下载下来。&lt;/p&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100009672&quot; data-ratio=&quot;0.3931888544891641&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S6gLbNhd72Wg7B8RRMaiaMoicic7Vibrz7ZxwffuqtsLkx4ZVdkA5emCskxw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1615&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过 GC 日志分析出单个 Flink Taskmanager 堆总大小、年轻代、老年代分配的内存空间、Full GC 后老年代剩余大小等，相关指标定义可以去 Github 具体查看。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;扩展：最重要的指标是Full GC后，老年代剩余大小这个指标，按照《Java性能优化权威指南》这本Java堆大小计算法则，设Full GC后老年代剩余大小空间为M，那么堆的大小建议3 ~ 4倍M，新生代为1 ~ 1.5倍M，老年代应为2 ~ 3倍M。&lt;/strong&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2.4 线程竞争&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;与上⾯的 CPU/线程瓶颈问题类似，subtask 可能会因为共享资源上高负载线程的竞争而成为瓶颈。同样，可以考虑使用2.2.1提到的分析工具，考虑在用户代码中查找同步开销、锁竞争，尽管避免在用户代码中添加同步。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.4.5 负载不平衡&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果瓶颈是由数据倾斜引起的，可以尝试通过将数据分区的 key 进行加盐或通过实现本地预聚合来减轻数据倾斜的影响。（关于数据倾斜的详细解决方案，会在下一章节详细讨论）&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.4.6 外部依赖&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果发现我们的 Source 端数据读取性能比较低或者 Sink 端写入性能较差，需要检查第三方组件是否遇到瓶颈。例如，Kafka 集群是否需要扩容，Kafka 连接器是否并行度较低，HBase 的 rowkey 是否遇到热点问题。关于第三方组件的性能问题，需要结合具体的组件来分析。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;span/&gt;&lt;span&gt;3、数据倾斜&lt;/span&gt;&lt;span/&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.1 判断是否存在数据倾斜&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相同 Task 的多个 Subtask 中，个别Subtask 接收到的数据量明显大于其他 Subtask 接收到的数据量，通过 Flink Web UI 可以精确地看到每个 Subtask 处理了多少数据，即可判断出 Flink 任务是否存在数据倾斜。通常，数据倾斜也会引起反压。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009668&quot; data-ratio=&quot;1.0089445438282647&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S6NVGIxvbfa8vsaOYyl0bIHZofw0KXjt4VicBeZvf6E6wpTYZQvfib9ic9w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;559&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2 数据倾斜的解决&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2.1 keyBy后的聚合操作存在数据倾斜&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用LocalKeyBy的思想：在 keyBy 上游算子数据发送之前，首先在上游算子的本地对数据进行聚合后再发送到下游，使下游接收到的数据量大大减少，从而使得 keyBy 之后的聚合操作不再是任务的瓶颈。类似MapReduce 中 Combiner 的思想，但是这要求聚合操作必须是多条数据或者一批数据才能聚合，单条数据没有办法通过聚合来减少数据量。从Flink LocalKeyBy 实现原理来讲，必然会存在一个积攒批次的过程，在上游算子中必须攒够一定的数据量，对这些数据聚合后再发送到下游。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;**注意：**Flink是实时流处理，如果keyby之后的聚合操作存在数据倾斜，且没有开窗口的情况下，简单的认为使用两阶段聚合，是不能解决问题的。因为这个时候Flink是来一条处理一条，且向下游发送一条结果，对于原来keyby的维度（第二阶段聚合）来讲，数据量并没有减少，且结果重复计算（非FlinkSQL，未使用回撤流），如下图所示：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009669&quot; data-ratio=&quot;0.3807062876830319&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S6dxxKTtdiaU6nHgZzlSLmHvo3D0AFMkSWQW6bVbgkeAZTIVZKudibgZhg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1161&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;**实现方式：**以计算PV为例，keyby之前，使用flatMap实现LocalKeyby&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;LocalKeyByFlatMap&lt;/span&gt; &lt;span&gt;extends&lt;/span&gt; &lt;span&gt;RichFlatMapFunction&lt;/span&gt;&amp;lt;&lt;span&gt;String&lt;/span&gt;, &lt;span&gt;Tuple2&lt;/span&gt;&amp;lt;&lt;span&gt;String&lt;/span&gt;, &lt;br/&gt; //&lt;span&gt;Checkpoint&lt;/span&gt; 时为了保证 &lt;span&gt;Exactly&lt;/span&gt; &lt;span&gt;Once&lt;/span&gt;，将 &lt;span&gt;buffer&lt;/span&gt; 中的数据保存到该 &lt;span&gt;ListState&lt;/span&gt; 中&lt;br/&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;ListState&lt;/span&gt;&amp;lt;&lt;span&gt;Tuple2&lt;/span&gt;&amp;lt;&lt;span&gt;String&lt;/span&gt;, &lt;span&gt;Long&lt;/span&gt;&amp;gt;&amp;gt; &lt;span&gt;localPvStatListState&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt; &lt;br/&gt; &lt;span&gt;//本地 buffer，存放 local 端缓存的 app 的 pv 信息&lt;/span&gt;&lt;br/&gt; &lt;span&gt;private&lt;/span&gt; HashMap&amp;lt;String, Long&amp;gt; localPvStat;&lt;br/&gt; &lt;br/&gt; &lt;span&gt;//缓存的数据量大小，即：缓存多少数据再向下游发送&lt;/span&gt;&lt;br/&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; batchSize;&lt;br/&gt; &lt;br/&gt; &lt;span&gt;//计数器，获取当前批次接收的数据量&lt;/span&gt;&lt;br/&gt; &lt;span&gt;private&lt;/span&gt; AtomicInteger currentSize;&lt;br/&gt;&lt;br/&gt; &lt;span&gt;//构造器，批次大小传参&lt;/span&gt;&lt;br/&gt; LocalKeyByFlatMap(&lt;span&gt;int&lt;/span&gt; batchSize){&lt;br/&gt;  &lt;span&gt;this&lt;/span&gt;.batchSize = batchSize;&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt; &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;flatMap&lt;/span&gt;&lt;span&gt;(String in, Collector collector)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;  &lt;span&gt;// 将新来的数据添加到 buffer 中&lt;/span&gt;&lt;br/&gt;  Long pv = localPvStat.getOrDefault(in, &lt;span&gt;0L&lt;/span&gt;);&lt;br/&gt;  localPvStat.put(in, pv + &lt;span&gt;1&lt;/span&gt;);&lt;br/&gt;    &lt;span&gt;// 如果到达设定的批次，则将 buffer 中的数据发送到下游&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt;(currentSize.incrementAndGet() &amp;gt;= batchSize){&lt;br/&gt;   &lt;span&gt;// 遍历 Buffer 中数据，发送到下游&lt;/span&gt;&lt;br/&gt;   &lt;span&gt;for&lt;/span&gt;(Map.Entry&amp;lt;String, Long&amp;gt; appIdPv: localPvStat.entrySet()) {&lt;br/&gt;    collector.collect(Tuple2.of(appIdPv.getKey(), appIdPv.getValue()&lt;br/&gt;   }&lt;br/&gt;   &lt;span&gt;// Buffer 清空，计数器清零&lt;/span&gt;&lt;br/&gt;   localPvStat.clear();&lt;br/&gt;   currentSize.set(&lt;span&gt;0&lt;/span&gt;);&lt;br/&gt;  }&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt; &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;snapshotState&lt;/span&gt;&lt;span&gt;(FunctionSnapshotContext functionSnapshotConte&lt;br/&gt;  // 将 buffer 中的数据保存到状态中，来保证 Exactly Once&lt;br/&gt;  localPvStatListState.clear()&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;  &lt;span&gt;for&lt;/span&gt;(Map.Entry&amp;lt;String, Long&amp;gt; appIdPv: localPvStat.entrySet()) {&lt;br/&gt;   localPvStatListState.add(Tuple2.of(appIdPv.getKey(), appIdPv.ge&lt;br/&gt;  }&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt; &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;initializeState&lt;/span&gt;&lt;span&gt;(FunctionInitializationContext context)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;  &lt;span&gt;// 从状态中恢复 buffer 中的数据&lt;/span&gt;&lt;br/&gt;  localPvStatListState = context.getOperatorStateStore().getListState&lt;br/&gt;  &lt;span&gt;new&lt;/span&gt; ListStateDescriptor&amp;lt;&amp;gt;(&lt;span&gt;&quot;localPvStat&quot;&lt;/span&gt;,&lt;br/&gt;  TypeInformation.of(&lt;span&gt;new&lt;/span&gt; TypeHint&amp;lt;Tuple2&amp;lt;String, Long&amp;gt;&amp;gt;})));&lt;br/&gt;  localPvStat = &lt;span&gt;new&lt;/span&gt; HashMap();&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt;(context.isRestored()) {&lt;br/&gt;   &lt;span&gt;// 从状态中恢复数据到 localPvStat 中&lt;/span&gt;&lt;br/&gt;   &lt;span&gt;for&lt;/span&gt;(Tuple2&amp;lt;String, Long&amp;gt; appIdPv: localPvStatListState.get()){&lt;br/&gt;&lt;span&gt;long&lt;/span&gt; pv = localPvStat.getOrDefault(appIdPv.f0, &lt;span&gt;0L&lt;/span&gt;);&lt;br/&gt;    &lt;span&gt;// 如果出现 pv != 0,说明改变了并行度，&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// ListState 中的数据会被均匀分发到新的 subtask中&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// 所以单个 subtask 恢复的状态中可能包含两个相同的 app 的数据&lt;/span&gt;&lt;br/&gt;    localPvStat.put(appIdPv.f0, pv + appIdPv.f1);&lt;br/&gt;   }&lt;br/&gt;   &lt;span&gt;// 从状态恢复时，默认认为 buffer 中数据量达到了 batchSize，需要向下游发&lt;/span&gt;&lt;br/&gt;   currentSize = &lt;span&gt;new&lt;/span&gt; AtomicInteger(batchSize);&lt;br/&gt;  } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;   currentSize = &lt;span&gt;new&lt;/span&gt; AtomicInteger(&lt;span&gt;0&lt;/span&gt;);&lt;br/&gt;  }&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2.2 keyBy之前发生数据倾斜&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果 keyBy 之前就存在数据倾斜，上游算子的某些实例可能处理的数据较多，某些实例可能处理的数据较少，产生该情况可能是因为数据源的数据本身就不均匀，例如由于某些原因 Kafka 的 topic 中某些 partition 的数据量较大，某些 partition 的数据量较少。对于不存在 keyBy 的 Flink 任务也会出现该情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种情况，需要让 Flink 任务强制进行shuffle。使用shuffle、rebalance 或 rescale算子即可将数据均匀分配，从而解决数据倾斜的问题。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2.3 keyBy后的窗口聚合操作存在数据倾斜&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为使用了窗口，变成了有界数据的处理（3.2.1已分析过），窗口默认是触发时才会输出一条结果发往下游，所以可以使用两阶段聚合的方式：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;实现思路：&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;第一阶段聚合：key拼接随机数前缀或后缀，进行keyby、开窗、聚合&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;注意：聚合完不再是WindowedStream，要获取WindowEnd作为窗口标记作为第二阶段分组依据，避免不同窗口的结果聚合到一起）&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;第二阶段聚合：去掉随机数前缀或后缀，按照原来的key及windowEnd作keyby、聚合&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;span/&gt;&lt;span&gt;4、KafkaSource调休&lt;/span&gt;&lt;span/&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.1 动态发现分区&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当 FlinkKafkaConsumer 初始化时，每个 subtask 会订阅一批 partition，但是当 Flink 任务运行过程中，如果被订阅的 topic 创建了新的 partition，FlinkKafkaConsumer 如何实现动态发现新创建的 partition 并消费呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在使用 FlinkKafkaConsumer 时，可以开启 partition 的动态发现。通过 Properties指定参数开启（单位是毫秒）:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;FlinkKafkaConsumerBase.KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS &lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该参数表示间隔多久检测一次是否有新创建的 partition。默认值是Long的最小值，表示不开启，大于0表示开启。开启时会启动一个线程根据传入的interval定期获取Kafka最新的元数据，新 partition 对应的那一个 subtask 会自动发现并从earliest 位置开始消费，新创建的 partition 对其他 subtask 并不会产生影响。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;properties.setProperty(FlinkKafkaConsumerBase.KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS, &lt;span&gt;30&lt;/span&gt; * &lt;span&gt;1000&lt;/span&gt; + &lt;span&gt;&quot;&quot;&lt;/span&gt;); &lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.2 从kafka数据源生成watermark&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Kafka单分区内有序，多分区间无序。在这种情况下，可以使用 Flink 中可识别 Kafka 分区的 watermark 生成机制。使用此特性，将在 Kafka 消费端内部针对每个 Kafka 分区生成 watermark，并且不同分区 watermark 的合并方式与在数据流 shuffle 时的合并方式相同。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在单分区内有序的情况下，使用时间戳单调递增按分区生成的 watermark 将生成完美的全局 watermark。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以不使用 TimestampAssigner，直接用 Kafka 记录自身的时间戳：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;&lt;br/&gt;Properties properties = &lt;span&gt;new&lt;/span&gt; Properties();&lt;br/&gt;properties.setProperty(&lt;span&gt;&quot;bootstrap.servers&quot;&lt;/span&gt;, &lt;span&gt;&quot;node01:9092,node01:9092,node03:9092&quot;&lt;/span&gt;);&lt;br/&gt;properties.setProperty(&lt;span&gt;&quot;group.id&quot;&lt;/span&gt;, &lt;span&gt;&quot;dsjlg&quot;&lt;/span&gt;);&lt;br/&gt;FlinkKafkaConsumer&amp;lt;String&amp;gt; kafkaSourceFunction = &lt;span&gt;new&lt;/span&gt; FlinkKafkaConsumer&amp;lt;&amp;gt;(&lt;br/&gt;                &lt;span&gt;&quot;flinktest&quot;&lt;/span&gt;,&lt;br/&gt;                &lt;span&gt;new&lt;/span&gt; SimpleStringSchema(),&lt;br/&gt;                properties&lt;br/&gt;        );&lt;br/&gt;&lt;br/&gt;kafkaSourceFunction.assignTimestampsAndWatermarks(&lt;br/&gt;                WatermarkStrategy&lt;br/&gt;                        .forBoundedOutOfOrderness(Duration.ofMinutes(&lt;span&gt;2&lt;/span&gt;))&lt;br/&gt;);&lt;br/&gt;&lt;br/&gt;env.addSource(kafkaSourceFunction);&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.3 设置空闲等待&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果数据源中的某一个分区/分片在一段时间内未发送事件数据，则意味着 WatermarkGenerator 也不会获得任何新数据去生成 watermark。我们称这类数据源为空闲输入或空闲源。在这种情况下，当某些其他分区仍然发送事件数据的时候就会出现问题。比如Kafka的Topic中，由于某些原因，造成个别Partition一直没有新的数据。由于下游算子 watermark 的计算方式是取所有不同的上游并行数据源 watermark 的最小值，则其 watermark 将不会发生变化，导致窗口、定时器等不会被触发。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了解决这个问题，你可以使用 WatermarkStrategy 来检测空闲输入并将其标记为空闲状态。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;br/&gt;&lt;br/&gt;Properties properties = &lt;span&gt;new&lt;/span&gt; Properties();&lt;br/&gt;properties.setProperty(&lt;span&gt;&quot;bootstrap.servers&quot;&lt;/span&gt;, &lt;span&gt;&quot;node01:9092,node02:9092,node03:9092&quot;&lt;/span&gt;);&lt;br/&gt;properties.setProperty(&lt;span&gt;&quot;group.id&quot;&lt;/span&gt;, &lt;span&gt;&quot;gzhdsjlg&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;FlinkKafkaConsumer&amp;lt;String&amp;gt; kafkaSourceFunction = &lt;span&gt;new&lt;/span&gt; FlinkKafkaConsumer&amp;lt;&amp;gt;(&lt;br/&gt;                &lt;span&gt;&quot;flinktest&quot;&lt;/span&gt;,&lt;br/&gt;                &lt;span&gt;new&lt;/span&gt; SimpleStringSchema(),&lt;br/&gt;                properties&lt;br/&gt;        );&lt;br/&gt;&lt;br/&gt;kafkaSourceFunction.assignTimestampsAndWatermarks(&lt;br/&gt;                WatermarkStrategy&lt;br/&gt;                        .forBoundedOutOfOrderness(Duration.ofMinutes(&lt;span&gt;2&lt;/span&gt;))&lt;br/&gt;      .withIdleness(Duration.ofMinutes(&lt;span&gt;5&lt;/span&gt;))&lt;br/&gt;);&lt;br/&gt;&lt;br/&gt;env.addSource(kafkaSourceFunction)&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.4 Kafka的offset消费策略&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;FlinkKafkaConsumer可以调用以下API，注意与&lt;code&gt;auto.offset.reset&lt;/code&gt;区分开：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;setStartFromGroupOffsets()：默认消费策略，默认读取上次保存的offset信息，如果是应用第一次启动，读取不到上次的offset信息，则会根据这个参数auto.offset.reset的值来进行消费数据。建议使用这个。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;setStartFromEarliest()：从最早的数据开始进行消费，忽略存储的offset信息&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;setStartFromLatest()：从最新的数据进行消费，忽略存储的offset信息&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;setStartFromSpecificOffsets(Map)：从指定位置进行消费&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;setStartFromTimestamp(long)：从topic中指定的时间点开始消费，指定时间点之前的数据忽略&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;当checkpoint机制开启的时候，KafkaConsumer会定期把kafka的offset信息还有其他operator的状态信息一块保存起来。当job失败重启的时候，Flink会从最近一次的checkpoint中进行恢复数据，重新从保存的offset消费kafka中的数据（也就是说，上面几种策略，只有第一次启动的时候起作用）。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;为了能够使用支持容错的kafka Consumer，需要开启checkpoint&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;span/&gt;&lt;span&gt;5、FlinkSQL调优&lt;/span&gt;&lt;span/&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1 Group Aggregate优化&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1.1 开启MiniBatch（提升吞吐）&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MiniBatch是微批处理，原理是缓存一定的数据后再触发处理，以减少对State的访问，从而提升吞吐并减少数据的输出量。MiniBatch主要依靠在每个Task上注册的Timer线程来触发微批，需要消耗一定的线程调度性能。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;// 初始化table environment&lt;/span&gt;&lt;br/&gt;TableEnvironment tEnv = ...&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 获取 tableEnv的配置对象&lt;/span&gt;&lt;br/&gt;Configuration configuration = tEnv.getConfig().getConfiguration();&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 设置参数：&lt;/span&gt;&lt;br/&gt;&lt;span&gt;// 开启miniBatch&lt;/span&gt;&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.exec.mini-batch.enabled&quot;&lt;/span&gt;, &lt;span&gt;&quot;true&quot;&lt;/span&gt;);&lt;br/&gt;&lt;span&gt;// 批量输出的间隔时间&lt;/span&gt;&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.exec.mini-batch.allow-latency&quot;&lt;/span&gt;, &lt;span&gt;&quot;5 s&quot;&lt;/span&gt;);&lt;br/&gt;&lt;span&gt;// 防止OOM设置每个批次最多缓存数据的条数，可以设为2万条&lt;/span&gt;&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.exec.mini-batch.size&quot;&lt;/span&gt;, &lt;span&gt;&quot;20000&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/table/config.html&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;微批处理通过增加延迟换取高吞吐，如果有超低延迟的要求，不建议开启微批处理。通常对于聚合的场景，微批处理可以显著的提升系统性能，建议开启。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1）目前，key-value 配置项仅被 Blink planner 支持。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2）1.12之前的版本有bug，开启miniBatch，不会清理过期状态，也就是说如果设置状态的TTL，无法清理过期状态。1.12版本才修复这个问题。参考ISSUE：https://issues.apache.org/jira/browse/FLINK-17096&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1.2 开启LocalGlobal（解决常见数据热点问题）&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;LocalGlobal优化将原先的Aggregate分成Local+Global两阶段聚合，即MapReduce模型中的Combine+Reduce处理模式。第一阶段在上游节点本地攒一批数据进行聚合（localAgg），并输出这次微批的增量值（Accumulator）。第二阶段再将收到的Accumulator合并（Merge），得到最终的结果（GlobalAgg）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;LocalGlobal本质上能够靠LocalAgg的聚合筛除部分倾斜数据，从而降低GlobalAgg的热点，提升性能。结合下图理解LocalGlobal如何解决数据倾斜的问题。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009670&quot; data-ratio=&quot;0.44724409448818897&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S6UElWmicxGqMKhZmXzicdosEZQlzGRdS9LRibhSM1Jy2A7VEFhUAnNy68w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1270&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由上图可知：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;未开启LocalGlobal优化，由于流中的数据倾斜，Key为红色的聚合算子实例需要处理更多的记录，这就导致了热点问题。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;开启LocalGlobal优化后，先进行本地聚合，再进行全局聚合。可大大减少GlobalAgg的热点，提高性能。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;LocalGlobal开启方式：&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1）LocalGlobal优化需要先开启MiniBatch，依赖于MiniBatch的参数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2）table.optimizer.agg-phase-strategy: 聚合策略。默认AUTO，支持参数AUTO、TWO_PHASE(使用LocalGlobal两阶段聚合)、ONE_PHASE(仅使用Global一阶段聚合)。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;// 初始化table environment&lt;/span&gt;&lt;br/&gt;TableEnvironment tEnv = ...&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 获取 tableEnv的配置对象&lt;/span&gt;&lt;br/&gt;Configuration configuration = tEnv.getConfig().getConfiguration();&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 设置参数：&lt;/span&gt;&lt;br/&gt;&lt;span&gt;// 开启miniBatch&lt;/span&gt;&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.exec.mini-batch.enabled&quot;&lt;/span&gt;, &lt;span&gt;&quot;true&quot;&lt;/span&gt;);&lt;br/&gt;&lt;span&gt;// 批量输出的间隔时间&lt;/span&gt;&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.exec.mini-batch.allow-latency&quot;&lt;/span&gt;, &lt;span&gt;&quot;5 s&quot;&lt;/span&gt;);&lt;br/&gt;&lt;span&gt;// 防止OOM设置每个批次最多缓存数据的条数，可以设为2万条&lt;/span&gt;&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.exec.mini-batch.size&quot;&lt;/span&gt;, &lt;span&gt;&quot;20000&quot;&lt;/span&gt;);&lt;br/&gt;&lt;span&gt;// 开启LocalGlobal&lt;/span&gt;&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.optimizer.agg-phase-strategy&quot;&lt;/span&gt;, &lt;span&gt;&quot;TWO_PHASE&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;观察最终生成的拓扑图的节点名字中是否包含GlobalGroupAggregate或LocalGroupAggregate。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;LocalGlobal适用于提升如SUM、COUNT、MAX、MIN和AVG等普通聚合的性能，以及解决这些场景下的数据热点问题。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;1）需要先开启MiniBatch
2）开启LocalGlobal需要UDAF实现Merge方法。&lt;/p&gt;&lt;/blockquote&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1.3 开启split distinct（解决count distinct热点问题）&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;LocalGlobal优化针对普通聚合（例如SUM、COUNT、MAX、MIN和AVG）有较好的效果，对于COUNT DISTINCT收效不明显，因为COUNT DISTINCT在Local聚合时，对于DISTINCT KEY的去重率不高，导致在Global节点仍然存在热点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前，为了解决COUNT DISTINCT的热点问题，通常需要手动改写为两层聚合（增加按Distinct Key取模的打散层）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从Flink1.9.0版本开始，提供了COU&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;NT DISTINCT自动打散功能，不需要手动重写。Split Distinct和LocalGlobal的原理对比参见下图。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009671&quot; data-ratio=&quot;0.48974763406940064&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S64xOc8JF1Ac8RtZNZPoz8oh8xjXtUq4MEhMDVrwGxOMW982I6p8sHDA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1268&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;举例：统计一天的UV&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;SELECT&lt;/span&gt; &lt;span&gt;day&lt;/span&gt;, &lt;span&gt;COUNT&lt;/span&gt;(&lt;span&gt;DISTINCT&lt;/span&gt; user_id)&lt;br/&gt;&lt;span&gt;FROM&lt;/span&gt; T&lt;br/&gt;&lt;span&gt;GROUP&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; &lt;span&gt;day&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果手动实现两阶段聚合：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;SELECT&lt;/span&gt; &lt;span&gt;day&lt;/span&gt;, &lt;span&gt;SUM&lt;/span&gt;(cnt)&lt;br/&gt;&lt;span&gt;FROM&lt;/span&gt; (&lt;br/&gt;    &lt;span&gt;SELECT&lt;/span&gt; &lt;span&gt;day&lt;/span&gt;, &lt;span&gt;COUNT&lt;/span&gt;(&lt;span&gt;DISTINCT&lt;/span&gt; user_id) &lt;span&gt;as&lt;/span&gt; cnt&lt;br/&gt;    &lt;span&gt;FROM&lt;/span&gt; T&lt;br/&gt;    &lt;span&gt;GROUP&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; &lt;span&gt;day&lt;/span&gt;, &lt;span&gt;MOD&lt;/span&gt;(HASH_CODE(user_id), &lt;span&gt;1024&lt;/span&gt;)&lt;br/&gt;)&lt;br/&gt;&lt;span&gt;GROUP&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; &lt;span&gt;day&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一层聚合: 将Distinct Key打散求COUNT DISTINCT。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第二层聚合: 对打散去重后的数据进行SUM汇总。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;Split Distinct开启方式&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;默认不开启，使用参数显式开启：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;table.optimizer.distinct-agg.split.enabled: true，默认false。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;table.optimizer.distinct-agg.split.bucket-num: Split Distinct优化在第一层聚合中，被打散的bucket数目。默认1024。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;// 初始化table environment&lt;/span&gt;&lt;br/&gt;TableEnvironment tEnv = ...&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 获取 tableEnv的配置对象&lt;/span&gt;&lt;br/&gt;Configuration configuration = tEnv.getConfig().getConfiguration();&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 设置参数：&lt;/span&gt;&lt;br/&gt;&lt;span&gt;// 开启Split Distinct&lt;/span&gt;&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.optimizer.distinct-agg.split.enabled&quot;&lt;/span&gt;, &lt;span&gt;&quot;true&quot;&lt;/span&gt;);&lt;br/&gt;&lt;span&gt;// 第一层打散的bucket数目&lt;/span&gt;&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.optimizer.distinct-agg.split.bucket-num&quot;&lt;/span&gt;, &lt;span&gt;&quot;1024&quot;&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;观察最终生成的拓扑图的节点名中是否包含Expand节点，或者原来一层的聚合变成了两层的聚合。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用COUNT DISTINCT，但无法满足聚合节点性能要求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1）目前不能在包含UDAF的Flink SQL中使用Split Distinct优化方法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2）拆分出来的两个GROUP聚合还可参与LocalGlobal优化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3）从Flink1.9.0版本开始，提供了COUNT DISTINCT自动打散功能，不需要手动重写（不用像上面的例子去手动实现）。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1.4 改写为AGG WITH FILTER语法（提升大量count distinct场景性能）&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在某些场景下，可能需要从不同维度来统计UV，如Android中的UV，iPhone中的UV，Web中的UV和总UV，这时，可能会使用如下CASE WHEN语法。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;SELECT&lt;/span&gt;&lt;br/&gt; &lt;span&gt;day&lt;/span&gt;,&lt;br/&gt; &lt;span&gt;COUNT&lt;/span&gt;(&lt;span&gt;DISTINCT&lt;/span&gt; user_id) &lt;span&gt;AS&lt;/span&gt; total_uv,&lt;br/&gt; &lt;span&gt;COUNT&lt;/span&gt;(&lt;span&gt;DISTINCT&lt;/span&gt; &lt;span&gt;CASE&lt;/span&gt; &lt;span&gt;WHEN&lt;/span&gt; flag &lt;span&gt;IN&lt;/span&gt; (&lt;span&gt;&#x27;android&#x27;&lt;/span&gt;, &lt;span&gt;&#x27;iphone&#x27;&lt;/span&gt;) &lt;span&gt;THEN&lt;/span&gt; user_id &lt;span&gt;ELSE&lt;/span&gt; &lt;span&gt;NULL&lt;/span&gt; &lt;span&gt;END&lt;/span&gt;) &lt;span&gt;AS&lt;/span&gt; app_uv,&lt;br/&gt; &lt;span&gt;COUNT&lt;/span&gt;(&lt;span&gt;DISTINCT&lt;/span&gt; &lt;span&gt;CASE&lt;/span&gt; &lt;span&gt;WHEN&lt;/span&gt; flag &lt;span&gt;IN&lt;/span&gt; (&lt;span&gt;&#x27;wap&#x27;&lt;/span&gt;, &lt;span&gt;&#x27;other&#x27;&lt;/span&gt;) &lt;span&gt;THEN&lt;/span&gt; user_id &lt;span&gt;ELSE&lt;/span&gt; &lt;span&gt;NULL&lt;/span&gt; &lt;span&gt;END&lt;/span&gt;) &lt;span&gt;AS&lt;/span&gt; web_uv&lt;br/&gt;&lt;span&gt;FROM&lt;/span&gt; T&lt;br/&gt;&lt;span&gt;GROUP&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; &lt;span&gt;day&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这种情况下，建议使用FILTER语法, 目前的Flink SQL优化器可以识别同一唯一键上的不同FILTER参数。如，在上面的示例中，三个COUNT DISTINCT都作用在user_id列上。此时，经过优化器识别后，Flink可以只使用一个共享状态实例，而不是三个状态实例，可减少状态的大小和对状态的访问。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;将上边的CASE WHEN替换成FILTER后，如下所示:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;SELECT&lt;/span&gt;&lt;br/&gt; &lt;span&gt;day&lt;/span&gt;,&lt;br/&gt; &lt;span&gt;COUNT&lt;/span&gt;(&lt;span&gt;DISTINCT&lt;/span&gt; user_id) &lt;span&gt;AS&lt;/span&gt; total_uv,&lt;br/&gt; &lt;span&gt;COUNT&lt;/span&gt;(&lt;span&gt;DISTINCT&lt;/span&gt; user_id) FILTER (&lt;span&gt;WHERE&lt;/span&gt; flag &lt;span&gt;IN&lt;/span&gt; (&lt;span&gt;&#x27;android&#x27;&lt;/span&gt;, &lt;span&gt;&#x27;iphone&#x27;&lt;/span&gt;)) &lt;span&gt;AS&lt;/span&gt; app_uv,&lt;br/&gt; &lt;span&gt;COUNT&lt;/span&gt;(&lt;span&gt;DISTINCT&lt;/span&gt; user_id) FILTER (&lt;span&gt;WHERE&lt;/span&gt; flag &lt;span&gt;IN&lt;/span&gt; (&lt;span&gt;&#x27;wap&#x27;&lt;/span&gt;, &lt;span&gt;&#x27;other&#x27;&lt;/span&gt;)) &lt;span&gt;AS&lt;/span&gt; web_uv&lt;br/&gt;&lt;span&gt;FROM&lt;/span&gt; T&lt;br/&gt;&lt;span&gt;GROUP&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; &lt;span&gt;day&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2 TopN优化&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当TopN的输入是非更新流（例如Source），TopN只有一种算法AppendRank。当TopN的输入是更新流时（例如经过了AGG/JOIN计算），TopN有2种算法，性能从高到低分别是：UpdateFastRank 和RetractRank。算法名字会显示在拓扑图的节点名字上。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009674&quot; data-ratio=&quot;0.3076923076923077&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S6xHDns8dFn0c2HDzicia3Pic9lw532Xuqh1bG22ibqmKNWYPDLUFicVKLRbQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;585&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;注意：apache社区版的Flink1.12目前还没有UnaryUpdateRank，阿里云实时计算版Flink才有&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009677&quot; data-ratio=&quot;0.47342026078234706&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S6GZB1CBfeT555kWujpmLibS50d1UauxAnM0D8Jw0gdF5ydN9q2YPMzYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;997&quot;/&gt;&lt;/figure&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009675&quot; data-ratio=&quot;0.18629173989455183&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S6R1LKpkrumMRkeiab1t2UkicOjYSoVw2JbvfJeqX8Qh6maFeukibGYD0TA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;569&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;需要具备2个条件：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1）输入流有PK（Primary Key）信息，例如ORDER BY AVG。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2）排序字段的更新是单调的，且单调方向与排序方向相反。例如，ORDER BY COUNT/COUNT_DISTINCT/SUM（正数）DESC。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果要获取到优化Plan，则您需要在使用ORDER BY SUM DESC时，添加SUM为正数的过滤条件。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;AppendFast：结果只追加，不更新&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;RetractRank：普通算法，性能差&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;不建议在生产环境使用该算法。请检查输入流是否存在PK信息，如果存在，则可进行UpdateFastRank优化。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.2 无排名优化（解决数据膨胀问题）&lt;span/&gt;&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;SELECT&lt;/span&gt; *&lt;br/&gt;&lt;span&gt;FROM&lt;/span&gt; (&lt;br/&gt;&lt;span&gt;SELECT&lt;/span&gt; *,&lt;br/&gt;   ROW_NUMBER() &lt;span&gt;OVER&lt;/span&gt; ([&lt;span&gt;PARTITION&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; col1[, col2..]]&lt;br/&gt;   &lt;span&gt;ORDER&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; col1 [&lt;span&gt;asc&lt;/span&gt;|&lt;span&gt;desc&lt;/span&gt;][, col2 [&lt;span&gt;asc&lt;/span&gt;|&lt;span&gt;desc&lt;/span&gt;]...]) &lt;span&gt;AS&lt;/span&gt; &lt;span&gt;rownum&lt;/span&gt;&lt;br/&gt;&lt;span&gt;FROM&lt;/span&gt; table_name)&lt;br/&gt;&lt;span&gt;WHERE&lt;/span&gt; &lt;span&gt;rownum&lt;/span&gt; &amp;lt;= N [&lt;span&gt;AND&lt;/span&gt; conditions]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据TopN的语法，rownum字段会作为结果表的主键字段之一写入结果表。但是这可能导致数据膨胀的问题。例如，收到一条原排名9的更新数据，更新后排名上升到1，则从1到9的数据排名都发生变化了，需要将这些数据作为更新都写入结果表。这样就产生了数据膨胀，导致结果表因为收到了太多的数据而降低更新速度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;TopN的输出结果无需要显示rownum值，仅需在最终前端显式时进行1次排序，极大地减少输入结果表的数据量。只需要在外层查询中将rownum字段裁剪掉即可&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;// 最外层的字段，不写 rownum&lt;br/&gt;&lt;span&gt;SELECT&lt;/span&gt; col1, col2, col3&lt;br/&gt;&lt;span&gt;FROM&lt;/span&gt; (&lt;br/&gt; &lt;span&gt;SELECT&lt;/span&gt; col1, col2, col3&lt;br/&gt;   ROW_NUMBER() &lt;span&gt;OVER&lt;/span&gt; ([&lt;span&gt;PARTITION&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; col1[, col2..]]&lt;br/&gt;   &lt;span&gt;ORDER&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; col1 [&lt;span&gt;asc&lt;/span&gt;|&lt;span&gt;desc&lt;/span&gt;][, col2 [&lt;span&gt;asc&lt;/span&gt;|&lt;span&gt;desc&lt;/span&gt;]...]) &lt;span&gt;AS&lt;/span&gt; &lt;span&gt;rownum&lt;/span&gt;&lt;br/&gt; &lt;span&gt;FROM&lt;/span&gt; table_name)&lt;br/&gt;&lt;span&gt;WHERE&lt;/span&gt; &lt;span&gt;rownum&lt;/span&gt; &amp;lt;= N [&lt;span&gt;AND&lt;/span&gt; conditions]&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在无rownum的场景中，对于结果表主键的定义需要特别小心。如果定义有误，会直接导致TopN结果的不正确。无rownum场景中，主键应为TopN上游GROUP BY节点的KEY列表。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.3 增加TopN的Cache大小&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;TopN为了提升性能有一个State Cache层，Cache层能提升对State的访问效率。TopN的Cache命中率的计算公式为。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;cache_hit = cache_size*parallelism/top_n/partition_key_num&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如，Top100配置缓存10000条，并发50，当PatitionBy的key维度较大时，例如10万级别时，Cache命中率只有10000*50/100/100000=5%，命中率会很低，导致大量的请求都会击中State（磁盘），性能会大幅下降。因此当PartitionKey维度特别大时，可以适当加大TopN的CacheS ize，相对应的也建议适当加大TopN节点的Heap Memory。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;// 初始化table environment&lt;/span&gt;&lt;br/&gt;TableEnvironment tEnv = ...&lt;br/&gt;&lt;span&gt;// 获取 tableEnv的配置对象&lt;/span&gt;&lt;br/&gt;Configuration configuration = tEnv.getConfig().getConfiguration();&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 设置参数：&lt;/span&gt;&lt;br/&gt;&lt;span&gt;// 默认10000条，调整TopN cahce到20万，那么理论命中率能达200000*50/100/100000 = 100%&lt;/span&gt;&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.exec.topn.cache-size&quot;&lt;/span&gt;, &lt;span&gt;&quot;200000&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;注意：目前源码中标记为实验项，官网中未列出该参数&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-fileid=&quot;100009676&quot; data-ratio=&quot;0.19702276707530647&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBfmMF1GHmZ4TnUKutsicR3S6LTt8EzEUJ2f10CYcmE9Ec5gpPbZkwalXAiaxHFReK7sT0sBRC3JQDSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1142&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.4 PartitionBy的字段中要有时间类字段&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如每天的排名，要带上Day字段。否则TopN的结果到最后会由于State ttl有错乱。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.5 优化后的SQL示例&lt;span/&gt;&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;insert&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;into&lt;/span&gt; print_test&lt;br/&gt;&lt;span&gt;SELECT&lt;/span&gt;&lt;br/&gt;  cate_id,&lt;br/&gt;  seller_id,&lt;br/&gt;  stat_date,&lt;br/&gt;  pay_ord_amt  &lt;span&gt;--不输出rownum字段，能减小结果表的输出量（无排名优化）&lt;/span&gt;&lt;br/&gt;&lt;span&gt;FROM&lt;/span&gt; (&lt;br/&gt;    &lt;span&gt;SELECT&lt;/span&gt;&lt;br/&gt;      *,&lt;br/&gt;      ROW_NUMBER () &lt;span&gt;OVER&lt;/span&gt; (&lt;br/&gt;        &lt;span&gt;PARTITION&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; cate_id,&lt;br/&gt;        stat_date  &lt;span&gt;--注意要有时间字段，否则state过期会导致数据错乱（分区字段优化）&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;ORDER&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;BY&lt;/span&gt; pay_ord_amt &lt;span&gt;DESC&lt;/span&gt;  &lt;span&gt;--根据上游sum结果排序。排序字段的更新是单调的，且单调方向与排序方向相反（走最优算法）&lt;/span&gt;&lt;br/&gt;      ) &lt;span&gt;as&lt;/span&gt; &lt;span&gt;rownum&lt;/span&gt;  &lt;br/&gt;    &lt;span&gt;FROM&lt;/span&gt; (&lt;br/&gt;        &lt;span&gt;SELECT&lt;/span&gt;&lt;br/&gt;          cate_id,&lt;br/&gt;          seller_id,&lt;br/&gt;          stat_date,&lt;br/&gt;          &lt;span&gt;--重点。声明Sum的参数都是正数，所以Sum的结果是单调递增的，因此TopN能使用优化算法，只获取前100个数据（走最优算法）&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;sum&lt;/span&gt; (total_fee) filter (&lt;br/&gt;            &lt;span&gt;where&lt;/span&gt;&lt;br/&gt;              total_fee &amp;gt;= &lt;span&gt;0&lt;/span&gt;&lt;br/&gt;          ) &lt;span&gt;as&lt;/span&gt; pay_ord_amt&lt;br/&gt;        &lt;span&gt;FROM&lt;/span&gt;&lt;br/&gt;          random_test&lt;br/&gt;        &lt;span&gt;WHERE&lt;/span&gt;&lt;br/&gt;            total_fee &amp;gt;= &lt;span&gt;0&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;GROUP&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;BY&lt;/span&gt; cate_name,&lt;br/&gt;          seller_id,&lt;br/&gt;          stat_date&lt;br/&gt;      ) a&lt;br/&gt;    &lt;span&gt;WHERE&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;rownum&lt;/span&gt; &amp;lt;= &lt;span&gt;100&lt;/span&gt;&lt;br/&gt;  );&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.3 高效去重方案&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于SQL上没有直接支持去重的语法，还要灵活的保留第一条或保留最后一条。因此我们使用了SQL的ROW_NUMBER OVER WINDOW功能来实现去重语法。去重本质上是一种特殊的TopN。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.3.1 保留首行的去重策略&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;保留KEY下第一条出现的数据，之后出现该KEY下的数据会被丢弃掉。因为STATE中只存储了KEY数据，所以性能较优，示例如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;SELECT&lt;/span&gt; *&lt;br/&gt;&lt;span&gt;FROM&lt;/span&gt; (&lt;br/&gt;  &lt;span&gt;SELECT&lt;/span&gt; *,&lt;br/&gt;    ROW_NUMBER() &lt;span&gt;OVER&lt;/span&gt; (&lt;span&gt;PARTITION&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; b &lt;span&gt;ORDER&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; proctime) &lt;span&gt;as&lt;/span&gt; &lt;span&gt;rowNum&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;FROM&lt;/span&gt; T&lt;br/&gt;)&lt;br/&gt;&lt;span&gt;WHERE&lt;/span&gt; &lt;span&gt;rowNum&lt;/span&gt; = &lt;span&gt;1&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上示例是将T表按照b字段进行去重，并按照系统时间保留第一条数据。Proctime在这里是源表T中的一个具有Processing Time属性的字段。如果按照系统时间去重，也可以将Proctime字段简化PROCTIME()函数调用，可以省略Proctime字段的声明。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.3.2 保留末行的去重策略&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;保留KEY下最后一条出现的数据。保留末行的去重策略性能略优于LAST_VALUE函数，示例如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;SELECT&lt;/span&gt; *&lt;br/&gt;&lt;span&gt;FROM&lt;/span&gt; (&lt;br/&gt;  &lt;span&gt;SELECT&lt;/span&gt; *,&lt;br/&gt;    ROW_NUMBER() &lt;span&gt;OVER&lt;/span&gt; (&lt;span&gt;PARTITION&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; b, d &lt;span&gt;ORDER&lt;/span&gt; &lt;span&gt;BY&lt;/span&gt; rowtime &lt;span&gt;DESC&lt;/span&gt;) &lt;span&gt;as&lt;/span&gt; &lt;span&gt;rowNum&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;FROM&lt;/span&gt; T&lt;br/&gt;)&lt;br/&gt;&lt;span&gt;WHERE&lt;/span&gt; &lt;span&gt;rowNum&lt;/span&gt; = &lt;span&gt;1&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上示例是将T表按照b和d字段进行去重，并按照业务时间保留最后一条数据。Rowtime在这里是源表T中的一个具有Event Time属性的字段。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.4 指定时区&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本地时区定义了当前会话时区id。当本地时区的时间戳进行转换时使用。在内部，带有本地时区的时间戳总是以UTC时区表示。但是，当转换为不包含时区的数据类型时(例如TIMESTAMP, TIME或简单的STRING)，会话时区在转换期间被使用。为了避免时区错乱的问题，可以参数指定时区。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;// 初始化table environment&lt;/span&gt;&lt;br/&gt;TableEnvironment tEnv = ...&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 获取 tableEnv的配置对象&lt;/span&gt;&lt;br/&gt;Configuration configuration = tEnv.getConfig().getConfiguration();&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 设置参数：&lt;/span&gt;&lt;br/&gt;&lt;span&gt;// 指定时区&lt;/span&gt;&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.local-time-zone&quot;&lt;/span&gt;, &lt;span&gt;&quot;Asia/Shanghai&quot;&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.5 设置参数总结&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;// 初始化table environment&lt;br/&gt;TableEnvironment tEnv = ...&lt;br/&gt;&lt;br/&gt;// 获取 tableEnv的配置对象&lt;br/&gt;Configuration configuration = tEnv.getConfig().getConfiguration();&lt;br/&gt;&lt;br/&gt;// 设置参数：&lt;br/&gt;// 开启miniBatch&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.exec.mini-batch.enabled&quot;&lt;/span&gt;, &lt;span&gt;&quot;true&quot;&lt;/span&gt;);&lt;br/&gt;// 批量输出的间隔时间&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.exec.mini-batch.allow-latency&quot;&lt;/span&gt;, &lt;span&gt;&quot;5 s&quot;&lt;/span&gt;);&lt;br/&gt;// 防止OOM设置每个批次最多缓存数据的条数，可以设为2万条&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.exec.mini-batch.size&quot;&lt;/span&gt;, &lt;span&gt;&quot;20000&quot;&lt;/span&gt;);&lt;br/&gt;// 开启LocalGlobal&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.optimizer.agg-phase-strategy&quot;&lt;/span&gt;, &lt;span&gt;&quot;TWO_PHASE&quot;&lt;/span&gt;);&lt;br/&gt;// 开启Split Distinct&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.optimizer.distinct-agg.split.enabled&quot;&lt;/span&gt;, &lt;span&gt;&quot;true&quot;&lt;/span&gt;);&lt;br/&gt;// 第一层打散的bucket数目&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.optimizer.distinct-agg.split.bucket-num&quot;&lt;/span&gt;, &lt;span&gt;&quot;1024&quot;&lt;/span&gt;);&lt;br/&gt;// TopN 的缓存条数&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.exec.topn.cache-size&quot;&lt;/span&gt;, &lt;span&gt;&quot;200000&quot;&lt;/span&gt;);&lt;br/&gt;// 指定时区&lt;br/&gt;configuration.setString(&lt;span&gt;&quot;table.local-time-zone&quot;&lt;/span&gt;, &lt;span&gt;&quot;Asia/Shanghai&quot;&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img data-fileid=&quot;100009719&quot; data-ratio=&quot;0.008695652173913044&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3wAU40iaiaJzCyFgm72ooL4mPwJ21btH6vmMZOg53X0liaGke7muYswenwJmds5AcojKK3FIsW89dLNb1y4qJZdPQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;690&quot;/&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;span&gt;资源&lt;/span&gt;&lt;span&gt;获&lt;/span&gt;&lt;span&gt;取 获取Flink面试题，Spark面试题，程序员必备软件，hive面试题，Hadoop面试题，Docker面试题，简历模板等资源请去 GitHub自行下载 https://github.com/lhh2002/Framework-Of-BigData Gitee 自&lt;/span&gt;&lt;span&gt;行下载  https://gitee.com/li_hey_hey/dashboard/projects&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img data-fileid=&quot;100009718&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/v2xdUItjMNib4HsBWcwjGcyN0r7lOW63yx70K2M5cangicNVdORFgCGa3dQIlicaWibIvlia0jBvsrougL2ViaLt8ngA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;50&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;center data-tool=&quot;mdnice编辑器&quot;&gt;&lt;center data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;大数据老哥&lt;/span&gt;&lt;/center&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzA3MjQ1MTQzMQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/2UHIhrbfNBcaVkoNT9zIhLeABq1xb4p11Bn5NK0hMIvw60EX2vY5drumsb036H4W60O5rGpVlN5hzeVVicHODSQ/0?wx_fmt=png&quot; data-nickname=&quot;大数据老哥&quot; data-alias=&quot;&quot; data-signature=&quot;欢迎来自CSDN、GitHub、哔哩哔哩等小伙伴。以自信、人际交往、情感为核心的学习成长的学习方法论。同时分享我的一些人生经验、学习成长方法。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/center&gt;&lt;center data-tool=&quot;mdnice编辑器&quot;&gt;&lt;center data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;希望这篇文章可以帮到你~&lt;br/&gt;记得点赞收藏哦&lt;/span&gt;&lt;/center&gt;&lt;section data-mpa-template=&quot;t&quot; data-from=&quot;yb-recommend-list&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; data-from=&quot;yb-recommend&quot; data-recommend-article-type=&quot;normal&quot; data-recomment-template-id=&quot;1&quot; data-recommend-article-id=&quot;2247493262_1&quot; data-recommend-article-time=&quot;1634860800&quot; data-recommend-article-cover=&quot;http://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBe1xVvxhmAQticwhhgP8JrS4OCkamfibz34Xeq51EgZBD8FrYyLrd1HdxiaGQwBOqic2J7H9nqjjXm2yA/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;企业级Hive SQL迁移Spark SQL&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MjQ1MTQzMQ==&amp;amp;mid=2247493262&amp;amp;idx=1&amp;amp;sn=e3a3a6474074eb296092afef5b529495&amp;amp;chksm=9f1cb286a86b3b9020d1fce77fd6e5d92f8043725def7dff102eb43265594c33b0c3dfa8be5f#rd&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MjQ1MTQzMQ==&amp;amp;mid=2247493262&amp;amp;idx=1&amp;amp;sn=e3a3a6474074eb296092afef5b529495&amp;amp;chksm=9f1cb286a86b3b9020d1fce77fd6e5d92f8043725def7dff102eb43265594c33b0c3dfa8be5f&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;1&quot;&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img data-fileid=&quot;100009723&quot; data-ratio=&quot;0.42592592592592593&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBe1xVvxhmAQticwhhgP8JrS4OCkamfibz34Xeq51EgZBD8FrYyLrd1HdxiaGQwBOqic2J7H9nqjjXm2yA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p data-recommend-title=&quot;t&quot; data-mid=&quot;&quot;&gt;企业级Hive SQL迁移Spark SQL&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;br/&gt;&lt;section data-mpa-template=&quot;t&quot; data-from=&quot;yb-recommend&quot; data-recommend-article-type=&quot;normal&quot; data-recomment-template-id=&quot;1&quot; data-recommend-article-id=&quot;2247493209_1&quot; data-recommend-article-time=&quot;1634688000&quot; data-recommend-article-cover=&quot;http://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBcRly9da86vsGOD5uBvBlicUVknUrKPmWJqiaobX0DGcCvGibxPgibDNjOa5UEZmwnFk1qKia7eQ42hnBA/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;实时离线一体化技术架构(万字，15张图）&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MjQ1MTQzMQ==&amp;amp;mid=2247493209&amp;amp;idx=1&amp;amp;sn=c1aa31f396385d14e400aee424ce434f&amp;amp;chksm=9f1cb251a86b3b47c03ed2e7b17d9f3fa79f0c8a7180e6f56a2e53af03ed930083def1539469#rd&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MjQ1MTQzMQ==&amp;amp;mid=2247493209&amp;amp;idx=1&amp;amp;sn=c1aa31f396385d14e400aee424ce434f&amp;amp;chksm=9f1cb251a86b3b47c03ed2e7b17d9f3fa79f0c8a7180e6f56a2e53af03ed930083def1539469&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;1&quot;&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img data-fileid=&quot;100009722&quot; data-ratio=&quot;0.42525533890436396&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBcRly9da86vsGOD5uBvBlicUVknUrKPmWJqiaobX0DGcCvGibxPgibDNjOa5UEZmwnFk1qKia7eQ42hnBA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1077&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p data-recommend-title=&quot;t&quot; data-mid=&quot;&quot;&gt;实时离线一体化技术架构(万字，15张图）&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;br/&gt;&lt;section data-mpa-template=&quot;t&quot; data-from=&quot;yb-recommend&quot; data-recommend-article-type=&quot;normal&quot; data-recomment-template-id=&quot;1&quot; data-recommend-article-id=&quot;2247493164_1&quot; data-recommend-article-time=&quot;1634554800&quot; data-recommend-article-cover=&quot;http://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd1wTYSEmoicL8MFUnicqFk5MQkpHo8SEL8FJ2xcqMsWHWpialG5nauicGF5sdQNkXstKsHovITpO7Bjg/0?wx_fmt=jpeg&quot; data-recommend-article-title=&quot;Hbase、Kudu 和 ClickHouse 全面对比（万字、16张图）&quot; data-recommend-article-content-url=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MjQ1MTQzMQ==&amp;amp;mid=2247493164&amp;amp;idx=1&amp;amp;sn=275854e762107f22fbd504cabaee0040&amp;amp;chksm=9f1cb224a86b3b32ec19c7370af2056224ee00844cdcb53dc5312ab9a166fdf6b98e0543dacf#rd&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MjQ1MTQzMQ==&amp;amp;mid=2247493164&amp;amp;idx=1&amp;amp;sn=275854e762107f22fbd504cabaee0040&amp;amp;chksm=9f1cb224a86b3b32ec19c7370af2056224ee00844cdcb53dc5312ab9a166fdf6b98e0543dacf&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;1&quot;&gt;&lt;section data-recommend-type=&quot;normal&quot; data-recommend-tid=&quot;1&quot; data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img data-fileid=&quot;100009721&quot; data-ratio=&quot;0.4243369734789392&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2UHIhrbfNBd1wTYSEmoicL8MFUnicqFk5MQkpHo8SEL8FJ2xcqMsWHWpialG5nauicGF5sdQNkXstKsHovITpO7Bjg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;641&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot;&gt;&lt;p data-recommend-title=&quot;t&quot; data-mid=&quot;&quot;&gt;Hbase、Kudu 和 ClickHouse 全面对比（万字、16张图）&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/a&gt;&lt;/section&gt;&lt;br/&gt;&lt;/section&gt;&lt;center data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;🧐&lt;/span&gt;&lt;span&gt;&lt;span&gt;分享&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;点赞&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;、&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;在看&lt;/span&gt;&lt;/span&gt;&lt;span&gt;，给个&lt;/span&gt;&lt;span&gt;&lt;span&gt;3连击&lt;/span&gt;&lt;/span&gt;&lt;span&gt;呗！&lt;span&gt;👇&lt;/span&gt;&lt;/span&gt;&lt;span/&gt;&lt;br/&gt;&lt;/center&gt;&lt;/center&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>70a15e7e3c27063ca90f70f170c0a195</guid>
<title>探究：Elasticsearch Painless 脚本 ctx、doc、_source 的区别是什么？</title>
<link>https://toutiao.io/k/a7sw05g</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1、实战问题&lt;/span&gt;&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;星主，请教一下，我在painless中使用doc的形式访问字段，如if(doc[&#x27;xxx&#x27;].value ...)报错了，是painless中不允许使用doc吗？&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;我看官方示例和您之前的博客都是用ctx，请问 ctx 和 doc, params，params._source之间有什么区别吗?
我知道doc直接从内存获取，params从磁盘获取，但是对于上述4个的区别不是很了解，也没有查询到相关的资料......&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;——来自《死磕Elasticsearch 知识星球》&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;上述问题不止一次被问到，我自己在使用 painless 脚本的时候，也会遇到上述困惑。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;今天，我们把这几种的区别梳理清楚。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2、关于 Elasticsearch painless 脚本&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果对 painless “无痛”脚本不了解的，推荐阅读：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDY1MTA3OQ==&amp;amp;mid=2247484536&amp;amp;idx=1&amp;amp;sn=ac8d01e442b04d7d6e7bec15092e9b99&amp;amp;chksm=eaa82c50dddfa546c460df5e68b4bd59fbe6f16917596c0dd8e7673a2a0190dfae864e5983a1&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;干货 | Elasticsearch7.X Scripting脚本使用详解&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;干货 | Elasticsearch7.X Scripting脚本使用详解&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDY1MTA3OQ==&amp;amp;mid=2247485003&amp;amp;idx=1&amp;amp;sn=1f0d1c933d458bb9e3c71794d354aff1&amp;amp;chksm=eaa82e63dddfa77584bde5083adcdb4b33ef0c35fce8749dd6b6980ff92071b567a6a7ff93f7&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Elasticsearch 预处理没有奇技淫巧，请先用好这一招！&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;Elasticsearch 预处理没有奇技淫巧，请先用好这一招！&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDY1MTA3OQ==&amp;amp;mid=2247487850&amp;amp;idx=1&amp;amp;sn=9e0fb97f949613f828543e7734e5bd54&amp;amp;chksm=eaa83942dddfb054831e443aab3bf26d1c38ebfa4ab723242587c745dc1cb21fed8481a15d8f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Elasticsearch 脚本安全使用指南&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;Elasticsearch 脚本安全使用指南&lt;/a&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDY1MTA3OQ==&amp;amp;mid=2247487575&amp;amp;idx=1&amp;amp;sn=dfba8bc7c984c9f3c26807f8a3b07d5a&amp;amp;chksm=eaa8387fdddfb16952df24d58457f620713f84e09c588ffc4331c3703d7ea8092a66e0b4683a&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Elasticsearch 线上问题实战——如何借助 painless 更新时间？&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;Elasticsearch 线上问题实战——如何借助 painless 更新时间？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3、 从应用层面解读：ctx、doc、_source 的区别？&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;3.1 场景1：ingest 管道预处理脚本使用 ctx&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;上例子：&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;PUT _ingest/pipeline/check_url&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;processors&quot;&lt;/span&gt;: [&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;set&quot;&lt;/span&gt;: {&lt;br/&gt;        &lt;span&gt;&quot;if&quot;&lt;/span&gt;: &lt;span&gt;&quot;&quot;&quot;ctx.href.url!=null &amp;amp;&amp;amp; ctx.href.url.startsWith(&quot;&lt;/span&gt;http&lt;span&gt;&quot;)&quot;&quot;&quot;&lt;/span&gt;,&lt;br/&gt;        &lt;span&gt;&quot;field&quot;&lt;/span&gt;: &lt;span&gt;&quot;href.insecure&quot;&lt;/span&gt;,&lt;br/&gt;        &lt;span&gt;&quot;value&quot;&lt;/span&gt;: &lt;span&gt;true&lt;/span&gt;&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;  ]&lt;br/&gt;}&lt;br/&gt;POST &lt;span&gt;test&lt;/span&gt;/_doc/1?pipeline=check_url&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;href&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;url&quot;&lt;/span&gt;: &lt;span&gt;&quot;http://www.elastic.co/&quot;&lt;/span&gt;&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;POST &lt;span&gt;test&lt;/span&gt;/_search&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;解读如下：&lt;/span&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;上面的脚本通过 ingest painless 脚本实现了判定：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;ctx.href.url 如果非空且 ctx.href.url 以 http 开头，则：href.insecure 设置为：true。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7736842105263158&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/mjl8GCpsL9YJvG193woDdVbFJlDhV0hy0aGhDJLuZqjrNoMuJUBVzJEKLrB94OfYF21wzneHmfcUCUP8nprWVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;380&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;官方文档地址：&lt;/span&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;https://www.elastic.co/guide/en/elasticsearch/painless/7.15/painless-ingest-processor-context.html&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;3.2 场景 2：update/update_by_query 脚本使用 ctx._source&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;POST &lt;span&gt;test&lt;/span&gt;/_doc/2&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;tags&quot;&lt;/span&gt;: &lt;span&gt;&quot;green&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;GET &lt;span&gt;test&lt;/span&gt;/_doc/2&lt;br/&gt;POST &lt;span&gt;test&lt;/span&gt;/_update/2&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;script&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;source&quot;&lt;/span&gt;: &lt;span&gt;&quot;if (ctx._source.tags.contains(params.tag)) { ctx.op = &#x27;delete&#x27; } else { ctx.op = &#x27;none&#x27; }&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;lang&quot;&lt;/span&gt;: &lt;span&gt;&quot;painless&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;params&quot;&lt;/span&gt;: {&lt;br/&gt;      &lt;span&gt;&quot;tag&quot;&lt;/span&gt;: &lt;span&gt;&quot;green&quot;&lt;/span&gt;&lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;GET &lt;span&gt;test&lt;/span&gt;/_doc/2&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;上面的例子解读如下：&lt;/span&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果标签字段：tags 包含：“green”，则 执行删除操作；否则保持现状。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.1587982832618027&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/mjl8GCpsL9YJvG193woDdVbFJlDhV0hywV5cvG4DKibSH9tial9Ro6ibIQHKTbQUzgqZxzic5juD8PLaZHOlBLcKPw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;233&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;官方文档地址：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;https://www.elastic.co/guide/en/elasticsearch/painless/7.15/painless-update-context.html&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;3.3 场景3：reindex 脚本使用 ctx._source&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;上例子：&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;POST &lt;span&gt;test&lt;/span&gt;-04/_doc/1&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;foo&quot;&lt;/span&gt;: &lt;span&gt;&quot;bar&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;views&quot;&lt;/span&gt;: 1&lt;br/&gt;}&lt;br/&gt;POST _reindex&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;source&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;index&quot;&lt;/span&gt;: &lt;span&gt;&quot;test-04&quot;&lt;/span&gt;&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;&quot;dest&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;index&quot;&lt;/span&gt;: &lt;span&gt;&quot;test-new-04&quot;&lt;/span&gt;&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;&quot;script&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;source&quot;&lt;/span&gt;: &lt;span&gt;&quot;if (ctx._source.foo == &#x27;bar&#x27;) {ctx._source.views++; ctx._source.remove(&#x27;foo&#x27;)}&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;lang&quot;&lt;/span&gt;: &lt;span&gt;&quot;painless&quot;&lt;/span&gt;&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;GET &lt;span&gt;test&lt;/span&gt;-new-04/_search&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如上 reindex 脚本解读如下：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果源索引：test-04 字段 foo 内容=‘bar’，则 reindex 后删除 ‘foo’ 字段 且 views 取值加 1 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6534653465346535&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/mjl8GCpsL9YJvG193woDdVbFJlDhV0hyyqUnJU9WFPgV8YyhUlgK0bv0DHMficElpS9L8c6GXiawHsnXdQicnasPQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;303&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;3.4 场景4：search 脚本使用 doc[&#x27;XXX&#x27;]&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;DELETE test_03&lt;br/&gt;PUT test_03&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;mappings&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;properties&quot;&lt;/span&gt;: {&lt;br/&gt;      &lt;span&gt;&quot;views&quot;&lt;/span&gt;: {&lt;br/&gt;        &lt;span&gt;&quot;type&quot;&lt;/span&gt;: &lt;span&gt;&quot;integer&quot;&lt;/span&gt;&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;POST test_03/_doc/1&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;views&quot;&lt;/span&gt;: 30&lt;br/&gt;}&lt;br/&gt;GET test_03/_search&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;script_fields&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;rnd_views&quot;&lt;/span&gt;: {&lt;br/&gt;      &lt;span&gt;&quot;script&quot;&lt;/span&gt;: {&lt;br/&gt;        &lt;span&gt;&quot;lang&quot;&lt;/span&gt;: &lt;span&gt;&quot;painless&quot;&lt;/span&gt;,&lt;br/&gt;        &lt;span&gt;&quot;source&quot;&lt;/span&gt;: &lt;span&gt;&quot;&quot;&quot;&lt;br/&gt;java.util.Random rnd = new Random();&lt;br/&gt;doc[&#x27;views&#x27;].value+rnd.nextInt(1000);&lt;br/&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;&quot;query&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;match_all&quot;&lt;/span&gt;: {}&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;如上search 脚本解读如下：&lt;/span&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;对观看数 views 在检索的时候加了随机值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.9657794676806084&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/mjl8GCpsL9YJvG193woDdVbFJlDhV0hykiayZkwfibH1flbeys6aKlkm91mJHFmbE1uLicoa7icBXe2hg6lqicW4yQQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;263&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;官方文档：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;https://www.elastic.co/guide/en/elasticsearch/painless/7.15/painless-field-context.html&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;3.5 应用层面小结&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;从上面的应用层面，我们能看出区别：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;ingest 场景，使用：ctx.XXX；&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;update / update / update_by_query / reindex 场景，使用：ctx._source；&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;search和聚合场景，使用：doc[&#x27;value&#x27;]。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;当然，Elasticsearch 远不止上面这些场景，更多推荐阅读：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;2.468208092485549&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/mjl8GCpsL9YJvG193woDdVbFJlDhV0hykQ8Ifwdx8wxjYpkQQOXPbTrntOLqFktvsjrYGnibATMsicDcDa3tbbRg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;346&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4、那遇到复杂的脚本处理咋办呢？&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;4.1 获取字符串中的子串&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;举例如下：求字符串中的某子串，java 语法中的 substring 还能用吗？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果使用：ingest processor 预处理方式，怎么查官方是否支持，我相信是大家关注的问题。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;因为：支不支持可以试，但试是穷举的方式，时间复杂度为 O(n)；&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;能查看官方明确说支持，是最快的方式，时间复杂度为O(1)。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;对于我们程序员来说，怎么快，我们就怎么来。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;来吧，一步步走一遍，其他复杂例子原理同。&lt;/span&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.1.1 第一步，找 shard API。&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;细节 API 入口文档。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3474358974358974&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/mjl8GCpsL9YJvG193woDdVbFJlDhV0hy9KW2kB5FZTBH9onRBEdzfyjF9dcjQdKl4KrAnicCFn52wMdQYpEI6wQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;780&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;https://www.elastic.co/guide/en/elasticsearch/painless/master/painless-api-reference-shared.html&lt;/span&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.1.2 第二步，找到 string&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如上是 7.13 版本截图，早期版本如：7.2 版本还有 string类， 7.13 已没有。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.951276102088167&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/mjl8GCpsL9YJvG193woDdVbFJlDhV0hyl9icwKhicWWRm4b3UM9iceYoickAnibibbaqIhwfvTUc9SMTGkJCic9AkHu2g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;431&quot;/&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.1.3 第三步：找 substring&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4864864864864865&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/mjl8GCpsL9YJvG193woDdVbFJlDhV0hykXv4A6MbUTpYYHP998zqPF8g6X0qX0na8qWAXyvkS6SxRmBj56FFuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;481&quot;/&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.1.4 第四步：找 java API&lt;/span&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这就到了 oracle 官网了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.42769607843137253&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/mjl8GCpsL9YJvG193woDdVbFJlDhV0hyJ5A5zONmovQsleicSwD7oQAmnQ7nkDRg97I0CAmTn3LPdzQr31lOGnA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;816&quot;/&gt;&lt;span&gt;实践一把：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;POST &lt;span&gt;test&lt;/span&gt;-05/_doc/1&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;title&quot;&lt;/span&gt;: &lt;span&gt;&quot;hello world&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;PUT _ingest/pipeline/substring_pipeline&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;processors&quot;&lt;/span&gt;: [&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;script&quot;&lt;/span&gt;: {&lt;br/&gt;        &lt;span&gt;&quot;lang&quot;&lt;/span&gt;: &lt;span&gt;&quot;painless&quot;&lt;/span&gt;,&lt;br/&gt;        &lt;span&gt;&quot;source&quot;&lt;/span&gt;: &lt;span&gt;&quot;&quot;&quot;&lt;br/&gt;ctx.sub_title = ctx.title.substring(0,5);&lt;br/&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;  ]&lt;br/&gt;}&lt;br/&gt;POST &lt;span&gt;test&lt;/span&gt;-05/_update_by_query?pipeline=substring_pipeline&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;query&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;match_all&quot;&lt;/span&gt;: {}&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;POST &lt;span&gt;test&lt;/span&gt;-05/_search&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;上面脚本是借助 ingest pipelie 实现：取子串内容，源串为：“hello world”，取出后的子串为：“hello”。&lt;/span&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;核心步骤再结合上面的截图解释一下：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;-步骤1：确认 string 类型支持取子串；&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;-步骤2：找到取子串的语法：substring；&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;-步骤3：通过 ingest 预处理方式实现取子串，借助 ctx 组合 substring 实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7551724137931034&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/mjl8GCpsL9YJvG193woDdVbFJlDhV0hyITpQaRaNu2oUd9QgBnZfe3wPBponVxo414tcyej2O8oeKSbNjHVFpw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;290&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;4.2 获取日期格式的年份&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;POST test_06/_bulk&lt;br/&gt;{&lt;span&gt;&quot;index&quot;&lt;/span&gt;:{&lt;span&gt;&quot;_id&quot;&lt;/span&gt;:1}}&lt;br/&gt;{&lt;span&gt;&quot;m_type&quot;&lt;/span&gt;:1,&lt;span&gt;&quot;create_time&quot;&lt;/span&gt;:&lt;span&gt;&quot;2015-01-01T12:10:30Z&quot;&lt;/span&gt;,&lt;span&gt;&quot;update_time&quot;&lt;/span&gt;:&lt;span&gt;&quot;2021-07-01T12:10:30Z&quot;&lt;/span&gt;}&lt;br/&gt;GET test_06/_mapping&lt;br/&gt;GET test_06/_search&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;script_fields&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;rnd_views&quot;&lt;/span&gt;: {&lt;br/&gt;      &lt;span&gt;&quot;script&quot;&lt;/span&gt;: {&lt;br/&gt;        &lt;span&gt;&quot;lang&quot;&lt;/span&gt;: &lt;span&gt;&quot;painless&quot;&lt;/span&gt;,&lt;br/&gt;        &lt;span&gt;&quot;source&quot;&lt;/span&gt;: &lt;span&gt;&quot;&quot;&quot;&lt;br/&gt;doc[&#x27;create_time&#x27;].value.getYear()&lt;br/&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;&quot;query&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;match_all&quot;&lt;/span&gt;: {}&lt;br/&gt;  }&lt;br/&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;section&gt;如上实例，借助 painless 脚本实现了获取日期类型数据的年份，是借助 getYear( ) 的函数实现的。&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.9283018867924528&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/mjl8GCpsL9YJvG193woDdVbFJlDhV0hyibMIDibJibmbNibNl4T9swlQQz2ymDshpkusIZL7onKQmerXLZHzTb7mJg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;265&quot;/&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5、小结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;Painless 脚本在数据预处理、更新、reindex、获取字段方面应用广泛。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;因业务场景的不同，脚本使用方式也会有不同。大家使用过程中要根据使用方式的不同，来决定ctx、doc、_source 的选型。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;希望本文对你的脚本实战选型有所帮助，也欢迎留言交流你的脚本使用心得......&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>5a19e0c9ad074d175272ba524c30994c</guid>
<title>工作 3 年，我终于开窍了</title>
<link>https://toutiao.io/k/csgs7ln</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;“当时每酣醉，不觉行路难”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每每有人问我:&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;程序员工作三年，要大致学习到什么程度才算合格？&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时候，我感觉很难给出一个绝对正确的回答。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我能做的就是，如实的把我做程序员三年后的状态分享出来，供大家参考。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;卖油翁今已手熟尔&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我当了程序员三年之后，我对开发这事儿已经非常熟练了，熟练主要表现在两个方面：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;提给我的业务需求，我已经能毫不费劲的形成技术思路。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;写代码的时候，我已经能准确而快速的使用开发语言的 API 了。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我认为三年的程序员，做到以上两点是基本条件。干了三年左右，大部分人都已经很适应程序员这个工作了，是团队中编码的主力军，开发工作应该做的很顺利了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果大家在这方面还没做到位，我的建议是多写一些代码。这些代码可以是一些小工具，也可以是一些刻意练习。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;牛客网上求职必备下的编程集合和它的基础提升模块大家可以看看。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说到这里，我多说一下，如果大家真的很熟练了，大家也要警醒一些。因为这种熟练的开发代码就像麻药一样，会渐渐地麻痹了大家的精神却不自知。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我自己对此是有些教训的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我当时由于工作比较顺利，学习开始不那么努力了。虽然技术文章还在看，但系统的学习却停滞不前了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我没有去系统性的拓展我的新技术学习，也没有规划好如何继续深入挖掘各种已掌握技术的细节。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;直到一年后，公司有了一些变动，我被迫提前做了架构师，才发现自己知识的贫瘠。还好那时我醒悟的还不算晚。否则，我可能就一直沉湎于自己构造的舒适圈，很可能就影响到自己以后的发展。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，这里我想通过我的经历告诉大家，当你工作了几年后，一个最基本的要求就是，你得成为一个熟手，能搞定大部分常规的需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，这种工作上的顺利可能会让你懒惰，这点一定要警惕。干咱们这行，是需要持续学习的，因为行业变化太快了，各种新技术新理念新架构层出不穷。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;打算在这个内卷的行业里继续走下去，只有不断的学习，深挖技术细节夯实基础，学新技术拓展眼界。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;已知曲中意，亦是曲中人&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;干了三年，品鉴代码的好坏应该成为了自己的基本能力了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们至少应该拿到代码一看，就知道这代码写的好还是坏，维护容易还是困难。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个能力是咱们的基础能力之一，其他基础能还例如，选第三方工具库的能力，如何重构代码的能力等等&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你在代码方面还有些薄弱，我建议看看《代码整洁之道》这本书。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那如果你工作了三年，对代码好坏的嗅觉已经非常灵敏了，也千万不要自得，因为你此时需要克服一个问题，那就是嘚瑟。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种嘚瑟体现在，你可能会开始评判别人的代码了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;回过头去看看，我当时就是这样。当看同事代码或者接手别人项目的时候，每当看到写的很难读，又或者组织很乱的代码的时候，我就开始去肆意的批评别人。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但我并不知道，自己也是把二把刀。我并不了解为什么人家代码写的难以维护，可能人家也是被迫的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后来我接手了一个赶得很急、产品经理又不给力的项目，这时候，我才深刻体会到了那种赶工写代码的无奈。我才知道，自己也是写这类不可维护代码的同类人。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，后来我逐渐闭上了自己的嘴巴。当我再看到不好的代码，本能还是会反感，因为这增加了我的工作难度。但是，我已经不会再去批评作者了，而是会仔细思考，有没有更好的实现方式，我怎么能把代码改的更优雅。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;自从这么做以后，我发现自己的编程能力竟然也跟着进步了。从很多烂代码后面，我学会了一些优化技巧，比如，使用位移去替代正常的加减乘数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也从一些为了赶时间而写的不那么清晰的代码后面，看到了一些妥协的工作窍门，比如，使用 coninue label 和 break label 等去简化复杂的算法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，工作了三年，品鉴代码好坏应该成为你的一种重要能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于好代码，我们努力学习其风格；而对于坏代码，与其去狂妄的批评代码的作者，还不如我们仔细分析为什么它是坏代码，以及如何优化它。仅此而已，因为你自己也可能被迫会写出类似的坏代码。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;穷千里目，更上层楼&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;老实讲，工作三年后，咱们至少要深度掌握一些技术了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如，我擅长 SQL ，能写各种性能优异的SQL，对 MySQL 有一定程度的了解。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面我说过，我此时学习态度是很松垮的，所以，除了我掌握的，我后续竟然不知道该学什么方向了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后来，可能是因为站到了更高的一个位置上，我突然知道了学习目标，那就是：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我的知识体系应该是随着公司后台架构的发展而进行拓展的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如，公司的架构主要是使用 Redis 做了第三方缓存，数据库是 MySQL，服务之间的通讯方式则是消息队列 RabbitMQ。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么如果我想让自己的知识体系建立在公司的项目架构上，我应该怎么定学习目标？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当时我是这么分析的，我对 MySQL 了解的还算深入，但是对 Redis 和 RabbitMQ 还没有什么了解，只限于会用而已。所以，我定的目标就是对后两个技术进行深入学习。这样学完之后，我的知识体系就成了这样：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.48262032085561496&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/6nbNnibOq5KSb4mYqpfCFcrcJGcicczdmXNn1e8WGPWu4HpvCYqVJEsxicq4x2MDQGaqAQOqpxraDpaLFF2MhQGeA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;748&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这套知识体系我掌握了，才能从众多的同事们中脱颖而出，才有可能成为团队中的核心。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，工作三年之后，咱们应该至少要深入掌握一些技术，并以此为基础，根据公司的技术架构去逐渐完善自己的知识体系。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;做到了学习和工作相结合，才能在实力提升的同时也能得到职场上的正反馈。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;花相似，人不同&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;做程序员的前三年，大家少不了各种 CV 代码。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5108877721943048&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/6nbNnibOq5KSb4mYqpfCFcrcJGcicczdmXtwCL6icZjwD5fic4ewWBnyvDpWFRg37kLBAn8WVu3jECxBvfPe1E1lSA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;597&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不过在这三年中，我认为我们的 CV 应该有一些变化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就说我吧，首先，我拷贝代码的来源发生了变化。从在网上随意找代码，变成了主要从 GitHub 上拷代码了，因为 GitHub 上的例子更多、更丰富。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其次，我拷代码的方式发生了变化。我会仔细研读要复制的代码，并配合官方文档，综合分析后，会对其做一些修改，变成真正适合我自己项目的代码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，我拷代码的次数发生了变化。因为拷的代码我会仔细读、会改，所以我拷代码的次数在不断减少，自己独立写的代码越来越多。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，我推荐大家 CV 的时候，一是可以去专门的开源网站上找代码示例，二是 CV 前一定要分析下，明白每条语句的目的是什么，只有这样，咱们自己才能跟着进步。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在 CV 是为了以后不 CV。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;可言秋日胜春朝&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;三年工作，我可以独立解决一些线上问题了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后来反思，我做的还不够好。因为我解决问题的方式大部分就是就事论事，只注重解决问题的表象，而不会去深挖问题的根源。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如，JVM 内存溢出了，我的做法是改配置参数或者加内存，而不是想着怎么优化代码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;类似这种事情多了之后，由于很多深层次的问题没有得到解决，导致后期维护项目的时候，bug 越改越多，问题越修复越大，极大的增加了维护成本，慢慢的就变成了一个大“屎山”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家解决问题的时候，千万别学当时的我，只看问题表象。尽力对问题深挖，去根本性的解决问题。这样除了对项目和公司有好处，对个人成长也极为有利。坑踩的多，填的多，都会变成你的宝贵经验。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;久在樊笼里，复得返自然&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;代码要写的尽量可读，尽量清晰，是我这个时候写代码的主要理念了。我不知道别人工作三年如何，但是我自己是吃够了这上面的亏。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以前写代码，由于编程水平很渣，而且也没听过“重构”，经常会写一些很难读的代码。比如，把很长的逻辑写到一个方法里，一个类几百上千行。结果在维护的时候就懵逼了，自己写的代码自己都看不懂，经常改错。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后来，我注重了代码质量，注重了重构，bug 也随之减少了很多。后来，团队 Leader 评价我写的代码“可读性和工程性都很好”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;建议大家也重视代码质量，代码要清晰可读，不要为了炫技而特意写一些难读的代码。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;好雨知时节&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;三年里，我经过了很多项目 DeadLine 的考验。我此时已经明白了一个道理——按时完成任务比完美的完成任务要更重要。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;单纯从技术角度看，如果我们要达到完美，是需要花费大量的时间的。优雅的代码，极致的性能，最优的资源利用，都是体现技术完美的因素。而这些因素，无一不是猛烈吞噬时间的猛兽。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;优雅的代码需要更多的时间去重构代码&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;极致的性能需要长时间不同角度的压测&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;而最优的资源利用更是需要不断地修改代码去不停的尝试&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现实上呢，我们开发的产品，市面上基本都有竞品，所以呢，需要我们早做完上线去抢有限的用户、有限的份额。因此，这就需要我们一定要快，在保证质量的前提下按时完活，应该成为咱们的第一优先保障。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;方与人便人称便&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;工作了三年，我也明白了技术是为业务服务的这个道理。我也明白，越了解业务，我做出来的项目就会越契合业务，而越契合业务，项目、代码的价值就越大。这是一个正向循环。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以后来，我每次要开发一套系统的时候，都会去主动学习相关业务知识。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;后来我能从技术无缝转管理，有很大一部分原因是，我能更顺利的理顺业务和技术之间的裂痕，也能更平滑的将业务需求转化为技术需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你不得不承认，在国内真正技术驱动的公司和产品太少了，大部分现状是“技术服务于业务”。虽然这个现状我不喜欢，但是不得不接受，所以我还是想告诉大家：熟悉业务，是我们能突出自己的一个很好的切入点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;写到这里基本就写完了，最后我想说一下，工作三年的程序员大概要到什么程度，真的是千人前面的。每个人所在的公司不同，开发的项目不同，所在的职位不同，自然大家的感悟不同。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我上面说的那些话，除了想分享给大家，有些话也是想说给从前那个我听的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;年底了工作上事儿贼多，&lt;strong&gt;百忙之中抽空写的这些感悟，希望大家看完能给个支持&lt;/strong&gt;，点赞、在看。&lt;/p&gt;&lt;hr/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;你好，我是四猿外。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一家上市公司的技术总监，管理的技术团队一百余人。想了解我如何管理团队——&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MTg3NDYwNg==&amp;amp;mid=2247485282&amp;amp;idx=1&amp;amp;sn=f368ffae1845809ccf06859f988a88a8&amp;amp;chksm=fcd8cb23cbaf4235db644759c3d8099045d10fc952b950d429e4a5e07ed9a806fddf85c451d3&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;我，管理100多人团队的二三事&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我从一名非计算机专业的毕业生，转行到程序员，一路打拼，一路成长。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我会通过公众号，&lt;br/&gt;把自己的成长故事写成文章，&lt;br/&gt;把枯燥的技术文章写成故事。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我建了一个读者交流群，里面大部分是程序员，一起聊技术、工作、八卦。欢迎加我微信，拉你入群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.9852216748768473&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/6nbNnibOq5KQibCDibpTo0kqofPehQvDDibibcb3bQUELdY3Knsl4r0RcgsV9l4icr3icmZQfaBXtSFNTxmdQlAZT1OQg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;609&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>