<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>f225165eb4281236baddef64a03ab3e2</guid>
<title>Redis 集群 JedisCluster 的 pipeline 自定义实现</title>
<link>https://toutiao.io/k/y3b2owg</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;h1&gt;前言&lt;/h1&gt;

&lt;p&gt;2020年4月30日，Redis 6.0.0正式发布，标志着redis从此告别单线程。在此之前，在大数据生产环境中使用的是一个30个节点的Codis集群，SparkStreaming以此作为缓存，QPS高峰大概在2000w/s。&lt;/p&gt;

&lt;p&gt;因为Codis不再更新迭代，于是在Redis 6.0.6版本发布的时候搭建了Redis Cluster，新的应用将不再使用Codis。之前连接Codis使用的Java客户端是Jedis，通过Pipeline方式批次执行命令，以此来提高效率。而Redis Cluster的客户端JedisCluster没有提供Pipeline方式，只能单条执行命令，于是开始考虑其他的Java客户端。&lt;/p&gt;

&lt;p&gt;这里备选了两个客户端：&lt;strong&gt;lettuce&lt;/strong&gt;和&lt;strong&gt;Redisson&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;pipeline原理&lt;/h2&gt;

&lt;p&gt;这里先说一下Jedis的pipeline的原理。通过pipeline对redis的所有操作命令，都会先放到一个List中，当pipeline直接执行或者通过jedis.close()调用sync()的时候，所有的命令都会一次性地发送到客户端，并且每个操作命令返回一个response，通过get来获取操作结果。&lt;/p&gt;

&lt;h1&gt;lettuce&lt;/h1&gt;

&lt;p&gt;lettuce提供了async异步方式来实现pipeline的功能，来测试一下是否可按批次处理命令。&lt;/p&gt;

&lt;p&gt;测试代码：&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt;public static void main(String[] args) throws Exception {
        RedisURI uri = RedisURI.builder()
                .withHost(&quot;47.102.xxx.xxx&quot;)
                .withPassword(&quot;Redis6.0.6&quot;.toCharArray())
                .withPort(10001)
                .build();
        RedisClusterClient client = RedisClusterClient.create(uri);
        StatefulRedisClusterConnection&amp;lt;String, String&amp;gt; connect = client.connect();
        RedisAdvancedClusterAsyncCommands&amp;lt;String, String&amp;gt; async = connect.async();
        // 断点1
        async.set(&quot;key1&quot;, &quot;v1&quot;);
        Thread.sleep(1000 * 3);
        // 断点2
        async.set(&quot;key2&quot;, &quot;v2&quot;);
        // 断点3
        async.flushCommands();
        Thread.sleep(1000 * 3);
        connect.close();
        client.shutdown();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在程序中设置三个断点。如果是pipeline的话，只有执行完断点3，两条set命令才会执行。
运行结果：
&lt;img src=&quot;https://img-blog.csdnimg.cn/20201214092218858.png&quot; alt=&quot;运行结果&quot;/&gt;
结果表明还未到flushCommands()，第一个set命令已经执行。到这你可能就会以为lettuce其实还是逐条命令执行，只是开启了异步请求模式。其实不然，在lettuce异步操作中，默认开启了&lt;strong&gt;命令自动刷新&lt;/strong&gt;功能，所以给你的假象还是逐条执行，在此需要&lt;strong&gt;禁用自动刷新&lt;/strong&gt;来开启pipeline功能。&lt;/p&gt;

&lt;p&gt;在set()之前加上一行代码：&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt;async.setAutoFlushCommands(false);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;运行结果：
&lt;img src=&quot;https://img-blog.csdnimg.cn/20201214094221395.png&quot; alt=&quot;运行结果&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;Redisson&lt;/h1&gt;

&lt;p&gt;redisson提供了batch来实现pipeline的功能。&lt;/p&gt;

&lt;p&gt;测试代码:&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt; Config config = new Config();
 config.useClusterServers()
       .addNodeAddress(&quot;redis://47.102.219.86:10001&quot;)
       .setPassword(&quot;Redis@6.0.6&quot;);
 RedissonClient redisson = Redisson.create(config);
 RBatch batch = redisson.createBatch();
 String key = &quot;test&quot;;
 for (int i = 1; i &amp;lt; 3; i++) {
      batch.getMap(key + i).putAsync(String.valueOf(i), String.valueOf(i));
    }
 // 打上断点
 batch.execute();
 redisson.shutdown();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里我们在execute()处打上断点，debug运行程序。
运行结果：
&lt;img src=&quot;https://img-blog.csdnimg.cn/202012140047268.png&quot; alt=&quot;执行结果&quot;/&gt;
结果表明Redisson会将命令放在一个batch中，当执行execute()时，会将命令一次性发送到redis执行。虽然Redisson实现了pipeline的功能，但是我最后还是放弃了它。原因很简单，它的方法不像jedis和lettuce一样简单明了，和redis的操作命令相差太多，导致使用起来比较繁琐。&lt;/p&gt;

&lt;h1&gt;Jedis Cluster Pipeline&lt;/h1&gt;

&lt;h2&gt;原因&lt;/h2&gt;

&lt;p&gt;开头也提到了，Jedis对Redis Cluster提供了JedisCluster客户端，但是没有Pipeline模式，那么JedisCluster为什么不支持Pipeline？&lt;/p&gt;

&lt;p&gt;在redis中一共有16384个Slot，每个节点负责一部分Slot，当对Key进行操作时，redis会通过&lt;em&gt;CRC16&lt;/em&gt;计算出key对应的Slot，将Key映射到Slot所在节点上执行操作。&lt;/p&gt;

&lt;p&gt;因为不同Key映射的节点不同，所以JedisCluster需要持有Redis Cluster每个节点的连接才能执行操作，而Pipeline是面向于一个redis连接的执行模式，所以JedisCluster无法支持Pipeline。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;那么我们自己有没有办法利用JedisCluster去封装一个具有Pipeline模式的客户端？&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;思路&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;刚刚提到，JedisCluster会持有Redis Cluster所有节点的连接&lt;/strong&gt;。那么，如果我们可以获取到所有节点的连接，对每个节点的连接都开启Pipeline。首先计算出每个Key所在的Slot，再找到Slot对应节点，就可以将Key放到对应节点连接的Pipeline上，这样不就实现了集群版的Pipeline了么！&lt;/p&gt;

&lt;p&gt;我们要做的工作就是找到对应关系，将每个Key分配到对应的节点连接中。&lt;/p&gt;

&lt;p&gt;秉着不重复造轮子的观点，我们先看看JedisCluster是如何执行命令的？&lt;/p&gt;

&lt;h2&gt;JedisCluster&lt;/h2&gt;

&lt;p&gt;先写样例，并在get()处打断点。
&lt;img src=&quot;https://img-blog.csdnimg.cn/2020121509471542.png&quot; alt=&quot;JedisCluster&quot;/&gt;
 &lt;img src=&quot;https://img-blog.csdnimg.cn/2020121510133387.png&quot; alt=&quot;run()&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;CRC16&lt;/h3&gt;

&lt;p&gt;进入run()，可以看到JedisClusterCRC16提供了getSlot()方法，&lt;strong&gt;可以计算出Key所在的Slot&lt;/strong&gt;。
&lt;img src=&quot;https://img-blog.csdnimg.cn/20201215102154264.png&quot; alt=&quot;run()&quot;/&gt;&lt;/p&gt;

&lt;p&gt;run()里面调用了runWithRetries()，这是核心方法之一，Step into&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt;// 据方法调用参数删除了部分代码
private T runWithRetries(final int slot, int attempts, boolean tryRandomNode, JedisRedirectionException redirect) {
    Jedis connection = null;
    try {
        // false
        if (tryRandomNode) {
            connection = connectionHandler.getConnection();
        } else {
            // 重点：从方法名看，是根据slot来获取jedis连接！！
            connection = connectionHandler.getConnectionFromSlot(slot);
        }
        return execute(connection);
    } catch (JedisNoReachableClusterNodeException jnrcne) {
      throw jnrcne;
    } catch (JedisConnectionException jce) {
      // 释放连接
      releaseConnection(connection);
      connection = null;
      if (attempts &amp;lt;= 1) {
        // 刷新slots
        this.connectionHandler.renewSlotCache();
      }
      return runWithRetries(slot, attempts - 1, tryRandomNode, redirect);
    } 
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从runWithRetries()可以看到，JedisCluster通过调用getConnectionFromSlot(slot)来获取jedis连接，这里&lt;strong&gt;实现了Slot和Jedis的关系&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;那么connectionHandler为什么可以提供redis连接？&lt;/em&gt;&lt;/p&gt;

&lt;h3&gt;connectionHandler&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;查看connectionHandler变量信息&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201215145801307.png&quot; alt=&quot;connectionHandler&quot;/&gt;
可以看到它有一个JedisClusterInfoCache类型的成员变量cache，cache有两个HashMap类型的成员变量nodes和slots，nodes保存节点和JedisPool的映射关系，slots保存16384个slot和JedisPool的映射关系，这里&lt;strong&gt;slot和节点实现了映射关系&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;接着看一下getConnectionFromSlot()&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20201215155826851.png&quot; alt=&quot;getConnectionFromSlot()&quot;/&gt;
&lt;img src=&quot;https://img-blog.csdnimg.cn/20201215162754242.png&quot; alt=&quot;getSlotPool()&quot;/&gt;
可以看出，cache调用getSlotPool()，从成员变量slots中通过slot取到了相应节点的JedisPool。&lt;/p&gt;

&lt;p&gt;简单的画一下流程图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/202012151706329.png&quot; alt=&quot;流程图&quot;/&gt;&lt;/p&gt;

&lt;p&gt;至此，所有轮子都已经具备，开始造车。
&lt;img src=&quot;https://img-blog.csdnimg.cn/20201216160632824.jpg&quot; alt=&quot;Pipeline&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;实现Pipeline&lt;/h1&gt;

&lt;p&gt;我们只要获取到connectionHandler变量，就可以使用它的成员变量cache来获取Jedis。&lt;/p&gt;

&lt;p&gt;connectionHandler是JedisCluster的成员变量，在其父类BinaryJedisCluster中找到了此变量。
&lt;img src=&quot;https://img-blog.csdnimg.cn/20201215174630762.png&quot; alt=&quot;BinaryJedisCluster&quot;/&gt;
cache是connectionHandler的成员变量，在其父类JedisClusterConnectionHandler找到了此变量。
&lt;img src=&quot;https://img-blog.csdnimg.cn/20201215175345852.png&quot; alt=&quot;JedisClusterConnectionHandler&quot;/&gt;
connectionHandler和cache都是protected变量，外部类无法直接访问，所以需要定义子类访问变量。&lt;/p&gt;

&lt;h2&gt;自定义ConnectionHandler&lt;/h2&gt;

&lt;p&gt;目的：使用cache保存的Cluster信息，用其来获取JedisPool。&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt;public class JedisSlotConnectionHandlerImp extends JedisSlotBasedConnectionHandler implements Serializable {
    public JedisSlotConnectionHandlerImp(Set&amp;lt;HostAndPort&amp;gt; nodes, GenericObjectPoolConfig poolConfig, int connectionTimeout, int soTimeout, String password) {
        super(nodes, poolConfig, connectionTimeout, soTimeout, password);
    }

    // 自定义通过slot获取JedisPool的方法
    // 为了保证后面一个JedisPool只取一个Jedis
    public JedisPool getJedisPoolFromSlot(int slot) {
        JedisPool jedisPool = cache.getSlotPool(slot);
        if (jedisPool != null) {
            return jedisPool;
        } else {
            renewSlotCache();
            jedisPool = cache.getSlotPool(slot);
            if (jedisPool != null) {
                return jedisPool;
            } else {
                throw new JedisNoReachableClusterNodeException(&quot;No reachable node in cluster for slot &quot; + slot);
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;自定义ClusterPipeline&lt;/h2&gt;

&lt;p&gt;目的：使用connectionHandler来建立key、slot以及JedisPool之间关系映射&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt;public class JedisClusterPipeline extends JedisCluster implements Serializable {
    // 覆盖父类中的connectionHandler
    protected JedisSlotConnectionHandlerImp connectionHandler;
    public JedisClusterPipeline(HashSet node, int connectionTimeout, int soTimeout, int maxAttempts, String password, GenericObjectPoolConfig poolConfig) {
        super(node, connectionTimeout, soTimeout, maxAttempts, password, poolConfig);
        connectionHandler = new JedisSlotConnectionHandlerImp(node, poolConfig, connectionTimeout, soTimeout, password);
    }
    // 通过key转换成slot，再获取JedisPool
    public JedisPool getJedisPoolFromSlot(String key) {
        return connectionHandler.getJedisPoolFromSlot(JedisClusterCRC16.getSlot(key));
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;使用&lt;/h2&gt;

&lt;p&gt;使用自定义的JedisClusterPipeline，需要自己实现set、get、hget等方法来覆盖父类JedisCluster对应的方法。最初的目的是应用于Spark将维度信息存入Redis Cluster，当时是用scala面向RDD的partition实现了集群版的hmset()方法。&lt;/p&gt;

&lt;p&gt;这里临时用Java实现一下Pipeline的set()方法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;实现set()&lt;/strong&gt;&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt;public class JedisClusterPipelineCommand {
    /**
     * 自定义的pipeline模式set方法
     * @param key 存放的key
     * @param value 存放的value
     * @param clusterPipeline 用来获取JedisPool
     * @param pipelines 建立JedisPool和pipeline映射，保证一个JedisPool只开启一个pipeline
     * @param jedisMap 建立pipeline和Jedis映射，用来释放Jedis
     * @param nums 记录每个pipeline放入key的条数
     * @param threshold pipeline进行sync的阈值
     */
    public static void setByPipeline(String key, String value, JedisClusterPipeline clusterPipeline, ConcurrentHashMap&amp;lt;JedisPool, Pipeline&amp;gt; pipelines, ConcurrentHashMap&amp;lt;Pipeline, Jedis&amp;gt; jedisMap,  ConcurrentHashMap&amp;lt;Pipeline, Integer&amp;gt; nums, int threshold) {
        JedisPool jedisPool = clusterPipeline.getJedisPoolFromSlot(key);
        // 查看对应节点是否已经开启了pipeline
        Pipeline pipeline = pipelines.get(jedisPool);
        if (pipeline == null) {
            Jedis jedis = jedisPool.getResource();
            pipeline = jedis.pipelined();
            // 构建映射关系，保证每个节点只有一个jedis来开启pipeline
            jedisMap.put(pipeline, jedis);
            pipelines.put(jedisPool, pipeline);
            nums.put(pipeline, 0);
        }else {
            int num = nums.get(pipeline);
            nums.put(pipeline, num + 1);
            if (num % threshold == 0) {
                pipeline.sync();
            }
        }
        pipeline.set(key, value);
    }

    /**
     * 释放jedis并强制pipeline sync
     */
    public static void releaseConnection(ConcurrentHashMap&amp;lt;Pipeline, Jedis&amp;gt; jedisMap) {
        for (Jedis jedis : jedisMap.values()) {
            jedis.close();
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;执行类&lt;/strong&gt;&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt;    public static void main(String[] args) throws Exception {
        JedisPoolConfig config = new JedisPoolConfig();
        HashSet jedisClusterNodes = new java.util.HashSet&amp;lt;HostAndPort&amp;gt;();
        jedisClusterNodes.add(new HostAndPort(&quot;47.102.xxx.xx&quot;, 10001));
        JedisClusterPipeline jedisClusterPipeline = new JedisClusterPipeline(jedisClusterNodes, 1000, 1000, 10, &quot;Redis6&quot;, config);
        ConcurrentHashMap&amp;lt;JedisPool, Pipeline&amp;gt; pipelines = new ConcurrentHashMap&amp;lt;&amp;gt;();
        ConcurrentHashMap&amp;lt;Pipeline, Jedis&amp;gt; jedisMap = new ConcurrentHashMap&amp;lt;&amp;gt;();
        ConcurrentHashMap&amp;lt;Pipeline, Integer&amp;gt; nums = new ConcurrentHashMap&amp;lt;&amp;gt;();
        for (int i = 0; i &amp;lt; 1000; i++) {
            JedisClusterPipelineCommand.setByPipeline(&quot;k&quot; + i, &quot;v&quot; + i, jedisClusterPipeline, pipelines, jedisMap, nums, 100 );
        }
        JedisClusterPipelineCommand.releaseConnection(jedisMap);
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;执行结果&lt;/strong&gt;
&lt;img src=&quot;https://img-blog.csdnimg.cn/20201216182558100.png&quot; alt=&quot;执行结果&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;性能测试&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;本机环境1000条数据&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;pipeline模式：2.32s&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;JedisCluster：68.6s&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Spark on Yarn 128w条 Hash&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;本机环境测试结果受限于网络和主机配置，仅供比较参考。&lt;/p&gt;

&lt;h1&gt;结语&lt;/h1&gt;

&lt;p&gt;最后选择自己实现pipeline，首先是因为比较了解pipeline的原理，说白了就是用习惯了。其次是在本机测试letttuce时，出现了一些意料之外的问题，目前还在探索中。下一步的工作就是慢慢的将Pipeline其他的方法实现，逐步优化，用于生产。&lt;/p&gt;

&lt;p/&gt;

&lt;hr/&gt;

&lt;p&gt;95后小程序员，写的都是日常工作中的亲身实践，置身于初学者的角度从0写到1，保证能够真正让大家看懂。&lt;/p&gt;

&lt;p&gt;文章会在公众号 [&lt;strong&gt;入门到放弃之路&lt;/strong&gt;] 首发，期待你的关注。
&lt;img src=&quot;https://img-blog.csdnimg.cn/20210519233121183.png&quot; alt=&quot;感谢每一份关注&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>5f9fdc0ffcb46679d9f498d16d1fb322</guid>
<title>消息队列解耦是骗小孩儿的</title>
<link>https://toutiao.io/k/szkr8sy</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;有一个观点已经被说烂了：使用 MQ 可以帮助业务系统解耦。&lt;/p&gt;&lt;p&gt;想法很简单，在业务状态流转时，如果没有 MQ，那么其它系统想要知道状态变了，那就需要核心流程系统去主动做通知。&lt;/p&gt;&lt;p&gt;比如电商系统里订单从创建到处理中状态切换了，客服系统需要知道，风控系统需要知道，用户系统也需要知道。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.48671875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Lq0XA1b7xbdflATJWdgiay3CIlhor3dgT38iaUtchvVtx9OZcTdiaiaCknSYibM5nE1L4jicUJqpzIg6ZcTRwB10Sh2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;一个典型的依赖关系&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这里的通知通过 RPC 来进行，下游系统需要的数据可以在这次 RPC 里携带上，也可以在请求的时候让下游系统自己去查。&lt;/p&gt;&lt;p&gt;下游系统增加的时候，核心业务的代码也需要修改，比如新做了一个积分系统，现在订单状态流转积分系统也想知道。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.48828125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Lq0XA1b7xbdflATJWdgiay3CIlhor3dgT25fwzicUU79WDDYEIsTxeSJgdFVCg97ib8SxuhftqfAL9w8vTuFN7KVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;下游增加新系统时&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;核心系统需要不停地增加调用关系来迎合下游新增的业务方需求。这些边边角角的计算逻辑和订单系统本身没啥关系，但是因为下游需要拿到这些数据，我们就需要自己用 RPC 去调用下游的接口。这确实不太合理。&lt;/p&gt;&lt;p&gt;当下游系统发生事故时，很容易让核心系统也跟着一起躺了：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.48868778280542985&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/Lq0XA1b7xbdflATJWdgiay3CIlhor3dgTicnnFibq5niaSKpJe7FqDpzTgcibo7GfwqCQcycykh5bNequo20UE1wCUQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;2210&quot;/&gt;&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;下游炸了上游也得炸&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这种情况下，核心系统对下游系统的依赖主要是因为 &lt;strong&gt;core system&lt;/strong&gt; mentions &lt;strong&gt;downstream system&lt;/strong&gt;，和单系统内的耦合是一样的。&lt;/p&gt;&lt;p&gt;解决这种耦合的最简单的方法，在单模块的情况是用依赖反转，在分布式场景下，就是引入消息队列：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.48671875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Lq0XA1b7xbdflATJWdgiay3CIlhor3dgTqxwAFJa7rRxTDmgpqmXI5E9FyJvNUHrciaXPXjkoLN3yGaH1ic3EbYDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;用消息队列解除上游对下游的依赖&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在修改之后，每次订单流转只要将 domain event 发送到消息队列就可以了。下游系统有计算需求，自己去订阅相关的 topic 即可。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.44765625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Lq0XA1b7xbdflATJWdgiay3CIlhor3dgTeNrHVJCBeg66157XERVBc2LvghaibicodrFWt7XtsbicKyfc2Zda7YgwA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;有了消息队列时下游增加新系统&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;讲到这里就结束，那就是童话故事了。在一开始的图中，我们存在的依赖是双向的：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.77265625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Lq0XA1b7xbdflATJWdgiay3CIlhor3dgToqXeXprjcxUnibW9hST0MXQ6ZiamibewMIEnTyKmJYmoDzvgMibicM9ibDoQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;双向依赖&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;核心系统依赖下游系统是因为调用关系，下游系统依赖核心系统是因为下游系统要使用核心系统的数据。&lt;/p&gt;&lt;p&gt;我们使用 MQ 只是解开了单个方向上的依赖，核心系统没有对下游系统的调用了。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.7266666666666667&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/Lq0XA1b7xbdflATJWdgiay3CIlhor3dgTSQicTBzLo6QWz3DBLZhdjhuw7PJexvRFDugWhN91Ypm59L7rrxhllZw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;900&quot;/&gt;&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;有一个方向的依赖被解除了&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这样下游系统在崩溃的时候，也就不太容易影响到核心系统的稳定性。&lt;/p&gt;&lt;h2&gt;隐式依赖导致事故&lt;/h2&gt;&lt;p&gt;但下游系统对核心系统的数据依赖是不可能解除的，如果核心系统修改了产生 domain event 的代码，还是会导致下游系统出故障，很多情况下出故障都是一死死一片：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4755905511811024&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/Lq0XA1b7xbdflATJWdgiay3CIlhor3dgT0NZ1mUy2eCWhibIkHG0ufLaaGEmP6Kzn9dhiakQOVqxK8zr6PvHfO4HA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;1270&quot;/&gt;&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;上游的 domain event 出问题的时候&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大点的互联网公司经常是核心服务一做重构，下游服务哀鸿遍野。&lt;/p&gt;&lt;p&gt;数据依赖对于核心系统来说并不是一个可以显式看到的依赖，所以对于核心系统来说，这是外部对我的隐式依赖。&lt;/p&gt;&lt;p&gt;看不见的依赖是很可怕的，所有人都会慢慢地逐渐忽视它，直到事故发生的那一天。&lt;/p&gt;&lt;h2&gt;核心系统对下游系统重新建立依赖&lt;/h2&gt;&lt;p&gt;虽然梦做的很好，但核心系统在服务用户的过程中，往往也是要给用户返回一些实时计算的数据的，这部分数据从哪里来？&lt;/p&gt;&lt;p&gt;很多就是从下游计算系统来，比如说，我的订单流转系统，现在要在用户积分达到某个条件的时候，做一些特殊逻辑。&lt;/p&gt;&lt;p&gt;随着业务的发展，我们最初解除掉的依赖，又重新被建立了。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.7397260273972602&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/Lq0XA1b7xbdflATJWdgiay3CIlhor3dgTFBs7XpcKibMfLgYdXZtM7Vpdrh9Zhic6jeSZJ6znb6tPcSjNLgCcXibiaA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;876&quot;/&gt;&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;回到原点&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;环形依赖回来了！这下两个系统可能又会变成你挂我也挂的情况了。兜兜转转，我们重新回到了原点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>770fd86d689bf868c819d3c0b163e8be</guid>
<title>搜狗面试题：IO 多路复用之 select、poll、epoll 的区别</title>
<link>https://toutiao.io/k/d6e55fr</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;section data-support=&quot;96编辑器&quot; data-style-id=&quot;26075&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-form=&quot;0&quot; data-num=&quot;1&quot;&gt;01&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;select&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;int select (int n, fd_set *readfds, fd_set *writefds, &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;                   fd_set *exceptfds, struct timeval *timeout);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;// fd_set 结构体简化为：&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;typedef struct{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    long int fds_bits[32];&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}fd_set;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、 单个进程可监视的&lt;/span&gt;&lt;span&gt;fd数量被限制&lt;/span&gt;&lt;span&gt;，即能监听端口的大小有限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、 对socket进行扫描时是&lt;/span&gt;&lt;span&gt;线性扫描&lt;/span&gt;&lt;span&gt;，即采用轮询的方法，效率较低：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、需要维护一个用来存放大量fd的数据结构，每次调用select时把fd集合从&lt;/span&gt;&lt;span&gt;用户态拷贝到内核态&lt;/span&gt;&lt;span&gt;，这样会使得&lt;/span&gt;&lt;span&gt;用户空间和内核空间&lt;/span&gt;&lt;span&gt;在传递该结构时复制&lt;/span&gt;&lt;span&gt;开销大&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-support=&quot;96编辑器&quot; data-style-id=&quot;26075&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-form=&quot;0&quot; data-num=&quot;2&quot;&gt;02&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;poll&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cpp&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;int poll (struct pollfd *fds, unsigned int nfds, int timeout);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;struct pollfd {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    int fd; /* file descriptor */&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    short events; /* requested events to watch */ // 请求监视的事件&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    short revents; /* returned events witnessed */ // 返回发生的事件&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;};&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;和select没有区别，它将用户传入的&lt;/span&gt;&lt;span&gt;数组拷贝到内核空间&lt;/span&gt;&lt;span&gt;，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次&lt;/span&gt;&lt;span&gt;无谓的遍历&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;它没有最大连接数的限制，原因是它是基于&lt;/span&gt;&lt;span&gt;链表&lt;/span&gt;&lt;span&gt;来存储的。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;缺点：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;1、大量的fd的数组被整体复制于&lt;/span&gt;&lt;span&gt;用户态和内核&lt;/span&gt;&lt;span&gt;地址空间之间，而不管这样的复制是不是有意义。                   &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、poll还有一个特点是“&lt;/span&gt;&lt;span&gt;水平触发&lt;/span&gt;&lt;span&gt;”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;LT模式&lt;/span&gt;：level trigger。当epoll_wait检测到描述符事件发生并将此事件通知应用程序，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;ET模式&lt;/span&gt;：edge trigger。当epoll_wait检测到描述符事件发生并将此事件通知应用程序，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。&lt;/span&gt;&lt;/p&gt;&lt;section data-support=&quot;96编辑器&quot; data-style-id=&quot;26075&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-form=&quot;0&quot; data-num=&quot;3&quot;&gt;03&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;epoll&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;int epoll_create(int size)；&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;epoll_create&lt;/span&gt;：创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大。参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;epoll_ctl&lt;/span&gt;：对指定描述符fd执行op操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;-epfd：是epoll_create()的返回值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;-op操作：对应宏：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD，对应添加、删除和修改对fd的监听事件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;- fd：是需要监听的fd（文件描述符）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;- epoll_event：是告诉内核需要监听什么事件（读、写事件等）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;epoll_wait&lt;/span&gt;：等待epfd上的io事件，最多返回maxevents个事件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;-events：用来从内核得到事件的集合，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;-maxevents：告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;-timeout：是超时时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式。LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作，而在ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读光，也就是说一直读到read的返回值小于请求值，或者遇到EAGAIN错误。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;epoll为什么要有EPOLLET触发模式？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;如果采用EPOLLLT模式的话，系统中一旦有大量你不需要读写的就绪文件描述符，它们每次调用epoll_wait都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率.。而采用EPOLLET这种边沿触发模式的话，当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你！！！&lt;strong&gt;这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符。&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;epoll优点&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;1、&lt;span&gt;没有最大并发连接的限制&lt;/span&gt;，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、&lt;span&gt;效率提升&lt;/span&gt;，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;span&gt;即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、 &lt;span&gt;内存拷贝&lt;/span&gt;，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。&lt;/span&gt;&lt;/p&gt;&lt;mpcpc js_editor_cpcad=&quot;&quot; class=&quot;js_cpc_area cpc_iframe&quot; src=&quot;/cgi-bin/readtemplate?t=tmpl/cpc_tmpl#1620212822188&quot; data-category_id_list=&quot;1|11|16|17|22|24|26|27|28|29|3|31|32|35|36|37|39|41|42|43|45|46|47|48|49|5|50|51|52|53|54|55|6|7|8&quot; data-id=&quot;1620212822188&quot;/&gt;&lt;section data-support=&quot;96编辑器&quot; data-style-id=&quot;26075&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span data-form=&quot;0&quot; data-num=&quot;3&quot;&gt;04&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;区别&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;0、底层数据结构&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;select：数组，poll：链表，epoll：红黑树。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;1、支持一个进程所能打开的最大连接数&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;select 单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是32*32，同理64位机器上FD_SETSIZE为32*64），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;poll本质上和select没有区别，但是它&lt;/span&gt;&lt;span&gt;没有最大连接数的限制&lt;/span&gt;&lt;span&gt;，原因是它是基于&lt;/span&gt;&lt;span&gt;链表&lt;/span&gt;&lt;span&gt;来存储的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;epoll 虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2、FD剧增后带来的IO效率问题&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;select/poll 因为每次调用时都会对连接进行&lt;/span&gt;&lt;span&gt;线性遍历&lt;/span&gt;&lt;span&gt;，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;epoll 因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;3、消息传递方式&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;select/poll 内核需要将消息传递到用户空间，都需要内核拷贝动作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;epoll通过内核和用户空间共享一块内存来实现的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;select、poll与epoll之间的区别总结图：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.7448478900883219&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5hLBZVCyG9Shnibm5jEufxcKolbr2yZNkuJhynJkX2wtHHABXcIib7OqyctYkrWd6sLGEHia2ibFD1lTgmeKgFKkicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1019&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;历史背景&lt;/strong&gt;：&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;152&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;p&gt;&lt;span&gt;1）select出现是1984年在BSD里面实现的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）14年之后也就是1997年才实现了poll，其实拖那么久也不是效率问题， 而是那个时代的硬件实在太弱，一台服务器处理1千多个链接简直就是神一样的存在了，select很长段时间已经满足需求 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）2002, 大神 Davide Libenzi 实现了epoll。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考资料：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.cnblogs.com/Anker/p/3265058.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.cnblogs.com/aspirant/p/9166944.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://www.cnblogs.com/dhcn/p/12731883.html&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;笔记系列&lt;img class=&quot;rich_pages&quot; data-backh=&quot;253&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.43684992570579495&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/5hLBZVCyG9Trgib1F9icTlVo1xlHsH3QgErvpia4d7jHeibicNaK6q8eNgCnxLbldROsqeicufA3wTJThStjKJM44QIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;673&quot;/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5NTUzNTA2Mw==&amp;amp;mid=2454934251&amp;amp;idx=1&amp;amp;sn=77f210efd1960589975422e9000fb9e4&amp;amp;chksm=871a1853b06d9145c104c8ba9b7ef6df9e223ce227048422359be76a334c2c9adc4e822f9c29&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Java对象探秘&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;笔记 | Java对象探秘&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5NTUzNTA2Mw==&amp;amp;mid=2454934264&amp;amp;idx=1&amp;amp;sn=9c08f626d627122645c78c18563c4cf9&amp;amp;chksm=871a1840b06d9156e3bbea12e17d5fff668b4c717005be6c7462cfd746b3af1961e423faf27f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;JVM内存区域结构：一计两栈一堆一区&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;笔记 | JVM内存区域结构：一计两栈一堆一区&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5NTUzNTA2Mw==&amp;amp;mid=2454934346&amp;amp;idx=1&amp;amp;sn=4067d49c5e56f5a805a46c7e6daebd8c&amp;amp;chksm=871a19f2b06d90e4ab8f3b4d9b4a1fdabd7f4ec91493a8fbc0572334b2ef97b6f1a57f96ba5a&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;笔记 | 面试官问我：TCP与UDP的区别&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5NTUzNTA2Mw==&amp;amp;mid=2454934425&amp;amp;idx=1&amp;amp;sn=7ca25eafb3098ff3e2b5f98ce323be47&amp;amp;chksm=871a1921b06d9037257e123d7646141e936b53bbba448bed35b13b288132410426e4854c36b4&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;笔记 | 网络编程基础：TCP如何保证可靠性&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5NTUzNTA2Mw==&amp;amp;mid=2454934505&amp;amp;idx=1&amp;amp;sn=388f9b70b5e5a1791f79ba66de471152&amp;amp;chksm=871a1951b06d9047bc697fdd4c912fb61783a17d45dd7f409819147576573bb6493449f56869&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;笔记 | 面试又挂了，只因问了：TCP三次握手和四次挥手&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5NTUzNTA2Mw==&amp;amp;mid=2454934925&amp;amp;idx=1&amp;amp;sn=15d7e4482090f917f3e8ecb5420e56b5&amp;amp;chksm=871a1f35b06d962346ba631dcd098f74118872f95c00ada3091e9e2cd3fb7152078388fc2dab&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;笔记 | 5种网络IO模型&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a15716414d6fe7b54ae9cba0deca719f</guid>
<title>面试侃集合：SynchronousQueue 公平模式篇</title>
<link>https://toutiao.io/k/bv8je05</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;面试官：呦，小伙子来的挺早啊！&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hydra：那是，不能让您等太久了啊（别废话了快开始吧，还赶着去下一场呢）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;面试官：前面两轮表现还不错，那我们今天继续说说队列中的&lt;/strong&gt;&lt;/span&gt;&lt;code&gt;SynchronousQueue&lt;/code&gt;&lt;span&gt;&lt;strong&gt;吧。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hydra：好的，&lt;code&gt;SynchronousQueue&lt;/code&gt;和之前介绍过的队列相比，稍微有一些特别，必须等到队列中的元素被消费后，才能继续向其中添加新的元素，因此它也被称为无缓冲的等待队列。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我还是先写一个例子吧，创建两个线程，生产者线程&lt;code&gt;putThread&lt;/code&gt;向&lt;code&gt;SynchronousQueue&lt;/code&gt;中放入元素，消费者线程&lt;code&gt;takeThread&lt;/code&gt;从中取走元素：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;SynchronousQueue&amp;lt;Integer&amp;gt; queue=&lt;span&gt;new&lt;/span&gt; SynchronousQueue&amp;lt;&amp;gt;(&lt;span&gt;true&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;Thread putThread=&lt;span&gt;new&lt;/span&gt; Thread(()-&amp;gt;{&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt;= &lt;span&gt;2&lt;/span&gt;; i++) {&lt;br/&gt;        &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;            System.out.println(&lt;span&gt;&quot;put thread put:&quot;&lt;/span&gt;+i);&lt;br/&gt;            queue.put(i);&lt;br/&gt;            System.out.println(&lt;span&gt;&quot;put thread put:&quot;&lt;/span&gt;+i+&lt;span&gt;&quot; awake&quot;&lt;/span&gt;);&lt;br/&gt;        } &lt;span&gt;catch&lt;/span&gt; (InterruptedException e) {&lt;br/&gt;            e.printStackTrace();&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;});&lt;br/&gt;Thread takeThread=&lt;span&gt;new&lt;/span&gt; Thread(()-&amp;gt;{&lt;br/&gt;    &lt;span&gt;int&lt;/span&gt; j=&lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt;(j&amp;lt;&lt;span&gt;2&lt;/span&gt;){&lt;br/&gt;        &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;            j=queue.take();&lt;br/&gt;            System.out.println(&lt;span&gt;&quot;take from putThread:&quot;&lt;/span&gt;+j);&lt;br/&gt;        } &lt;span&gt;catch&lt;/span&gt; (InterruptedException e) {&lt;br/&gt;            e.printStackTrace();&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;});&lt;br/&gt;&lt;br/&gt;putThread.start();&lt;br/&gt;Thread.sleep(&lt;span&gt;1000&lt;/span&gt;);&lt;br/&gt;takeThread.start();&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;执行上面的代码，查看结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;put thread put:0&lt;br/&gt;take from putThread:0&lt;br/&gt;put thread put:0 awake&lt;br/&gt;put thread put:1&lt;br/&gt;take from putThread:1&lt;br/&gt;put thread put:1 awake&lt;br/&gt;put thread put:2&lt;br/&gt;take from putThread:2&lt;br/&gt;put thread put:2 awake&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到，生产者线程在执行&lt;code&gt;put&lt;/code&gt;方法后就被阻塞，直到消费者线程执行&lt;code&gt;take&lt;/code&gt;方法对队列中的元素进行了消费，生产者线程才被唤醒，继续向下执行。简单来说运行流程是这样的：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicbGc3kYsT3lpcicdvCVLO1DUj5dW0TxTG9L0OrKprMcWdyPCnuRVnQcR0uYlS6oBkDicmP6g5PqGWZg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-ratio=&quot;0.3780487804878049&quot; data-w=&quot;820&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;面试官：就这？应用谁不会啊&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;，不讲讲底层原理就想蒙混过&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;关？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hydra：别急啊，我们先从它的构造函数说起，根据参数不同，&lt;code&gt;SynchronousQueue&lt;/code&gt;分为公平模式和非公平模式，默认情况下为非公平模式&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;SynchronousQueue&lt;/span&gt;(&lt;span&gt;boolean&lt;/span&gt; fair) &lt;/span&gt;{&lt;br/&gt;    transferer = fair ? &lt;span&gt;new&lt;/span&gt; TransferQueue&amp;lt;E&amp;gt;() : &lt;span&gt;new&lt;/span&gt; TransferStack&amp;lt;E&amp;gt;();&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们先来看看公平模式吧，该模式下底层使用的是&lt;code&gt;TransferQueue&lt;/code&gt;队列，内部节点由&lt;code&gt;QNode&lt;/code&gt;构成，定义如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;volatile&lt;/span&gt; QNode next;          &lt;span&gt;// next node in queue&lt;/span&gt;&lt;br/&gt;&lt;span&gt;volatile&lt;/span&gt; Object item;         &lt;span&gt;// CAS&#x27;ed to or from null&lt;/span&gt;&lt;br/&gt;&lt;span&gt;volatile&lt;/span&gt; Thread waiter;       &lt;span&gt;// to control park/unpark&lt;/span&gt;&lt;br/&gt;&lt;span&gt;final&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; isData;&lt;br/&gt;QNode(Object item, &lt;span&gt;boolean&lt;/span&gt; isData) {&lt;br/&gt;    &lt;span&gt;this&lt;/span&gt;.item = item;&lt;br/&gt;    &lt;span&gt;this&lt;/span&gt;.isData = isData;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;item&lt;/code&gt;用来存储数据，&lt;code&gt;isData&lt;/code&gt;用来区分节点是什么类型的线程产生的，&lt;code&gt;true&lt;/code&gt;表示是生产者，&lt;code&gt;false&lt;/code&gt;表示是消费者，是后面用来进行节点&lt;strong&gt;匹配&lt;/strong&gt;（&lt;code&gt;complementary&lt;/code&gt; ）的关键。在&lt;code&gt;SynchronousQueue&lt;/code&gt;中匹配是一个非常重要的概念，例如一个线程先执行&lt;code&gt;put&lt;/code&gt;产生了一个节点放入队列，另一个线程再执行&lt;code&gt;take&lt;/code&gt;产生了一个节点，这两个不同类型的节点就可以匹配成功。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;面试官：可是我看很多资料里说&lt;/strong&gt;&lt;/span&gt;&lt;code&gt;SynchronousQueue&lt;/code&gt;&lt;span&gt;&lt;strong&gt;是一个不存储元素的阻塞队&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;列，这点你是怎么理解的？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hydra：通过上面节点中封装的属性，可以看出&lt;code&gt;SynchronousQueue&lt;/code&gt;的队列中封装的节点更多针对的不是数据，而是要执行的操作，个人猜测这个说法的出发点就是队列中存储的节点更多偏向于操作这一属性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;面&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;试官：好吧，接着往下说队列的结构吧。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hydra：&lt;code&gt;TransferQueue&lt;/code&gt;中主要定义的属性有下面这些：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;transient&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt; QNode head;&lt;br/&gt;&lt;span&gt;transient&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt; QNode tail;&lt;br/&gt;&lt;span&gt;transient&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt; QNode cleanMe;&lt;br/&gt;TransferQueue() {&lt;br/&gt;    QNode h = &lt;span&gt;new&lt;/span&gt; QNode(&lt;span&gt;null&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;); &lt;span&gt;// initialize to dummy node.&lt;/span&gt;&lt;br/&gt;    head = h;&lt;br/&gt;    tail = h;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比较重要的有头节点&lt;code&gt;head&lt;/code&gt;、尾节点&lt;code&gt;tail&lt;/code&gt;、以及用于标记下一个要删除的节点的&lt;code&gt;cleanMe&lt;/code&gt;节点。在构造函数初始化中创建了一个节点，注释中将它称为&lt;code&gt;dummy node&lt;/code&gt;，也就是伪造的节点，它的作用类似于&lt;code&gt;AQS&lt;/code&gt;中的头节点的作用，实际操作的节点是它的下一个节点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要说&lt;code&gt;SynchronousQueue&lt;/code&gt;，真是一个神奇的队列，不管你调用的是&lt;code&gt;put&lt;/code&gt;和&lt;code&gt;offer&lt;/code&gt;，还是&lt;code&gt;take&lt;/code&gt;和&lt;code&gt;poll&lt;/code&gt;，它都一概交给核心的&lt;code&gt;transfer&lt;/code&gt;方法去处理，只不过参数不同。今天我们抛弃源码，通过画图对它进行分析，首先看一下方法的定义：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;E &lt;span&gt;transfer&lt;/span&gt;(E e, &lt;span&gt;boolean&lt;/span&gt; timed, &lt;span&gt;long&lt;/span&gt; nanos)&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;面&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;试官：呦呵，就一个方法？我倒要看看它是怎么区分实现的入队和出队操作…&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hydra：在方法的参数中，&lt;code&gt;timed&lt;/code&gt;和&lt;code&gt;nanos&lt;/code&gt;用于标识调用&lt;code&gt;transfer&lt;/code&gt;的方法是否是能够超时退出的，而&lt;code&gt;e&lt;/code&gt;是否为空则可以说明是生产者还是消费者调用的此方法。如果&lt;code&gt;e&lt;/code&gt;不为&lt;code&gt;null&lt;/code&gt;，是生产者调用，如果&lt;code&gt;e&lt;/code&gt;为&lt;code&gt;null&lt;/code&gt;则是消费者调用。方法的整体逻辑可以分为下面几步：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1&lt;/strong&gt;、若队列为空，或队列中的尾节点类型和自己的类型相同，那么准备封装一个新的&lt;code&gt;QNode&lt;/code&gt;添加到队列中。在添加新节点到队尾的过程中，并没有使用&lt;code&gt;synchronized&lt;/code&gt;或&lt;code&gt;ReentrantLock&lt;/code&gt;，而是通过&lt;code&gt;CAS&lt;/code&gt;来保证线程之间的同步。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在添加新的&lt;code&gt;QNode&lt;/code&gt;到队尾前，会首先判断之前取到的尾节点是否发生过改变，如果有改变的话那么放弃修改，进行自旋，在下一次循环中再次判断。当检查队尾节点没有发生改变后，构建新的节点&lt;code&gt;QNode&lt;/code&gt;，并将它添加到队尾。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicbGc3kYsT3lpcicdvCVLO1DUy4ibuEKt2q4zpfAqIrg1wDkLjfBEYKn1PUoPhiaiaWJWZXA8nTqZtSVjQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-ratio=&quot;0.5697674418604651&quot; data-w=&quot;860&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2&lt;/strong&gt;、当新节点被添加到队尾后，会调用&lt;code&gt;awaitFulfill&lt;/code&gt;方法，会根据传递的参数让线程进行自旋或直接挂起。方法的定义如下，参数中的&lt;code&gt;timed&lt;/code&gt;为&lt;code&gt;true&lt;/code&gt;时，表示这是一个有等待超时的方法。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;Object &lt;span&gt;awaitFulfill&lt;/span&gt;(QNode s, E e, &lt;span&gt;boolean&lt;/span&gt; timed, &lt;span&gt;long&lt;/span&gt; nanos)&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在&lt;code&gt;awaitFulfill&lt;/code&gt;方法中会进行判断，如果新节点是&lt;code&gt;head&lt;/code&gt;节点的下一个节点，考虑到可能很快它就会完成匹配后出队，先不将它挂起，进行一定次数的自旋，超过自旋次数的上限后再进行挂起。如果不是&lt;code&gt;head&lt;/code&gt;节点的下一个节点，避免自旋造成的资源浪费，则直接调用&lt;code&gt;park&lt;/code&gt;或&lt;code&gt;parkNanos&lt;/code&gt;挂起线程。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicY21VhDjK3Faf4WjynvibMcqc1Uw3cGF4UBib7DKMruHQZzocgOicyem0hMOxxKVzwXRvGkoEnDW1dpA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-ratio=&quot;0.4883720930232558&quot; data-w=&quot;860&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;3&lt;/strong&gt;、当挂起的线程被中断或到达超时时间，那么需要将节点从队列中进行移除，这时会执行&lt;code&gt;clean()&lt;/code&gt;方法。如果要被删除的节点不是链表中的尾节点，那么比较简单，直接使用&lt;code&gt;CAS&lt;/code&gt;替换前一个节点的&lt;code&gt;next&lt;/code&gt;指针。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.37681159420289856&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicbvib2dIHQAiaKBhgn6ykEhw8UM2xqX1etXlJ9qYWuLo8UHclgaJjtHibtAic28EbPBcIB3QafnVS87qQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;690&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果要删除的节点是链表中的尾节点，就会有点复杂了，因为多线程环境下可能正好有其他线程正在向尾节点后添加新的节点，这时如果直接删除尾节点的话，会造成后面节点的丢失。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时候就会用到&lt;code&gt;TransferQueue&lt;/code&gt;中定义的&lt;code&gt;cleanMe&lt;/code&gt;标记节点了，&lt;code&gt;cleanMe&lt;/code&gt;的作用就是当要被移除的节点是队尾节点时，用它来标记队尾节点的前驱节点。具体在执行过程中，又会分为两种情况：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;cleanMe&lt;/code&gt;节点为&lt;code&gt;null&lt;/code&gt;，说明队列在之前没有标记需要删除的节点。这时会使用&lt;code&gt;cleanMe&lt;/code&gt;来标识该节点的前驱节点，标记完成后退出&lt;code&gt;clean&lt;/code&gt;方法，当下一次执行&lt;code&gt;clean&lt;/code&gt;方法时才会删除&lt;code&gt;cleanMe&lt;/code&gt;的下一个节点。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5666666666666667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicbvib2dIHQAiaKBhgn6ykEhw8LrjJO9x2YtdQRt4T275hbGQWeSqsJnibgyqmRfnUcBbtyAOF9qqnuQg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;600&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;cleanMe&lt;/code&gt;节点不为&lt;code&gt;null&lt;/code&gt;，那么说明之前已经标记过需要删除的节点。这时删除&lt;code&gt;cleanMe&lt;/code&gt;的下一个节点，并清除当前&lt;code&gt;cleanMe&lt;/code&gt;标记，并再将当前节点&lt;strong&gt;未修改前的&lt;/strong&gt;前驱节点标记为&lt;code&gt;cleanMe&lt;/code&gt;。注意，当前要被删除的节点的前驱节点不会发生改变，即使这个前驱节点已经在逻辑上从队列中删除掉了。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicbvib2dIHQAiaKBhgn6ykEhw8h8VWxgSlHNYcWLFJatp51ib3pFnbqnKUkMVD82YsHuIianv1tbyAPPmw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-ratio=&quot;0.46511627906976744&quot; data-w=&quot;860&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;执行完成&lt;code&gt;clean&lt;/code&gt;方法后，&lt;code&gt;transfer&lt;/code&gt;方法会直接返回&lt;code&gt;null&lt;/code&gt;，说明入队操作失败。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;面&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;试官：讲了这么多，入队的还都是一个类型的节点吧？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hydra：是的，&lt;code&gt;TransferQueue&lt;/code&gt;队列中，只会存在一个类型的节点，如果有另一个类型的节点过来，那么就会执行出队的操作了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;面&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;试官：好吧，那你接着再说说出队方法吧。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hydra：相对入队来说，出队的逻辑就比较简单了。因为现在使用的是公平模式，所以当队列不为空，且队列的&lt;code&gt;head&lt;/code&gt;节点的下一个节点与当前节点匹配成功时，进行出队操作，唤醒&lt;code&gt;head&lt;/code&gt;节点的下一个节点，进行数据的传递。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据队列中节点类型的不同，可以分为两种情况进行分析：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1&lt;/strong&gt;、如果&lt;code&gt;head&lt;/code&gt;节点的下一个节点是&lt;code&gt;put&lt;/code&gt;类型，当前新节点是&lt;code&gt;take&lt;/code&gt;类型。&lt;code&gt;take&lt;/code&gt;线程取出&lt;code&gt;put&lt;/code&gt;节点的&lt;code&gt;item&lt;/code&gt;的值，并将其&lt;code&gt;item&lt;/code&gt;变为&lt;code&gt;null&lt;/code&gt;，然后推进头节点，唤醒被挂起的&lt;code&gt;put&lt;/code&gt;线程，&lt;code&gt;take&lt;/code&gt;线程返回&lt;code&gt;item&lt;/code&gt;的值，完成数据的传递过程。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;head&lt;/code&gt;节点的下一个节点被唤醒后，会推进&lt;code&gt;head&lt;/code&gt;节点，虽然前面说过队列的&lt;code&gt;head&lt;/code&gt;节点是一个&lt;code&gt;dummy&lt;/code&gt;节点，并不存储数据，理论上应该将第二个节点直接移出队列，但是源码中还是将&lt;code&gt;head&lt;/code&gt;节点出队，将原来的第二个节点变成了新的&lt;code&gt;head&lt;/code&gt;节点。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicbvib2dIHQAiaKBhgn6ykEhw8e16N2Pd3jZxSkn75ibzHKt5M9dhG9b5mKkfoZoULCza8DUITibMk9mjA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-ratio=&quot;0.4186046511627907&quot; data-w=&quot;860&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2&lt;/strong&gt;、同理，如果&lt;code&gt;head&lt;/code&gt;节点的下一个节点是&lt;code&gt;take&lt;/code&gt;类型，当前新节点是&lt;code&gt;put&lt;/code&gt;类型。&lt;code&gt;put&lt;/code&gt;线程会将&lt;code&gt;take&lt;/code&gt;节点的&lt;code&gt;item&lt;/code&gt;设为自己的数据值，然后推进头节点，并唤醒挂起的&lt;code&gt;take&lt;/code&gt;线程，唤醒的&lt;code&gt;take&lt;/code&gt;线程最终返回从&lt;code&gt;put&lt;/code&gt;线程获得的&lt;code&gt;item&lt;/code&gt;的值。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicbvib2dIHQAiaKBhgn6ykEhw8779MENPI1Duunw4gzNPpf2W24Uz6XGH46OrcV66P65mV1CicXmRrvug/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-ratio=&quot;0.4186046511627907&quot; data-w=&quot;860&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，在&lt;code&gt;take&lt;/code&gt;线程唤醒后，会将自己&lt;code&gt;QNode&lt;/code&gt;的&lt;code&gt;item&lt;/code&gt;指针指向自己，并将&lt;code&gt;waiter&lt;/code&gt;中保存的线程置为&lt;code&gt;null&lt;/code&gt;，方便之后被&lt;code&gt;gc&lt;/code&gt;回收。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;面&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;试官：也就是说，在代码中不一定非要生产者先去生产产品，也可以由消费者先到达后进行阻塞等待？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hydra：是的，两种线程都可以先进入队列。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;面&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;试官：好了，公平模式下我是明白了，我去喝口水，给你十分钟时间，回来我们聊聊非公平模式的实现&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;吧。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Hydra：……&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4b733524765af2795ccd4bad932c62a5</guid>
<title>架构师图谱（上篇）</title>
<link>https://toutiao.io/k/xha1t37</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;entry-content&quot;&gt;
&lt;h1&gt;1. 概述&lt;/h1&gt;
&lt;p&gt;“架构师图谱”是一个很宏大的命题，特别是优秀的架构师自身也是“由点到面再到图”，一点点成长积累起来，尝试写这篇文章的目的更多的是结合自身的一些架构、研发、管理经验对现阶段做一个复盘总结，所以这里更偏向于后端图谱，依赖于开源技术、云原生或者其他第三方服务。 这里会重点介绍一些技术栈、设计理念以及适应场景，这些可以作为我们选型时的依据。所谓“架构即决策”，是在一个有约束的盒子中寻求最优解。这个有约束的盒子是团队经验、成本、资源、进度、业务所处阶段等编织、掺杂在一起的综合体。本质上无优劣，但是存在恰当的架构用在合适的软件系统中，而这些就是决策的结果。&lt;/p&gt;
&lt;h2&gt;1.1 序章&lt;/h2&gt;
&lt;p&gt;一个技术图谱：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/uTools_1621160730437.png&quot;&gt;&lt;img src=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/uTools_1621160730437.png&quot; alt=&quot;&quot; class=&quot;alignnone size-full wp-image-235&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;计划会分上、中、下三个篇章来介绍：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;上篇：重点聚焦在微服务和常用的消息队列，包括相关的选型以及一些理论基础&lt;/li&gt;
&lt;li&gt;中篇：主要集中在数据库、分布式（一致性/锁/缓存/发号/任务调度等），以及流媒体&lt;/li&gt;
&lt;li&gt;下篇：分享一些Devops、项目管理、团队建设方向的一些经验&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;完整的思维导图：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/ArchitectMap.png&quot;&gt;&lt;img src=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/ArchitectMap.png&quot; alt=&quot;&quot; class=&quot;alignnone size-full wp-image-232&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;2. 微服务&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;微服务&lt;/strong&gt;（英语：Microservices）是一种&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84&quot;&gt;软件架构风格&lt;/a&gt;，它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，利用模块化的方式组合出复杂的大型应用程序，各功能区块使用与语言无关 (Language-Independent/Language agnostic）的&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E6%8E%A5%E5%8F%A3&quot;&gt;API&lt;/a&gt;集相互通信。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;微服务架构有别于更为传统的单体服务，可将应用拆分成多个核心功能。每个功能都被称为一项服务，可以单独构建和部署。这也体现了可扩展的基本思想：将原本大一统的系统拆成多个小部分，扩展时只修改其中一部分，通过这种方式减少改动范围，降低改动风险。 微服务架构涵盖了服务的多个方面，包括网关、通信协议、服务注册/发现、可观察性、如何合理的划分等等。&lt;/p&gt;
&lt;h2&gt;2.1 理论基础&lt;/h2&gt;
&lt;p&gt;微服务的理论基础主要用来指导微服务架构设计、服务拆分，确定合适的服务粒度和边界。在做微服务之前我们首先要想明白我们现有系统面临什么样的问题，为什么需要微服务，随后才是怎么做。微服务很多核心理念其实在半个世纪前的一篇文章中就被阐述过了，而且这篇文章中的很多论点在软件开发飞速发展的这半个世纪中竟然一再被验证，这就是康威定律（Conway’s Law）。在康威的这篇文章中，最有名的一句话就是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations. – Melvin Conway(1967)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;中文直译大概的意思就是：设计系统的组织，其产生的设计等同于组织之内、组织之间的沟通结构。 最初这篇文章只是描述作者自己的发现和总结，后来“人月神话”中，引用这个观点，并将其“吹捧”成现在熟知的“高位定律”，其中的一些核心观点可以概括如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;组织沟通方式决定系统设计，对于复杂的系统，聊设计就离不开聊人与人的沟通，解决好人与人的沟通问题，才能有一个好的系统设计&lt;/li&gt;
&lt;li&gt;时间再多一件事情也不可能做的完美，但总有时间做完一件事情，这与架构设计的“简单、合适、演化”思维不谋而合&lt;/li&gt;
&lt;li&gt;线型系统和线型组织架构间有潜在的异质同态特征，更直白的说，你想要什么样的系统，就搭建什么样的团队，定义好系统的边界和接口，团队内应该是自治的，这样将沟通成本维持在系统内部，每个子系统就会更加内聚&lt;/li&gt;
&lt;li&gt;大的系统组织总是比小系统更倾向于分解，面对复杂的系统及组织，往往可以采用分而治之&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是当我们的业务和组织架构复杂度比较高的时候，很多概念只从技术角度很难去抽象，这就需要我们自上而下，建立起通用语言，让业务人员和研发人员说一样的话，把思考层次从代码细节拉到业务层面。越高层的抽象越稳定，越细节的东西越容易变化。通过对不同领域的建模，逐步确定领域范围和业务边界，这也就是领域驱动设计（DDD）。 DDD 是一种在面向高度复杂的软件系统时，关于如何去建模的方法论，它的关键点是根据系统的复杂程度建立合适的模型，DDD中的界限上下文也完美匹配了微服务的高内聚、低耦合特性，这也为我们微服务的划分提供了强有力的基础。DDD实施的一般步骤是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;根据需求划分出初步的领域和限界上下文，以及上下文之间的关系&lt;/li&gt;
&lt;li&gt;进一步分析每个上下文内部，识别出哪些是实体，哪些是值对象&lt;/li&gt;
&lt;li&gt;对实体、值对象进行关联和聚合，划分出聚合的范畴和聚合根&lt;/li&gt;
&lt;li&gt;为聚合根设计仓储，并思考实体或值对象的创建方式&lt;/li&gt;
&lt;li&gt;在工程中实践领域模型，并在实践中检验模型的合理性，倒推模型中不足的地方并重构&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是DDD也不是银弹，特别是在一些新业务场景，本身就充满了很多的不确定性，一次性把边界划清楚并不是一件很容易的事。大家在一个进程里，调整起来会相对容易，然后让不同的界限上下文各自演化，等到了一定程度之后再考虑微服务也是一个不错的选择。&lt;/p&gt;
&lt;h2&gt;2.2 网关&lt;/h2&gt;
&lt;p&gt;作为微服务的统一入口，也肩负着整个微服务的流量接入、管理、聚合、安全等，从服务分层的角度可以划分为接入网关和业务网关。 &lt;strong&gt;接入网关&lt;/strong&gt; 接入网关提供最基础的流量接入和安全防护能力，侧重于全局，与业务无关。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;域名&amp;amp;DNS，作为服务的流量入口，对外通过域名和DNS提供服务，国内域名厂商一般都依托于共有云或被共有云厂商收购，用来完善自由的云生态，像阿里的万网，腾讯的DNSPod等，也有国外的aws，godaddy和neamcheap等，可以用作.me等国内无法托管或备案域名的管理，其次也可以借助DNS（HTTPDNS、EDNS）实现跨地域、运营商网络等负载均衡，实现异地多活、就近访问、容灾等。&lt;/li&gt;
&lt;li&gt;负载均衡（LB），主要负责请求的转发代理，按机器负载来分配流量等，对外提供VIP，这里的负载可以宽泛的理解为系统的压力，可以用 CPU 负载来衡量，也可以用连接数、I/O 使用率、网卡吞吐量等来衡量。负载均衡器按服务层级来划分，除了前边提到的DNS，还有集群级别的硬件负载均衡，以及机器级别的软件负载均衡。
&lt;ul&gt;
&lt;li&gt;DNS/硬件负载均衡(F5/A10)主要用来应对海量用户的访问，中小量用户使用无疑会增加更多的维护和采购成本。&lt;/li&gt;
&lt;li&gt;软件负载均衡可以选择自研或上云，LVS、Keepalived主要用于四层（IP+端口）的负载均衡，在四层的基础之上如果要实现应用层（域名/URL/用户会话）等的7层负载均衡，可以使用Nginx、Keepalived的组合。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;除此之外，网关也负责服务整体的安全防护，SSL，IPV6等。
&lt;ul&gt;
&lt;li&gt;安全防护目的是保护服务数据以及可用性，例如防范常见的DDOS/CC网络攻击，反爬虫，自定义访问控制，自研成本往往比较高，可以借助云上一系列的高防、防火墙服务。&lt;/li&gt;
&lt;li&gt;SSL（TLS）用来提供外部https访问，https可以防止数据在传输过程中不被窃取、改变，确保数据的完整性，在支付或者用户登录等敏感数据场景，可以起到一定的保护作用，同时https页面对搜索引擎也比较友好。&lt;/li&gt;
&lt;li&gt;IPV6，全球43亿IPV4地址已经在2019年年底耗尽，网信办在2018年开始就已经推行各大运营商、CDN厂商、互联网核心产品支持IPV6，我们公司之前也是试点之一。IPV6的支持只需要增加一条“AAAA”DNS记录，将域名解析到自持IPV6的IP/VIP即可。IPV4到IPV6由于存在兼容性等问题，一定是长期共存的，过渡方案可以采用IPV6代理（IPV6代理转发到IPV4服务）或者双栈（同时支持IPV6和IPV4）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;业务网关&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/企业微信截图_290de30d-bf31-4921-978c-2bd8b8f56be9.png&quot;&gt;&lt;img src=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/企业微信截图_290de30d-bf31-4921-978c-2bd8b8f56be9.png&quot; alt=&quot;&quot; class=&quot;alignnone size-full wp-image-231&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;业务网关作为业务的最上层出口，一般承担起业务接入或者BFF的工作，例如基础的路由、鉴权、限流、熔断降级、服务聚合、插件化能力，并可以通过可视化界面管理网关配置。可选框架有基于openrestry的kong、apisix以及其他语言相关的spring cloud gateway、grpc-gateway等等，国内开源的goku、kratos、go-zero go框架，有很多比较有意思的组件实现，我们日常业务上也可以借鉴。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;鉴权，鉴权的目的是为了验证用户、请求等的有效性，例如用户身份鉴权（jwt/oauth2/cookie），请求鉴权（请求签名、请求加密），鉴权逻辑也花样繁多，大多需要基于业务定制化，通过网关插件能很好的集成进来。&lt;/li&gt;
&lt;li&gt;限流，限流是为了做一定的流量控制，防止对系统产生过大压力从而影响整个服务。可以基于单台机器或整个集群限流，常见的方式有限制总量和限制速率，超过的则排队或丢弃，例如令牌桶（弹性）/漏桶（匀速）算法。&lt;/li&gt;
&lt;li&gt;熔断降级，熔断作为服务断路器，当下游的服务因为某种原因突然变得不可用或响应过慢（这里既可以指单次请求也可以指一段时间），上游服务为了保证自己整体服务的可用性，不再继续调用目标服务，直接返回，这样也能对整体链路起到保护作用。如果目标服务情况好转则恢复调用，同时结合降级策略提升服务的鲁棒性。常见的有hystrix/resilience4J（hystrix虽然已停止更新，但现有功能已经能满足大多业务场景）。&lt;/li&gt;
&lt;li&gt;重试，大量网络IO，避免不了会出现因网络抖动，出现连接失败或者超时，重试可以提高请求的最终成功率，削平服务毛刺。但重试也有可能放大故障，所以可以结合退避策略（backoff）、限制单点重试、限制链路重试这些策略进行优雅的重试，同时也可以采用更加激进的“对冲请求”提前（tp99时间未响应时）发起重试请求，降低系统时延。&lt;/li&gt;
&lt;li&gt;插件化，各个网关集成插件的方式尽不相同，但是目的都是为了集成技术人员编写的一些业务相关的通用能力，例如前边提到的身份鉴权、请求鉴权等等。另外作为业务网关插件，也可以编写一些基础业务（API鉴权、请求格式化）逻辑，直接透传请求到服务层，省去很多BFF和上下游对接的工作。&lt;/li&gt;
&lt;li&gt;BFF，Backend For Frontend，可以按照业务逻辑，以串行、并行和分支等结构编排多个服务API，为服务提供聚合、适配、裁剪（只返回需要的字段）功能，核心是API的动态编排以满足日益增长的业务逻辑，降低前端与微服务之间的对接成本。BFF并不意味着只能由后端实现，也可以在前端通过GraphQL等API查询语言实现。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2.3 协议&lt;/h2&gt;
&lt;p&gt;服务间的通信方式是在采用微服务架构时需要做出一个最基本的决策，统一的协议标准也能大大降低服务的联调和维护成本。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HTTP REST，REST更确切的讲是指的API设计风格，而不是协议标准。通常基于使用HTTP，URL，和JSON这些现有的广泛流行的协议和标准。符合REST设计风格的API称作RESTful API。在实际应用中大多实现的是伪REST API，例如用POST请求同时实现资源的增删改，或者为了请求的扩展性，资源的增删改查都使用POST JSON。&lt;/li&gt;
&lt;li&gt;RPC，RPC协议描绘了客户端与服务端之间的点对点调用流程，包括stub、通信、RPC消息协议部分。可以基于tcp，也可以基于http。在实际应用中，还需要考虑服务的高可用、负载均衡等问题，所以产品级的 RPC 框架除了点对点的 RPC 协议的具体实现外，还应包括服务的发现与注册、提供服务的多台 Server 的负载均衡、服务的高可用等更多的功能。目前的 RPC 框架大致有两种不同的侧重方向，一种偏重于服务治理（Dubbo、Motan），另一种偏重于跨语言调用（Thrift/GRPC）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;RPC vs HTTP REST优点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;更清晰的API定义，例如grpc协议的定义文件proto，自身就可以作为很好的API文档，日常开发中也可以把proto文件独立版本库管理，精简目录结构，方便不同的服务引用。&lt;/li&gt;
&lt;li&gt;更好的传输效率，通过序列化和反序列化进一步压缩网络传输数据，不过序列化、反序列化也会有一定的性能损耗，protobuf可以说很好的兼顾了这两点。&lt;/li&gt;
&lt;li&gt;更合适的容错机制，可以基于实际的业务场景，实现更合适的超时控制与异常重试机制，以应对网络抖动等对服务造成的影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在一些特定场景，例如：OpenApi、BFF等，HTTP REST可以更大程度上降低外部团队的接入成本。并且RPC也有调试不便、多语言互通需要对应的SDK支持这些问题，各有利弊。综合考虑来看，除了一些特定场景，如果我们已经有相对完善的基础设施支撑（RPC框架、服务治理），RPC可以为一个更合适的选择。&lt;/p&gt;
&lt;h2&gt;2.4 服务注册/发现&lt;/h2&gt;
&lt;p&gt;服务注册主要是通过将微服务的后端机器IP、端口、地域等信息注册起来，并结合一定的发现机制使客户端的请求能够直连具体的后端机器。从实现方式上可以分为服务端模式与客户端模式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务端模式，也可以说是传统模式，通过借助负载均衡器和DNS实现，负载均衡器负责健康检查、负载均衡策略，DNS负责实现访问域名到负载均衡器IP/VIP的映射。通过直接暴露域名和端口的方式提供客户端访问。&lt;/li&gt;
&lt;li&gt;客户端模式，可以借助注册中心实现，注册中心负责服务的注册与健康检查，客户端通过监听配置变更的方式及时把配置中心维护的配置同步到本地，通过客户端负载均衡策略直接向后端机器发起请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从两种模式的实现方式上可以看出&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务端模式注册与发现都由服务端完成，这样可以使客户端专注在自身的业务实现，但是由于依赖负载均衡器，也就是集中式的proxy，proxy需要维护双向连接，也很容易使自己成为系统瓶颈，可用性的高低直接决定了服务质量，并且DNS缓存机制也会导致故障发生时，迁移并不能及时完成。当然在服务量少，且负载均衡器有VIP的情况下，我们也可以不使用DNS。&lt;/li&gt;
&lt;li&gt;客户端模式注册与发现由配置中心和客户端共同完成，通过分布式的方式，可以避免出现proxy节点性能瓶颈问题，但是可靠性与性能瓶颈很容器出现在配置中心上，并且客户端的也需要一定的接入成本。好在开源的已经有很成熟的架构方案与丰富的客户端SDK，例如etcd/zookeeper/consul，consul提供开箱即用的功能，etcd社区和接入易用性方面更优一些，他们之间的一些具体区别：&lt;br/&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Feature&lt;/th&gt;
&lt;th&gt;etcd&lt;/th&gt;
&lt;th&gt;zookeeper&lt;/th&gt;
&lt;th&gt;consul&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;服务健康检查&lt;/td&gt;
&lt;td&gt;连接心跳&lt;/td&gt;
&lt;td&gt;连接心跳&lt;/td&gt;
&lt;td&gt;心跳、内存、硬盘等&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;一致性&lt;/td&gt;
&lt;td&gt;raft&lt;/td&gt;
&lt;td&gt;paxos&lt;/td&gt;
&lt;td&gt;raft&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;接口&lt;/td&gt;
&lt;td&gt;http/grpc&lt;/td&gt;
&lt;td&gt;客户端sdk&lt;/td&gt;
&lt;td&gt;http/dns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;metrics&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;不支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;安全&lt;/td&gt;
&lt;td&gt;https&lt;/td&gt;
&lt;td&gt;acl&lt;/td&gt;
&lt;td&gt;acl/https&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kv存储&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2.5 配置中心&lt;/h2&gt;
&lt;p&gt;配置中心从使用场景来讲，一类是前边讲到的服务注册、发现和KV存储，例如etcd/zk/consul，在k8s场景下也可以通过configmap/secret将配置写入本地文件、环境变量或者共享的volume中，这样没有了中心服务的依赖和客户端的接入，可以实现一些老旧服务的无侵入式改造。但是作为配置中心，除了基础的配置数据，一些情况下还要开放给非开发人员（测试、运维、产品）使用，完善的控制台、权限管理、dashbord的支持，也非常重要，这类可以参考nacos（阿里开源）/apollo（携程开源）。nacos在读写性能上优于apollo，但是功能特性（例如权限管理）稍逊于apollo。&lt;/p&gt;
&lt;h2&gt;2.6 可观察性&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;在控制论中，可观察性是用系统输出到外部的信息来推断系统内部运运行状态的一种度量方式&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在云原生时代，容器和服务的生命周期是紧密联系在一起的，相较在传统的单体服务运行在物理主机或者虚拟机当中，排查问题的时候显得非常不便，这种复杂性导致了一个定义研发运营效率的MTTR（平均故障修复时间）指标急剧增加。所以这里更强调的是微服务的可观察性，需要提前想好我们要如何观察容器内的服务以及服务之间的拓扑信息、各式指标的搜集等，这些监测能力相当重要。 可观察性三大支柱围绕Tracing（链路追踪）、Logging（日志）和Metrics（度量）展开，这三个维度几乎涵盖了应用程序的各种表征行为，开发人员通过收集并查看这三个维度的数据时刻掌握应用程序的运行情况。很长一段时间，这三者是独立存在的，随着时间的推移，这三者已经相互关联，相辅相成。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/observability.jpg&quot;&gt;&lt;img src=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/observability.jpg&quot; alt=&quot;&quot; class=&quot;alignnone size-full wp-image-233&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;2.6.1 链路追踪&lt;/h3&gt;
&lt;p&gt;链路追踪为分布式应用的开发者提供了完整的调用链路还原、调用请求量统计、链路拓扑、应用依赖分析等工具，可以帮助开发者快速分析和诊断分布式应用架构下的性能瓶颈，提高微服务时代下的开发诊断效率以及系统的可观察性。 为了解决不同的分布式系统API不兼容的问题，诞生了OpenTracing规范，OpenTracing中的Trace可以被认为是由多个Spacn组成的DAG图。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[Span A]  ←←←(the root span)
            |
     +------+------+
     |             |
 [Span B]      [Span C] ←←←(Span C 是 Span A 的孩子节点, ChildOf)
     |             |
 [Span D]      +---+-------+
               |           |
           [Span E]    [Span F] &amp;gt;&amp;gt;&amp;gt; [Span G] &amp;gt;&amp;gt;&amp;gt; [Span H]
                                       ↑
                                       ↑
                                       ↑
                         (Span G 在 Span F 后被调用, FollowsFrom)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;OpenTracing专注在tracing，除此之外还有包含了metrics的OpenCensus标准，以及由CNCF推出，融合OpenTracing和OpenCensus的OpenTelemetry。OpenTelemetry旨在实现云原生时代可观察性指标（Tracing、Logging、Metrics）的统一收集和处理，同时提供推动这些标准实施的组件和工具。 OpenTracing中的佼佼者当属Jaeger、Zipkin、Skywalking。他们之间的一些对比：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Feature&lt;/th&gt;
&lt;th&gt;Jaeger&lt;/th&gt;
&lt;th&gt;Zipkin&lt;/th&gt;
&lt;th&gt;Skywalking&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;OpenTracing兼容&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;社区&lt;/td&gt;
&lt;td&gt;社区生态好，文档丰富&lt;/td&gt;
&lt;td&gt;社区生态好，文档丰富&lt;/td&gt;
&lt;td&gt;时间不长，仅限中文社区&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;存储&lt;/td&gt;
&lt;td&gt;In-Memory/Cassandra/ES&lt;/td&gt;
&lt;td&gt;In-Memory/Cassandra/Mysql/ES&lt;/td&gt;
&lt;td&gt;Mysql/ES/H2/TiDB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;传输协议&lt;/td&gt;
&lt;td&gt;UDP/HTTP&lt;/td&gt;
&lt;td&gt;HTTP/Kafka/Scribe/AMQP&lt;/td&gt;
&lt;td&gt;gRPC&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;APM监控&lt;/td&gt;
&lt;td&gt;不支持&lt;/td&gt;
&lt;td&gt;不支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;侵入性&lt;/td&gt;
&lt;td&gt;侵入&lt;/td&gt;
&lt;td&gt;侵入&lt;/td&gt;
&lt;td&gt;无侵入（部分语言）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;采样策略&lt;/td&gt;
&lt;td&gt;全量/概率/限速/动态限速&lt;/td&gt;
&lt;td&gt;全量/概率/限速/计数&lt;/td&gt;
&lt;td&gt;全量/概率&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Zipkin开源时间长，社区相对丰富，Jaeger更加轻量，也是Istio推荐方案，Skywalking支持部分语言（Java、PHP、Python等）的无侵入式接入。另外APM（应用性能）监控的支持也会影响到我们的选型。 除此之外，面对线上海量请求，如果采用抽样采样策略，那就需要支持一定的流量染色，把我们核心关注的请求（例如链路中发生了错误、部分请求耗时过高等）都进行采样，可以通过结合opentelemetry-collector以及开箱即用的&lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/tailsamplingprocessor&quot;&gt;tailsamplingprocessor&lt;/a&gt;构建pipeline插件实现。&lt;/p&gt;
&lt;h3&gt;2.6.2 日志&lt;/h3&gt;
&lt;p&gt;服务间的链路日志能否帮助我们判断错误发生的具体位置，这类业务日志主要集中在访问日志/打点日志等等。随着大数据的兴起，我们对数据的分析解读能力越来越强，日志作为原始数据则体现出了更大的价值，例如用户的行为分析，反垃圾，舆情分析等等。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;业务日志：这类日志重点在于通过不同级别的日志，及时发现分析系统存在的异常，RFC 5424定义的8中日志级别:
&lt;ul&gt;
&lt;li&gt;Emergency: system is unusable&lt;/li&gt;
&lt;li&gt;Alert: action must be taken immediately&lt;/li&gt;
&lt;li&gt;Critical: critical conditions&lt;/li&gt;
&lt;li&gt;Error: error conditions&lt;/li&gt;
&lt;li&gt;Warning: warning conditions&lt;/li&gt;
&lt;li&gt;Notice: normal but significant condition&lt;/li&gt;
&lt;li&gt;Informational: informational messages&lt;/li&gt;
&lt;li&gt;Debug: debug-level messages&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在实际使用过程中可能会对日志级别进行简化和调整，一般来讲Warning及以上的日志是需要重点关注的，需要做好及时的监控告警，Warning以下的日志也可以辅助问题的定位。 日志写入可以选择写入消息队列，也可以选择落地磁盘，将关心的结构化或非结构化日志、业务模块信息（如果是细粒度的微服务，可以选择将日志放同一模块收集），以及级别、时间（who、when、where、how、what）等要素正确的写入正确写入后再收集到日志服务。写入消息队列需要考虑消息队列的选型以及做好可用性和积压监控，写入磁盘需要考虑写入性能以及日志的切割清理，例如golang的zap+rotatelogs组合。日志收集的话，由于Logstash资源消耗相对比较大，虚拟机环境中可以使用filebeat来替代，更严苛的线上或容器环境，可以使用Fluentd/Fluentd Bit。日志最终汇总到ES和Kibana做展示，通过esalert定制告警策略。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大数据日志：大数据日志本质上也对应着我们一定的业务场景，但大多是海量日志、高吞吐量场景，所以对海量日志的收集和存储是较大的挑战。实现方案我们可以采用高吞吐量的流式中间件，例如kafka/plusar等，在结合流式处理(flink)或者批处理(spark)系统，将数据汇总到hadoop进行分析，这里涉及到的中间件和数据库可参考后续章节。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;2.6.3 指标&lt;/h3&gt;
&lt;p&gt;指标是有关系统的离散的数据点，这些指标通常表示为计数或度量，并且通常在一段时间内进行汇总或计算，一般用来做基础的资源监控和业务监控：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;资源监控：CPU、内存、IO、fd、GC等&lt;/li&gt;
&lt;li&gt;业务监控：QPS、模调、耗时分布等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Zabbix作为老牌的监控系统，适合更复杂的物理机、虚拟机、数据库等更复杂的场景，同时也拥有更丰富的图形化界面，但是Prometheus作为云原生的代表作，与k8s、容器等能更好的结合，协同grafana实现可定制化的界面，另外存储基于TSDB，相比于关系型数据库也有更好的扩展性。以Prometheus为例，支持的数据类型有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Counter 只增不减的计数器，例如请求数（http_requests_total）。基于此数据模型，使用Prometheus提供的强大PromQL表达式能够拓展出更加适合开发观察的指标数据。 分钟增量请求：increase(http_requests_total[1m]) 分钟QPS：rate(http_requests_total[1m])&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Gauge 可增可减的时刻量，例如Go语言协程数（go_goroutines） 波动量：delta(go_goroutines[10m])&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Histogram 直方图，不同区间内样本的个数。例如，耗时50ms-100ms每分钟请求量，100ms-150ms每分钟请求量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Summary 概要，反应百分位值。例如，某RPC接口，95%的请求耗时低于150ms，99%的请求耗时低于200ms。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2.7 Service Mesh&lt;/h2&gt;
&lt;p&gt;Service Mesh这个服务网格专注于处理服务和服务之间的通信，包括我们前边讲的服务发现、熔断降级、安全、流量控制、可观察性等能力。这些通用能力在Service Mesh出现之前，由Lib/Framework完成，这样就可以在开发层面上很容易地集成到我们的应用服务中。但是并没有办法实现跨语言编程，有什么改动后，也需要重新编译重新发布服务。理论上应该有一个专门的层来干这事，于是出现了 Sidecar，Sidecar 集群就成了 Service Mesh，加上对整个集群的管理控制面板，就成了现在的 Service Mesh 架构，可以说Service Mesh是云原生时代的必然产物。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/WechatIMG47.jpeg&quot;&gt;&lt;img src=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/WechatIMG47.jpeg&quot; alt=&quot;&quot; class=&quot;alignnone size-full wp-image-237&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;目前比较流行的 Service Mesh 开源软件是 Istio 和 Linkerd，还有更加轻量级的Conduit，它们都可以在 Kubernetes 中集成。Istio 基于 Golang 编写，使用Envoy作为Sidecar，在服务治理方面职责分明，国内落地案例相较 Linkerd 、Conduit更加广泛。 由于Service Mesh承担了服务核心的流量调度环节，再给我们带来便利的同时，也引入很多的不可控因素，例如：Sidecar组件不可用，将直接导致系统出现致命问题。所以在充分做好服务可观察性的前提下，也要保证Service Mesh的高可用，一种比较好的方式是，除了在本机有 Sidecar，我们还可以部署一下稍微集中一点的 Sidecar——比如为某个服务集群部署一个集中式的 Sidecar。一旦本机的有问题，可以走集中的。&lt;/p&gt;
&lt;h1&gt;3. 消息队列&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;在计算机科学中，消息队列（英语：Message queue）是一种进程间通信或同一进程的不同线程间的通信方式，软件的贮列用来处理一系列的输入，通常是来自用户。消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的数据，包含发生的时间，输入设备的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列交互。消息会保存在队列中，直到接收者取回它。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/Screen-Shot-2017-05-22-at-09.05.54.png&quot;&gt;&lt;img src=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/Screen-Shot-2017-05-22-at-09.05.54.png&quot; alt=&quot;&quot; class=&quot;alignnone size-full wp-image-234&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;实际应用场景中，消息队列也经常作为中间件，用于异步解耦、削峰填谷、数据广播、错峰与流控、最终一致性等，在一些核心的大数据分析、交易支付等场景也经常扮演重要角色，消息队列的选型主要侧重以下几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HA：自身的高可用性保障，避免消息队列的引入而影响整体服务的可用性&lt;/li&gt;
&lt;li&gt;高吞吐：在面对海量数据写入能否保持一个相对稳定、高效的数据处理能力&lt;/li&gt;
&lt;li&gt;功能丰富性：是否支持延迟消息、事务消息、死信队列、优先级队列等&lt;/li&gt;
&lt;li&gt;消息广播：是否支持将消息广播给消费者组或者一组消费者&lt;/li&gt;
&lt;li&gt;消息堆积能力：在数据量过大时，是否允许一定消息堆积到broker&lt;/li&gt;
&lt;li&gt;数据持久性：数据持久化策略的采用，也决定着数据在宕机恢复后是否会丢失数据&lt;/li&gt;
&lt;li&gt;重复消费：是否支持ack机制，在消费者未正确处理消息时，支持重新消费&lt;/li&gt;
&lt;li&gt;消息顺序性：针对顺序消费的场景保证数据按写入时间的顺序性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里着重对比一下Redis、Rabbitmq/Rocketmq、Kafka、Plusar&lt;/p&gt;
&lt;h2&gt;3.1 Redis&lt;/h2&gt;
&lt;p&gt;redis实现消息队列可以通过List类型、Pub/Sub、Stream（redis 5.0）类型来实现，HA使用多副本或者集群的方式。作为消息队列使用起来非常方便，但是也有很多的弊端：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;功能丰富性：只支持普通的消息类型&lt;/li&gt;
&lt;li&gt;数据持久性：Pub/Sub只提供缓冲区广播能力，不进行持久化，List/Stream即使基于aof和rdb持久化策略，但是并没有事务性保障，在宕机恢复后还是存在丢失数据的可能性&lt;/li&gt;
&lt;li&gt;消息堆积能力：List随长度增大，内存不断增长；Pub/Sub只在缓冲区内堆积，缓冲区满消费者强制下线；Stream创建时可以指定队列最大长度，写满后剔除旧消息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除此之外，List类型无法支持消息广播，和Pub/Sub一样也不支持重复消费。结合整体来看redis作为消息队列大多数只应用在数据量小，对丢失数据不敏感的业务场景，适用范围较小，复杂业务并且有一定运维支撑的情况下，可以直接考虑企业级消息中间件。&lt;/p&gt;
&lt;h2&gt;3.2 Rabbitmq vs Kafka vs Rocketmq&lt;/h2&gt;
&lt;p&gt;这几个可以作为企业级消息中间件的代表，Rabbitmq和kafka的一些详细对比，可以参考之前写的这篇文章《&lt;a href=&quot;https://blog.xstudio.mobi/a/60.html&quot;&gt;消息队列Rabbitmq与Kafka对比分析&lt;/a&gt;》。而Rocketmq在设计之初就借鉴了很多Rabbitmq、Kafka的设计理念，例如：Routing、多副本、顺序写（IO），也广泛应用在淘宝双十一等场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HA&lt;/strong&gt;&lt;br/&gt;
在HA方面他们都是通过副本的方式，区别是Rabbitmq是集群级别的副本，Kafka是多partiton和ISR、选举机制，而Rocketmq通过多（master/slave）副本同时保障NameServer和Broker。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;高吞吐&lt;/strong&gt;&lt;br/&gt;
Kafka和Rocketmq通过直接操作文件系统，相比于Rabbitmq，顺序写能大幅度提升数据的处理速度。Kafka为了进一步提升消息的吞吐量，可以采用客户端缓冲队列的方式批量发送，但也会存在宕机丢失数据的可能性，可以通过设置 batch.size 与 linger.ms 来动态调整，相比于Rocketmq更加灵活。Kafka的partition机制的确会带来性能的提升，但是在Topic不断增多的情况下，众多的partition及副本也将顺序写逐步退化为随机写，并且扩容时，由于hash值的变化，也会涉及到大量partiton数据的迁移。Rocketmq采用commitlog的方式实现全局写，所以能支持更多的Topic，扩容也不涉及大量数据的迁移。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;功能丰富性&lt;/strong&gt;&lt;br/&gt;
Kafka只有基础的消息类型，Rabbitmq支持优先级队列，通过TTL和死信队列可以实现消息的延迟和重试，但是需要提前创建好对应重试频率的队列，例如：1s重试队列，10s重试队列，Rocketmq则内置了18个重试频率“1s 5s 10s 30s 1m 2m…”，另外也具有独有的2PL事务消息，很好的保障业务逻辑与消息发送的一致性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;重复消费&lt;/strong&gt;&lt;br/&gt;
他们三者都采用Ack机制保障了单条消息重复消费的能力，Kafka通过offset和partition特殊的ttl机制（segment过期，按文件名顺序清理），能支持通过重置offset来回溯历史数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消息顺序性&lt;/strong&gt;&lt;br/&gt;
Rabbitmq和Rocketmq可以保证写入同一topic的顺序性，但是在多个消费者同时消费的情况下还是会出现乱序的情况，在数据量较大的时候，我们也可以通过单个消费者消费，再按照一定的分发策略分配给多个消费者执行，只不过会提升整体复杂度，同时会带来更多的HA、维护成本考量。Kafka可以保障单个partition的顺序性，并且每个partiton只允许一个消费者来消费（N：1），这就从策略上避免了多消费者的情况，在数据量较大的情况下，可以通过划分更多的partition提升数据处理能力。 综合来讲，Rabbitmq、Rocketmq使用Queue模型，丰富的消息队列功能，更多的应用在业务场景，Kafka基于Streaming模型，结合批处理、流式处理，更多的应用在大数据分析场景。&lt;/p&gt;
&lt;h2&gt;3.3 Pulsar&lt;/h2&gt;
&lt;p&gt;Pulsar作为Apache开源、云原生的消息中间件，诞生之初就引发了很大的关注。设计上避免了kafka遇到的功能丰富性、扩容等方面的问题，采用计算、存储分离的架构，broker层只作为“API接口层”，存储交给更专业的bookeeper，由于broker层的无状态性，结合k8s等非常方便的进行扩容。并且Pulsar支持多个消费模型提升消费者处理能力，例如：exclusive、failover、shared、key-shared等，可以说综合了kafka和其他消息中间件的众多优点。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/WechatIMG45.jpeg&quot;&gt;&lt;img src=&quot;http://yueqian-wordpress.stor.sinaapp.com/uploads/2021/05/WechatIMG45.jpeg&quot; alt=&quot;&quot; class=&quot;alignnone size-full wp-image-236&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HA、高吞吐：和kafka类似，通过多partition和选举机制功，除此之外，还支持丰富的跨地域复制能力&lt;/li&gt;
&lt;li&gt;功能丰富性：可以支持秒级的延迟消息，以及独特的重试队列和私信队列&lt;/li&gt;
&lt;li&gt;消息顺序性：为了实现partition消息的顺序性，和kafka一样，都需要将消息写入到同一broker，区别是kafka会同时存储消息在该broker，broker和partiton绑定在一起，而pulsar可以将消息分块（segment）后，更加均匀的分散到bookeeper节点上，broker只需要记录映射关系即可，这样在资源扩容时，可以更加快速便捷&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;像能量守恒定律一样，系统的复杂度往往也是守恒的，实现即高性能又高可用的消息中间件需要的技术复杂性，不会凭空消失，只会从一个地方转移到另一个地方，消息队列本质上可以理解为feature+fs，只不过存储、计算分离架构，将各层间的职责分离，使每一层都能专注在自身领域，以应对海量数据和更加复杂多变的环境，这也是现在新技术发展的一个趋势。 作为后起之秀，的确可以站在巨人的肩膀上，避免很多设计上的不足，同时引入一些新的架构理念，但是要成功的在其中分一杯羹，同样也要面临用户学习成本高、缺少杀手级应用、如何迁移等等这些现实性的问题，不过依靠良好的社区和技术先驱，随着时间的变迁，这些短板也会逐步补齐，真正适应当前时代的技术一定会脱颖而出。ps：腾讯云最近开源&lt;a href=&quot;https://github.com/streamnative/rop&quot;&gt;Rop&lt;/a&gt;，支持Rocketmq相对平滑的迁移至Pulsar。&lt;/p&gt;
&lt;h1&gt;4.推荐阅读&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Github Gateway &lt;a href=&quot;https://github.com/search?o=desc&amp;amp;p=2&amp;amp;q=gateway&amp;amp;s=stars&amp;amp;type=Repositories&quot;&gt;https://github.com/search?o=desc&amp;amp;p=2&amp;amp;q=gateway&amp;amp;s=stars&amp;amp;type=Repositories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Rest vs RPC &lt;a href=&quot;https://cloud.google.com/blog/products/application-development/rest-vs-rpc-what-problems-are-you-trying-to-solve-with-your-apis&quot;&gt;https://cloud.google.com/blog/products/application-development/rest-vs-rpc-what-problems-are-you-trying-to-solve-with-your-apis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;IPV6 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/35509560&quot;&gt;https://zhuanlan.zhihu.com/p/35509560&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;k8s secret &amp;amp; configmap &lt;a href=&quot;https://kubernetes.io/zh/docs/concepts/configuration/&quot;&gt;https://kubernetes.io/zh/docs/concepts/configuration/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OPENTRACING-SPECIFICATION &lt;a href=&quot;https://opentracing-contrib.github.io/opentracing-specification-zh/specification.html&quot;&gt;https://opentracing-contrib.github.io/opentracing-specification-zh/specification.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;可观察性和微服务 &lt;a href=&quot;https://www.infoq.cn/article/2018/06/observability-microservices&quot;&gt;https://www.infoq.cn/article/2018/06/observability-microservices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;RFC 5424 &lt;a href=&quot;https://tools.ietf.org/html/rfc5424&quot;&gt;https://tools.ietf.org/html/rfc5424&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;分布式文件系统架构对比 &lt;a href=&quot;https://www.infoq.cn/article/bp7uvbnb7dbgdk2gtxl9&quot;&gt;https://www.infoq.cn/article/bp7uvbnb7dbgdk2gtxl9&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Service Mesh 中的可观察性实践 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/145524861&quot;&gt;https://zhuanlan.zhihu.com/p/145524861&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;全面解析 GraphQL，携程微服务背景下的前后端数据交互方案 &lt;a href=&quot;https://www.infoq.cn/article/xz0ws6_a5jmrj6ztpoz8&quot;&gt;https://www.infoq.cn/article/xz0ws6_a5jmrj6ztpoz8&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;调用链追踪系统在伴鱼：实践篇 &lt;a href=&quot;https://tech.ipalfish.com/blog/2021/03/04/implementing-tail-based-sampling/&quot;&gt;https://tech.ipalfish.com/blog/2021/03/04/implementing-tail-based-sampling/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Conway’s Law — A Theoretical Basis for the Microservice Architecture &lt;a href=&quot;https://alibaba-cloud.medium.com/conways-law-a-theoretical-basis-for-the-microservice-architecture-c666f7fcc66a&quot;&gt;https://alibaba-cloud.medium.com/conways-law-a-theoretical-basis-for-the-microservice-architecture-c666f7fcc66a&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;如何优雅地重试 &lt;a href=&quot;https://www.infoq.cn/article/5fboevkal0gvgvgeac4z&quot;&gt;https://www.infoq.cn/article/5fboevkal0gvgvgeac4z&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Pattern: Service Mesh &lt;a href=&quot;https://philcalcado.com/2017/08/03/pattern_service_mesh.html&quot;&gt;https://philcalcado.com/2017/08/03/pattern_service_mesh.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;

&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>