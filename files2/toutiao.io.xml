<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>514755e2398a37168b16f261d37b4423</guid>
<title>高并发，你真的理解透彻了吗？</title>
<link>https://toutiao.io/k/93k2zfb</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                           autoTypeSetting24psection&amp;#10;                          &quot; id=&quot;js_content&quot;&gt;
            &lt;p data-tool=&quot;mdnice编辑器&quot;&gt;高并发，几乎是每个程序员都想拥有的经验。原因很简单：随着流量变大，会遇到各种各样的技术问题，比如接口响应超时、CPU load升高、GC频繁、死锁、大数据量存储等等，这些问题能推动我们在技术深度上不断精进。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在过往的面试中，如果候选人做过高并发的项目，我通常会让对方谈谈对于高并发的理解，但是能系统性地回答好此问题的人并不多，大概分成这样几类：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、&lt;strong&gt;对数据化的指标没有概念&lt;/strong&gt;：不清楚选择什么样的指标来衡量高并发系统？分不清并发量和QPS，甚至不知道自己系统的总用户量、活跃用户量，平峰和高峰时的QPS和TPS等关键数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、&lt;strong&gt;设计了一些方案，但是细节掌握不透彻&lt;/strong&gt;：讲不出该方案要关注的技术点和可能带来的副作用。比如读性能有瓶颈会引入缓存，但是忽视了缓存命中率、热点key、数据一致性等问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、&lt;strong&gt;理解片面，把高并发设计等同于性能优化&lt;/strong&gt;：大谈并发编程、多级缓存、异步化、水平扩容，却忽视高可用设计、服务治理和运维保障。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4、&lt;strong&gt;掌握大方案，却忽视最基本的东西&lt;/strong&gt;：能讲清楚垂直分层、水平分区、缓存等大思路，却没意识去分析数据结构是否合理，算法是否高效，没想过从最根本的IO和计算两个维度去做细节优化。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4659090909090909&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt1db27zfRllYrkrYdTMf5ODQSbhFQMPbzShfJxWsGdUwoIeyRsL8V0Da4d7ibZicGD2ugKic7E9sicl0Q/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;616&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这篇文章，我想结合自己的高并发项目经验，系统性地总结下高并发需要掌握的知识和实践思路，希望对你有所帮助。内容分成以下3个部分：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;如何理解高并发？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;高并发系统设计的目标是什么？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;高并发的实践方案有哪些？&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如何理解高并发？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;高并发意味着大流量，需要运用技术手段抵抗流量的冲击，这些手段好比操作流量，能让流量更平稳地被系统所处理，带给用户更好的体验。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们常见的高并发场景有：淘宝的双11、春运时的抢票、微博大V的热点新闻等。除了这些典型事情，每秒几十万请求的秒杀系统、每天千万级的订单系统、每天亿级日活的信息流系统等，都可以归为高并发。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很显然，上面谈到的高并发场景，并发量各不相同，&lt;strong&gt;那到底多大并发才算高并发呢&lt;/strong&gt;？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、不能只看数字，要看具体的业务场景。不能说10W QPS的秒杀是高并发，而1W QPS的信息流就不是高并发。信息流场景涉及复杂的推荐模型和各种人工策略，它的业务逻辑可能比秒杀场景复杂10倍不止。因此，不在同一个维度，没有任何比较意义。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、业务都是从0到1做起来的，并发量和QPS只是参考指标，最重要的是：在业务量逐渐变成原来的10倍、100倍的过程中，你是否用到了高并发的处理方法去演进你的系统，从架构设计、编码实现、甚至产品方案等维度去预防和解决高并发引起的问题？而不是一味的升级硬件、加机器做水平扩展。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，各个高并发场景的业务特点完全不同：有读多写少的信息流场景、有读多写多的交易场景，&lt;strong&gt;那是否有通用的技术方案解决不同场景的高并发问题呢？&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我觉得大的思路可以借鉴，别人的方案也可以参考，但是真正落地过程中，细节上还会有无数的坑。另外，由于软硬件环境、技术栈、以及产品逻辑都没法做到完全一致，这些都会导致同样的业务场景，就算用相同的技术方案也会面临不同的问题，这些坑还得一个个趟。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，这篇文章我会将重点放在基础知识、通用思路、和我曾经实践过的有效经验上，希望让你对高并发有更深的理解。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;高并发系统设计的目标是什么？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先搞清楚高并发系统设计的目标，在此基础上再讨论设计方案和实践经验才有意义和针对性。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;宏观目标&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;高并发绝不意味着只追求高性能，这是很多人片面的理解。从宏观角度看，高并发系统设计的目标有三个：高性能、高可用，以及高可扩展。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、高性能：性能体现了系统的并行处理能力，在有限的硬件投入下，提高性能意味着节省成本。同时，性能也反映了用户体验，响应时间分别是100毫秒和1秒，给用户的感受是完全不同的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、高可用：表示系统可以正常服务的时间。一个全年不停机、无故障；另一个隔三差五出线上事故、宕机，用户肯定选择前者。另外，如果系统只能做到90%可用，也会大大拖累业务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、高扩展：表示系统的扩展能力，流量高峰时能否在短时间内完成扩容，更平稳地承接峰值流量，比如双11活动、明星离婚等热点事件。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6342592592592593&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt1db27zfRllYrkrYdTMf5ODibMTIy15HCkzH4FdnZhwPGiczoxwhLWN4YE37ibazKXMUTPQfB9LJBcLg/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这3个目标是需要通盘考虑的，因为它们互相关联、甚至也会相互影响。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如说：考虑系统的扩展能力，你会将服务设计成无状态的，这种集群设计保证了高扩展性，其实也间接提升了系统的性能和可用性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再比如说：为了保证可用性，通常会对服务接口进行超时设置，以防大量线程阻塞在慢请求上造成系统雪崩，那超时时间设置成多少合理呢？一般，我们会参考依赖服务的性能表现进行设置。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;微观目标&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再从微观角度来看，高性能、高可用和高扩展又有哪些具体的指标来衡量？为什么会选择这些指标呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;性能指标&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过性能指标可以度量目前存在的性能问题，同时作为性能优化的评估依据。一般来说，会采用一段时间内的接口响应时间作为指标。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、平均响应时间：最常用，但是缺陷很明显，对于慢请求不敏感。比如1万次请求，其中9900次是1ms，100次是100ms，则平均响应时间为1.99ms，虽然平均耗时仅增加了0.99ms，但是1%请求的响应时间已经增加了100倍。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、TP90、TP99等分位值：将响应时间按照从小到大排序，TP90表示排在第90分位的响应时间， 分位值越大，对慢请求越敏感。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.27494199535962877&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt1db27zfRllYrkrYdTMf5ODOoMt73YpeJDNepwjoCkpK7oK6htD3Wjardta5dQ7CDeZCvNYWGwmfQ/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;862&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、吞吐量：和响应时间呈反比，比如响应时间是1ms，则吞吐量为每秒1000次。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通常，设定性能目标时会兼顾吞吐量和响应时间，比如这样表述：在每秒1万次请求下，AVG控制在50ms以下，TP99控制在100ms以下。对于高并发系统，AVG和TP分位值必须同时要考虑。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，从用户体验角度来看，200毫秒被认为是第一个分界点，用户感觉不到延迟，1秒是第二个分界点，用户能感受到延迟，但是可以接受。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，对于一个健康的高并发系统，TP99应该控制在200毫秒以内，TP999或者TP9999应该控制在1秒以内。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;可用性指标&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;高可用性是指系统具有较高的无故障运行能力，可用性 = 正常运行时间 / 系统总运行时间，一般使用几个9来描述系统的可用性。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.39800995024875624&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt1db27zfRllYrkrYdTMf5ODu8L6WhzQ9yo4qnWtHIWpWZRokZNrU8RGCThoWX692SExv29ibb4Qj1A/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;402&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于高并发系统来说，最基本的要求是：保证3个9或者4个9。原因很简单，如果你只能做到2个9，意味着有1%的故障时间，像一些大公司每年动辄千亿以上的GMV或者收入，1%就是10亿级别的业务影响。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;可扩展性指标&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;面对突发流量，不可能临时改造架构，最快的方式就是增加机器来线性提高系统的处理能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于业务集群或者基础组件来说，扩展性 = 性能提升比例 / 机器增加比例，理想的扩展能力是：资源增加几倍，性能提升几倍。通常来说，扩展能力要维持在70%以上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是从高并发系统的整体架构角度来看，扩展的目标不仅仅是把服务设计成无状态就行了，因为当流量增加10倍，业务服务可以快速扩容10倍，但是数据库可能就成为了新的瓶颈。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;像MySQL这种有状态的存储服务通常是扩展的技术难点，如果架构上没提前做好规划（垂直和水平拆分），就会涉及到大量数据的迁移。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，高扩展性需要考虑：服务集群、数据库、缓存和消息队列等中间件、负载均衡、带宽、依赖的第三方等，当并发达到某一个量级后，上述每个因素都可能成为扩展的瓶颈点。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;高并发的实践方案有哪些？&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;了解了高并发设计的3大目标后，再系统性总结下高并发的设计方案，会从以下两部分展开：先总结下通用的设计方法，然后再围绕高性能、高可用、高扩展分别给出具体的实践方案。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;通用的设计方法&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通用的设计方法主要是从「纵向」和「横向」两个维度出发，俗称高并发处理的两板斧：纵向扩展和横向扩展。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;纵向扩展（scale-up）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;它的目标是提升单机的处理能力，方案又包括：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、提升单机的硬件性能：通过增加内存、CPU核数、存储容量、或者将磁盘升级成SSD等堆硬件的方式来提升。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、提升单机的软件性能：使用缓存减少IO次数，使用并发或者异步的方式增加吞吐量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;横向扩展（scale-out）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为单机性能总会存在极限，所以最终还需要引入横向扩展，通过集群部署以进一步提高并发处理能力，又包括以下2个方向：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、做好分层架构：这是横向扩展的前&lt;span&gt;提&lt;/span&gt;，因为高并发系统往往业务复杂，通过分层处理可以简化复杂问题，更容易做到横向扩展。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8009259259259259&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ELQw2WCMgt1db27zfRllYrkrYdTMf5OD1EherBJmH2EX2PO2Xz44f9wibK5ggLRuurWOibbVAcSDeBV6xBK2icuCA/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面这种图是互联网最常见的分层架构，当然真实的高并发系统架构会在此基础上进一步完善。比如会做动静分离并引入CDN，反向代理层可以是LVS+Nginx，Web层可以是统一的API网关，业务服务层可进一步按垂直业务做微服务化，存储层可以是各种异构数据库。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、各层进行水平扩展：无状态水平扩容，有状态做分片路由。业务集群通常能设计成无状态的，而数据库和缓存往往是有状态的，因此需要设计分区键做好存储分片，当然也可以通过主从同步、读写分离的方案提升读性能。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;具体的实践方案&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面再结合我的个人经验，针对高性能、高可用、高扩展3个方面，总结下可落地的实践方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;高性能的实践方案&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、集群部署，通过负载均衡减轻单机压力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、多级缓存，包括静态数据使用CDN、本地缓存、分布式缓存等，以及对缓存场景中的热点key、缓存穿透、缓存并发、数据一致性等问题的处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、分库分表和索引优化，以及借助搜索引擎解决复杂查询问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4、考虑NoSQL数据库的使用，比如HBase、Redis等，但是团队必须熟悉这些组件，且有较强的运维能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;5、异步化，将次要流程通过多线程、MQ、甚至延时任务进行异步处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;6、限流，需要先考虑业务是否允许限流（比如秒杀场景是允许的），包括前端限流、Nginx接入层的限流、服务端的限流。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;7、对流量进行削峰填谷，通过MQ承接流量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;8、并发处理，通过多线程将串行逻辑并行化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;9、预计算，比如抢红包场景，可以提前计算好红包金额缓存起来，发红包时直接使用即可。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;10、缓存预热，通过异步任务提前预热数据到本地缓存或者分布式缓存中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;11、减少IO次数，比如数据库和缓存的批量读写、RPC的批量接口支持、或者通过冗余数据的方式干掉RPC调用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;12、减少IO时的数据包大小，包括采用轻量级的通信协议、合适的数据结构、去掉接口中的多余字段、减少缓存key的大小、压缩缓存value等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;13、程序逻辑优化，比如将大概率阻断执行流程的判断逻辑前置、For循环的计算逻辑优化，或者采用更高效的算法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;14、各种池化技术的使用和池大小的设置，包括HTTP请求池、线程池（考虑CPU密集型还是IO密集型设置核心参数）、数据库和Redis连接池等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;15、JVM优化，包括新生代和老年代的大小、GC算法的选择等，尽可能减少GC频率和耗时。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;16、锁选择，读多写少的场景用乐观锁，或者考虑通过分段锁的方式减少锁冲突。上述方案无外乎从计算和 IO 两个维度考虑所有可能的优化点，需要有配套的监控系统实时了解当前的性能表现，并支撑你进行性能瓶颈分析，然后再遵循二八原则，抓主要矛盾进行优化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;高可用的实践方案&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、对等节点的故障转移，Nginx和服务治理框架均支持一个节点失败后访问另一个节点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、非对等节点的故障转移，通过心跳检测并实施主备切换（比如redis的哨兵模式或者集群模式、MySQL的主从切换等）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、接口层面的超时设置、重试策略和幂等设计。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4、降级处理：保证核心服务，牺牲非核心服务，必要时进行熔断；或者核心链路出问题时，有备选链路。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;5、限流处理：对超过系统处理能力的请求直接拒绝或者返回错误码。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;6、MQ场景的消息可靠性保证，包括producer端的重试机制、broker侧的持久化、consumer端的ack机制等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;7、灰度发布，能支持按机器维度进行小流量部署，观察系统日志和业务指标，等运行平稳后再推全量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;8、监控报警：全方位的监控体系，包括最基础的CPU、内存、磁盘、网络的监控，以及Web服务器、JVM、数据库、各类中间件的监控和业务指标的监控。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;9、灾备演练：类似当前的“混沌工程”，对系统进行一些破坏性手段，观察局部故障是否会引起可用性问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;高可用的方案主要从冗余、取舍、系统运维3个方向考虑，同时需要有配套的值班机制和故障处理流程，当出现线上问题时，可及时跟进处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;高扩展的实践方案&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、合理的分层架构：比如上面谈到的互联网最常见的分层架构，另外还能进一步按照数据访问层、业务逻辑层对微服务做更细粒度的分层（但是需要评估性能，会存在网络多一跳的情况）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、存储层的拆分：按照业务维度做垂直拆分、按照数据特征维度进一步做水平拆分（分库分表）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、业务层的拆分：最常见的是按照业务维度拆（比如电商场景的商品服务、订单服务等），也可以按照核心接口和非核心接口拆，还可以按照请求源拆（比如To C和To B，APP和H5）。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;最后的话&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;高并发确实是一个复杂且系统性的问题，由于篇幅有限，诸如分布式Trace、全链路压测、柔性事务都是要考虑的技术点。另外，如果业务场景不同，高并发的落地方案也会存在差异，但是总体的设计思路和可借鉴的方案基本类似。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;高并发设计同样要秉承架构设计的3个原则：简单、合适和演进。“过早的优化是万恶之源”，不能脱离业务的实际情况，更不要过度设计，合适的方案就是最完美的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;希望这篇文章能带给你关于高并发更全面的认识，如果你也有可借鉴的经验和深入的思考，欢迎评论区留言讨论。&lt;/p&gt;&lt;p&gt;&lt;span&gt;- EOF -&lt;/span&gt;&lt;/p&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_030&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section&gt;&lt;span&gt;推荐阅读&lt;/span&gt;  &lt;span&gt;点击标题可跳转&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&amp;amp;mid=2651516135&amp;amp;idx=1&amp;amp;sn=f1f14e39a9c846a43ca19a3cf40f75b0&amp;amp;chksm=bd2580988a52098e2e5f17ad8a779bed77ec94236fb30964620e50b4d1ebeeac68b6da7cef9b&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;高并发下如何防重？&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;高并发下如何防重？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&amp;amp;mid=2651513836&amp;amp;idx=1&amp;amp;sn=37a40a1e7f36845b36c3ce589efe8c77&amp;amp;chksm=bd258f938a5206853eb812b26c990147c5419e2f4897ed22594e5a285def044352e7acf133c4&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;服务端高并发分布式架构演进之路&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;服务端高并发分布式架构演进之路&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&amp;amp;mid=2651506492&amp;amp;idx=1&amp;amp;sn=b2ff75dbbe026e96e2b74eb499fd5223&amp;amp;chksm=bd25ab438a522255f8ef889431b9eb4ac67fbc51ecf9becd176b816b111d1729d6a0387596ff&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;看完这篇还不懂高并发中的线程与线程池你来打我&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;看完这篇还不懂高并发中的线程与线程池你来打我&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看完本文有收获？请转发分享给更多人&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关注「ImportNew」，提升Java技能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9166666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2A8tXicCG8ylbWIGfdoDED35IRRySQZTXUkJ1eop9MHApzFibKnOo0diboXpl0rmS5mH78YJhsWQv0dhv718A6kUA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;点赞和在看就是最大的支持&lt;/span&gt;&lt;span&gt;❤️&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a7ff4f8176fb82b948d5167cae4c3227</guid>
<title>他来了！性能吊打 Node.js 和 Deno 的新一代 javaScript 运行时！</title>
<link>https://toutiao.io/k/jbcbma9</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天跟大家介绍一个最新开源的 &lt;code&gt;javaScript&lt;/code&gt; 运行时：&lt;code&gt;Bun.js&lt;/code&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5091258405379443&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/e5Dzv8p9XdTlPCwFbaXDPLvJ4ls5TiavPXJnW6hBzdQFLultkLnksnMeSZj8oAMLtfZXJs6XyVDcib4zzKmT7HQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2082&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;刚开源不到一个月就获得了 &lt;code&gt;19.5k&lt;/code&gt; star！看起来马上就会成为 &lt;code&gt;Node.js&lt;/code&gt; 和 &lt;code&gt;Deno&lt;/code&gt; 的一大竞争对手了！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;和传统的 &lt;code&gt;Node.js&lt;/code&gt; 这种传统的 &lt;code&gt;javaScript&lt;/code&gt; 运行时不同，&lt;code&gt;Bun.js&lt;/code&gt; 直接内置了打包器、转译器、任务运行器和 &lt;code&gt;npm&lt;/code&gt; 客户端，这意味着你不再需要 &lt;code&gt;Webpack/Rollup/esbuild/Snowpack/Parcel/Rome/swc/babel&lt;/code&gt; 就可以直接运行 &lt;code&gt;TypeScript、JSX&lt;/code&gt;！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，&lt;code&gt;Bun.js&lt;/code&gt; 原生支持了数百个 &lt;code&gt;Node.js&lt;/code&gt; 和 &lt;code&gt;Web API&lt;/code&gt;，包括约 &lt;code&gt;90%&lt;/code&gt; 的 &lt;code&gt;Node-API&lt;/code&gt; 函数(&lt;code&gt;fs、path、Buffer&lt;/code&gt; 等)。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Bun.js&lt;/code&gt; 的目标是可以在浏览器之外的其他地方运行世界上大多数 &lt;code&gt;JavaScript&lt;/code&gt;，为你未来的基础架构带来性能和复杂性的增强，并通过更好、更简单的工具提高开发者的生产力！&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;性能表现如何？&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;服务端渲染：每秒处理 &lt;code&gt;HTTP&lt;/code&gt; 请求数&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.757847533632287&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/e5Dzv8p9XdTlPCwFbaXDPLvJ4ls5TiavPEtp9nKBwGDvbSbZrN5r9cs8VOeMwrxpe7Pp9e1E74iaCuR9f9mSI3Og/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;892&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;加载一个巨大的 &lt;code&gt;sqlite&lt;/code&gt; 表：每秒平均查询次数&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8521303258145363&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/e5Dzv8p9XdTlPCwFbaXDPLvJ4ls5TiavPOCfj1Odne3EEtl4OQic64q4icsn86sG6EUPye1XrtMrwnPpjI1zQsW6w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;798&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;FFI&lt;/code&gt;：每秒操作数&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6756198347107438&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/e5Dzv8p9XdTlPCwFbaXDPLvJ4ls5TiavPJzU9j6oP9cpfoNP8kNBnIt4SUyTkia3mnByXJ1RlpBNxW5jOX6mPvVw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;968&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;为啥这么快？&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;和 &lt;code&gt;Node.js、Deno&lt;/code&gt; 不同，&lt;code&gt;Bun.js&lt;/code&gt; 并没有基于 &lt;code&gt;V8&lt;/code&gt; 引擎，它直接选择了 &lt;code&gt;JavaScriptCore&lt;/code&gt; 引擎，它的执行速度往往要比 &lt;code&gt;V8&lt;/code&gt; 等更传统引擎要快。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.47533206831119545&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/e5Dzv8p9XdTlPCwFbaXDPLvJ4ls5TiavPomjx5CwcqDW4kHD3a4H1nGEEnsscceTQFy0owwzvZpHib0OIsficS1NQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2108&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，&lt;code&gt;Bun.js&lt;/code&gt; 是用一种具有手动内存管理的低级编程语言 &lt;code&gt;ZIG&lt;/code&gt; 编写的，对内存的低级控制、没有隐藏的控制流可能就是它性能非常好的秘诀。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4699812382739212&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/e5Dzv8p9XdTlPCwFbaXDPLvJ4ls5TiavPRDTQNV5qFgOE5QLjcomwDMDRRGUIUL07H3UFujosaFyloXOLmlsXow/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2132&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Bun.js&lt;/code&gt; 的大部分内容都是完全从零开始编写的，包括 &lt;code&gt;JSX/TypeScript&lt;/code&gt; 转译器、&lt;code&gt;npm&lt;/code&gt; 客户端、打包器、&lt;code&gt;SQLite&lt;/code&gt; 客户端、&lt;code&gt;HTTP&lt;/code&gt; 客户端、&lt;code&gt;WebSocket&lt;/code&gt; 客户端等等。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;有哪些能力？&lt;/span&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;Web API&lt;/code&gt;：对 &lt;code&gt;fetch、WebSocket、 ReadableStream&lt;/code&gt; 等 &lt;code&gt;API&lt;/code&gt; 都提供了内置支持&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;Node.js&lt;/code&gt; 模块：&lt;code&gt;Bun&lt;/code&gt; 实现了 &lt;code&gt;Node.js&lt;/code&gt; 的模块解析算法，同时支持 &lt;code&gt;ESM&lt;/code&gt; 和 &lt;code&gt;CommonJS&lt;/code&gt;，但 &lt;code&gt;Bun&lt;/code&gt; 内部使用 &lt;code&gt;ESM&lt;/code&gt;。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;支持转译大量文件类型，你可以直接运行 &lt;code&gt;TypeScript、JSX&lt;/code&gt;，甚至支持各种 &lt;code&gt;tsconfig.json&lt;/code&gt; 中的配置。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.230958230958231&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/e5Dzv8p9XdTlPCwFbaXDPLvJ4ls5TiavPNCDXGXPvlE7YLZE1ibQtwdnAUSb4e9yzFnyPLN4MicGjIiaunic94s4AIg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;814&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;Bun.write&lt;/code&gt; 使用最快的系统调用，实现写入、复制、管道、发送和克隆文件。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;自动加载环境变量 &lt;code&gt;.env&lt;/code&gt; 文件，不需要再 &lt;code&gt;require(&quot;dotenv&quot;).load()&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;附带一个内置的快速 &lt;code&gt;SQLite3&lt;/code&gt; 客户端 &lt;code&gt;bun:sqlite&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;Bun.js&lt;/code&gt; 实现了大部分 &lt;code&gt;Node-API&lt;/code&gt; (&lt;code&gt;N-API&lt;/code&gt;)，大部分 &lt;code&gt;Node.js&lt;/code&gt; 原生模块都可以正常工作。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;bun:ffi&lt;/code&gt; 可以使用低成本的外部函数接口从 &lt;code&gt;JavaScript&lt;/code&gt; 调用本机代码(据测试比 &lt;code&gt;napi&lt;/code&gt; 快 5 倍 、比 &lt;code&gt;Deno&lt;/code&gt; 快 &lt;code&gt;100&lt;/code&gt; 倍)&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9185059422750425&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/e5Dzv8p9XdTlPCwFbaXDPLvJ4ls5TiavPtN0PXk9yiayxHqaqOXmvuc1dKsd7ER2yctr6vIGG9LjoicSlJ6vLqibxQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1178&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;原生支持不断增长的 &lt;code&gt;Node.js&lt;/code&gt; 核心模块列表以及全局变量，例如 &lt;code&gt;Buffer&lt;/code&gt; 和 &lt;code&gt;process&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;试用一下&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;安装 &lt;code&gt;Bun CLI&lt;/code&gt;：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;curl https://bun.sh/install | bash&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;Bun&lt;/code&gt; 的 &lt;code&gt;HTTP&lt;/code&gt; 服务器基于 &lt;code&gt;Request&lt;/code&gt; 和 &lt;code&gt;Response&lt;/code&gt; 等 &lt;code&gt;Web&lt;/code&gt; 标准构建：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;// http.js&lt;/span&gt;&lt;br/&gt;&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; {&lt;br/&gt;  &lt;span&gt;port&lt;/span&gt;: &lt;span&gt;3000&lt;/span&gt;,&lt;br/&gt;  fetch(request) {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; Response(&lt;span&gt;&quot;Hi, ConardLi！Welcome to Bun!&quot;&lt;/span&gt;);&lt;br/&gt;  },&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;用 &lt;code&gt;bun&lt;/code&gt; 运行它：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;bun run http.js&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后在浏览器中打开 &lt;code&gt;http://localhost:3000&lt;/code&gt;。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;查看更多示例：https://github.com/Jarred-Sumner/bun/tree/main/examples&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;查看官方文档：https://github.com/Jarred-Sumner/bun#Reference&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CLI 命令：&lt;code&gt;bun run&lt;/code&gt;：可以直接运行 &lt;code&gt;JavaScript&lt;/code&gt; 和 &lt;code&gt;TypeScript&lt;/code&gt; 文件以及 &lt;code&gt;package.json&lt;/code&gt; 中的 &lt;code&gt;scripts&lt;/code&gt; 脚本。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;根据测试，&lt;code&gt;bun&lt;/code&gt; 运行 &lt;code&gt;package.json&lt;/code&gt; 脚本比 &lt;code&gt;npm&lt;/code&gt; 运行 &lt;code&gt;package.json&lt;/code&gt; 脚本快 30 倍。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CLI 命令：&lt;code&gt;bun install&lt;/code&gt;：兼容 &lt;code&gt;npm&lt;/code&gt; 的包管理器，使用最快的系统调用来复制文件。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4283854166666667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/e5Dzv8p9XdTlPCwFbaXDPLvJ4ls5TiavPYneMEiajERgpAfFSuw0NheAYBia9W8gE6qPvls5GMdgy9ibNQAw5WLkYA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1536&quot;/&gt;&lt;/figure&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;根据测试，bun 比 npm 的包安装速度快 20 倍。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CLI 命令：&lt;code&gt;bun wiptest&lt;/code&gt;：一个类似于 &lt;code&gt;Jest&lt;/code&gt; 的测试运行器，用于内置到 &lt;code&gt;bun&lt;/code&gt; 的 &lt;code&gt;JavaScript&lt;/code&gt; 和 &lt;code&gt;TypeScript&lt;/code&gt; 项目。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Bun 目前还处于 beta 阶段，距离生产环节还有一段路要走，大家觉得它的未来究竟如何呢？&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzg5NDEyMzA2NQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/iccXN8sGPLT448GlibKCW2RVGEL14qHxzyyponoibrYxCtZSMy8ulr2PNGcdcticP1Z3OnZWFiaWTsVgpeT8COOCgVA/0?wx_fmt=png&quot; data-nickname=&quot;小生方勤&quot; data-alias=&quot;XSFQ_HSD&quot; data-signature=&quot;这里是前端人的一片栖息之地，愿你在这里可以解开迷惑，收获喜悦。&quot; data-from=&quot;0&quot;/&gt;&lt;strong/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;在看点这里⬇️⬇️⬇️&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>85e4de88416ccbbb069cc4dd05af063e</guid>
<title>Kubernetes网络插件详解 - Flannel篇</title>
<link>https://toutiao.io/k/a1mop7y</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                  &lt;strong class=&quot;profile_nickname&quot;&gt;巨子嘉&lt;/strong&gt;
                  &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;juzijia-club&lt;/span&gt;
                  &lt;/p&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;容器，微服务及开源产品在大企业中的平台产品化建设之路&lt;/span&gt;
                  &lt;/p&gt;
                &lt;/div&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>bde59a620636457b29282657c3ee01a0</guid>
<title>浅析 Apache Kafka 分区重分配的实现原理</title>
<link>https://toutiao.io/k/grkgf9a</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                           autoTypeSetting24psection&amp;#10;                          &quot; id=&quot;js_content&quot;&gt;
            &lt;blockquote&gt;&lt;p&gt;本文作者为中国移动云能力中心大数据团队软件开发工程师孙大鹏，本文结合 2.0.0 版本的 Kafka 源码，详细介绍了 Kafka 分区副本重分配的流程和逻辑，供大家参考。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2&gt;一、前言&lt;/h2&gt;&lt;p&gt;Kafka 是由 Apache 软件基金会开发的一个开源流处理平台，旨在提供一个统一的、高吞吐、低延迟的实时数据处理平台。其持久化层本质上是一个“按照分布式事务日志架构的大规模发布/订阅消息队列”，这使它作为企业级基础设施来处理流式数据非常有价值。&lt;/p&gt;&lt;p&gt;在 Kafka 中，用 topic 来对消息进行分类，每个进入到 Kafka 的信息都会被放到一个 topic 下，同时每个 topic 中的消息又可以分为若干 partition 以此来提高消息的处理效率。存储消息数据的主机服务器被命名为 broker。通常为了保证数据的可靠性，数据是以多副本的形式保存在不同 broker 的不同磁盘上的。对于每一个 topic 的每一个 partition，如果多个副本之间完成了数据同步，保证了数据的一致性，则此时的多个副本所在的 broker 的集合称为 Isr。同一时间，某个 topic 的某个 partition 的多个副本中仅有一个对外提供服务，此时对外提供服务的 broker 被认定为该 partition 的 leader，客户端的请求都集中到 leader 上。&lt;/p&gt;&lt;p&gt;对于 2 副本 3 分区的 topic 其描述信息及存储状态如下所示：&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;bash&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__built_in&quot;&gt;test&lt;/span&gt;的描述信息：&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;Topic:&lt;span class=&quot;code-snippet__built_in&quot;&gt;test&lt;/span&gt; PartitionCount:3 ReplicationFactor:2 Configs:min.insync.replic&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;as=1&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;Topic: &lt;span class=&quot;code-snippet__built_in&quot;&gt;test&lt;/span&gt; Partition: 0 Leader: 0 Replicas: 0，1 Isr: 0，1&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;Topic: &lt;span class=&quot;code-snippet__built_in&quot;&gt;test&lt;/span&gt; Partition: 1 Leader: 2 Replicas: 2，0 Isr: 2，0&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;Topic: &lt;span class=&quot;code-snippet__built_in&quot;&gt;test&lt;/span&gt; Partition: 2 Leader: 1 Replicas: 1，2 Isr: 1，2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5196759259259259&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/rSj1QeSoL8vHLqlfKCQ3ct33f8oqGcx4uooGAakL0mg0jjVBT8Kz9qmKj2dOZOmJGx8qOGysFicE5UDPAu1dWdg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;p&gt;test的副本分布&lt;/p&gt;&lt;p&gt;健康状态的 Kafka 集群，对于每个 topic 的每个 partition，其 Isr 都应该等于预期的副本集合（后面均已 Replicas 表示），但在实际场景中，不可避免的存在磁盘/主机故障，或者 由于某些原因需要将部分 broker 节点下线的情况，此时就需要将故障/要下线的 broker 从 Replicas 中移除。对此 Kafka 提供了 kafka-reassign-partitions 工具来进行手动的分区副本迁移。&lt;/p&gt;&lt;h2&gt;二、工具的使用&lt;/h2&gt;&lt;p&gt;在 Kafka 的根路径下，通过执行如下命令，来完成分区副本的重分配：&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;./bin/kafka‐reassign‐partitions.sh ‐‐zookeeper localhost:2181/kafka ‐‐reassignment‐json‐file reassign‐topic.json ‐‐&lt;span class=&quot;code-snippet__keyword&quot;&gt;execute&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;其中:reassign‐topic.json 文件指定了分区副本的分布情况，示例如下：&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;json&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;{   &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;&quot;version&quot;&lt;/span&gt;: &lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;,   &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;&quot;partitions&quot;&lt;/span&gt;: [       &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;{         &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;&quot;topic&quot;&lt;/span&gt;: &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;test&quot;&lt;/span&gt;,         &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;&quot;partition&quot;&lt;/span&gt;: &lt;span class=&quot;code-snippet__number&quot;&gt;2&lt;/span&gt;,         &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;&quot;replicas&quot;&lt;/span&gt;: [            &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__number&quot;&gt;2&lt;/span&gt;,             &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;         &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;],         &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;&quot;log_dirs&quot;&lt;/span&gt;: [             &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__string&quot;&gt;&quot;any&quot;&lt;/span&gt;,             &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__string&quot;&gt;&quot;any&quot;&lt;/span&gt;         &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;]        &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;} &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;文件中指明了将 topic=test,partition=2 的分区的两副本分别移动到 brokerId=2 和 brokerId=1 的节点的任意磁盘路径上。&lt;/p&gt;&lt;p&gt;下面将结合 2.0.0 版本的 Kafka 源码简单的介绍下 Kafka 分区副本重分配的流程和逻辑。&lt;/p&gt;&lt;h2&gt;三、元数据管理及协调器&lt;/h2&gt;&lt;p&gt;在开始之前先简单介绍下在 Kafka 分区副本重分配中涉及到的两个概念：ZooKeeper 和 Kafka Controller。&lt;/p&gt;&lt;h3&gt;3.1 ZooKeeper&lt;/h3&gt;&lt;p&gt;Kafka 的元数据，是存储在 &lt;span&gt;ZooKeeper &lt;/span&gt;中的。Apache &lt;span&gt;ZooKeeper &lt;/span&gt;是一个提供高可靠性的分布式协调服务框架。它使用的数据模型类似于文件系统的树形结构，根目录也是以“/”开始。该结构上的每个节点被称为 znode，用来保存一些元数据协调信息。同时 ZooKeeper 赋予客户端监控 znode 变更的能力，即所谓的 Watch 通知功能。一旦 znode 节点被创建、删除，子节点数量发生变化，或是 znode 所存的数据本身变更， ZooKeeper 会通过节点变更监听器 (ChangeHandler) 的方式显式通知客户端以便客户端 触发对应的处理操作。&lt;/p&gt;&lt;h3&gt;3.2 Kafka Controller&lt;/h3&gt;&lt;p&gt;Kafka Controller 是 Apache Kafka 的核心组件，它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。集群中任意一台 Broker 都能充当控制器的角色，但是，在运行过程中，只能有一个 Broker 成为控制器，行使其管理和协调的职责。&lt;/p&gt;&lt;h2&gt;四、分区重分配流程分析&lt;/h2&gt;&lt;p&gt;Kafka 的分区重分配就是在 client、broker 和 controller 的协同运行下完成的。即：&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1.&lt;/span&gt;客户端发起分区重分配任务，在 &lt;span&gt;ZooKeeper &lt;/span&gt; 中创建/admin/reassign_partitions 节点，然 后向涉及的 broker 发送 alterReplicaLogDirs 请求&lt;/span&gt;&lt;span&gt;&lt;span&gt;2.&lt;/span&gt;controller 监测到 &lt;span&gt;ZooKeeper &lt;/span&gt;中/admin/reassign_partitions 的变化，触发 Kafka 分区元 数据的变更维护操作&lt;/span&gt;&lt;span&gt;&lt;span&gt;3.&lt;/span&gt;broker 接收到客户端发送的 alterReplicaLogDirs 请求，根据具体任务内容在服务端实际完成分区副本移动&lt;/span&gt;&lt;/p&gt;&lt;p&gt;流程总结如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5918367346938775&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/rSj1QeSoL8vHLqlfKCQ3ct33f8oqGcx4r94OJ0x4mfcSqLf2jZBPljWtJjCPOTqHPvewPKAAxSJB4Ury1iba01Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;686&quot;/&gt;&lt;/p&gt;&lt;p&gt;下面将针对这三部分分别展开介绍：&lt;/p&gt;&lt;h3&gt;4.1 kafka-reassign-partitions 客户端&lt;/h3&gt;&lt;p&gt;分区重分配任务是由客户端发起的，其入口主类为 ReassignPartitionsCommand.scala 中，调用 executeAssignment 方法。客户端的 executeAssignment 方法主要完成了如下操作：&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1.&lt;/span&gt;解析 json 文件并进行相关校验&lt;span&gt;&lt;span&gt;•&lt;/span&gt;读取 json 文件内容，校验“partitions”的“version”，仅为 1 时，继续执行副本重分 配&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;校验分区副本数和副本数据路径数是否一致&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;校验 partition/replica 是否为空/重复&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;2.&lt;/span&gt;检查待重分配的分区在集群中是否存在（根据 zk 中的/brokers/topics/${topic}）&lt;/span&gt;&lt;span&gt;&lt;span&gt;3.&lt;/span&gt;检查确认所有目标 broker 均在线（zk 中/brokers/ids 的子 znode 列表）&lt;/span&gt;&lt;span&gt;&lt;span&gt;4.&lt;/span&gt;检查是否已存在分区副本重分配任务，如果已存在相关任务，则退出&lt;/span&gt;&lt;span&gt;&lt;span&gt;5.&lt;/span&gt;将分区重分配任务记录到 zk 中，即在 zk 中创建/admin/reassign_partitions，以便 controller 可以发现并协调 broker 进行相关操作&lt;/span&gt;&lt;span&gt;&lt;span&gt;6.&lt;/span&gt;根据解析的 json 内容，逐个 topic 向相关的 broker 发送 alterReplicaLogDirs 请求&lt;/span&gt;&lt;/p&gt;&lt;p&gt;客户端的处理逻辑可总结为如下流程图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7673611111111112&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/rSj1QeSoL8vHLqlfKCQ3ct33f8oqGcx47meG9TQY97v0XZrR3zRh3bRjqjkxDbvBk9PvmiaAJl3Cz1gjysED8dA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;h3&gt;4.2 controller 维护分区的元数据信息&lt;/h3&gt;&lt;p&gt;在 controller 启动时会创建 partitionReassignmentHandler，kafkaController 主线程回调 onControllerFailover 时，检测到/admin/reassign_partitions 发生变化时，触发分区副本重分配操作，在 maybeTriggerPartitionReassignment 中通过调用 onPartitionReassignment 真正执行分区副本重分配。在 onPartitionReassignment 中定 义了三个概念：&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;RAR：指定的分区副本放置策略&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;OAR：原始的分区副本放置策略&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;AR：当前的分区副本放置策略&lt;/span&gt;&lt;/p&gt;&lt;p&gt;onPartitionReassignment 的执行过程可以总结为如下步骤：&lt;/p&gt;&lt;p&gt;检查指定的分区副本是否处在 isr 中，如果不在则执行以下前 3 步，否则直接执行第 4 步&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1.&lt;/span&gt;在 zk 中将 AR 更新为 RAR+OAR （/broker/topics/${topicName}）&lt;/span&gt;&lt;span&gt;&lt;span&gt;2.&lt;/span&gt;向所有副本（RAR+OAR）中发送 LeaderAndIsr 请求&lt;/span&gt;&lt;span&gt;&lt;span&gt;3.&lt;/span&gt;将 RAR-OAR 的副本状态置为 NewReplica，等待 NewReplica 中的数据与 leader 中的数据 完成同步&lt;/span&gt;&lt;span&gt;&lt;span&gt;4.&lt;/span&gt;等待直到所有 RAR 中的副本完成与 leader 的同步&lt;/span&gt;&lt;span&gt;&lt;span&gt;5.&lt;/span&gt;将所有 RAR 的副本置为 OnlineReplica 状态&lt;/span&gt;&lt;span&gt;&lt;span&gt;6.&lt;/span&gt;将 RAR 作为 AR&lt;/span&gt;&lt;span&gt;&lt;span&gt;7.&lt;/span&gt;如果当前的 leader 不在 RAR 中，发送 LeaderAndIsr Request 从 RAR 中选出一个新的 leader；如果当前 leader 在 RAR 中，检查 leader 状态，如果 leader 健康则更新 LeaderEpoch，否则重新选择 leader&lt;/span&gt;&lt;span&gt;&lt;span&gt;8.&lt;/span&gt;将 OAR-RAR 的副本置为 Offline 状态&lt;/span&gt;&lt;span&gt;&lt;span&gt;9.&lt;/span&gt;将 OAR-RAR 的副本置为 NonExistentReplica 状态（真实删除对应的分区副本）&lt;/span&gt;&lt;span&gt;&lt;span&gt;10.&lt;/span&gt;将 zk 中的 AR 置为 RAR（/brokers/topics/${topicName}数据格式：{&quot;version&quot;:1,&quot;partitions&quot;:{&quot;0&quot;:[${brokerId}]}}）&lt;/span&gt;&lt;span&gt;&lt;span&gt;11.&lt;/span&gt;更新 zk 中/admin/reassign_partitions 的值，将完成迁移的分区删除&lt;/span&gt;&lt;span&gt;&lt;span&gt;12.&lt;/span&gt;同步所有 broker，更新元数据信息&lt;/span&gt;&lt;/p&gt;&lt;p&gt;逻辑流程图如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.2453703703703705&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/rSj1QeSoL8vHLqlfKCQ3ct33f8oqGcx4CbAbPfjT1GR1icW2TkLStIibmtib6mD7MFx0txoYEp0IE1WeGHP6GtfNw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;h3&gt;4.3 broker 端数据跨路径迁移&lt;/h3&gt;&lt;p&gt;底层数据跨路径迁移，是由 broker 端完成的，broker 接收到客户端发来的 ALTER_REPLICA_LOG_DIRS 请求后，调用 alterReplicaLogDirs 方法，相关流程如下：&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1.&lt;/span&gt;确保目的路径/待移动分区在线&lt;/span&gt;&lt;span&gt;&lt;span&gt;2.&lt;/span&gt;如果当前分区副本的 log 路径不存在给定的目的路径并且 futureLogs（用于跨路径数据迁移的中间过程）也不包含目的路径，则在内存中记录当前分区副本和目的 logDir，即标记那些需要进行迁移的分区副本路径&lt;/span&gt;&lt;span&gt;&lt;span&gt;3.&lt;/span&gt;对于需要移动的分区副本，目的 broker 的路径中创建 future Log&lt;/span&gt;&lt;span&gt;&lt;span&gt;4.&lt;/span&gt;停止当前 Log 的清理工作，等待 future Log 同步完再清理&lt;/span&gt;&lt;span&gt;&lt;span&gt;5.&lt;/span&gt;创建 ReplicaAlterLogDirsThread,逐个 topic 逐个 partition 获取 fetchOffset、 logStartOffset 、fetchSize 等数据构造 Fetch 请求&lt;/span&gt;&lt;span&gt;&lt;span&gt;6.&lt;/span&gt;通过 ReplicaManager.fetchMessages 从分区副本 leader 获取数据，完成数据同步&lt;/span&gt;&lt;/p&gt;&lt;p&gt;更详细的处理流程如下图所示：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9178240740740741&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/rSj1QeSoL8vHLqlfKCQ3ct33f8oqGcx4C3JXF729KiagDaJ1619hfouibqvlF63Jsy2gduictkfbCK8Y8fR9c0scA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;864&quot;/&gt;&lt;/p&gt;&lt;h2&gt;五、总结&lt;/h2&gt;&lt;p&gt;Kafka 分区重分配，通过 kafka-reassign-partitions 启动任务，将任务记录在元数据管理器 &lt;span&gt;ZooKeeper &lt;/span&gt;中，Kafka controller 通过对 &lt;span&gt;ZooKeeper &lt;/span&gt;的监测，发现相关任务通过和 broker 的交互按序处理相关的迁移任务，同时 controller 实时维护 &lt;span&gt;ZooKeeper &lt;/span&gt;中的元数据信息并进行相关变化的记录，保证在重分配过程中，不影响 topic 分区的正常使用，在任务完成后，再由 controller 负责 &lt;span&gt;ZooKeeper &lt;/span&gt;中重分配任务标记的清理，以便客户端验证重分配任务的结果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>333168480903713e5979d4595257cd5d</guid>
<title>一种快速判断点在多边形内的算法 - sunsky303 - 博客园</title>
<link>https://toutiao.io/k/tk72sfy</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div id=&quot;cnblogs_post_body&quot; class=&quot;blogpost-body blogpost-body-html&quot;&gt;
&lt;p&gt;由于业务需要， 我总结了一种快速判断点在多边形内的算法。&lt;/p&gt;
&lt;h2&gt;先说思路：&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2022.cnblogs.com/blog/420532/202207/420532-20220711214724789-515700249.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如图：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果点在多边形内部，射线第一次穿越边界一定是穿出多边形。&lt;/li&gt;
&lt;li&gt;如果点在多边形外部，射线第一次穿越边界一定是进入多边形。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以归纳出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;当射线穿越多边形边界的次数为偶数时，所有第偶数次（包括最后一次）穿越都是穿出，因此所有第奇数次（包括第一次）穿越为穿入，由此可推断点在多边形外部。&lt;/li&gt;
&lt;li&gt;当射线穿越多边形边界的次数为奇数时，所有第奇数次（包括第一次和最后一次）穿越都是穿出，由此可推断点在多边形内部。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2&gt;实现关键点&lt;/h2&gt;
&lt;h3&gt;1. 点在多边形的边上&lt;/h3&gt;
&lt;p&gt;前面我们讲到，射线法的主要思路就是计算射线穿越多边形边界的次数。那么对于点在多边形的边上这种特殊情况，射线出发的这一次，是否应该算作穿越呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2022.cnblogs.com/blog/420532/202207/420532-20220711215309565-59031607.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;思路： 先求边和点的交点， 即边的起点y乘以边斜率，得到交点的x， 若x == X， X是参考点的横坐标，则点在线上。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;2. 点和多边形的顶点重合&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2022.cnblogs.com/blog/420532/202207/420532-20220711215813678-1744237223.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;思路：参考点与边顶点重合，则直接是 x == X &amp;amp;&amp;amp; y == Y ，其中x,y是边顶点， X,Y是参考点， 则直接返回。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;3. 射线经过多边形顶点&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2022.cnblogs.com/blog/420532/202207/420532-20220711220539385-1514772224.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;思路：这时相交点次数无论内外都是偶数次，无法判断。不过，这里看射线两侧的边如果都在两侧时算作一次“穿过”，即 y == Y时， x1 &amp;gt; X 并且 x2 &amp;lt;= X (或  x1 &amp;lt; X 且 x2 &amp;gt; X），穿过数次加1 , 其中X，Y是参考点， x1,y1 ,  x2, y2是线段顶点。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;4. 射线刚好经过一条边&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://img2022.cnblogs.com/blog/420532/202207/420532-20220711221230450-1951006409.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;思路： 这个最简单， 直接判断 y == Y，可以理解成穿过了这条边的2个顶点， Y是参考点的纵坐标， y是边的纵坐标。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;问题都解决了，其实并不复杂。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2&gt;实现代码&lt;/h2&gt;
&lt;pre class=&quot;language-bash highlighter-hljs&quot;&gt;&lt;code&gt;type Point struct {
X float64
Y float64
}

func IfPointsInPolygon(point Point, area []Point) bool {
// 目标点的x, y坐标
x := point.X
y := point.Y

// 多边形的点数
count := len(area)

// 点是否在多边形中
var inInside bool

// 浮点类型计算与0的容差
precision := 2e-10

// 依次计算每条边，根据每边两端点和目标点的状态栏判断
for i, j := 0, count-1; i &amp;lt; count; j, i = i, i+1 {
// 记录每条边上的两个点坐标
x1 := area[i].X
y1 := area[i].Y
x2 := area[j].X
y2 := area[j].Y

// 判断点与多边形顶点是否重合
if (x1 == x &amp;amp;&amp;amp; y1 == y) || (x2 == x &amp;amp;&amp;amp; y2 == y) {
return true
}

// 判断点是否在水平直线上
if (y == y1) &amp;amp;&amp;amp; (y == y2) {
return true
}

// 判断线段两端点是否在射线两侧
if (y &amp;gt;= y1 &amp;amp;&amp;amp; y &amp;lt; y2) || (y &amp;lt; y1 &amp;amp;&amp;amp; y &amp;gt;= y2) {
// 斜率
k := (x2 - x1) / (y2 - y1)

// 相交点的 x 坐标
_x := x1 + k*(y-y1)

// 点在多边形的边上
if _x == x {
return true
}

// 浮点类型计算容差
if math.Abs(_x-x) &amp;lt; precision {
return true
}

// 射线平行于x轴，穿过多边形的边
if _x &amp;gt; x {
inInside = !inInside
}
}
}

return inInside
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;language-bash highlighter-hljs&quot;&gt;&lt;code&gt;#压测
/private/var/folders/9l/9h6c50j93qs8c43wpwnvhnbc0000gn/T/GoLand/___gobench_common_algorithm_polygon.test -test.v -test.paniconexit0 -test.bench . -test.run ^$
goos: darwin
goarch: amd64
pkg: common/algorithm/polygon
cpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz
BenchmarkPIP
BenchmarkPIP-12    29140065        40.57 ns/op
PASS&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>