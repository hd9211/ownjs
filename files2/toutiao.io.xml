<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>f60272d343e086c7e0b11f2cd03824e6</guid>
<title>惊！这个 Go 开源项目号称「不改一行代码做秒杀」</title>
<link>https://toutiao.io/k/qnyxbs9</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;23&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;span&gt;阅读本文大概需要 2 分钟。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，我是 polarisxu。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到耗子叔发推文推荐了一个新开源的网关：Easegress。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.43005181347150256&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UzjmETLXwBaZWKKF0aSaChclOHu7laFedvaxa0eueVuPxwnhF2HdGLz3ZIrMTaEwy6DJ5TfbyHNMhhYgArxW5w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1158&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;打开看了下，这是一个 Go 语言实现的开源项目。它有如下亮点：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;高可用。内置 Raft 共识和领导者选举，提供 99.99％ 的可用性。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;流量编排。将各种过滤器动态地编排到流量管道。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;高性能。轻量级和基础特性提升性能。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;可观察性。以可读方式定期存放许多有意义的统计数据。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;可扩展性。使用高级编程语言开发自己的过滤器或控制器很容易。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一体化。简单的接口使其易于与其他系统集成，例如 Kubernetes Ingress，Easemesh Sidecar，Workflow 等。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;给一张架构图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4578125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UzjmETLXwBaZWKKF0aSaChclOHu7laFelnG5ouQsoNo4HAlGd7I5LXFaMlz93Kr5NEfywFoXLgdY4jibAxEevEA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体的功能特性，耗子叔给了一张图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;3.8641509433962264&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UzjmETLXwBaZWKKF0aSaChclOHu7laFecibnIyqiak6pfS1LYmYvaicg33tbR7Tcz4fkzGmia2LfYfAicRAiakiawibemQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1060&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看起来很强大，而且他们公司的产品宣传是：&lt;strong&gt;不改一行代码做秒杀&lt;/strong&gt;。有机会可以深入学习研究下。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然是国人开源项目，不过文档是全英文的，没有中文版。很显然是要走向国际的。&lt;strong&gt;阅读原文&lt;/strong&gt;可以直达项目首页：https://github.com/megaease/easegress。&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;hr/&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;往期推荐&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UzjmETLXwBYuP3ncUTaemHXQYjOZDS40VoicqII73Hu9RncJv06g0kJhnrVicSmUfJRg5Wf9qcDHj7zf5vTjns5A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;258&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我是 polarisxu，北大硕士毕业，曾在 360 等知名互联网公司工作，10多年技术研发与架构经验！2012 年接触 Go 语言并创建了 Go 语言中文网！著有《&lt;/span&gt;&lt;span&gt;Go语言编程之旅&lt;/span&gt;&lt;span&gt;》、开源图书《&lt;/span&gt;&lt;span&gt;Go语言标准库&lt;/span&gt;&lt;span&gt;》等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;坚持输出技术（包括 Go、Rust 等技术）、职场心得和创业感悟！欢迎关注「polarisxu」一起成长！也欢迎加我微信好友交流：&lt;/span&gt;&lt;span&gt;gopherstudio&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e39ca2426990cde6c0193caf09cc2601</guid>
<title>ClickHouse 数据目录完全解析</title>
<link>https://toutiao.io/k/3ldiykv</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;        之前文章有介绍过基础的MergeTree的物理存储结构，数据会按分区目录的形式保存到磁盘。本文着重介绍一些二进制文件的格式及内容。&lt;/p&gt;&lt;p&gt;        首先按照如下规则创建表，用于后续数据的对照查询&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;TABLE&lt;/span&gt; default.ansel&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;(&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__string&quot;&gt;`a`&lt;/span&gt; Int32,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__string&quot;&gt;`b`&lt;/span&gt; Int32,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__string&quot;&gt;`c`&lt;/span&gt; Int32,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;INDEX&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;`idx_c`&lt;/span&gt; (c) &lt;span class=&quot;code-snippet__keyword&quot;&gt;TYPE&lt;/span&gt; minmax GRANULARITY &lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;ENGINE&lt;/span&gt; = MergeTree&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;BY&lt;/span&gt; a &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;BY&lt;/span&gt; b&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;SETTINGS&lt;/span&gt; index_granularity=&lt;span class=&quot;code-snippet__number&quot;&gt;3&lt;/span&gt;, index_granularity_bytes = &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;into&lt;/span&gt; default.ansel(a,b,c) &lt;span class=&quot;code-snippet__keyword&quot;&gt;values&lt;/span&gt;(&lt;span class=&quot;code-snippet__number&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;10&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;9&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;5&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;8&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;6&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;7&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;7&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;6&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;8&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;5&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;9&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;10&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;        注意：设置index_granularity_bytes = 0取消自适应索引粒度，便于后续观察mrk文件结构。&lt;/section&gt;&lt;section&gt;        插入后看一下测试数据如下：&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4975609756097561&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5aZzibwULnhUGicRWFXtGFMEBicAmR0ugTYAg6DMD4TYxeHlhwkib9xTytg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;820&quot;/&gt;&lt;/p&gt;&lt;section&gt;        生成的数据文件如下：&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;[clickhouse@localhost /&lt;span class=&quot;code-snippet__keyword&quot;&gt;var&lt;/span&gt;/lib/clickhouse/data/&lt;span class=&quot;code-snippet__keyword&quot;&gt;default&lt;/span&gt;/ansel ]$ tree&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;├── &lt;span class=&quot;code-snippet__number&quot;&gt;3_1_1_0&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── a.bin&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── a.mrk&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── b.bin&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── b.mrk&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── &lt;span class=&quot;code-snippet__built_in&quot;&gt;c&lt;/span&gt;.bin&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── checksums.txt&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── &lt;span class=&quot;code-snippet__built_in&quot;&gt;c&lt;/span&gt;.mrk&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── columns.txt&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── &lt;span class=&quot;code-snippet__built_in&quot;&gt;count&lt;/span&gt;.txt&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── minmax_a.idx&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── &lt;span class=&quot;code-snippet__built_in&quot;&gt;partition&lt;/span&gt;.dat&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── primary.idx&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   ├── skp_idx_idx_c.idx&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│   └── skp_idx_idx_c.mrk&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;├── detached&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;└── format_version.txt&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;        一般的数据目录结构如下：&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;table_name                                 &lt;span class=&quot;code-snippet__meta&quot;&gt;#表名&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;├─ partition_{index}            DIR        &lt;span class=&quot;code-snippet__meta&quot;&gt;#分区目录&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  │  &lt;span class=&quot;code-snippet__meta&quot;&gt;# 基础文件&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  ├─ checksums.txt             BIN        &lt;span class=&quot;code-snippet__meta&quot;&gt;#各类文件的尺寸以及尺寸的散列&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  ├─ columns.txt               TXT        &lt;span class=&quot;code-snippet__meta&quot;&gt;#列信息&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  ├─ count.txt                 TXT        &lt;span class=&quot;code-snippet__meta&quot;&gt;#当前分区目录下数据总行数&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  ├─ primary.idx               BIN        &lt;span class=&quot;code-snippet__meta&quot;&gt;#稀疏索引文件&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  ├─ {column}.bin              BIN        &lt;span class=&quot;code-snippet__meta&quot;&gt;#经压缩的列数据文件，以字段名命名&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  ├─ {column}.mrk              BIN        &lt;span class=&quot;code-snippet__meta&quot;&gt;#列字段标记文件&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  ├─ {column}.mrk2             BIN        &lt;span class=&quot;code-snippet__meta&quot;&gt;#使用自适应索引间隔的标记文件&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  │&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  │  &lt;span class=&quot;code-snippet__meta&quot;&gt;# 分区键文件&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  ├─ partition.dat             BIN        &lt;span class=&quot;code-snippet__meta&quot;&gt;#当前分区表达式最终值&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  ├─ minmax_{column}.idx       BIN        &lt;span class=&quot;code-snippet__meta&quot;&gt;#当前分区字段对应原始数据的最值&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  │ &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  │  &lt;span class=&quot;code-snippet__meta&quot;&gt;# 跳数索引文件&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  ├─ skp_idx_{column}.idx      BIN        &lt;span class=&quot;code-snippet__meta&quot;&gt;#跳数索引文件&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│  └─ skp_idx_{column}.mrk      BIN        &lt;span class=&quot;code-snippet__meta&quot;&gt;#跳数索引表及文件&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;│&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;└─ partition_{index}            DIR        &lt;span class=&quot;code-snippet__meta&quot;&gt;#分区目录&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;        列信息文件，使用文本文件存储，用于保存分区下的列字段信息。&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2234185733512786&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5AhtMEntsXFP2ooXBNqwCeibufUds58xSr0RWvBw842QsqE1m6nt6HHw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;743&quot;/&gt;&lt;/p&gt;&lt;section&gt;        记录了有多少个字段，及字段名字和类型。&lt;/section&gt;&lt;section&gt;        计数文件，文本文件存储，用于记录当前数据分区目录下数据的总行数。&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.094211123723042&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5j6DU4v2jJWgNodKPiaT1L9ic6fXmwzkeL7mPhvTZyBNg8bWRQc1Tkcuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;881&quot;/&gt;&lt;/p&gt;&lt;section&gt;        记录了该part中row的数量。&lt;/section&gt;&lt;section&gt;        一级索引文件，使用二进制格式存储。&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.13459399332591768&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5JWWICFYpZgKlYBnxqgv8VMiaJxprSn32mW01dYiaklv5cialLQuHhibRhA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;899&quot;/&gt;&lt;/p&gt;&lt;section&gt;        主键索引，根据index_granularity索引粒度，每index_granularity行取一个主键列的值组合起来作为索引，例子中并没有设置PRIMARY KEY，clickhouse在这种情况下默认将ORDER BY的字段默认作为PRIMARY KEY，所以这里的primary.idx是根据b字段的数据进行固定间隔抽取的。例子中index_granularity=3，所以primary.idx中存的是4、7、10。&lt;/section&gt;&lt;section&gt;        列字段标记，使用二进制格式存储。标记文件中保存了bin文件中数据的偏移量信息，mrk文件与稀疏文件对齐，又与bin文件一一对应，所以MergeTree通过标记文件建立了primary.idx稀疏索引与bin数据文件的映射关系&lt;/section&gt;&lt;p&gt;        以b.mrk为例&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.12594187298170076&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW51oXBev7kWAanRMFIsf6aKKuPIZ7Z5tet6mg8icYmicENbeWkTr1Tdf5g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;929&quot;/&gt;&lt;/p&gt;&lt;section&gt;        mrk文件分为两列，第一个值对应bin文件中压缩后数据块的偏移量，第二个值对应bin文件解压后数据块的偏移量，单位均为字节。Int32为4字节，索引粒度为3，所以数据块的偏移量是0、12、24。&lt;/section&gt;&lt;section&gt;        直观点可以表示成下面规则：&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3006198347107438&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5P4oGuTDQaSG4q5oQvbha3e8xATHQDib8tqIvDTibj1FLtPR9vicBLq63g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;968&quot;/&gt;&lt;/p&gt;&lt;section&gt;        所以primary.idx和mrk的行是一一对应。&lt;br/&gt;&lt;/section&gt;&lt;p&gt;        数据文件，使用压缩格式存储，默认使用LZ4压缩格式，用于存储某一列的数据。&lt;/p&gt;&lt;p&gt;        以b.bin为例&lt;/p&gt;&lt;p&gt;        一个压缩数据块由头信息和压缩数据两部分组成。头信息固定使用9位字节表示，具体由1个UInt8(1字节)和2个UInt32(4字节)整型组成，分别代表了使用的压缩算法类型、压缩后的数据大小和压缩前的数据大小。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3109700815956482&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5d63jvsKb5Eq63wdl2tiaE0djSdia9eliaVibrbeTTBvQbKbwDpjfUCc80Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1103&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Checksum：该bin文件的校验值，16字节。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Block：数据块，包含Head和CompressedData。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Head：包含CompressionMethod、CompressedSize、UncompressedSize三部分，其中CompressionMethod类型为UInt8占4字节，包含LZ4（0x82）、ZSTD（0x90）、Multipile（0x91）、Delta（0x92）,CompressedSize类型为UInt32占4字节，UncompressedSize类型同样为UInt32占4字节。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;CompressedData：压缩数据块，默认最小65535字节/64K，最大1048576字节/1M。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;        查看bin文件内容可以使用官方的clickhouse-compressor，其余bin文件都可以用这个方法&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;clickhouse-compressor &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.16717095310136157&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5McVCHax60Of5cCa3yHB7brCnFHsEwicyz3mLhibndibib8PiaJZpWsBqWVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1322&quot;/&gt;&lt;/p&gt;&lt;section&gt;        还可以通过clickhouse-compressor查看b.bin的统计信息。&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;http&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attribute&quot;&gt;clickhouse-compressor --stat &amp;lt; b.bin&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.05693296602387511&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5InggAQiavGDLLfiaw7RGfbxU8lOKR7R7pH9Kr2dY7rlF2VSqkA5tmxuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1089&quot;/&gt;&lt;/p&gt;&lt;section&gt;        其中28表示压缩前数据大小，因为从4-10，每个数字占4字节，一共28字节，39表示压缩后数据大小，因为数据量太小，压缩也要有些必要的字节表示一些元信息，所以会比压缩前大，也可以再插入些数据再观察一下，如：&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;into&lt;/span&gt; default.ansel(a,b,c) &lt;span class=&quot;code-snippet__keyword&quot;&gt;values&lt;/span&gt;(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;10&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;9&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;5&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;8&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;6&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;7&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;7&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;6&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;8&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;5&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;9&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;10&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;11&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;7&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;12&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;13&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;8&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;14&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;6&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;15&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;16&lt;/span&gt;),(&lt;span class=&quot;code-snippet__number&quot;&gt;4&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;6&lt;/span&gt;,&lt;span class=&quot;code-snippet__number&quot;&gt;17&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;‍&lt;/span&gt;&lt;/p&gt;&lt;section&gt;        可以发现，压缩后是小的，如下：&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.05853658536585366&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5rYmuUa2doGXUQmKiajXIhN2Aia028EZnMGib6apoZHF3kAymkRAOwhKuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1025&quot;/&gt;&lt;/p&gt;&lt;section&gt;        还回到原始数据的b.bin，看下二进制文件&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.11180992313067785&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5QViaXKnrpHFqzP1FSGtBNcxWHRGBFTfkTV8N6TVRY9EJKQ5Vc8t4Ppg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1431&quot;/&gt;&lt;/p&gt;&lt;section&gt;        第一行16个自己就是Checksum值；&lt;/section&gt;&lt;section&gt;        第二行第一个字节0x82就是压缩算法，这里就是默认的LZ4，第三到第五字节就是CompressedSize，这里centos7中安装的ck，所以是小端模式，所以要把27 00 00 00反过来看，即00 00 00 27，转换成10进制就是39，所以和上面的clickhouse-compressor中第二个数字39是一致的；继续向后看4个字节，反过来就是00 00 00 1c，即十进制的28，和上面的clickhouse-compressor中第二个数字28是一致的；再向后就涉及LZ4压缩的内容了&lt;/section&gt;&lt;section&gt;        还可以通过clickhouse-compressor直接看数据的16进制存储&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.07215189873417721&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5BaYqryicQSqVia1lcYPgDRHLBcgVleeQXuDnPGgJkFhjibcTQ8TvC5I6g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1580&quot;/&gt;&lt;/p&gt;&lt;p&gt;        可以看到从04 00 00 00到0a 00 00 00，反过来看也就是4-10&lt;/p&gt;&lt;p&gt;        用于保存当前分区下分区表达式最终生成值。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.05429864253393665&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5DUItPdS4RNKtYAfliazeLNib53ic1cqpeHFmlTeUtsBZfSZm8IWw3ZibyA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1105&quot;/&gt;&lt;/p&gt;&lt;section&gt;        记录了该part的partition最终计算值，与3_1_1_0的3是一致的&lt;/section&gt;&lt;section&gt;        用于记录当前分区字段对应原始数据的最小值和最大值&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.05258386219401632&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5xRCUEPqZBMt7HJS63r8u1wOxIJWubyia2ibgpcrx8nMAPGR3R2fQicUlQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1103&quot;/&gt;&lt;/p&gt;&lt;section&gt;        校验文件，使用二进制存储，保存了各类文件的size大小和size的哈希值，用于快速校验文件的完整性和正确性。&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5242857142857142&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPxCEXhJ7jWm6hia1Co7ZiaQW5banfrTdRXwRib9X7Lg71wcqbnSeBtOZj8rKJqW6QicxPC4UFd6EiaLLjA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;section&gt;        从中能看到各个column的bin和mrk文件、primary.idx、minmax_a.idx、skp_idx_c.idx、skp_idx_c.mrk的checksum值都会记录在该二进制文件中。&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;近期文章推荐：&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzkyNDIxNjQ3MQ==&amp;amp;mid=2247484154&amp;amp;idx=1&amp;amp;sn=b0f8ffc7ef927da4ee20a95851a51686&amp;amp;chksm=c1d87f02f6aff6145669a710eb80a1792e3de45eca4c2cd77fc9de98f3ddc9d172c5dac4a3ba&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;        ClickHouse优化典藏&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzkyNDIxNjQ3MQ==&amp;amp;mid=2247484165&amp;amp;idx=1&amp;amp;sn=05b9c7ead699867b31feb3876ce8ebac&amp;amp;chksm=c1d87efdf6aff7eb5cd49c5c85142e7eb5eb98b1389beff808dc29344d5654d6da6a4b060f0c&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;        ClickHouse 之 Server Settings&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzkyNDIxNjQ3MQ==&amp;amp;mid=2247484176&amp;amp;idx=1&amp;amp;sn=651a3c543418520206ec4ebbab7e7b04&amp;amp;chksm=c1d87ee8f6aff7fefc1dc0406e1a5606930b9f51fe9cdc47c921db0f1b3d8c30bb45eb76402f&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;        ClickHouse那些年我们遇到过的问题&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;更多精彩内容欢迎关注微信公众号&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/WAG0WbTTFPzZwtbpCF52qmgFw01uPdHJxfSYHtbZWsial5wEnzOzicr6u916XE1ibUDvQnUxMicuAYuibfIGkGa9M7g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>da5e335dd0436d8d8a58f37808f6911d</guid>
<title>ACL 2021｜美团提出基于对比学习的文本表示模型，效果提升 8%</title>
<link>https://toutiao.io/k/4v7pi9s</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;48&quot; data-ratio=&quot;0.10078125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUrXicw2VXTQTVVN5yxXWEacdY1ZdxTH195Pgibtib8EENJRMia3tzEnyVfgyfAgRibMssKqwlE186TLSw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总第455&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;篇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2021年 第025篇&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;127&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;127&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;img border=&quot;0&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;93&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;93&quot; data-ratio=&quot;0.9966329966329966&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVLR21NicmyQxcmiaqQ2KOJJj2JLwgJL4KSbo7CcuMF1hLf4xFjGQiaDRhSPyERxWGChWYP47Oc4sKGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;594&quot; data-width=&quot;100%&quot; opacity=&quot;&quot; title=&quot;undefined&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; data-style=&quot;text-align: left; font-size: 14px; color: inherit;&quot;&gt;&lt;section&gt;&lt;span&gt;尽管基于BERT的模型在NLP诸多下游任务中取得了成功，直接从BERT导出的句向量表示往往被约束在一个很小的区域内，表现出很高的相似度，因而难以直接用于文本语义匹配。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为解决BERT原生句子表示这种“坍缩”现象，美团NLP中心知识图谱团队提出了基于对比学习的句子表示迁移方法——ConSERT，通过在目标领域的无监督语料上Fine-tune，使模型生成的句子表示与下游任务的数据分布更加适配。在句子语义匹配（STS）任务的实验结果显示，同等设置下ConSERT相比此前的SOTA大幅提升了8%，并且在少样本场景下仍表现出较强的性能提升。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1. 背景&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2. 研究现状和相关工作&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3. 模型介绍&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3.1 问题定义&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3.2 基于对比学习的句子表示迁移框架&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3.3 用于文本领域的数据增强方法探索&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3.4 进一步融合监督信号&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4. 实验分析&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.1 无监督实验&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.2 有监督实验&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.3 不同的数据增强方法分析&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.4 少样本设置下的实验分析&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.5 Temperature超参的实验分析&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.6 Batch size超参的实验分析&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;5. 总结&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;参考文献&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;作者简介&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;| 论文：《ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer》&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;| 会议&lt;/strong&gt;：ACL 2021&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;| 下载链接&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;https://arxiv.org/abs/2105.11741&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;https://arxiv.org/abs/2105.11741&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2105.11741&quot; data-linktype=&quot;2&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;| 开源代码&lt;/strong&gt;：&lt;/span&gt;&lt;a href=&quot;https://github.com/yym6472/ConSERT&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;https://github.com/yym6472/ConSERT&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1. 背景&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;句向量表示学习在自然语言处理（&lt;/span&gt;&lt;span&gt;NLP&lt;/span&gt;&lt;span&gt;）领域占据重要地位，许多NLP任务的成功离不开训练优质的句子表示向量。特别是在文本语义匹配（&lt;/span&gt;&lt;span&gt;Semantic Textual Similarity&lt;/span&gt;&lt;span&gt;）、文本向量检索（&lt;/span&gt;&lt;span&gt;Dense Text Retrieval&lt;/span&gt;&lt;span&gt;）等任务上，模型通过计算两个句子编码后的Embedding在表示空间的相似度来衡量这两个句子语义上的相关程度，从而决定其匹配分数。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;尽管基于BERT的模型在诸多NLP任务上取得了不错的性能（&lt;/span&gt;&lt;span&gt;通过有监督的Fine-tune&lt;/span&gt;&lt;span&gt;），但其自身导出的句向量（&lt;/span&gt;&lt;span&gt;不经过Fine-tune，对所有词向量求平均&lt;/span&gt;&lt;span&gt;）质量较低，甚至比不上Glove的结果，因而难以反映出两个句子的语义相似度&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 3036.8 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot; transform=&quot;translate(1056, 0)&quot;/&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot; transform=&quot;translate(1334, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(1834, 0)&quot;/&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot; transform=&quot;translate(2112, 0)&quot;/&gt;&lt;path data-c=&quot;33&quot; d=&quot;M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z&quot; transform=&quot;translate(2390, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(2890, 0)&quot;/&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot; transform=&quot;translate(3168, 0)&quot;/&gt;&lt;path data-c=&quot;34&quot; d=&quot;M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z&quot; transform=&quot;translate(3446, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(3946, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;。我们在研究的过程中进一步分析了BERT导出的句向量所具有的特性，证实了以下两点：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;BERT对所有的句子都倾向于编码到一个较小的空间区域内，这使得大多数的句子对都具有较高的相似度分数，即使是那些语义上完全无关的句子对（&lt;span&gt;如图1a所示&lt;/span&gt;）。我们将此称为BERT句子表示的“坍缩（&lt;span&gt;Collapse&lt;/span&gt;）”现象。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.49024707412223667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsW8OBYwCuKFqGIAJMgzCCktnHvdOSwgCTC41dzyKNM6KS4oqKJyDObnwkTWFibmbj8OUDKsRSfrsrg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1538&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图1 左：BERT表示空间的坍缩问题（横坐标是人工标注的相似度分数，纵坐标是模型预测的余弦相似度）；右：经过我们的方法Fine-tune之后&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;ol start=&quot;2&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;BERT句向量表示的坍缩和句子中的高频词有关。具体来说，当通过平均词向量的方式计算句向量时，那些高频词的词向量将会主导句向量，使之难以体现其原本的语义。当计算句向量时去除若干高频词时，坍缩现象可以在一定程度上得到缓解（&lt;/span&gt;&lt;span&gt;如图2蓝色曲线所示&lt;/span&gt;&lt;span&gt;）。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5038167938931297&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsW8OBYwCuKFqGIAJMgzCCkthxIKqfEyxa0cAJgC2O2SHrgrBhHLyibUyMPffKXJEHXC9F2HVkO8Xyw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1834&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图2 计算句向量时移除Top-K高频词后的性能变化&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;BERT导出的句向量难以直接用于下游的语义匹配任务，而用于Fine-tune的监督语料又是昂贵的。因此我们希望寻找一种自监督的方法，只需要收集少量来自于下游任务无标注的文本用于Fine-tune，就能解决BERT句向量的“坍缩”问题，同时让其表征更适用于下游任务。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在本文中，我们使用了对比学习（&lt;/span&gt;&lt;span&gt;Contrastive Learning&lt;/span&gt;&lt;span&gt;）来达到上述目的。对比学习是目前被广泛应用的自监督任务之一，其核心思想为：人类是通过“对比”来辨别对象的，因此相似的事物在编码后的表示空间中应当相近，不同的事物则应当相距尽可能远。通过对同一样本施加不同的数据增强方法，我们能够得到一系列“自相似”的文本对作为正例，同时将同一个Batch内的其他文本作为负例，以此为监督信号去规范BERT的表示空间。在实验中，我们发现对比学习能够出色地消解高频词对句子语义表示的干扰（&lt;/span&gt;&lt;span&gt;如图2橙色曲线所示&lt;/span&gt;&lt;span&gt;）。在经过对比学习训练之后，模型生成的句子表示将不再由高频词主导（体现在移除前几个高频词后，性能没有出现非常明显的变化）。这是因为对比学习“辨别自身”的学习目标能够天然地识别并抑制这类高频特征，从而避免语义相差较大的句子表示过于相近（&lt;/span&gt;&lt;span&gt;即坍缩现象&lt;/span&gt;&lt;span&gt;）。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在对比学习中，我们进一步分析了不同的数据增强方法在其中的影响，同时验证了我们的方法在少样本情况下的性能表现。实验结果显示，即使是在非常有限的数据量情况下（&lt;/span&gt;&lt;span&gt;如1000条无标注样本&lt;/span&gt;&lt;span&gt;），我们的方法仍然表现出很强的鲁棒性，能够十分有效地解决BERT表示空间的坍缩问题，提升在下游语义匹配任务上的指标。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2. 研究现状和相关工作&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.1 句子表征学习&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;句子表征学习是一个很经典的任务，分为以下三个阶段：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;有监督的句子表征学习方法：早期的工作&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 796.7 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;35&quot; d=&quot;M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;发现自然语言推理（&lt;/span&gt;&lt;span&gt;Natural Language Inference，NLI&lt;/span&gt;&lt;span&gt;）任务对语义匹配任务有较大的帮助，他们使用BiLSTM编码器，融合了两个NLI的数据集SNLI和MNLI进行训练。Universal Sentence Encoder&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 796.7 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;36&quot; d=&quot;M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;（&lt;/span&gt;&lt;span&gt;USE&lt;/span&gt;&lt;span&gt;）使用了基于Transformer的架构，并使用SNLI对无监督训练进行增强。SBERT&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 796.7 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;进一步使用了一个共享的预训练的BERT编码器对两个句子进行编码，在NLI数据集上进行训练（&lt;/span&gt;&lt;span&gt;Fine-tune&lt;/span&gt;&lt;span&gt;）。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;自监督的Sentence-level预训练：有监督数据标注成本高，研究者们开始寻找无监督的训练方式。BERT提出了NSP的任务，可以算作是一种自监督的句子级预训练目标。尽管之后的工作指出NSP相比于MLM其实没有太大帮助。Cross-Thought&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 796.7 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;37&quot; d=&quot;M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;、CMLM&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 796.7 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;38&quot; d=&quot;M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt; 是两种思想类似的预训练目标，他们把一段文章切成多个短句，然后通过相邻句子的编码去恢复当前句子中被Mask的Token。相比于MLM，额外添加了上下文其他句子的编码对Token恢复的帮助，因此更适合句子级别的训练。SLM&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 796.7 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;39&quot; d=&quot;M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;通过将原本连贯的若干个短句打乱顺序（&lt;/span&gt;&lt;span&gt;通过改变Position Id实现&lt;/span&gt;&lt;span&gt;），然后通过预测正确的句子顺序进行自监督预训练。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;无监督的句子表示迁移：预训练模型现已被普遍使用，然而BERT的NSP任务得到的表示表现更不好，大多数同学也没有资源去进行自监督预训练，因此将预训练模型的表示迁移到任务才是更有效的方式。BERT-flow&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 796.7 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;：CMU&amp;amp;字节AI Lab的工作，通过在BERT之上学习一个可逆的Flow变换，可以将BERT表示空间映射到规范化的标准高斯空间，然后在高斯空间进行相似度匹配。BERT-whitening&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 1150.3 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;30&quot; d=&quot;M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(1278, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;：苏剑林和我们同期的工作。他们提出对BERT表征进行白化操作（&lt;/span&gt;&lt;span&gt;均值变为0，协方差变为单位矩阵&lt;/span&gt;&lt;span&gt;）就能在STS上达到媲美BERT-flow的效果。SimCSE&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 1150.3 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(1278, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;：在我们2月份投稿ACL后，看到陈丹琦组在2021年4月份公开的工作。他们同样使用基于对比学习的训练框架，使用Dropout的数据增强方法，在维基百科语料上Fine-tune BERT。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2.2 对比学习&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;对比学习是CV领域从2019年末开始兴起的预训练方法，同时最近也被广泛应用到了NLP任务中，我们简要介绍两个领域下的进展：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;计算机视觉（&lt;/span&gt;&lt;span&gt;CV&lt;/span&gt;&lt;span&gt;）领域的对比学习：2019年年末～2020年年初，Facebook提出MoCo&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 1150.3 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;34&quot; d=&quot;M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(1278, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;，谷歌提出SimCLR&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 1150.3 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;35&quot; d=&quot;M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(1278, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;，自此对比学习开始在无监督图像表示预训练领域大放光彩。SimCLR提出了一种简单的对比学习框架，通过对同一个图像进行增强，得到两个不同版本，随后通过ResNet对图像编码，再使用一个映射层将其映射到对比学习空间，使用NT-Xent损失进行预训练。本文的框架也主要受到SimCLR的启发。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;NLP领域的对比学习（&lt;/span&gt;&lt;span&gt;用于文本表示学习&lt;/span&gt;&lt;span&gt;）：随着对比学习在CV无监督图像表示预训练任务上大获成功，许多工作也试图将对比学习引入到NLP的语言模型预训练中。下面是一些代表性的工作及其总结：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8293838862559242&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsWS6x0Cic1r2gCGnwRbY55e4TLiaycvWRSibCEuHom4C2wxCoWSGiaH35uU0YprWBtZibMuYGzMZNx6gQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1266&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3. 模型介绍&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.1 问题定义&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;给定一个类似BERT的预训练语言模型&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -686 1092 686&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot;&gt;&lt;path data-c=&quot;4D&quot; d=&quot;M314 0Q296 3 181 3T48 0H39V62H147V624H39V686H305Q316 679 323 667Q330 653 434 414L546 157L658 414Q766 662 773 674Q778 681 788 686H1052V624H944V62H1052V0H1040Q1016 3 874 3T708 0H696V62H804V341L803 618L786 580Q770 543 735 462T671 315Q540 13 536 9Q528 1 507 1Q485 1 477 9Q472 14 408 162T281 457T217 603Q215 603 215 334V62H323V0H314Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;，以及从目标领域数据分布中收集的无标签文本语料库&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 771 683&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;44&quot; d=&quot;M37 475Q19 475 19 487Q19 536 103 604T327 682H356Q386 683 408 683H419Q475 683 506 681T582 668T667 633Q766 571 766 450Q766 365 723 287T611 152T455 57T279 6Q248 1 160 0Q148 0 131 0T108 -1Q72 -1 72 11Q72 24 90 40T133 64L144 68L152 88Q247 328 272 587Q275 613 272 613Q272 613 269 613Q225 610 195 602T149 579T129 556T119 532Q118 530 116 525T113 518Q102 502 80 490T37 475ZM665 407Q665 596 412 613Q403 614 383 614Q370 614 370 612Q370 598 363 542T323 357T242 103L228 69H265Q391 73 481 119Q536 148 575 188T633 268T658 338T665 392V407Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;，我们希望通过构建自监督任务在&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 771 683&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;44&quot; d=&quot;M37 475Q19 475 19 487Q19 536 103 604T327 682H356Q386 683 408 683H419Q475 683 506 681T582 668T667 633Q766 571 766 450Q766 365 723 287T611 152T455 57T279 6Q248 1 160 0Q148 0 131 0T108 -1Q72 -1 72 11Q72 24 90 40T133 64L144 68L152 88Q247 328 272 587Q275 613 272 613Q272 613 269 613Q225 610 195 602T149 579T129 556T119 532Q118 530 116 525T113 518Q102 502 80 490T37 475ZM665 407Q665 596 412 613Q403 614 383 614Q370 614 370 612Q370 598 363 542T323 357T242 103L228 69H265Q391 73 481 119Q536 148 575 188T633 268T658 338T665 392V407Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;上对&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -686 1092 686&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot;&gt;&lt;path data-c=&quot;4D&quot; d=&quot;M314 0Q296 3 181 3T48 0H39V62H147V624H39V686H305Q316 679 323 667Q330 653 434 414L546 157L658 414Q766 662 773 674Q778 681 788 686H1052V624H944V62H1052V0H1040Q1016 3 874 3T708 0H696V62H804V341L803 618L786 580Q770 543 735 462T671 315Q540 13 536 9Q528 1 507 1Q485 1 477 9Q472 14 408 162T281 457T217 603Q215 603 215 334V62H323V0H314Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;进行Fine-tune，使得Fine-tune后的模型能够在目标任务（&lt;/span&gt;&lt;span&gt;文本语义匹配&lt;/span&gt;&lt;span&gt;）上表现最好。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.2 基于对比学习的句子表示迁移框架&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.9532019704433498&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsW8OBYwCuKFqGIAJMgzCCktFPGYXVSk5iaFxtR1UNjMOG5IEqjvXsWTMshzUuSeH4gO24huY34fBfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;812&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图3 ConSERT的基本框架&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如图3所示，我们受到SimCLR的启发对BERT编码器进行了改进，提出ConSERT，主要包含三个部分：&lt;/span&gt;&lt;/section&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;一个数据增强模块（&lt;span&gt;详见后文&lt;/span&gt;），作用于Embedding层，为同一个句子生成两个不同的增强版本（&lt;span&gt;View&lt;/span&gt;）。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;一个共享的BERT编码器，为输入的句子生成句向量。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;一个对比损失层，用于在一个Batch的样本中计算对比损失，其思想是最大化同一个样本不同增强版本句向量的相似度，同时使得不同样本的句向量相互远离。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;训练时，先从数据集&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 771 683&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;TeXAtom&quot; data-mjx-texclass=&quot;ORD&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;44&quot; d=&quot;M37 475Q19 475 19 487Q19 536 103 604T327 682H356Q386 683 408 683H419Q475 683 506 681T582 668T667 633Q766 571 766 450Q766 365 723 287T611 152T455 57T279 6Q248 1 160 0Q148 0 131 0T108 -1Q72 -1 72 11Q72 24 90 40T133 64L144 68L152 88Q247 328 272 587Q275 613 272 613Q272 613 269 613Q225 610 195 602T149 579T129 556T119 532Q118 530 116 525T113 518Q102 502 80 490T37 475ZM665 407Q665 596 412 613Q403 614 383 614Q370 614 370 612Q370 598 363 542T323 357T242 103L228 69H265Q391 73 481 119Q536 148 575 188T633 268T658 338T665 392V407Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;中采样一个Batch的文本，设Batch size为&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 888 683&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;4E&quot; d=&quot;M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;。通过数据增强模块，每一个样本都通过两种预设的数据增强方法生成两个版本，得到总共&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 1388 683&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mn&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mi&quot; transform=&quot;translate(500, 0)&quot;&gt;&lt;path data-c=&quot;4E&quot; d=&quot;M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;条样本。这&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 1388 683&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mn&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mi&quot; transform=&quot;translate(500, 0)&quot;&gt;&lt;path data-c=&quot;4E&quot; d=&quot;M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;条样本均会通过共享的BERT编码器进行编码，然后通过一个平均池化层，得到&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 1388 683&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mn&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mi&quot; transform=&quot;translate(500, 0)&quot;&gt;&lt;path data-c=&quot;4E&quot; d=&quot;M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;个句向量。我们采用和SimCLR一致的NT-Xent损失对模型进行Fine-tune：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;section role=&quot;presentation&quot; data-formula=&quot;\mathcal{L}_{i,j} = -\log \frac{\exp (\text{sim}(r_i, r_j) / \tau)}{\sum_{k=1}^{2N} \mathbb{1}_{[k \neq i]}\exp(\text{sim}(r_i, r_k)/\tau)}&amp;#10;&quot; data-formula-type=&quot;block-equation&quot;&gt;&lt;embed src=&quot;https://mmbiz.qlogo.cn/mmbiz_svg/3a3QxMHZ8YxPYDLa63KjlOfsa4CctUadlDibmOk0VXLAfN52jbJPa6HyHgfDJTMhwOLNIqQUicR1gyrGrs9CuicXFAxEQPemdIO/0?wx_fmt=svg&quot; data-type=&quot;svg+xml&quot;/&gt;&lt;/section&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这里的&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -750 2283 1000&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot;&gt;&lt;path data-c=&quot;73&quot; d=&quot;M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z&quot;/&gt;&lt;path data-c=&quot;69&quot; d=&quot;M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z&quot; transform=&quot;translate(394, 0)&quot;/&gt;&lt;path data-c=&quot;6D&quot; d=&quot;M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z&quot; transform=&quot;translate(672, 0)&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mo&quot; transform=&quot;translate(1505, 0)&quot;&gt;&lt;path data-c=&quot;28&quot; d=&quot;M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mo&quot; transform=&quot;translate(1894, 0)&quot;&gt;&lt;path data-c=&quot;29&quot; d=&quot;M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;函数为余弦相似度函数；&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -442 451 453&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;72&quot; d=&quot;M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;表示对应的句向量；&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -431 517 444&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;3C4&quot; d=&quot;M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;表示temperature，是一个超参数，实验中取0.1。该损失从直观上理解，是让Batch内的每个样本都找到其对应的另一个增强版本，而Batch内的其他&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -683 3110.4 765&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mn&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mi&quot; transform=&quot;translate(500, 0)&quot;&gt;&lt;path data-c=&quot;4E&quot; d=&quot;M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mo&quot; transform=&quot;translate(1610.2, 0)&quot;&gt;&lt;path data-c=&quot;2212&quot; d=&quot;M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z&quot;/&gt;&lt;/g&gt;&lt;g data-mml-node=&quot;mn&quot; transform=&quot;translate(2610.4, 0)&quot;&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;个样本将充当负样本。优化的结果就是让同一个样本的两个增强版本在表示空间中具有尽可能大的一致性，同时和其他的Batch内负样本相距尽可能远。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.3 用于文本领域的数据增强方法探索&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.36674528301886794&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsW8OBYwCuKFqGIAJMgzCCkte2tp798AfticCA3ICQDZN50JsIcwznAc04n60bfg3DlYG5mCU8phZbg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1696&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图4 四种高效的数据增强方法：Adversarial Attack、Token Shuffling、Cutoff、Dropout，均作用于Embedding层&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图像领域可以方便地对样本进行变换，如旋转、翻转、裁剪、去色、模糊等等，从而得到对应的增强版本。然而，由于语言天然的复杂性，很难找到高效的、同时又保留语义不变的数据增强方法。一些显式生成增强样本的方法包括：&lt;/span&gt;&lt;/section&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;回译：利用机器翻译模型，将文本翻译到另一个语言，再翻译回来。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;CBERT&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 2250.5 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(1278, 0)&quot;/&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot; transform=&quot;translate(1556, 0)&quot;/&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot; transform=&quot;translate(1834, 0)&quot;/&gt;&lt;path data-c=&quot;33&quot; d=&quot;M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z&quot; transform=&quot;translate(2334, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(2834, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt; ：将文本的部分词替换成[MASK]，然后利用BERT去恢复对应的词，生成增强句子。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;意译（&lt;/span&gt;&lt;span&gt;Paraphrase&lt;/span&gt;&lt;span&gt;）：利用训练好的Paraphrase生成模型生成同义句。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;然而这些方法一方面不一定能保证语义一致，另一方面每一次数据增强都需要做一次模型Inference，开销会很大。鉴于此，我们考虑了在Embedding层隐式生成增强样本的方法，如图4所示：&lt;/span&gt;&lt;/section&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;对抗攻击（Adversarial Attack）&lt;/strong&gt;：这一方法通过梯度反传生成对抗扰动，将该扰动加到原本的Embedding矩阵上，就能得到增强后的样本。由于生成对抗扰动需要梯度反传，因此这一数据增强方法仅适用于有监督训练的场景。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;打乱词序（&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;Token Shuffling&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;）&lt;/strong&gt;：这一方法扰乱输入样本的词序。由于Transformer结构没有“位置”的概念，模型对Token位置的感知全靠Embedding中的Position Ids得到。因此在实现上，我们只需要将Position Ids进行Shuffle即可。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;裁剪（&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;Cutoff&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;）&lt;/strong&gt;：又可以进一步分为两种：&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Token Cutoff：随机选取Token，将对应Token的Embedding整行置为零。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Feature Cutoff：随机选取Embedding的Feature，将选取的Feature维度整列置为零。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;Dropout&lt;/strong&gt;：Embedding中的每一个元素都以一定概率置为零，与Cutoff不同的是，该方法并没有按行或者按列的约束。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;这四种方法均可以方便地通过对Embedding矩阵（&lt;/span&gt;&lt;span&gt;或是BERT的Position Encoding&lt;/span&gt;&lt;span&gt;）进行修改得到，因此相比显式生成增强文本的方法更为高效。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.4 进一步融合监督信号&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;除了无监督训练以外，我们还提出了几种进一步融合监督信号的策略：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;联合训练（&lt;em&gt;joint&lt;/em&gt;）：有监督的损失和无监督的损失通过加权联合训练模型。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;先有监督再无监督（&lt;em&gt;sup-unsup&lt;/em&gt;）：先使用有监督损失训练模型，再使用无监督的方法进行表示迁移。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;联合训练再无监督（&lt;em&gt;joint-unsup&lt;/em&gt;）：先使用联合损失训练模型，再使用无监督的方法进行表示迁移。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4. 实验分析&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;我们主要在文本语义匹配（Semantic Textual Similarity，STS）任务上进行了实验，包括七个数据集：STS12、STS13、STS14、STS15、STS16、STSb、SICK-R。其中STS12-16为SemEval2012 ～ 2016评测比赛放出的数据集；STSb为STS benchmark，来自于SemEval2017评测赛；SICK-R 表示 SICK-Relatedness，是SICK（&lt;/span&gt;&lt;span&gt;Sentences Involving ComPositional Knowledge&lt;/span&gt;&lt;span&gt;）数据集中的一个子任务，目标是推断两个句子时间的语义相关性（&lt;/span&gt;&lt;span&gt;即Relatedness&lt;/span&gt;&lt;span&gt;）。这些数据集中的样本均包含两个短文本text1和text2，以及人工标注的位于0～5之间的分数，代表text1和text2语义上的匹配程度（&lt;/span&gt;&lt;span&gt;5表示最匹配，即“两句话表达的是同一个语义”；0表示最不匹配，即“两句话表达的语义完全不相关”&lt;/span&gt;&lt;span&gt;）。下面给出了两条样本作为示例：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.30077519379844964&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsWS6x0Cic1r2gCGnwRbY55e4XGicnfIux5QYsEr4aNYh3hlDNrvicBX5DSbwWPjLol09bw6jhelF7cRw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1290&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;在测试时，我们根据此前的工作&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -893.3 1543.4 893.3&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;msup&quot;&gt;&lt;g data-mml-node=&quot;mtext&quot; transform=&quot;translate(0, 363) scale(0.707)&quot;&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot;/&gt;&lt;path data-c=&quot;31&quot; d=&quot;M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z&quot; transform=&quot;translate(278, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(778, 0)&quot;/&gt;&lt;path data-c=&quot;5B&quot; d=&quot;M118 -250V750H255V710H158V-210H255V-250H118Z&quot; transform=&quot;translate(1056, 0)&quot;/&gt;&lt;path data-c=&quot;32&quot; d=&quot;M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z&quot; transform=&quot;translate(1334, 0)&quot;/&gt;&lt;path data-c=&quot;5D&quot; d=&quot;M22 710V750H159V-250H22V-210H119V710H22Z&quot; transform=&quot;translate(1834, 0)&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;选择了斯皮尔曼相关系数（&lt;/span&gt;&lt;span&gt;Spearman correlation&lt;/span&gt;&lt;span&gt;）作为评测指标，它将用于衡量两组值（&lt;/span&gt;&lt;span&gt;模型预测的余弦相似度和人工标注的语义相似度&lt;/span&gt;&lt;span&gt;）之间的相关性，结果将位于[-1, 1]之间，仅当两组值完全正相关时取到1。对于每个数据集，我们将其测试样本全部融合计算该指标，并且报告了七个数据集的平均结果。考虑到简洁性，会在表格中报告乘以100倍的结果。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.1 无监督实验&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4117647058823529&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsW8OBYwCuKFqGIAJMgzCCktDBNAia470EwsDrzRnGJ9icXDUXDhjVb2fsQ82Xs5eMyciciaVFXnMyA7Lw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1666&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图5 无监督设置下的实验结果&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在无监督实验中，我们直接基于预训练的BERT在无标注的STS数据上进行Fine-tune。结果显示，我们的方法在完全一致的设置下大幅度超过之前的SOTA—BERT-flow，达到了8%的相对性能提升。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.2 有监督实验&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5095011876484561&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsW8OBYwCuKFqGIAJMgzCCktz92JU9B1hRYflMhhYTq7ibUZsLYicibB6pH5Vj4NicwRq0UYlj0yCkTSZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1684&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图6 有监督设置下的实验结果&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在有监督实验中，我们额外使用了来自SNLI和MNLI的训练数据，使用上面提到的融合额外监督信号的三种方法进行了实验。实验结果显示，我们的方法在“仅使用NLI有标注数据”和“使用NLI有标注数据 + STS无标注数据”的两种实验设置下均超过了基线。在三种融合监督信号的实验设置中，我们发现&lt;em&gt;joint-unsup&lt;/em&gt;方法取得了最好的效果。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.3 不同的数据增强方法分析&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.7869249394673123&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsW8OBYwCuKFqGIAJMgzCCktIIicobZ1DO2FEZyCB7vWVbrbt3WDEnhZibKRGv0hCyZHxagxoEpHoziaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;826&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图7 不同数据增强组合方法的性能&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们对不同的数据增强组合方法进行了消融分析，结果如图7所示。我们发现Token Shuffle和Feature Cutoff的组合取得了最优性能（&lt;/span&gt;&lt;span&gt;72.74&lt;/span&gt;&lt;span&gt;）。此外，就单种数据增强方法而言，Token Shuffle &amp;gt; Token Cutoff &amp;gt;&amp;gt; Feature Cutoff ≈ Dropout &amp;gt;&amp;gt; None。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.4 少样本设置下的实验分析&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;我们进一步分析了数据量（&lt;/span&gt;&lt;span&gt;无标注文本的数目&lt;/span&gt;&lt;span&gt;）对效果的影响，结果如图8所示。结果显示，我们的方法仅需较少的样本就能近似达到全数据量的效果；同时，在样本量很少的情况下（&lt;/span&gt;&lt;span&gt;如100条文本的情况下&lt;/span&gt;&lt;span&gt;）仍相比于Baseline表现出不错的性能提升。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5170731707317073&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsW8OBYwCuKFqGIAJMgzCCktjRcPIQwDZcx3JibXksF7EjQgvA8zTM20moxQuZ0KCVBL9h3vvT9vgcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;820&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图8 ConSERT在小样本情况下的性能&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.5 Temperature超参的实验分析&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;在实验中，我们发现对比学习损失函数中的温度超参数（&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -431 517 444&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;3C4&quot; d=&quot;M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;）对于结果有很大影响。从图9的分析实验中可以看到，当&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -431 517 444&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;3C4&quot; d=&quot;M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;值在0.08到0.12之间时会得到最优结果。这个现象再次证明了BERT表示的塌缩问题，因为在句子表示都很接近的情况下，&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -431 517 444&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;3C4&quot; d=&quot;M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;过大会使句子间相似度更平滑，编码器很难学到知识。而&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -431 517 444&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;3C4&quot; d=&quot;M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;如果过小，任务就太过简单，所以需要调整到一个合适的范围内。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5115131578947368&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsW8OBYwCuKFqGIAJMgzCCktyv0meUeicxmw6icJWQyPlBicIUmf3YEIMzqaibKc08KS4drYfURRE5V2MQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1216&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图9 不同超参数&lt;span&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; role=&quot;img&quot; focusable=&quot;false&quot; viewbox=&quot;0 -431 517 444&quot; aria-hidden=&quot;true&quot;&gt;&lt;g stroke=&quot;currentColor&quot; fill=&quot;currentColor&quot; stroke-width=&quot;0&quot; transform=&quot;matrix(1 0 0 -1 0 0)&quot;&gt;&lt;g data-mml-node=&quot;math&quot;&gt;&lt;g data-mml-node=&quot;mi&quot;&gt;&lt;path data-c=&quot;3C4&quot; d=&quot;M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z&quot;/&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/span&gt;下的性能&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.6 Batch size超参的实验分析&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;在图像领域的对比学习中，Batch size会对结果有很大影响，因此我们也对比了不同Batch size下模型的表现。从图10可以看到两者基本是成正比的，但提升很有限。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.17687074829931973&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsW8OBYwCuKFqGIAJMgzCCkt5khPXdL4zlnZjFrKMqkJXYlBDPFcf3ib2XxTFdunqAzIr5aR5nDON7g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1176&quot;/&gt;&lt;figcaption&gt;&lt;span&gt;图10 不同Batch size下的性能&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5. 总结&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;在此工作中，我们分析了BERT句向量表示空间坍缩的原因，并提出了一种基于对比学习的句子表示迁移框架ConSERT。ConSERT在无监督Fine-tune和进一步融合监督信号的实验中均表现出了不错的性能；同时当收集到的样本数较少时，仍能有不错的性能提升，表现出较强的鲁棒性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;同时，在美团的业务场景下，有大量不同领域的短文本相关性计算需求，目前ConSERT已经在知识图谱构建、KBQA、搜索召回等业务场景使用。未来将会在美团更多业务上进行探索落地。目前，相关代码已经&lt;/span&gt;&lt;a href=&quot;https://github.com/yym6472/ConSERT&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;在GitHub上开源&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，欢迎大家使用。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考文献&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;[1] Reimers, Nils, and Iryna Gurevych. &quot;Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.&quot; Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[2] Li, Bohan, et al. &quot;On the Sentence Embeddings from Pre-trained Language Models.&quot; Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[3] Gao, Jun, et al. &quot;Representation Degeneration Problem in Training Natural Language Generation Models.&quot; International Conference on Learning Representations. 2018.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[4] Wang, Lingxiao, et al. &quot;Improving Neural Language Generation with Spectrum Control.&quot; International Conference on Learning Representations. 2019.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[5] Conneau, Alexis, et al. &quot;Supervised Learning of Universal Sentence Representations from Natural Language Inference Data.&quot; Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[6] Cer, Daniel, et al. &quot;Universal Sentence Encoder for English.&quot; Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 2018.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[7] Wang, Shuohang, et al. &quot;Cross-Thought for Sentence Encoder Pre-training.&quot; Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[8] Yang, Ziyi, et al. &quot;Universal Sentence Representation Learning with Conditional Masked Language Model.&quot; arXiv preprint arXiv:2012.14388 (2020).&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[9] Lee, Haejun, et al. &quot;SLM: Learning a Discourse Language Representation with Sentence Unshuffling.&quot; Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[10] Su, Jianlin, et al. &quot;Whitening sentence representations for better semantics and faster retrieval.&quot; arXiv preprint arXiv:2103.15316 (2021).&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[11] Gao, Tianyu, Xingcheng Yao, and Danqi Chen. &quot;SimCSE: Simple Contrastive Learning of Sentence Embeddings.&quot; arXiv preprint arXiv:2104.08821 (2021).&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[12] Wu, Xing, et al. &quot;Conditional bert contextual augmentation.&quot; International Conference on Computational Science. Springer, Cham, 2019.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[13] Zhou, Wangchunshu, et al. &quot;BERT-based lexical substitution.&quot; Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2019.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[14] He, Kaiming, et al. &quot;Momentum contrast for unsupervised visual representation learning.&quot; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[15] Chen, Ting, et al. &quot;A simple framework for contrastive learning of visual representations.&quot; International conference on machine learning. PMLR, 2020.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[16] Zhang, Yan, et al. &quot;An Unsupervised Sentence Embedding Method by Mutual Information Maximization.&quot; Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[17] Fang, Hongchao, et al. &quot;Cert: Contrastive self-supervised learning for language understanding.&quot; arXiv preprint arXiv:2005.12766 (2020).&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[18] Carlsson, Fredrik, et al. &quot;Semantic re-tuning with contrastive tension.&quot; International Conference on Learning Representations. 2021.&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[19] Giorgi, John M., et al. &quot;Declutr: Deep contrastive learning for unsupervised textual representations.&quot; arXiv preprint arXiv:2006.03659 (2020).&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[20] Wu, Zhuofeng, et al. &quot;CLEAR: Contrastive Learning for Sentence Representation.&quot; arXiv preprint arXiv:2012.15466(2020).&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;本文作者&lt;/span&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;渊蒙、如寐、思睿、富峥、武威等，美团平台/搜索与NLP部。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;徐蔚然，北京邮电大学人工智能学院，模式识别实验室，副教授，博士生导师。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;活动推荐&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4274543874891399&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsWS6x0Cic1r2gCGnwRbY55e4NvGGWvMUjd4XsaVUXkD4Iy4RibvLCV6TvMYoDKjC3ubLuKqnS1kgPibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1151&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;6月5日（&lt;span&gt;本周六&lt;/span&gt;）下午14:00-17:00，美团技术沙龙《聊聊美团无人车配送的实践与挑战》，将与大家分享无人车配送团队在自动驾驶相关技术方向所遇到的挑战和研发进展。期待你的参与，点击&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://hdxu.cn/Phe3s&quot; textvalue=&quot;这里&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;这里&lt;/a&gt;&lt;span&gt;报名~&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;阅读更多&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;---&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jo7r&quot; textvalue=&quot;前端&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;前端&lt;/a&gt;&lt;strong&gt;&lt;span&gt; |&lt;/span&gt;&lt;/strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jo7v&quot; textvalue=&quot; 安全&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;strong&gt; &lt;/strong&gt; &lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jsdG&quot; textvalue=&quot;算法&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;算法&lt;/a&gt;&lt;strong&gt; |&lt;/strong&gt;&lt;span&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jsWK&quot; textvalue=&quot;后端&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;后端&lt;/a&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt; |&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jqRZ&quot; textvalue=&quot;数据&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;数据&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jo7v&quot; textvalue=&quot; 安全&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;安全&lt;/a&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jui4&quot; textvalue=&quot;Android&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;Android&lt;/a&gt;&lt;strong&gt; |&lt;/strong&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jtXE&quot; textvalue=&quot;iOS&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;iOS&lt;/a&gt; &lt;strong&gt; |&lt;/strong&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jo7K&quot; textvalue=&quot;运维&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;运维&lt;/a&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jtsX&quot; textvalue=&quot;测试&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;测试&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;----------  END  ----------&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;招聘信息&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-source=&quot;bj.96weixin.com&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;美团搜索与NLP部，长期招聘算法工程师，坐标北京。欢迎感兴趣的同学发送简历至：&lt;span&gt;tech@meituan.com&lt;/span&gt;（&lt;/span&gt;&lt;span&gt;邮件标题注明：搜索与NLP部&lt;/span&gt;&lt;span&gt;）&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;也许你还想看&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;  | &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651752878&amp;amp;idx=2&amp;amp;sn=b14a4027ef5988f2e81394a075dcbcf3&amp;amp;chksm=bd1250e38a65d9f55a14abea662db9959b6286d809a9510f70d95d1942b68745a4d1c0b7f61a&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;/strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651752878&amp;amp;idx=2&amp;amp;sn=b14a4027ef5988f2e81394a075dcbcf3&amp;amp;chksm=bd1250e38a65d9f55a14abea662db9959b6286d809a9510f70d95d1942b68745a4d1c0b7f61a&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;MT-BERT在文本检索任务中的实践&lt;/a&gt;&lt;strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651752878&amp;amp;idx=2&amp;amp;sn=b14a4027ef5988f2e81394a075dcbcf3&amp;amp;chksm=bd1250e38a65d9f55a14abea662db9959b6286d809a9510f70d95d1942b68745a4d1c0b7f61a&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;  |&lt;/strong&gt;&lt;/span&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651752296&amp;amp;idx=1&amp;amp;sn=6c20fd97bfd9cc7e5557e40e867f123b&amp;amp;chksm=bd125e258a65d7335e7b649796248908d5a19c7d64f6f8935ab162c11539397feac3d830c3aa&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;BERT在美团搜索核心排序的探索和实践&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;  |&lt;/strong&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651750945&amp;amp;idx=1&amp;amp;sn=713f16c46065db1f831a495ffb1d9a78&amp;amp;chksm=bd125b6c8a65d27adb13bb234f027d619950a979259ae1c035427c4c025c95e26d7485194232&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;美团BERT的探索和实践&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;560&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;249&quot; data-ratio=&quot;0.44533333333333336&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUrXicw2VXTQTVVN5yxXWEacsJ3aFxXFol84VVW89JYtgorr2aQnLz2YzwrVicCFXS7hEPGWvVJ6LWg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1875&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>54dddaa291472bba1c0938c876134431</guid>
<title>详解 Go 团队不建议用的 unsafe.Pointer</title>
<link>https://toutiao.io/k/4v9vvbf</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家好，我是煎鱼。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大家在学习 Go 的时候，肯定都学过 “Go 的指针是不支持指针运算和转换” 这个知识点。为什么呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，Go 是一门静态语言，所有的变量都必须为标量类型。不同的类型不能够进行赋值、计算等跨类型的操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么指针也对应着相对的类型，也在 Compile 的静态类型检查的范围内。同时静态语言，也称为强类型。也就是一旦定义了，就不能再改变它。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;错误的示例&lt;/h2&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;func &lt;span&gt;&lt;span&gt;main&lt;/span&gt;&lt;/span&gt;(){&lt;br/&gt; num := 5&lt;br/&gt; numPointer := &amp;amp;num&lt;br/&gt;&lt;br/&gt; flnum := (*float32)(numPointer)&lt;br/&gt; fmt.Println(flnum)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输出结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;# command-line-arguments&lt;/span&gt;&lt;br/&gt;...: cannot convert numPointer (&lt;span&gt;type&lt;/span&gt; *int) to &lt;span&gt;type&lt;/span&gt; *float32&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在示例中，我们创建了一个 &lt;code&gt;num&lt;/code&gt; 变量，值为 5，类型为 &lt;code&gt;int&lt;/code&gt;，准备干一番大事。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来我们取了其对于的指针地址后，试图强制转换为 &lt;code&gt;*float32&lt;/code&gt;，结果失败...&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;万能的破壁 unsafe&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对刚刚的 “错误示例”，我们可以采用今天的男主角 &lt;code&gt;unsafe&lt;/code&gt; 标准库来解决。它是一个神奇的包，在官方的诠释中，有如下概述：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;围绕 Go 程序内存安全及类型的操作。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;很可能会是不可移植的。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;不受 Go 1 兼容性指南的保护。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单来讲就是，不怎么推荐你使用，因为它是 unsafe（不安全的）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是在特殊的场景下，使用了它，可以打破 Go 的类型和内存安全机制，让你获得眼前一亮的惊喜效果。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;unsafe.Pointer&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了解决这个问题，需要用到 &lt;code&gt;unsafe.Pointer&lt;/code&gt;。它表示任意类型且可寻址的指针值，可以在不同的指针类型之间进行转换（类似 C 语言的 void * 的用途）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其包含四种核心操作：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;任何类型的指针值都可以转换为 Pointer。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Pointer 可以转换为任何类型的指针值。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;uintptr 可以转换为 Pointer。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Pointer 可以转换为 uintptr。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这一部分，重点看第一点、第二点。你再想想怎么修改 “错误的例子” 让它运行起来？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;修改如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;func &lt;span&gt;&lt;span&gt;main&lt;/span&gt;&lt;/span&gt;(){&lt;br/&gt; num := 5&lt;br/&gt; numPointer := &amp;amp;num&lt;br/&gt;&lt;br/&gt; flnum := (*float32)(unsafe.Pointer(numPointer))&lt;br/&gt; fmt.Println(flnum)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输出结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;0xc4200140b0&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上述代码中，我们小加改动。通过 &lt;code&gt;unsafe.Pointer&lt;/code&gt; 的特性对该指针变量进行了修改，就可以完成任意类型（*T）的指针转换。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;需要注意的是，这时还无法对变量进行操作或访问，因为不知道该指针地址指向的东西具体是什么类型。不知道是什么类型，又如何进行解析呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;无法解析也就自然无法对其变更了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;unsafe.Offsetof&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上小节中，我们对普通的指针变量进行了修改。那么它是否能做更复杂一点的事呢？&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; Num struct{&lt;br/&gt; i string&lt;br/&gt; j int64&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;func &lt;span&gt;&lt;span&gt;main&lt;/span&gt;&lt;/span&gt;(){&lt;br/&gt; n := Num{i: &lt;span&gt;&quot;EDDYCJY&quot;&lt;/span&gt;, j: 1}&lt;br/&gt; nPointer := unsafe.Pointer(&amp;amp;n)&lt;br/&gt;&lt;br/&gt; niPointer := (*string)(unsafe.Pointer(nPointer))&lt;br/&gt; *niPointer = &lt;span&gt;&quot;煎鱼&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt; njPointer := (*int64)(unsafe.Pointer(uintptr(nPointer) + unsafe.Offsetof(n.j)))&lt;br/&gt; *njPointer = 2&lt;br/&gt;&lt;br/&gt; fmt.Printf(&lt;span&gt;&quot;n.i: %s, n.j: %d&quot;&lt;/span&gt;, n.i, n.j)&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;输出结果：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;n.i: 煎鱼, n.j: 2&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在剖析这段代码做了什么事之前，我们需要了解结构体的一些基本概念：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;结构体的成员变量在内存存储上是一段连续的内存。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;结构体的初始地址就是第一个成员变量的内存地址。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;基于结构体的成员地址去计算偏移量。就能够得出其他成员变量的内存地址。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再回来看看上述代码，得出执行流程：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;修改 &lt;code&gt;n.i&lt;/code&gt; 值：&lt;code&gt;i&lt;/code&gt; 为第一个成员变量。因此不需要进行偏移量计算，直接取出指针后转换为 &lt;code&gt;Pointer&lt;/code&gt;，再强制转换为字符串类型的指针值即可。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;修改 &lt;code&gt;n.j&lt;/code&gt; 值：&lt;code&gt;j&lt;/code&gt; 为第二个成员变量。需要进行偏移量计算，才可以对其内存地址进行修改。在进行了偏移运算后，当前地址已经指向第二个成员变量。接着重复转换赋值即可。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;细节分析&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;需要注意的是，这里使用了如下方法（来完成偏移计算的目标）：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、uintptr：&lt;code&gt;uintptr&lt;/code&gt; 是 Go 的内置类型。返回无符号整数，可存储一个完整的地址。后续常用于指针运算&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; uintptr uintptr&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、unsafe.Offsetof：返回成员变量 x 在结构体当中的偏移量。更具体的讲，就是返回结构体初始位置到 x 之间的字节数。需要注意的是入参 &lt;code&gt;ArbitraryType&lt;/code&gt; 表示任意类型，并非定义的 &lt;code&gt;int&lt;/code&gt;。它实际作用是一个占位符&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;func Offsetof(x ArbitraryType) uintptr&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这一部分，其实就是巧用了 &lt;code&gt;Pointer&lt;/code&gt; 的第三、第四点特性。这时候就已经可以对变量进行操作了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;糟糕的例子&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;func &lt;span&gt;&lt;span&gt;main&lt;/span&gt;&lt;/span&gt;(){&lt;br/&gt; n := Num{i: &lt;span&gt;&quot;EDDYCJY&quot;&lt;/span&gt;, j: 1}&lt;br/&gt; nPointer := unsafe.Pointer(&amp;amp;n)&lt;br/&gt;    ...&lt;br/&gt;&lt;br/&gt; ptr := uintptr(nPointer)&lt;br/&gt; njPointer := (*int64)(unsafe.Pointer(ptr + unsafe.Offsetof(n.j)))&lt;br/&gt; ...&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里存在一个问题，&lt;code&gt;uintptr&lt;/code&gt; 类型是不能存储在临时变量中的。因为从 GC 的角度来看，&lt;code&gt;uintptr&lt;/code&gt; 类型的临时变量只是一个无符号整数，并不知道它是一个指针地址。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此当满足一定条件后，&lt;code&gt;ptr&lt;/code&gt; 这个临时变量是可能被垃圾回收掉的，那么接下来的内存操作，岂不成迷？&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简洁回顾两个知识点，如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;第一是 &lt;code&gt;unsafe.Pointer&lt;/code&gt; 可以让你的变量在不同的指针类型转来转去，也就是表示为任意可寻址的指针类型。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第二是 &lt;code&gt;uintptr&lt;/code&gt; 常用于与 &lt;code&gt;unsafe.Pointer&lt;/code&gt; 打配合，用于做指针运算，巧妙地很。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后还是那句，没有特殊必要的话。是不建议使用 &lt;code&gt;unsafe&lt;/code&gt; 标准库，它并不安全。虽然它常常能让你眼前一亮。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>7f750362dc104ba85cba19194f0c076b</guid>
<title>网络连接存在大量 time_wait 和 close_wait 的原因以及解决方法</title>
<link>https://toutiao.io/k/b9vlrcu</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-source-line=&quot;1&quot;&gt;如果对tcp中的握手挥手不了解的同学，请先看这篇博客：《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247483765&amp;amp;idx=1&amp;amp;sn=70179fa0e28aacd42d4c15dbd08bc6fc&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;关于三次握手与四次挥手你要知道这些&lt;/a&gt;》。&lt;/p&gt;&lt;p data-source-line=&quot;3&quot;&gt;&lt;img data-ratio=&quot;0.6995305164319249&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gzia45CTkHaZ3W8ewRXgOZ5ayNKNuHChs2vHVS9qBKiaxTnpb6vbcmkl9nCEGQich82xDS8wSBzx5zQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;426&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;5&quot;&gt;四次挥手过程：&lt;/p&gt;&lt;p data-source-line=&quot;7&quot;&gt;第一次挥手：主机A（可以是客户端，也可以是服务器端），设置Sequence Number和Acknowledgment Number，向主机B发送一个FIN报文段；此时，主机A进入FIN_WAIT_1状态；这表示主机A没有数据要发送给主机B了。&lt;/p&gt;&lt;p data-source-line=&quot;9&quot;&gt;第二次挥手：主机B收到了主机A发送的FIN报文段，向主机A回一个ACK报文段，Acknowledgment Number为Sequence Number加1，主机A进入FIN_WAIT_2状态；主机B告诉主机A，我也没有数据要发送了，可以进行关闭连接了。&lt;/p&gt;&lt;p data-source-line=&quot;11&quot;&gt;第三次挥手：主机B向主机A发送FIN报文段，请求关闭连接，同时主机B进入CLOSE_WAIT状态。&lt;/p&gt;&lt;p data-source-line=&quot;13&quot;&gt;第四次挥手：主机A收到主机B发送的FIN报文段，向主机B发送ACK报文段，然后主机A进入TIME_WAIT状态；主机B收到主机A的ACK报文段以后，就关闭连接；此时，主机A等待2MSL后依然没有收到回复，则证明主机B已正常关闭，那好，主机A也可以关闭连接了。&lt;/p&gt;&lt;h2 data-source-line=&quot;15&quot;&gt;大量time_wait&lt;/h2&gt;&lt;h3 data-source-line=&quot;17&quot;&gt;问题原因&lt;/h3&gt;&lt;p data-source-line=&quot;19&quot;&gt;《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247483765&amp;amp;idx=1&amp;amp;sn=70179fa0e28aacd42d4c15dbd08bc6fc&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;关于三次握手与四次挥手你要知道这些&lt;/a&gt;》中有关于“四次挥手释放连接时，等待2MSL的意义”的解释。正因为有2ML的存在，所以可能会发生大量time_wait存在的现象，从而影响服务器性能，甚至导致套接字数量达到服务器上限。&lt;/p&gt;&lt;blockquote data-source-line=&quot;21&quot;&gt;&lt;p&gt;实际上，TIME_WAIT对于系统资源的消耗影响比较小，而真正需要考虑因为TIME_WAIT多而触碰到限制的是如下几个方面：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;源端口数量 (net.ipv4.ip_local_port_range)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;TIME_WAIT bucket 数量 (net.ipv4.tcp_max_tw_buckets)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;文件描述符数量 (max open files)&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;h3 data-source-line=&quot;26&quot;&gt;解决方法&lt;/h3&gt;&lt;p data-source-line=&quot;28&quot;&gt;只需要优化服务器系统的网络配置，连接配置，使用socket重用或及时释放资源即可。（由于系统不断迭代，所以这里不给出具体参数修改）&lt;/p&gt;&lt;h2 data-source-line=&quot;30&quot;&gt;大量close_wait&lt;/h2&gt;&lt;h3 data-source-line=&quot;32&quot;&gt;问题原因&lt;/h3&gt;&lt;p data-source-line=&quot;34&quot;&gt;主机B一直没有进行第三次挥手，会导致主机B存在大量close_wait状态的连接。大量这种情况发生会影响服务器性能，同样可能导致套接字数量达到服务器上限。&lt;/p&gt;&lt;p data-source-line=&quot;36&quot;&gt;网络连接未及时释放，通常是服务端发生异常后未关闭连接或者close_wait的配置时间过长。如果是mysql数据库也可能存在事务开启后没有正确rollback或commit的可能。&lt;/p&gt;&lt;p data-source-line=&quot;38&quot;&gt;总之，都是大概率是服务端代码或配置的问题。&lt;/p&gt;&lt;h3 data-source-line=&quot;40&quot;&gt;解决方法&lt;/h3&gt;&lt;p data-source-line=&quot;42&quot;&gt;以下方法并不存在顺序，定位问题时也并不是一定同时需要。&lt;/p&gt;&lt;ul data-source-line=&quot;44&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;top查看cpu利用率和load情况（大量close_wait属于io密集型，会导致load相比cpu利用率高出很多）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;netstat观察close_wait的数量变化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;wireshark辅助查看网络包的发送情况。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;perf或者火焰图定位热点函数。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;java可以将服务器线程堆栈dump，查看大量线程在哪里blocked。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>