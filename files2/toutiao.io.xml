<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>23aadca594fd04183c170aa020bb507d</guid>
<title>什么鬼：谷歌浏览器，一次get请求建立两次tcp连接</title>
<link>https://toutiao.io/k/d2k0ruf</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5635416666666667&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/Z85sZvtmju0tiaJS6BMffqEdxZTHN7MmibYwlBITT6bn2tPqP3SFeqKN2QnYN5od7mnR3veDrRdhs1w9lkLZHgdA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;960&quot;/&gt;&lt;/p&gt;&lt;p&gt;今天，同事说在谷歌浏览器中发起一次请求，使用wireshark抓包时，却发现了有两次tcp连接建立：其中一次是正常的三次握手-请求应答-四次挥手；另一次只有三次握手和四次挥手。谷歌浏览器抓包如图所示：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-croporisrc=&quot;https://mmbiz.qlogo.cn/mmbiz_png/Z85sZvtmju1YPcZlVMKMJbbuibYfVpaWhnrU6aPeQ2PS4IgITmRUZWI3nkdkgAyPurdEoprEgJia6DG6fXfAYzBw/0?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;912&quot; data-cropy1=&quot;52.069204152249135&quot; data-cropy2=&quot;397.61937716262975&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3793859649122807&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/Z85sZvtmju1YPcZlVMKMJbbuibYfVpaWhrQh9JibGaFzzwtSdyRC26p99xMxar9l9dGuX420mDGRjNRvME0NAE6g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;912&quot;/&gt;&lt;/p&gt;&lt;section&gt;可以看到客户端在端口61112和端口64272分别进行了三次握手，建立了tcp连接，下面的http请求都是在端口61112进行的请求应答。那端口64272在干什么呢？&lt;br/&gt;&lt;/section&gt;&lt;p&gt;为了排除浏览器的问题，我们使用火狐浏览器进行请求抓包，抓包如下图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.32073544433094997&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z85sZvtmju1YPcZlVMKMJbbuibYfVpaWhhXA6gokxz8JrNZBDaJNiaxh2Jo5S6t4dwicpQUKQSAia4DWFpW1qaePQQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;979&quot;/&gt;&lt;/p&gt;&lt;section&gt;可以看到火狐浏览器中正常：一次请求只建立一次tcp连接。我们尝试了curl发起请求，抓包记录都是一次tcp连接。基本确定不是浏览器的共性，只是谷歌浏览器的个性。&lt;br/&gt;&lt;/section&gt;&lt;p&gt;使用多个连接通常最容易想到的是加速访问，比如一个数据库连接不够用，可以建立多个连接（连接池复用连接）。于是，我们在谷歌浏览器设置里搜索有关加速、快速的内容，经过测试找到了一项：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z85sZvtmju1YPcZlVMKMJbbuibYfVpaWhfa77dwTL0ru8vRhZo6K2WibcBhzcTQiaUbkTA2HcfA82HpH9VurhFIaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;856&quot;/&gt;&lt;/p&gt;&lt;section&gt;关闭预加载后，再次发起请求，谷歌浏览器也正常变成单个三次握手了。本文使用wireshark抓包，过滤指定端口filter：&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;tcp.port==8787&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;使用springboot2项目，配置tomcat 连接超时时间（验证keep-alive超时时间）：&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;server.connection-timeout=5000&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.32695035460992905&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z85sZvtmju1YPcZlVMKMJbbuibYfVpaWhzXtNrjYTSQO51DUfblQkrKWCOczhedticiaMPgA4kQEjMc3wh6uZTZcw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1410&quot;/&gt;&lt;/p&gt;&lt;section&gt;本文就简单分享到这里，觉得有用点个&lt;em&gt;在看&lt;/em&gt;，喜欢请关注我们：&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5226390685640362&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z85sZvtmju2ZMvElmjsA4IjbhwMTv9HFQHMSCWvDnX6DtgEiaVYia6ZlZL9jPGvBDIyIDK5tAP1oZGlJxDhFYSYw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;773&quot;/&gt;&lt;span/&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                          
              &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_reward_qrcode&quot;&gt;
                  &lt;p class=&quot;tips_global&quot; aria-hidden=&quot;true&quot; id=&quot;js_a11y_reward_qr_title&quot;&gt;Long-press QR code to transfer me a reward&lt;/p&gt;
                                    &lt;p role=&quot;option&quot; aria-labelledby=&quot;js_a11y_reward_qr_word js_a11y_comma js_a11y_reward_qr_title js_a11y_reward_qr_money&quot; aria-describedby=&quot;js_a11y_reward_qr_tips &quot; class=&quot;reward_tips&quot; id=&quot;js_a11y_reward_qr_word&quot;/&gt;
                  &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img alt=&quot;赞赏二维码&quot; class=&quot;reward_qrcode_img&quot; id=&quot;js_reward_qrcode_img&quot;/&gt;&lt;/span&gt;
                  &lt;p aria-hidden=&quot;true&quot; id=&quot;js_a11y_reward_qr_tips&quot; class=&quot;tips_global&quot;&gt;As required by Apple&#x27;s new policy, the Reward feature has been disabled on Weixin for iOS. You can still reward an Official Account by transferring money via QR code.&lt;/p&gt;
                &lt;/div&gt;
                                              
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b249630e379fc927095e86702dc72698</guid>
<title>MQTT 协议基本介绍</title>
<link>https://toutiao.io/k/xxeqcbo</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div id=&quot;cnblogs_post_body&quot; class=&quot;blogpost-body blogpost-body-html&quot;&gt;
&lt;h2 class=&quot;_1RuRku&quot;&gt;&lt;span&gt;简介&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://links.jianshu.com/go?to=https%3A%2F%2Fwww.emqx.io%2Fcn%2Fmqtt&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MQTT&lt;/a&gt; 全称为 Message Queuing Telemetry Transport（消息队列遥测传输）是一种基于发布/订阅范式的“轻量级”消息协议，由 IBM 发布。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MQTT 可以被解释为一种低开销，低带宽占用的即时通讯协议，可以用极少的代码和带宽的为连接远程设备提供实时可靠的消息服务，它适用于硬件性能低下的远程设备以及网络状况糟糕的环境下，因此 MQTT 协议在 IoT（Internet of things，物联网），小型设备应用，移动应用等方面有较广泛的应用。&lt;/li&gt;
&lt;li&gt;IoT 设备要运作，就必须连接到互联网，设备才能相互协作，以及与后端服务协同工作。而互联网的基础网络协议是 TCP/IP，MQTT 协议是基于 TCP/IP 协议栈而构建的，因此它已经慢慢的已经成为了 IoT 通讯的标准。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在简介完 MQTT 协议后，EMQ君将从其一些基本特点和基本概念为两部分，介绍 MQTT 协议。&lt;/p&gt;
&lt;h2&gt;基本特点&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;MQTT是一种发布/订阅传输协议，基本原理和实现如下；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;MQTT 协议提供一对多的消息发布，可以解除应用程序耦合，信息冗余小。该协议需要客户端和服务端，而协议中主要有三种身份：发布者（Publisher）、代理（Broker，服务器）、订阅者（Subscriber）。其中，消息的发布者和订阅者都是客户端，消息代理是服务器，而消息发布者可以同时是订阅者，实现了生产者与消费者的脱耦。&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;
&lt;p&gt;使用 TCP/IP 提供网络连接，提供有序、无损、双向连接；&lt;/p&gt;
&lt;p&gt;MQTT 是一种连接协议，它指定了如何组织数据字节并通过 TCP/IP 网络传输它们。设备联网，也需要连接到互联网中，在大万维的世界中，TCP 如同汽车，有轮子就能用来运输数据，MQTT 就像是交通规则。在网络模型中，TCP是传输层协议，而 MQTT是在应用层，在 TCP 的上层，因此 MQTT 也是基于这个而构建的，提高了可靠性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对负载内容屏蔽的消息传输；&lt;/p&gt;
&lt;p&gt;可以对消息订阅者所接受到的内容有所屏蔽。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;具体有三种消息发布的服务质量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;至多一次&lt;/code&gt;，消息发布完全依赖底层 TCP/IP 网络。会发生消息丢失或重复。这一级别可用于如下情况，环境传感器数据，丢失一次读记录无所谓，因为不久后还会有第二次发送。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;至少一次&lt;/code&gt;，确保消息到达，但消息重复可能会发生。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;只有一次&lt;/code&gt;，确保消息到达一次。这一级别可用于如下情况，在计费系统中，消息重复或丢失会导致不正确的结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;小型传输，开销小，固定长度的头部是 2 字节，协议交换最小化，以降低网络流量；&lt;/p&gt;
&lt;p&gt;整体上协议可拆分为：固定头部+可变头部+消息体，这就是为什么在介绍里说它非常适合&quot;在物联网领域，传感器与服务器的通信，信息的收集&quot;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用Last Will和Testament特性通知有关各方客户端异常中断的机制；&lt;/p&gt;
&lt;p&gt;Last Will：即遗言机制，用于通知同一主题下的其他设备发送遗言的设备已经断开了连接。&lt;/p&gt;
&lt;p&gt;Testament：遗嘱机制，功能类似于Last Will。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;基本概念&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;MQTT 客户端&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一个使用 MQTT 协议的设备、应用程序等，它总是建立到服务器的网络连接。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;可以发布信息，其他客户端可以订阅该信息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;订阅其它客户端发布的消息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;退订或删除应用程序的消息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;断开与服务器连接&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MQTT 服务器&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;MQTT 服务器也称为 Broker（消息代理），以是一个应用程序或一台设备。它是位于消息发布者 和订阅者之间&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;接受来自客户端的网络连接&lt;/li&gt;
&lt;li&gt;接受客户端发布的应用信息&lt;/li&gt;
&lt;li&gt;处理来自客户端的订阅和退订请求&lt;/li&gt;
&lt;li&gt;向订阅的客户转发应用程序消息&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;主题（Topic）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;连接到一个应用程序消息的标签，该标签与服务器的订阅相匹配。服务器会将消息发送给订阅所匹配标签的每个客户端。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;主题筛选器（Topic Filter）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一个对主题名通配符筛选器，在订阅表达式中使用，表示订阅所匹配到的多个主题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;QoS（消息传递的服务质量水平）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;服务质量，标志表明此主题范围内的消息传送到客户端所需的一致程度。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;值 0：不可靠，消息基本上仅传送一次，如果当时客户端不可用，则会丢失该消息。&lt;/li&gt;
&lt;li&gt;值 1：消息应传送至少 1 次。&lt;/li&gt;
&lt;li&gt;值 2：消息仅传送一次。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;会话（Session）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;每个客户端与服务器建立连接后就是一个会话，客户端和服务器之间有状态交互。会话存在于一个网络之间，也可能在客户端和服务器之间跨越多个连续的网络连接。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;订阅（Subscription）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;订阅包含主题筛选器（Topic Filter）和最大服务质量（QoS）。订阅会与一个会话（Session）关联。一个会话可以包含多个订阅。每一个会话中的每个订阅都有一个不同的主题筛选器。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;客户端在成功建立TCP连接之后，发送CONNECT消息，在得到服务器端授权允许建立彼此连接的CONNACK消息之后，客户端会发送SUBSCRIBE消息，订阅感兴趣的Topic主题列表（至少一个主题）&lt;/li&gt;
&lt;li&gt;订阅的主题名称采用UTF-8编码，然后紧跟着对应的QoS值&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;发布（publish）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;控制报文是指从客户端向服务端或者服务端向客户端传输一个应用消息，MQTT 客户端发送消息请求，发送完成后返回应用程序线程&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;比如安卓的推送服务，还有一些即时通信软件如微信等也是采用的推送技术。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;负载（Payload）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;消息订阅者所具体接收的内容&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;简单示例&lt;/h2&gt;
&lt;p&gt;MQTT 协议主要是根据以下情况设计的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;M2M（Machine to Machine），机器或设备间端到端通信，比如传感器之间的数据通讯。&lt;/li&gt;
&lt;li&gt;设备（Machine）中，例如传感器，硬件能力很弱，协议要考虑尽量小的资源消耗，比如计算能力和存储等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据 MQTT 的基础了解后并结合简单的架构，在这里做一个简单的示例图，可以更直观的理解MQTT协议的通信模型。MQTT Broker 就选择 EMQ 作为示范。比如有1个温度传感器（1个Machine），1个移动设备，1个电脑，一个服务器（3个Machine)，都可以得到或者显示温度传感器的温度值，需要先通过 MQTT 协议subscribe（订阅）一个比如叫 temperature 的 topic（主题）如下：&lt;/p&gt;

&lt;p&gt;图中移动设备，服务器，电脑需要先通过 EMQ subscribe 一个叫 temperature 的 topic，当温度传感器 publish 温度数据，三个设备就可以收到了。&lt;/p&gt;
&lt;h1&gt;进一步了解MQTT 3&lt;/h1&gt;
&lt;p&gt;MQTT 3 （当前版本3.1.1）是目前使用的最为广泛的 MQTT 协议标准。尽管 &lt;a href=&quot;https://links.jianshu.com/go?to=https%3A%2F%2Fwww.emqx.io%2Fcn%2Fmqtt%2Fmqtt5&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MQTT 5&lt;/a&gt; 标准已经发布，并且带来了一些令人振奋的新特性，但是在整个应用场景上，从后台服务到消息中间件再到客户端SDK等环节上的产品升级并没有都完成，再加上既有部署的维护，业界从版本3到5的过渡可能会持续相当长一段时间，所以，对于刚加入物联网行业的生力军来说，现在来学习 MQTT 3 依然是一件很有意义的事情。&lt;/p&gt;
&lt;h2&gt;MQTT 协议的工作方式&lt;/h2&gt;
&lt;p&gt;前面简介中讲到，在 MQTT 协议中有三个角色会参与到整个通信过程，发布者（publisher）、代理（broker）和订阅者（subscriber）。有别于传统的客户端/服务器通讯协议，MQTT协议并不是端到端的，消息传递通过代理，包括会话（session）也不是建立在发布者和订阅者之间，而是建立在端和代理之间。代理解除了发布者和订阅者之间的耦合。&lt;/p&gt;
&lt;p&gt;除了发布者和订阅者之间传递普通消息，代理还可以为发布者处理保留消息和遗愿消息，并可以更改服务质量（QoS）等级。&lt;/p&gt;
&lt;h2&gt;MQTT控制报文&lt;/h2&gt;
&lt;p&gt;MQTT协议工作在TCP之上，端和代理之间通过交换预先定义的控制报文来完成通信。MQTT报文有3个部分组成，并按下表顺序出现：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;固定报头（fixed header）&lt;/th&gt;&lt;th&gt;可变报头（variable header）&lt;/th&gt;&lt;th&gt;荷载（payload）&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;所有报文都包含&lt;/td&gt;
&lt;td&gt;部分报文包含&lt;/td&gt;
&lt;td&gt;部分报文包含&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;所有的MQTT控制报文都有一个固定报头，格式如下：&lt;/p&gt;

&lt;p&gt;协议版本3定义了14种 MQTT 报文，用于建立/断开连接、发布消息、订阅消息和维护连接。固定报头的第一字节的4-7位的值指定了报文类型，其取值如下表。0和15为系统保留值；0-3位为标志位，依照报文类型有不同的含义，事实上，除了 PUBLISH 报文以外，其他报文的标志位均为系统保留。如果收到报文的标志位无效，代理应断开连接。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;报文类型&lt;/th&gt;&lt;th&gt;值&lt;/th&gt;&lt;th&gt;描述&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CONNECT&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;客户端向代理发起连接请求&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CONNACK&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;连接确认&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUBLISH&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;发布消息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUBACK&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;发布确认&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUBREC&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;发布收到（QoS2）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUBREL&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;发布释放（QoS2）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PUBCOMP&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;发布完成（QoS2）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SUBSCRIBE&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;客户端向代理发起订阅请求&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SUBACK&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;订阅确认&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UNSUBSCRIBE&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;取消订阅&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UNSUBACK&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;取消订阅确认&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PINGREQ&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;PING请求&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PINGRESP&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;PING响应&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DISCONNECT&lt;/td&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;td&gt;断开连接&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;固定报头的第二字节起表示报文的剩余长度。&lt;span&gt;最大4个字节，每字节可以编码至127，并含有一位继续位，如继续位非0，则下一字节依然为剩余长度。由此，理论上一个控制报文最长可以到256MB。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/420532/202106/420532-20210607095138649-2085346960.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;span/&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;一些报文在固定报头和荷载之间可以有一个可变报头。可变报头的内容根据报文类型不同而不同。最常见的可变报头是报文标识符（Packet Identifier）。&lt;/p&gt;
&lt;p&gt;一些报文可以在最后携带一个荷载。不同的报文可以无荷载，可选荷载，或必须带有荷载。&lt;/p&gt;
&lt;p&gt;限于篇幅，在这里我们仅以CONNECT和CONNACK为例解释一下 MQTT 报文的构成和报文响应行为。其他报文请查阅MQTT标准文档。&lt;/p&gt;
&lt;h3&gt;CONNECT报文&lt;/h3&gt;
&lt;p&gt;限于篇幅，在这里我们仅以CONNECT为例解释一下MQTT报文的构成。其他报文请查阅MQTT标准文档。&lt;br/&gt;CONNECT是客户端连接到代理的第一个报文，如果在连接已经存在，代理收到该报文将会断开现有连接。&lt;/p&gt;
&lt;h4&gt;CONNECT报文的固定报头&lt;/h4&gt;

&lt;h4&gt;CONNECT报文的可变报头&lt;/h4&gt;
&lt;p&gt;CONNECT报文的可变报头由4部分组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;协议名。协议名是UTF-8编码的大写的MQTT。&lt;/li&gt;
&lt;li&gt;协议级别。MQTT 3.1.1的协议级别为4.&lt;/li&gt;
&lt;li&gt;连接标志位。定义连接行为的参数。见下表。&lt;/li&gt;
&lt;li&gt;Keep Alive。2字节，客户端和代理之间的无活动时间超过该值后，应关闭连接。如果该值置0表示客户端不要求代理启用KEEPALIVE功能。&lt;/li&gt;

&lt;/ul&gt;
&lt;p&gt;连接标志位：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;位&lt;/th&gt;&lt;th&gt;7&lt;/th&gt;&lt;th&gt;6&lt;/th&gt;&lt;th&gt;5&lt;/th&gt;&lt;th&gt;4&lt;/th&gt;&lt;th&gt;3&lt;/th&gt;&lt;th&gt;2&lt;/th&gt;&lt;th&gt;1&lt;/th&gt;&lt;th&gt;0&lt;/th&gt;&lt;/tr&gt;

&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt; &lt;/td&gt;
&lt;td&gt;用户名&lt;/td&gt;
&lt;td&gt;密码&lt;/td&gt;
&lt;td&gt;保留遗愿&lt;/td&gt;
&lt;td&gt;遗愿QoS&lt;/td&gt;
&lt;td&gt;遗愿QoS&lt;/td&gt;
&lt;td&gt;遗愿&lt;/td&gt;
&lt;td&gt;清除会话&lt;/td&gt;
&lt;td&gt;保留（0）&lt;/td&gt;

&lt;/tr&gt;

&lt;/tbody&gt;

&lt;/table&gt;
&lt;p&gt;清除会话标志位：&lt;br/&gt;这个标志位定义了如何处理会话状态。如果设置为0，客户端和代理可以恢复上一次连接时的会话状态，如果上一次连接的会话状态不存在，代理将会为客户端建立一个新的会话。如果该位设置为1，则双方将清除掉上一次连接的会话状态并建立一个新的会话。&lt;/p&gt;
&lt;p&gt;遗愿标志位：&lt;br/&gt;如果遗愿标志为1，则遗愿消息会被存储在代理上，当连接关闭时，代理将发布这个消息，除非在客户端断开连接时把遗愿消息清除了。&lt;/p&gt;
&lt;p&gt;遗愿QoS标志位：&lt;br/&gt;指定了遗愿消息的服务质量等级。&lt;/p&gt;
&lt;p&gt;保留遗愿消息标志位：&lt;br/&gt;指定在发布遗愿消息的时候，是否把该消息作为保留消息存储在代理。&lt;/p&gt;
&lt;p&gt;用户名标志位：&lt;br/&gt;如果设置为1，则用户名必须出现在荷载中，反之，用户名不允许出现在荷载中。&lt;/p&gt;
&lt;p&gt;密码标志位：&lt;br/&gt;如果该位为1，则密码必须出现在荷载中；如果该位为0，则密码不允许出现在荷载中。如果用户名标志位为0，则该位必须也为0。&lt;/p&gt;
&lt;h4&gt;CONNECT报文的荷载&lt;/h4&gt;
&lt;p&gt;CONNECT报文的荷载由一个或者多个字段组成，这些字段是否出现由可变报头中的标志位决定。字段总是以长度开始。字段出现的顺序必须是：客户端标识符，遗愿主题，遗愿消息，用户名，密码。&lt;/p&gt;
&lt;h4&gt;CONNECT报文的响应&lt;/h4&gt;
&lt;p&gt;在代理在为MQTT协议开放的端口上接收到TCP连接请求并建立连接后应该会收到CONNECT报文，如果在一定时间内代理没有收到CONNECT报文，则应该关闭这个TCP连接。&lt;br/&gt;在收到CONNECT报文后，代理应该检查报文格式是否符合协议标准。如果不符合协议标准，代理应关闭连接，且不发送CONNACK报文给客户端。&lt;br/&gt;代理可以检查CONNECT报文的内容并执行响应的认证和鉴权。如果这些检查没有通过，代理应该向客户端发送一个带有非0返回码的CONNACK报文。&lt;/p&gt;
&lt;h3&gt;CONNACK报文&lt;/h3&gt;
&lt;p&gt;CONNACK是代理用来响应客户端CONNECT的报文。代理向客户端发送的第一个报文必须是CONNACT。CONNACK有一个固定报头，一个可变报头，但是不带有荷载。&lt;/p&gt;
&lt;h4&gt;CONNACK的固定报头&lt;/h4&gt;

&lt;p&gt;CONNACT报文只有固定报头和一个2字节的可变报头，所以它的剩余长度总是2。&lt;/p&gt;
&lt;h4&gt;CONNACK报文的可变报头&lt;/h4&gt;
&lt;p&gt;CONNACK报文的可变报头为定长2字节。第一字节的0位表示是否有会话存在。如果代理上已经有请求连接的客户端的会话，且连接请求的清除会话标识为0，则该位为1，否则该位为0。客户端可以根据这一位的值采取响应行为，比如（重新）订阅主题等。&lt;/p&gt;
&lt;p&gt;CONNACK报文的可变报头的第二字节为返回码。如果CONNECT请求的格式正确，但是代理依然不能允许客户端连接，则返回码为一个非零值。如果连接成功，则返回0。&lt;/p&gt;
&lt;p&gt;返回码的定义：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;值&lt;/th&gt;&lt;th&gt;返回码含义&lt;/th&gt;&lt;/tr&gt;

&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;成功，连接请求被接受。&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;拒绝连接，不可接受的协议版本。&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;拒绝连接，不被允许的身份识别符（Client Identifier）。&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;拒绝连接，服务器不可用。&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;拒绝连接，无效的用户名和密码。&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;拒绝连接，客户端无授权。&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6-255&lt;/td&gt;
&lt;td&gt;系统保留。&lt;/td&gt;

&lt;/tr&gt;

&lt;/tbody&gt;

&lt;/table&gt;
&lt;p&gt;客户端接受到代理的CONNACK的返回码为0，则连接建立完成，双方可以开始通信。&lt;/p&gt;
&lt;h2&gt;清除会话、保留消息和QoS的组合&lt;/h2&gt;
&lt;p&gt;清除会话、保留消息等概念，在传统的客户端/服务器方式的通信中不一定会出现，这些概念有时候不太容易理解，特别是当他们被组合起来用的时候。&lt;/p&gt;
&lt;p&gt;下面的表格汇总了当一个客户端连接上来时，它能收到消息的各种情况。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;清除会话位&lt;/th&gt;&lt;th&gt;保留位&lt;/th&gt;&lt;th&gt;订阅QoS&lt;/th&gt;&lt;th&gt;发布QoS&lt;/th&gt;&lt;th&gt;可收到的消息&lt;/th&gt;&lt;/tr&gt;

&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Y，会话全部消息&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Y，最后一条消息&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Y，最后一条消息&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Y，最后一条消息&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Y，最后一条消息&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Y，最后一条消息&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Y，最后一条消息&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Y，最后一条消息&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Y，会话全部消息&lt;/td&gt;

&lt;/tr&gt;

&lt;/tbody&gt;

&lt;/table&gt;
&lt;h1&gt;MQTT 5.0 协议新增介绍&lt;/h1&gt;
&lt;p&gt;MQTT 5.0 协议相比 MQTT 3.1.1 协议新增了许多内容， 比如说属性，AUTH 包，还有对一些字段做了修改，比如将 Clean Session 修改成 Clean Start 配合 Session Expiry Internal 去实现更灵活的会话控制。&lt;/p&gt;
&lt;p&gt;这里就简单罗列一下 5.0 协议新增的内容。&lt;/p&gt;
&lt;h2&gt;设计目标&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;增强了扩展性&lt;/li&gt;
&lt;li&gt;改善了错误报告的方式&lt;/li&gt;
&lt;li&gt;定型了一些通用范式，例如能力发现和请求、响应&lt;/li&gt;
&lt;li&gt;扩展机制包括用户属性(user properties)&lt;/li&gt;
&lt;li&gt;性能改善，并且添加了对小客户端（small clients） 的支持&lt;/li&gt;

&lt;/ul&gt;
&lt;p&gt;读者可以参考MQTT5.0协议规范的&lt;a href=&quot;https://links.jianshu.com/go?to=http%3A%2F%2Fdocs.oasis-open.org%2Fmqtt%2Fmqtt%2Fv5.0%2Fcs02%2Fmqtt-v5.0-cs02.html%23AppendixC&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;附录C&lt;/a&gt;来了解协议变更。&lt;/p&gt;
&lt;h2&gt;属性&lt;/h2&gt;
&lt;p&gt;为了达成新协议的设计目标，MQTT 5.0 协议中新增了许多属性，以下是新添加的属性列表。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;标识符 Identifier(十进制)&lt;/th&gt;&lt;th&gt;标识符 Identifier(十六进制)&lt;/th&gt;&lt;th&gt;名称（用法）Name(usage)&lt;/th&gt;&lt;th&gt;类型 Type&lt;/th&gt;&lt;th&gt;报文/遗嘱属性 Packet/Will Properties&lt;/th&gt;&lt;/tr&gt;

&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0x01&lt;/td&gt;
&lt;td&gt;有效载荷格式指示器 Payload Format Indicator&lt;/td&gt;
&lt;td&gt;字节&lt;/td&gt;
&lt;td&gt;PUBLISH, 遗嘱属性 Will Properties&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0x02&lt;/td&gt;
&lt;td&gt;消息到期间隔 Message Exipiry Interval&lt;/td&gt;
&lt;td&gt;四字节整形&lt;/td&gt;
&lt;td&gt;PUBLISH，遗嘱属性&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;0x03&lt;/td&gt;
&lt;td&gt;内容类型 Content Type&lt;/td&gt;
&lt;td&gt;UTF-8 编码字符串&lt;/td&gt;
&lt;td&gt;PUBLISH，遗嘱属性&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;0x08&lt;/td&gt;
&lt;td&gt;响应主题 Response Topic&lt;/td&gt;
&lt;td&gt;UTF-8 编码字符串&lt;/td&gt;
&lt;td&gt;PUBLISH，遗嘱属性&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;0x09&lt;/td&gt;
&lt;td&gt;关联数据 Correlation Data&lt;/td&gt;
&lt;td&gt;二进制数据 Binary Data&lt;/td&gt;
&lt;td&gt;PUBLISH，遗嘱属性&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;0x0B&lt;/td&gt;
&lt;td&gt;订阅标识符 Subscription Identifier&lt;/td&gt;
&lt;td&gt;可变字节整形&lt;/td&gt;
&lt;td&gt;PUBLISH, SUBSCRIBE&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;0x11&lt;/td&gt;
&lt;td&gt;会话到期间隔 Session Expiry Interval&lt;/td&gt;
&lt;td&gt;四字节整形&lt;/td&gt;
&lt;td&gt;CONNECT, CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;18&lt;/td&gt;
&lt;td&gt;0x12&lt;/td&gt;
&lt;td&gt;已分配客户端标识符 Assigned Client Identifier&lt;/td&gt;
&lt;td&gt;UTF-8 编码字符串&lt;/td&gt;
&lt;td&gt;CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;0x13&lt;/td&gt;
&lt;td&gt;服务器保活 Server Keep Alive&lt;/td&gt;
&lt;td&gt;两字节整形&lt;/td&gt;
&lt;td&gt;CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;0x15&lt;/td&gt;
&lt;td&gt;认证方法 Authentication Method&lt;/td&gt;
&lt;td&gt;UTF-8 编码字符串&lt;/td&gt;
&lt;td&gt;CONNECT, CONNACK, AUTH&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;22&lt;/td&gt;
&lt;td&gt;0x16&lt;/td&gt;
&lt;td&gt;认证数据 Authentication Data&lt;/td&gt;
&lt;td&gt;二进制数据&lt;/td&gt;
&lt;td&gt;CONNECT, CONNACK, AUTH&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;23&lt;/td&gt;
&lt;td&gt;0x17&lt;/td&gt;
&lt;td&gt;请求响应信息 Request Response Information&lt;/td&gt;
&lt;td&gt;字节&lt;/td&gt;
&lt;td&gt;CONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;0x18&lt;/td&gt;
&lt;td&gt;遗嘱延迟间隔 Will Delay Interval&lt;/td&gt;
&lt;td&gt;四字节整形&lt;/td&gt;
&lt;td&gt;遗嘱属性 Will Properties&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;0x19&lt;/td&gt;
&lt;td&gt;请求响应信息 Request Response Information&lt;/td&gt;
&lt;td&gt;字节&lt;/td&gt;
&lt;td&gt;CONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;26&lt;/td&gt;
&lt;td&gt;0x1A&lt;/td&gt;
&lt;td&gt;响应信息 Response Information&lt;/td&gt;
&lt;td&gt;UTF-8 编码字符串&lt;/td&gt;
&lt;td&gt;CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;0x1C&lt;/td&gt;
&lt;td&gt;服务器引用 Server Reference&lt;/td&gt;
&lt;td&gt;UTF-8 编码字符串&lt;/td&gt;
&lt;td&gt;CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;td&gt;0x1F&lt;/td&gt;
&lt;td&gt;原因字符串 Reason String&lt;/td&gt;
&lt;td&gt;UTF-8 编码字符串&lt;/td&gt;
&lt;td&gt;CONNACK, PUBACK, PUBREC, PUBREL, PUBCOMP, SUBACK,UNSUBACK, DISCONNECT, AUTH&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;33&lt;/td&gt;
&lt;td&gt;0x21&lt;/td&gt;
&lt;td&gt;接收最大值 Receive Maximum&lt;/td&gt;
&lt;td&gt;两字节整形&lt;/td&gt;
&lt;td&gt;CONNECT, CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;34&lt;/td&gt;
&lt;td&gt;0x22&lt;/td&gt;
&lt;td&gt;主题别名最大值 Topic Alias Maximum&lt;/td&gt;
&lt;td&gt;两字节整形&lt;/td&gt;
&lt;td&gt;CONNECT, CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;35&lt;/td&gt;
&lt;td&gt;0x23&lt;/td&gt;
&lt;td&gt;主题别名 Topic Alias&lt;/td&gt;
&lt;td&gt;两字节整形&lt;/td&gt;
&lt;td&gt;PUBLISH&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;36&lt;/td&gt;
&lt;td&gt;0x24&lt;/td&gt;
&lt;td&gt;服务质量最大值 Maximum QoS&lt;/td&gt;
&lt;td&gt;字节&lt;/td&gt;
&lt;td&gt;CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;37&lt;/td&gt;
&lt;td&gt;0x25&lt;/td&gt;
&lt;td&gt;保留可用 Retain Available&lt;/td&gt;
&lt;td&gt;字节&lt;/td&gt;
&lt;td&gt;CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;38&lt;/td&gt;
&lt;td&gt;0x26&lt;/td&gt;
&lt;td&gt;用户属性 User Property&lt;/td&gt;
&lt;td&gt;UTF-8 字符串对 UTF-8 String Pair&lt;/td&gt;
&lt;td&gt;CONNECT, CONNACK, PUBLISH, PUBACK, PUBREC, PUBREL, PUBCOMP, SUBACK, UNSUBACK, DISCONNECT, AUTH&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;39&lt;/td&gt;
&lt;td&gt;0x27&lt;/td&gt;
&lt;td&gt;最大报文大小 Maximum Packet Size&lt;/td&gt;
&lt;td&gt;四字节整形&lt;/td&gt;
&lt;td&gt;CONNECT, CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;0x28&lt;/td&gt;
&lt;td&gt;可用通配符订阅 Wildcard Subscription Available&lt;/td&gt;
&lt;td&gt;字节&lt;/td&gt;
&lt;td&gt;CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;41&lt;/td&gt;
&lt;td&gt;0x29&lt;/td&gt;
&lt;td&gt;可用订阅标识符 Subscription Identifier Available&lt;/td&gt;
&lt;td&gt;Byte&lt;/td&gt;
&lt;td&gt;CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;42&lt;/td&gt;
&lt;td&gt;0x2A&lt;/td&gt;
&lt;td&gt;可用共享订阅 Shared Subscription Available&lt;/td&gt;
&lt;td&gt;字节&lt;/td&gt;
&lt;td&gt;CONNACK&lt;/td&gt;

&lt;/tr&gt;

&lt;/tbody&gt;

&lt;/table&gt;
&lt;h2&gt;原因码&lt;/h2&gt;
&lt;p&gt;MQTT v3.1.1 只有寥寥 6 个返回码，用来表示网络连接时可能会出现的异常行为，在引入属性后的 MQTT 5.0 协议中，仅仅这 6 个返回码显然已经不足以用来描述各种异常行为，因此MQTT 5.0 协议中将返回码改成了原因码，用来实现改善错误报告的目的。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;原因码（十进制）&lt;/th&gt;&lt;th&gt;原因码（十六进制）&lt;/th&gt;&lt;th&gt;名称&lt;/th&gt;&lt;th&gt;报文&lt;/th&gt;&lt;/tr&gt;

&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0x00&lt;/td&gt;
&lt;td&gt;成功 Success&lt;/td&gt;
&lt;td&gt;CONNACK, PUBACK, PUBREC, PUBREL, PUBCOMP, UNSUBACK, AUTH&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0x00&lt;/td&gt;
&lt;td&gt;正常断连 Normal disconnection&lt;/td&gt;
&lt;td&gt;DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0x00&lt;/td&gt;
&lt;td&gt;准许 QoS 0 Granted QoS 0&lt;/td&gt;
&lt;td&gt;SUBACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0x01&lt;/td&gt;
&lt;td&gt;准许 QoS 1 Granted QoS 1&lt;/td&gt;
&lt;td&gt;SUBACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0x02&lt;/td&gt;
&lt;td&gt;准许 QoS 2 Granted QoS 2&lt;/td&gt;
&lt;td&gt;SUBACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;0x04&lt;/td&gt;
&lt;td&gt;以遗嘱消息断开连接 Disconnect with Will Message&lt;/td&gt;
&lt;td&gt;DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;0x10&lt;/td&gt;
&lt;td&gt;没有匹配的订阅者 No matching subscribers&lt;/td&gt;
&lt;td&gt;PUBACK, PUBREC&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;0x11&lt;/td&gt;
&lt;td&gt;没有订阅 No subscription existed&lt;/td&gt;
&lt;td&gt;UNSUBACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;0x18&lt;/td&gt;
&lt;td&gt;继续认证 Continue authentication&lt;/td&gt;
&lt;td&gt;AUTH&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;0x19&lt;/td&gt;
&lt;td&gt;重新认证 Re-authenticate&lt;/td&gt;
&lt;td&gt;AUTH&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;td&gt;0x80&lt;/td&gt;
&lt;td&gt;未指定错误 Unspecified error&lt;/td&gt;
&lt;td&gt;CONNACK, PUBACK, PUBREC, SUBACK, UNSUBACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;129&lt;/td&gt;
&lt;td&gt;0x81&lt;/td&gt;
&lt;td&gt;畸形报文 Malformed Packet&lt;/td&gt;
&lt;td&gt;CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;130&lt;/td&gt;
&lt;td&gt;0x82&lt;/td&gt;
&lt;td&gt;协议错误 Protocol Error&lt;/td&gt;
&lt;td&gt;CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;131&lt;/td&gt;
&lt;td&gt;0x83&lt;/td&gt;
&lt;td&gt;实现特有错误 Implementation specific error&lt;/td&gt;
&lt;td&gt;CONNACK, PUBACK, PUBREC, SUBACK, UNSUBACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;132&lt;/td&gt;
&lt;td&gt;0x84&lt;/td&gt;
&lt;td&gt;不支持的协议版本 Unsupported Protocol Version&lt;/td&gt;
&lt;td&gt;CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;133&lt;/td&gt;
&lt;td&gt;0x85&lt;/td&gt;
&lt;td&gt;客户端标识符无效 Client Identifier not valid&lt;/td&gt;
&lt;td&gt;CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;134&lt;/td&gt;
&lt;td&gt;0x86&lt;/td&gt;
&lt;td&gt;错误的用户名和密码 Bad User Name or Password&lt;/td&gt;
&lt;td&gt;CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;135&lt;/td&gt;
&lt;td&gt;0x87&lt;/td&gt;
&lt;td&gt;未授权 Not authorized&lt;/td&gt;
&lt;td&gt;CONNACK, PUBACK, PUBREC, SUBACK, UNSUBACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;136&lt;/td&gt;
&lt;td&gt;0x88&lt;/td&gt;
&lt;td&gt;服务器不可用 Server unavailable&lt;/td&gt;
&lt;td&gt;CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;137&lt;/td&gt;
&lt;td&gt;0x89&lt;/td&gt;
&lt;td&gt;服务器繁忙 Server busy&lt;/td&gt;
&lt;td&gt;CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;138&lt;/td&gt;
&lt;td&gt;0x8A&lt;/td&gt;
&lt;td&gt;禁止访问 Banned&lt;/td&gt;
&lt;td&gt;CONNACK&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;139&lt;/td&gt;
&lt;td&gt;0x8B&lt;/td&gt;
&lt;td&gt;服务器关机中 Server shutting down&lt;/td&gt;
&lt;td&gt;DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;140&lt;/td&gt;
&lt;td&gt;0x8C&lt;/td&gt;
&lt;td&gt;错误验证方法 Bad authentication method&lt;/td&gt;
&lt;td&gt;CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;141&lt;/td&gt;
&lt;td&gt;0x8D&lt;/td&gt;
&lt;td&gt;保活超时 Keep Alive timeout&lt;/td&gt;
&lt;td&gt;DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;142&lt;/td&gt;
&lt;td&gt;0x8E&lt;/td&gt;
&lt;td&gt;会话被接管 Session taken over&lt;/td&gt;
&lt;td&gt;DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;143&lt;/td&gt;
&lt;td&gt;0x8F&lt;/td&gt;
&lt;td&gt;主题过滤器无效 Topic Filter invalid&lt;/td&gt;
&lt;td&gt;SUBACK, UNSUBACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;144&lt;/td&gt;
&lt;td&gt;0x90&lt;/td&gt;
&lt;td&gt;主题名无效 Topic Name invalid&lt;/td&gt;
&lt;td&gt;CONNACK, PUBACK, PUBREC, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;145&lt;/td&gt;
&lt;td&gt;0x91&lt;/td&gt;
&lt;td&gt;报文标识符在使用中 Packet Identifier in use&lt;/td&gt;
&lt;td&gt;PUBACK, PUBREC, SUBACK, UNSUBACK=&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;146&lt;/td&gt;
&lt;td&gt;0x92&lt;/td&gt;
&lt;td&gt;没有发现报文标识符 Packet Identifier not found&lt;/td&gt;
&lt;td&gt;PUBREL, PUBCOMP&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;147&lt;/td&gt;
&lt;td&gt;0x93&lt;/td&gt;
&lt;td&gt;超出接收最大值 Receive Maximum exceeded&lt;/td&gt;
&lt;td&gt;DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;148&lt;/td&gt;
&lt;td&gt;0x94&lt;/td&gt;
&lt;td&gt;主题别名无效 Topic Alias invalid&lt;/td&gt;
&lt;td&gt;DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;149&lt;/td&gt;
&lt;td&gt;0x95&lt;/td&gt;
&lt;td&gt;报文太大 Packet too large&lt;/td&gt;
&lt;td&gt;CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;150&lt;/td&gt;
&lt;td&gt;0x96&lt;/td&gt;
&lt;td&gt;消息传输速率太高 Message rate too high&lt;/td&gt;
&lt;td&gt;DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;151&lt;/td&gt;
&lt;td&gt;0x97&lt;/td&gt;
&lt;td&gt;超出限额 Quota exceeded&lt;/td&gt;
&lt;td&gt;CONNACK, PUBACK, PUBREC, SUBACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;152&lt;/td&gt;
&lt;td&gt;0x98&lt;/td&gt;
&lt;td&gt;管理行为 Administrative action&lt;/td&gt;
&lt;td&gt;DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;153&lt;/td&gt;
&lt;td&gt;0x99&lt;/td&gt;
&lt;td&gt;有效载荷格式无效 Payload format invalid&lt;/td&gt;
&lt;td&gt;PUBACK, PUBREC, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;154&lt;/td&gt;
&lt;td&gt;0x9A&lt;/td&gt;
&lt;td&gt;不支持消息保留 Retain not supported&lt;/td&gt;
&lt;td&gt;CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;155&lt;/td&gt;
&lt;td&gt;0x9B&lt;/td&gt;
&lt;td&gt;不支持的QoS QoS not supported&lt;/td&gt;
&lt;td&gt;CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;156&lt;/td&gt;
&lt;td&gt;0x9C&lt;/td&gt;
&lt;td&gt;使用另一台服务器 Use another server&lt;/td&gt;
&lt;td&gt;CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;157&lt;/td&gt;
&lt;td&gt;0x9D&lt;/td&gt;
&lt;td&gt;服务器被移除 Server moved&lt;/td&gt;
&lt;td&gt;CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;158&lt;/td&gt;
&lt;td&gt;0x9E&lt;/td&gt;
&lt;td&gt;不支持的共享订阅 Shared Subscription not supported&lt;/td&gt;
&lt;td&gt;SUBACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;159&lt;/td&gt;
&lt;td&gt;0x9F&lt;/td&gt;
&lt;td&gt;超出连接速率 Connection rate exceeded&lt;/td&gt;
&lt;td&gt;CONNACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;160&lt;/td&gt;
&lt;td&gt;0xA0&lt;/td&gt;
&lt;td&gt;最大连接时间 Maximum connect time&lt;/td&gt;
&lt;td&gt;DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;161&lt;/td&gt;
&lt;td&gt;0xA1&lt;/td&gt;
&lt;td&gt;不支持的订阅标识符 Subscription Identifiers not supported&lt;/td&gt;
&lt;td&gt;SUBACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;162&lt;/td&gt;
&lt;td&gt;0xA2&lt;/td&gt;
&lt;td&gt;不支持的通配符订阅 Wildcard Subscription not supported&lt;/td&gt;
&lt;td&gt;SUBACK, DISCONNECT&lt;/td&gt;

&lt;/tr&gt;

&lt;/tbody&gt;

&lt;/table&gt;
&lt;h2&gt;实际应用&lt;/h2&gt;
&lt;p&gt;1.　由于&lt;span&gt;主题别名（Topic Alias）的引入，使 MQTT PUBLISH 控制报文的体积更小&lt;/span&gt;，更便于在带宽和网络受限的物联网环境下传输消息。&lt;/p&gt;
&lt;p&gt;2.　AUTH 包的引入使 MQTT 协议扩展了认证方式，增加了询问/响应式的认证方式，&lt;span&gt;服务器或客户端在发送 CONNECT 与接收 CONNACK 包之间交换 AUTH 报文来完成身份验证的流程&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;3.　由于很多嵌入式设备的 CPU 并没有对 AES 加密标准下的加密算法提供硬件级的支持，因此，使用 AES 加密对嵌入式设备的硬件开销是非常大的，所以 MQTT 5.0 协议提供了新的加密算法 ChaCha20 ，&lt;span&gt;ChaCha20 在软件层面做加密和解密处理要比 AES 快得多&lt;/span&gt;。因此也算是一大进步，不过本人更希望 MQTT 下一版协议能够增加对 AEAD 加密算的支持。&lt;/p&gt;
&lt;p&gt;总的来说，MQTT 5.0 协议的内容增加了很多，协议书的内容几乎是 MQTT 3.1.1 协议的两倍，除了本文上述提到的这些新的变化，还有很多非常细节的东西没有在这里做详细的介绍。基于 MQTT 5.0 协议现有的很多属性，在实现 MQTT 5.0 协议的时说不定还能挖掘出更多的有意思的新用法，不过这需要开发人员去多读协议的具体细节，去更深入地理解 MQTT 5.0 协议。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2&gt;参考信息&lt;/h2&gt;

&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>f7b7d7a566d17d0543f910997cbcc708</guid>
<title>腾讯云实时数仓建设实践（PPT附下载）</title>
<link>https://toutiao.io/k/wkiyw89</link>
<content:encoded>&lt;div&gt;&lt;div&gt;

          

          
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>3276825a11756fbf0ed5cb9ecfe5804d</guid>
<title>你凭什么如此成功，自律？时间管理？</title>
<link>https://toutiao.io/k/er2ql1x</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;原创不易，求分享、求一键三连&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最近有个粉丝问了一个很有意思的问题：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;blockquote&gt;&lt;p&gt;小钗，我设定了很多目标，但都因不太自律半途而废了，怎么破？&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;设定了目标，但没有达成，很多人会将之归咎于&lt;strong&gt;时间管理有问题&lt;/strong&gt;或者&lt;strong&gt;不够自律&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但关于如何实现目标，之前&lt;strong&gt;瞬变思维框架&lt;/strong&gt;提供了很好的回答：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;所有冥顽不明，不接受改变的人，其实是因为缺乏清晰的目标，所以第一步是提供清晰的目标；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;表面上懒散的人，实际上是激情耗尽的表现，不能强迫这种人去完成清晰的目标，而是要把感性的部分引入进来，自驱前进；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;目标明确+思想深层次想改变的同时需要控制外部环境（控制路径），当路径形成后，改变会更容易产生；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;举个例子：如果目标是减肥，那么就要清晰定义减到多少；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其次要说清楚为什么要减肥，因为想要便漂亮还是什么，如果本身长得丑，那减肥自然没动力；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后是要列出减肥的具体行动计划，并且参与减肥群体互相激励，这样就会更容易达成目标。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;抛开瞬变思维框架，我们先来聊聊如何做时间管理，什么是自律。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;时间管理&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;时间管理即是体力的选择，就是你决定将时间用到什么地方，这里直接说时间管理的方法论，我这边常用的是&lt;strong&gt;重要紧急四象限&lt;/strong&gt;：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9232914923291492&quot; data-type=&quot;png&quot; data-w=&quot;717&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTBqgwduQzBswWldeczv6kSL3kGhSpYTCCk1cfNMVoUyuYzjkqGwRAE8HjIUqgm4LibjgCtY7assIxw/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;重要紧急&lt;/strong&gt;的事要保证越少越好，因为这种事情一旦出现就必须all in，他导致的后果可能是手段有限必须付出额外代价，一旦出现一定是时间管理有问题或者意想不到的情况；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;重要不紧急&lt;/strong&gt;的事要成为我们主要投资的部分，要有计划的做，持续的做，如果长时间不处理他们会变成重要紧急的事，但如果重要不紧急的事过多，需要整理事件分类排序；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;紧急不重要&lt;/strong&gt;给其他人提要求，分出去，查看结果就行，因为不重要偶尔失败也无妨，但一定要管理为什么失败，否则他也可能变成重要紧急；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;不紧急不重要&lt;/strong&gt;当没有这件事；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;时间管理事实上只是帮你整理出来&lt;strong&gt;应该做的事&lt;/strong&gt;是什么，但我们多数时候未必会去做，这就涉及到第二个话题：如何保证投入时间去做真正重要的事，这就涉及到自律了。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;自律&lt;/span&gt;&lt;/h2&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6642424242424242&quot; data-type=&quot;png&quot; data-w=&quot;3300&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTBqgwduQzBswWldeczv6kSL46eLibeKwyZXNWQbBicVGcs41ic428PNXXzT1Vc1YdTusbsHnvZO423Gg/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的上进心等同于自律，在理想的场景是我有一个目标，并且我为这个目标付诸了行动，最后目标达成了；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但事实上情况下，那个行动需要不断的重复，并且执行那个行动是要消耗意志力的，最后因为这样那样的借口，我们停止了那个行动，并且最后放弃了目标。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这很正常，多数时候目标都不能达成，所以怎么办呢，有两个办法：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;第一是对目标本身&lt;strong&gt;极度渴望&lt;/strong&gt;，愿意放弃所有；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;其次是在具体行动上下功夫，给他&lt;strong&gt;加杠杆&lt;/strong&gt;；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5351787773933102&quot; data-type=&quot;png&quot; data-w=&quot;3468&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTBqgwduQzBswWldeczv6kSLl03hz6UZmHfgw81KBwe8XY0hibuTnMsjRWICnAxZNoIia6ryNsdVVY6g/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;举个例子，我的公众号基本做到了日更，很多同学觉得不可思议，觉得我好自律，其实我王者荣耀都45星了，对于打王者荣耀我更自律......&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么为什么公众号可以不断更呢？因为我给内容输出这个事情加了杠杆！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先我本身是部门负责人，需要大量的思考，如果我一周没有两个思考结果，那说明一周都在摸鱼，所以必须有思考输出物；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其次我是公司文化建设负责人，文化建设本来就需要大量的内容输出，那是本质工作；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后到了公众号，只需要将工作中的内容脱敏一下，自然而然就产出了；&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;一鱼多吃，&lt;strong&gt;找到一件事更多的价值&lt;/strong&gt;，赋予一件事更多的意义，这件事自然就容易坚持了&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你跑步不只能拥有好身材，还能结识新朋友，甚至还能赚钱，那跑步这件事就很难中断了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为我们的核心动作加杠杆，&lt;strong&gt;拿到更多的正反馈&lt;/strong&gt;，能让自律这个事情更容易发生，不要跟人性做斗争嘛。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;知识地图&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事实上，重要紧急就是一个工具，他让“为事件分类排序这件事”变得更简单了，而这节约了很多的时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们首先得确定目标，其次要让多数的时间为目标而服务，最后要让单位时间的ROI更高，这时就需要切入方法论了，而这个提升ROI的方法就是：&lt;strong&gt;复盘，形成你的知识地图&lt;/strong&gt;，如图所示：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4537037037037037&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTBqgwduQzBswWldeczv6kSLds9xx5qZicY7Ksq5pLuhBIABGr01IycibgoZicoqtXtBRA64XngJ2vE8Q/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;知识地图是认知体系的重要组成部分，他是结构化运作的，比如一提到管理我们马上就会想到能力五维模型和Leader的五件事：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9297052154195011&quot; data-type=&quot;png&quot; data-w=&quot;1764&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTBqgwduQzBswWldeczv6kSLY2o2U5Y7QmAvnzQiawMIBnLYSqFZLb7NpibPqULvibBtWiavqmJX3hfHHg/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而且，知识地图并不是一层不变的，比如开始只有能力五维模型，Leader的五件事是随后摸索出来的，在实际使用过程中又发现，貌似辅导可以合并至人才（梯队建设）中，所以他还会持续变化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但无论怎么变化都已经形成知识地图深入体系了，这会对我们做一件事有极大的帮助。举个简单例子：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;我人在远洋光华国际上班；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;再上是朝阳区；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;再上是北京；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;周围是一些标志性建筑；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，一旦有人提到北京，我就可以跟他细说朝阳区某个办公区是什么样的，很细节也很形象；再比如说我们提到的自律：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6263157894736842&quot; data-type=&quot;png&quot; data-w=&quot;2660&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTBqgwduQzBswWldeczv6kSLeNNOtFEP6OOaMIaU8BicXbgoXUEibJm3BbOF9QqO1Q9dcwj4AQL4RFOg/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;自律跟目标有关系；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;目标可以与成长相关；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;成长的底层是心力的理想模型；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;成长增速逻辑是上进和热爱以及三种认知提升；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;但目标也可以与欲望相关；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;所以也可以衍生很多欲望相关的话题；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;知识就像串糖葫芦一样，一点一点的就被连起来了，如果没有形成知识地图，很容易形成盲点。比如一提到目标实现失败，很多人第一反应就是不够自律；看到某个人特别优秀，第一反应就是他的时间管理做得真好。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但自律与时间管理只是其中一个解释，某个目标失败的原因可能是目标不清晰，可能是路径难以实现，这不能完全说他不自律；某个人优秀可能是他心中的理想十分宏伟，可能是他的单位效率特别高，甚至他时间管理做得并不好。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;结语&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;至此，我相信大家不会认为一些优点会独立存在了，比如有人问：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;你是如何做到如此自律的；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;你是如何做时间管理的；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;你为何会如此优秀；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果用之前的&lt;strong&gt;心脑体框架&lt;/strong&gt;解释一次：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;心力即是目标，目标越清晰心力越强；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;体力即是时间的选择，日程安排的越合理体力越充沛；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;脑力即是利用时间的工具，方法论得宜必定事半功倍；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9858490566037735&quot; data-type=&quot;png&quot; data-w=&quot;2120&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTBqgwduQzBswWldeczv6kSLbiahdykdhTa4IzYnBOVTtmZpEFyicu3faur7CUsiaqp4d3oVqtibcfOzBg/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;心力、体力、脑力是一个正循环，一个拉胯，两个受损，一荣俱荣，一损俱损，但可以清晰的看到，体力是其中最重要的存在，体力只要出问题，那么心力、体力都没得玩。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而体力是什么呢，体力对应着我们常说的&lt;strong&gt;时间管理&lt;/strong&gt;和&lt;strong&gt;自律&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这不，&lt;strong&gt;自律&lt;/strong&gt;居然又跟心脑体联系起来了：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;体力是一个时间选择的问题，是你要把时间要用到什么地方；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;脑力是认知和思维框架，是时间的乘法，他能带来体力的价值最大化；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;心力是告诉你所有的时间和技巧要服务于什么目标。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个世界真是循环往复，说不清道不明啊！&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，今天的分享就到这。如果本文对你有帮助的话，欢迎&lt;strong&gt;点赞&amp;amp;评论&amp;amp;在看&amp;amp;分享&lt;/strong&gt;，这对我非常重要，感谢🙏🏻。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;想要更多交流可以加我微信：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5549076773566569&quot; data-type=&quot;png&quot; data-w=&quot;2058&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JdfjlwvwuTBqgwduQzBswWldeczv6kSLHCiap9GRSLMSqSBDyLGzlxVuUcWwRUAOj63N8O3TibATO08LzdatrmwQ/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>2d76c434b867cf31f0ece288a1d82d1e</guid>
<title>外卖广告大规模深度学习模型工程实践</title>
<link>https://toutiao.io/k/ba3jckk</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;58&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1546875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsU2zk0q52HtKQjubeUEyZHBVHPgeBXgTUj0ib1Kwfosl82xO1Aw7x6gccLuuYs1dbxI7REI7OcjbGw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;总第520&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;篇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2022年 第037篇&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;127&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;127&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;img border=&quot;0&quot; class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;103&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;103&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsU2zk0q52HtKQjubeUEyZHBic5ADGrKxgSd0tibyMiasOHXjb46qFBw7PTfuWAxXzWq32lDkL05icwkMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot; data-width=&quot;100%&quot; opacity=&quot;&quot; title=&quot;undefined&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; data-style=&quot;text-align: left; font-size: 14px; color: inherit;&quot;&gt;&lt;section&gt;&lt;span&gt;在外卖广告CTR场景下，深度学习模型正在从简单DNN小模型过渡到千亿参数复杂模型。基于该背景，本文将重点针对大规模深度模型在全链路带来的挑战，从在线时延、离线效率两个方面展开，阐述外卖广告在大规模深度模型上的工程实践经验，希望能为读者提供思路上的借鉴。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;导语&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1 背景&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2 分析&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3 模型推理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3.1 分布式&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3.2 CPU加速&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3.3 GPU加速&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4 特征服务CodeGen优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.1 全流程CodeGen优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.2 传输优化&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4.3 高维ID特征编码&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;5 样本构建&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;6 数据准备&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;6.1 做“加法”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;6.2 做“减法”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;6.3 做“乘法”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;6.4 做“除法”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;7 总结与展望&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;导语&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;随着美团外卖业务不断发展，外卖广告引擎团队在多个领域进行了工程上的探索和实践，也取得了一些成果。我们将以连载的方式进行分享，内容主要包括：① 业务平台化的实践；② 大规模深度学习模型工程实践；③ 近线计算的探索与实践；④ 大规模索引构建与在线检索服务实践；⑤ 机制工程平台化实践。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;不久前，我们已发表过业务平台化的实践（&lt;/span&gt;&lt;span&gt;详情请参阅《&lt;/span&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651766814&amp;amp;idx=1&amp;amp;sn=ffa130184ee8596cb7b7e3ee0a884683&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;美团外卖广告平台化的探索与实践&lt;/span&gt;&lt;/a&gt;&lt;span&gt;》&lt;span&gt;一文&lt;/span&gt;&lt;/span&gt;&lt;span&gt;）。本文为连载文章的第二篇，我们将重点针对大规模深度模型在全链路层面带来的挑战，从在线时延、离线效率两个方面进行展开，阐述广告在大规模深度模型上的工程实践，希望能为大家带来一些帮助或者启发。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1 背景&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;在搜索、推荐、广告（&lt;/span&gt;&lt;span&gt;下简称搜推广&lt;/span&gt;&lt;span&gt;）等互联网核心业务场景下，进行数据挖掘及兴趣建模，为用户提供优质的服务，已经成为改善用户体验的关键要素。近几年，针对搜推广业务，深度学习模型凭借数据红利和硬件技术红利，在业界得以广泛落地，同时在CTR场景，业界逐步从简单DNN小模型过渡到数万亿参数的Embedding大模型甚至超大模型。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;外卖广告业务线主要经历了“LR浅层模型（&lt;/span&gt;&lt;span&gt;树模型&lt;/span&gt;&lt;span&gt;）” -&amp;gt; “深度学习模型” -&amp;gt; “大规模深度学习模型”的演化过程。整个演化趋势从以人工特征为主的简单模型，逐步向以数据为核心的复杂深度学习模型进行过渡。而大模型的使用，大幅提高了模型的表达能力，更精准地实现了供需侧的匹配，为后续业务发展提供了更多的可能性。但随着模型、数据规模的不断变大，我们发现效率跟它们存在如下的关系：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;29&quot; data-cropselx2=&quot;403&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;375&quot; data-ratio=&quot;0.8688524590163934&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkYhoibq1H9rMt0NVlPbbI1SYBiagU7ayNsJVic2CPhTX7NGTMNyZ8mVPiaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1464&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;根据上图所示，在数据规模、模型规模增长的情况下，所对应的“时长”变得会越来越长。这个“时长”对应到离线层面，体现在效率上；对应到在线层面，就体现在Latency上。而我们的工作就是围绕这个“时长”的优化来开展。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2 分析&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;相比普通小模型，大模型的核心问题在于：随着数据量、模型规模增加数十倍甚至百倍，整体链路上的存储、通信、计算等都将面临新的挑战，进而影响算法离线的迭代效率。如何突破在线时延约束等一系列问题？我们先从全链路进行分析，如下所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;265&quot; data-ratio=&quot;0.48420074349442377&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOk1EtpRmpJKcsEeNSzHqZFEXG8iaiaD1mK2PMreS4wvzooZ5U5qCB2t1jg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2152&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;“时长”变长，主要会体现在以下几个方面：&lt;/span&gt;&lt;/section&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;在线时延&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：特征层面，在线请求不变的情况下，特征量的增加，带来的IO、特征计算耗时增加等问题尤为突出，需要在特征算子解析编译、特征抽取内部任务调度、网络I/O传等方面重塑。在模型层面，模型历经百M/G到几百G的变化，在存储上带来了2个数量级的上升。此外，单模型的计算量也出现了数量级的上涨（&lt;/span&gt;&lt;span&gt;FLOPs从百万到现在千万&lt;/span&gt;&lt;span&gt;），单纯的靠CPU，解决不了巨大算力的需求，建设CPU+GPU+Hierarchical Cache推理架构来支撑大规模深度学习推理势在必行。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;离线效率&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：随着样本、特征的数倍增加，样本构建，模型训练的时间会被大大拉长，甚至会变得不可接受。如何在有限的资源下，解决海量样本构建、模型训练是系统的首要问题。在数据层面，业界一般从两个层面去解决，一方面不断优化批处理过程中掣肘的点，另一方面把数据“化批为流”，由集中式转到分摊式，极大提升数据的就绪时间。在训练层面，通过硬件GPU并结合架构层面的优化，来达到加速目的。其次，算法创新往往都是通过人来驱动，新数据如何快速匹配模型，新模型如何快速被其他业务应用，如果说将N个人放在N条业务线上独立地做同一个优化，演变成一个人在一个业务线的优化，同时广播适配到N个业务线，将会有N-1个人力释放出来做新的创新，这将会极大地缩短创新的周期，尤其是在整个模型规模变大后，不可避免地会增加人工迭代的成本，实现从“人找特征/模型” 到“特征/模型找人”的深度转换，减少“重复创新”，从而达到模型、数据智能化的匹配。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Pipeline其他问题&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：机器学习Pipeline并不是在大规模深度学习模型链路里才有，但随着大模型的铺开，将会有新的挑战，比如：① 系统流程如何支持全量、增量上线部署；② 模型的回滚时长，把事情做正确的时长，以及事情做错后的恢复时长。简而言之，会在开发、测试、部署、监测、回滚等方面产生新的诉求。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;本文重点从在线时延（&lt;/span&gt;&lt;span&gt;&lt;strong&gt;模型推理、特征服务&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;）、离线效率（&lt;/span&gt;&lt;span&gt;&lt;strong&gt;样本构建、数据准备&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;）等两个方面来展开，逐步阐述广告在大规模深度模型上的工程实践。如何去优化“时长”等相关问题，我们会在后续篇章介进行分享，敬请期待。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3 模型推理&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;在模型推理层面，外卖广告历经了三个版本，从1.0时代，支持小众规模的DNN模型为代表，到2.0时代，高效、低代码支持多业务迭代，再到如今的3.0时代，逐步面向深度学习DNN算力以及大规模存储的需求。主要演进趋势如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;558&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;177&quot; data-ratio=&quot;0.32967032967032966&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkEZyiaiaJaG1HniaPhreesmhoSJ6orP7WEfoBvVLk0W8LxAnpf7lQNauQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1638&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;面向大模型推理场景，3.0架构解决的两个核心问题是：“存储问题”和“性能问题”。当然，面向N个百G+模型如何迭代，运算量数十倍增加时在线稳定性如何保障，Pipeline如何加固等等，也是工程面临的挑战。下面我们将重点介绍模型推理3.0架构是如何通过“分布式”来解决大模型存储问题，以及如何通过CPU/GPU加速来解决性能、吞吐问题。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.1 分布式&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;大模型的参数主要分为两部分：Sparse参数和Dense参数。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;因此，解决大模型参数规模增长的关键是将Sparse参数由单机存储改造为分布式存储，改造的方式包括两部分：① 模型网络结构转换；② Sparse参数导出。&lt;/span&gt;&lt;/section&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.1.1 模型网络结构转换&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;业界对于分布式参数的获取方式大致分为两种：外部服务提前获取参数并传给预估服务；预估服务内部通过改造TF（&lt;/span&gt;&lt;span&gt;TensorFlow&lt;/span&gt;&lt;span&gt;）算子来从分布式存储获取参数。为了减少架构改造成本和降低对现有模型结构的侵入性，我们选择通过改造TF算子的方式来获取分布式参数。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;正常情况下，TF模型会使用原生算子进行Sparse参数的读取，其中核心算子是GatherV2算子，算子的输入主要有两部分：① 需要查询的ID列表；② 存储Sparse参数的Embedding表。算子的作用是从Embedding表中读取ID列表索引对应的Embedding数据并返回，本质上是一个Hash查询的过程。其中，Embedding表存储的Sparse参数，其在单机模型中全部存储在单机内存中。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;改造TF算子本质上是对模型网络结构的改造，改造的核心点主要包括两部分：① 网络图重构；② 自定义分布式算子。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;1. 网络图重构&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong/&gt;：改造模型网络结构，将原生TF算子替换为自定义分布式算子，同时进行原生Embedding表的固化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;226&quot; data-ratio=&quot;0.4158686730506156&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkKMiaeciburUVOicnfzf1tDa7y3B2aDAEvFImFHTKVxDU0vJ3OK1wglzGg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1462&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;2. &lt;/span&gt;&lt;strong&gt;自定义分布式算子&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong/&gt;：改造根据ID列表查询Embedding流程，从本地Embedding表中查询，改造为从分布式KV中查询。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;206&quot; data-ratio=&quot;0.36039360393603936&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkAdASHr1KbtNFSFmW6vvyqm3UU1EHEkOAXAa8sicyCSYxHZTz1k3oqMA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1626&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.1.2 Sparse参数导出&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;整体流程如下图所示，我们通过离线分布式模型结构转换、近线数据一致性保证、在线热点数据缓存等手段，保障了百G大模型的正常迭代需求。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;165&quot; data-ratio=&quot;0.30184331797235026&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkWmhPUyjNWntp2wbhOEuUPbmj4ibBR4l4hib8AFjLBL5MLbRB4Q5J8Q7A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1736&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;可以看到，分布式借助的存储是外部KV能力，后续会替换为更加高效、灵活、易管理的Embedding Service。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.2 CPU加速&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;抛开模型本身的优化手段外，常见的CPU加速手段主要有两种：① 指令集优化，比如使用AVX2、AVX512指令集；② 使用加速库（&lt;/span&gt;&lt;span&gt;TVM、OpenVINO&lt;/span&gt;&lt;span&gt;）。&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;指令集优化&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：如果使用TensorFlow模型，在编译TensorFlow框架代码时，直接在编译选项里加入指令集优化项即可。实践证明引入AVX2、AVX512指令集优化效果明显，在线推理服务吞吐提升30%+。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;加速库优化&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：加速库通过对网络模型结构进行优化融合，以达到推理加速效果。业界常用的加速库有TVM、OpenVINO等，其中TVM支持跨平台，通用性较好。OpenVINO面向Intel厂商硬件进行针对性优化，通用性一般，但加速效果较好。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;下面，将会重点介绍我们使用OpenVINO进行CPU加速的一些实践经验。OpenVINO是Intel推出的一套基于深度学习的计算加速优化框架，支持机器学习模型的压缩优化、加速计算等功能。OpenVINO的加速原理简单概括为两部分：线性算子融合和数据精度校准。&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;线性算子融合&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：OpenVINO通过模型优化器，将模型网络中的多层算子进行统一线性融合，以降低算子调度开销和算子间的数据访存开销，比如将Conv+BN+Relu三个算子合并成一个CBR结构算子。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;数据精度校准&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：模型经过离线训练后，由于在推理的过程中不需要反向传播，完全可以适当降低数据精度，比如降为FP16或INT8的精度，从而使得内存占用更小，推理延迟更低。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;CPU加速通常是针对固定Batch的候选队列进行加速推理，但在搜推广场景中，候选队列往往都是动态的。这就意味着在模型推理之前，需要增加Batch匹配的操作，即将请求的动态Batch候选队列映射到一个离它最近的Batch模型上，但这需构建N个匹配模型，导致N倍的内存占用。而当前模型体积已达百G规模，内存严重吃紧。因此，选取合理的网络结构用于加速是需要考虑的重点问题。下图是整体的运行架构：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;283&quot; data-ratio=&quot;0.5154777927321669&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkeibk2Bs1tAibEOm2tQn8GbJVGC7HABQBS8RG7xk23mzds9cyjkhz4icEA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1486&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络分布&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：CTR模型网络结构整体抽象为三部分：Embedding层、Attention层和MLP层，其中Embedding层用于数据获取，Attention层包含较多逻辑运算和轻量级的网络计算，MLP层则为密集网络计算。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;加速网络选择&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：OpenVINO针对纯网络计算的加速效果较好，可以很好地应用于MLP层。另外，模型大部分数据存储在Embedding层中，MLP层占内存只有几十兆左右。如果针对MLP层网络划分出多个Batch，模型内存占用在优化前（&lt;/span&gt;&lt;span&gt;Embedding+Attention+MLP&lt;/span&gt;&lt;span&gt;）≈ 优化后（&lt;/span&gt;&lt;span&gt;Embedding+Attention+MLP×Batch个数&lt;/span&gt;&lt;span&gt;），对于内存占用的影响较小。因此，我们最终选取MLP层网络作为模型加速网络。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;目前，基于OpenVINO的CPU加速方案已经在生产环境取得不错效果：CPU与基线持平时，服务吞吐提升40%，平均时延下降15%。如果大家想在CPU层面做些加速的话，OpenVINO是个不错的选择。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.3 GPU加速&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;一方面，随着业务的发展，业务形态越来越丰富，流量越来越高，模型变宽变深，算力的消耗急剧增加；另一方面，广告场景主要使用DNN模型，涉及大量稀疏特征Embedding和神经网络浮点运算。作为访存和计算密集型的线上服务，在保证可用性的前提下，还要满足低延迟、高吞吐的要求，对单机算力也是一种挑战。这些算力资源需求和空间的矛盾，如果解决不好，会极大限制业务的发展：在模型加宽加深前，纯CPU 推理服务能够提供可观的吞吐，但是在模型加宽加深后，计算复杂度上升，为了保证高可用性，需要消耗大量机器资源，导致大模型无法大规模应用于线上。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;目前，业界比较通用的解决办法是利用GPU来解决这个问题，GPU本身比较适用于计算密集型任务。使用GPU需要解决如下挑战：如何在保证可用性、低延迟的前提下，尽可能做到高吞吐，同时还需要考虑易用性和通用性。为此，我们也在GPU上做了大量实践工作，比如TensorFlow-GPU、TensorFlow-TensorRT、TensorRT等，为了兼顾TF的灵活性以及TensorRT的加速效果，我们采用TensorFlow+TensorRT独立两阶段的架构设计。&lt;/span&gt;&lt;/section&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.3.1 加速分析&lt;/span&gt;&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;异构计算&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：我们的思路跟CPU加速比较一致，200G的深度学习CTR模型不能直接全放入到GPU里，访存密集型算子适用（&lt;/span&gt;&lt;span&gt;比如Embedding相关操作&lt;/span&gt;&lt;span&gt;）CPU，计算密集型算子（&lt;/span&gt;&lt;span&gt;比如MLP&lt;/span&gt;&lt;span&gt;）适用GPU。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;GPU使用需要关注的几个点&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：① 内存与显存的频繁交互；② 时延与吞吐；③ 扩展性与性能优化的Trade Off；④ GPU Utilization 。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;推理引擎的选择&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：业界常用推理加速引擎有TensorRT、TVM、XLA、ONNXRuntime等，由于TensorRT在算子优化相比其他引擎更加深入，同时可以通过自定义plugin的方式实现任意算子，具有很强的扩展性。而且TensorRT支持常见学习平台（&lt;/span&gt;&lt;span&gt;Caffe、PyTorch、TensorFlow等&lt;/span&gt;&lt;span&gt;）的模型，其周边越来越完善（&lt;/span&gt;&lt;span&gt;模型转换工具onnx-tensorrt、性能分析工具nsys等&lt;/span&gt;&lt;span&gt;），因此在GPU侧的加速引擎使用TensorRT。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;模型分析&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：CTR模型网络结构整体抽象为三部分：Embedding层、Attention层和MLP层，其中Embedding层用于数据获取，适合CPU；Attention层包含较多逻辑运算和轻量级的网络计算，MLP层则重网络计算，而这些计算可以并行进行，适合GPU，可以充分利用GPU Core（&lt;/span&gt;&lt;span&gt;Cuda Core、Tensor Core&lt;/span&gt;&lt;span&gt;），提高并行度。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.3.2 优化目标&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;深度学习推理阶段对算力和时延具有很高的要求，如果将训练好的神经网络直接部署到推理端，很有可能出现算力不足无法运行或者推理时间较长等问题。因此，我们需要对训练好的神经网络进行一定的优化。业界神经网络模型优化的一般思路，可以从模型压缩、不同网络层合并、稀疏化、采用低精度数据类型等不同方面进行优化，甚至还需要根据硬件特性进行针对性优化。为此，我们主要围绕以下两个目标进行优化：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;延时和资源约束下的吞吐：当register、Cache等共享资源不需要竞争时，提高并发可有效提高资源利用率（&lt;/span&gt;&lt;span&gt;CPU、GPU等利用率&lt;/span&gt;&lt;span&gt;），但随之可能带来请求延时的上涨。由于在线系统的延时限制非常苛刻，所以不能只通过资源利用率这一指标简单换算在线系统的吞吐上限，需要在延时约束下结合资源上限进行综合评估。当系统延时较低，资源（&lt;/span&gt;&lt;span&gt;Memory/CPU/GPU等&lt;/span&gt;&lt;span&gt;）利用率是制约因素时，可通过模型优化降低资源利用率；当系统资源利用率均较低，延时是制约因素时，可通过融合优化和引擎优化来降低延时。通过结合以上各种优化手段可有效提升系统服务的综合能力，进而达到提升系统吞吐的目的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;计算量约束下的计算密度：CPU/GPU异构系统下，模型推理性能主要受数据拷贝效率和计算效率影响，它们分别由访存密集型算子和计算密集型算子决定，而数据拷贝效率受PCIe数据传输、CPU/GPU内存读写等效率的影响，计算效率受各种计算单元CPU Core、CUDA Core、Tensor Core等计算效率的影响。随着GPU等硬件的快速发展，计算密集型算子的处理能力同步快速提高，导致访存密集型算子阻碍系统服务能力提升的现象越来越突出，因此减少访存密集型算子，提升计算密度对系统服务能力也变得越来越重要，即在模型计算量变化不大的情况下，减少数据拷贝和kernel launch等。比如通过模型优化和融合优化来减少算子变换（&lt;/span&gt;&lt;span&gt;比如Cast/Unsqueeze/Concat等算子&lt;/span&gt;&lt;span&gt;）的使用，使用CUDA Graph减少kernel launch等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;下面将围绕以上两个目标，具体介绍我们在&lt;strong&gt;模型优化&lt;/strong&gt;、&lt;strong&gt;融合优化&lt;/strong&gt;和&lt;strong&gt;引擎优化&lt;/strong&gt;所做的一些工作。&lt;/span&gt;&lt;/section&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.3.3 模型优化&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1. 计算与传输去重&lt;/strong&gt;：推理时同一Batch只包含一个用户信息，因此在进行inference之前可以将用户信息从Batch Size降为1，真正需要inference时再进行展开，降低数据的传输拷贝以及重复计算开销。如下图，inference前可以只查询一次User类特征信息，并在只有用户相关的子网络中进行裁剪，待需要计算关联时再展开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;217&quot; data-ratio=&quot;0.38498789346246975&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkREOOvFgIjUrQPznbO8O22JWxG7tiaWlvm3zrRiasibdFgot5HKzZbzOjg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1652&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2. 数据精度优化&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：由于模型训练时需要反向传播更新梯度，对数据精度要求较高；而模型推理时，只进行前向推理不需要更新梯度，所以在保证效果的前提下，使用FP16或混合精度进行优化，节省内存空间，减少传输开销，提升推理性能和吞吐。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;3. 计算下推&lt;/strong&gt;：CTR模型结构主要由Embedding、Attention和MLP三层构成，Embedding层偏数据获取，Attention有部分偏逻辑，部分偏计算，为了充分压榨GPU的潜力，将CTR模型结构中Attention和MLP大部分计算逻辑由CPU下沉到GPU进行计算，整体吞吐得到大幅提升。&lt;/span&gt;&lt;/section&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.3.4 融合优化&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;在线模型inference时，每一层的运算操作都是由GPU完成，实际上是CPU通过启动不同的CUDA kernel来完成计算，CUDA kernel计算张量的速度非常快，但是往往大量的时间是浪费在CUDA kernel的启动和对每一层输入/输出张量的读写操作上，这造成了内存带宽的瓶颈和GPU资源的浪费。这里我们将主要介绍TensorRT部分&lt;strong&gt;自动优化&lt;/strong&gt;以及&lt;strong&gt;手工优化&lt;/strong&gt;两块工作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;1. &lt;/span&gt;&lt;strong&gt;自动优化&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong/&gt;：TensorRT是一个高性能的深度学习inference优化器，可以为深度学习应用提供低延迟、高吞吐的推理部署。TensorRT可用于对超大规模模型、嵌入式平台或自动驾驶平台进行推理加速。TensorRT现已能支持TensorFlow、Caffe、MXNet、PyTorch等几乎所有的深度学习框架，将TensorRT和NVIDIA的GPU结合起来，能在几乎所有的框架中进行快速和高效的部署推理。而且有些优化不需要用户过多参与，比如部分Layer Fusion、Kernel Auto-Tuning等。&lt;/span&gt;&lt;/section&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Layer Fusion&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：TensorRT通过对层间的横向或纵向合并，使网络层的数量大大减少，简单说就是通过融合一些计算op或者去掉一些多余op，来减少数据流通次数、显存的频繁使用以及调度的开销。比如常见网络结构Convolution And ElementWise Operation融合、CBR融合等，下图是整个网络结构中的部分子图融合前后结构图，FusedNewOP在融合过程中可能会涉及多种Tactic，比如CudnnMLPFC、CudnnMLPMM、CudaMLP等，最终会根据时长选择一个最优的Tactic作为融合后的结构。通过融合操作，使得网络层数减少、数据通道变短；相同结构合并，使数据通道变宽；达到更加高效利用GPU资源的目的。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;218&quot; data-ratio=&quot;0.39520958083832336&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkTg05CpTALichSNatZcCibeUGuVrXGPa9G68Z7v0TJwKko8ZRFV5hMicSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1670&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Kernel Auto-Tuning&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：网络模型在inference时，是调用GPU的CUDA kernel进行计算。TensorRT可以针对不同的网络模型、显卡结构、SM数量、内核频率等进行CUDA kernel调整，选择不同的优化策略和计算方式，寻找适合当前的最优计算方式，以保证当前模型在特定平台上获得最优的性能。上图是优化主要思想，每一个op会有多种kernel优化策略（&lt;/span&gt;&lt;span&gt;cuDNN、cuBLAS等&lt;/span&gt;&lt;span&gt;），根据当前架构从所有优化策略中过滤低效kernel，同时选择最优kernel，最终形成新的Network。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;2. &lt;/span&gt;&lt;strong&gt;手工优化&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong/&gt;：众所周知，GPU适合计算密集型的算子，对于其他类型算子（&lt;/span&gt;&lt;span&gt;轻量级计算算子，逻辑运算算子等&lt;/span&gt;&lt;span&gt;）不太友好。使用GPU计算时，每次运算一般要经过几个流程：CPU在GPU上分配显存 -&amp;gt; CPU把数据发送给GPU -&amp;gt; CPU启动CUDA kernel -&amp;gt; CPU把数据取回 -&amp;gt; CPU释放GPU显存。为了减少调度、kernel launch以及访存等开销，需要进行网络融合。由于CTR大模型结构灵活多变，网络融合手段很难统一，只能具体问题具体分析。比如在垂直方向，Cast、Unsqueeze和Less融合，TensorRT内部Conv、BN和Relu融合；在水平方向，同维度的输入算子进行融合。为此，我们基于线上实际业务场景，使用NVIDIA相关性能分析工具（&lt;/span&gt;&lt;span&gt;NVIDIA Nsight Systems、NVIDIA Nsight Compute等&lt;/span&gt;&lt;span&gt;）进行具体问题的分析。把这些性能分析工具集成到线上inference环境中，获得inference过程中的GPU Profing文件。通过Profing文件，我们可以清晰的看到inference过程，我们发现整个inference中部分算子kernel launch bound现象严重，而且部分算子之间gap间隙较大，存在优化空间，如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;261&quot; data-ratio=&quot;0.45671267252195735&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkZrqoUdTbUELznzHjXCTLGY5avRX9Rb1icM5hyruqDJ30YKIL4yhtoUg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1594&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为此，基于性能分析工具和转换后的模型对整个Network分析，找出TensorRT已经优化的部分，然后对Network中其他可以优化的子结构进行网络融合，同时还要保证这样的子结构在整个Network占有一定的比例，保证融合后计算密度能够有一定程度的上升。至于采用什么样的网络融合手段，根据具体的场景进行灵活运用即可，如下图是我们融合前后的子结构图对比：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;401&quot; data-ratio=&quot;0.6698872785829307&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkPHjHRC32f6piaEZIMib6snxz3yGicyIwQqmanH3aRuhxEzNhF5AuHjpmg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1242&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.3.5 引擎优化&lt;/span&gt;&lt;/h4&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;多模型&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：由于外卖广告中用户请求规模不确定，广告时多时少，为此加载多个模型，每个模型对应不同输入的Batch，将输入规模分桶归类划分，并将其padding到多个固定Batch，同时对应到相应的模型进行inference。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Multi-contexts和Multi-streams&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：对每一个Batch的模型，使用多context和多stream，不仅可以避免模型等待同一context的开销，而且可以充分利用多stream的并发性，实现stream间的overlap，同时为了更好的解决资源竞争的问题，引入CAS。如下图所示，单stream变成多stream：&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;197&quot; data-ratio=&quot;0.3683510638297872&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkiaWEDwQGxwPp3lQlmC5LgG0QRWL45TEn94qragMScwaRHZjR5hpccJA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1504&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;ol start=&quot;3&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Dynamic Shape&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：为了应对输入Batch不定场景下，不必要的数据padding，同时减少模型数量降低显存等资源的浪费，引入Dynamic Shape，模型根据实际输入数据进行inference，减少数据padding和不必要的计算资源浪费，最终达到性能优化和吞吐提升的目的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;CUDA Graph&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：现代GPU每个operation（&lt;/span&gt;&lt;span&gt;kernel运行等&lt;/span&gt;&lt;span&gt;）所花费的时间至少是微秒级别，而且，将每个operation提交给GPU也会产生一些开销（&lt;/span&gt;&lt;span&gt;微秒级别&lt;/span&gt;&lt;span&gt;）。实际inference时，经常需要执行大量的kernel operation，这些operation每一个都单独提交到GPU并独立计算，如果可以把所有提交启动的开销汇总到一起，应该会带来性能的整体提升。CUDA Graph可以完成这样的功能，它将整个计算流程定义为一个图而不是单个操作的列表，然后通过提供一种由单个CPU操作来启动图上的多个GPU操作的方法减少kernel提交启动的开销。CUDA Graph核心思想是减少kernel launch的次数，通过在推理前后capture graph，根据推理的需要进行update graph，后续推理时不再需要一次一次的kernel launch，只需要graph launch，最终达到减少kernel launch次数的目的。如下图所示，一次inference执行4次kernel相关操作，通过使用CUDA Graph可以清晰看到优化效果。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;184&quot; data-ratio=&quot;0.36039360393603936&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkFnyfmes68BjdBiciaqudzA3TbL07iboXuyaxkXRdkyMHMpmSx4vAdS5bw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1626&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;ol start=&quot;5&quot; data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;多级PS&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：为了进一步挖掘GPU加速引擎性能，对Embedding数据的查询操作可通过多级PS的方式进行：GPU显存Cache-&amp;gt;CPU内存Cache-&amp;gt;本地SSD/分布式KV。其中，热点数据可缓存在GPU显存中，并通过数据热点的迁移、晋升和淘汰等机制对缓存数据进行动态更新，充分挖掘GPU的并行算力和访存能力进行高效查询。经离线测试，GPU Cache查询性能相比CPU Cache提升10倍+；对于GPU Cache未命中数据，可通过访问CPU Cache进行查询，两级Cache可满足90%+的数据访问；对于长尾请求，则需要通过访问分布式KV进行数据获取。具体结构如下：&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;216&quot; data-ratio=&quot;0.3987577639751553&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkDgOhF6bibE9FAAJqCR19kgoBGXMSD312Ijd0hianPoc290hfVhSyP88g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1610&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3.3.6 Pipeline&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;模型从离线训练到最终在线加载，整个流程繁琐易出错，而且模型在不同GPU卡、不同TensorRT和CUDA版本上无法通用，这给模型转换带来了更多出错的可能性。因此，为了提升模型迭代的整体效率，我们在Pipeline方面进行了相关能力建设，如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;309&quot; data-ratio=&quot;0.56125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkjRTNQGDpD7w87q7cj6z4FSN9RITkkib3ylgZgUxajvaLoZVaEg1ic7Sw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1600&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Pipeline建设包括两部分：离线侧模型拆分转换流程，以及在线侧模型部署流程：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;离线侧&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：只需提供模型拆分节点，平台会自动将原始TF模型拆分成Embedding子模型和计算图子模型，其中Embedding子模型通过分布式转换器进行分布式算子替换和Embedding导入工作；计算图子模型则根据选择的硬件环境（&lt;/span&gt;&lt;span&gt;GPU型号、TensorRT版本、CUDA版本&lt;/span&gt;&lt;span&gt;）进行TensorRT模型的转换和编译优化工作，最终将两个子模型的转换结果存储到S3中，用于后续的模型部署上线。整个流程都是平台自动完成，无需使用方感知执行细节。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;在线测&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：只需选择模型部署硬件环境（&lt;/span&gt;&lt;span&gt;与模型转换的环境保持一致&lt;/span&gt;&lt;span&gt;），平台会根据环境配置，进行模型的自适应推送加载，一键完成模型的部署上线。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;Pipeline通过配置化、一键化能力的建设，极大提升了模型迭代效率，帮助算法和工程同学能够更加专注的做好本职工作。下图是在GPU实践中相比纯CPU推理取得的整体收益：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;3&quot; data-cropselx2=&quot;390&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;292&quot; data-ratio=&quot;0.7450271247739603&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkjDlSiaeC0NpupzkWWvN9c7IxxJ1sw8T5KT8ccT8xl8AvNy57ljtWLdA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1106&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4 特征服务CodeGen优化&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;特征抽取是模型计算的前置阶段，无论是传统的LR模型还是日趋流行的深度学习模型，都需要通过特征抽取来得到输入。在之前的博客&lt;/span&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651760534&amp;amp;idx=1&amp;amp;sn=89fcab81347782818edb98fd7fa76991&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;美团外卖特征平台的建设与实践&lt;/span&gt;&lt;/a&gt;&lt;span&gt;中，描述了我们基于模型特征自描述MFDL，将特征计算流程配置化，尽量保证了在线预估和离线训练时样本的一致性。随着业务快速迭代，模型特征数量不断增加，特别是大模型引入了大量的离散特征，导致计算量有了成倍的增长。为此，我们对特征抽取层做了一些优化，在吞吐和耗时上都取得了显著的收益。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.1 全流程CodeGen优化&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;DSL是对特征处理逻辑的描述。在早期的特征计算实现中，每个模型配置的DSL都会被解释执行。解释执行的优点是实现简单，通过良好的设计便能获得较好的实现，比如常用的迭代器模式；缺点是执行性能较低，在实现层面为了通用性避免不了添加很多的分支跳转和类型转换等。实际上，对于一个固定版本的模型配置来说，它所有的模型特征转换规则都是固定的，不会随请求而变化。极端情况下，基于这些已知的信息，可以对每个模型特征各自进行Hard Code，从而达到最极致的性能。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;显然，模型特征配置千变万化，不可能针对每个模型去人工编码。于是便有了CodeGen的想法，在编译期为每一个配置自动生成一套专有的代码。CodeGen并不是一项具体的技术或框架，而是一种思想，完成从抽象描述语言到具体执行语言的转换过程。其实在业界，计算密集型场景下使用CodeGen来加速计算已是常用做法。如Apache Spark通过CodeGen来优化SparkSql执行性能，从1.x的ExpressionCodeGen加速表达式运算到2.x引入的WholeStageCodeGen进行全阶段的加速，都取得了非常明显的性能收益。在机器学习领域，一些TF模型加速框架，如TensorFlow XLA和TVM，也是基于CodeGen思想，将Tensor节点编译成统一的中间层IR，基于IR结合本地环境进行调度优化，从而达到运行时模型计算加速的目的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;47&quot; data-ratio=&quot;0.12515188335358446&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkjDz3lKicibbQc6Tab6FI7DejZF6fnDYUNd965ynqzVoxwo2cVndHPFWQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1646&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;借鉴了Spark的WholeStageCodeGen，我们的目标是将整个特征计算DSL编译形成一个可执行方法，从而减少代码运行时的性能损耗。整个编译过程可以分为：前端（&lt;/span&gt;&lt;span&gt;FrontEnd&lt;/span&gt;&lt;span&gt;），优化器（&lt;/span&gt;&lt;span&gt;Optimizer&lt;/span&gt;&lt;span&gt;）和后端（&lt;/span&gt;&lt;span&gt;BackEnd&lt;/span&gt;&lt;span&gt;）。前端主要负责解析目标DSL，将源码转化为AST或IR；优化器则是在前端的基础上，对得到的中间代码进行优化，使代码更加高效；后端则是将已经优化的中间代码转化为针对各自平台的本地代码。具体实现如下：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;前端&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：每个模型对应一张节点DAG图，逐个解析每个特征计算DSL，生成AST，并将AST节点添加到图中。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;优化器&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：针对DAG节点进行优化，比如公共算子提取、常量折叠等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;后端&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：将经过优化后的图编译成字节码。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;348&quot; data-ratio=&quot;0.6050670640834576&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkg3lF8r1hyWXQ7Pm6as04DibT6ak3CfclIq4sK5ImXCPEAHPF1fO6M7g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1342&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;经过优化之后，对节点DAG图的翻译，即后端代码实现，决定了最终的性能。这其中的一个难点，同时也是不能直接使用已有开源表达式引擎的原因：特征计算DSL并非是一个纯计算型表达式。它可以通过读取算子和转换算子的组合来描述特征的获取和处理过程：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;读取算子&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：从存储系统获取特征的过程，是个IO型任务。比如查询远程KV系统。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;转换算子&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：特征获取到本地之后对特征进行转换，是个计算密集型任务。比如对特征值做Hash。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;所以在实际实现中，需要考虑不同类型任务的调度，尽可能提高机器资源利用率，优化流程整体耗时。结合对业界的调研以及自身实践，进行了以下三种实现：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;128&quot; data-ratio=&quot;0.23897911832946636&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkpVjN3ysxQ6CHdNCSapSiaIamRNhicILLu3icNHuJFsJS3ZUicQOqZSP5Wg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1724&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基于任务类型划分Stage&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：将整个流程划分成获取和计算两种Stage，Stage内部分片并行处理，上一个Stage完成后再执行下一个Stage。这是我们早期使用的方案，实现简单，可以基于不同的任务类型选择不同的分片大小，比如IO型任务可以使用更大的分片。但缺点也很明显，会造成不同Stage的长尾叠加，每个Stage的长尾都会影响整个流程的耗时。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;基于流水线划分Stage&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：为了减少不同Stage的长尾叠加，可以先将数据分片，为每个特征读取分片添加回调，在IO任务完成后回调计算任务，使整个流程像流水线一样平滑。分片调度可以让上一个Stage就绪更早的分片提前进入下一个Stage，减少等待时间，从而减少整体请求耗时长尾。但缺点就是统一的分片大小不能充分提高每个Stage的利用率，较小的分片会给IO型任务带来更多的网络消耗，较大的分片会加剧计算型任务的耗时。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;基于SEDA（Staged Event-Driven Architecture）方式&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：阶段式事件驱动方式使用队列来隔离获取Stage和计算Stage，每个Stage分配有独立的线程池和批处理处理队列，每次消费N（&lt;/span&gt;&lt;span&gt;batching factor&lt;/span&gt;&lt;span&gt;）个元素。这样既能够实现每个Stage单独选择分片大小，同时事件驱动模型也可以让流程保持平滑。这是我们目前正在探索的方式。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;CodeGen方案也并非完美，动态生成的代码降低了代码可读性，增加了调试成本，但以CodeGen作为适配层，也为更深入的优化打开了空间。基于CodeGen和异步非阻塞的实现，在线上取到了不错的收益，一方面减少了特征计算的耗时，另一方面也明显的降低了CPU负载，提高了系统吞吐。未来我们会继续发挥CodeGen的优势，在后端编译过程中进行针对性的优化，如探索结合硬件指令（&lt;/span&gt;&lt;span&gt;如SIMD&lt;/span&gt;&lt;span&gt;）或异构计算（&lt;/span&gt;&lt;span&gt;如GPU&lt;/span&gt;&lt;span&gt;）来做更深层次的优化。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.2 传输优化&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;在线预估服务整体上是双层架构，特征抽取层负责模型路由和特征计算，模型计算层负责模型计算。原有的系统流程是将特征计算后的结果拼接成M（&lt;/span&gt;&lt;span&gt;预测的Batch Size&lt;/span&gt;&lt;span&gt;） × N（&lt;/span&gt;&lt;span&gt;样本宽度&lt;/span&gt;&lt;span&gt;）的矩阵，再经过序列化传输到计算层。之所以这么做，一方面出于历史原因，早期很多非DNN的简单模型的输入格式是个矩阵，经过路由层拼接后，计算层可以直接使用，无需转换；另一方面，数组格式比较紧凑，可以节省网络传输耗时。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;72&quot; data-ratio=&quot;0.15639269406392695&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOk0Mj9oKoWDaS9SYGLWqadfjibQm6NTyOmsdDTrWvl1YSMPJ3K6qPB54w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1752&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;然而随着模型迭代发展，DNN模型逐渐成为主流，基于矩阵传输的弊端也非常明显：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;扩展性差&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：数据格式统一，不兼容非数值类型的特征值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;传输性能损耗&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：基于矩阵格式，需要对特征做对齐，比如Query/User维度需要被拷贝对齐到每个Item上，增大了请求计算层的网络传输数据量。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;为了解决以上问题，优化后的流程在传输层之上加入一层转换层，用来根据MDFL的配置将计算的模型特征转换成需要的格式，比如Tensor、矩阵或离线使用的CSV格式等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;170&quot; data-ratio=&quot;0.3007246376811594&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkFqJ6RNxiakmFsuDLJbgicX6M6bhbQXaBn176yFgTCuJze0iaHMRDwhpuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1656&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;实际线上大多数模型都是TF模型，为了进一步节省传输消耗，平台设计了Tensor Sequence格式来存储每个Tensor矩阵：其中，r_flag用来标记是否是item类特征，length表示item特征的长度，值为M（&lt;/span&gt;&lt;span&gt;Item个数&lt;/span&gt;&lt;span&gt;）×NF（&lt;/span&gt;&lt;span&gt;特征长度&lt;/span&gt;&lt;span&gt;），data用来存储实际的特征值，对于Item特征将M个特征值扁平化存储，对于请求类特征则直接填充。基于紧凑型Tensor Sequence格式使数据结构更加紧凑，减少网络传输数据量。优化后的传输格式在线上也取得不错的效果，路由层调用计算层的请求大小下降了50%+，网络传输耗时明显下降。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4.3 高维ID特征编码&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;离散特征和序列特征可以统一为Sparse特征，特征处理阶段会把原始特征经过Hash处理，变为ID类特征。在面对千亿级别维度的特征，基于字符串拼接再Hash的过程，在表达空间和性能上，都无法满足要求。基于对业界的调研，我们设计和应用了基于Slot编码的方式特征编码格式：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;170&quot; data-ratio=&quot;0.3319615912208505&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkIs5r5RiayPWewCqbaJhgNCFwA9gGt7O68XbjtCemLxnfgbsxOKB0QdA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1458&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;其中，feature_hash为原始特征值经过Hash后的值。整型特征可以直接填充，非整型特征或交叉特征先经过Hash后再填充，超过44位则截断。基于Slot编码方案上线后，不仅提升了在线特征计算的性能，同时也为模型效果的带来了明显提升。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5 样本构建&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5.1 流式样本&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;业界为了解决线上线下一致性的问题，一般都会在线dump实时打分使用的特征数据，称为特征快照；而不是通过简单离线Label拼接，特征回填的方式来构建样本，因为这种方式会带来较大的数据不一致。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;架构原始的方式如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;91&quot; data-ratio=&quot;0.18509615384615385&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkX5QsxqPgRsQ5VOUPTqDw8tpV2sxJ0XmP7765HbJqutFaWeibkLRRjAw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1664&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这种方案随着特征规模越来越大、迭代场景越来越复杂，突出的问题就是在线特征抽取服务压力大，其次是整个数据流收集成本太高。此样本收集方案存在以下问题：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;就绪时间长&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在现有资源限制下，跑那么大数据几乎要在T+2才能将样本数据就绪，影响算法模型迭代。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;资源耗费大&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：现有样本收集方式是将所有请求计算特征后与曝光、点击进行拼接，由于对未曝光Item进行了特征计算、数据落表，导致存储的数据量较大，耗费大量资源。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5.1.1 常见的方案&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;为了解决上面的问题，业界常见有两个方案：①Flink实时流处理；②KV缓存二次处理。具体流程如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;120&quot; data-ratio=&quot;0.24317617866004962&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkdNrA6wc23VowvY269iaXUzlr4bVyu52p1qlmGq9oLKL61XAbu9fSa5w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1612&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;流式拼接方案&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：借助流式处理框架（&lt;/span&gt;&lt;span&gt;Flink、Storm等&lt;/span&gt;&lt;span&gt;）低延迟的流处理能力，直接读取曝光/点击实时流，与特征快照流数据在内存中进行关联（&lt;/span&gt;&lt;span&gt;Join&lt;/span&gt;&lt;span&gt;）处理；先生成流式训练样本，再转存为模型离线训练样本。其中流式样本和离线样本分别存储在不同的存储引擎中，支持不同类型的模型训练方式。此方案的问题：在数据流动环节的数据量依然很大，占用较多的消息流资源（&lt;/span&gt;&lt;span&gt;比如Kafka&lt;/span&gt;&lt;span&gt;）；Flink资源消耗过大，如果每秒百G的数据量，做窗口Join则需要30分钟×60×100G的内存资源。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;KV缓存方案&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：把特征抽取的所有特征快照写入KV存储（&lt;/span&gt;&lt;span&gt;如Redis&lt;/span&gt;&lt;span&gt;）缓存N分钟，业务系统通过消息机制，把候选队列中的Item传入到实时计算系统（&lt;/span&gt;&lt;span&gt;Flink或者消费应用&lt;/span&gt;&lt;span&gt;），此时的Item的量会比之前请求的Item量少很多，这样再将这些Item特征从特征快照缓存中取出，数据通过消息流输出，支持流式训练。这种方法借助了外存，不管随着特征还是流量增加，Flink资源可控，而且运行更加稳定。但突出的问题还是需要较大的内存来缓存大批量数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5.1.2 改进优化&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;从减少无效计算的角度出发，请求的数据并不会都曝光。而策略对曝光后的数据有更强的需求，因此将天级处理前置到流处理，可以极大提升数据就绪时间。其次，从数据内容出发，特征包含请求级变更的数据与天级变更的数据，链路灵活分离两者处理，可以极大提升资源的利用，下图是具体的方案：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;257&quot; data-ratio=&quot;0.4550898203592814&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOk7oIObjFVO27bJFfePVoMvwic7UB1UdZyGfkswZrcO1leDwwlu651Ckw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1670&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;1. 数据拆分&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：解决数据传输量大问题（&lt;/span&gt;&lt;span&gt;特征快照流大问题&lt;/span&gt;&lt;span&gt;），预测的Label与实时数据一一Match，离线数据可以通过回流的时候二次访问，这样可以极大降低链路数据流的大小。&lt;/span&gt;&lt;/section&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;样本流中只有上下文+实时特征，增加读取数据流稳定性，同时由于只需要存储实时特征，Kafka硬盘存储下降10+倍。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2. 延时消费Join方式&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：解决占用内存大问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;3. 特征补录拼样本&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通过Label的Join，此处补录的特征请求量不到在线的20%；样本延迟读取，与曝光做拼接后过滤出有曝光模型服务请求（&lt;/span&gt;&lt;span&gt;Context+实时特征&lt;/span&gt;&lt;span&gt;），再补录全部离线特征，拼成完整样本数据，写入HBase。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5.2 结构化存储&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;随着业务迭代，特征快照中的特征数量越来越大，使得整体特征快照在单业务场景下达到几十TB级别/天；从存储上看，多天单业务的特征快照就已经PB级别，快到达广告算法存储阈值，&lt;strong&gt;存储压力大&lt;/strong&gt;；从计算角度上看，使用原有的计算流程，由于计算引擎（&lt;/span&gt;&lt;span&gt;Spark&lt;/span&gt;&lt;span&gt;）的资源限制（&lt;/span&gt;&lt;span&gt;使用到了shuffle，shuffle write阶段数据会落盘，如果分配内存不足，会出现多次落盘和外排序&lt;/span&gt;&lt;span&gt;），需要与自身数据等大小的内存和较多的计算CU才能有效的完成计算，&lt;strong&gt;占用内存高&lt;/strong&gt;。样本构建流程核心流程如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;105&quot; data-ratio=&quot;0.20512820512820512&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkx1RQbMJAWhGwomSFtXKL5kiarFRMnKNMicXoqxg5ZFa1EJ7HrGmyBpmA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1638&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在补录特征时，存在以下问题：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据冗余&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：补录特征的离线表一般为全量数据，条数在亿级别，样本构建用到的条数约为当日DAU的数量即千万级别，因此补录的特征表数据在参与计算时存在冗余数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Join顺序&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：补录特征的计算过程即维度特征补全，存在多次Join计算，因此Join计算的性能和Join的表的顺序有很大关系，如上图所示，如果左表为几十TB级别的大表，那么之后的shuffle计算过程都会产生大量的网络IO、磁盘IO。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;为了解决样本构建效率慢的问题，短期先从数据结构化治理，详细过程如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;291&quot; data-ratio=&quot;0.5191176470588236&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkhDLm2XpibPwEbl4c5IHrUhF22ficiaQnf6GBtzcy1oWcYZ4ZYbyMSKnsw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1360&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结构化拆分。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;数据拆分成Context数据和结构化存储的维度数据代替混合存储。解决Label样本拼接新特征过程中携带大量冗余数据问题；并且做结构化存储后，针对离线特征，得到了很大的存储压缩。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;高效过滤前置&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。数据过滤提前到Join前，减少参与特征计算的数据量，可以有效降低网络IO。在拼接过程中，补录特征的Hive表一般来说是全量表，数据条数一般为月活量，而实际拼接过程中使用的数据条数约为日活量，因此存在较大的数据冗余，无效的数据会带来额外的IO和计算。优化方式为预计算使用的维度Key，并生成相应的布隆过滤器，在数据读取的时候使用布隆过滤器进行过滤，可以极大降低补录过程中冗余数据传输和冗余计算。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;高性能Join&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。使用高效的策略去编排Join顺序，提升特征补录环节的效率和资源占用。在特征拼接过程中，会存在多张表的Join操作，Join的先后顺序也会极大影响拼接性能。如上图所示，如果拼接的左表数据量较大时，那么整体性能就会差。可以使用哈夫曼算法的思想，把每个表看作一个节点，对应的数据量量看成是他的权重，表之间的Join计算量可以简单类比两个节点的权重相加。因此，可以将此问题抽象成构造哈夫曼树，哈夫曼树的构造过程即为最优的Join顺序。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;数据离线存储资源节省达80%+，样本构建效率提升200%+，当前整个样本数据也正在进行基于数据湖的实践，进一步提升数据效率。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;6 数据准备&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;平台积累了大量的特征、样本和模型等有价值的内容，希望通过对这些数据资产进行复用，帮助策略人员更好的进行业务迭代，取得更好的业务收益。特征优化占了算法人员提升模型效果的所有方法中40%的时间，但传统的特征挖掘的工作方式存在着花费时间长、挖掘效率低、特征重复挖掘等问题，所以平台希望在特征维度赋能业务。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果有自动化的实验流程去验证任意特征的效果，并将最终效果指标推荐给用户，无疑会帮助策略同学节省大量的时间。当整个链路建设完成，后续只需要输入不同的特征候选集，即可输出相应效果指标。为此平台建设了特征、样本的“加”、“减”、“乘”、“除”智能机制。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;6.1 做“加法”&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;特征推荐基于模型测试的方法，将特征复用到其他业务线现有模型，构造出新的样本和模型；对比新模型和Base模型的离线效果，获取新特征的收益，自动推送给相关的业务负责人。具体特征推荐流程如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;189&quot; data-ratio=&quot;0.3482849604221636&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkgWNPV40gnLqVrxFiaHxlq6hPkVkf6Tc4zwIQ7ot4vEiaaBOnxopD1z5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1516&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;特征感知&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通过上线墙或业务间存量方式触发特征推荐，这些特征已经过一定验证，可以保证特征推荐的成功率。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;样本生产&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：样本生产时通过配置文件抽取特征，流程自动将新增特征加到配置文件中，然后进行新样本数据的生产。获取到新特征后，解析这些特征依赖的原始特征、维度、和UDF算子等，将新特征配置和依赖的原始数据融合到基线模型的原有配置文件中，构造出新的特征配置文件。自动进行新样本构建，样本构建时通过特征名称在特征仓库中抽取相关特征，并调用配置好的UDF进行特征计算，样本构建的时间段可配置。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;模型训练&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：自动对模型结构和样本格式配置进行改造，然后进行模型训练，使用TensorFlow作为模型训练框架，使用tfrecord格式作为样本输入，将新特征按照数值类和ID类分别放到A和B两个组中，ID类特征进行查表操作，然后统一追加到现有特征后面，不需要修改模型结构便可接收新的样本进行模型训练。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;自动配置新模型训练参数&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：包括训练日期、样本路径、模型超参等，划分出训练集和测试集，自动进行新模型的训练。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;模型评测&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：调用评估接口得到离线指标，对比新老模型评测结果，并预留单特征评估结果，打散某些特征后，给出单特征贡献度。将评估结果统一发送给用户。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;5&quot; data-cropselx2=&quot;395&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;162&quot; data-ratio=&quot;0.4048913043478261&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkPIhmtFFkEILq5Jp5QsmBZ1ibtVFN7aupCXVr902hMjDKjAwTn87UtIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;736&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;6.2 做“减法”&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;特征推荐在广告内部落地并取得了一定收益后，我们在特征赋能层面做一些新的探索。随着模型的不断优化，特征膨胀的速度非常快，模型服务消耗资源急剧上升，剔除冗余特征，为模型“瘦身”势在必行。因此，平台建设了一套端到端的特征筛选工具。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;81&quot; data-ratio=&quot;0.17258261933904528&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkcXsXSHeACQKondespicU1TBU3zH8D9GDUS8Z2RqYpnndlkibutprMSlg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1634&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;特征打分&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通过WOE（&lt;/span&gt;&lt;span&gt;Weight Of Evidence, 证据权重&lt;/span&gt;&lt;span&gt;）等多种评估算法给出模型的所有特征评分，打分较高特征的质量较高，评估准确率高。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;效果验证&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：训练好模型后，按打分排序，分批次对特征进行剔除。具体通过采用特征打散的方法，对比原模型和打散后模型评估结果，相差较大低于阈值后结束评估， 给出可以剔除的特征。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;端到端方案&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：用户配置好实验参数和指标阈值后，无需人为干涉，即可给出可删除的特征以及删除特征后模型的离线评估结果。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;最终，在内部模型下线40%的特征后，业务指标下降仍然控制在合理的阈值内。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;6.3 做“乘法”&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;为了得到更好的模型效果，广告内部已经开始做一些新的探索，包括大模型、实时化、特征库等。这些探索背后都有一个关键目标：需要更多、更好的数据让模型更智能、更高效。从广告现状出发，提出样本库（&lt;/span&gt;&lt;span&gt;Data Bank&lt;/span&gt;&lt;span&gt;）建设，实现把外部更多种类、更大规模的数据拿进来，应用于现有业务。具体如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;185&quot; data-ratio=&quot;0.3563968668407311&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOk5AyZyFd0R4rP2DMuVibLh5qtGibTHg5IPnSubibfou5lffG4H1UVxobBg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1532&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们建立了一套通用的样本共享平台，在这个平台上，可以借用其他业务线来产生增量样本。并且也搭建通用的Embedding共享架构，实现业务的以大带小。下面以广告业务线复用非广告样本为例，具体做法如下：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;扩样本&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：基于Flink流式处理框架，建设了高扩展样本库DataBank，业务A很方便复用业务B、业务C的曝光、点击等Label数据去做实验。尤其是为小业务线，扩充了大量的价值数据，这种做法相比离线补录Join，一致性会更强，特征平台提供了在线、离线一致性保障。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;做共享&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在样本就绪后，一个很典型的应用场景就是迁移学习。另外，也搭建Embedding共享的数据通路（&lt;/span&gt;&lt;span&gt;不强依赖“扩样本”流程&lt;/span&gt;&lt;span&gt;），所有业务线可以基于大的Embedding训练，每个业务方也可以update这个Embedding，在线通过建立Embedding版本机制，供多个业务线使用。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;举例来说，通过将非广告样本复用到广告内一个业务，使样本数量增加了几倍，结合迁移学习算法，离线AUC提升千分之四，上线后CPM提升百分之一。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;此外，我们也在建设广告样本主题库，将各业务生成的样本数据进行统一管理（&lt;/span&gt;&lt;span&gt;统一元数据&lt;/span&gt;&lt;span&gt;），面向用户透出统一样本主题分类，快速注册、查找、复用，面向底层统一存储，节约存储、计算资源，减少数据Join，提高时效性。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;6.4 做“除法”&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;通过特征“减法”可以剔除一些无正向作用的特征，但通过观察发现模型中还存在很多价值很小的特征。所以更进一步我们可以通过价值、成本两方面综合考虑，在全链路基于成本的约束下价值最大，筛选出那些投入产出比较低特征，降低资源消耗。这个在成本约束下去求解的过程定义为做“除法”，整体流程如下图所示。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;148&quot; data-ratio=&quot;0.3011904761904762&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVEIiaRzEAbjb3ZwuLTianZOkykQbq983rLVA6K0iaSSvqZePPe4SgyUgaT2xfzy4AGxDItVTocEDINg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1680&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在离线维度，我们建立了一套特征价值评估系统，给出特征的成本和价值，在线推理时可以通过特征价值信息进行流量降级、特征弹性计算等操作，做“除法”关键步骤如下：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;问题抽象&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：如果我们能得到每个特征的价值得分，又可以拿到特征的成本（&lt;/span&gt;&lt;span&gt;存储、通信、计算加工&lt;/span&gt;&lt;span&gt;），那么问题就转换成了在已知模型结构、固定资源成本下，如何让特征的价值最大化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;成本约束下的价值评估&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：基于模型的特征集，平台首先进行成本和价值的统计汇总；成本包括了离线成本和在线成本，基于训练好的评判模型，得出特征的综合排序。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;分场景建模&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：可以根据不同的资源情况，选择不同的特征集，进行建模。在有限的资源下，选择价值最大的模型在线Work。另外，可以针对比较大的特征集建模，在流量低峰启用，提升资源利用率的同时给业务带来更大收益。还有一种应用场景是流量降级，推理服务监控在线资源的消耗，一旦资源计算达到瓶颈，切换到降级模型。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;7 总结与展望&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;以上是我们在大规模深度学习工程上的反“增”实践，去助力业务降本提效。未来我们还会持续在以下方面进行探索、实践：&lt;/span&gt;&lt;/section&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;全链路GPU化&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：在推理层面，通过GPU的切换，支撑更复杂业务迭代的同时，整体成本也极大的降低，后面会在样本构建、特征服务上进行GPU化改造，并协同推进离线训练层面的升级。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;样本数据湖&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：通过数据湖的Schema Evolution、Patch Update等特性构建更大规模的样本仓库，对业务方进行低成本、高价值的数据透出。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Pipeline&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：算法全生命周期迭代过程中，很多环节的调试，链路信息都不够“串联”，以及离线、在线、效果指标的视角都比较割裂，基于全链路的标准化、可观测大势所趋，并且这是后续链路智能化弹性调配的基础。现在业界比较火的MLOps、云原生都有较多的借鉴思路。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;数据、模型智能匹配&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：上文提到在模型结构固定前提下，自动为模型加、减特征，同理在模型层面，固定一定特征输入前提下，去自动嵌入一些新的模型结构。以及在未来，我们也将基于业务领域，通过平台的特征、模型体系，自动化地完成数据、模型的匹配。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;8 本文作者&lt;/span&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;亚劼、英亮、陈龙、成杰、登峰、东奎、仝晔、思敏、乐彬等，均来自美团外卖技术团队。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;----------  END  ----------&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;招聘信息&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section data-source=&quot;bj.96weixin.com&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;美团外卖广告工程团队长期招聘后台高级工程师/技术专家，负责广告多个方向（&lt;/span&gt;&lt;span&gt;推荐/搜索/召回/预估/创新&lt;/span&gt;&lt;span&gt;）的系统研发工作，坐标北京。欢迎感兴趣的同学加入我们。可投简历至：&lt;/span&gt;&lt;span&gt;zouyajie@meituan.com&lt;/span&gt;&lt;span&gt;（&lt;/span&gt;&lt;span&gt;邮件主题请注明 — 美团外卖广告工程团队&lt;/span&gt;&lt;span&gt;）。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;也许你还想看&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;  | &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651766814&amp;amp;idx=1&amp;amp;sn=ffa130184ee8596cb7b7e3ee0a884683&amp;amp;chksm=bd1219538a659045ae5d7df2f1d70c7b9416296cde513776080dddca9cc2cc2a04750d599407&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;美团外卖广告平台化的探索与实践&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;/strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651766814&amp;amp;idx=1&amp;amp;sn=ffa130184ee8596cb7b7e3ee0a884683&amp;amp;chksm=bd1219538a659045ae5d7df2f1d70c7b9416296cde513776080dddca9cc2cc2a04750d599407&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;美团外卖广告平台化的探索与实践&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;美团外卖广告平台化的探索与实践&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;  |&lt;/strong&gt;&lt;/span&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651763222&amp;amp;idx=1&amp;amp;sn=dadbae89e463870649b74d5265bebb5a&amp;amp;chksm=bd126b5b8a65e24dda6173efb7216874dd666cf87c32b3fcf9f078af4347a62791834c4410c0&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;美团外卖广告智能算力的探索与实践&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;美团外卖广告智能算力的探索与实践&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;  |&lt;/strong&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651768124&amp;amp;idx=2&amp;amp;sn=dea973ddab0b195ba9173f5369b54265&amp;amp;chksm=bd121c718a659567c6a5b245b2fc03878df4196b59dfbda2e800ba273f10acc896290b85f8bd&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;美团外卖广告智能算力的探索与实践（二）&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;美团外卖广告智能算力的探索与实践（二）&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;阅读更多&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;---&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765958&amp;amp;idx=1&amp;amp;sn=8201546812e5a95a2bee9dffc6d12f00&amp;amp;chksm=bd12658b8a65ec9de2f5be1e96796dfb3c8f1a374d4b7bd91266072f557caf8118d4ddb72b07&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;前‍端&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;前端&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://t.1yb.co/jo7v&quot; textvalue=&quot; 安全&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;&lt;strong&gt; &lt;/strong&gt; &lt;/span&gt;&lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765981&amp;amp;idx=1&amp;amp;sn=c2dd86f15dee2cbbc89e27677d985060&amp;amp;chksm=bd1265908a65ec86d4d08f7600d1518b61c90f6453074f9b308c96861c045712280a73751c73&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;算‍法&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;算法&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765982&amp;amp;idx=1&amp;amp;sn=231b41f653ac7959f3e3b8213dcec2b0&amp;amp;chksm=bd1265938a65ec85630c546169444d56377bc2f11401d251da7ca50e5d07e353aa01580c7216&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;后‍端&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;后端&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765964&amp;amp;idx=1&amp;amp;sn=ab6d8db147234fe57f27dd46eec40fef&amp;amp;chksm=bd1265818a65ec9749246dd1a2eb3bf7798772cc4d5b4283b15eae2f80bc6db63a1471a9e61e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;数‍据&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;数据&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765965&amp;amp;idx=1&amp;amp;sn=37e0c56c8b080146ce5249243bfd84d8&amp;amp;chksm=bd1265808a65ec96d3a2b2c87c6e27c910d49cb6b149970fb2db8bf88045a0a85fed2e6a0b84&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;安‍全&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;安全&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765972&amp;amp;idx=1&amp;amp;sn=afe02ec92762c1ce18740d03324c4ac3&amp;amp;chksm=bd1265998a65ec8f10d5f58d0f3681ddfc5325137218e568e1cda3a50e427749edb5c6a7dcf5&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;And‍roid&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;Android&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765973&amp;amp;idx=1&amp;amp;sn=32a23bf1d278dda0398f993ab60a697e&amp;amp;chksm=bd1265988a65ec8e630ef4d24b4946ab6bd7e66702c1d712481cf3c471468a059c470a14c30d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;iO‍S&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;iOS&lt;/span&gt;&lt;/a&gt;&lt;span&gt; &lt;strong&gt; |&lt;/strong&gt; &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765963&amp;amp;idx=1&amp;amp;sn=a3de9ef267d07d94118c1611776a4b28&amp;amp;chksm=bd1265868a65ec906592d25ad65f2a8516338d07ec3217059e6975fc131fc0107d66a8cd2612&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;运‍维&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;运维&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;strong&gt; | &lt;/strong&gt;&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;amp;mid=2651765974&amp;amp;idx=1&amp;amp;sn=763c1e37d04acffd0142a2852ecfb000&amp;amp;chksm=bd12659b8a65ec8dfcfeb2028ef287fae7c38f134a665375ba420556ce5d2e4cf398147bd12e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;测‍试&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;测试&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MjM5NjQ5MTI5OA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsVGibnsaEib3aNlqF0tOrA2RGEmNSbia2nnohE4Tpf95UyTiaSjDVbHRfY8WNBeTuLLTaVdSckkNyEx1Q/0?wx_fmt=png&quot; data-nickname=&quot;美团技术团队&quot; data-alias=&quot;meituantech&quot; data-signature=&quot;10000+工程师，如何支撑中国领先的生活服务电子商务平台？数亿消费者、数百万商户、2000多个行业、几千亿交易额背后是哪些技术在支撑？这里是美团、大众点评、美团外卖、美团配送、美团优选等技术团队的对外窗口。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>