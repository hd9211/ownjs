<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>425113ce32ae56021f0689e7b2b1f433</guid>
<title>Spring Boot 引起的 “堆外内存泄漏”</title>
<link>https://toutiao.io/k/o802afr</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;src-views-article-detail-main-module__content--2qOBd markdown-body&quot;&gt;&lt;h1&gt;背景&lt;/h1&gt;
&lt;p&gt;组内一个项目最近一直报swap区域使用过高异常，笔者被叫去帮忙查看原因。发现配置的4G堆内内存，但是实际使用的物理内存高达7G，确实有点不正常，JVM参数配置是：&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;-XX:MetaspaceSize=&lt;span class=&quot;hljs-number&quot;&gt;256&lt;/span&gt;M -XX:MaxMetaspaceSize=&lt;span class=&quot;hljs-number&quot;&gt;256&lt;/span&gt;M -XX:+AlwaysPreTouch -XX:ReservedCodeCacheSize=&lt;span class=&quot;hljs-number&quot;&gt;128&lt;/span&gt;m -XX:InitialCodeCacheSize=&lt;span class=&quot;hljs-number&quot;&gt;128&lt;/span&gt;m, -Xss512k -Xmx4g -Xms4g,-XX:+UseG1GC -XX:G1HeapRegionSize=&lt;span class=&quot;hljs-number&quot;&gt;4&lt;/span&gt;M
&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;p&gt;但是使用的虚拟内存和物理内存使用情况如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386034&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;h1&gt;排查过程&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;步骤一：先使用java层面的工具定位是不是堆内内存、code区域或者使用unsafe.allocateMemory和DirectByteBuffer申请的堆外内存&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;笔者在项目中添加“-XX:NativeMemoryTracking=summary ”JVM参数重启项目，查看查到的内存分布如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386059&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;发现这个命令显示的committed的远内存小于物理内存。因为之前就对NativeMemoryTracking有所了解和测试，知道NativeMemoryTracking可以追踪到堆内内存、code区域、通过unsafe.allocateMemory和DirectByteBuffer申请的内存，但是追踪不到其他native code（c代码）申请的堆外内存。这一步也可以使用arthas去查看：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386084&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;为了防止误判，笔者适应了pmap查看内存分布，发现大量的64M的地址，而这些地址空间不在NativeMemoryTracking所给出的地址空间里面。基本上就断定就是这些64M的内存导致的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386087&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;步骤二：使用系统层面的工具定位堆外内存&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因为基本上确定是native code引起之后，java层面的工具基本上就失效了，只能使用系统层面的工具去查找问题。首先使用了gperftools去查看，截图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386113&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上图可以看出，使用malloc申请的的内存最高到3G之后就释放了，之后始终维持在700M-800M。第一反应就是难道native code 中没有使用malloc申请，直接使用mmap/brk申请的？（gperftools原理就使用动态链接的方式替换了操作系统默认的内存分配器（glibc））&lt;/p&gt;
&lt;p&gt;直接使用strace对mmap/brk进行追踪发现，并没有申请内存，此时陷入了比较迷茫的状态。于是想着能不能看看内存里面是啥东西，就用gdb去dump这些64M的内存下来看看，内容如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386121&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从内容上来看像解压后的jar信息。读取jar信息应该是在项目启动的时候，那么在项目启动之后使用strace作用就不是很大了，于是在项目启动的时候就使用strace，发现确实申请了很多64M内存空间，截图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386153&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;使用该mmap申请的地址空间在pmap对应如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386182&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;根据strace显示的线程Id，去jstack一下java进程，找到线程栈如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386188&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里基本上就可以看出问题来了，这里使用了Reflections进行扫包，底层使用了spring boot loader去加载了jar。因为需要解压jar肯定需要Inflater类，这个需要用到堆外内存，然后使用btrace去追踪这个方法如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386197&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在代码中找到扫包的地方，发现没有配置扫包路径，默认的是扫描所有jar，修改为扫描特定的jar路径。上线测试，内存正常，问题修复。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;步骤三：为什么堆外内存没有释放掉呢&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;到步骤二的时候，问题已经解决了，但是有几个疑问：&lt;/p&gt;
&lt;p&gt;为什么堆外内存没有释放&lt;/p&gt;
&lt;p&gt;为什么内存大小都是64M，jar大小不可能这么大，而且都是一样大&lt;/p&gt;
&lt;p&gt;为什么gperftools最终显示使用的的内存大小是700M左右，解压包真的没有使用malloc申请内存吗？&lt;/p&gt;
&lt;p&gt;直接看了一下spring boot loader那一块源码，发现spring对jdk的JarFile的进行了包装。他使用Inflater却没有手动去释放，依赖于Inflater中的finalize机制，在gc的时候释放。于是怀疑gc的时候没有调用finalize。带着这样的怀疑，我把Inflater进行包装在spring loader里面替换成我包装的Inflater，在finalize进行打点监控，发现finalize在young gc 的时候确实被调用了啊。去看了一下Inflater对应的C代码，初始化的使用了malloc 申请内存，调用end的时候调用了free去释放内存了。于是怀疑free的时候没有真正释放内存。然后想着把spring boot包装JarFile 替换成jdk 自带的 JarFile，发现替换之后内存问题解决。&lt;/p&gt;
&lt;p&gt;然后再返过来看gperftools的内存分布情况。发现使用spring loader的时候，内存使用一直在增加，突然某个点内存使用下降了好多。这个点应该就是gc引起的，内存应该释放了。但是操作系统层面没有看到内存变化，怀疑没有释放到操作系统，被内存分配器持有了。&lt;/p&gt;
&lt;p&gt;发现和不使用gperftools内存地址分布差别很明显，2.5G地址使用smaps发现他是属于native stack。物理内存地址分布如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386217&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;到此基本上可以确定是内存分配器在捣鬼，搜索了一下glibc 64M，发现从glibc 从2.11 开始对每个线程引入内存池（64位机器大小就是64M内存），原文如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386228&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;按照文中所说去修改MALLOC_ARENA_MAX环境变量，发现没什么效果，去查看tcmalloc（gperftools使用的内存分配器）也使用了内存池方式。&lt;/p&gt;
&lt;p&gt;因为glibc 内存分配器代码太多，懒得去看，为了验证就自己简单写个内存分配器。使用动态链接替换掉glibc 的内存分配器，代码如下（因为都是从main中分配内存，没有考虑线程安全，realloc，calloc代码类似没截图了）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386240&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过在自定义分配器当中埋点可以发现其实程序启动之后程序实际申请的堆外内存其实始终在700M-800M之前，tcmalloc 也有相关埋点也是在700M-800M左右。但是从操作系统角度来看进程占用的内存差别很大（这里只是监控堆外内存）。&lt;/p&gt;
&lt;p&gt;笔者做了一下测试，使用不同分配器进行不同程度的扫包，占用的内存如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386259&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;为什么自定义的malloc 申请800M，最终占用的物理内存在1.7G呢？&lt;/p&gt;
&lt;p&gt;因为自定义内存采用的是mmap分配内存，mmap分配内存的单位是page，也就是page的整数倍，笔者使用的系统pagesize=4k，也就说如果用户申请了1一个字节，也会分配一个page，存在着巨大的空间浪费，可以通过埋点查看系统申请了多少页。埋点发现最终在536k左右吧。那实际上向系统申请的内存 = 512k * 4k = 2G，为什么这个数据由大于1.7G内，因为操作系统采取的是延迟加载的方式，也就是说通过mmap向系统申请内存的时候系统仅仅返回地址并没有分配真实的物理地址，只有在使用的时候系统产生一个缺页中断然后在加载这个page到内存当中，这也是使用pmap看到的物理和虚拟内存的区别。&lt;/p&gt;
&lt;h1&gt;总结&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://a.perfma.net/img/386284&quot; alt=&quot;image.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;整个内存分配的流程如上图。在扫描包的时候，spring loader不会主动去释放堆外内存，导致在扫描过程中，堆外内存占用量一直持续飙升。当发生gc 的时候会依赖于finalize机制一并去释放了堆外内存。但是glibc为了性能考虑，并没有真正把内存归返到操作系统，而是留下来当做内存池了，导致应用层以为发生了“内存泄漏”。&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>cfa214ba1eee9daff4c3907737be8970</guid>
<title>[推荐] 有赞 TCP 网络编程最佳实践</title>
<link>https://toutiao.io/k/a7bxrhs</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section class=&quot;post-content&quot;&gt;
&lt;h1 id=&quot;&quot;&gt;概述&lt;/h1&gt;

&lt;p&gt;本文是根据有赞中间件团队多年的TCP网络编程实践经验总结而来，目的是为了避免应用因各种网络异常而出现各种非预期行为，从而造成非预期的影响，影响系统稳定性与可靠性。&lt;/p&gt;

&lt;p&gt;本文不会涉及TCP的各个基础知识点，主要是总结一些TCP网络编程实践中可能碰到的一些问题，以及相应的经过实践验证的解决方案等。虽然本文档很多细节主要是针对于Linux系统，不过，大部分建议适合于所有系统。&lt;/p&gt;

&lt;p&gt;本文共总结了&lt;strong&gt;16&lt;/strong&gt;项建议，下面逐一进行介绍。&lt;/p&gt;

&lt;h1 id=&quot;1so_reuseaddr&quot;&gt;1. 服务端监听设置SO_REUSEADDR选项&lt;/h1&gt;

&lt;p&gt;当我们重启服务端程序的时候可能会碰到“address already in use”这样的报错信息，即地址已被使用，导致程序无法快速成功重启。老的进程关闭退出了，为什么还会报地址已被使用呢？&lt;/p&gt;

&lt;p&gt;我们先来理解如下两点：  &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TCP连接主动关闭方存在持续2MSL的&lt;code&gt;TIME_WAIT&lt;/code&gt;状态；  &lt;/li&gt;
&lt;li&gt;TCP连接由是由四元组&amp;lt;本地地址，本地端口，远程地址，远程端口&amp;gt;来确定的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们先简单回顾一下TCP连接关闭过程中的&lt;code&gt;TIME_WAIT&lt;/code&gt;状态，如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/content/images/2021/05/tcp_close.png&quot; align=&quot;center&quot;/&gt;&lt;/p&gt;

&lt;p&gt;（图片来源：&lt;a href=&quot;https://en.wikipedia.org/wiki/Transmission_Control_Protocol&quot;&gt;Wikipedia&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;TIME_WAIT存在的意义主要有两点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;维护连接状态，使TCP连接能够可靠地关闭。如果连接主动关闭端发送的最后一条ACK丢失，连接被动关闭端会重传FIN报文。因此，主动关闭方必须维持连接状态，以支持收到重传的FIN后再次发送ACK。如果没有&lt;code&gt;TIME_WAIT&lt;/code&gt;，并且最后一个ACK丢失，那么此时被动关闭端还会处于&lt;code&gt;LAST_ACK&lt;/code&gt;一段时间，并等待重传；如果此时主动关闭方又立即创建新TCP连接且恰好使用了相同的四元组，连接会创建失败，会被对端重置。  &lt;/li&gt;
&lt;li&gt;等待网络中所有此连接老的重复的、走失的报文消亡，避免此类报文对新的相同四元组的TCP连接造成干扰，因为这些报文的序号可能恰好落在新连接的接收窗口内。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因为每个TCP报文最大存活时间为MSL，一个往返最大是2*MSL，所以&lt;code&gt;TIME_WAIT&lt;/code&gt;需要等待2MSL。&lt;/p&gt;

&lt;p&gt;当进程关闭时，进程会发起连接的主动关闭，连接最后会进入&lt;code&gt;TIME_WAIT&lt;/code&gt;状态。当新进程bind监听端口时，就会报错，因为有对应本地端口的连接还处于&lt;code&gt;TIME_WAIT&lt;/code&gt;状态。&lt;/p&gt;

&lt;p&gt;实际上，只有当新的TCP连接和老的TCP连接四元组完全一致，且老的迷走的报文序号落在新连接的接收窗口内时，才会造成干扰。为了使用&lt;code&gt;TIME_WAIT&lt;/code&gt;状态的端口，现在大部分系统的实现都做了相关改进与扩展：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;新连接SYN告知的初始序列号，要求一定要比&lt;code&gt;TIME_WAIT&lt;/code&gt;状态老连接的序列号大，可以一定程度保证不会与老连接的报文序列号重叠。&lt;/li&gt;
&lt;li&gt;开启TCP &lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc6191&quot;&gt;timestamps扩展选项&lt;/a&gt;后，新连接的时间戳要求一定要比&lt;code&gt;TIME_WAIT&lt;/code&gt;状态老连接的时间戳大，可以保证老连接的报文不会影响新连接。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，在开启了TCP timestamps扩展选项的情况下（&lt;code&gt;net.ipv4.tcp_timestamps = 1&lt;/code&gt;），可以放心的设置&lt;code&gt;SO_REUSEADDR&lt;/code&gt;选项，支持程序快速重启。&lt;/p&gt;

&lt;p&gt;注意不要与&lt;code&gt;net.ipv4.tcp_tw_reuse&lt;/code&gt;系统参数混淆，该参数仅在客户端调用connect创建连接时才生效，可以使用&lt;code&gt;TIME_WAIT&lt;/code&gt;状态超过1秒的端口（防止最后一个ACK丢失）；而&lt;code&gt;SO_REUSEADDR&lt;/code&gt;是在bind端口时生效，一般用于服务端监听时，可以使用本地非&lt;code&gt;LISTEN&lt;/code&gt;状态的端口（另一个端口也必须设置&lt;code&gt;SO_REUSEADDR&lt;/code&gt;），不仅仅是&lt;code&gt;TIME_WAIT&lt;/code&gt;状态端口。&lt;/p&gt;

&lt;h1 id=&quot;2&quot;&gt;2. 建立并遵守应用监听端口规范&lt;/h1&gt;

&lt;p&gt;每个应用、每个通信协议要有固定统一的监听端口，便于在公司内部形成共识，降低协作成本，提升运维效率。如对于一些网络ACL控制，规范统一的端口会给运维带来极大的便利。&lt;/p&gt;

&lt;p&gt;应用监听端口不能在&lt;code&gt;net.ipv4.ip_local_port_range&lt;/code&gt;区间内，这个区间是操作系统用于本地端口号自动分配的（bind或connect时没有指定端口号），Linux系统默认值为[32768, 60999]。现在一个应用服务器实例（无论是VM还是K8S Pod等），本地不仅仅会包含应用进程自身，还可能会包括监控采集、sidecar代理等进程。如果选了&lt;code&gt;net.ipv4.ip_local_port_range&lt;/code&gt;这个范围内的端口作为监听端口，你的应用进程启动前，对应的端口很可能已经被自动分配给其他进程的TCP连接，就会导致监听端口绑定失败，从而导致进程启动失败；当然，如果已经分配的端口设置了&lt;code&gt;SO_REUSEADDR&lt;/code&gt;也不会导致你的应用监听端口绑定失败，但这些临时端口一般都不会设置&lt;code&gt;SO_REUSEADDR&lt;/code&gt;。如果确实有需求监听&lt;code&gt;net.ipv4.ip_local_port_range&lt;/code&gt;区间内的端口（如保留三方系统的默认端口），可以设置&lt;code&gt;net.ipv4.ip_local_reserved_ports&lt;/code&gt;系统参数进行预留，预留的端口不会被自动分配出去；但这样会给运维增加系统的交付难度，所以，一般不建议这样做。&lt;/p&gt;

&lt;p&gt;有赞的&lt;code&gt;net.ipv4.ip_local_port_range&lt;/code&gt;系统值设置为[9000, 65535]，并且对所有类型的应用、通信协议监听端口都进行了统一规范，监听端口都小于9000。&lt;/p&gt;

&lt;h1 id=&quot;3&quot;&gt;3. 应用服务端口与管理端口分离&lt;/h1&gt;

&lt;p&gt;服务端口即业务请求的处理端口，管理端口为框架或应用的管理请求处理端口（如服务注册上线、下线）。以Spring Boot为例，应用端口对应&lt;code&gt;server.port&lt;/code&gt;，管理端口对应&lt;code&gt;management.port&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;应用的服务端口与管理端口分离有如下意义：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;避免业务请求与管理请求互相影响，如线程池等。&lt;/li&gt;
&lt;li&gt;更好地进行权限管理、ACL控制等。管理端口一般可以控制应用的核心行为，需要进行严格的权限管理、ACL控制，比如通过防火墙仅允许特定IP访问管理端口等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有赞线上曾经碰到过一个问题：一个Dubbo业务应用提供HTTP服务和Dubbo服务，HTTP服务端口与HTTP管理端口是同一个，该应用的一个实例因内部逻辑问题发生了死锁，造成请求阻塞超时，但这时服务注册的健康保活线程仍然正常，所以该异常服务实例还是在线的，客户端仍在发送请求到该实例。这时想将该实例进行服务注册下线操作但保留进程以便排查问题，但由于业务线程阻塞导致HTTP线程池所有线程阻塞，进而导致管理模块无线程可处理HTTP服务注册下线请求，最终无法正常下线。有赞Dubbo框架已经对应用服务端口与管理端口进行了分离，并进行了线程池隔离，避免再出现类似的问题。当然，熔断等其他机制也有助于应对个别实例异常问题，这里我们主要关注端口分离问题。&lt;/p&gt;

&lt;h1 id=&quot;4&quot;&gt;4. 建立连接设置超时时间&lt;/h1&gt;

&lt;p&gt;网络拥塞、IP不可达、握手队列满时，都可能会导致建立连接阻塞与超时，为了避免不可控的阻塞时间对应用造成难以预知的影响，建议在建立连接时设置超时时间，进行超时控制。如果没有主动进行设置，超时时间是由系统默认行为进行控制的，而系统的默认行为肯定是无法满足所有应用场景的。（注：握手队列满时，如果设置了系统参数&lt;code&gt;net.ipv4tcp_abort_on_overflow&lt;/code&gt;，连接会立刻被重置）&lt;/p&gt;

&lt;p&gt;我们看一下系统默认是如何控制连接建立超时时间的？&lt;/p&gt;

&lt;p&gt;TCP三次握手的第一个SYN报文没有收到ACK，系统会自动对SYN报文进行重试，最大重试次数由系统参数&lt;code&gt;net.ipv4.tcp_syn_retries&lt;/code&gt;控制，默认值为6。初始RTO为1s，如果一直收不到SYN ACK，依次等待1s、2s、4s、8s、16s、32s发起重传，最后一次重传等待64s后放弃，最终在127s后才会返回ETIMEOUT超时错误。&lt;/p&gt;

&lt;p&gt;建议根据整个公司的业务场景，调整&lt;code&gt;net.ipv4.tcp_syn_retries&lt;/code&gt;系统参数进行兜底。有赞将该参数设为3，即最大15s左右可返回超时错误。&lt;/p&gt;

&lt;h1 id=&quot;5&quot;&gt;5. 使用应用层心跳对连接进行健康检查&lt;/h1&gt;

&lt;p&gt;当TCP连接有异常时，我们需要尽快感知到，然后进行相应的异常处理与恢复。对于FIN或RST这种连接关闭、重置场景，应用层是可以快速感知到的。但是对于对端机器掉电、网线脱落、网络设备异常等造成的假连接，如果没有特殊措施，应用层很长时间都感知不到。&lt;/p&gt;

&lt;p&gt;提到网络异常检测，大家可能首先想到的是TCP Keepalive。系统TCP Keepalive相关的三个参数为&lt;code&gt;net.ipv4.tcp_keepalive_time&lt;/code&gt;、&lt;code&gt;net.ipv4.tcp_keepalive_intvl&lt;/code&gt;、&lt;code&gt;net.ipv4.tcp_keepalive_probes&lt;/code&gt;，默认值分别为7200s、75s、9，即如果7200s没有收到对端的数据，就开始发送TCP Keepalive报文，如果75s内，没有收到响应，会继续重试，直到重试9次都失败后，返回应用层错误信息。&lt;/p&gt;

&lt;p&gt;为什么需要实现应用层的心跳检查呢？系统的TCP Keepalive满足不了需求吗？是的，系统的TCP Keepalive只能作为一个最基本的防御方案，而满足不了高稳定性、高可靠性场景的需求。原因有如下几点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TCP Keepalive是扩展选项，不一定所有的设备都支持；&lt;/li&gt;
&lt;li&gt;TCP Keepalive报文可能被设备特意过滤或屏蔽，如运营商设备；&lt;/li&gt;
&lt;li&gt;TCP Keepalive无法检测应用层状态，如进程阻塞、死锁、TCP缓冲区满等情况；&lt;/li&gt;
&lt;li&gt;TCP Keepalive容易与TCP重传控制冲突，从而导致失效。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于TCP状态无法反应应用层状态问题，这里稍微介绍几个场景。第一个是TCP连接成功建立，不代表对端应用感知到了该连接，因为TCP三次握手是内核中完成的，虽然连接已建立完成，但对端可能根本没有Accept；因此，一些场景仅通过TCP连接能否建立成功来判断对端应用的健康状况是不准确的，这种方案仅能探测进程是否存活。另一个是，本地TCP写操作成功，但数据可能还在本地写缓冲区中、网络链路设备中、对端读缓冲区中，并不代表对端应用读取到了数据。&lt;/p&gt;

&lt;p&gt;这里重点解释一下TCP KeepAlive与TCP重传的冲突问题。Linux系统通过&lt;code&gt;net.ipv4.tcp_retries2&lt;/code&gt;参数控制TCP的超时重传次数，即影响TCP超时时间。初始RTO为&lt;code&gt;TCP_RTO_MIN&lt;/code&gt;（200ms），RTO进行指数退让，最大RTO为&lt;code&gt;TCP_RTO_MAX&lt;/code&gt;（2min），&lt;code&gt;net.ipv4.tcp_retries2&lt;/code&gt;默认为15，大概924.6s超时。详细重传次数、RTO、超时时间关系，如下表所示。&lt;/p&gt;

&lt;table border=&quot;1&quot;&gt;  
&lt;tr&gt;  
&lt;th&gt;重传次数&lt;/th&gt;  
&lt;th&gt;RTO（毫秒）&lt;/th&gt;  
&lt;th colspan=&quot;2&quot;&gt;总超时时间&lt;/th&gt;  
&lt;/tr&gt;  
&lt;tr&gt; &lt;td&gt; 1&lt;/td&gt; &lt;td&gt;   200&lt;/td&gt; &lt;td&gt;  0.2 秒&lt;/td&gt; &lt;td&gt;0.0 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 2&lt;/td&gt; &lt;td&gt;   400&lt;/td&gt; &lt;td&gt;  0.6 秒&lt;/td&gt; &lt;td&gt;0.0 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 3&lt;/td&gt; &lt;td&gt;   800&lt;/td&gt; &lt;td&gt;  1.4 秒&lt;/td&gt; &lt;td&gt;0.0 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 4&lt;/td&gt; &lt;td&gt;  1600&lt;/td&gt; &lt;td&gt;  3.0 秒&lt;/td&gt; &lt;td&gt;0.1 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 5&lt;/td&gt; &lt;td&gt;  3200&lt;/td&gt; &lt;td&gt;  6.2 秒&lt;/td&gt; &lt;td&gt;0.1 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 6&lt;/td&gt; &lt;td&gt;  6400&lt;/td&gt; &lt;td&gt; 12.6 秒&lt;/td&gt; &lt;td&gt;0.2 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 7&lt;/td&gt; &lt;td&gt; 12800&lt;/td&gt; &lt;td&gt; 25.4 秒&lt;/td&gt; &lt;td&gt;0.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 8&lt;/td&gt; &lt;td&gt; 25600&lt;/td&gt; &lt;td&gt; 51.0 秒&lt;/td&gt; &lt;td&gt;0.9 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 9&lt;/td&gt; &lt;td&gt; 51200&lt;/td&gt; &lt;td&gt;102.2 秒&lt;/td&gt; &lt;td&gt;1.7 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;10&lt;/td&gt; &lt;td&gt;102400&lt;/td&gt; &lt;td&gt;204.6 秒&lt;/td&gt; &lt;td&gt;3.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;11&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;324.6 秒&lt;/td&gt; &lt;td&gt;5.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;12&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;444.6 秒&lt;/td&gt; &lt;td&gt;7.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;13&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;564.6 秒&lt;/td&gt; &lt;td&gt;9.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;14&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;684.6 秒&lt;/td&gt; &lt;td&gt;11.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;15&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;804.6 秒&lt;/td&gt; &lt;td&gt;13.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;16&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;924.6 秒&lt;/td&gt; &lt;td&gt;15.4 分钟&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/table&gt;

&lt;p&gt;如果TCP发送缓冲区中有数据未发送成功，TCP会进行超时重传，而不会触发TCP Keepalive。也就是说，即使应用设置了很小的TCP Keepalive参数，如time=10s、interval=10s、probes=3，在&lt;code&gt;net.ipv4.tcp_retries2&lt;/code&gt;默认配置下，可能还是一直等到15min左右才能感知到网络异常。可能有的人不理解为什么Keepalive会被重传干扰，其实这里就是个优先级的问题。TCP最大重传次数的作用高于Keepalive参数的作用，未达到最大重传次数，不会向应用层报告网络错误信息。如果Keepalive不受重传影响，同样也会对关注重传的人造成干扰，比如为什么还没达到最大重传次数就放弃重传并关闭连接了？我们可以通过&lt;code&gt;netstat -ot&lt;/code&gt;或&lt;code&gt;ss -ot&lt;/code&gt;命令查看当前连接的计时器信息。&lt;/p&gt;

&lt;p&gt;建议根据实际情况调低&lt;code&gt;net.ipv4.tcp_retries2&lt;/code&gt;参数。RFC 1122建议对应的超时时间不低于100s，即至少为8，有赞系统该参数默认为10。&lt;/p&gt;

&lt;p&gt;因此，想实现一个网络健壮的应用，应用层心跳必不可少。对于&lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc7540#section-6.7&quot;&gt;HTTP2&lt;/a&gt;、&lt;a href=&quot;https://github.com/grpc/grpc/blob/master/doc/keepalive.md&quot;&gt;gRPC&lt;/a&gt;、&lt;a href=&quot;https://dubbo.apache.org/zh/docs/v2.7/dev/implementation/#%E5%8D%8F%E8%AE%AE%E5%A4%B4%E7%BA%A6%E5%AE%9A&quot;&gt;Dubbo&lt;/a&gt;等协议都支持心跳，如果是基于这些协议开发的应用，可以直接使用这些协议的特性来实现应用层心跳。&lt;/p&gt;

&lt;p&gt;实现应用层心跳需要考虑如下点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;心跳间隔不能太小也不能太大。间隔太小心可能会对轻微抖动过于敏感，造成过度反应，反而会影响稳定性，同时也有一定的性能开销；间隔太大会导致异常检测延迟比较高。可以严格地定期发送心跳，也可以一段时间内没有收到对端数据才发起心跳。建议心跳间隔为5s~20s。&lt;/li&gt;
&lt;li&gt;设置连续失败阈值，避免瞬间抖动造成误判等。建议连续失败阈值为2~5。&lt;/li&gt;
&lt;li&gt;不要使用独立的TCP连接进行心跳检查，因为不同连接的网络路径、TCP缓冲区等都不同，无法真实反映业务通信连接的真实状态。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;6&quot;&gt;6. 连接重连需要增加退让与窗口抖动&lt;/h1&gt;

&lt;p&gt;当网络异常恢复后，大量客户端可能会同时发起TCP重连及进行应用层请求，可能会造成服务端过载、网络带宽耗尽等问题，从而导致客户端连接与请求处理失败，进而客户端触发新的重试。如果没有退让与窗口抖动机制，该状况可能会一直持续下去，很难快速收敛。&lt;/p&gt;

&lt;p&gt;建议增加指数退让，如1s、2s、4s、8s...，同时必须限制最大退让时间（如64s），否则重试等待时间可能越来越大，同样导致无法快速收敛。同时，为了降低大量客户端同时建连并请求，也需要增加窗口抖动，窗口大小可以与退让等待时间保持一致，如:
nextRetryWaitTime = backOffWaitTime + rand(0.0, 1.0) * backOffWaitTime。&lt;/p&gt;

&lt;p&gt;在进行网络异常测试或演练时，需要把网络异常时间变量考虑进来，因为不同的时长，给应用带来的影响可能会完全不同。&lt;/p&gt;

&lt;h1 id=&quot;7&quot;&gt;7. 服务端需要限制最大连接数&lt;/h1&gt;

&lt;p&gt;一个服务端口，理论上能接收的最大TCP连接数是多少呢？TCP四元组中的服务端IP、服务端端口已经固定了，理论上的上限就是客户端可用IP数量*客户端可用端口数量。去除一些IP分类、端口保留等细节，理论上限就是2^32 * 2 ^16 = 2^48。&lt;/p&gt;

&lt;p&gt;当然，目前现实中肯定达不到理论上限的瓶颈。一个TCP socket所关联的主要资源有内存缓冲区、文件描述符等，因此，实际限制主要取决于系统内存大小与文件描述符数量限制。&lt;/p&gt;

&lt;p&gt;服务端限制最大连接数，主要有两个目的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;避免服务过载导致CPU、内存耗尽；&lt;/li&gt;
&lt;li&gt;避免文件描述符耗尽。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每个TCP连接的socket都占用一个FD，每个进程以及整个系统的FD数量都是有限制的。Linux系统下，通过&lt;code&gt;ulimit -n&lt;/code&gt;可以查看单个用户的进程运行打开的FD最大数量，通过&lt;code&gt;cat /proc/sys/fs/file-max&lt;/code&gt;可以查看所有进程运行打开的最大FD数量，如果不符合应用的需求，那就需要进行相应的调整。&lt;/p&gt;

&lt;p&gt;达到FD上限会有什么影响呢？首先，肯定是无法接收新TCP连接了；其次，除了TCP连接占用的FD外，你的应用肯定还有内部场景占用或需要分配新的FD，比如日志文件发生轮转创建新日志文件时，如果日志文件创建失败，对于依赖本地存储的应用（如KV、MQ等存储型应用），就导致服务不可用了。所以，要在系统限制的基础上，根据应用的特性预留一定数量的FD，而不能把所有的FD都给客户端TCP连接使用。&lt;/p&gt;

&lt;p&gt;有赞在线上压测时，一个应用就碰到过类似的一个问题。压测期间，压力比较高，导致磁盘IO压力增高，请求处理延迟增高，导致客户端超时。客户端发现超时关闭连接，创建新连接重试，但此时服务端由于IO阻塞带来的延迟并未能够及时回收连接关闭（CLOSE_WAIT）的socket以及FD，导致FD消耗越来越多，最终导致FD耗尽，新日志文件创建失败，而该应用又是存储类型应用，强依赖于日志落盘，最终导致服务不可用。&lt;/p&gt;

&lt;p&gt;除了服务端限制最大连接数外，如果应用有对应的客户端SDK，最好也在客户端SDK也做一层保护。&lt;/p&gt;

&lt;h1 id=&quot;8&quot;&gt;8. 尽量不要依赖中心化四层负载均衡器&lt;/h1&gt;

&lt;p&gt;LVS是一个经典的中心化四层负载均衡解决方案，也有各种云厂商提供的类似LVS的产品，原理大多是一致的。它们的优点这里我们就不谈了。使用该类方案可能会面临如下问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每次应用伸缩容，需要变更后端实例列表配置，运维成本高、风险高；&lt;/li&gt;
&lt;li&gt;中心化的组件可伸缩性较差，容易触达瓶颈，如网络带宽瓶颈等；&lt;/li&gt;
&lt;li&gt;中心化的组件可用性较差，一旦负载均衡器出问题，整个服务受影响；&lt;/li&gt;
&lt;li&gt;四层健康检查对后端实例异常不敏感，无法进行应用层健康检查；&lt;/li&gt;
&lt;li&gt;负载均衡器的拆分、迁移对应用影响较大，需要应用配合更新配置、发布等，使用成本较高；&lt;/li&gt;
&lt;li&gt;负载均衡器会可能丢弃一段时间内没有通信的空闲连接，给应用带来非预期的影响；&lt;/li&gt;
&lt;li&gt;客户端访问服务端需经过负载均衡器中转，可能对RT有一定影响。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;建议通过分布式的动态服务注册与发现以及客户端负载均衡来替代中心化负载均衡方案，如微服务架构中的服务注册、服务发现、负载均衡等解决方案。&lt;/p&gt;

&lt;p&gt;在不得不使用中心化负载均衡器的场景下，也需要注意以下问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;注意选择合适的负载均衡算法，避免长连接分布不均衡。比如，如果选择了轮询负载均衡算法，正常情况下各个后端实例的连接数是均衡的，但当某个实例重启后，该实例的连接断开后，客户端会发起重连，重连就大概率转移其他实例上，导致最近启动的实例连接数较少，最早启动的实例连接数较多。可以考虑最少连接数负载均衡，长连接增加TTL限制等。&lt;/li&gt;
&lt;li&gt;注意空闲超时，超时后负载均衡器可能不会给两端发送Close或Reset信号，从而导致无法通信的假连接，如果客户端与服务端双方都没有心跳、空闲超时等，假连接会一直存在，占用系统资源；应用层或TCP层的健康检查周期需要小于负载均衡器的空闲超时。&lt;/li&gt;
&lt;li&gt;注意摘除后端实例时保证平滑，如果直接移除后端实例，可能不会给两端发送Close或Reset信号，从而导致无法通信的假连接，且客户端和服务端无法及时感知到。一般先将实例权重调整为0，保证新连接不再分配到该实例，然后等待已有的连接释放，最后再完全移除后端实例。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有赞线上环境曾多次碰到过LVS引起的相关问题，也正在研发分布式的四层代理。&lt;/p&gt;

&lt;h1 id=&quot;9close_wait&quot;&gt;9. 警惕大量CLOSE_WAIT&lt;/h1&gt;

&lt;p&gt;先介绍曾经碰到的一个问题。线上环境告警提示有服务器发生较高的TCP重传，经抓包分析重传包都是FIN包，且目标IP已不存在。查看连接状态发现大量&lt;code&gt;CLOSE_WAIT&lt;/code&gt;状态连接。该问题并不是一直持续，时有时无。经过对应用日志与应用代码分析，发现某个场景应用读取到EOF时，未关闭本地socket。进一步分析，原因是客户端应用是K8S部署的，发布后，旧实例下线，作为客户端发起主动关闭连接，并且旧实例的IP很快会被回收；服务端未关闭的socket，在几分钟后GC时（Go语言应用）才会进行socket回收关闭操作，但此时，客户端IP已不存在，因此，最后一个FIN报文不断重传，一直到超过最大重传次数，从而问题恢复。等到再次有客户端应用发布时，又会出现。该问题对于没有GC机制的编程语言开发的应用，可能会造成更严重的后果，socket不断泄露，导致FD耗尽、内存耗尽等问题。&lt;/p&gt;

&lt;p&gt;因此，一定要警惕大量CLOSE_WAIT状态连接的出现，这种情况出现时，首先要排除一些相关代码。同时，开发过程中，一定要注意正确关闭socket，通过一些语言特性进行兜底处理，如Go语言的&lt;code&gt;defer&lt;/code&gt;，Java语言的&lt;code&gt;try...catch...finally&lt;/code&gt;，C++语言的&lt;code&gt;RAII&lt;/code&gt;机制等。&lt;/p&gt;

&lt;h1 id=&quot;10ttl&quot;&gt;10. 合理设置长连接TTL&lt;/h1&gt;

&lt;p&gt;长连接减少了像短连接频繁建立连接的开销，包括三次握手开销、慢启动开销等。但也有一定的弊端：长连接的持续时间过长，可能会导致一些负载均衡问题，以及其他一些长时间难以收敛的问题。比如LVS场景，随着后端应用实例的重启，对于一些负载均衡算法（如轮询），会导致最新启动的实例连接数最少，最早启动的实例连接数最多。对于一些客户端负载均衡方案，当只需要连接后端集群中的一个节点时，长连接也会出现类似的问题，比如类似Etcd watch的场景。有赞内部有很多使用Etcd的场景，早期运维每次变更Etcd集群的时候都特别谨慎，避免连接的不均衡。&lt;/p&gt;

&lt;p&gt;有赞中间件团队规定任何应用的TCP长连接TTL不能超过2小时。当然，这已经是一个很保守的时长了，建议根据应用场景，合理设置TTL。&lt;/p&gt;

&lt;h1 id=&quot;11dns&quot;&gt;11. 通过域名访问服务需定期解析DNS&lt;/h1&gt;

&lt;p&gt;DNS是一种服务发现机制，应用通过配置DNS访问其他服务，本意是为了解决其他服务实例IP变动带来的影响，但如果处理不当还是会有问题。通过域名访问其他服务时，需要定时更新域名解析，如果解析有更新，则需要重新建立连接，避免后端实例迁移（IP有变化）时导致难以收敛。千万不要只在应用启动的时候进行一次域名解析，这种情况在DNS变更后想实现快速收敛，只能重启或发布所有相关应用了。一些语言内置了DNS相关的实现，需要注意对应的一些参数以及行为是否符合预期。&lt;/p&gt;

&lt;p&gt;另外，某些应用提供了获取最新集群成员列表的接口，如Etcd、Redis，这样即使客户端启动的时候只进行一次域名解析，只要定期从服务端同步服务集群的成员列表也能支持服务端集群成员的动态变化。&lt;/p&gt;

&lt;h1 id=&quot;12&quot;&gt;12. 降低网络读写系统调用次数&lt;/h1&gt;

&lt;p&gt;当我们调用read/write系统函数从socket读写数据时，每次调用都至少进行两次用户态与内核态的上下文切换，成本比较高。针对该问题，一般有两种优化思路：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;使用读写缓冲区；读数据时，先一次性从socket读入缓冲区，然后再按需要分次从缓冲区读取；写数据时，先分次写入缓冲区，缓冲区满时或所有写操作完成时，一次性写入socket。&lt;/li&gt;
&lt;li&gt;当不方便将数据合并到连续内存时，使用readv/writev一次性读取/写入多段内存数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于批量写操作还有一个优点，就是可以避免&lt;a href=&quot;https://en.wikipedia.org/wiki/Nagle%27s_algorithm&quot;&gt;Nagle算法&lt;/a&gt;带来的延迟（一般也不建议开启Nagle算法）。假如当前写缓冲区中没有数据，我们先通过write写4个字节，这时TCP协议栈将其发送出去，然后再通过write写96个字节，这时，由于前面发送了一个报文，还没有收到ACK，并且当前可发送数据未达到MSS，Nagle算法不允许继续发送报文，必须等到前一个报文的ACK回来才能继续发送数据，大大降低了吞吐量并且提高了延迟。如果接收端开启了&lt;a href=&quot;https://en.wikipedia.org/wiki/TCP_delayed_acknowledgment&quot;&gt;延迟ACK&lt;/a&gt;，影响更大。&lt;/p&gt;

&lt;p&gt;因此，应该尽量批量读写网络数据，以提升性能。&lt;/p&gt;

&lt;h1 id=&quot;13tcp&quot;&gt;13. 谨慎设置TCP缓冲区大小&lt;/h1&gt;

&lt;p&gt;一般来说我们不需要更改TCP默认缓冲区大小，如果我们确实有需求设置，也需要谨慎考虑与评估。&lt;/p&gt;

&lt;p&gt;TCP缓冲区大小设置为多少合适呢？我们知道，TCP 的传输速度，受制于发送窗口与接收窗口大小，以及网络传输能力。其中，两个窗口由缓冲区大小决定，如果缓冲区大小与网络传输能力匹配，那么缓冲区的利用率就是最高的。&lt;/p&gt;

&lt;p&gt;带宽时延积（缩写为 BDP，&lt;a href=&quot;https://en.wikipedia.org/wiki/Bandwidth-delay_product&quot;&gt;Bandwidth-delay Product&lt;/a&gt;）是用来描述网络传输能力的。如最大带宽是 100MB/s、网络时延是 10ms 时，客户端到服务端之间的网络一共可以存放 100MB/s * 0.01s = 1MB 的字节，这个 1MB 是带宽与时延的乘积，也就是带宽时延积。这 1MB 字节存在于飞行中的 TCP 报文，它们就在网络线路、路由器等网络设备上。如果飞行报文超过了 1MB，就一定会让网络过载，最终导致丢包。&lt;/p&gt;

&lt;p&gt;由于发送缓冲区决定了发送窗口的上限，而发送窗口又决定了已发送但未确认的飞行报文的上限，因此，发送缓冲区不能超过带宽时延积，因为超出的部分没有办法用于有效的网络传输，且飞行字节大于带宽时延积还会导致丢包，从而触发网络拥塞避免；而且，缓冲区也不能小于带宽时延积，否则无法发挥出高速网络的价值。&lt;/p&gt;

&lt;p&gt;总结而言：缓冲区太小，会降低TCP吞吐量，无法高效利用网络带宽，导致通信延迟升高；缓冲区太大，会导致TCP连接内存占用高以及受限于带宽时延积的瓶颈，从而造成内存浪费。如果缓冲区过小，如2K，还可能会导致&lt;a href=&quot;https://en.wikipedia.org/wiki/TCP_congestion_control#Fast_retransmit&quot;&gt;快速重传&lt;/a&gt;无法生效，因为未确认的报文可能最多只有2个，不会出现3个重复的ACK。&lt;/p&gt;

&lt;p&gt;Linux系统是可以根据系统状态自动调节缓冲区大小的，相关参数由&lt;code&gt;net.ipv4.tcp_wmem&lt;/code&gt;和&lt;code&gt;net.ipv4.tcp_rmem&lt;/code&gt;控制，参数是一个3元组&lt;min default=&quot;&quot; max=&quot;&quot;&gt;，即最大值、初始默认值、最大值。但如果在 socket 上直接设置 SO&lt;em&gt;SNDBUF 或者 SO&lt;/em&gt;RCVBUF，这样会关闭缓冲区的系统动态调整功能，这样操作前务必要进行充分的评估。 &lt;br/&gt;
因此，除非非常明确自己的需求，以及进行充分的评估与验证，否则，不要轻易设置TCP缓冲区大小。&lt;/min&gt;&lt;/p&gt;

&lt;h1 id=&quot;14&quot;&gt;14. 网络相关参数支持灵活配置&lt;/h1&gt;

&lt;p&gt;当应用可能有多种部署环境、部署场景时，需要根据使用场景、网络环境等因素，调整合适的网络相关参数。LAN和WAN的网络状况差别很大，会涉及到诸多参数的调整。&lt;/p&gt;

&lt;p&gt;比如对于有赞的服务代理组件&lt;a href=&quot;https://tech.youzan.com/service-meshzai-you-zan-de-shi-jian-yu-fa-zhan/&quot;&gt;Tether&lt;/a&gt;，既有数据中心内的sidecar部署场景，又有跨公网的网关部署场景，这时就需要按需调整对应的参数，否则难以适应不同的网络环境。如连接超时、读写超时、健康检查超时、健康检查失败阈值等都应该支持灵活配置。&lt;/p&gt;

&lt;h1 id=&quot;15&quot;&gt;15. 合理设置连接池大小&lt;/h1&gt;

&lt;p&gt;对于不同类型的协议，连接池的设计也不同。我们将协议是否支持连接多路复用划分为两类：非多路复用协议和多路复用协议。非多路复用协议，一个连接发送请求后，必须等待响应返回后，该连接才能发送新的请求，如HTTP1.1、Redis等；多路复用协议，支持同一个连接同时发送多个请求，如HTTP2、gRPC、Dubbo等。&lt;/p&gt;

&lt;p&gt;我们先看一下非多路复用协议如何设置连接池大小。连接池涉及到的参数一般有：最小连接数、最大连接数、最大空闲时间、连接获取超时时间、连接获取超时重试次数等。应用与连接池主要交互逻辑如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/content/images/2021/05/conn_pool-1.png&quot; align=&quot;center&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我们主要讨论最小连接数和最大连接数。之所以不是固定连接数，是因为流量有高峰、有低谷；固定连接数太小，流量高峰期容易导致请求等待时间过长；固定连接数太大，流量低谷期容易造成资源浪费。因此，最小连接数对应的就是流量低谷期连接数多少为合适，最大连接数对应的就是流量高峰期连接数多少为合适，也就是连接数与流量大小是相关的。除了流量大小，还需要考虑请求RT，即每个请求占用连接的时间。所需要的连接数其实就是请求并发数，这里我们可以利用著名的利特尔法则（&lt;a href=&quot;https://en.wikipedia.org/wiki/Little%27s_law&quot;&gt;Little&#x27;s law&lt;/a&gt;）来计算，&lt;em&gt;L=λW&lt;/em&gt;，在该场景即：并发数 = 请求QPS * 请求RT。比如流量低谷期请求QPS为100，请求RT为0.05s，则并发数为5，所需连接数为5；流量高峰期请求QPS为500，请求RT为0.1s，则并发数为50，所需连接数为50。这类问题其实与&lt;a href=&quot;https://en.wikipedia.org/wiki/Queueing_theory&quot;&gt;排队论&lt;/a&gt;相关，不过我们这里不做过多讨论，如果有更复杂的需求场景，可以参考更多排队论相关资料。&lt;/p&gt;

&lt;p&gt;接下来我们继续看一下多路复用协议如何设置连接池大小。连接池涉及到的参数一般有：最小连接数、最大连接数、单连接并发请求数高水位、单连接并发请求数低水位。当单连接并发请求数高于高水位时，如果连接池未达到最大连接数，进行连接池扩容，创建连接；当单连接并发请求数低于低水位时，如果连接池未达到最小连接数，进行连接池缩容，释放连接（释放过程需要做到平滑）。由于每个请求不独占连接，请求是可以选择任意连接的，所以这里也面临负载均衡的问题，需要尽可能的确保每个连接上的处理中的请求数接近平均值。一般使用最少请求数负载均衡，但最少请求数负载均衡时间复杂度可能比较高，最简单的实现需要扫描整个连接池。我们可以使用其近似的优化实现，随机选择两个连接，选择Pending请求数少的连接；为了更加近似最少请求，可以选择3个、5个，甚至更多个连接，取其中Pending请求数最少的连接。&lt;/p&gt;

&lt;h1 id=&quot;16&quot;&gt;16. 完善网络指标监控&lt;/h1&gt;

&lt;p&gt;需要对各个关键网络指标进行监控与告警，包括但不限于：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TCP连接建立失败数&lt;/li&gt;
&lt;li&gt;TCP报文重传率&lt;/li&gt;
&lt;li&gt;TCP各个状态连接数（尤其是&lt;code&gt;ESTABLISHED&lt;/code&gt;、&lt;code&gt;TIME_WAIT&lt;/code&gt;、&lt;code&gt;CLOSE_WAIT&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;TCP主动关闭连接数&lt;/li&gt;
&lt;li&gt;TCP被动关闭连接数&lt;/li&gt;
&lt;li&gt;连接健康检查失败数&lt;/li&gt;
&lt;li&gt;系统及进程FD使用数&lt;/li&gt;
&lt;li&gt;连接池大小 &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果能尽早发现这些指标的异常，那么就可以尽快发现问题，从而降低问题影响面。&lt;/p&gt;

&lt;h1 id=&quot;&quot;&gt;总结&lt;/h1&gt;

&lt;p&gt;本文根据有赞TCP网络编程实践经验总结了&lt;strong&gt;16&lt;/strong&gt;项建议，希望能够在TCP网络编程方面帮助大家提升应用的健壮性、可靠性，减少线上问题与故障。&lt;/p&gt;

&lt;h1 id=&quot;&quot;&gt;参考资料&lt;/h1&gt;



&lt;p&gt;`&lt;/p&gt;
                    &lt;p class=&quot;break-line&quot;&gt;欢迎关注我们的公众号&lt;/p&gt;
                    &lt;img src=&quot;https://tech.youzan.com/static_image/coder_qrcode.png&quot;/&gt;
&lt;/section&gt;

&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8611c28ec86f3e7d7744721ceee9617c</guid>
<title>[推荐] Redis 存储对象信息是用 Hash 还是 String</title>
<link>https://toutiao.io/k/2rcud9q</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText&quot;&gt;&lt;p&gt;Redis 内部使用一个 RedisObject 对象来表示所有的 key 和 value，RedisObject 中的 type，则是代表一个 value 对象具体是何种数据类型，它包含字符串（String）、链表（List）、哈希结构（Hash）、集合（Set）、有序集合（Sorted set）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b188fc9df3bb28ffbbc456f00ee63233_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;671&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-b188fc9df3bb28ffbbc456f00ee63233_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;671&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-b188fc9df3bb28ffbbc456f00ee63233_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b188fc9df3bb28ffbbc456f00ee63233_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;日常工作中我们存储对象信息的时候，一般有两种做法，一种是用 Hash 存储，另一种是 String 存储。但好像并没有所谓的最佳实践，那么实际上到底用什么数据结构存储更好呢？&lt;/p&gt;&lt;p&gt;首先简单回顾下，Redis 的 Hash 和 String 结构。&lt;/p&gt;&lt;h2&gt;String&lt;/h2&gt;&lt;p&gt;String 数据结构是简单的 key-value 类型，value 其实不仅是 String，也可以是数字。Redis 中的 String 可以表示很多语义：&lt;/p&gt;&lt;p&gt;这三种类型，Redis 会根据具体的场景完成自动转换，并且根据需要选取底层的承载方式。String 在Redis 内部存储默认就是一个字符串，被 RedisObject 所引用，当遇到 incr、decr 等操作时会转成数值型进行计算，此时 RedisObject 的 encoding 字段为int。&lt;/p&gt;&lt;p&gt;在存储过程中，我们可以将用户信息使用 Json 序列化成字符串，然后将序列化后的字符串存入 Redis 进行缓存。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-27f8be534bfc97f96460328e94a72c8e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;964&quot; data-rawheight=&quot;402&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-27f8be534bfc97f96460328e94a72c8e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;964&quot; data-rawheight=&quot;402&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-27f8be534bfc97f96460328e94a72c8e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-27f8be534bfc97f96460328e94a72c8e_b.jpg&quot;/&gt;&lt;figcaption&gt;String 数据结构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;由于 Redis 的字符串是动态字符串，可以修改，内部结构类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配。如上图所示，内部为当前字符串实际分配的空间 capacity，一般高于实际字符串长度 len。&lt;/p&gt;&lt;p&gt;假设我们要存储的结构是：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;1 {
2   &quot;name&quot;: &quot;xiaowang&quot;,
3   &quot;age&quot;: &quot;35&quot;
4 }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果此时将此用户信息的 name 改为“xiaoli”，再存到 Redis 中，Redis 是不需要重新分配空间的。而且我们在读取和存储数据的时候只需要对做 Json 序列化与反序列化，比较方便。&lt;/p&gt;&lt;h2&gt;Hash&lt;/h2&gt;&lt;p&gt;Hash 在很多编程语言中都有着很广泛的应用，而在 Redis 中也是如此。在 Redis 中，Hash 常常用来缓存一些对象信息，如用户信息、商品信息、配置信息等，因此也被称为字典（dictionary），Redis 的字典使用 Hash table 作为底层实现， 一个 Hash table 里面可以有多个哈希表节点，而每个哈希表节点保存了字典中的一个键值对。实际上，Redis 数据库底层也是采用 Hash table 来存储键值对的。&lt;/p&gt;&lt;p&gt;Redis 的 Hash 相当于 Java 的 HashMap，内部结构实现与 HashMap 一致，即数组+链表结构。只是 reHash 方式不一样。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b4bc1aa71667b1b437671aad442daf0d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;370&quot; data-rawheight=&quot;244&quot; class=&quot;content_image&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;370&quot; data-rawheight=&quot;244&quot; class=&quot;content_image lazy&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b4bc1aa71667b1b437671aad442daf0d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;前面说到 String 适合存储用户信息，而 Hash 结构也可以存储用户信息，不过是对每个字段单独存储，因此可以在查询时获取部分字段的信息，节省网络流量。不过 Redis 的 Hash 的值只能是字符串，存储上面的那个例子还好，如果存储的用户信息变为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;1 {
2   &quot;name&quot;: &quot;xiaowang&quot;,
3   &quot;age&quot;: 25,
4   &quot;clothes&quot;: {
5     &quot;shirt&quot;: &quot;gray&quot;,
6     &quot;pants&quot;: &quot;read&quot;
7   }
8 }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;那么该如何存储&quot;clothes&quot;属性又变成了该用 String 还是 Hash 的问题。&lt;/p&gt;&lt;h2&gt;String 和 Hash 占用内存的比较&lt;/h2&gt;&lt;p&gt;既然两种数据结构都可以存储结构体信息。到底哪种更加合适呢？&lt;/p&gt;&lt;p&gt;首先我们用代码先插入 10000 条数据，然后用可视化工具来看看内存的占用情况。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;1  const Redis = require(&quot;ioRedis&quot;);
2  const Redis0 = new Redis({port: 6370});
3  const Redis1 = new Redis({port: 6371});
4
5
6  const user = {
7   name: &#x27;name12345&#x27;,
8   age: 16,
9   avatar: &#x27;https://dss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=256767015,24101428&amp;amp;fm=26&amp;amp;gp=0.jpg&#x27;,
10  phone: &#x27;13111111111&#x27;,
11  email: &#x27;1111111@11.email&#x27;,
12  lastLogon: &#x27;2021-04-28 10:00:00&#x27;,
13 }
14
15
16 async function main() {
17  for (let i = 0; i &amp;lt; 10000; i++) {
18     await Redis0.set(`String:user:${i}`, Json.Stringify(user));
19     await Redis1.hmset(`Hash:user:${i}`, user);
20   }
21 }
22
23 main().then(process.exit);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;先看 Redis0：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bb939848be9abcf4bd68095d4940f139_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;630&quot; data-rawheight=&quot;534&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-bb939848be9abcf4bd68095d4940f139_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;630&quot; data-rawheight=&quot;534&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-bb939848be9abcf4bd68095d4940f139_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bb939848be9abcf4bd68095d4940f139_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;再来看看 Redis1：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-32e8929036b707955e9337668c57eaf3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;652&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-32e8929036b707955e9337668c57eaf3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;652&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-32e8929036b707955e9337668c57eaf3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-32e8929036b707955e9337668c57eaf3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;可以看到还是有点差距的，但是差距并不明显。&lt;/p&gt;&lt;h2&gt;网友讨论&lt;/h2&gt;&lt;p&gt;网上的用户也有同样的疑问， 因为值的长度是不确定的，所以不知道采用 String 还是 Hash 存储更有效率。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2ec5a5fc745eecba2893edb5a6572f9d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;765&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-2ec5a5fc745eecba2893edb5a6572f9d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;765&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-2ec5a5fc745eecba2893edb5a6572f9d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2ec5a5fc745eecba2893edb5a6572f9d_b.jpg&quot;/&gt;&lt;figcaption&gt;△ 截图来源于 StackOverflow（Redis Strings vs Redis Hashes to represent Json: efficiency?）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这里我主要给大家翻译下该问题下优质的答案：&lt;/p&gt;&lt;p&gt;&lt;b&gt;适合用 String 存储的情况：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每次需要访问大量的字段&lt;/li&gt;&lt;li&gt;存储的结构具有多层嵌套的时候&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;适合用 Hash 存储的情况：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在大多数情况中只需要访问少量字段&lt;/li&gt;&lt;li&gt;自己始终知道哪些字段可用，防止使用 mget 时获取不到想要的数据&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文主要介绍了Redis 存储对象信息是用 Hash 还是 String，我的建议是大部分情况下使用 String 存储就好，毕竟在存储具有多层嵌套的对象时方便很多，占用的空间也比 Hash 小。当我们需要存储一个特别大的对象时，而且在大多数情况中只需要访问该对象少量的字段时，可以考虑使用 Hash。&lt;/p&gt;&lt;p&gt;&lt;b&gt;推荐阅读：&lt;/b&gt;&lt;/p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://link.zhihu.com/?target=https%3A//www.upyun.com/tech/article/563/%25E4%25B8%2589%25E5%2588%2586%25E9%2592%259F%25E4%25BA%2586%25E8%25A7%25A3%2520Python3%2520%25E7%259A%2584%25E5%25BC%2582%25E6%25AD%25A5%2520Web%2520%25E6%25A1%2586%25E6%259E%25B6%2520FastAPI.html&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic4.zhimg.com/v2-32db835da87060ffdd805ef17d07aec3_180x120.jpg&quot; data-image-width=&quot;957&quot; data-image-height=&quot;620&quot; class=&quot;LinkCard old LinkCard--hasImage&quot;&gt;&lt;span class=&quot;LinkCard-backdrop&quot;/&gt;&lt;span class=&quot;LinkCard-content&quot;&gt;&lt;span class=&quot;LinkCard-text&quot;&gt;&lt;span class=&quot;LinkCard-title&quot; data-text=&quot;true&quot;&gt;三分钟了解 Python3 的异步 Web 框架 FastAPI&lt;/span&gt;&lt;span class=&quot;LinkCard-meta&quot;&gt;&lt;span&gt;​&lt;svg class=&quot;Zi Zi--InsertLink&quot; fill=&quot;currentColor&quot; viewbox=&quot;0 0 24 24&quot;&gt;&lt;path d=&quot;M13.414 4.222a4.5 4.5 0 1 1 6.364 6.364l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005a2.5 2.5 0 1 0-3.536-3.536l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005zm-6.187 6.187a.5.5 0 0 1 .638-.058l.07.058.706.707a.5.5 0 0 1 .058.638l-.058.07-3.005 3.004a2.5 2.5 0 0 0 3.405 3.658l.13-.122 3.006-3.005a.5.5 0 0 1 .638-.058l.069.058.707.707a.5.5 0 0 1 .058.638l-.058.069-3.005 3.005a4.5 4.5 0 0 1-6.524-6.196l.16-.168 3.005-3.005zm8.132-3.182a.25.25 0 0 1 .353 0l1.061 1.06a.25.25 0 0 1 0 .354l-8.132 8.132a.25.25 0 0 1-.353 0l-1.061-1.06a.25.25 0 0 1 0-.354l8.132-8.132z&quot;/&gt;&lt;/svg&gt;&lt;/span&gt;www.upyun.com&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-imageCell&quot;&gt;&lt;img class=&quot;LinkCard-image LinkCard-image--horizontal&quot; alt=&quot;图标&quot; src=&quot;https://pic4.zhimg.com/v2-32db835da87060ffdd805ef17d07aec3_180x120.jpg&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://link.zhihu.com/?target=https%3A//www.upyun.com/tech/article/558/QUIC%252FHTTP3%2520%25E5%258D%258F%25E8%25AE%25AE%25E7%25AE%2580%25E6%259E%2590.html&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic1.zhimg.com/v2-7a88939758f822892186586001fb0d2c_180x120.jpg&quot; data-image-width=&quot;1080&quot; data-image-height=&quot;608&quot; class=&quot;LinkCard old LinkCard--hasImage&quot;&gt;&lt;span class=&quot;LinkCard-backdrop&quot;/&gt;&lt;span class=&quot;LinkCard-content&quot;&gt;&lt;span class=&quot;LinkCard-text&quot;&gt;&lt;span class=&quot;LinkCard-title&quot; data-text=&quot;true&quot;&gt;QUIC/HTTP3 协议简析&lt;/span&gt;&lt;span class=&quot;LinkCard-meta&quot;&gt;&lt;span&gt;​&lt;svg class=&quot;Zi Zi--InsertLink&quot; fill=&quot;currentColor&quot; viewbox=&quot;0 0 24 24&quot;&gt;&lt;path d=&quot;M13.414 4.222a4.5 4.5 0 1 1 6.364 6.364l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005a2.5 2.5 0 1 0-3.536-3.536l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005zm-6.187 6.187a.5.5 0 0 1 .638-.058l.07.058.706.707a.5.5 0 0 1 .058.638l-.058.07-3.005 3.004a2.5 2.5 0 0 0 3.405 3.658l.13-.122 3.006-3.005a.5.5 0 0 1 .638-.058l.069.058.707.707a.5.5 0 0 1 .058.638l-.058.069-3.005 3.005a4.5 4.5 0 0 1-6.524-6.196l.16-.168 3.005-3.005zm8.132-3.182a.25.25 0 0 1 .353 0l1.061 1.06a.25.25 0 0 1 0 .354l-8.132 8.132a.25.25 0 0 1-.353 0l-1.061-1.06a.25.25 0 0 1 0-.354l8.132-8.132z&quot;/&gt;&lt;/svg&gt;&lt;/span&gt;www.upyun.com&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-imageCell&quot;&gt;&lt;img class=&quot;LinkCard-image LinkCard-image--horizontal&quot; alt=&quot;图标&quot; src=&quot;https://pic1.zhimg.com/v2-7a88939758f822892186586001fb0d2c_180x120.jpg&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;p/&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>35b847572daa0a8491692d02ce6fff69</guid>
<title>[推荐] 面试题：MySQL 一棵 B+ 树能存多少条数据？</title>
<link>https://toutiao.io/k/85kvlje</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;大家好，我是Tom哥~&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;今日寄语：充满活力的新人，能让身边的人都重回初心，真是不可思议。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;my&lt;/span&gt;&lt;span&gt;sql 的InnoDB存储引擎 一棵B+树可以存放多少行数据?&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.41114982578397213&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzpVLicRx4bhoYFC2IyEJGQichDkNPaf1ubltvu1LibkZTwU9dP5pyVJejA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;574&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;（答案在文章中！！）&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;要搞清楚这个问题，首先要从InnoDB索引数据结构、数据组织方式说起。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们都知道计算机有五大组成部分：控制器，运算器，存储器，输入设备，输出设备。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;其中很重要的，也跟今天这个题目有关系的是存储器。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们知道万事万物都有自己的单元体系，若干个小单体组成一个个大的个体。就像拼乐高一样，可以自由组合。所以说，如果能熟悉最小单元，就意味着我们抓住了事物的本事，再复杂的问题也会迎刃而解。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;存储单元&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;存储器范围比较大，但是数据具体怎么存储，有自己的最小存储单元。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1、数据持久化存储磁盘里，磁盘的最小单元是扇区，&lt;/span&gt;&lt;code&gt;&lt;span&gt;一个扇区的大小是 512个字节&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2、文件系统的最小单元是块，&lt;/span&gt;&lt;code&gt;&lt;span&gt;一个块的大小是 4K&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3、InnoDB存储引擎，有自己的最小单元，称之为页，&lt;/span&gt;&lt;code&gt;&lt;span&gt;一个页的大小是16K&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;扇区、块、页这三者的存储关系？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4234375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzlYj9YicSEnH5fHR3M2vhZXRAx5ziaicicGYF8ticfyhddjfoMDSsia5F2kzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;InnoDB引擎&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果mysql部署在本地，通过命令行方式连接mysql，默认的端口 &lt;/span&gt;&lt;code&gt;&lt;span&gt;3306&lt;/span&gt;&lt;/code&gt;&lt;span&gt; ，然后输入密码即可进入&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;mysql -u root -p&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;查看InnoDB的页大小&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;show variables like &lt;span&gt;&#x27;innodb_page_size&#x27;&lt;/span&gt;;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.3391304347826087&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzEFG2ibmpdO3d6tPLUeKoXj30aAaJKib31DbJrsucRC8RGAffyxIcNO6w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;690&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;mysql数据库中，table表中的记录都是存储在页中，那么一页可以存多少行数据？假如一行数据的大小约为1K字节，那么按 &lt;/span&gt;&lt;code&gt;&lt;span&gt;16K / 1K = 16&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，可以计算出一页大约能存放16条数据。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;mysql 的最小存储单元叫做“页”，这么多的页是如何构建一个庞大的数据组织，我们又如何知道数据存储在哪一个页中？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果逐条遍历，性能肯定很差。为了提升查找速度，我们引入了&lt;/span&gt;&lt;code&gt;&lt;span&gt;B+树&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，先来看下&lt;/span&gt;&lt;code&gt;&lt;span&gt;B+树&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的存储结构&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.7431972789115646&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzQoknttTWIrdxibtddSIiaXkNRwaa7nbLNhzAZic8jOx7ExBGFkDT5hZQg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1176&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;页除了可以存放&lt;/span&gt;&lt;code&gt;&lt;span&gt;数据&lt;/span&gt;&lt;/code&gt;&lt;span&gt;（叶子节点），还可以存放&lt;/span&gt;&lt;code&gt;&lt;span&gt;健值和指针&lt;/span&gt;&lt;/code&gt;&lt;span&gt;（非叶子节点），当然他们是有序的。这样的数据组织形式，我们称为索引组织表。&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如：上图中 page number=3的页，该页存放键值和指向数据页的指针，这样的页由N个键值+指针组成&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;B+ 树是如何检索记录？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;首先找到根页，你怎么知道一张表的根页在哪呢？&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;其实每张表的根页位置在表空间文件中是固定的，即page number=3的页&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;找到根页后通过二分查找法，定位到id=5的数据应该在指针P5指向的页中&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;然后再去page number=5的页中查找，同样通过二分查询法即可找到id=5的记录&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;如何计算B+树的高度？&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在&lt;/span&gt;&lt;code&gt;&lt;span&gt;InnoDB&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 的表空间文件中，约定&lt;/span&gt;&lt;code&gt;&lt;span&gt;page number = 3&lt;/span&gt;&lt;/code&gt;&lt;span&gt;表示主键索引的根页&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;SELECT&lt;br/&gt;b.name, a.name, index_id, &lt;span&gt;type&lt;/span&gt;, a.space, a.PAGE_NO&lt;br/&gt;FROM&lt;br/&gt;information_schema.INNODB_SYS_INDEXES a,&lt;br/&gt;information_schema.INNODB_SYS_TABLES b&lt;br/&gt;WHERE&lt;br/&gt;a.table_id = b.table_id AND a.space &amp;lt;&amp;gt; 0&lt;br/&gt;and b.name like &lt;span&gt;&#x27;%sp_job_log&#x27;&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4416326530612245&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzDYSy4C3FBQGVAicTia8eWaE0ibSbmR1nR0fQrxvPzpH314j8wwD7BQzJQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1225&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;从图中可以看出，每个表的主键索引的根页的page number都是3，而其他的二级索引page number为4&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在根页偏移量为&lt;/span&gt;&lt;code&gt;&lt;span&gt;64&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的地方存放了该B+树的&lt;/span&gt;&lt;code&gt;&lt;span&gt;page level&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。主键索引B+树的根页在整个表空间文件中的第3个页开始，所以算出它在文件中的偏移量：&lt;/span&gt;&lt;code&gt;&lt;span&gt;16384*3 + 64 = 49152 + 64 =49216&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，前2个字节中。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;首先，找到MySql数据库物理文件存放位置：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;show global variables like &lt;span&gt;&quot;%datadir%&quot;&lt;/span&gt; ;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.23905723905723905&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketznDFboCv74nXKOaM99gicGfGPWOX4iaV47GdCokFqSrlUv32h8z5mS6wA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;594&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;hexdump工具，查看表空间文件指定偏移量上的数据：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;hexdump -s 49216 -n 10  sp_job_log.ibd&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.09765625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzuZepNfX9ZfrDShVg5coaEoKmmZEe5jAxad1Te2Q5y8v5IcI09mzzpw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;page_level 值是 1，那么 B+树高度为 &lt;/span&gt;&lt;code&gt;&lt;span&gt;page level + 1 = 2&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;特别说明：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;查询数据库时，不论读一行，还是读多行，都是将这些行所在的整页数据加载，然后在内存中匹配过滤出最终结果。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;表的检索速度跟树的深度有直接关系，毕竟一次页加载就是一次IO，而磁盘IO又是比较费时间。&lt;/span&gt;&lt;code&gt;&lt;span&gt;对于一张千万级条数B+树高度为3的表与几十万级B+树高度也为3的表，其实查询效率相差不大。&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;一棵树可以存放多少行数据？&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;假设B+树的深度为2&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这棵B+树的存储总记录数 = &lt;/span&gt;&lt;code&gt;&lt;span&gt;根节点指针数 * 单个叶子节点记录条数&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;那么指针数如何计算？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;假设主键ID为&lt;/span&gt;&lt;code&gt;&lt;span&gt;bigint&lt;/span&gt;&lt;/code&gt;&lt;span&gt;类型，长度为&lt;/span&gt;&lt;code&gt;&lt;span&gt;8字节&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，而指针大小在InnoDB源码中设置为&lt;/span&gt;&lt;code&gt;&lt;span&gt;6字节&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，这样一共&lt;/span&gt;&lt;code&gt;&lt;span&gt;14字节&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;那么一个页中能存放多少这样的组合，就代表有多少指针，即 &lt;/span&gt;&lt;code&gt;&lt;span&gt;16384 / 14 = 1170&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。那么可以算出一棵高度为2 的B+树，能存放 &lt;/span&gt;&lt;code&gt;&lt;span&gt;1170 * 16 = 18720&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 条这样的数据记录。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;同理：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;高度为3的B+树可以存放的行数 =  &lt;/span&gt;&lt;code&gt;&lt;span&gt;1170 * 1170 * 16 = 21902400&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;千万级的数据存储只需要约3层B+树，查询数据时，每加载一页（page）代表一次IO。所以说，根据主键id索引查询约3次IO便可以找到目标结果。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;对于一些复杂的查询，可能需要走二级索引，那么通过二级索引查找记录最多需要花费多少次IO呢？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.66640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketz38TgsCyJTkFxDq7psbdsdsbYqoL9le40CKiaeaiaObAliaFWnOaGs48aA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;首先，从二级索引B+树中，根据&lt;/span&gt;&lt;code&gt;&lt;span&gt;name&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 找到对应的主键id&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.69296875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzk8Vt860QGV3uwh5GjeEgfwmRcYFpADH8hZNwV2ic5eTutzYPGhVEttQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;然后，再根据主键id 从 聚簇索引查找到对应的记录。如上图所示，二级索引有3层，聚簇索引有3层，那么最多花费的IO次数是：3+3 = 6&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;聚簇索引默认是主键，如果表中没有定义主键，InnoDB 会选择一个唯一的非空索引代替。如果没有这样的索引，InnoDB 会隐式定义一个主键来作为聚簇索引。&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;这也是为什么InnoDB表必须有主键，并且推荐使用整型的自增主键！！！&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;InnoDB使用的是聚簇索引，将主键组织到一棵B+树中，而行数据就储存在叶子节点上&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;举例说明：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1、若使用&lt;/span&gt;&lt;code&gt;&lt;span&gt;&quot;where id = 14&quot;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;这样的条件查找记录，则按照B+树的检索算法即可查找到对应的叶节点，之后获得行数据。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2、若对Name列进行条件搜索，则需要两个步骤：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键值。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二步使用主键值在主索引B+树中再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据。（重点在于通过其他键需要建立辅助索引）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;实战演示&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;实际项目中，每个表的结构设计都不一样，占用的存储空间大小也各不相等。如何计算不同的B+树深度下，一个表可以存储的记录条数？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们以业务日志表 &lt;/span&gt;&lt;code&gt;&lt;span&gt;sp_job_log&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 为例，讲解详细的计算过程：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1、查看表的状态信息&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;show table status like &lt;span&gt;&#x27;sp_job_log&#x27;&lt;/span&gt;\G&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.54140625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzPSO6icytqwXDU2rF2yy2CJKyc3V4462NyPbvuVroIicBhoz7Bk5TILDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;图中看到&lt;/span&gt;&lt;code&gt;&lt;span&gt;sp_job_log&lt;/span&gt;&lt;/code&gt;&lt;span&gt;表的行平均大小为&lt;/span&gt;&lt;code&gt;&lt;span&gt;153&lt;/span&gt;&lt;/code&gt;&lt;span&gt;个字节&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2、查看表结构&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;desc sp_job_log;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.2640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzlKOpFialibXWIiaZOIY26AZjhr2lTWicGTfOxAdq7xeZTzCZS0ib5ZQgVicQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3、计算B+树的行数&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;单个叶子节点（页）中的记录数 = 16K / 153 = 105&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;非叶子节点能存放多少指针， 16384 / 14 = 1170&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果树的高度为3，可以存放的记录行数 =  1170 * 1170 * 105 = 143,734,500&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;最后加餐&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;普通索引和唯一索引在查询效率上有什么不同？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;唯一索引就是在普通索引上增加了约束性，也就是关键字唯一，找到了关键字就停止检索。而普通索引，可能会存在用户记录中的关键字相同的情况，根据页结构的原理，当我们读取一条记录的时候，不是单独将这条记录从磁盘中读出去，而是将这个记录所在的页全部加载到内存中进行读取。InnoDB 存储引擎的页大小为 16KB，在一个页中可能存储着上千个记录，因此在普通索引的字段上进行查找也就是在内存中多几次&lt;/span&gt;&lt;code&gt;&lt;span&gt;判断下一条记录&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的操作，对于 CPU 来说，这些操作所消耗的时间是可以忽略不计的。所以对一个索引字段进行检索，采用普通索引还是唯一索引在检索效率上基本上没有差别。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;hr/&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;关于我：前阿里架构师，出过专利，竞赛拿过奖，CSDN博客专家，负责过电商交易、社区生鲜、营销、金融等业务，多年团队管理经验，爱思考，喜欢结交朋友&lt;/span&gt;&lt;/section&gt;&lt;h1 accuse=&quot;qTitle&quot;&gt;&lt;span&gt;&lt;span&gt;「长按2秒」↓↓&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;↓ 二维码，拉你进群，一线大厂技术交流&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.2021660649819494&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3Ohm6WHibeXLL4AVYEUeBKzcTZJd7mrk9XicnYiccg6n8YjsA4ibpRk6hkog7Qqx6cJNIF1rhicl992vID1IFUKWYuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;554&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推荐阅读&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&amp;amp;mid=2247484947&amp;amp;idx=1&amp;amp;sn=5a70f88fba83b435b8144bf1ddd3cc9f&amp;amp;chksm=ceb9fab8f9ce73ae97afc43f87314dd3bb61c966b9a40c12801cddc454dcf2845bbb605694e3&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;亿级系统的Redis缓存如何设计？？？&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&amp;amp;mid=2247484957&amp;amp;idx=1&amp;amp;sn=e50e0808cb6503ca7214bdd6fee4f134&amp;amp;chksm=ceb9fab6f9ce73a0c0725e381673fc7dc50c0594fb995b5f985b263143b34371e5e2936d7be0&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;【高并发、高性能、高可用】系统设计经验&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&amp;amp;mid=2247484929&amp;amp;idx=1&amp;amp;sn=d8cb3306dea9f1b92fd30d59da3f536a&amp;amp;chksm=ceb9faaaf9ce73bca59b46021a450fdc84aa0f85d6b49ff0e5578cc3abaa1433447f7dffc5e4&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;人人都是架构师？？？谈何容易！！&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&amp;amp;mid=2247484921&amp;amp;idx=1&amp;amp;sn=b429efe7e622759fc8f3bb24c2979a90&amp;amp;chksm=ceb9f952f9ce7044b001528ce8ae0ec89ed63727764081c21a8400e9f8f685345ec9cb0a54d7&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;【万级并发】电商库存扣减如何设计？不超卖！&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>708505d3cd88587be98e4a30354d1380</guid>
<title>[推荐] 一文理解 Redis 底层数据结构</title>
<link>https://toutiao.io/k/a3gplbq</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-source-line=&quot;1&quot;&gt;Redis的5种常见数据结构：字符串(String)、列表(List)、散列(Hash)、集合(Set)、有序集合(Sorted Set)。这些都是Redis对外暴露的数据结构，本文将介绍这些数据结构的底层数据结构的实现。&lt;/p&gt;&lt;p data-source-line=&quot;3&quot;&gt;Redis底层数据结构有六种：&lt;/p&gt;&lt;ul data-source-line=&quot;4&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;简单动态字符串（SDS）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;列表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;字典&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;整数集合&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;跳跃表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;压缩列表&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;快速列表&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-source-line=&quot;12&quot;&gt;简单动态字符串（SDS）&lt;/h2&gt;&lt;p data-source-line=&quot;14&quot;&gt;SDS是&quot;simple dynamic string&quot;的缩写。Redis中所有场景中出现的字符串，基本都是由SDS来实现的。&lt;/p&gt;&lt;p data-source-line=&quot;16&quot;&gt;使用场景：&lt;/p&gt;&lt;ul data-source-line=&quot;17&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;所有非数字的key。例如：&lt;code&gt;set msg &quot;hello world&quot;&lt;/code&gt;中的key msg.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;字符串数据类型的值。例如：&lt;code&gt;set msg &quot;hello world&quot;&lt;/code&gt;中的msg的值&lt;code&gt;&quot;hello wolrd&quot;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;非字符串数据类型中的“字符串值”。例如：&lt;code&gt;RPUSH fruits &quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;&lt;/code&gt;中的&lt;code&gt;&quot;apple&quot; &quot;banana&quot; &quot;cherry&quot;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;21&quot;&gt;SDS结构图：&lt;/p&gt;&lt;p data-source-line=&quot;23&quot;&gt;&lt;img data-ratio=&quot;0.37174721189591076&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwQMQXH7jatA6qic7FxhOlD3lMxqC4iaGuE7grIlFJ6sicCCRbynhTicXRmA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;538&quot;/&gt;&lt;/p&gt;&lt;ul data-source-line=&quot;25&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;len：记录当前已使用的字节数（不包括&#x27;\0&#x27;），获取SDS长度的复杂度为O(1)（C 语言中获取字符串长度的时间复杂度为 O(N)）。此外，len值还避免了二进制安全与缓存区溢出的问题。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;alloc：记录当前字节数组总共分配的字节数量（不包括&#x27;\0&#x27;）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;flags：标记当前字节数组的属性，是sdshdr8还是sdshdr16等。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;buf：字节数组，用于保存字符串，包括结尾空白字符&#x27;\0&#x27;。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-source-line=&quot;30&quot;&gt;&lt;code&gt;&lt;span&gt;// flags&lt;span&gt;值定义&lt;/span&gt;(&lt;span&gt;为了节约头部空间，在&lt;/span&gt;Redis3.2&lt;span&gt;开始，增加&lt;/span&gt;flag&lt;span&gt;字段。&lt;/span&gt;SDS&lt;span&gt;由一种数据结构变成了&lt;/span&gt;5&lt;span&gt;种数据结构，会根据&lt;/span&gt;SDS&lt;span&gt;存储的内容长度来选择不同的结构，以达到节省内存的效果&lt;/span&gt;)&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_5  0&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_8  1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_16 2&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_32 3&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;define&lt;/span&gt; SDS_TYPE_64 4&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote data-source-line=&quot;39&quot;&gt;&lt;p&gt;注：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;二进制安全：通俗的讲，C语言中，用“\0”表示字符串的结束，如果字符串本身就有“\0”字符，字符串就会被截断，即非二进制安全；若通过某种机制，保证读写字符串时不损害其内容，这就是二进制安全。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;因为C字符串不记录自身的长度，所以strcat会假定用户在执行这个函数时，已经为dest分配足够多的内存了，可以容纳src字符串中的所有内容，而一旦这个假设不成立，就会产生缓存区溢出。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;h3 data-source-line=&quot;43&quot;&gt;频繁内存分配问题处理&lt;/h3&gt;&lt;p data-source-line=&quot;45&quot;&gt;每次增长或者缩短一个字符，程序都需要对保存这个字符串的数组进行一次内存重新分配操作。因为内存重分配涉及复杂的算法，并且可能需要执行系统调用，所以它通常是一个比较耗时的操作。&lt;/p&gt;&lt;p data-source-line=&quot;47&quot;&gt;为了避免C字符串的这种缺陷，SDS通过未使用空间解除了字符串长度和底层数组长度之间的关联。通过未使用空间，SDS实现了空间预分配和惰性空间释放两种优化策略。&lt;/p&gt;&lt;ol data-source-line=&quot;49&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;空间预分配&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;51&quot;&gt;空间预分配用于优化SDS的字符串增长操作。当SDS的API对一个SDS进行修改，并且需要对SDS进行空间扩展的时候，程序不仅会为SDS分配修改所必须要的空间，还会为SDS分配额外的未使用空间。其中，额外分配的未使用空间数量由以下公式决定：&lt;/p&gt;&lt;p data-source-line=&quot;57&quot;&gt;在扩展SDS空间之前，SDS API会先检查未使用空间是否足够，如果足够的话，API就会直接使用未使用空间，而无需执行内存重分配。通过空间预分配策略，Redis可以减少连续执行字符串增长操作所需的内存重分配次数。&lt;/p&gt;&lt;ol start=&quot;2&quot; data-source-line=&quot;59&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;惰性空间释放&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;61&quot;&gt;惰性空间释放用于优化SDS的字符串缩短操作。当SDS的API需要缩短SDS保存的字符串时，程序不会立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录下来，并等待将来使用。&lt;/p&gt;&lt;p data-source-line=&quot;63&quot;&gt;通过惰性空间释放策略，SDS避免了缩短字符串时所需的内存重分配操作，并为将来可能的增长操作提供了优化。&lt;/p&gt;&lt;p data-source-line=&quot;65&quot;&gt;与此同时，SDS也提供了响应的API可以在有需要时，真正的释放SDS里面的未使用空间，所以不用担心惰性空间释放策略会造成内存浪费。&lt;/p&gt;&lt;h2 data-source-line=&quot;67&quot;&gt;列表&lt;/h2&gt;&lt;p data-source-line=&quot;69&quot;&gt;列表在Redis中应用的非常广，列表的底层实现就是链表。此外，Redis的发布与订阅、慢查询、监视器等功能也用到了链表。&lt;/p&gt;&lt;p data-source-line=&quot;71&quot;&gt;列表特点：&lt;/p&gt;&lt;ul data-source-line=&quot;72&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;双端链表：带有指向前置节点和后置节点的指针，获取这两个节点的复杂度为O(1)。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;无环：表头节点的prev和表尾节点的next都指向NULL，对链表的访问以NULL结束。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;链表长度计数器：带有len属性，获取链表长度的复杂度为O(1)。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;多态：链表节点使用 void*指针保存节点值，可以保存不同类型的值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;77&quot;&gt;列表结构图：&lt;/p&gt;&lt;p data-source-line=&quot;79&quot;&gt;&lt;img data-ratio=&quot;0.5209471766848816&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwbJxwcmialX3lgnMv3gocSuvgic5bUDfNIpRiaicVXAEZTZ6icReicJMNBovQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;549&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;81&quot;&gt;列表的数据结构（adlist.h/listNode与adlist.h/list）：&lt;/p&gt;&lt;p data-source-line=&quot;83&quot;&gt;listNode：&lt;/p&gt;&lt;ul data-source-line=&quot;84&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;prev：前置节点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;next：后置节点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;value：节点值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;88&quot;&gt;list：&lt;/p&gt;&lt;h2 data-source-line=&quot;96&quot;&gt;字典&lt;/h2&gt;&lt;p data-source-line=&quot;98&quot;&gt;字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对的抽象数据结构。字典中的每一个键都是唯一的，可以通过键查找与之关联的值，并对其修改或删除。&lt;/p&gt;&lt;p data-source-line=&quot;100&quot;&gt;Redis的键值对存储就是用字典实现的，散列（Hash）的底层实现之一也是字典。&lt;/p&gt;&lt;p data-source-line=&quot;102&quot;&gt;字典的结构图（与JDk中的HashMap结构很相似）：&lt;/p&gt;&lt;p data-source-line=&quot;104&quot;&gt;&lt;img data-ratio=&quot;0.3811074918566775&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwc4KGUvAU6PYaLgaYHiaksQSZO0SHKErKibXVyWXHXTahl1UjGDr9W8xA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;921&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;106&quot;&gt;字典的数据结构（dict.h/dictht与dict.h/dict）：&lt;/p&gt;&lt;p data-source-line=&quot;108&quot;&gt;dict：&lt;/p&gt;&lt;ul data-source-line=&quot;109&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;type：针对不同类型的键值对，用于创建多类型的字典&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;privdata：针对不同类型的键值对，用于创建多类型的字典&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ht：两个元素的数组，包含两个dictht哈希表，一般字典只使用ht[0]哈希表，ht[1]哈希表会在对ht[0]哈希表进行rehash（重哈希）的时候使用，即当哈希表的键值对数量超过负载数量过多的时候，会将键值对迁移到ht[1]上&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;rehashidx：rehashidx也是跟rehash相关的，rehash的操作不是瞬间完成的，rehashidx记录着rehash的进度，图中没有进行rehash，它的值为-1&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;114&quot;&gt;dictht：&lt;/p&gt;&lt;p data-source-line=&quot;120&quot;&gt;dictEntry：&lt;/p&gt;&lt;ul data-source-line=&quot;121&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;key：键&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;next：下一个dictEntry节点&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;value：union类型，支持不同类型的值&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-source-line=&quot;125&quot;&gt;渐进式hash&lt;/h3&gt;&lt;p data-source-line=&quot;127&quot;&gt;字典类型容量变化过程叫做rehash。需要满足一定的条件才能触发扩容机制：&lt;/p&gt;&lt;ol data-source-line=&quot;128&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;服务器当前没有进行BGWRITEAOF或者BGSAVE命令，且当前键值对个数超过一维数组的大小，才会触发扩容。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果当前键值对个数超过一维数组大小的五倍，无论是否在进行BGWRITEAOF或者BGSAVE命令，都会强制扩容。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;如果当前键值对个数少于一维数组大小的十分之一，则触发缩容过程。缩容不会考虑当前服务器是否在进行BGWRITEAOF或者BGSAVE命令。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;132&quot;&gt;渐进式hash的过程，简单来说类似数据库的迁移，读的时候先读ht[0]，读不到读ht[1]；写的时候只写ht[1]；ht[0]数据慢慢地往ht[1]上搬。&lt;/p&gt;&lt;p data-source-line=&quot;134&quot;&gt;当ht[0]的所有键值都迁至ht[1]之后，ht[0]变为空表，释放ht[0]。并将ht[1]设置为ht[0]，并在ht[1]新创建一个空白哈希表，将rehashidx属性的值设为-1，表示rehash操作已完成。&lt;/p&gt;&lt;p data-source-line=&quot;136&quot;&gt;具体步骤如下：&lt;/p&gt;&lt;ol data-source-line=&quot;138&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;为字典的备用哈希表分配空间：如果执行的是扩展操作，那么备用哈希表的大小为第一个大于等于(已用节点个数)*2的2n（2的n次方幂） 如果执行的是收缩操作，那么备用哈希表的大小为第一个大于等于(已用节点个数)的2n&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始（为-1时表示没有进行rehash）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当一次rehash工作完成之后，程序将rehashidx属性的值+1。同时在serverCron中调用rehash相关函数，在1ms的时间内，进行rehash处理，每次仅处理少量的转移任务(100个元素)。随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;145&quot;&gt;这里比较下Redis的渐进hash与JDk中HashMap的resize过程。如果对HashMap不了解，可以查看《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247483866&amp;amp;idx=1&amp;amp;sn=9ae4f9da57a198fdfc16265657e5efde&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;详解并发下的HashMap以及JDK8的优化&lt;/a&gt;》。&lt;/p&gt;&lt;h2 data-source-line=&quot;147&quot;&gt;整数集合&lt;/h2&gt;&lt;p data-source-line=&quot;149&quot;&gt;整数集合（intset）是Redis用于保存整数值的集合抽象数据结构，可以保存类型为int16_t、int32_t、int64_t的整数值，并且保证集合中不会出现重复元素 整数集合是集合（Set）的底层实现之一，如果一个集合只包含整数值元素，且元素数量不多时，会使用整数集合作为底层实现&lt;/p&gt;&lt;p data-source-line=&quot;152&quot;&gt;整数集合的结构图：&lt;/p&gt;&lt;p data-source-line=&quot;154&quot;&gt;&lt;img data-ratio=&quot;0.2747826086956522&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwnnOYZUcLPR1lvcM8ibLVFmXVJea0x7PDUGpPIxYdv5kytO6tUkt21Gw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;575&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;156&quot;&gt;整数集合的数据结构（inset.h/inset）：&lt;/p&gt;&lt;p data-source-line=&quot;158&quot;&gt;intset：&lt;/p&gt;&lt;ul data-source-line=&quot;159&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;encoding：决定contents数组的真正类型，如INTSET_ENC_INT16、INTSET_ENC_INT32、INTSET_ENC_INT64。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;length：记录整数集合的元素数量，即contents数组长度&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;contents：整数集合的每个元素在数组中按值的大小从小到大排序，且不包含重复项。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-source-line=&quot;163&quot;&gt;整数集合的升级&lt;/h3&gt;&lt;p data-source-line=&quot;165&quot;&gt;当想要添加一个新元素到整数集合中时，并且新元素的类型比整数集合现有的所有元素的类型都要长，整数集合需要先进行升级，才能将新元素添加到整数集合里面。每次想整数集合中添加新元素都有可能会引起升级，每次升级都需要对底层数组已有的所有元素进行类型转换。&lt;/p&gt;&lt;p data-source-line=&quot;167&quot;&gt;升级添加新元素：&lt;/p&gt;&lt;p data-source-line=&quot;173&quot;&gt;整数集合的升级策略可以提升整数集合的灵活性，并尽可能的节约内存。另外，整数集合不支持降级，一旦升级，编码就会一直保持升级后的状态。&lt;/p&gt;&lt;h2 data-source-line=&quot;175&quot;&gt;跳跃表&lt;/h2&gt;&lt;p data-source-line=&quot;177&quot;&gt;一个普通的单链表查询一个元素的时间复杂度为O(N)，即便该单链表是有序的。使用跳跃表（SkipList）是来解决查找问题的，它是一种有序的数据结构，不属于平衡树结构，也不属于Hash结构，它通过在每个节点维持多个指向其他节点的指针，而达到快速访问节点的目的 跳跃表是有序集合（Sorted Set）的底层实现之一，如果有序集合包含的元素比较多，或者元素的成员是比较长的字符串时，Redis会使用跳跃表做有序集合的底层实现。&lt;/p&gt;&lt;p data-source-line=&quot;180&quot;&gt;跳跃表其实可以把它理解为多层的链表，它有如下的性质：&lt;/p&gt;&lt;p data-source-line=&quot;187&quot;&gt;有关跳跃表的讲解，可以查看《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247483893&amp;amp;idx=1&amp;amp;sn=04e19d3f3a424bd53937c4bca78f3003&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;有关跳跃表的干货都在这里&lt;/a&gt;》&lt;/p&gt;&lt;p data-source-line=&quot;189&quot;&gt;跳跃表的结构图：&lt;/p&gt;&lt;p data-source-line=&quot;191&quot;&gt;&lt;img data-ratio=&quot;0.49741468459152016&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwLlkfia9Via47JDhg1U2I0CicnvaItUfkMosCsn0JkZJ9whEvMjXscSacQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;967&quot;/&gt;&lt;/p&gt;&lt;h2 data-source-line=&quot;197&quot;&gt;压缩列表&lt;/h2&gt;&lt;p data-source-line=&quot;199&quot;&gt;压缩列表（ziplist）是为了节约内存而设计的，是由一系列特殊编码的连续内存块组成的顺序性（sequential）数据结构，一个压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者一个整数值。&lt;/p&gt;&lt;p data-source-line=&quot;201&quot;&gt;压缩列表是列表（List）和散列（Hash）的底层实现之一，一个列表只包含少量列表项，并且每个列表项是小整数值或比较短的字符串，会使用压缩列表作为底层实现（在3.2版本之后是使用quicklist实现）。&lt;/p&gt;&lt;p data-source-line=&quot;203&quot;&gt;压缩列表的结构图：&lt;/p&gt;&lt;p data-source-line=&quot;205&quot;&gt;&lt;img data-ratio=&quot;0.07936507936507936&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZw1gyTUNkEoFVgRIia2VmIH6LlsYu7Yzu3IcPQJxG5tRZgAUhPSgibfrYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;693&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;207&quot;&gt;一个压缩列表可以包含多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。&lt;/p&gt;&lt;p data-source-line=&quot;209&quot;&gt;压缩列表的数据结构：&lt;/p&gt;&lt;ul data-source-line=&quot;211&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;zlbytes：记录整个压缩列表占用的内存字节数，在压缩列表内存重分配，或者计算zlend的位置时使用。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;zltail：记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，通过该偏移量，可以不用遍历整个压缩列表就可以确定表尾节点的地址。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;zllen：记录压缩列表包含的节点数量，但该属性值小于UINT16_MAX（65535）时，该值就是压缩列表的节点数量，否则需要遍历整个压缩列表才能计算出真实的节点数量。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;entryX：压缩列表的节点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;zlend：特殊值0xFF（十进制255），用于标记压缩列表的末端。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-source-line=&quot;217&quot;&gt;压缩列表节点的构成&lt;/h3&gt;&lt;p data-source-line=&quot;219&quot;&gt;&lt;img data-ratio=&quot;0.11711711711711711&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwfnGricWnnmBUw6Lw1ricMYmXzWBiagknicIVD6EfygeNC3ib19zN9EYo5rQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;444&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;221&quot;&gt;每个压缩列表节点可以保存一个字节数字或者一个整数值。压缩列表节点的数据结构：&lt;/p&gt;&lt;ul data-source-line=&quot;222&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;previous_entry_ength：记录压缩列表前一个字节的长度。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;encoding：节点的encoding保存的是节点的content的内容类型。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;content：content区域用于保存节点的内容，节点内容类型和长度由encoding决定。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-source-line=&quot;226&quot;&gt;快速列表&lt;/h2&gt;&lt;p data-source-line=&quot;228&quot;&gt;考虑到链表的附加空间相对太高，prev和next指针就要占去16个字节（64bit系统的指针是8个字节）。另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。因此Redis3.2版本开始对列表数据结构进行了改造，使用快速列表（quicklist）代替了压缩列表和列表。&lt;/p&gt;&lt;p data-source-line=&quot;230&quot;&gt;快速列表的结构图：&lt;/p&gt;&lt;p data-source-line=&quot;232&quot;&gt;&lt;img data-ratio=&quot;0.6107470511140236&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gq4Mear6kfeD5qHWmojzZwibUXyMRzf0qFFCPM9NUtXwn45M69TWMdq15P4rcx9mKUZJdAKndU59w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;763&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;234&quot;&gt;快速列表的数据结构：&lt;/p&gt;&lt;p data-source-line=&quot;236&quot;&gt;quicklistNode：&lt;/p&gt;&lt;ul data-source-line=&quot;238&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;prev: 指向链表前一个节点的指针。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;next: 指向链表后一个节点的指针。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;zl: 数据指针。如果当前节点的数据没有压缩，那么它指向一个ziplist结构；否则，它指向一个quicklistLZF结构。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;sz: 表示zl指向的ziplist的总大小（包括zlbytes, zltail, zllen, zlend和各个数据项）。需要注意的是：如果ziplist被压缩了，那么这个sz的值仍然是压缩前的ziplist大小。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;count: 表示ziplist里面包含的数据项个数。这个字段只有16bit。稍后我们会一起计算一下这16bit是否够用。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;encoding: 表示ziplist是否压缩了（以及用了哪个压缩算法）。目前只有两种取值：2表示被压缩了（而且用的是LZF压缩算法），1表示没有压缩。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;container: 是一个预留字段。本来设计是用来表明一个quicklist节点下面是直接存数据，还是使用ziplist存数据，或者用其它的结构来存数据（用作一个数据容器，所以叫container）。但是，在目前的实现中，这个值是一个固定的值2，表示使用ziplist作为数据容器。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;recompress: 当我们使用类似lindex这样的命令查看了某一项本来压缩的数据时，需要把数据暂时解压，这时就设置recompress=1做一个标记，等有机会再把数据重新压缩。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;attempted_compress: 这个值只对Redis的自动化测试程序有用。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;extra: 其它扩展字段。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;249&quot;&gt;quickList：&lt;/p&gt;&lt;ul data-source-line=&quot;250&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;head: 指向头节点（左侧第一个节点）的指针。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;tail: 指向尾节点（右侧第一个节点）的指针。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;count: 所有ziplist数据项的个数总和。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;len: quicklist节点的个数。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;fill: 16bit，ziplist大小设置，存放list-max-ziplist-size参数的值。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;compress: 16bit，节点压缩深度设置，存放list-compress-depth参数的值。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-source-line=&quot;257&quot;&gt;压缩深度&lt;/h3&gt;&lt;p data-source-line=&quot;259&quot;&gt;quicklist默认的压缩深度是0，也就是不压缩。压缩的实际深度由配置参数&lt;code&gt;list-compress-depth&lt;/code&gt;决定。为了支持快速的push/pop操作，quicklist的首尾两个ziplist不压缩，此时深度就是1；如果深度为2，就表示quicklist的首尾第一个 ziplist以及首尾第二个ziplist都不压缩。&lt;/p&gt;&lt;h3 data-source-line=&quot;261&quot;&gt;zipList长度&lt;/h3&gt;&lt;p data-source-line=&quot;262&quot;&gt;quicklist 内部默认单个ziplist长度为8k字节，超出了这个字节数，就会新起一个ziplist。ziplist的长度由配置参数&lt;code&gt;list-max-ziplist-size&lt;/code&gt;决定。&lt;/p&gt;&lt;h2 data-source-line=&quot;264&quot;&gt;编码&lt;/h2&gt;&lt;p data-source-line=&quot;266&quot;&gt;上面介绍了Redis的主要底层数据结构，包括简单动态字符串（SDS）、链表、字典、跳跃表、整数集合、压缩列表。但是Redis并没有直接使用这些数据结构来构建数据库，而是基于这些数据结构创建不同的编码，然后由不同条件下的不同编码来实现Redis的这些数据类型：字符串(String)、列表(List)、散列(Hash)、集合(Set)、有序集合(Sorted Set)。&lt;/p&gt;&lt;p data-source-line=&quot;268&quot;&gt;接下来就介绍Redis五种数据结构对应的编码。&lt;/p&gt;&lt;h3 data-source-line=&quot;270&quot;&gt;字符串对象的编码&lt;/h3&gt;&lt;p data-source-line=&quot;272&quot;&gt;上面介绍了SDS，但这只是字符串对象的其中一种实现。字符串对象的编码可能有三种：int、raw、embstr。&lt;/p&gt;&lt;ol data-source-line=&quot;274&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;int&lt;br/&gt;如果一个字符串对象，保存的值是一个整数值，并且这个整数值在long的范围内，那么Redis用整数值来保存这个信息，并且将字符串编码设置为 int。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;raw&lt;br/&gt;如果字符串对象保存的是一个字符串, 并且长度大于32个字节，它就会使用前面讲过的SDS（简单动态字符串）数据结构来保存这个字符串值，并且将字符串对象的编码设置为raw。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;embstr&lt;br/&gt;如果字符串对象保存的是一个字符串，但是长度小于32个字节，它就会使用embstr来保存了，embstr编码不是一个数据结构，而是对SDS的一个小优化，当使用SDS 的时候，程序需要调用两次内存分配，来给字符串对象和SDS各自分配一块空间，而embstr只需要一次内存分配，因为他需要的空间很少，所以采用连续的空间保存，即将SDS的值和字符串对象的值放在一块连续的内存空间上。这样能在短字符串的时候提高一些效率。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;283&quot;&gt;浮点数如何保存：&lt;/p&gt;&lt;p data-source-line=&quot;285&quot;&gt;Redis的字符串数据类型是支持保存浮点数，并且支持对浮点数进行加减操作，但是Redis在底层是把浮点数转换成字符串值，然后按照上述编码规则。对浮点数进行操作时，也是从字符串转换成浮点数进行计算，然后再转换成字符串进行保存的。&lt;/p&gt;&lt;p data-source-line=&quot;287&quot;&gt;编码转换条件：&lt;/p&gt;&lt;p data-source-line=&quot;289&quot;&gt;如果对一个int编码的字符串对象，修改它成非整数值，则对象就会使用raw编码。而Redis没有为embstr编码提供任何的修改操作，embstr编码的值是只读的，只要发生修改，立刻将编码转换成raw。&lt;/p&gt;&lt;table data-source-line=&quot;291&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码&lt;/th&gt;&lt;th&gt;使用条件&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;int&lt;/td&gt;&lt;td&gt;可以用long保存的整数&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;raw&lt;/td&gt;&lt;td&gt;长度大于32的字符串&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;embstr&lt;/td&gt;&lt;td&gt;字符串长度小于32字节（或者浮点数转换后满足）&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;297&quot;&gt;列表对象的编码&lt;/h3&gt;&lt;p data-source-line=&quot;299&quot;&gt;在 Redis 3.2 版本之前，列表对象底层由 压缩列表和双向链表配合实现，当元素数量较少的时候，使用压缩列表，当元素数量增多，就开始使用普通的双向链表保存数据。&lt;/p&gt;&lt;p data-source-line=&quot;301&quot;&gt;但是这种实现方式不够好，双向链表中的每个节点，都需要保存前后指针，这个内存的使用量 对于Redis这个内存数据库来说极其不友好。&lt;/p&gt;&lt;p data-source-line=&quot;303&quot;&gt;因此在 3.2 之后的版本，Redis新实现了一个数据结构，叫做快速列表（quicklist）。所有列表的底层实现都是这个数据结构了。它的底层实现基本上就是将 双向链表和压缩列表进行了结合，用双向的指针将压缩列表进行连接，这样不仅避免了压缩列表存储大量元素的性能压力，同时避免了双向链表连接指针占用空间过多的问题。&lt;/p&gt;&lt;h3 data-source-line=&quot;309&quot;&gt;集合对象的编码&lt;/h3&gt;&lt;p data-source-line=&quot;311&quot;&gt;集合对象的编码可以是intset或者hashtable。&lt;/p&gt;&lt;p data-source-line=&quot;313&quot;&gt;当集合中的所有元素都是整数，且元素的数量不大于512个的时候，使用intset编码。&lt;/p&gt;&lt;p data-source-line=&quot;315&quot;&gt;当元素不符合全部为整数值且元素个数小于512时，集合对象使用的编码方式为 hashtable。&lt;/p&gt;&lt;table data-source-line=&quot;317&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码&lt;/th&gt;&lt;th&gt;使用条件&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;intset&lt;/td&gt;&lt;td&gt;所有元素都是整数且元素个数小于 512&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;hashtable&lt;/td&gt;&lt;td&gt;其他数据&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;322&quot;&gt;有序集合对象的编码&lt;/h3&gt;&lt;p data-source-line=&quot;324&quot;&gt;有序集合对象的编码可以是ziplist以及skiplist。&lt;/p&gt;&lt;p data-source-line=&quot;326&quot;&gt;当使用ziplist编码时，有序集合对象的实现数据结构为压缩列表。当条件变化，ziplist编码会转换成skiplist编码。&lt;/p&gt;&lt;p data-source-line=&quot;328&quot;&gt;当使用skiplist编码的时候，内部使用zset 来实现数据的保存，zset的定义如下：&lt;/p&gt;&lt;pre data-source-line=&quot;329&quot;&gt;&lt;code&gt;typedef struct zset{&lt;br/&gt;  zskiplist *zsl&lt;span&gt;;&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;dict &lt;/span&gt;*&lt;span&gt;dict;&lt;br/&gt;&lt;/span&gt;}zset&lt;span&gt;;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-source-line=&quot;335&quot;&gt;为什么需要同时使用跳跃表以及字典呢？&lt;/p&gt;&lt;p data-source-line=&quot;340&quot;&gt;因此，将字典和跳跃表结合进行使用，可以在O(1)的时间复杂度下完成查询分值操作，而对一些范围操作使用跳跃表可以达到O(logn)的时间复杂度。&lt;/p&gt;&lt;table data-source-line=&quot;342&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码&lt;/th&gt;&lt;th&gt;使用条件&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;ziplist&lt;/td&gt;&lt;td&gt;元素数量少于128且所有元素成员的长度小于64字节&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;skiplist&lt;/td&gt;&lt;td&gt;不满足上述条件的其他情况&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;347&quot;&gt;散列对象&lt;/h3&gt;&lt;p data-source-line=&quot;349&quot;&gt;散列对象的编码可以是ziplist或者hashtable.&lt;/p&gt;&lt;p data-source-line=&quot;351&quot;&gt;ziplist编码下的哈希对象，使用了压缩列表作为底层实现数据结构，用两个连续的压缩列表节点来表示哈希对象中的一个键值对。实现方式类似于上面的有序集合的场景。&lt;/p&gt;&lt;p data-source-line=&quot;353&quot;&gt;哈希结构本身在结构上和字典颇为相似，因此哈希对象中的每一个键值对都是字典中的一个键值对。&lt;/p&gt;&lt;table data-source-line=&quot;357&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;编码&lt;/th&gt;&lt;th&gt;使用条件&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;ziplist&lt;/td&gt;&lt;td&gt;键值对的键和值的长度都小于64字节，且键值对个数小于512&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;hastable&lt;/td&gt;&lt;td&gt;不满足上述条件的其他情况&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;362&quot;&gt;总结&lt;/h3&gt;&lt;table data-source-line=&quot;364&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;基础数据类型&lt;/th&gt;&lt;th&gt;可能的编码方式&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;字符串&lt;/td&gt;&lt;td&gt;int, raw, embstr&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;列表&lt;/td&gt;&lt;td&gt;之前是 ziplist, linkedlist。3.2开始都是quicklist&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;集合&lt;/td&gt;&lt;td&gt;intset, hashtable&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;有序集合&lt;/td&gt;&lt;td&gt;ziplist, skiplist&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;散列&lt;/td&gt;&lt;td&gt;ziplist, hashtable&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p data-source-line=&quot;374&quot;&gt;参考文档：&lt;/p&gt;&lt;ol data-source-line=&quot;376&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;《Redis设计与实现》&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://github.com/redis/redis&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;《Redis 深度历险：核心原理和应用实践》&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>