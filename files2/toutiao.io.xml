<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>2ee9f6222fa110d9e3f034bd3e6ee7c0</guid>
<title>云计算的全球变局与中国故事</title>
<link>https://toutiao.io/k/9z6dese</link>
<content:encoded>&lt;div&gt;&lt;body id=&quot;readabilityBody&quot;&gt;
&lt;p id=&quot;app&quot;/&gt;
&lt;img src=&quot;https://static001.infoq.cn/static/infoq/img/logo-121-75.yuij86g.png&quot; alt=&quot;云计算的全球变局与中国故事_云原生_刘燕_InfoQ精选文章&quot;/&gt;





    

&lt;/body&gt;
&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>eb316818b048377a71f5cf41df051011</guid>
<title>介绍一个数据血缘的项目 OpenLineage</title>
<link>https://toutiao.io/k/pb9ns85</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;h4&gt;&lt;span&gt;背景&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;“大数据”这个概念逐渐深入人心，很多公司都面临的着：&lt;/p&gt;&lt;p&gt;总的来说，就是“大数据”中的“大”不仅仅是数据量大，也指的是数据种类多、数据来源复杂，不同的数据被各式各样的人使用。如何发现数据，确定数据的来龙去脉就成了一个急迫的问题。&lt;/p&gt;&lt;p&gt;OpenLineage 应运而生。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;介绍 OpenLineage&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;OpenLineage 可以翻译成开源血缘。按照这个项目的发起者 Julien Le Dem 的说法，“数据血缘需要遵循开源社区贡献者商定的标准，以保证其各自解决方案生成的元数据的兼容性和一致性。”&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Data lineage needs to follow a standard agreed upon by contributors to the open source community to guarantee the compatibility and consistency of the metadata produced by their respective solutions.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;它回答的问题是：“谁生产数据？它是如何转变的？谁在使用它？数据血缘是 DataOps 的支柱，它提供了对组织内数据旅程中系统和数据集交互的可见性。”&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Data lineage is the backbone of DataOps, providing visibility into the interaction of systems and datasets across the journey of data within an organization.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;也给出了一个可用的数据血缘应该满足什么样的要求。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它不仅需要捕获正在生成的数据集之间的依赖关系，还需要捕获生成和转换它们的业务逻辑&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这些数据集和程序中的每一个都需要有一种统一命名的形式，以便可以轻松识别并跨不同域统一访问&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这些数据集和程序中的所有变化都需要以细粒度和自动方式进行跟踪和版本控制，以更好地了解整个生态系统随时间的演变&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;考虑到它需要支持的各种用例，描述这些数据集和程序的元数据需要灵活且可扩展&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现在的 OpenLineage 的参与者包括了下面的一些开源项目：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Airflow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Amundsen&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Datahub&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;dbt&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Egeria&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Great Expectations&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Iceberg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Marquez&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Pandas&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Parquet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Prefect&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Spark&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Superset&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;&lt;span&gt;OpenLineage 概览&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;正如上面列举的参与 OpenLineage 的项目，它们都有着独特的设计理念和实现思路，让数据发现平台去和这些计算引擎一对一对接的话，就会变成复杂的网状的的链路。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4766666666666667&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;300&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAiclJSTyNpeJk78iaJ0Rqq1dZCsGGIk8y4N8gcwlmdRK1HRaqDGW3p76Jg/640?wx_fmt=png&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;而 OpenLineage 起到了中间件的作用，负责沟通上下游。&lt;br/&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5154639175257731&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;291&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAicWqJwbOOa81hSs1JwSicX0CvFEr1XyUCgw7yyGUkdjJ8bIP5kqH6MbqA/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;&lt;p&gt;作为一个中间件，就是抛去所有花里胡哨的特性，直击本质。也就是上面提到的三个问题：&lt;/p&gt;&lt;p&gt;OpenLineage 的回答就是它的核心数据模型&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6382978723404256&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;940&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAicY1o085MZ2RofngfeQXLOicKpYXlfC6GGlsMHo5RVF5WqfjCrg30WXdQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;Run 和 Job 回答的是“它是如何转变的？”，Inputs/Outputs 回答的是“谁生产数据”/“谁在使用它”。在  OpenLineage 的核心数据模型设计中，它没有选择实现更细节，也更麻烦的列级别血缘，而是只做到了表级别的血缘。在我看来，这个选择是非常棒的，因为要选择实现列级别的血缘，每一种特定类型的 SQL 势必要绑定对应的 SQL 解释器，这就让 OpenLineage 变得复杂，就谈不上通用的标准了。&lt;/p&gt;&lt;p&gt;OpenLineage 的表达方式选择了 Json 格式，具体细节可以参考：https://github.com/OpenLineage/OpenLineage/blob/main/spec/OpenLineage.md&lt;/p&gt;&lt;pre&gt;&lt;code&gt;{&lt;br/&gt;  &lt;span&gt;&quot;eventType&quot;&lt;/span&gt;: &lt;span&gt;&quot;START&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;eventTime&quot;&lt;/span&gt;: &lt;span&gt;&quot;2020-12-09T23:37:31.081Z&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;run&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;runId&quot;&lt;/span&gt;: &lt;span&gt;&quot;3b452093-782c-4ef2-9c0c-aafe2aa6f34d&quot;&lt;/span&gt;,&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;&quot;job&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;namespace&quot;&lt;/span&gt;: &lt;span&gt;&quot;my-scheduler-namespace&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;name&quot;&lt;/span&gt;: &lt;span&gt;&quot;myjob.mytask&quot;&lt;/span&gt;,&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;&quot;inputs&quot;&lt;/span&gt;: [&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;namespace&quot;&lt;/span&gt;: &lt;span&gt;&quot;my-datasource-namespace&quot;&lt;/span&gt;,&lt;br/&gt;      &lt;span&gt;&quot;name&quot;&lt;/span&gt;: &lt;span&gt;&quot;instance.schema.table&quot;&lt;/span&gt;,&lt;br/&gt;    }&lt;br/&gt;  ],&lt;br/&gt;  &lt;span&gt;&quot;outputs&quot;&lt;/span&gt;: [&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;namespace&quot;&lt;/span&gt;: &lt;span&gt;&quot;my-datasource-namespace&quot;&lt;/span&gt;,&lt;br/&gt;      &lt;span&gt;&quot;name&quot;&lt;/span&gt;: &lt;span&gt;&quot;instance.schema.output_table&quot;&lt;/span&gt;,&lt;br/&gt;    }&lt;br/&gt;  ],&lt;br/&gt;  &lt;span&gt;&quot;producer&quot;&lt;/span&gt;: &lt;span&gt;&quot;https://github.com/OpenLineage/OpenLineage/blob/v1-0-0/client&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;schemaURL&quot;&lt;/span&gt;: &lt;span&gt;&quot;https://openlineage.io/spec/1-0-0/OpenLineage.json#/definitions/RunEvent&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;&lt;span&gt;介绍 Marquez&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;空有标准，没有实现是没有意义的，OpenLineage 官方推荐的实现是 Marquez。它和 Databub、Amundsen 类似，长得像下面这样。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6084745762711864&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1180&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAicsD7iaO8eAF0dVN3QQmQQqD6icezS7kWUc6EzkbPE3t5UCLL21zNJqJFA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.53&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1800&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAicXicmVfHs4icSrsu3eAjQeCsOcY4EuEhFiaMp0JwcDUoLGRpuIONzPBYjg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;OpenLineage 是一个有野心的项目，它想和 HDFS 变成了分布式文件系统通用标准一样，变成数据血缘的通用标准。但是 OpenLineage 从 2020 年发布到现在，Databub、Amundsen 并没有受到 OpenLineage 的影响，依旧在按照项目自身的发展路径前进。&lt;/p&gt;&lt;p&gt;从个人实践来看，我很喜欢这个项目。国内很多谈数据治理的文章，都是在讲规章制度和规范这些，至于具体的落实，基本上很少会涉及，特别是像把数据血缘做成标准，可以让各种各样的数据计算引擎以同一套标准接入，就几乎上没有了。毕竟光讲理念、规章和制度，不去谈实现，略有“好高骛远”的嫌疑。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;参考链接&lt;/span&gt;&lt;/h4&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://datakin.com/introducing-openlineage/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://github.com/OpenLineage/OpenLineage&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://openlineage.io/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>13ede43ae9c37c8861721c3cd09ac68e</guid>
<title>更准更快的YOLOv6来了，美团出品并开源</title>
<link>https://toutiao.io/k/jylzk4r</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;section data-mpa-powered-by=&quot;yiban.io&quot; data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; data-style=&quot;white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__0&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; data-style=&quot;margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__1&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;NaN&quot;&gt;&lt;span mp-original-font-size=&quot;15&quot; mp-original-line-height=&quot;NaN&quot;&gt;机器之心发布&lt;/span&gt;&lt;/section&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;51&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;51&quot;&gt;&lt;strong mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;51&quot;&gt;机器之心编辑部&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;blockquote data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;12&quot; data-source-title=&quot;&quot; mp-original-font-size=&quot;15&quot; mp-original-line-height=&quot;24&quot;&gt;&lt;section mp-original-font-size=&quot;15&quot; mp-original-line-height=&quot;24&quot;&gt;&lt;section mp-original-font-size=&quot;15&quot; mp-original-line-height=&quot;24&quot;&gt;&lt;p mp-original-font-size=&quot;15&quot; mp-original-line-height=&quot;24&quot;&gt;&lt;span&gt;YOLOv6的精度与速度都远超 YOLOv5 和 YOLOX。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;YOLOv6 是美团视觉智能部研发的一款目标检测框架，致力于工业应用。本框架同时专注于检测的精度和推理效率，在工业界常用的尺寸模型中：YOLOv6-nano 在 COCO 上精度可达 35.0% AP，在 T4 上推理速度可达 1242 FPS；YOLOv6-s 在 COCO 上精度可达 43.1% AP，在 T4 上推理速度可达 520 FPS。在部署方面，YOLOv6 支持 GPU（TensorRT）、CPU（OPENVINO）、ARM（MNN、TNN、NCNN）等不同平台的部署，极大地简化工程部署时的适配工作。目前，项目已开源至 Github，欢迎有需要的小伙伴们 Star 收藏，随时取用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.39985538684020244&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9L53gxmhfMqgm8b0BYGfqSyDu3qYd8Iia0nWBr12ZdY743k8Qg6fPajquvtJ391le9RnQiaBHkfrcg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;2766&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;项目地址：https://github.com/meituan/YOLOv6&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;精度与速度远超 YOLOv5 和 YOLOX 的新框架&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;目标检测作为计算机视觉领域的一项基础性技术，在工业界得到了广泛的应用，其中 YOLO 系列算法因其较好的综合性能，逐渐成为大多数工业应用时的首选框架。至今，业界已衍生出许多 YOLO 检测框架，其中以 YOLOv5[1]、YOLOX[2] 和 PP-YOLOE[3] 最具代表性，但在实际使用中，我们发现上述框架在速度和精度方面仍有很大的提升的空间。基于此，我们通过研究并借鉴了业界已有的先进技术，开发了一套新的目标检测框架——YOLOv6。该框架支持模型训练、推理及多平台部署等全链条的工业应用需求，并在网络结构、训练策略等算法层面进行了多项改进和优化，在 COCO 数据集上，YOLOv6 在精度和速度方面均超越其他同体量算法，相关结果如下图 1 所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7212962962962963&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9L53gxmhfMqgm8b0BYGfqSrbaYJibdMVhGXQL2dSXBFE52fJW6jKWCk84Y2pR39xouuTKQJxAEWgQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1-1 YOLOv6 各尺寸模型与其他模型性能对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7212962962962963&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9L53gxmhfMqgm8b0BYGfqSUvFibHM6S6FQiciaXI4Nibdwnj8tyFpbxkH7tJRauWEgQelDB5Z3UOGNCg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 1-2 YOLOv6 与其他模型在不同分辨率下性能对比&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图 1-1 展示了不同尺寸网络下各检测算法的性能对比，曲线上的点分别表示该检测算法在不同尺寸网络下（s/tiny/nano）的模型性能，从图中可以看到，YOLOv6 在精度和速度方面均超越其他 YOLO 系列同体量算法。图 1-2 展示了输入分辨率变化时各检测网络模型的性能对比，曲线上的点从左往右分别表示图像分辨率依次增大时（384/448/512/576/640）该模型的性能，从图中可以看到，YOLOv6 在不同分辨率下，仍然保持较大的性能优势。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;YOLOv6 关键技术介绍&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;YOLOv6 主要在 Backbone、Neck、Head 以及训练策略等方面进行了诸多的改进：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;我们统一设计了更高效的 Backbone 和 Neck ：受到硬件感知神经网络设计思想的启发，基于 RepVGG style[4] 设计了可重参数化、更高效的骨干网络 EfficientRep Backbone 和 Rep-PAN Neck。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;优化设计了更简洁有效的 Efficient Decoupled Head，在维持精度的同时，进一步降低了一般解耦头带来的额外延时开销。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在训练策略上，我们采用 Anchor-free 无锚范式，同时辅以 SimOTA[2] 标签分配策略以及 SIoU[9] 边界框回归损失来进一步提高检测精度。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2.1 Hardware-friendly 的骨干网络设计&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;YOLOv5/YOLOX 使用的 Backbone 和 Neck 都基于 CSPNet[5] 搭建，采用了多分支的方式和残差结构。对于 GPU 等硬件来说，这种结构会一定程度上增加延时，同时减小内存带宽利用率。下图 2 为计算机体系结构领域中的 Roofline Model[8] 介绍图，显示了硬件中计算能力和内存带宽之间的关联关系。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.8175925925925925&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9L53gxmhfMqgm8b0BYGfqSOLmSyUHpeAo6LedTuQXhDL0vhqiaqQrsGN8UkQSPPXRnkhicfmjfbdibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 2 Roofline Model 介绍图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;于是，我们基于硬件感知神经网络设计的思想，对 Backbone 和 Neck 进行了重新设计和优化。该思想基于硬件的特性、推理框架 / 编译框架的特点，以硬件和编译友好的结构作为设计原则，在网络构建时，综合考虑硬件计算能力、内存带宽、编译优化特性、网络表征能力等，进而获得又快又好的网络结构。对上述重新设计的两个检测部件，我们在 YOLOv6 中分别称为 EfficientRep Backbone 和 Rep-PAN Neck，其主要贡献点在于：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1. 引入了 RepVGG[4] style 结构。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2. 基于硬件感知思想重新设计了 Backbone 和 Neck。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;RepVGG[4] Style 结构是一种在训练时具有多分支拓扑，而在实际部署时可以等效融合为单个 3x3 卷积的一种可重参数化的结构（融合过程如下图 3 所示）。通过融合成的 3x3 卷积结构，可以有效利用计算密集型硬件计算能力（比如 GPU），同时也可获得 GPU/CPU 上已经高度优化的 NVIDIA cuDNN 和 Intel MKL 编译框架的帮助。实验表明，通过上述策略，YOLOv6 减少了在硬件上的延时，并显著提升了算法的精度，让检测网络更快更强。以 nano 尺寸模型为例，对比 YOLOv5-nano 采用的网络结构，本方法在速度上提升了 21%，同时精度提升 3.6% AP。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.9192229038854806&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9L53gxmhfMqgm8b0BYGfqSlz2ia6X8AdBWm4wljwGz82zlzaRUVoOKFDCENg6h6GPAW1GyWpCBSMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;978&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 3 Rep 算子的融合过程 [4]&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;EfficientRep Backbone：在 Backbone 设计方面，我们基于以上 Rep 算子设计了一个高效的 Backbone。相比于 YOLOv5 采用的 CSP-Backbone，该 Backbone 能够高效利用硬件（如 GPU）算力的同时，还具有较强的表征能力。下图 4 为 EfficientRep Backbone 具体设计结构图，我们将 Backbone 中 stride=2 的普通 Conv 层替换成了 stride=2 的 RepConv 层。同时，将原始的 CSP-Block 都重新设计为 RepBlock，其中 RepBlock 的第一个 RepConv 会做 channel 维度的变换和对齐。另外，我们还将原始的 SPPF 优化设计为更加高效的 SimSPPF。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.8979591836734694&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9L53gxmhfMqgm8b0BYGfqSzrgD90JCSBGn1RKFYl3SN8XMwib8bMlID1JGbc0IFiaY5zLypxcuULSw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;784&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 4 EfficientRep Backbone 结构图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Rep-PAN：在 Neck 设计方面，为了让其在硬件上推理更加高效，以达到更好的精度与速度的平衡，我们基于硬件感知神经网络设计思想，为 YOLOv6 设计了一个更有效的特征融合网络结构。Rep-PAN 基于 PAN[6] 拓扑方式，用 RepBlock 替换了 YOLOv5 中使用的 CSP-Block，同时对整体 Neck 中的算子进行了调整，目的是在硬件上达到高效推理的同时，保持较好的多尺度特征融合能力（Rep-PAN 结构图如下图 5 所示）。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6638888888888889&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9L53gxmhfMqgm8b0BYGfqSiaXJIaRGxge7BET2JicGubg9OUK1q5w3pQNtSurLWDknbT1zo4mwNSjA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 5 Rep-PAN 结构图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2.2 更简洁高效的 Decoupled Head&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在 YOLOv6 中，我们采用了解耦检测头（Decoupled Head）结构，并对其进行了精简设计。原始 YOLOv5 的检测头是通过分类和回归分支融合共享的方式来实现的，而 YOLOX 的检测头则是将分类和回归分支进行解耦，同时新增了两个额外的 3x3 的卷积层，虽然提升了检测精度，但一定程度上增加了网络延时。因此，我们对解耦头进行了精简设计，同时综合考虑到相关算子表征能力和硬件上计算开销这两者的平衡，采用 Hybrid Channels 策略重新设计了一个更高效的解耦头结构，在维持精度的同时降低了延时，缓解了解耦头中 3x3 卷积带来的额外延时开销。通过在 nano 尺寸模型上进行消融实验，对比相同通道数的解耦头结构，精度提升 0.2% AP 的同时，速度提升 6.8%。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.700925925925926&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9L53gxmhfMqgm8b0BYGfqSVCVkibwCicLWqPOUvtoMqIgsjodhDge2H8PWpY4MdZeXNFkLTzbsaFsQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;图 6 Efficient Decoupled Head 结构图&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2.3 更有效的训练策略&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了进一步提升检测精度，我们吸收借鉴了学术界和业界其他检测框架的先进研究进展：Anchor-free 无锚范式 、SimOTA 标签分配策略以及 SIoU 边界框回归损失。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;YOLOv6 采用了更简洁的 Anchor-free 检测方法。由于 Anchor-based 检测器需要在训练之前进行聚类分析以确定最佳 Anchor 集合，这会一定程度提高检测器的复杂度；同时，在一些边缘端的应用中，需要在硬件之间搬运大量检测结果的步骤，也会带来额外的延时。而 Anchor-free 无锚范式因其泛化能力强，解码逻辑更简单，在近几年中应用比较广泛。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;经过对 Anchor-free 的实验调研，我们发现，相较于 Anchor-based 检测器的复杂度而带来的额外延时，Anchor-free 检测器在速度上有 51% 的提升。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了获得更多高质量的正样本，YOLOv6 引入了 SimOTA [4] 算法动态分配正样本，进一步提高检测精度。YOLOv5 的标签分配策略是基于 Shape 匹配，并通过跨网格匹配策略增加正样本数量，从而使得网络快速收敛，但是该方法属于静态分配方法，并不会随着网络训练的过程而调整。近年来，也出现不少基于动态标签分配的方法，此类方法会根据训练过程中的网络输出来分配正样本，从而可以产生更多高质量的正样本，继而又促进网络的正向优化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;例如，OTA[7] 通过将样本匹配建模成最佳传输问题，求得全局信息下的最佳样本匹配策略以提升精度，但 OTA 由于使用了 Sinkhorn-Knopp 算法导致训练时间加长，而 SimOTA[4] 算法使用 Top-K 近似策略来得到样本最佳匹配，大大加快了训练速度。故 YOLOv6 采用了 SimOTA 动态分配策略，并结合无锚范式，在 nano 尺寸模型上平均检测精度提升 1.3% AP。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了进一步提升回归精度，YOLOv6 采用了 SIoU[9] 边界框回归损失函数来监督网络的学习。目标检测网络的训练一般需要至少定义两个损失函数：分类损失和边界框回归损失，而损失函数的定义往往对检测精度以及训练速度产生较大的影响。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;近年来，常用的边界框回归损失包括 IoU、GIoU、CIoU、DIoU loss 等等，这些损失函数通过考虑预测框与目标框之前的重叠程度、中心点距离、纵横比等因素来衡量两者之间的差距，从而指导网络最小化损失以提升回归精度，但是这些方法都没有考虑到预测框与目标框之间方向的匹配性。SIoU 损失函数通过引入了所需回归之间的向量角度，重新定义了距离损失，有效降低了回归的自由度，加快网络收敛，进一步提升了回归精度。通过在 YOLOv6s 上采用 SIoU loss 进行实验，对比 CIoU loss，平均检测精度提升 0.3% AP。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;实验结果&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;经过以上优化策略和改进，YOLOv6 在多个不同尺寸下的模型均取得了卓越的表现。下表 1 展示了 YOLOv6-nano 的消融实验结果，从实验结果可以看出，我们自主设计的检测网络在精度和速度上都带来了很大的增益。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.33796296296296297&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9L53gxmhfMqgm8b0BYGfqSXVgNllO7Zww8EXHjBJHWQoUHm2g6wNcQcPvYRxS59N9CmBeiaOqa5Sg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 1 YOLOv6-nano 消融实验结果&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下表 2 展示了 YOLOv6 与当前主流的其他 YOLO 系列算法相比较的实验结果。从表格中可以看到：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5425925925925926&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9L53gxmhfMqgm8b0BYGfqSyr6mbgxOCSGaF8xkc9000SOPOBR6SWib4l62to7icEzB3d8wo10evuLw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;表 2 YOLOv6 各尺寸模型性能与其他模型的比较&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;YOLOv6-nano 在 COCO val 上 取得了 35.0% AP 的精度，同时在 T4 上使用 TRT FP16  batchsize=32 进行推理，可达到 1242FPS 的性能，相较于 YOLOv5-nano 精度提升 7% AP，速度提升 85%。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;YOLOv6-tiny 在 COCO val 上 取得了 41.3% AP 的精度， 同时在 T4 上使用 TRT FP16  batchsize=32 进行推理，可达到 602FPS 的性能，相较于 YOLOv5-s 精度提升 3.9% AP，速度提升 29.4%。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;YOLOv6-s 在 COCO val 上 取得了 43.1% AP 的精度， 同时在 T4 上使用 TRT FP16 batchsize=32 进行推理，可达到 520FPS 的性能，相较于 YOLOX-s 精度提升 2.6% AP，速度提升 38.6%；相较于 PP-YOLOE-s 精度提升 0.4% AP 的条件下，在 T4 上使用 TRT FP16 进行单 batch 推理，速度提升 71.3%。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;总结与展望&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;本文介绍了美团视觉智能部在目标检测框架方面的优化及实践经验，我们针对 YOLO 系列框架，在训练策略、主干网络、多尺度特征融合、检测头等方面进行了思考和优化，设计了新的检测框架 - YOLOv6，初衷来自于解决工业应用落地时所遇到的实际问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在打造 YOLOv6 框架的同时，我们探索和优化了一些新的方法，例如基于硬件感知神经网络设计思想自研了 EfficientRep Backbone、Rep-Neck 和 Efficient Decoupled Head，同时也吸收借鉴了学术界和工业界的一些前沿进展和成果，例如 Anchor-free、SimOTA 和 SIoU 回归损失。在 COCO 数据集上的实验结果显示，YOLOv6 在检测精度和速度方面都属于佼佼者。未来我们会持续建设和完善 YOLOv6 生态，主要工作包括以下几个方面：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1. 完善 YOLOv6 全系列模型，持续提升检测性能。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2. 在多种硬件平台上，设计硬件友好的模型。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3. 支持 ARM 平台部署以及量化蒸馏等全链条适配。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;4. 横向拓展和引入关联技术，如半监督、自监督学习等等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;5. 探索 YOLOv6 在更多的未知业务场景上的泛化性能。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;同时也欢迎社区同学加入我们，共同建设一个适合工业应用的更快更准的目标检测框架。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;参考文献&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[1] YOLOv5, https://github.com/ultralytics/yolov5&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[2] YOLOX: Exceeding YOLO Series in 2021, https://arxiv.org/abs/2107.08430&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[3] PP-YOLOE: An evolved version of YOLO, https://arxiv.org/abs/2203.16250&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[4] RepVGG: Making VGG-style ConvNets Great Again, https://arxiv.org/pdf/2101.03697&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[5] CSPNet: A New Backbone that can Enhance Learning Capability of CNN, https://arxiv.org/abs/1911.11929&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[6] Path aggregation network for instance segmentation, https://arxiv.org/abs/1803.01534&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[7] OTA: Optimal Transport Assignment for Object Detection, https://arxiv.org/abs/2103.14259&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[8] Computer Architecture: A Quantitative Approach&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;[9] SIoU Loss: More Powerful Learning for Bounding Box Regression, https://arxiv.org/abs/2205.12740&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;2.13515625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibOtQXeDEwIroCPqGDVy2RMnQpQrLicFHaJXj97JhbLofkkiad4ciab3b32L6ibvmu0sOsm1cT8unoh7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;br mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;/&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt;© THE END &lt;/span&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt;投稿或寻求报道：content@jiqizhixin.com&lt;/span&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>fab35e5893ba196e27a1c5855a39f500</guid>
<title>快用上PerformanceObserver，别再手动计算首屏时间了</title>
<link>https://toutiao.io/k/tbxln35</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天给大家介绍一个非常好用的浏览器api：&lt;strong&gt;PerformanceObserver&lt;/strong&gt; ， 我们可以用它来获取首屏、白屏的时间，就不用再麻烦地手动去计算了。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7795275590551181&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvyww1AOVtJHd7BDEictrZgXjI1b3hKJ4QHRZFhbrzUono2YYfmQtiaFIDQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;254&quot;/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;介绍&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;PerformanceObserver&lt;/strong&gt; 可用于获取性能相关的数据，例如&lt;strong&gt;首帧fp&lt;/strong&gt;、&lt;strong&gt;首屏fcp&lt;/strong&gt;、&lt;strong&gt;首次有意义的绘制 fmp&lt;/strong&gt;等等。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;构造函数&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;PerformanceObserver()&lt;/code&gt;创建并返回一个新的 PerformanceObserver 对象。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;提供的方法&lt;/span&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;PerformanceObserver.observe()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当记录的性能指标在指定的 entryTypes 之中时，将调用性能观察器的回调函数。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;PerformanceObserver.disconnect()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;停止性能观察者回调接收到性能指标。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;PerformanceObserver.takeRecords()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;返回存储在性能观察器中的性能指标的列表，并将其清空。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;重点我们看看observer.observe(options);&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;options&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个只装了单个键值对的对象，该键值对的键名规定为 &lt;strong&gt;entryTypes&lt;/strong&gt;。e&lt;strong&gt;ntryTypes&lt;/strong&gt; 的取值要求如下:&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;entryTypes 的值：一个放字符串的数组，字符串的有效值取值在性能条目类型 中有详细列出。如果其中的某个字符串取的值无效，浏览器会自动忽略它。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另：若未传入 options 实参，或传入的 options 实参为空数组，会抛出 TypeError。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;2&lt;/span&gt;&lt;/span&gt;&lt;span&gt;实例&lt;/span&gt;&lt;/h2&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&amp;lt;script&amp;gt;&lt;br/&gt; &lt;span&gt;const&lt;/span&gt; observer = &lt;span&gt;new&lt;/span&gt; PerformanceObserver(&lt;span&gt;(&lt;span&gt;list&lt;/span&gt;) =&amp;gt;&lt;/span&gt; {&lt;br/&gt;  &lt;span&gt;for&lt;/span&gt;(&lt;span&gt;const&lt;/span&gt; entry &lt;span&gt;of&lt;/span&gt; list.getEntries()){&lt;br/&gt;   &lt;span&gt;console&lt;/span&gt;.groupCollapsed(entry.name);&lt;br/&gt;   &lt;span&gt;console&lt;/span&gt;.log(entry.entryType);&lt;br/&gt;   &lt;span&gt;console&lt;/span&gt;.log(entry.startTime);&lt;br/&gt;   &lt;span&gt;console&lt;/span&gt;.log(entry.duration);&lt;br/&gt;   &lt;span&gt;console&lt;/span&gt;.groupEnd(entry.name);&lt;br/&gt;  }&lt;br/&gt; }) &lt;br/&gt; observer.observe({&lt;span&gt;entryTypes&lt;/span&gt;:[&lt;span&gt;&#x27;longtask&#x27;&lt;/span&gt;,&lt;span&gt;&#x27;frame&#x27;&lt;/span&gt;,&lt;span&gt;&#x27;navigation&#x27;&lt;/span&gt;,&lt;span&gt;&#x27;resource&#x27;&lt;/span&gt;,&lt;span&gt;&#x27;mark&#x27;&lt;/span&gt;,&lt;span&gt;&#x27;measure&#x27;&lt;/span&gt;,&lt;span&gt;&#x27;paint&#x27;&lt;/span&gt;]});&lt;br/&gt;&amp;lt;&lt;span&gt;/script&amp;gt;&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;获取结果&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7601522842639594&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvy9S9BZEibqp5smUeWNuoEvm7zjmVRlgbsDCIiaPzVEwH42FT81icTOREQg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;788&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据打印结果我们可以推测出来：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;entryTypes里的值其实就是我们告诉PerformanceObserver，我们想要获取的某一方面的性能值。例如传入&lt;strong&gt;paint&lt;/strong&gt;，就是说我们想要得到fcp和fp。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以我们看打印，它打印出来了fp和fcp&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2964071856287425&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvywXmOzGYvwKHbVP95xj64Z5iaQic5erYNOS1HIhDesibFgZcJI0DZTicsJQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;668&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里有必要解释一下什么是fp，fcp，fpm&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;TTFB：Time To First Byte，首字节时间&lt;br/&gt;FP：First Paint，首次绘制，绘制Body&lt;br/&gt;FCP：First Contentful Paint，首次有内容的绘制，第一个dom元素绘制完成&lt;br/&gt;FMP：First Meaningful Paint，首次有意义的绘制&lt;br/&gt;TTI：Time To Interactive，可交互时间，整个内容渲染完成&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvyyneHZpsEibq7RaJBvkKwhcH2FQ1S6icjMEFLY1Xq6gA2icOuXbZKrGpBw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;270&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不懂？看图！&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.35789473684210527&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvyRArb0GharyamZNnPAA1WRczKLl534Bseh9XvFHZQWUwbicVtbmSxAGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;665&quot;/&gt;&lt;/figure&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;FP仅有一个div根节点&lt;br/&gt;FCP包含页面的基本框架，但没有数据内容&lt;br/&gt;FMP包含页面的所有元素及数据&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Wow！恍然大悟！&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;3&lt;/span&gt;&lt;/span&gt;&lt;span&gt;实际使用&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好了，我们在实际项目中怎么取获取呢？可以看看我的实现参考一下下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;  &lt;span&gt;// 使用 PerformanceObserver 监听 fcp&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (!!PerformanceObserver){&lt;br/&gt;    &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;      &lt;span&gt;const&lt;/span&gt; type = &lt;span&gt;&#x27;paint&#x27;&lt;/span&gt;;&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; ((PerformanceObserver.supportedEntryTypes || []).includes(type)) {&lt;br/&gt;        observer = &lt;span&gt;new&lt;/span&gt; PerformanceObserver(&lt;span&gt;(&lt;span&gt;entryList&lt;/span&gt;)=&amp;gt;&lt;/span&gt;{&lt;br/&gt;          &lt;span&gt;for&lt;/span&gt;(&lt;span&gt;const&lt;/span&gt; entry &lt;span&gt;of&lt;/span&gt; entryList.getEntriesByName(&lt;span&gt;&#x27;first-contentful-paint&#x27;&lt;/span&gt;)){&lt;br/&gt;            &lt;span&gt;const&lt;/span&gt; { startTime,duration } = entry;&lt;br/&gt;            &lt;span&gt;console&lt;/span&gt;.log(&lt;span&gt;&#x27;[assets-load-monitor] PerformanceObserver fcp:&#x27;&lt;/span&gt;, startTime+&lt;span&gt;durati&lt;/span&gt;&lt;span&gt;on&lt;/span&gt;);&lt;br/&gt;            &lt;br/&gt;            &lt;span&gt;// 上报startTime操作&lt;/span&gt;&lt;br/&gt;          }&lt;br/&gt;        });&lt;br/&gt;        observer.observe({&lt;br/&gt;          &lt;span&gt;entryTypes&lt;/span&gt;: [type],&lt;br/&gt;        });&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt;;&lt;br/&gt;      }&lt;br/&gt;    } &lt;span&gt;catch&lt;/span&gt; (e) {&lt;br/&gt;      &lt;span&gt;// ios 不支持这种entryTypes，会报错 https://caniuse.com/?search=PerformancePaintTiming&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;console&lt;/span&gt;.warn(&lt;span&gt;&#x27;[assets-load-monitor] PerformanceObserver error:&#x27;&lt;/span&gt;, (e || {}).message ? e.message : e);&lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里用了判断是否可以使用PerformanceObserver，不能使用的话，我们是用其他方法的，例如MutationObserver，这个我们我们后面再讲。&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8733333333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvyC9BYibejt6iaLuXKnDMhUmBNwE4FLicCwaQJejnycialvM64zK4lV4l7dQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;150&quot;/&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4139749505603164&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FaeDdIfeuq4sKDyNWpYu0aYzrbGBbZvyz1NnBZOkqbKnXtocxPAgdsocNMkZINp1SJwWQ6BZSWAibEE7cLunFyQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1517&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;4&lt;/span&gt;&lt;/span&gt;&lt;span&gt;参考文章：&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;https://blog.csdn.net/weixin_40970987/article/details/108121988 https://developer.mozilla.org/zh-CN/docs/Web/API/PerformanceObserver/observe&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8b16dc0d9fec58f267ee028d502dfd85</guid>
<title>刨根问底: Kafka 到底会不会丢数据？</title>
<link>https://toutiao.io/k/909ukbu</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;em&gt;&lt;span/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;阅读本文大约需要 30 分钟。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;那么 Kafka 到底会不会丢数据呢？如果丢数据，究竟该怎么解决呢？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;只有掌握了这些， 我们才能处理好 Kafka 生产级的一些故障，从而更稳定地服务业务。&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;认真读完这篇文章，我相信你会对Kafka 如何解决丢数据问题，有更加深刻的理解。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;这篇文章干货很多，希望你可以耐心读完。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.599290780141844&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgDMV2ZHaB5kf106rAXEfTHvztibRqyYzYzTAaQYxlxRk7aNbGzsA0ZDEw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1410&quot;/&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;01 总体概述&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;越来越多的互联网公司使用消息队列来支撑自己的核心业务。由于是核心业务，一般都会要求消息传递过程中最大限度的做到不丢失，如果中间环节出现数据丢失，就会引来用户的投诉，年底绩效就要背锅了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么使用 Kafka 到底会不会丢数据呢？如果丢数据了该怎么解决呢？为了避免类似情况发生，除了要做好补偿措施，我们更应该在系统设计的时候充分考虑系统中的各种异常情况，从而设计出一个稳定可靠的消息系统。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家都知道 Kafka 的整个架构非常简洁，是分布式的架构，主要由 Producer、Broker、Consumer 三部分组成，后面剖析丢失场景会从这三部分入手来剖析。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4658730158730159&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoy608FibvOZ3G3oUeCm1weLtKg0t7fed0PZGTjX3rAkv0rjeyPnNs5FCoiakrj3dObYvwGU1FAmib8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1260&quot;/&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;02 消息传递语义剖析&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在深度剖析消息丢失场景之前，我们先来聊聊&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;消息传递语义&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;&lt;span&gt;到底是个什么玩意？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所谓的消息传递语义是 Kafka 提供的 Producer 和 Consumer 之间的消息传递过程中消息传递的保证性。主要分为三种， 如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.30466666666666664&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgD5VoCylicDO5Jhy4CTTL9RM4MgVrDXOic1FXWgibOVcxUGsFTC2tjyJBnA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1500&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）首先当 Producer 向 Broker 发送数据后，会进行 commit，&lt;span&gt;如果 commit 成功，&lt;/span&gt;由于 Replica 副本机制的存在，则意味着消息不会丢失，但是 Producer 发送数据给 Broker 后，遇到网络问题而造成通信中断，那么 Producer 就无法准确判断该消息是否已经被提交（commit），这就可能造成 at least once 语义&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）在 Kafka 0.11.0.0 之前， 如果 Producer 没有收到消息 commit 的响应结果，它只能重新发送消息，确保消息已经被正确的传输到 Broker，重新发送的时候会将消息再次写入日志中；而在 0.11.0.0 版本之后， Producer 支持幂等传递选项，保证重新发送不会导致消息在日志出现重复&lt;/span&gt;。&lt;span&gt;为了实现这个, Broker 为 Producer 分配了一个ID，并通过每条消息的序列号进行去重。也支持了类似事务语义来保证将消息发送到多个 Topic 分区中，保证所有消息要么都写入成功，要么都失败，这个主要用在 Topic 之间的 exactly once 语义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;其中启用幂等传递的方法配置&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：enable.idempotence = true。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;启用事务支持的方法配置&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：设置属性 transcational.id = &quot;指定值&quot;。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）从 Consumer 角度来剖析, 我们知道 Offset 是由 Consumer 自己来维护的, 如果 Consumer 收到消息后更新 Offset， 这时 Consumer 异常 crash 掉， 那么新的 Consumer 接管后再次重启消费，就会造成 at most once 语义（消息会丢，但不重复）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4) 如果 Consumer 消费消息完成后, 再更新 Offset， 如果这时 Consumer crash 掉，那么新的 Consumer 接管后重新用这个 Offset 拉取消息， 这时就会造成 at least once 语义（消息不丢，但被多次重复处理）。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;总结：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;默认 Kafka 提供 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;at least once&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;span&gt;语义的消息传递&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;&lt;span&gt;允许用户通过在处理消息之前保存 Offset 的方式提供 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;at most once&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt; 语义。如果我们可以自己实现消费幂等，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;理想情况下这个系统的消息传递就是严格的&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;exactly once&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」, &lt;/span&gt;&lt;span&gt;也就是保证不丢失、且只会被精确的处理一次，但是这样是很难做到的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 Kafka 整体架构图我们可以得出有三次消息传递的过程：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1）Producer 端发送消息给 Kafka Broker 端。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）Kafka Broker 将消息进行同步并持久化数据。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）&lt;strong&gt;&lt;span&gt;Consumer 端从 &lt;/span&gt;&lt;/strong&gt;Kafka Broker 将消息拉取并进行消费。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在以上这三步中每一步都可能会出现丢失数据的情况， 那么 Kafka 到底在什么情况下才能保证消息不丢失呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;通过上面三步，我们可以得出：Kafka 只对 &lt;/span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」的消息做&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;最大限度的持久化保证不丢失&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;怎么理解上面这句话呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）首先是 &lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」的消息：当 Kafka 中 &lt;span&gt;N&lt;/span&gt; 个 Broker 成功的收到一条消息并写入到日志文件后，它们会告诉 Producer 端这条消息已成功提交了，那么这时该消息在 Kafka 中就变成 &lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;已提交消息&quot;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;N &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;个 Broker &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们怎么理解呢？这主要取决于对 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;已提交&quot;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 的定义， 这里可以选择只要一个 Broker 成功保存该消息就算已提交，也可以是所有 Broker 都成功保存该消息才算是已提交&lt;span/&gt;&lt;/span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;span&gt;&lt;span/&gt;。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）其次是 &lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;最大限度的持久化保证不丢失&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，也就是说 Kafka 并不能保证在任何情况下都能做到数据不丢失。即 Kafka 不丢失数据是有前提条件的。假如这时你的消息保存在 N 个 Broker 上，那么前提条件就是这 N 个 Broker 中至少有1个是存活的，就可以保证你的消息不丢失。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说 Kafka 是能做到不丢失数据的， 只不过这些消息必须是 &lt;span&gt;「&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;的消息，且还要满足一定的条件才可以。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;了解了 Kafka 消息传递语义以及什么情况下可以保证不丢失数据，下面我们来详细剖析每个环节为什么会丢数据，以及如何最大限度的避免丢失数据。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;03 消息丢失场景剖析&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Producer 端丢失场景剖析&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在剖析 Producer 端数据丢失之前，我们先来了解下 Producer 端发送消息的流程，对于不了解 Producer 的读者们，可以查看 &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTcxMDgxNA==&amp;amp;mid=2247488849&amp;amp;idx=1&amp;amp;sn=febda095589f02553d9191528f271c07&amp;amp;chksm=cefb3c60f98cb576fd9c58d760b9a5e4ae32a0c001e2049b591297d904a0401646448999c78a&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;聊聊 Kafka Producer 那‍点事&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;聊聊 Kafka Producer 那点事&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5580969807868252&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j83KibYlWcyceJicnUBWdByYTAibzaQsQ90c1IKpZhfXTVOJ1Mj4ErYMPzLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1093&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;消息发送流程如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）首先我们要知道一点就是 Producer 端是直接与 Broker 中的 Leader Partition 交互的，所以在 Producer 端初始化中就需要通过 Partitioner 分区器从 Kafka 集群中获取到相关 Topic 对应的 Leader Partition 的元数据 &lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）待获取到 Leader Partition 的元数据后直接将消息发送过去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）Kafka Broker 对应的 Leader Partition 收到消息会先写入 Page Cache，定时刷盘进行持久化（顺序写入磁盘）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4) Follower Partition 拉取 Leader Partition 的消息并保持同 Leader Partition 数据一致，待消息拉取完毕后需要给 Leader Partition 回复 ACK 确认消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5）待 Kafka Leader 与 Follower Partition 同步完数据并收到所有 ISR 中的 Replica 副本的 ACK 后，Leader Partition 会给 Producer 回复 ACK 确认消息。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;根据上图以及消息发送流程可以得出：Producer 端为了提升发送效率，减少IO操作，发送数据的时候是将多个请求合并成一个个 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;RecordBatch&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，并将其封装转换成 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;Request&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; 请求&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;异步&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;将数据发送出去（也可以按时间间隔方式，达到时间间隔自动发送），&lt;/span&gt;&lt;span&gt;&lt;strong&gt;所以 Producer 端消息丢失更多是因为消息根本就没有发送到 Kafka Broker 端&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;导致 Producer 端消息没有发送成功有以下原因：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外 Kafka Producer 端也可以通过配置来确认消息是否生产成功：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4184818481848185&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j83ibHEc1zjbRF13jNcgcN8j7ichWjVY4lXXQOPDw6Uvy4GA9PIebBUfhVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1515&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;在 Kafka Producer 端的 acks 默认配置为1， 默认级别是 at least once 语义, 并不能保证 exactly once 语义。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5719360568383659&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgDWN00EfxZVYY8KN1XElAQibuzibDZibZiaicCJY8L7NOwBhkJC9icavRGt0SA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;563&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然 Producer 端发送数据有 ACK 机制, 那么这里就可能会丢数据的&lt;strong&gt;!!!&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;acks = 0：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;由于发送后就自认为发送成功，&lt;/span&gt;&lt;span&gt;这时如果发生网络抖动， Producer 端并不会校验 ACK 自然也就丢了，且无法重试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;acks = 1：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;消息发送 Leader Parition 接收成功就表示发送成功，这时&lt;/span&gt;&lt;span&gt;只要 Leader Partition 不 Crash 掉，就可以保证 Leader Partition 不丢数据，但是如果 Leader Partition 异常 Crash 掉了， Follower Partition 还未同步完数据且没有 ACK，这时就会丢数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;acks = -1 或者 all：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 消息发送需要等待 ISR 中 Leader Partition 和 所有的 Follower Partition 都确认收到消息才算发送成功, 可靠性最高, 但也不能保证不丢数据,比如当 ISR 中只剩下 Leader Partition 了, 这样就变成 acks = 1 的情况了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Broker 端丢失场景剖析&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;接下来我们来看看 Broker 端持久化存储丢失场景， 对于不了解 Broker 的读者们，可以先看看 &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTcxMDgxNA==&amp;amp;mid=2247488847&amp;amp;idx=1&amp;amp;sn=fe2dace4ebf39001062fa331711606ba&amp;amp;chksm=cefb3c7ef98cb5689c91b02edb345cc75751ae7e2daf27d8de9a47f9ecc3eedaf3551eead037&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;聊聊 Kafka Brok‍er 那点事&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;聊聊 Kafka Broker 那点事&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;，&lt;span&gt;数据存储过程如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8770614692653673&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpohQngGEXiaejib1KGW2yCL7iarBhb6BMv1k68TN9yicVfl0VbPU2byKSIicoOkYIEawkKKbpJae7YDcKw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;667&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kafka Broker 集群接收到数据后会将数据进行持久化存储到磁盘，为了提高吞吐量和性能，采用的是&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;异步批量刷盘的策略&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，也就是说按照一定的消息量和间隔时间进行刷盘。首先会将数据存储到 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;PageCache&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt; 中，至于什么时候将 Cache 中的数据刷盘是由&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;操作系统&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;根据自己的策略决定或者调用 fsync 命令进行强制刷盘，如果此时 Broker 宕机 Crash 掉，且选举了一个落后 Leader Partition 很多的 Follower Partition 成为新的 Leader Partition，那么落后的消息数据&lt;span&gt;就会丢失&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;                &lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5719360568383659&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgDWN00EfxZVYY8KN1XElAQibuzibDZibZiaicCJY8L7NOwBhkJC9icavRGt0SA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;563&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然 Broker 端消息存储是通过异步批量刷盘的，那么这&lt;span&gt;里就可能会丢数据的&lt;/span&gt;&lt;strong&gt;!!!&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Consumer 端丢失场景剖析&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;接下来我们来看看 Consumer 端消费数据丢失场景，对于不了解 Consumer 的读者们，可以先看看 &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTcxMDgxNA==&amp;amp;mid=2247488851&amp;amp;idx=1&amp;amp;sn=987824e5ba607e2e33ae0c64adb77d84&amp;amp;chksm=cefb3c62f98cb574d3932d5898dd1da3c20772e1d1885fc90d9b9f4bb5cdf8f34d4e0c7ff7ad&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;聊聊 Kafka‍ ‍Consumer 那点事&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;聊聊 Kafka Consumer 那点事&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;, &lt;span&gt;我们先来看看消费流程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5238095238095238&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j83viczAKDtc5fufr0K3ME0Oas26TkdMNG1fwib5ZGGnoa792cPVFFb52bw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1302&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4313304721030043&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j8354hIicJUibMVspQ7pMLgmm4EEBFBqp4l1QeEyADkGUFIt1HthRSq45bg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1398&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）Consumer 拉取数据之前跟 Producer 发送数据一样, 需要通过订阅关系获取到集群元数据, &lt;/span&gt;找到&lt;span&gt;相关 Topic 对应的 Leader Partition 的元数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）然后 Consumer 通过 Pull 模式主动的去 Kafka 集群中拉取消息。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）在这个过程中，有个消费者组的概念（&lt;/span&gt;&lt;strong&gt;&lt;span&gt;不了解的可以看上面链接文章&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;），多个 Consumer 可以组成一个消费者组即 Consumer Group，每个消费者组都有一个Group-Id。同一个 Consumer Group 中的 Consumer 可以消费同一个 Topic 下不同分区的数据，但是不会出现多个 Consumer 去消费同一个分区的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4）拉取到消息后进行业务逻辑处理，待处理完成后，会进行 ACK 确认，即提交 Offset 消费位移进度记录。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5）最后 Offset 会被保存到 Kafka Broker 集群中的 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;__consumer_offsets&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 这个 Topic 中，且每个 Consumer 保存自己的 Offset 进度。 &lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;根据上图以及消息消费流程可以得出消费主要分为两个阶段：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;                       &lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5719360568383659&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgDWN00EfxZVYY8KN1XElAQibuzibDZibZiaicCJY8L7NOwBhkJC9icavRGt0SA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;563&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然 Consumer 拉取后消息最终是要提交 Offset， 那么这&lt;span&gt;里就可能会丢数据的&lt;/span&gt;&lt;strong&gt;!!!&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;拉取消息后&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;先提交 Offset，后处理消息&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;，如果此时处理消息的时候异常宕机，由于 Offset 已经提交了,  待 Consumer 重启后，会从之前已提交的 Offset 下一个位置重新开始消费， 之前未处理完成的消息不会被再次处理，对于该 Consumer 来说消息就丢失了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;拉取消息后&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;先处理消息，在进行提交 Offset&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;， 如果此时在提交之前发生异常宕机，由于没有提交成功 Offset， 待下次 Consumer 重启后还会从上次的 Offset 重新拉取消息，不会出现消息丢失的情况， 但是会出现重复消费的情况，这里只能业务自己保证幂等性。&lt;/span&gt;        &lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;04 消息丢失解决方案&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;上面带你从 Producer、Broker、Consumer 三端剖析了可能丢失数据的场景，下面我们就来看看如何解决才能最大限度的&lt;span&gt;保证消息不丢失。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Producer 端解决方案&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在剖析&lt;span&gt; Producer 端&lt;/span&gt;丢失场景的时候， 我们得出其是通过&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;异步&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」方式进行发送的，所以如果此时是使用&lt;/span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;发后即焚&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;」的方式发送，即&lt;/span&gt;&lt;span&gt;调用 Producer.send(msg) 会立即返回，由于没有回调，可能因网络原因导致 Broker 并没有收到消息，此时就丢失了。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此我们可以从以下几方面进行解决 Producer 端消息丢失问题：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.1.1 更换调用方式：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;弃用调用发后即焚的方式，使用带回调通知函数的方法进行发送消息，即 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;Producer.send(msg, callback)&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;, 这样一旦发现发送失败， 就可以做针对性处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;kotlin&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;Future&amp;lt;RecordMetadata&amp;gt; send(ProducerRecord&amp;lt;K, V&amp;gt; record, Callback callback);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; Future&amp;lt;RecordMetadata&amp;gt; send(ProducerRecord&amp;lt;K, V&amp;gt; record, Callback callback) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        ProducerRecord&amp;lt;K, V&amp;gt; interceptedRecord = &lt;span class=&quot;code-snippet__keyword&quot;&gt;this&lt;/span&gt;.interceptors == &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; ? record : &lt;span class=&quot;code-snippet__keyword&quot;&gt;this&lt;/span&gt;.interceptors.onSend(record);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; doSend(interceptedRecord, callback);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;）网络抖动&lt;/span&gt;&lt;span&gt;导致消息丢失，Producer 端可以进行重试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）消息大小不合格，可以进行适当调整，符合 Broker 承受范围再发送。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过以上方式可以保证最大限度消息可以发送成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.1.2 ACK 确认机制：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;该参数代表了对&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;已提交&quot;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;消息的定义。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;需要将 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;request.required.acks 设置为 -1/ all&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，-1/all 表示有多少个副本 Broker 全部收到消息，才认为是消息提交成功的标识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;acks = -1/ all &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;, 这里有两种非常典型的情况：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;（1）数据发送到 Leader Partition， 且所有的 ISR 成员全部同步完数据， 此时，Leader Partition 异常 Crash 掉，那么会选举新的 Leader Partition，数据不会丢失， 如下图所示&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6088534107402032&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbypdvf0k7OrsblGBGmIXwIIedLVUEYL2aVWTplEiaKYB2SjSw0DCaEibXBOUCdWXdvAASqpbQkhrgwBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1378&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;（2）数据发送到&lt;strong&gt;&lt;span&gt; Leader Partition&lt;/span&gt;&lt;/strong&gt;，部分 ISR 成员同步完成，此时 Leader Partition 异常 Crash， 剩下的 Follower &lt;span&gt;Partition&lt;/span&gt; 都可能被选举成新的 Leader Partition，会给 Producer 端发送失败标识， 后续会重新发送数据，数据可能会重复， 如下图所示：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6083086053412463&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbypdvf0k7OrsblGBGmIXwIIe0n7XoQWXSxHU5q2zpFH9Ric5jFdKcSeaNMIojr9UurYicAspAQtKwR2g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1348&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此通过上面分析，我们还需要通过其他参数配置来进行保证：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;replication.factor &amp;gt;= 2&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;min.insync.replicas &amp;gt; 1&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是 Broker 端的配置，下面会详细介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.1.3 重试次数 retries：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示 Producer 端发送消息的重试次数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;需要将 retries 设置为大于0的数， 在 Kafka 2.4 版本中默认设置为&lt;/span&gt;&lt;span&gt;Integer.MAX_VALUE。另外如果需要保证发送消息的顺序性，配置如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;retries &lt;span&gt;=&lt;/span&gt; Integer&lt;span&gt;.&lt;/span&gt;&lt;span&gt;MAX_VALUE&lt;/span&gt;&lt;br/&gt;max&lt;span&gt;.&lt;/span&gt;in&lt;span&gt;.&lt;/span&gt;flight&lt;span&gt;.&lt;/span&gt;requests&lt;span&gt;.&lt;/span&gt;per&lt;span&gt;.&lt;/span&gt;connection &lt;span&gt;=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这样 Producer 端就会一直进行重试直到 Broker 端返回 ACK 标识，同时只有一个连接向 Broker 发送数据保证了消息的顺序性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.1.4 重试时间 retry.backoff.ms：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示消息发送超时后&lt;/span&gt;&lt;strong&gt;&lt;span&gt;两次重试之间的间隔时间&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，避免无效的频繁重试，默认值为100ms,  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;推荐设置为300ms&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Broker 端解决方案&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在剖析 Broker 端丢失场景的时候， 我们得出其是通过&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;异步批量刷盘&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」的策略，先将数据存储到 &lt;/span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;PageCache&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;」，再进行异步刷盘， 由于没有提供 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;同&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;步刷盘&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」策略， 因此 Kafka 是通过&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;多分区多副本&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;的方式来&lt;span&gt;最大限度的&lt;/span&gt;保证数据不丢失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以通过以下参数配合来保证：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.2.1 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;unclean.leader.election.enable&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示&lt;/span&gt;&lt;strong&gt;&lt;span&gt;有哪些 Follower 可以有资格被选举为 Leader&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; , 如果一个 Follower 的数据落后 Leader 太多，那么一旦它被选举为新的 Leader， 数据就会丢失，因此我们要将其设置为false，防止此类情况发生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;4.2.2 &lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;replication.factor&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示分区副本的个数。建议设置 &lt;strong&gt;&lt;strong&gt;&lt;span&gt;replication.factor &amp;gt;=3&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;, 这样如果 Leader 副本异常 Crash 掉，Follower 副本会被选举为新的 Leader 副本继续提供服务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;4.2.3 &lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;min.insync.replicas&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示消息至少要被写入成功到 ISR 多少个副本才算&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;已提交&quot;，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;建议&lt;/span&gt;&lt;span&gt;设置&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;min.insync.replicas &amp;gt; 1, &lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;这样才可以提升消息持久性，保证数据不丢失。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外我们还需要确保一下 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;replication.factor &amp;gt; min.insync.replicas&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;, 如果相等，只要有一个副本异常 Crash 掉，整个分区就无法正常工作了，因此推荐设置成： &lt;strong&gt;&lt;span&gt;replication.factor = min.insync.replicas +1&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;, 最大限度保证系统可用性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Consumer 端解决方案&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在剖析 Consumer 端丢失场景的时候，我们得出其拉取完消息后是需要提交 Offset 位移信息的，因此为了不丢数据，正确的做法是：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;拉取数据、&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;业务逻辑处理、&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;提交消费 Offset 位移信息。&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;我们还需要设置参数 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;enable.auto.commit = false, 采用手动提交位移的方式。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外对于消费消息重复的情况，业务自己保证幂等性, &lt;/span&gt;&lt;strong&gt;&lt;span&gt;保证只成功消费一次即可&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;05 总结&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里，我们一起来总结一下这篇文章的重点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、从 Kafka 整体架构上概述了可能发生数据丢失的环节。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、带你剖析了&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;消息传递语义&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;的概念， 确定了 Kafka 只对&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;的消息做&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;最大限度的持久化保证不丢失&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、带你剖析了 Producer、Broker、Consumer 三端可能导致数据丢失的场景以及具体的高可靠解决方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果我的文章对你有所帮助，还请帮忙&lt;/span&gt;&lt;strong&gt;点赞、在看、转发&lt;/strong&gt;&lt;span&gt;一下，非常感谢！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;坚持总结, 持续输出高质量文章&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;  关注我: 华仔聊技&lt;span data-raw-text=&quot;术&quot; data-textnode-index=&quot;537&quot; data-index=&quot;7642&quot;&gt;术&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;br/&gt;&lt;/h1&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzg3MTcxMDgxNA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyp4CYMexUiagvdYANIhY2ibiaibtqichibk92kiaMvHTJmavuepu4yZWC2OqwCVz834X916B5txFNYY7KgXw/0?wx_fmt=png&quot; data-nickname=&quot;华仔聊技术&quot; data-alias=&quot;&quot; data-signature=&quot;聊聊后端技术架构以及中间件源码&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>