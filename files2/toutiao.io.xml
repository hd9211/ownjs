<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>4edb4f871c80352974e8509a841da31f</guid>
<title>vivo 全球商城：优惠券系统架构设计与实践</title>
<link>https://toutiao.io/k/yyiq1f3</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;24&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;作者：vivo互联网开发团队-Yan Chao&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;一、业务背景&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;优惠券是电商常见的营销手段，具有灵活的特点，既可以作为促销活动的载体，也是重要的引流入口。优惠券系统是vivo商城营销模块中一个重要组成部分，早在15年vivo商城还是单体应用时，优惠券就是其中核心模块之一。随着商城的发展及用户量的提升，优惠券做了服务拆分，成立了独立的优惠券系统，提供通用的优惠券服务。目前，优惠券系统覆盖了优惠券的4个核心要点：创、发、用、计。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;“创”&lt;/strong&gt;指优惠券的创建，包含各种券规则和使用门槛的配置。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;“发”&lt;/strong&gt;指优惠券的发放，优惠券系统提供了多种发放优惠券的方式，满足针对不同人群的主动发放和被动发放。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;“用”&lt;/strong&gt;指优惠券的使用，包括正向购买商品及反向退款后的优惠券回退。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;“计”&lt;/strong&gt;指优惠券的统计，包括优惠券的发放数量、使用数量、使用商品等数据汇总。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;vivo商城优惠券系统除了提供常见的优惠券促销玩法外，还以优惠券的形式作为其他一些活动或资产的载体，比如手机类商品的保值换新、内购福利、与外部广告商合作发放优惠券等。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以下为vivo商城优惠券部分场景的展示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.03828125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6NTK2KoQqMmNOPalPdthCwCbXROn2MOJh0C88eZwj3pt9vII8q6IFNP46eEyxpvwcgldISUWB4CA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;二、系统架构及变迁&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;优惠券最早和商城耦合在一个系统中。随着vivo商城的不断发展，营销活动力度加大，优惠券使用场景增多，优惠券系统逐渐开始“力不从心”，暴露了很多问题：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了解决以上问题，19年优惠券系统进行了系统独立，提供通用的优惠券服务，独立后的系统架构如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.91953125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6NTK2KoQqMmNOPalPdthCwKZvt05yFAHJoibzla0Oib7tyMd4RWNCzvGIa6IeWjXfL4s6rNWRuEbrw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;优惠券系统独立迁移方案&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;如何将优惠券从商城系统迁移出来，并兼容已对接的业务方和历史数据，也是一大技术挑战。系统迁移有两种方案：停机迁移和不停机迁移。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们采用的是不停机迁移方案：&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;58&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;p&gt;静态数据：优惠券后台生成的数据，与用户无关。&lt;/p&gt;&lt;p&gt;动态数据：与用户有关的优惠券数据，含用户领取的券、券和订单的关系数据等。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;配置当前数据库开关为单写，即优惠券数据写入商城库（旧库）。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;优惠券系统上线，通过脚本迁移静态数据。迁完后，验证静态数据迁移准确性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;配置当前数据库开关为双写，即线上数据同时写入商城库和优惠券新库。此时服务提供的数据源依旧是商城库。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;迁移动态数据。迁完后，验证动态数据迁移准确性。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;切换数据源，服务提供的数据源切换到新库。验证服务是否正确，出现问题时，切换回商城数据源。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;关闭双写，优惠券系统迁移完成。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;迁移后优惠券系统请求拓扑图如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5453125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6NTK2KoQqMmNOPalPdthCwJb9uvPAk35Z0p3icicFjpDUOibjtMcV9p3S5HZR2WQEXCsibS1a3zOoI3Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;三、系统设计&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;3.1 优惠券分库分表&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;随着优惠券发放量越来越大，单表已经达到瓶颈。为了支撑业务的发展，综合考虑，对用户优惠券数据进行分库分表。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;关键字：技术选型、分库分表因子&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;分库分表有成熟的开源方案，这里不做过多介绍。参考之前项目经验，采用了公司中间件团队提供的自研框架。原理是引入自研的MyBatis的插件，根据自定义的路由策略计算不同的库表后缀，定位至相应的库表。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;用户优惠券与用户id关联，并且用户id是贯穿整个系统的重要字段，因此使用用户id作为分库分表的路由因子。这样可以保证同一个用户路由至相同的库表，既有利于数据的聚合，也方便用户数据的查询。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;假设共分N个库M个表，分库分表的路由策略为：&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;72&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;p&gt;库后缀databaseSuffix = hash(userId) / M %N&lt;/p&gt;&lt;p&gt;表后缀tableSuffix = hash(userId) % M&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.76171875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6NTK2KoQqMmNOPalPdthCwn8kTU7upWnE5HT0qQGt9JML4yGM2FO10oxDO2QicmUpY5pwnrbdgvkg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;3.2 优惠券发放方式设计&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;为满足各种不同场景的发券需求，优惠券系统提供三种发券方式：&lt;strong&gt;统一领券接口&lt;/strong&gt;、&lt;strong&gt;后台定向发券&lt;/strong&gt;、&lt;strong&gt;券码兑换发放&lt;/strong&gt;。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;3.2.1 统一领券接口&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;保证领券校验的准确性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;领券时，需要严格校验优惠券的各种属性是否满足：比如领取对象、各种限制条件等。其中，比较关键的是库存和领取数量的校验。因为在高并发的情况下，需保证数量校验的准确性，不然很容易造成用户超领。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;存在这样的场景：A用户连续发起两次领取券C的请求，券C限制每个用户领取一张。第一次请求通过了领券数量的校验，在用户优惠券未落库的情况下，如果不做限制，第二次请求也会通过领券数量的校验。这样A用户会成功领取两张券C，造成超领。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了解决这个问题，优惠券采用的是分布式锁方案，分布式锁的实现依赖于Redis。在校验用户领券数量前先尝试获取分布式锁，优惠券发放成功后释放锁，保证用户领取同一张券时不会出现超领。上面这种场景，用户第一次请求成功获取分布式锁后，直至第一次请求成功释放已获取的分布式锁或超时释放，不然用户第二次请求会获取分布式锁失败，这样保证A用户只会成功领取一张。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;库存扣减&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;领券要进行库存扣减，常见库存扣减方案有两种：&lt;/p&gt;&lt;p&gt;&lt;strong/&gt;&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;197&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;strong&gt;方案一：&lt;/strong&gt;数据库扣减。&lt;/section&gt;&lt;section&gt;扣减库存时，直接更新数据库中库存字段。&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;该方案的&lt;strong&gt;优点&lt;/strong&gt;是简单便捷，查验库存时直接查库即可获取到实时库存。且有数据库事务保证，不用考虑数据丢失和不一致的问题。&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;缺点&lt;/strong&gt;也很明显，主要有两点：&lt;/section&gt;&lt;section&gt;1）库存是数据库中的单个字段，在更新库存时，所有的请求需要等待行锁。一旦并发量大了，就会有很多请求阻塞在这里，导致请求超时，进而系统雪崩。&lt;/section&gt;&lt;section&gt;2）频繁请求数据库，比较耗时，且会大量占用数据库连接资源。&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;strong/&gt;&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;121&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;strong&gt;方案二：&lt;/strong&gt;基于redis实现库存扣减操作。&lt;/section&gt;&lt;section&gt;将库存放到缓存中，利用redis的incrby特性来扣减库存。&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;该方案的&lt;strong&gt;优点&lt;/strong&gt;是突破数据库的瓶颈，速度快，性能高。&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;缺点&lt;/strong&gt;是系统流程会比较复杂，而且需要考虑缓存丢失或宕机数据恢复的问题，容易造成库存数据不一致。&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从优惠券系统当前及可预见未来的流量峰值、系统维护性、实用性上综合考虑，优惠券系统采用了方案一的改进方案。改进方案是将单库存字段分散成多库存字段，分散数据库的行锁，减少并发量大的情况数据库的行锁瓶颈。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.64609375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6NTK2KoQqMmNOPalPdthCwZITOHPTeUaIibEGYKsjHGaO8fGzkNsLicwowDyX3lY2qO0mWFIMXyicUg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;库存数更新后，会将库存平均分配成M份，初始化更新到库存记录表中。用户领券，随机选取库存记录表中已分配的某一库存字段（共M个）进行更新，更新成功即为库存扣减成功。同时，定时任务会定期同步已领取的库存数。相比方案一，该方案突破了数据库单行锁的瓶颈限制，且实现简单，不用考虑数据丢失和不一致的问题。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;一键领取多张券&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在对接的业务方的领券场景中，存在用户一键领取多张券的情形。因此统一领券接口需要支持用户一键领券，除了领取同一券模板的多张，也支持领取不同券模板的多张。一般来说，一键领取多张券指领取不同券模板的多张。在实现过程中，需要注意以下几点：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1）如何保证性能&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;领取多张券，如果每张券分别进行校验、库存扣减、入库，那么接口性能的瓶颈卡在券的数量上，数量越多，性能直线下降。那么在券数量多的情况下，怎么保证高性能呢？主要采取两个措施：&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;175&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;a. &lt;strong&gt;批量操作&lt;/strong&gt;。&lt;/section&gt;&lt;section&gt;从发券流程来看，瓶颈在于券的入库。领券是实时的（异步的话，不能实时将券发到用户账户下，影响到用户的体验还有券的转化率），券越多，入库时与数据库的IO次数越多，性能越差。批量入库可以保证与数据库的IO的次数只有一次，不受券的数量影响。如上所述，用户优惠券数据做了分库分表，同一用户的优惠券资产保存在同一库表中，因此同一用户可实现批量入库。&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;38&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;b. &lt;strong&gt;限制单次领券数量&lt;/strong&gt;。&lt;/section&gt;&lt;section&gt;设置阀值，超出数量后，直接返回，保证系统在安全范围内。&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2）保证高并发情况下，用户不会超领&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;假如用户在商城发起请求，一键领取A/B/C/D四张券，同时活动系统给用户发放券A，这两个领券请求是同时的。其中，券A限制了每个用户只能领取一张。按照前述采用分布式锁保证校验的准确性，两次请求的分布式锁的key分别为：&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;33&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;p&gt;用户id+A_id+B_id+C_id+D_id&lt;/p&gt;&lt;p&gt;用户id+A_id&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种情况下，两次请求的分布式锁并没有发挥作用，因为锁key是不同，数量校验依旧存在错误的可能性。为避免批量领券过程中用户超领现象的发生，在批量领券过程中，对分布锁的获取进行了改造。上例一键领取A/B/C/D四张券，需要批量获取4个分布式锁，锁key为：&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;36&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;p&gt;用户id+A_id&lt;/p&gt;&lt;p&gt;用户id+B_id&lt;/p&gt;&lt;p&gt;用户id+C_id&lt;/p&gt;&lt;p&gt;用户id+D_id&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;获取其中任何一个锁失败，即表明此时该用户正在领取其中某一张券，需要自旋等待（在超时时间内）。获取所有的分布式锁成功，才可以进行下一步。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;接口幂等性&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;统一领券接口需保证幂等性（幂等性：用户对于同一操作发起的一次请求或者多次请求的结果是一致的）。在网络超时、异常情况下，领券结果没有及时返回，业务方会进行领券重试。如果接口不保证幂等性，会造成超发。幂等性的实现有多种方案，优惠券系统利用数据库的唯一索引来保证幂等。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;领券最早是不支持幂等性的，表设计没有考虑幂等性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那么&lt;strong&gt;第一个需要考虑的问题：在哪个表来添加唯一索引呢？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;无非两种方案：现有的表或者新建表。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;第二个考虑的问题：怎么兼容历史数据和业务方？&lt;/strong&gt;历史数据增加了唯一字段，需要填入唯一值，不然无法添加唯一索引。我们采用脚本刷数据的方式，构造唯一值并刷新到每一行历史数据中。优惠券已对接的业务方没有传入唯一编码，针对这种情况，优惠券侧生成唯一编码作为替代，保证兼容性。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;3.2.2 定向发券&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;定向发券用于运营在后台针对特定人群进行发券。定向发券可以弥补用户主动领券，人群覆盖不精准、覆盖面不广的问题。通过定向发券，可以精准覆盖特定人群，提高下单转化率。在大促期间，大范围人群的定向发券还可以承载活动push和降价促销双重任务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;定向发券主要在于人群的圈选和发券流程的设计，整体流程如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.81875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6NTK2KoQqMmNOPalPdthCwNLJgCfVjmdibfNwcMCHYH8OEvsqUu8Db19zpnCTVCfV002asLiclHybw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;定向发券不同于用户主动领券，定向发券的量通常会很大（亿级）。为了支撑大批量的定向发券，定向发券做了一些优化：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1）去除事务&lt;/strong&gt;。事务逻辑过重，对于定向发券来说没必要。发券失败，记录失败的券，保证失败可以重试。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2）轻量化校验&lt;/strong&gt;。定向发券限制了券类型，通过限制配置的方式规避需严格校验属性的配置。不同于用户主动领券校验逻辑的冗长，定向发券的校验非常轻量，大大提升发券性能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3）批量插入&lt;/strong&gt;。批量券插入减少数据库IO次数，消除数据库瓶颈，提升发券速度。定向发券是针对不同的用户，用户优惠券做了分库分表，为了实现批量插入，需要在内存中先计算出不同用户对应的库表后缀，数据归集后再批量插入，最多插入M次，M为库表总个数。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4）核心参数可动态配置&lt;/strong&gt;。比如单次发券数量，单次读库数量，发给消息中心的消息体包含的用户数量等，可以控制定向发券的峰值速度和平均速度。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;3.2.3 券码兑换&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;站外营销券的发放方式与其他券不同，通过券码进行兑换。券码由后台导出，通过短信或者活动的方式发放到用户，用户根据券码兑换后获取相应的券。券码的组成有一定的规则，在规则的基础上要保证安全性，这种安全性主要是券码校验的准确性，防止已兑换券码的再次兑换和无效券码的恶意兑换。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;3.3 精细化营销能力设计&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;通过标签组合配置的方式，优惠券提供精细化营销的能力，以实现优惠券的千人千面。标签可分为准实时和实时，值得注意的是，一些实时的标签的处理需要前提条件，比如地区属性需要用户授权。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;优惠券的精准触达：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6686746987951807&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6NTK2KoQqMmNOPalPdthCwB6lRo0XACE1vr3xics8dA6QLpneDIUFxuP1fGj3iaYfgYXa84MR2SYIQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;996&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;3.4 券和商品之间的关系&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;优惠券的使用需要和商品关联，可关联所有商品，也可以关联部分商品。为了灵活性地满足运营对于券关联商品的配置，优惠券系统有两种关联方式：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;119&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;p&gt;a. 黑名单。&lt;/p&gt;&lt;p&gt;可用商品 = 全部商品 - 黑名单商品。&lt;/p&gt;&lt;p&gt;黑名单适用于券的可使用商品范围比较广这种情况，全部商品排除掉黑名单商品就是券的可使用范围。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;b. 白名单。&lt;/p&gt;&lt;p&gt;可用商品 = 白名单商品。&lt;/p&gt;&lt;p&gt;白名单适用于券的可使用商品范围比较小这种情况，直接配置券的可使用商品。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;除此以外，还有超级黑名单的配置，黑名单和白名单只对单个券有效，超级黑名单对所有券有效。当前优惠券系统提供商品级的关联，后续优惠券会支持商品分类维度的关联，分类维度 + 商品维度可以更灵活地关联优惠券和商品。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;3.5 高性能保证&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;优惠券对接系统多，存在高流量场景，优惠券对外提供接口需保证高性能和高稳定性。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;多级缓存&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为了提升查询速度，减轻数据库的压力，同时为了应对瞬时高流量带来热点key的场景（比如发布会直播结束切换流量至特定商品商详页、热点活动商品商详页都会给优惠券系统带来瞬时高流量），优惠券采用了多级缓存的方式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.628125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6NTK2KoQqMmNOPalPdthCwnu8K8v2LhBtySIYKMD4FzEaecfhPs9tQfFCZFOA5FkiaxCFz5I4fUibA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;数据库读写分离&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;优惠券除了上述所说的分库分表外，在此基础上还做了读写分离操作。主库负责执行数据更新请求，然后将数据变更实时同步到所有从库，用从库来分担查询请求，解决数据库写入影响查询的问题。主从同步存在延迟，正常情况下延迟不超过1ms，优惠券的领取或状态变更存在一个耗时的过程，主从延迟对于用户来说无感知。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.9698630136986301&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6NTK2KoQqMmNOPalPdthCwiabPvOLmgm9WzmMoCwQicKNp1JXiaia4lG3X8ibG8Nw64H8SeOSsBX5r9jw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1095&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;依赖外部接口隔离熔断&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;优惠券内部依赖了第三方的系统，为了防止因为依赖方服务不可用，产生连锁效应，最终导致优惠券服务雪崩的事情发生，优惠券对依赖外部接口做了隔离和熔断。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用户维度优惠券字段冗余&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;查询用户相关的优惠券数据是优惠券最频繁的查询操作之一，用户优惠券数据做了分库分表，在查询时无法关联券规则表进行查询，为了减少IO次数，用户优惠券表中冗余了部分券规则的字段。优惠券规则表字段较多，冗余的字段不能很多，要在性能和字段数之间做好平衡。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;四、总结及展望&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;最后对优惠券系统进行一个总结：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;展望：目前优惠券系统主要服务于vivo商城，未来我们希望将优惠券能力开放，为内部其他业务方提供通用一体化的优惠券平台。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;END&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span title=&quot;&quot; opera-tn-ra-cell=&quot;_$.pages:0.layers:0.comps:55.title1&quot;&gt;&lt;p&gt;猜你喜欢&lt;/p&gt;&lt;/span&gt; &lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>18caae1ce855a46c1a09efdc9657e18d</guid>
<title>软件质量保障体系建设</title>
<link>https://toutiao.io/k/i5z2q03</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;h2&gt;&lt;span&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;从事软件测试相关工作七年，做过功能测试、自动化测试、测试开发、性能测试、专项测试，也干过一段时间技术管理，近几年随着行业成熟度的发展，对软件测试也有了更高的要求，很多测试团队开始转变为质量保障团队。如何从质量保障的维度去更好的为业务提供支持，是我一直在思考的事情。整理了自己的很多笔记，结合我在工作中遇到的种种场景，我梳理出了下面这张质量保障体系思维导图，供大家参考。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;思维导图&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.6463314097279472&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ftksfIbzTWgW5o6S5poA9n0WktoeLe0tKwgNoSav87rVERapu0HZOiaTGnvfqrwtAZibZEokvHrNHsk7tgUF057g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1213&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;三大体系&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;组织&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;h4&gt;&lt;strong&gt;&lt;span&gt;愿景&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;所谓的愿景，就是长期规划，我们要到哪里去的问题。一个组织或者团队，是一定要有愿景的。在软件质量保障领域，所谓的愿景概括来说就四个字：保质提效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;保质，就是在日常交付中保障软件质量，并且在长期发展过程中，不断提高软件的质量。如何评估质量是否是稳定且不断提升的，就需要&lt;span&gt;引入评估体系，用事实、结果、背后的分析逻辑和数据来证明&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;提效，很好理解，提高效率。怎么提高效率呢？引入ROI体系，从&lt;span&gt;交付时间、耗用资源、团队成长&lt;/span&gt;方面着手。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;&lt;strong&gt;目标&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;有了愿景，还要将其拆分为不同的目标。&lt;span&gt;行业在变，组织架构在变，因此目标也要跟随整体的变化而调整&lt;/span&gt;。不同的企业在不同阶段有不同的侧重点和诉求。你不能要求一个初创企业要啥啥都有，也不能要求BAT啥都凑合。这是一个平衡和抉择的过程，可以参考CMMI模型来思考这一点。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;&lt;span&gt;规则&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;这里的规则不是强制要求大家一定要做什么，而是为了避免某些方式对团队和企业带来不好的影响。常见的规则比如：周报、信息同步机制、反馈机制&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;&lt;strong&gt;文化&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;谈到文化这一块，一直是很务虚的东西，很多同学对之嗤之以鼻，2020年之前我也是这么想的。20年读了一本书：《重新定义公司：Google是如何运营的》。里面对企业文化这一部分做了很经典的解释：&lt;span&gt;企业文化就是指导员工面临艰难选择时，做正确的选择&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;管理&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;团队管理方面，我将其分为了下面四个体系，每个体系都包含不同的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;相关内容，可参考我之前的文章：&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247484174&amp;amp;idx=1&amp;amp;sn=6cdf3e3a4f9931e021bb779b4b6e17d5&amp;amp;chksm=ce714b52f906c2442f722676f81473d27508e970a897c2082f71c6a6b71a5ee962d7eb17c3bf&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;从技术专家到技术管理，我对管理的思考&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;从技术专家到技术管理，我对管理的思考&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;&lt;strong&gt;业务体系&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;如果团队规模较小，业务也不复杂，可以暂时不用拆分。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是当人数超过10人&amp;amp;业务开始划分不同团队时候，就要考虑做业务拆分了。这里的业务拆分指的是根据组织架构将测试同学分为不同的组，每个组有一个小组长或team leader，提高管理效率，做好&lt;span&gt;信息同步和反馈机制&lt;/span&gt;。&lt;span&gt;避免自己成为团队的瓶颈，从繁杂的管理中抽身出来，去思考并解决更高维度的问题&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;&lt;strong&gt;资源体系&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;在团队管理中，无论是人力、设备还是时间，都可以纳入资源管理体系中。我将其分为了如下三个部分：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;人力模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol ne-level=&quot;1&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;新人目标&lt;/strong&gt;：新人入职如何落地？如何快速适应业务迭代节奏？如何设定合理的目标来达成预期结果？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;转正述职&lt;/strong&gt;：招聘、新人培养都需要成本投入，设定合理明确的转正评估机制，结合上述的新人目标，可以帮助新人更好的落地。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol start=&quot;2&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;能力模型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol ne-level=&quot;1&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;成长模型&lt;/strong&gt;：工作一方面为了金钱物质回报，另一方面也是希望能够借助平台获得自我成长。设定成长目标和模型，可以帮助员工在不同的阶段知道自己该向什么方向努力，达成不同阶段的不同目标，这是&lt;/span&gt;每一个管理者都需要考虑的事情。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;胜任力模型&lt;/strong&gt;：一个团队的组织结构，从初级的倒T型，经过金字塔模型，最终演变成纺锥型。在不同阶段，随着组织结构的演变，处在不同阶段和层级的员工，需要设定不同的级别和胜任评估体系，助力团队跟随公司不断发展，适应组织结构的变化。一般来说，可以从工作经验、技术、业务熟悉度、项目推动能力、沟通协同方面来设定评估指标。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol start=&quot;3&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;资产管理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol ne-level=&quot;1&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;云端资产&lt;/strong&gt;：现在大多数互联网公司，都采用了云服务。对于质量保障团队来说，测试环境及内部自建技术平台涉及的云端资产，都需要通过一定的手段管理起来。当然一般这种事在运维团队，有CMDB体系来进行管理，可进行参考。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;硬件资产&lt;/strong&gt;：这里的硬件资产包括移动端测试机&amp;amp;pad等设备，当然可能也包括用来做兼容测试而采购的相关服务等设施。还有一点，员工办公所使用的包含电脑显示器等设备，一般会有IT部门来专门登记管理。如果没有，建议做好统计，便于员工入离职交接等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;&lt;span&gt;&lt;strong&gt;知识体系&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;这里的知识体系，主要指的是团队内部的能力建设和沉淀，主要包含如下几个方面：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;技术博客：&lt;/strong&gt;无论是工作职场中还是和同行交流中，我一向是比较鼓励大家写技术博客的。这样无论是对个人知识的梳理总结，还是团队的技术能力沉淀都是有很大帮助的。长期以往坚持下来，还能形成品牌向外宣传，这也是吸引优秀候选人的一个方式。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;业务串讲&lt;/strong&gt;：前面提到随着企业的发展，业务规模越来越大也越来越复杂，业务串讲就显得很有必要。优点如下：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol ne-level=&quot;1&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;帮助不同team的同学了解不同的业务，便于日常工作理解；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;遇到不同团队协同工作时，更明确交接的业务边界，提供沟通效率；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;沉淀成业务知识库，可以让其他团队的同学&amp;amp;新入职的同学快速了解，离入职交接也更方便；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol start=&quot;3&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;内部分享&lt;/strong&gt;：这里的内部分享，指的是技术部门内部，上述的技术博客和业务串讲&amp;amp;知识库，都可以作为分享的素材来宣讲。一方面可以让更多的同学了解到不同的知识，另一方面加深团队的影响力，这样有助于日常工作的开展。也能在一定程度上培养团队同学的沟通和表达能力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;外部培训&lt;/strong&gt;：这个主要指下面几方面：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol ne-level=&quot;1&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;联合开源社区，合作举办技术沙龙、座谈会等类似的活动；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重量级的技术大会上做主题分享，主要目的是价值宣导和品牌影响力建设；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;&lt;span&gt;&lt;strong&gt;评估体系&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;如何理解这里的评估体系？围绕上文提到的保质提效相关的点，来分类进行评估。&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;问题管理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol ne-level=&quot;1&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;测试过程中遇到的BUG，分门别类，阶段性的总结梳理，输出质量保障参考手册/SOP；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol start=&quot;2&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;版本管理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol ne-level=&quot;1&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;版本管理主要涵盖每个版本的服务发版次数、冒烟通过率、bug的reopen率、上线质量等因素。每个版本结束，除了向上做汇报，内部的复盘总结优化，也是很重要的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol start=&quot;3&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;项目管理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol ne-level=&quot;1&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这里的项目管理，可以理解为PMO这个岗位做的一些事情，包括进度、风险、资源、deadline等因素。实际上无论是版本发布、和版本迭代同步进行的跨版本需求以及内部的一些独立项目，都可以采用这种方式来管理，总体上还是为了提高资源利用率以及风险前置。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol start=&quot;4&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;效率管理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol ne-level=&quot;1&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;效率管理，我们之前的做法，一方面是通过调查问卷的方式，在部门内部开展调查，获取日常工作中影响工作效率的点，归纳汇总进行专项优化。另一方面，随着团队规模的不断扩大，整体的效率问题也会变成团队成长的一大问题，需要时刻重视。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;专项&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;&lt;strong&gt;自动化体系&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;自动化体系的建设，目前来说在绝大多数稍有规模的互联网公司，都有不同的应用。有UI自动化、APP自动化、接口自动化、单测自动化、埋点自动化以及自动化打包发布校验等方式。最初的目标都是提高效率，降低手工的成本，让工作的个体突出发挥自己的思考能力，而不是手工的体力劳动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在自动化体系建设中，主要需要考虑如下几点：&lt;/span&gt;&lt;/p&gt;&lt;ol ne-level=&quot;1&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;场景&amp;amp;用例&amp;amp;执行：这里需要注意的是场景的覆盖、用例的筛选以及执行效率；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;框架&amp;amp;数据&amp;amp;CICD：人多了，需要注意避免团队内部造轮子，撸很多自动化框架。我个人对这点的理解是有成熟开源框架的，别自己造轮子。内部已有的，评估是否需要优化，而不是推到重构。自动化体系中，CICD是至关重要的一环，别忘记自动化的初衷。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提效&amp;amp;反馈&amp;amp;参与：自动化最终还是要解决的是效率问题，如上文提到的效率管理，需要持续不断的获得反馈，然后改进优化。说到参与，很多公司是自动化和功能测试工程师做了区分，实际上如果为了团队的整体成长，需要全员参与进来，有参与感，员工才能有收获和满足感。否则大部分人只靠工作本身的内容，是很难做到主动提升自己的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;&lt;strong&gt;&lt;span&gt;防资损体系&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;什么叫资损？造成公司&amp;amp;客户资产损失的都算。比如公司发优惠券，多发且被用户使用了，造成公司成本支出。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如用户的优惠券满足场景但无法在支付中使用，用户有了资损，实际上还是公司买单。还有部分舆情方面的东西，比如某个外部消息导致公司上了热搜，外部对公司的评价变差，对企业品牌造成不良影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们之前的做法是线上监控及时告警，专人专群处理。还有线上涉及资损的场景进行针对性校验，尽可能降低资损的成本以及造成的影响。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;质量大盘体系&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;这里的质量大盘，大家理解为一个可视化的监控即可。即把上面我们提到的各项规则和措施，通过数据量化的方式管控起来，便于做决策。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;&lt;span&gt;性能测试体系&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;性能测试体系，由于之前的文章已经详细介绍过，这里不过多赘述，大家可以参考之前的文章。&lt;/span&gt;&lt;span&gt;文章链接：&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247483922&amp;amp;idx=1&amp;amp;sn=b4eae6e7d3a37db02b6afe5c7fec099f&amp;amp;chksm=ce714a4ef906c3587c1d79ef9dfe2dcee6e15d2c6aa9b506f7ff79183cd0e5ad2c8140e5d3ee&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;性能测试体系建设演进之路&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;性能测试体系建设演进之路&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247483922&amp;amp;idx=1&amp;amp;sn=b4eae6e7d3a37db02b6afe5c7fec099f&amp;amp;chksm=ce714a4ef906c3587c1d79ef9dfe2dcee6e15d2c6aa9b506f7ff79183cd0e5ad2c8140e5d3ee&amp;amp;token=282506608&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NDAwMjM1NQ==&amp;amp;mid=2247483922&amp;amp;idx=1&amp;amp;sn=b4eae6e7d3a37db02b6afe5c7fec099f&amp;amp;chksm=ce714a4ef906c3587c1d79ef9dfe2dcee6e15d2c6aa9b506f7ff79183cd0e5ad2c8140e5d3ee&amp;amp;token=282506608&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;&lt;span/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;&lt;strong&gt;稳定性治理体系&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;稳定性是一个很大的范畴，在质量保障体系中稳定性的建设主要集中在如下几点：&lt;/span&gt;&lt;/p&gt;&lt;ol ne-level=&quot;1&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;测试过程监控（如自动化通过率&amp;amp;冒烟通过率&amp;amp;性能容量变化趋势等）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;测试环境稳定性治理（特别是有多套环境多个项目版本交叉使用以及频繁发布）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;线上服务可用性监控（质量保障不仅关注测试环境，线上的稳定性也至关重要）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;写在最后&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;总感觉自己写了很多，又好像有很多内容无法一一表达。关于本篇文章中提到的部分内容，如稳定性治理，会在后续的文章中进行详细介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文仅供参考，请知悉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>f47477f2b1331bfadf7edf15c5691ae6</guid>
<title>和谁在一起，的确很重要</title>
<link>https://toutiao.io/k/tketjuf</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;码农周刊是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;码农周刊是一份专为广大程序员、编程爱好者们打造的 IT 技术周刊。每周发送。&lt;br/&gt;2013 年 9 月 12 日创刊至今，已发送 300 多期，订阅用户超 20 万。&lt;br/&gt;&lt;/span&gt;&lt;span&gt;专业、简单、有用&lt;/span&gt;&lt;span&gt;，是我们一直坚持的办刊宗旨。一路走来，我们见证了不少订阅用户从编程新手进阶成了高级程序员、架构师、CTO……&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;2020 年 4 月，为了给用户提供更优质的服务，我们推出了「&lt;/span&gt;&lt;span&gt;码农周刊VIP会员&lt;/span&gt;&lt;span&gt;」服务。&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;你与 BAT 技术大牛，只差一份「码农周刊VIP会员」的距离！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;VIP会员特权&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 52 期码农周刊VIP会员&lt;span&gt;专属邮件周报&lt;/span&gt;，让你及时掌握技术动向；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 只限VIP会员加入的&lt;span&gt;交流圈子&lt;/span&gt;，让你与技术大牛切磋学习；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. VIP会员独享的&lt;span&gt;工作机会&lt;/span&gt;，为你介绍好公司的好机会；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 更多会员特权，持续更新……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;如何加入「码农周刊VIP会员」？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1. 微信扫描下方二维码，加入码农周刊VIP会员知识星球。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;促销期间，一年仅需 108 元！平均一天花费不到 3 毛！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-cropselx1=&quot;34&quot; data-cropselx2=&quot;356&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;425&quot; data-ratio=&quot;1.0857487922705313&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/t8lpVibticjQ6h6x4EnYInRLic6PibFNWw4zSv28rAxcJu9dumVJF03PwHGOWxOzeJKIsydVa7UJuTo4jOjrct9NZw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;828&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 加入码农周刊VIP会员知识星球后，客服会联系您，请留意知识星球内的私信。&lt;br/&gt;3. 客服向您发送码农周刊VIP会员欢迎邮件，开启您的码农周刊VIP会员之旅。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;心动不如心动，赶快订阅吧！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>900c6afb016e944c3492ae3d954f59b8</guid>
<title>Verilog 预编译</title>
<link>https://toutiao.io/k/jt04mil</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText&quot; articlelinkcardprops=&quot;[object Object]&quot; usegifprops=&quot;[object Object]&quot;&gt;&lt;h2&gt;&lt;b&gt;Verilog 预编译&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Verilog 语言支持&lt;b&gt;宏定义（`define）&lt;/b&gt;，&lt;b&gt;参数 parameter&lt;/b&gt;，&lt;b&gt;局域参数（localparam)&lt;/b&gt;以及&lt;b&gt;`include&lt;/b&gt;等内容。这些数据常量的支持极大方便数字系统设计、仿真与验证。这些参数是预编译的。&lt;/p&gt;&lt;h2&gt;预编译&lt;/h2&gt;&lt;p&gt;所谓预编译就是在系统编译之前，将定义的宏常量，参数等先对系统文件扫描一边，将文件中引用的宏和参数以实际值替代，对`include 文件的引用，将实际文件复制到对应位置，然后才对系统进行编译，这一点和具有编译运行的软件编译处理是一致的，如C语言，C++语言等。&lt;/p&gt;&lt;h2&gt;宏定义&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;`define&lt;/b&gt; 关键字&lt;/h3&gt;&lt;p&gt;宏定义的关键字是`define, 在预编译阶段，&lt;b&gt;`define&lt;/b&gt; 用于文本替换，类似于 C 语言中的 &lt;b&gt;#define&lt;/b&gt;。一旦 &lt;b&gt;`define&lt;/b&gt; 指令被定义，其在整个翻译过程中都会有效。例如，在一个文件中定义：&lt;/p&gt;&lt;p&gt;`define DATA_DW 32   //含义是 DATA_DW=32, 在编写文件时使用`DATA_DW,在系统编译时，首先将所有`DATA_DW 出现的地方都替换成32，然后再编译。&lt;/p&gt;&lt;p&gt;则在另一个文件中也可以直接使用 `DATA_DW。当然这和编译工具的设定有关，建议一个文件中定义的宏只在该文件中使用。&lt;/p&gt;&lt;p&gt;使用宏的好处是，在全局中使用宏定义的常量，将来如果该常量有变化，直接改动宏定义就可以改动所有使用宏的地方。&lt;/p&gt;&lt;p&gt;宏定义也可以是一个表达式方式, 例如：&lt;/p&gt;&lt;p&gt;`define low_pos(w,b) ((w)*64 + (b)*8)&lt;/p&gt;&lt;p&gt;例：&lt;/p&gt;&lt;p&gt;设计文件 mul8.v&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;`define PW 8

module mul8
(
    input  [`PW-1:0] a,
    input  [`PW-1:0] b,
    output [`PW*2-1:0] p
);

assign   p = a * b;

endmodule&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;仿真文件 t&lt;b&gt;b.v&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;`timescale 1 ns/1 ps&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;`define PW 8&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;module tb&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;(&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;);&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;parameter PERIOD = 10 ;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;reg CLK;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;initial &lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;begin&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;CLK = 1&#x27;b0;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;#(PERIOD/2);&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;forever&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;#(PERIOD/2) CLK = ~CLK;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;end&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;reg [`PW-1:0] a, b;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;wire [`PW*2-1:0] p;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;initial &lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;begin&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;a = `PW&#x27;b0;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;b = `PW&#x27;b0;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;end&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;always @(posedge CLK)&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;begin&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;a = a + 1;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;if(a == 2**(`PW)-1 )  //对于求幂运算符**，只能是2的幂，指数部                       //分必须是常量&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;b = b + 1;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;end&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;mul8 mul8_dut&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;(&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;.a  (a),&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;.b  (b),&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;.p  (p)&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;);&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;endmodule &lt;/code&gt;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;`undef&lt;/b&gt; 关键字&lt;/h3&gt;&lt;p&gt;&lt;b&gt;利用`undef&lt;/b&gt; 关键字可以中止当前宏常量的定义。&lt;/p&gt;&lt;p&gt;如&lt;b&gt;： `undef PW&lt;/b&gt;&lt;/p&gt;&lt;p&gt;文件在这条语句之后 就不能再以`PW 替代8 使用。&lt;/p&gt;&lt;h3&gt;`ifdef, `ifndef, `elsif, `else, `endif&lt;/h3&gt;&lt;p&gt;&lt;b&gt;`elsif, `else&lt;/b&gt; 编译指令对于 &lt;b&gt;`ifdef&lt;/b&gt; 指令是可选的，即可以只使用 &lt;b&gt;`ifdef&lt;/b&gt; 和 &lt;b&gt;`endif&lt;/b&gt; 组成一次条件编译指令块。&lt;/p&gt;&lt;p&gt;例：缺省对32位数据处理，如果定义宏，则按宏定义处理&lt;/p&gt;&lt;p&gt;&lt;code&gt;`ifdef   DATA_DW&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;reg   [`DATA_DW-1:0]  data_a;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;reg   [`DATA_DW-1:0]  data_b;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;reg   [`DATA_DW-1:0]  data_c;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;`else&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;reg   [31:0]  data_a;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;reg   [31:0]  data_b;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;reg   [31:0]  data_c;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;`endif&lt;/code&gt;&lt;/p&gt;&lt;p&gt;注： 宏一般在定义时大小写字符都可以使用，而且大小写是区分的，也就是大写字符定义的宏与小写字符定义宏虽然只有大小写之分，却代表了不同的宏&lt;/p&gt;&lt;p&gt;如：&lt;/p&gt;&lt;p&gt;`define   data_w  8 与`define    DATA_W  32 定义的宏，可以分别使用，互不冲突。一般习惯宏都是用大写字母。&lt;/p&gt;&lt;h3&gt;参数 parameter与局部参数localparam&lt;/h3&gt;&lt;p&gt;parameter 与localparam都可以定义参数常量，但使用范围不同：&lt;/p&gt;&lt;p&gt;localparam定义的参数仅限于本module内部使用，模块例化不可调用，相当于局部常量。状态机状态常量定义，而且只能在定义的位置之后使用。&lt;/p&gt;&lt;p&gt;parameter定义的参数不仅能在本文件中使用，还能利用module 例化后起到参数传递的作用。parameter经常在module接口，以及在设计文件中多处使用特定常数的地方使用。&lt;/p&gt;&lt;p&gt;举例：&lt;/p&gt;&lt;p&gt;设计文件  para_fadder.v&lt;/p&gt;&lt;p&gt;&lt;code&gt;module para_fadder&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;#(&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;parameter WDTH = 4&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;(&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;input             ci,&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;input  [WDTH-1:0] a,&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;input  [WDTH-1:0] b,&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;output [WDTH-1:0] sum,&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;output            co&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;);&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;assign {co, sum} = a + b + ci;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;endmodule&lt;/code&gt; &lt;/p&gt;&lt;p&gt;Testbench 文件 tb.v&lt;/p&gt;&lt;p&gt;&lt;code&gt;`timescale 1ns/1ps&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;module tb&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;(&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;);&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;parameter WDTH = 16;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;reg ci;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;reg [WDTH-1:0] a, b;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;wire [WDTH-1:0] sum;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;wire co;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;initial &lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;begin&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;a =&#x27;b0;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;b =&#x27;b0;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;ci = 0;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;#10&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;a =&#x27;d100;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;b =&#x27;d33;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;ci = 0;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;#10&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;a =&#x27;d101;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;b =&#x27;d37;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;ci = 1;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;end&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;para_fadder&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;#(&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;.WDTH(WDTH)&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;para_fadder_dut&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;(&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;.ci  (ci),&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;.a   (a),&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;.b   (b),&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;.sum (sum),&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;.co  (co)&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;);&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;endmodule&lt;/code&gt;&lt;/p&gt;&lt;p&gt; Modelsim仿真波形&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-98e1d6c5a8ddd6a356ea87b0d39e0df6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;599&quot; data-rawheight=&quot;153&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-98e1d6c5a8ddd6a356ea87b0d39e0df6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;599&quot; data-rawheight=&quot;153&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-98e1d6c5a8ddd6a356ea87b0d39e0df6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-98e1d6c5a8ddd6a356ea87b0d39e0df6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;/p&gt;&lt;p&gt;说明： 在设计文件中定义了 参数 WDTH=4，而在例化中传递的参数为16，那么最终在设计文件中的参数的具体数值由传递值决定，本例中WDTH的最终为16，最终例化了16位全加器。如果在例化中没有给参数传递值，则WDTH=4变成缺省值，即例化4位全加器。如例化如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;para_fadder    para_fadder_dut
(
    .ci   (ci),
    .a    (a),
    .b    (b),

    .sum  (sum),
    .co   (co)
);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;将例化成4位全加器。&lt;/p&gt;&lt;p&gt;module中 parameter 的格式如下：&lt;/p&gt;&lt;p&gt;设计文件&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;module para_fadder
#(
    parameter WDTH  = 4，
    parameter WDTH1 = 4    //最后一个参数没有分隔符
)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;多个参数采用逗号 “,”隔开，最后一个参数没有分隔符  。&lt;/p&gt;&lt;p&gt;例化端类似的格式：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;para_fadder
#(
    .WDTH   (WDTH),
    .WDTH1  (WDTH1)
)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果只有一个参数，则为&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;para_fadder
#(
    .WDTH(WDTH)
)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p/&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>93162c5b359ed170a742c133febfa63c</guid>
<title>Kudu 基础原理实践小总结</title>
<link>https://toutiao.io/k/vupg0md</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;h3&gt;Kudu简介&lt;/h3&gt;&lt;p&gt;&lt;span&gt;Hadoop生态系统发展到现在，存储层主要由HDFS和HBase两个系统把持着，一直没有太大突破。在追求高吞吐的批处理场景下，我们选用HDFS，在追求低延迟，有随机读写需求的场景下，我们选用HBase，那么是否存在一种系统，能结合两个系统优点，同时支持高吞吐率和低延迟呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有人尝试修改HBase内核构造这样的系统，即保留HBase的数据模型，而将其底层存储部分改为纯列式存储（目前HBase只能算是列簇式存储引擎），但这种修改难度较大。Kudu的出现解决了这一难题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu是Cloudera开源的列式存储引擎，具有以下几个特点：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;C++语言开发，Kudu 的 API 可以使用 Java 和 C++&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;高效处理类OLAP负载&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;与MapReduce，Spark以及Hadoop生态系统中其他组件进行友好集成&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可与Cloudera Impala集成，替代目前Impala常用的HDFS+Parquet组合&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;灵活的一致性模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;顺序写和随机写并存的场景下，仍能达到良好的性能&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;高可用，使用Raft协议保证数据高可靠存储&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;结构化数据模型&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;Kudu的出现，有望解决目前Hadoop生态系统难以解决的一大类问题，比如：流式实时计算结果的更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;时间序列相关应用，具体要求有：&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;使用场景&lt;/span&gt;&lt;/h3&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;实时数据更新&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时间序列相关的应用(例如APM),海量历史数据查询(数据顺序扫描),必须非常快地返回关于单个实体的细粒度查询(随机读)。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;实时预测模型的应用(机器学习),支持根据所有历史数据周期地更新模型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;span&gt;Kudu基本架构&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.6877168632893824&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpOziaJMf8LbT2Vj1miblRzj1YDCibWt7gz0mpQJyW4LXG51hZk4uiaPTE1A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1441&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu是典型的主从架构。一个Kudu集群由主节点即Master和若干个从节点即Tablet Server组成。Master负责管理集群的元数据（类似于HBase Master），Tablet Server负责数据存储（类似HBase的RegionServer）。在生产环境，一般部署多个Master实现高可用（奇数个、典型的是3个），Tablet Server一般也是奇数个。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;基础概念：&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;开发语言：C++&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Columnar Data Store（列式数据存储）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Read Efficiency（高效读取）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;对于分析查询，允许读取单个列或该列的一部分同时忽略其他列&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于给定的列只包含一种类型的数据，基于模式的压缩比压缩混合数据类型（在基于行的解决案中使用）时更有效几个数量级。结合从列读取数据的效率，压缩允许您在从磁盘读取更少的块时完成查询&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一张table是数据存储在 Kudu 的位置。表具有schema和全局有序的primary key（主键）。table被分成很多段，也就是称为tablets。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个tablet是一张table连续的segment，与其它数据存储引擎或关系型数据库的partition（分区）相似。给定的tablet冗余到多个tablet服务器上，并且在任何给定的时间点，其中一个副本被认为是leader tablet。任何副本都可以对读取进行服务，并且写入时需要在为tablet服务的一组tablet server之间达成一致性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一张表分成多个tablet，分布在不同的tablet server中，最大并行化操作Tablet在Kudu中被切分为更小的单元，叫做RowSets，RowSets分为两种MemRowSets和DiskRowSet，MemRowSets每生成32M，就溢写到磁盘中，也就是DiskRowSet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个tablet server存储tablet和为tablet向client提供服务。对于给定的tablet，一个tablet server充当 leader，其他tablet server充当该 tablet 的follower副本。只有leader服务写请求，然而leader或followers为每个服务提供读请求。leader使用Raft Consensus Algorithm来进行选举 。一个tablet server可以服务多个tablets，并且一个 tablet 可以被多个tablet servers服务着。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该master保持跟踪所有的tablets，tablet servers，Catalog Table 和其它与集群相关的metadata。在给定的时间点，只能有一个起作用的master（也就是 leader）。如果当前的 leader 消失，则选举出一个新的master，使用 Raft Consensus Algorithm来进行选举。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;master还协调客户端的metadata operations（元数据操作）。例如，当创建新表时，客户端内部将请求发送给master。master将新表的元数据写入catalog table，并协调在tablet server上创建 tablet 的过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所有master的数据都存储在一个 tablet 中，可以复制到所有其他候选的 master。tablet server以设定的间隔向master发出心跳（默认值为每秒一次）。master是以文件的形式存储在磁盘中，所以说，第一次初始化集群。需要设定好&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu 使用 Raft consensus algorithm 作为确保常规 tablet 和 master 数据的容错性和一致性的手段。通过 Raft，tablet 的多个副本选举出 leader，它负责接受以及复制到 follower 副本的写入。一旦写入的数据在大多数副本中持久化后，就会向客户确认。给定的一组 N 副本（通常为 3 或 5 个）能够接受最多(N - 1)/2 错误的副本的写入。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;catalog table是Kudu 的 metadata（元数据中）的中心位置。它存储有关tables和tablets的信息。该catalog table（目录表）可能不会被直接读取或写入。相反，它只能通过客户端 API中公开的元数据操作访问。catalog table 存储两类元数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;table schemas, locations, and states（表结构，位置和状态）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现有tablet 的列表，每个 tablet 的副本所在哪些tablet server，tablet的当前状态以及开始和结束的keys（键）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.4969843184559711&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPp3WuhFfXTywwkfMZADhyDNMrricWo8FucFmicbiaWia9zMYxHwCSsgsOcbw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;829&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注意：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;建表的时候要求所有的tserver节点都活着&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;根据raft机制，允许（replication的副本数-）/ 2宕掉，集群还会正常运行，否则会报错找不到ip:7050（7050是rpc的通信端口号），需要注意一个问题，第一次运行的时候要保证集群处于正常状态下，也就是所有的服务都启动，如果运行过程中，允许（replication的副本数-）/ 2宕掉&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;读操作，只要有一台活着的情况下，就可以运行&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.6493975903614457&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpUTzP0nnvfHCQ2OTX2zlHJv7XLiad2ujFmY1LrmjibQ95ahFzEXguaShQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;830&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图显示了一个具有三个 master 和多个tablet server的Kudu集群，每个服务器都支持多个tablet。它说明了如何使用 Raft 共识来允许master和tablet server的leader和follow。此外，tablet server 可以成为某些 tablet 的 leader，也可以是其他 tablet follower。leader以金色显示，而 follower 则显示为蓝色。&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;测试：&lt;br/&gt;7个tablet server&lt;br/&gt;ssd硬盘，5分钟manul flush到kudu 1000万数据&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;总结：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;KUDU分区数必须预先预定。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在内存中对每个Tablet分区维护一个MemRowSet来管理最新更新的数据，默认是1G刷新一次或者是2分钟。后Flush到磁盘上形成DiskRowSet，多个DiskRowSet在适当的时候进行归并处理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;和HBase采用的LSM（LogStructured Merge，很难对数据进行特殊编码，所以处理效率不高）方案不同的是，Kudu对同一行的数据更新记录的合并工作，不是在查询的时候发生的（HBase会将多条更新记录先后Flush到不同的Storefile中，所以读取时需要扫描多个文件，比较rowkey，比较版本等，然后进行更新操作），而是在更新的时候进行，在Kudu中一行数据只会存在于一个DiskRowSet中，避免读操作时的比较合并工作。那Kudu是怎么做到的呢？对于列式存储的数据文件，要原地变更一行数据是很困难的，所以在Kudu中，对于Flush到磁盘上的DiskRowSet（DRS）数据，实际上是分两种形式存在的，一种是Base的数据，按列式存储格式存在，一旦生成，就不再修改，另一种是Delta文件，存储Base数据中有变更的数据，一个Base文件可以对应多个Delta文件，这种方式意味着，插入数据时相比HBase，需要额外走一次检索流程来判定对应主键的数据是否已经存在。因此，Kudu是牺牲了写性能来换取读取性能的提升。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;更新、删除操作需要记录到特殊的数据结构里，保存在内存中的DeltaMemStore或磁盘上的DeltaFIle里面。DeltaMemStore是B-Tree实现的，因此速度快，而且可修改。磁盘上的DeltaFIle是二进制的列式的块，和base数据一样都是不可修改的。因此当数据频繁删改的时候，磁盘上会有大量的DeltaFiles文件，Kudu借鉴了Hbase的方式，会定期对这些文件进行合并。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5133630289532294&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpFDYz1hTI3sPnJYdqzYBOPymLAqW2WKgvKyTx8MtSNkn2qlE6W6trcw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;898&quot;/&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;既然存在Delta数据，也就意味着数据查询时需要同时检索Base文件和Delta文件，这看起来和HBase的方案似乎又走到一起去了，不同的地方在于，Kudu的Delta文件与Base文件不同，不是按Key排序的，而是按被更新的行在Base文件中的位移来检索的，号称这样做，在定位Delta内容的时候，不需要进行字符串比较工作，因此能大大加快定位速度，但是无论如何，Delta文件的存在对检索速度的影响巨大。因此Delta文件的数量会需要控制，需要及时的和Base数据进行合并。由于Base文件是列式存储的，所以Delta文件合并时，可以有选择性的进行，比如只把变化频繁的列进行合并，变化很少的列保留在Delta文件中暂不合并，这样做也能减少不必要的IO开销。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;除了Delta文件合并，DRS自身也会需要合并，为了保障检索延迟的可预测性（这一点是HBase的痛点之一，比如分区发生Major Compaction时，读写性能会受到很大影响），Kudu的compaction策略和HBase相比，有很大不同，kudu的DRS数据文件的compaction，本质上不是为了减少文件数量，实际上Kudu DRS默认是以32MB为单位进行拆分的，DRS的compaction并不减少文件数量，而是对内容进行排序重组，减少不同DRS之间key的overlap（重复），进而在检索的时候减少需要参与检索的DRS的数量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.43670886075949367&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPptdIPTua6ibJahMNmAOAnd1p7vwEIQFL6XD7FtynJJfAnbkCujOibFYKg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;948&quot;/&gt;&lt;img data-ratio=&quot;0.32484725050916496&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpcMtRQApQgSCeH7SS2hicFUvjJp8H6EvZibKqFRfkgstNl9S1C1FUSn5Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;982&quot;/&gt;&lt;/p&gt;&lt;h3&gt;原理&lt;/h3&gt;&lt;h4&gt;table与schema&lt;/h4&gt;&lt;p&gt;&lt;span&gt;kudu设计是面向结构化存储,因此kudu需要用户在建表时定义它的schema信息,这些schema信息包含:列定义(含类型),Primary Key定义（用户指定的若干个列的有序组合）数据的唯一性，依赖于用户所提供的Primary Key中的Column组合的值的唯一性。Kudu提供了Alter命令来增删列，但位于Primary Key中的列是不允许删除的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从用户角度来看,kudu是一种存储结构化数据表的存储系统,一个kudu集群中可以定义任意数量table,每个table都需要定义好schema,每个table的列数是确定的,每一列都需要名字和类型,表中可以把一列或者多列定义为主键,kudu更像关系型数据库,但是不支持二级索引。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;Kudu存储模型&lt;/h3&gt;&lt;p&gt;&lt;span&gt;Kudu的底层数据文件的存储，未采用HDFS这样的较高抽象层次的分布式文件系统，而是自行开发了一套可基于Table/Tablet/Replica视图级别的底层存储系统主要是&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.快速的列式查询&lt;br/&gt;2.快速的随机更新&lt;br/&gt;3.更为稳定的查询性能保障&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.45164835164835165&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpboBpyP0ibfke1sDtlcFTW5OM6fKlEvgdBmEiaoAm6xr8A87sbobZ8FicQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1820&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一张table会分成若干个tablet，每个tablet包括MetaData元信息及若干个RowSet。RowSet包含一个MemRowSet及若干个DiskRowSet，DiskRowSet中包含一个BloomFile、AdhocIndex、BaseData、DeltaMem及若干个RedoFile和UndoFile( UndoFile一般情况下只有一个 )&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RowSet组成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MemRowSet&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;用于新数据insert及已在MemRowSet中的数据的更新，一个MemRowSet写满后会将数据刷到磁盘形成若干个DiskRowSet。默认是1G或者或者120S&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;DiskRowSet&lt;/p&gt;&lt;pre&gt;&lt;code&gt;用于老数据的变更，后台定期对DiskRowSet做compaction，以删除没用的数据及合并历史数据，减少查询过程中的IO开销。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;BloomFile&lt;/p&gt;&lt;pre&gt;&lt;code&gt;根据一个DiskRowSet中的key生成一个bloom filter，用于快速模糊定位某个key是否在DiskRowSet中。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;AdhocIndex&lt;/p&gt;&lt;pre&gt;&lt;code&gt;是主键的索引，用于定位key在DiskRowSet中的具体哪个偏移位置&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;BaseData&lt;/p&gt;&lt;pre&gt;&lt;code&gt;是MemRowSet flush下来的数据，按列存储，按主键有序。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;UndoFile&lt;/p&gt;&lt;pre&gt;&lt;code&gt;是基于BaseData之前时间的历史数据，通过在BaseData上apply UndoFile中的记录，可以获得历史数据。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;RedoFile&lt;/p&gt;&lt;pre&gt;&lt;code&gt;是基于BaseData之后时间的变更记录，通过在BaseData上apply RedoFile中的记录，可获得较新的数据。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;DeltaMem&lt;/p&gt;&lt;pre&gt;&lt;code&gt;用于DiskRowSet中数据的变更，先写到内存中，写满后flush到磁盘形成&lt;br/&gt;RedoFile&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;MemRowSets与DiskRowSets的区别：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.48534798534798534&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpGwI9uxEv6kAqZdgLPUibpuHQVcoWNSWlGkOduEfbdr1N4qN17bvpFwQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1092&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;HBase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.4836488812392427&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpiaDX0XdqCSQt4z5eVyufMoN41o282prRfibjFOshoiaT1zXia6BmrZribjQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1162&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对比可知,MemRowSets中数据Flush磁盘后,形成DiskRowSets,DiskRowSets中数据32M大小为单位,按序划分一个个DiskRowSet,DiskRowSet中的数据按照Column进行组织,类比Parquet,这是Kudu可支持一些分析性查询的基础,每一个Column存储在一个相邻的数据区域,而这个数据区域进一步细分为一个个小Page单元,与hbase的File中Block类似,对于每个Column Page可以采用一些Encoding算法,以及通用的Compression算法.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于数据的更新和删除,Kudu与hbase蕾西,通过增加一条新记录来描述数据更新和删除,虽然对于DiskRowSet不可修改,Kudu将DiskRowSet划分两个部分,BaseData,DeltaStores,BaseData负责存储基础数据,DeltaStore负责存储BaseData中变更数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.6632947976878613&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpAib99cKNRJiaN69fsjtCKTicrLyDjNh4wnB1KHuU0bHf0kL207FunFvAA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1384&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据从 MemRowSet 刷到磁盘后就形成了一份 DiskRowSet（只包含 base data），每份DiskRowSet 在内存中都会有一个对应的 DeltaMemStore,负责记录此 DiskRowSet 后续的数据变更映射到每个 row_offset 对应的数据变更。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DeltaMemStore 数据增长到一定程度后转化成二进制文件存储到磁盘，形成一个 DeltaFile，随着base data 对应数据的不断变更，DeltaFile 逐渐增长。下图是DeltaFile生成过程的示意图（更新、删除）。DeltaMemStore 内部维护一个 B-树索引.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.7447973713033954&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpS5sfMuG3lqnXtFhz53FxjXxWM9z70S8nsA5UcJEawo9luWyic2H0HLQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;913&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Delta数据部分包含REDO与UNDO两部分：这里的REDO与UNDO与关系型数据库中的REDO与UNDO日志类似（在关系型数据库中，REDO日志记录了更新后的数据，可以用来恢复尚未写入DataFile的已成功事务更新的数据。而UNDO日志用来记录事务更新之前的数据，可以用来在事务失败时进行回滚），但也存在一些细节上的差异：&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;tablet发现过程&lt;/h3&gt;&lt;p&gt;&lt;span&gt;Kudu客户端无论在执行写入还是读操作,先从master获取tablet位置信息,这个过程为tablet发现。当创建Kudu客户端时，其会从主服务器上获取tablet位置信息，然后直接与服务于该tablet的服务器进行交谈,为了优化读取和写入路径,客户顿将保留该信息的本地缓存,防止每一个请求都要查询tablet位置信息,随着时间推移,并且当写入被发送不再是tablet的leader服务器时,被拒绝,然后客户顿通过查询主服务器发现新领导者位置来更新缓存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5323819978046103&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPp0DseAMphGbqOlArs8b0CoO1H1NibV1OT0mxMSEDibr1yh8FmiapTSSVyQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1822&quot;/&gt;&lt;/p&gt;&lt;h3&gt;Kudu目标：&lt;/h3&gt;&lt;p&gt;&lt;span&gt;按照cloudera的想法，kudu的出现是为了解决，hbase,parquet不能兼顾分析和更新的需求，所以需要一个新的存储引擎可以同时支持高吞吐的分析应用以及少量更新的应用。cloudera 的设计目标是：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在扫描和随机访问两种场景下都有很强的性能，帮助客户简化混合架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;高cpu利用率&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;高io效率充分利用现代存储&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;支持数据原地更新&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;支持双活复制集群&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;kudu核心机制：&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;模仿数据库，以二维表的形式组织数据，创建表的时候需要指定schema。所以只支持结构化数据。&lt;br/&gt;&lt;br/&gt;每个表指定一个或多个主键。&lt;br/&gt;&lt;br/&gt;支持insert/update/delete，这些修改操作全部要指定主键。&lt;br/&gt;&lt;br/&gt;read操作，只支持scan原语。&lt;br/&gt;&lt;br/&gt;一致性模型，默认支持snapshot ，这个可以保证scan和单个客户端 read-you-writes一致性保证。更强的一致性保证，提供manually propagate timestamps between clients或者commit-wait。&lt;br/&gt;&lt;br/&gt;cluster类似hbase简单的M-S结构，master支持备份。&lt;br/&gt;&lt;br/&gt;单个表支持水平分割，partitions叫tablets，单行一定在一个tablets里面，支持范围，以及list等更灵活的分区键。&lt;br/&gt;&lt;br/&gt;使用Raft 协议，可以根据SLA指定备份块数量。&lt;br/&gt;&lt;br/&gt;列式存储&lt;br/&gt;&lt;br/&gt;delta flushes，数据先更新到内存中，最后在合并到最终存储中，有专门到后台进程负责。&lt;br/&gt;&lt;br/&gt;Lazy Materialization ，对一些选择性谓词，可以帮助跳过很多不必要的数据。&lt;br/&gt;&lt;br/&gt;支持和MR/SPARK/IMPALA等集成，支持Locality ，Columnar Projection ，Predicate pushdown 等。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;kudu数据读写、更新&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;读&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.32710280373831774&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPp4O3V6gr5KUqibesf6Zt5mxlY4lVkAQLSIpgaBtrRv1Q9emydIg6kjRg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1177&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;先根据要扫描数据的主键范围，定位到目标的Tablets，然后读取Tablets 中的RowSets，在读取每个RowSet时，先根据主键过滤要scan范围，然后加载范围内的BaseData，再找到对应的DeltaMemStores，应用所有变更，最后union上MemRowSet中的内容，返回数据给Client。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;写&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.36863543788187375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpMxk1Ag3t0y4OwsNicribAuFLKPvxycqicjCuk8mTias7mP3ZbBsZ1ibgsrQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1964&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当CLient请求写数据时，先根据主键从Master获取要访问的目标Tablets，然后依次到对应的Tablet获取数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为kudu表存在主键约束，所以需要进行主键是否已经存在的判断,这里涉及到之前说的索引结构对读写的优化,一个Tablet中存在多个RowSets,为了提升性能,尽可能减少扫描RowSets数量，首先，我们先通过每个 RowSet 中记录的主键的（最大最小）范围，过滤掉一批不存在目标主键的RowSets，然后在根据RowSet中的布隆过滤器，过滤掉确定不存在目标主键的 RowSets，最后再通过RowSets中的 B-树索引，精确定位目标主键是否存在。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果主键已经存在，则报错（主键重复），否则就进行写数据（写MemRowSet）。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;更新&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.45625692137320045&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpmZickv17FnJibc3j0yK2coNicpWeZGC9YeSOArAHmlM73cYLyM30XkP9A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1806&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据更新的核心是定位到待更新数据的位置，这块与写入的时候类似，就不展开了，等定位到具体位置后，然后将变更写到对应的DeltaMemStore 中。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;kudu的模式设计&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;基于HTAP方式&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;kudu是基于hbase-hdfs之间,满足高并发的随机读写,兼顾大规模分析处理,具有OLTP以及OLAP特征,因此是典型的HTAP(在线事务处理/在线分析处理混合模式) 早期&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.42424242424242425&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPptk6NnNEgEEZsm3leGtibgcy3cIMncojbiab48QlPgQE5e3IaJ5A0pVrQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;594&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于将OLTP以及OLAP拆分,事务性应用和分析型应用分开,但是分析型应用无法获取最新数据,OLTP横向扩展性不足,维护一套系统复杂度很高&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lambda架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.47344110854503463&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpaB8KNtY3feEQV62pj2ZEVwAOAfUQfjCmKoibianval6bppHQCuVyejFQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;866&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lambda架构将工作负载分为实时层和批处理层，我们是用实施层检索和分析最新的数据，使用批处理层分析历史数据。这样会带来两个特别的问题,两套系统、两份代码，开发、运维、测试都很复杂,整个处理链条中有一处出现问题就需要重跑数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu设计模式&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;非常易于跟其他组件整合以支持SQL或者进行分布式计算,非常利于从其他关系型数据库迁移数据,数据的读写均匀分散到每个Tablet Server，以充分挖掘集群的潜力（受分区设计影响）,扫描时读取查询所需的最少数据量（主要受主键设计影响，但分区设计也会起到重要作用）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好的shema设计取决于要处理数据的特征、对数据的操作以及集群的拓扑结构。Schema设计对于kudu集群性能最大化来说是最重要的事情。shema设计包含三大块：&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;列设计&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;每个列选择合适的类型、编码和压缩方式&lt;br/&gt;Kudu的每个列都必须指定明确的数据类型的，非主键可以为null，目前支持的数据类型如下：&lt;/span&gt;&lt;img data-ratio=&quot;0.5405960945529291&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpIIcZtM2PumeHHvowVNKkBLW85q5A5g5v0T32ByajDGVFxwCgNeZ62g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1946&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu利用强类型列和列式存储格式来提供高效的编码和序列化。为了充分利用这些功能，应将列指定为适当的类型,而不是使用字符串或二进制列来模拟“无模式”表。除了编码之外,Kudu还允许在每列的基础上指定压缩&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;同HBase不同，kudu没有提供version和timestamp来跟踪行的变化,如果需要的话，需要自行设计一列&lt;/span&gt;&lt;/h4&gt;&lt;h4&gt;&lt;span&gt;Decimal类型&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;decimal是具有固定刻度和精度的十进制数字类型，适合于财务等算术运算,（float与double不精确有舍入行为）。decimal类型对于大于int64的整数和主键中具有小数值的情况也很有用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;精度：表示该列可以表示的总位数，与小数点的位置无关。此值必须介于1和38之间，并且没有默认值。例如，精度为4表示最大值为9999的整数值，或者表示最多99.99带有两个小数位值。您还可以表示相应的负值，而不用对精度进行任何更改。例如，-9999到9999的范围仍然只需要4的精度。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;刻度：表示小数位数。该值必须介于0和精度之间。刻度为0会产生整数值，没有小数部分。如果 精度和刻度相等，则所有数字都在小数点后面。例如，精度和刻度等于3的小数可以表示介于-0.999和0.999之间的值&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;decimal列类型编码默认&lt;br/&gt;性能考虑：Kudu将每个值存储在尽可能少的字节中，具体取决于decimal指定的精度,。因此，不建议为了方便使用最高精度。这样做可能会对性能，内存和存储产生负面影响&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在编码和压缩之前:&lt;br/&gt;精度为9或更小的十进制值以4个字节存储。&lt;br/&gt;精度为10到18的十进制值以8个字节存储。&lt;br/&gt;精度大于18的十进制值以16个字节存储。&lt;br/&gt;alter命令不能修改的decimal列的精度和刻度。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;列编码&lt;/h4&gt;&lt;p&gt;数据类型-编码对照表&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.30847145488029465&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpWCc25523GlehqdicYrTZPMUQ3RITA3uGm66ESp32rLIPibU7wV0MFPgw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1086&quot;/&gt;&lt;/p&gt;&lt;p&gt;编码&lt;/p&gt;&lt;p&gt;Plain&lt;/p&gt;&lt;pre&gt;&lt;code&gt;数据以其自然格式存储&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Bitshuffle&lt;/p&gt;&lt;pre&gt;&lt;code&gt;重新排列一个值块以存储每个值的最高有效位，然后是第二个最高有效位，依此类推。最后，结果进行LZ4压缩。如果值重复的比较多，或者按主键排序时值的变化很小，Bitshuffle编码是一个不错的选择。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;run length&lt;/p&gt;&lt;pre&gt;&lt;code&gt;对连续的重复值采用压缩存储，主要是通过只存储值和个数。该编码对按主键排序时具有许多连续重复值的列有效。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;dictionary&lt;/p&gt;&lt;pre&gt;&lt;code&gt;创建一个字典存放所有的值，每个列值使用索引进行编码存储。如果值的个数较少，这种方式比较有效。如果RowSet的列值由于唯一值的数量过多而无法&lt;br/&gt;压缩，则Kudu将透明地退回到Plain编码。这在flush期间进行评估计算&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;prefix&lt;/p&gt;&lt;pre&gt;&lt;code&gt;在连续的列值中对公共前缀进行压缩。对于有公共前缀的值或主键的第一列有效，因为tablet中的行是通过对主键排序并存储的。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;&lt;span&gt;列压缩&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;Kudu允许列使用LZ4、Snappy或zlib压缩编解码器进行压缩。如果减少存储空间比扫描性能更重要，请考虑使用压缩,每个数据集的压缩方式都不同，但一般来说LZ4是性能最佳的编解码器，而zlib空间压缩比最大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;默认情况下，使用BitLuffle编码的列固有地使用LZ4压缩进行压缩(不建议修改)，其他编码默认不进行压缩。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;主键设计&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;每个Kudu表必须声明由一列或多列组成的主键。与RDBMS主键一样，Kudu主键强制执行唯一性，约束。尝试插入具有与现有行相同的主键值的行将导致重复键错误。主键列必须是非可空的，并且不可以是boolean，float或double类型。表创建指定主键后，主键中的列集就不能更改。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;与RDBMS不同，Kudu不提供列的自增，因此应用程序必须提供完整的主键，删除和更新时必须指定完整主键。Kudu本身不支持范围删除或更新。即都是通过主键完成操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主键值无法修改，但是可以删除后重新插入来变相实现。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;主键索引&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;Kudu中只有主键才会被索引，没有二级索引。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;扫描Kudu行时，在主键列上使用等于或范围谓词来找行性能最佳，非主键列在数据量大的情况下性能不好，建议把查询用到的列尽量设置为主键列&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主键索引优化可以使扫描跳过个别Tablet，要想使扫描操作跳过很多Tablet需要借助分区设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主键索引是有序的，如果主键有多列则按照组合排序，即先按第一列排序，第一列一样则按第二列，排序，以此类推&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;时间戳主键回填问题&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;回填场景&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;kudu每次插入数据的时候会根据主键索引查找主键,判断主键是否存在来决定插入还是报错&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1.实时插入&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;数据产生立马就从数据源采集然后入库到Kudu，及时考虑有一段时间的延迟时间戳的范围也很小。这就意味着只有很小范围的主键是“热”的，它们会被频繁使用因此会被缓存在内存里，检查主键唯一性的操作会非常快，入库速度可以轻松达到百万条/秒。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2.导入历史数据(回填)&lt;/p&gt;&lt;pre&gt;&lt;code&gt;有些场景下我们需要将历史数据一次性导入Kudu，这个时间跨度可能很大，每插入一行都可能命中主键索引的冷数据，该部分主键索引存储在磁盘上，磁盘寻道和IO读写将会瞬间暴增，入库速度极有可能降低到数千条/秒&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;3.如何解决回填性能问题&lt;/p&gt;&lt;pre&gt;&lt;code&gt;使主键更具可压缩性主键压缩更小，则相同内存能够被缓存的主键索引就更多，从而减少磁盘IO&lt;br/&gt;使用SSD，随机寻道要比机械旋转磁盘快几个数量级,更改主键结构，以使回填写入命中连续的主键范围&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;分区设计&lt;/h3&gt;&lt;p&gt;&lt;span&gt;kudu中的表被分成很多tablet分布在多个tserver上，每一行属于一个tablet，行划分到哪个tablet由分区决定，分区是在表创建期间设置的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;写入频繁时，考虑将写入动作平衡到所有tablet之间能够有效降低单个tablet的压力，对于小范围扫描操作比较多的情况，如果所扫描的数据都为一个tablet上则可以提高性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;kudu没有默认分区，建议读写都较重的table可以设置和tserver服务器数量相同的分区数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;kudu提供两种类型的分区：范围分区和哈希分区。表可以有多级分区，组合使用范围和哈希或者多个哈希组合使用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分区设计好坏由场景+三个维度去考量：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;1.是否是读热点&lt;br/&gt;2,是否写热点&lt;br/&gt;3.Tablet可扩展性&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;span&gt;范围分区&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;Kudu允许在运行时动态添加和删除范围分区，而不会影响其他分区的可用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;删除分区将删除属于该分区的平板电脑以及其中包含的数据，后续插入到已删除的分区中将失败。可以添加新分区，但它们不得与任何现有范围分区重叠。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu允许在单个事务更改表操作中删除和添加任意数量的范围分区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;动态添加和删除范围分区对于时间序列特别有用。随着时间的推移，可以添加范围分区以覆盖即将到来的时间范围。例如，存储事件日志的表可以在每个月开始之前添加月份分区，以便保存即将发生的事件,可以删除旧范围分区,根据需要有效的删除历史数据。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;哈希分区&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;哈希分区按哈希值将行分配到存储桶中的一个。在单级散列分区表中，每个桶只对应一个tablet，在表创建期间设置桶的数量。通常，主键列用作要散列的列，但与范围分区一样，可以使用主键列的任何子集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当不需要对表进行有序访问时，散列分区是一种有效的策略。散列分区对于在tablet之间随机写入非常有效，这有助于缓解热点和不均匀的tablet大小。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;多级分区&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;Kudu允许表在单个表上组合多个级别的分区。零个或多个哈希分区可以与范围分区组合。除了各个分区类型的约束之外，多级分区的唯一附加约束是多级哈希分区不能散列相同的列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果使用正确，多级分区可以保留各个分区类型的好处，同时减少每个分区类型的缺点。多级分区表中的tablet总数是每个级别中分区数的乘积。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;修剪分区&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;当通过扫描条件能够完全确定分区的时候，kudu就会自动跳过整个分区的扫描要确定哈希分区，扫描条件必须包含每个哈希列的等值判定条件。多级分区表的扫描可以单独利用每一级的分区界定。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;分区案例&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;CREATE TABLE metrics (&lt;br/&gt; host STRING NOT NULL, -- 主机&lt;br/&gt; metric STRING NOT NULL, -- 度量指标&lt;br/&gt;  time INT64 NOT NULL, -- 时间戳&lt;br/&gt; value DOUBLE NOT NULL, -- 值&lt;br/&gt; PRIMARY KEY (host, metric, time), -- 主键&lt;br/&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;1.采用范围分区&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对time列进行范围分区，假如每年对应一个分区，数据包括2014，2015和2016，至少可以使用两种分区方式：有界范围分区和无界范围分区。但是如果后续时间不断增大,导致一个数据写入最后一个tablet中,导致tablet太大,无法容纳单个tablet&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2.采用哈希分区&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;host和 metric列上的哈希分区为四个桶。与之前的范围分区示例不同，此分区策略将均匀地在表中的所有tablet上进行写入，这有助于整体写入吞吐量。扫描特定host和metric可以通过指定等式来利用分区修剪,将扫描的tablet数量减少到一个。使用纯哈希分区策略时要注意的一个问题是，随着越来越多的数据插入表中，tablet可能会无限增长。最终tablet将变得太大，无法容纳单个tablet服务器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.哈希+范围组合分区&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;哈希分区可以最大限度地提高写入吞吐量，而范围分区可以避免无限制的tablets增长问题。这两种策略都可以利用分区修剪来优化不同场景下的扫描。使用多级分区，可以将这两种策略结合起来，以获得两者的好处，同时最大限度地减少每种策略的缺点&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.双哈希组合分区&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要没有共同的哈希列，Kudu就可以在同一个表中支持任意数量的散列分区级别。在上面的示例中，表被host散列为4个桶，并将散列分区metric为3个桶，产生12个tablet。尽管在使用此策略时，写入将倾向于在所有Tablet中传播，但与多个独立列上的散列分区相比，它更容易出现热点，因为单个主机或度量标准的所有值将始终属于单个tablet。扫描可以分别利用host和metric列上的等式谓词来修剪分区。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多级散列分区也可以与范围分区相结合，从逻辑上增加了分区的另一个维度。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;模式变更&lt;/h3&gt;&lt;p&gt;Kudu1.10.0能够支持的模式更改:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;1.重命名表&lt;br/&gt;2.重命名主键列&lt;br/&gt;3.重命名，添加或删除非主键列&lt;br/&gt;4,添加和删除范围分区&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;局限性&lt;/h3&gt;&lt;p&gt;Kudu目前有一些已知的局限性可能会影响到架构设计&lt;/p&gt;&lt;p&gt;列数&lt;/p&gt;&lt;pre&gt;&lt;code&gt;默认情况下，Kudu不允许创建超过300列的表。我们建议使用较少列的架构设计以获得最佳性能。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;cell大小&lt;/p&gt;&lt;pre&gt;&lt;code&gt;在编码或压缩之前，单个单元不得大于64KB。在Kudu完成内部复合密钥编码之后，构成复合密钥的单元限制为总共16KB。插入不符合这些限制的行将导致错误返回给客户端&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;行大小&lt;/p&gt;&lt;pre&gt;&lt;code&gt;虽然单个单元可能高达64KB，而Kudu最多支持300列，但建议单行不要大于几百KB。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;有效标识符&lt;/p&gt;&lt;pre&gt;&lt;code&gt;表名和列名等标识符必须是有效的UTF-8序列且不超过256个字节。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;主键值不可变&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Kudu不允许更新主键列得值。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;不可更改主键列&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Kudu不允许您在创建表后修改主键列&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;不可更改的分区&lt;/p&gt;&lt;pre&gt;&lt;code&gt;除了添加或删除范围分区之外，Kudu不允许您在创建后更改表的分区方式。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;不可改变的列类型&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Kudu不允许更改列的数据类型。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;分区拆分&lt;/p&gt;&lt;pre&gt;&lt;code&gt;创建表后，无法拆分或合并分区.&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;总结&lt;/h3&gt;&lt;p&gt;分区&lt;/p&gt;&lt;pre&gt;&lt;code&gt;一般哈希+范围分区组合在一起,只有范围分区的情况极少，因为不能避免写热点，除非有哈希分区，典型的例子就是时间序列。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;大对象&lt;/p&gt;&lt;pre&gt;&lt;code&gt;string, binary在未压缩之前不能大于64K，虽然有配置可以调大这个值，但千万不要这么做，避免出现未知错误。&lt;br/&gt;如果确实要存储超过64K的JSON、XML大对象，有两个办法：&lt;br/&gt;1.先对json、XML压缩再存储，编码方式设置为Plain且关闭压缩；&lt;br/&gt;2.如果远远超过64K，则可以把对象保存到HBase或者HDSF中，然后再去Kudu这边保存该对象的&quot;外键&quot;，即HBase的Rowkey、HDFS的路径。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;decimal（十进制数）&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Kudu1.7开始的版本推荐用decimal代替float和double，且可以出现在主键中（float和double就不可以），查询性能更佳，且更适合算数运算&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;不重复的字符串&lt;/p&gt;&lt;pre&gt;&lt;code&gt;如果一个表的主键只有一个string列推荐采用Prefix压缩；如果是多个string列构成主键，则推荐Plain编码+LZ4压缩&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;压缩&lt;/p&gt;&lt;pre&gt;&lt;code&gt;bitshuffle编码的列会自动使用LZ4压缩进行压缩，其他编码的列可以根据情况选择是否采用LZ4压缩，LZ4通常比Snappy快。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;对象命名&lt;/p&gt;&lt;pre&gt;&lt;code&gt;表名和列名都小写可以避免混乱（Impala不区分大小写，API操作区分大小写）。表名必须唯一，如果在Impala中创建内部Kudu表，则表名会默认加上前缀，如impala:default.person&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;列的数量&lt;/p&gt;&lt;pre&gt;&lt;code&gt;列数不能超过300个，如果你在迁移数据时确实有300个以上的列，则可以拆分为多个表，每个表都要保留主键，以便可以通过视图将它们合并在一起。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;kudu优化&lt;/h3&gt;&lt;h4&gt;机架感知&lt;/h4&gt;&lt;p&gt;&lt;span&gt;Kudu可以知道每个Tablet Server处于哪个数据中心的哪个机架上,副本的负载均衡策略就可以考虑更全面,避免一个tablet的多个副本负载在同一机架,防止机架故障时tablet不可用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.7684210526315789&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpLAE2vUWLE5XgjvwXas41XsXDp66hS2HjyvAA2TcreRNzibZQHhTlMAg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;665&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图中，L0-L2是三个机架，TS0 -TS5是5台Tablet Server，有两张表：&lt;br/&gt;A表(副本因子=3)，包含A0-A3四个tablets&lt;br/&gt;B表(副本因子=5)，包含B0-B2三个tablets&lt;br/&gt;如果Kudu配置了机架感知，它就会发现上面的tablet分布违背了相关规则：&lt;br/&gt;副本A0.0和A0.1构成了大多数副本（三分之二），并且位于相同的位置/ L0中，一旦L0机架电源或者交换机故障，将只有L1上的A0.2一个tablet副本可用且无法选择出leader（根据Raft协议必须 n/2+1 个副本正常才可以选举，n=总副本数）&lt;br/&gt;B表的大多数副本集中在TS0-TS4，而TS5非常空闲，在即考虑机架分布式由考虑负载均衡的前提下，需要把B表的相关副本往TS5挪一挪&lt;br/&gt;经过手工负载均衡，负载可能会变成如下样子&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.7462006079027356&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpR3GUwz6K4UqOh4mJTP1xnZnaMSvlyUj3FR8PBBbXO8n8usB2ibLyMCg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;658&quot;/&gt;&lt;/p&gt;&lt;h4&gt;透明分层存储管理方案&lt;/h4&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;存储选择方法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;Kudu是为快速数据上的快速分析场景而生的，但是Kudu的成本并不低，且扩展性并没有那么好（tserver的个数不能太多）&lt;br/&gt;HDFS旨在以低成本实现无限的可扩展性。它针对数据不可更改的面向批处理的场景进行了优化，当使用Parquet文件格式，可以以极高的吞吐量和效率访问结构化数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于数据比较小且不断变化的数据（例如维表）通常全部存放到Kudu当数据不会超过Kudu的扩展范围限制，且能够从Kudu的独特功能中受益时（快速变化、快速分析），通常作为大表保存在Kudu。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当数据量非常大，面向批处理且基本不太可能变更的情况下首选以Parquet格式将数据存储在HDFS中（冷数据）&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;基于滑动窗口的透明存储管理方案&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span&gt;当需要两个存储层的优势时，滑动窗口模式是一个有用的解决方案。该方案的主要思路是：&lt;br/&gt;使用Impala创建2张表：Kudu表和Parquet 格式的HDSF表这两张表都是按照时间分区的表，分区粒度取决于数据在Kudu表和HDSF表之间迁移的频率，一般是按照年或者月或者日分区，特殊情况下可以更细粒度在Impala另外创建一个统一视图，并使用where字句定义一个边界，由该边界决定哪些数据该从哪个表读取Kudu中变冷的数据分区会定期的被刷写到HDFS（Parquet ）数据刷写之后，在HDFS表新增分区、使用原子的ALTER VIEW 操作把视图的边界往前推移&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优点：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;流式数据可立即查询&lt;br/&gt;可以更新迟到的数据或进行手动更正&lt;br/&gt;HDFS中存储的数据具有最佳大小，可提高性能并防止小文件降低成本&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;2.数据从Kudu迁到HDFS的过程&lt;br/&gt;数据从Kudu迁移到HDFS需要经过下面两个步骤，该过程需要定时自动调度&lt;br/&gt;数据迁移在第一阶段，将现在不变的数据从Kudu复制到HDFS。即使将数据从Kudu复制到HDFS，在视图中定义的边界也将阻止向用户显示重复数据。此步骤应该包含检查机制，以确保成功完成数据的迁移和卸载。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.6817472698907956&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpk9ibtkwVgzJ4cWBbY22U8tGibIdQy9A3ksQhMgbC4dyjPhHFUYAlN6sw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;641&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;元数据修改&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在第二阶段，既然已将数据安全地复制到HDFS，则更改元数据以调整如何显示卸载的分区。这包括向前移动边界，添加下一个时间窗口的新的Kudu分区以及删除旧的Kudu分区。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;索引跳跃式扫描优化&lt;/h4&gt;&lt;pre&gt;&lt;code&gt;CREATE TABLE metrics (&lt;br/&gt; host STRING,&lt;br/&gt; tstamp INT,&lt;br/&gt; clusterid INT,&lt;br/&gt; role STRING,&lt;br/&gt; PRIMARY KEY (host, tstamp, clusterid)&lt;br/&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;Kudu在内部会创建主键索引（B-tree），跟上表类似，索引数据按所有主键列的组合排序。当用户查询包含第一主键列（host）时，Kudu将使用索引（因为索引数据主要在第一个主键列上排序）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果用户查询不包含第一个主键列而仅包含tstamp列怎么办？tstamp虽然在固定host下是有序的，但全局是无须的，所以无法使用主键索引。在关系型数据库中一般采用二级索引，但是Kudu并不支持二级索引&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tstamp之前的列为“prefix column”，列的具体值为“prefix key”，在咱们的例子中host就是prefix column。在索引中首先按照prefix key排序，相同的prefix key在按照剩余列的值排序，因此可以使用索引跳转到具有不同prefix key且tstamp满足条件的行上&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SELECT clusterid FROM metrics WHERE tstamp = 100，其余的是跳过的。Tablet Server使用索引（ prefix key (host = helium)+tstamp = 100）跳过不匹配的行直接到达第三行并逐步扫描直到不匹配tstamp = 100，就通过下一个prefix key (host = ubuntu)+tstamp = 100继续跳过不匹配的行。其余prefix key采用相同的做法，这就叫做Index Skip Scan优化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;性能&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;索引跳跃式扫描优化的性能与前缀列（prefix column）的基数（prefix key去重后的数量）负相关&lt;br/&gt;host的基数越低，跳跃扫描性能越高，反之则性能越差。&lt;br/&gt;前缀列基数很高时，索引跳跃式扫描优化就不可取了&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;在每个tablet一千万行的数据规模下，当【前缀列host基数&amp;gt;sqrt(number_of_rows_in_tablet)】时，索引跳跃式扫描性能开始下降。为了解决这个问题：&lt;br/&gt;Kudu目前在【跳跃次数&amp;gt;sqrt(number_of_rows_in_tablet)】时自动禁用跳跃扫描优化&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;资源规划&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;在做资源规划是重点考虑的是tserver，master负载要小很多，回顾已知tserver相关的建议和限制如下&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;选项 最佳性能(建议值) 限制&lt;br/&gt;tablet server数 不超过100 300+&lt;br/&gt;tablet数/tablet server（含副本） 1000+ 4000+&lt;br/&gt;tablet数/表/tablet server（含副本） 60+ 60+&lt;br/&gt;单台tablet server存储数据（含副本，压缩后） 8TB+ 10TB+&lt;br/&gt;单tablet存储数据（超过会性能下降、合并失败、启动慢） 10G 50G&lt;br/&gt;单tablet对应CPU核心数（不考虑副本，不考虑小表） 1 多对1&lt;br/&gt;tablet server内存 16G以上最佳 不低于4G&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;集群规模&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Master 必须是奇数，3或者5台为佳，7台就多&lt;br/&gt;Tablet Server 取决于数据规模，但最多不超过1000台的规模，以300以内性能最佳&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;这里有一个预估tserver服务器数量的公式供参考：t=d/(k∗(1-p))∗r&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;t:tserver数量&lt;br/&gt;d: 以Parquet格式存储的数据总量（可以将一段时间的数据以Parquet格式存储到HDFS上做预估）&lt;br/&gt;k: 每个Tablet Server的最大磁盘容量（建议8T）&lt;br/&gt;p: 余量，一般0.25&lt;br/&gt;r:tablet副本因子，一般为3&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;示例：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;d=120T&lt;br/&gt;K=8T&lt;br/&gt;p=25%&lt;br/&gt;r=3&lt;br/&gt;t=(120 / (8 * (1 - 0.25)))*3 = 60&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;内存和CPU&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.27582644628099173&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPptwZlcYMpOwb7rL71yAZGYRZnY0NHMcm0dXBBZN8SXV6I5TGAhb0xiag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;968&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;磁盘&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;跟HDFS不一样，Kudu针对SSD做了特别优化，推荐使用SSD&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.1446028513238289&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPplC1dQdIg8xRFnW4Qaia5uPOFvcKfW8Bhvw2e9Y9r5viabicQyeV7Co3cA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1964&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;WAL、metadata、data 配置目录&lt;br/&gt;–fs_wal_dir&lt;br/&gt;–fs_metadata_dir&lt;br/&gt;–fs_data_dirs&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网卡&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Master和Tablet Server和 2块千兆网卡绑定&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;性能调优&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;硬件层面优化&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;tserver的WAL采用M.2接口(NVMe协议) SSD,Kudu的每一次写入都会先写WAL，WAL是确保数据不丢失的关键，所以一般都会同步写磁盘（顺序写），为了提高性能建议tserver采用M.2接口（NVMe协议）SSD来存储WAL，至少也得是普通SD（master读写压力小，跟操作系统共享SSD即可） –fs_wal_dir=/data/kudu/tserver/wal&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据存储多SSD&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;tserver负责数据的读写和复制，压力比较大，建议采用多SSD分散读写IO。fs_data_dirs=/disk1/kudu/tserver/data,/disk2/kudu/tserver/data,/disk3/kudu/tserver/data&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;操作系统层面优化&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;操作系统会控制每个用户使用的文件描述符和线程数，Kudu作为数据库肯定比一般应用需要更多文件描述符和线程数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果Kudu使用的线程数超过OS的限制，你会在日志中看到如下报错：&lt;br/&gt;pthread_create failed: Resource temporarily unavailable&lt;br/&gt;降低或者禁用swap使用交换区会导致性能下降，建议降低swap的使用&lt;br/&gt;sudo su -&lt;br/&gt;echo ‘vm.swappiness=10’&amp;gt;&amp;gt; /etc/sysctl.conf&lt;br/&gt;exit&lt;br/&gt;上面参数重启才能生效，可以同时搭配如下命令避免重启：&lt;br/&gt;sudo sysctl vm.swappiness=10&lt;br/&gt;cat /proc/sys/vm/swappiness&lt;br/&gt;检查当前是否生效&lt;br/&gt;cat /proc/sys/vm/swappiness&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;配置调优&lt;/h3&gt;&lt;p&gt;&lt;span&gt;tserver内存限制&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tablet Server能使用的最大内存量，tablet Server在批量写入数据时并非实时写入磁盘，而是先Cache在内存中，在flush到磁盘。这个值设置过小时，会造成Kudu数据写入性能显著下降。对于写入性能要求比较高的集群，建议设置更大的值 ：&lt;br/&gt;–memory_limit_hard_bytes&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有两个软限制：&lt;br/&gt;Cgroup 内存软限制，这个限制并不会阻止进程使用超过限额的内存，只是在系统内存不足时，会优先回收超过限额的进程占用的内存，使之向限定值靠拢,当进程试图占用的内存超过了cgroups的限制，会触发out of memory，导致进程被kill掉&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;–memory_limit_soft_percentage=80&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;tserver维护管理器线程数&lt;br/&gt;Kudu后台对数据进行维护操作，如写入数据时的并发线程数，一般设置为4，建议的是数据目录的3倍&lt;/p&gt;&lt;pre&gt;&lt;code&gt;–maintenance_manager_num_threads=6&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;调大tserver block cache容量,分配给Kudu Tablet Server块缓存的最大内存量，建议是2-4G&lt;/p&gt;&lt;pre&gt;&lt;code&gt;–block_cache_capacity_mb=2048&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;避免磁盘耗尽,为避免磁盘空间耗尽，应该保留一部分空间：#默认-1，表示保留1%的磁盘空间，自己配置是必须大于0&lt;/p&gt;&lt;pre&gt;&lt;code&gt;–fs_data_dirs_reserved_bytes&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;容忍磁盘故障&lt;br/&gt;如果某个tablet的数据分散到更多的磁盘，则数据会更加分散，这个值越小每个tablet的数据会更加集中，不过受磁盘故障影响就越小。&lt;/p&gt;&lt;p&gt;#每个tablet的数据分散到几个目录&lt;/p&gt;&lt;pre&gt;&lt;code&gt;fs_target_data_dirs_per_tablet=3&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Kudu与HBase对比&lt;/h3&gt;&lt;h4&gt;整体结构&lt;/h4&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5689948892674617&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpouMWhX610ShyjCJwv756dvb0RViag9PSrxrrf0yxPoVonNx4pXLialmA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;587&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;HBase的主要组件包括Master，zookeeper服务，RegionServer，HDFS。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Master：用来管理与监控所有的HRegionServer，也是管理HBase元数据的模块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;zookeeper：作为分布式协调服务，用于保存meta表的位置，master的位置，存储RS当前的工作状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RegionServer：负责维护Master分配的region，region对应着表中一段区间内的内容，直接接受客户端传来的读写请求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;HDFS：负责最终将写入的数据持久化，并通过多副本复制实现数据的高可靠性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5742574257425742&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpUhPszex7KPpYhjtkrELVdsWvv0UB64c0xkjK6shOqosQXibiaJEoG8qQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;606&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu集群中存在两种主要组件：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）TServer，负责管理Tablet，tablet是负责一张表中某块内容的读写，接收其他TServer中leader tablet传来的同步信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）Master，集群中的管理节点，用于管理tablet的基本信息，表的信息，并监听TServer的状态。多个Master之间通过Raft协议实现数据同步和高可用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主要区别&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu结构看上去跟HBase差别并不大，主要的区别包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、Kudu将HBase中zookeeper的功能放进了Master内，Kudu中Master的功能比HBase中的Master任务要多一些。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、Hbase将数据持久化这部分的功能交给了Hadoop中的HDFS，最终组织的数据存储在HDFS上。Kudu自己将存储模块集成在自己的结构中，内部的数据存储模块通过Raft协议来保证leader Tablet和replica Tablet内数据的强一致性，和数据的高可靠性。为什么不像HBase一样，利用HDFS来实现数据存储，猜测可能是因为HDFS读小文件时的时延太大，所以Kudu自己重新完成了底层的数据存储模块，并将其集成在TServer中。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;数据存储方式&lt;/h4&gt;&lt;p&gt;&lt;span&gt;HBase是一款Nosql数据库，典型的KV系统，没有固定的schema模式，建表时只需指定一个或多个列族名即可，一个列族下面可以增加任意个列限定名。一个列限定名代表了实际中的一列，HBase将同一个列族下面的所有列存储在一起，所以HBase是一种面向列族式的数据库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.6071428571428571&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpvFl9khpuHH3yle4Zkg1zOlqSNcsSBARgESomIS122HiceIGYYoxw01g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;980&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;HBase将每个列族中的数据分别存储，一个列族中的每行数据中，将rowkey、列族名、列名、timestamp组成最终存取的key值，另外为了支持修改，删除，增加了一个表征该行数据是否删除的标记。在同一个列族中的所有数据，按照rowkey:columnfamily:columnQulifier:timestamp组成的key值大小进行升序排列，其中rowkey、columnfamily、columnQulifier采用的是字典顺序，其值越大，key越大，而timestamp是值越大，key越小。HBase通过按照列族分开存储，相对于行式存储能够实现更高的压缩比，这也是其比较重要的一个特性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;HBase对一行数据进行更新时，HBase也是相当于插入一行新数据，在读数据时HBase按照timestamp的大小得到经过更新过的最新数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.27040816326530615&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpZKkrsiasOB2ZzXArLplUO4aWnFz0ziafOdThWibicxibyicle9nDOueagGhw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;980&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu是一种完全的列式存储引擎，表中的每一列数据都是存放在一起，列与列之间都是分开的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了能够保存一部分历史数据，并实现MVCC，Kudu将数据分为三个部分。一个部分叫做base data，是当前的数据；第二个部分叫做UNDO records，存储的是从插入数据时到形成base data所进行的所有修改操作，修改操作以一定形式进行组织，实现快速查看历史数据；第三个部分是REDO records，存储的是还未merge到当前数据中的更新操作。下图中表示的是在Kudu中插入一条数据、更新数据两个操作的做法，当然做法不唯一，不唯一的原因是Kudu可以选择先不将更新操作合并到base data中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.49838187702265374&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpNfAn2sUYbDBoaicbaWxfTRo2zgLyEpEdqhgq1FTVJbha3s82qiakgbeQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;618&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;差异分析&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）HBase是面向列族式的存储，每个列族都是分别存放的，HBase表设计时，很少使用设计多个列族，大多情况下是一个列族。这个时候的HBase的存储结构已经与行式存储无太大差别了。而Kudu，实现的是一个真正的面向列的存储方式，表中的每一列都是单独存放的；所以HBase与Kudu的差异主要在于类似于行式存储的列族式存储方式与典型的面向列式的存储方式的差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）HBase是一款NoSQL类型的数据库，对表的设计主要在于rowkey与列族的设计，列的类型可以不指定，因为HBase在实际存储中都会将所有的value字段转换成二进制的字节流。因为不需要指定类型，所以在插入数据的时候可以任意指定列名（列限定名），这样相当于可以在建表之后动态改变表的结构。Kudu因为选择了列式存储，为了更好的提高列式存储的效果，Kudu要求在建表时指定每一列的类型，这样的做法是为了根据每一列的类型设置合适的编码方式，实现更高的数据压缩比，进而降低数据读入时的IO压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）HBase对每一个cell数据中加入了timestamp字段，这样能够实现记录同一rowkey和列名的多版本数据，另外HBase将数据更新操作、删除操作也是作为一条数据写入，通过timestamp来标记更新时间，type来区分数据是插入、更新还是删除。HBase写入或者更新数据时可以指定timestamp，这样的设置可以完成某些特定的操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu也在数据存储中加入了timestamp这个字段，不像HBase可以直接在插入或者更新数据时设置特殊的timestamp值，Kudu的做法是由Kudu内部来控制timestamp的写入。不过Kudu允许在scan的时候设置timestamp参数，使得客户端可以scan到历史数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（4）相对于HBase允许多版本的数据存在，Kudu为了提高批量读取数据时的效率，要求设计表时提供一列或者多列组成一个主键，主键唯一，不允许多个相同主键的数据存在。这样的设置下，Kudu不能像HBase一样将更新操作直接转换成插入一条新版本的数据，Kudu的选择是将写入的数据，更新操作分开存储。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（5）当然还有一些其他的行式存储与列式存储之间在不同应用场景下的性能差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;写入和读取过程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一、HBase&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;HBase作为一种非常典型的LSM结构的分布式存储系统，是Google bigtable的apache开源版本。经过近10年的发展，HBase已经成为了一个成熟的项目，在处理OLTP型的应用如消息日志，历史订单等应用较适用。在HBase中真正接受客户端读写请求的RegionServer的结构如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.46497584541062803&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpwwAsyXqZQmytqpdZyBw71YBd0z47TwXliablkAdDZghibWe5OPn8obNA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;828&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;关于HBase的几个关键点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）在HBase中，充当写入缓存的这个结构叫做Memstore，另外会将写入操作顺序写入HLOG（WAL）中以保证数据不丢失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）为了提高读的性能，HBase在内存中设置了blockcache，blockcache采用LRU策略将最近使用的数据块放在内存中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）作为分布式存储系统，为保证数据不因为集群中机器出现故障而导致数据丢失，HBase将实际数据存放在HDFS上，包括storefile与HLOG。HBase与HDFS低耦合，HBase作为HDFS的客户端，向HDFS读写数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、HBase写过程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）客户端通过客户端上保存的RS信息缓存或者通过访问zk得到需要读写的region所在的RS信息；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）RS接受客户端写入请求，先将写入的操作写入WAL，然后写入Memstore，这时HBase向客户端确认写入成功；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）HBase在一定情况下将Memstore中的数据flush成storefile（可能是Memstore大小达到一定阈值或者region占用的内存超过一定阈值或者手动flush之类的），storefile以HFile的形式存放在HDFS上；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（4）HBase会按照一定的合并策略对HDFS上的storefile进行合并操作，减少storefile的数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、HBase读过程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;HBase读数据的过程比较麻烦，原因包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）HBase采用了LSM-tree的多组件算法作为数据组织方式，这种算法会导致一个region中有多个storefile；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）HBase中采用了非原地更新的方式，将更新操作和删除操作转换成插入一条新数据的形式，虽然这样能够较快的实现更新与删除，但是将导致满足指定rowkey，列族、列名要求的数据有多个，并且可能分布在不同的storefile中；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）HBase中允许设置插入和删除数据行的timestamp属性，这样导致按顺序落盘的storefile内数据的timestamp可能不是递增的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面介绍从HBase中读取一条指定（rowkey，column family，column）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）读过程与HBase客户端写过程第一步一样，先尝试获取需要读的region所在的RS相关信息；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）RS接收读请求，因为HBase中支持多版本数据（允许存在rowkey、列族名、列名相同的数据，不同版本的数据通过timestamp进行区分），另外更新与删除数据都是通过插入一条新数据实现的。所以要准确的读到数据，需要找到所有可能存储有该条数据的位置，包括在内存中未flush的memstore，已经flush到HDFS上的storefile，所以需要在1 memstore +N storefile中查找；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）在找到的所有数据中通过判断timestamp值得到最终的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5650644783118406&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpFsl9HC5XsyJEXt3ibzm7IiaY5JRaaUvNqR8fkIkwOibybjda4TImJWkfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;853&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）Kudu中的Tablet是负责表中一块内容的读写工作，Tablet由一个或多个Rowset组成。其中有一个Rowset处于内存中，叫做Memrowset，Memrowset主要负责处理新的数据写入请求。DiskRowSet是MemRowset达到一定程序刷入磁盘后生成的，实质上是由一个CFile（Base Data）、多个DeltaFile（UNDO records &amp;amp;REDO records）和位于内存的DeltaMemStore组成。Base data、UNDO records、和REDO records都是不可修改的，DeltaMemStore达到一定大小后会将数据刷入磁盘生成新的REDO records。Kudu后台会有一个类似HBase的compaction线程按照一定的compaction 策略对tablet进行合并处理：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;a、将多个DeltaFile（REDO records）合并成一个大的DeltaFile；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;b、将多个REDO reccords文件与Base data进行合并，并生成新的UNDO records；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;c、将多个DiskRowset之间进行合并，减少DiskRowset的数量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）Kudu将最终的数据存储在本地磁盘上，为了保证数据可靠性，Kudu为一个tablet设置了多个副本（一般为3或5个）。所以一个tablet会由多个TServer负责维护，其中有个副本称为leader tablet，写入的请求只能通过leader tablet来处理，副本之间通过Raft协议保证其他副本与leader tablet的强一致性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu与HBase不同，Kudu将写入操作分为两种，一种是插入一条新数据，一种是对一条已插入数据的更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、Kudu插入一条新数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）客户端连接Master获取表的相关信息，包括分区信息，表中所有tablet的信息；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）客户端找到负责处理读写请求的tablet所负责维护的TServer。Kudu接受客户端的请求，检查请求是否符合要求（表结构）；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）Kudu在Tablet中的所有rowset（memrowset,diskrowset）中进行查找，看是否存在与待插入数据相同主键的数据，如果存在就返回错误，否则继续；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（4）Kudu在MemRowset中写入一行新数据，在MemRowset数据达到一定大小时，MemRowset将数据落盘，并生成一个diskrowset用于持久化数据，还生成一个memrowset继续接收新数据的请求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、Kudu对原有数据的更新&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）客户端连接Master获取表的相关信息，包括分区信息，表中所有tablet的信息；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）Kudu接受请求，检查请求是否符合要求；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）因为待更新数据可能位于memrowset中，也可能已经flush到磁盘上，形成diskrowset。因此根据待更新数据所处位置不同，kudu有不同的做法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当待更新数据位于memrowset时&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;a、找到待更新数据所在行，然后将更新操作记录在所在行中一个mutation链表中；在memrowset将数据落盘时，Kudu会将更新合并到base data，并生成UNDO records用于查看历史版本的数据和MVCC,UNDO records实际上也是以DeltaFile的形式存放；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当待更新数据位于DiskRowset中&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;b、找到待更新数据所在的DiskRowset，每个DiskRowset都会在内存中设置一个DeltaMemStore，将更新操作记录在DeltaMemStore中，在DeltaMemStore达到一定大小时，flush在磁盘，形成Delta并存在方DeltaFile中；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实际上Kudu提交更新时会使用Raft协议将更新同步到其他replica上去，当然如果在memrowset和diskrowset中都没有找到这条数据，那么返回错误给客户端；另外当DiskRowset中的deltafile太多时，Kudu会采用一定的策略对一组deltafile进行合并。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、客户端连接Master获取表的相关信息，包括分区信息，表中所有tablet的信息；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、客户端找到需要读取的数据的tablet所在的TServer，Kudu接受读请求，并记录timestamp信息，如果没有显式指定，那么表示使用当前时间；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、Kudu找到待读数据的所有相关信息，当目标数据处于memrowset时，根据读取操作中包含的timestamp信息将该timestamp前提交的更新操作合并到base data中，这个更新操作记录在该行数据对应的mutation链表中；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、当读取的目标数据位于diskrowset中，在所有DeltaFile中找到所有目标数据相关的UNDO record和REDO records，REDO records可能位于多个DeltaFile中，根据读操作中包含的timestamp信息判断是否需要将base data进行回滚或者利用REDO records将base data进行合并更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu与HBase在读写上过程中的差异&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）HBase写的时候，不管是新插入一条数据还是更新数据，都当作插入一条新数据来进行；而Kudu将插入新数据与更新操作分别看待。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）Kudu表结构中必须设置一个唯一键，插入数据的时候必须判断一些该数据的主键是否唯一，所以插入的时候其实有一个读的过程；而HBase没有太多限制，待插入数据将直接写进memstore。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）HBase实现数据可靠性是通过将落盘的数据写入HDFS来实现，而Kudu是通过将数据写入和更新操作同步在其他副本上实现数据可靠性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结合以上几点，可以看出Kudu在写的性能上相对HBase有一定的劣势。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）在HBase中，读取的数据可能有多个版本，所以需要结合多个storefile进行查询；Kudu数据只可能存在于一个DiskRowset或者MemRowset中，但是因为可能存在还未合并进原数据的更新，所以Kudu也需要结合多个DeltaFile进行查询。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）HBase写入或者更新时可以指定timestamp，导致storefile之间timestamp范围的规律性降低，增加了实际查询storefile的数量；Kudu不允许人为指定写入或者更新时的timestamp值，DeltaFile之间timestamp连续，可以更快的找到需要的DeltaFile。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）HBase通过timestamp值可以直接取出数据；而Kudu实现多版本是通过保留UNDO records（已经合并过的操作）和REDO records（未合并过的操作）完成的，在一些情况下Kudu需要将base data结合UNDO records进行回滚或者结合REDO records进行合并然后才能得到真正所需要的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结合以上三点可以得出，不管是HBase还是Kudu，在读取一条数据时都需要从多个文件中搜寻相关信息。相对于HBase，Kudu选择将插入数据和更新操作分开，一条数据只可能存在于一个DiskRowset或者memRowset中，只需要搜寻到一个rowset中存在指定数据就不用继续往下找了，用户不能设置更新和插入时的timestamp值，减少了在rowset中DeltaFile的读取数量。这样在scan的情况下可以结合列式存储的优点实现较高的读性能，特别是在更新数量较少的情况下能够有效提高scan性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外，本文在描述HBase读写过程中没有考虑读写中使用的优化技术如Bloomfilter、timestamp range等。其实Kudu中也有使用类似的优化技术来提高读写性能，本文只是简单的分析，因此就不再详细讨论读写过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;HBase：使用的java，内存的释放通过GC来完成，在内存比较紧张时可能引发full GC进而导致服务不稳定；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu：核心模块用的C++来实现，没有full gc的风险。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;Kudu在网易的实践&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;生产实践&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;实时数据采集场景&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实时数据分析中，一些用户行为数据有更新的需求。没有引入Kudu前，用户行为数据会首先通过流式计算引擎写入HBase，但HBase不能支撑聚合分析。为了支撑分析和查询需求，还需要把HBase上的数据通过Spark读取后写入其他OLAP引擎。使用Kudu后，用户行为数据会通过流式计算引擎写入Kudu，由Kudu完成数据更新操作。Kudu可以支持单点查询，也可以配合计算引擎做数据分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.3472222222222222&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpS4Kz4lxsuzic22OyIOgSMHLGyz8sJvRzBlmNYwLGceUibg2Sye5HHuuQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;维表数据关联应用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有些场景中，日志的事件表还需要和MySQL内维度表做关联后进行查询。使用Kudu，可以利用NDC同步工具，将MySQL中数据实时同步导入Kudu，使Kudu内数据表和MySQL中的表保持数据一致。这时Kudu配合计算引擎就可以直接对外提供结果数据，如产生报表和做在线分析等。省去了MySQL中维度表和数据合并的一步，大大提升了效率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.3712962962962963&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPp3AjDoq0aHhNAnVKeLvowyTKplI7j6tJOCBn3et34G2AgOdCUZjOuqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实时数仓ETL&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu作为分布式数据存储引擎，可以和Hadoop生态更好结合，因此在生产中我们采用了使用Kudu替换Oracle的做法，提升了扩展性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.49266862170087977&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpibDzibrEWzVzPgBnBonWnXEV0XaUa5ribibpVvuRycG960RcYut6EYX77A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1023&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ABTEST&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在我们的ABTest业务中有两种日志，行为日志和用户分流日志。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.2777777777777778&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpngqOvQNiaDib8q5xM53eKxSNvpdVMfTiafD5OKHIUyub4pH4ukxqtKswQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;架构升级前，我们采用了比较传统的模式，将用户行为日志和用户分流日志分别写入HDFS作为存储的ODS层，通过Spark做清洗、转换后导入HDFS作为存储的DWD层，再通过Spark进行一步清洗、按照时间或其他纬度做简单聚合后写入DWS层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个架构的问题是数据产出时间比较长，数据延迟在天级别。业务方需要更及时地拿到ABTest结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.4935185185185185&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpWTleuSnNZA2WEicsHiasd0GHsLvvfd0YLibFxywtn0TGtCHN4mBCGDicnQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;架构升级后，使用Kafka作为ODS、DWD层存储。Flink在ODS层数据的基础上继续做一层整理和过滤，写入DWD形成明细表数据；DWD层在Flink中做简单聚合后写入DWS层，Kudu在DWS层作为数据存储。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Flink开窗口实时修正实验数据，这一操作在Kudu完成；超出了Flink时间窗口的数据更新则由离线补数据的操作在Kudu中完成修正。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;架构升级后，数据延迟大大降低，能够让ABTest业务方更实时地拿到结果。&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;遇到的问题&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;问题1: 节点负载不均衡&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些大表场景下会有负载不均衡问题。Kudu不会把range下的哈希分片当作一张表，而是把整个表的分片当成了平等的表进行处理。而在真实使用场景中，range基本是时间字段；需要让range的hash分片更均匀地分布在各节点上，防止数据倾斜。下图是数据倾斜的情况展示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.4537037037037037&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpn5sW9nxGicgNtuo1t415Y1Ly8WRvyj0ocluZPSLzHr5DKORkA8qiauNA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的解决方案是实现了一套优化版本的负载均衡算法，这个算法能够把range表当作单独的表做负载均衡，解决了数据倾斜。下图是优化后效果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Uploading file...&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题2: 表结构设计复杂&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题3: 没有二级索引，只能通过控制主键顺序和分区键来优化某几种查询模式&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题4: 创建表时需要根据业务场景专门设计表结构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;问题2-4，对业务方要求比较高，经常需要专人介入引导业务方导入数据。为了解决问题，我们内部设计了二级索引来解决上述问题。二级索引可以满足查询性能的要求，同时减少用户设计表时候的复杂度：&lt;/span&gt;&lt;/p&gt;&lt;h4&gt;Kudu功能展望&lt;/h4&gt;&lt;p&gt;&lt;span&gt;BloomFilter&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;BloomFilter成本较低、效率较高。Join场景下，小表动态生成BloomFilter下推到存储层，防止大表在Join层做数据过滤。最近的Kudu中已经支持了BloomFilter作为过滤条件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;灵活分区哈希&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kudu每个range的hash bucket数量是固定的。考虑到时间和业务增长，在项目实施前期阶段要给Kudu哈希桶数量设置略大，但是数据量较小的场景下过大的分片个数对资源是一种浪费，社区也不推荐hash bucket设置得比较大。期望后续Kudu可以更灵活地适配hash bucket数。&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;KUDU-2671：Change hash number for range partitioning&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;多行事务&lt;/p&gt;&lt;p&gt;Kudu暂时不能支持多行事务。目前更新主键需要业务自己实现逻辑检测。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;KUDU-2612：Implement multi-row transactions&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Flexible Schema&lt;/p&gt;&lt;p&gt;一些业务场景下业务没有唯一主键，但只希望利用Kudu的大批量写入、聚合分析查询的特性。接入业务时Kudu对Schema的要求比较高，一些业务场景无法支持。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;KUDU-1879：Support table without a primary key&lt;/p&gt;&lt;/blockquote&gt;&lt;h3&gt;Spark Streaming + Kudu + Impala构建预测引擎&lt;/h3&gt;&lt;p&gt;&lt;span&gt;1.动态资源分配预测架构图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个例子的数据通过流式API进入Kafka，然后使用Spark Streaming从Kafka加载数据到Kudu。Kafka允许数据同时进入两个独立的Spark Streaming作业：一个用来进行特征工程；一个用来使用MLlib进行流式预测。预测的结果存储在Kudu中，我们也可以使用Impala或者Spark SQL进行交互式查询，见下图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.8578125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPp7aa2606Nlz5buwpavhh8zOwMiciarZrgMhLSHfkV8Vh6Juo8O8jhZFoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面是一些技术概要：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Kafka：Kafka可抽象数据输入，支持扩展，并耦合Spark Streaming框架。Kafka拥有每秒处理百万事件的扩展能力，并能和其他各项技术集成，比如，Spark Streaming。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Spark Streaming：Spark Streaming能够处理复杂的流式事件，并且采用Scala编程仅需简单的几行代码即可，也支持Java、Python或者R语言。Spark Streaming提供和Kafka、MLlib（Spark的机器学习库）的集成。Apache Kudu：Kudu支持事件的增量插入，它旨在提供一种基于HDFS（HDFS优势在于大数据存储下的快速扫描能力）和HBase（HBase优势是基于主键的快速插入／查询）之间超存储层。本项目可以采用HBase或者Cassandra，但Kudu为数据分析提供了快速的扫描能力、列式存储架构。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Impala：使用Impala可很容易的即席查询。它提供一个查询引擎直接查询加载到Kudu上的数据，并能理解生成模型。作为可选的方案可使用Spark SQL，但这里为了比较使用MADlib库训练的回归模型和使用Saprk MLlib训练的模型，故用Impala。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;2.构建实例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在解释下架构的选择，详细细节如下：&lt;br/&gt;首先，粗略浏览一下流式数据源。通过Kafka来监测文件，tail文件变化发送到Kafka，部分代码见Github。下面给出RSVP内容样例：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;{&quot;response&quot;:&quot;yes&quot;,&quot;member&quot;:{&quot;member_name&quot;:&quot;Richard &lt;br/&gt;Williamson&quot;,&quot;photo&quot;:&quot;http:\/\/photos3.meetupstatic.com\/photos\/member\/d\/a\/4\/0\/thu&lt;br/&gt;mb_231595872.jpeg&quot;,&quot;member_id&quot;:29193652},&quot;visibility&quot;:&quot;public&quot;,&quot;event&quot;:&lt;br/&gt;{&quot;time&quot;:1424223000000,&quot;event_url&quot;:&quot;http:\/\/www.meetup.com\/Big-Data-&lt;br/&gt;Science\/events\/217322312\/&quot;,&quot;event_id&quot;:&quot;fbtgdlytdbbc&quot;,&quot;event_name&quot;:&quot;Big Data Science &lt;br/&gt;@Strata Conference, &lt;br/&gt;2015&quot;},&quot;guests&quot;:0,&quot;mtime&quot;:1424020205391,&quot;rsvp_id&quot;:1536654666,&quot;group&quot;:{&quot;group_name&quot;:&quot;Big &lt;br/&gt;Data &lt;br/&gt;Science&quot;,&quot;group_state&quot;:&quot;CA&quot;,&quot;group_city&quot;:&quot;Fremont&quot;,&quot;group_lat&quot;:37.52,&quot;group_urlname&quot;:&quot;Big-&lt;br/&gt;Data-Science&quot;,&quot;group_id&quot;:3168962,&quot;group_country&quot;:&quot;us&quot;,&quot;group_topics&quot;:&lt;br/&gt;[{&quot;urlkey&quot;:&quot;data-visualization&quot;,&quot;topic_name&quot;:&quot;Data Visualization&quot;},{&quot;urlkey&quot;:&quot;data-&lt;br/&gt;mining&quot;,&quot;topic_name&quot;:&quot;Data Mining&quot;},{&quot;urlkey&quot;:&quot;businessintell&quot;,&quot;topic_name&quot;:&quot;Business &lt;br/&gt;Intelligence&quot;},{&quot;urlkey&quot;:&quot;mapreduce&quot;,&quot;topic_name&quot;:&quot;MapReduce&quot;},&lt;br/&gt;{&quot;urlkey&quot;:&quot;hadoop&quot;,&quot;topic_name&quot;:&quot;Hadoop&quot;},{&quot;urlkey&quot;:&quot;opensource&quot;,&quot;topic_name&quot;:&quot;Open &lt;br/&gt;Source&quot;},{&quot;urlkey&quot;:&quot;r-project-for-statistical-computing&quot;,&quot;topic_name&quot;:&quot;R Project for Statistical &lt;br/&gt;Computing&quot;},{&quot;urlkey&quot;:&quot;predictive-analytics&quot;,&quot;topic_name&quot;:&quot;Predictive Analytics&quot;},&lt;br/&gt;{&quot;urlkey&quot;:&quot;cloud-computing&quot;,&quot;topic_name&quot;:&quot;Cloud Computing&quot;},{&quot;urlkey&quot;:&quot;big-&lt;br/&gt;data&quot;,&quot;topic_name&quot;:&quot;Big Data&quot;},{&quot;urlkey&quot;:&quot;data-science&quot;,&quot;topic_name&quot;:&quot;Data Science&quot;},&lt;br/&gt;{&quot;urlkey&quot;:&quot;data-analytics&quot;,&quot;topic_name&quot;:&quot;Data Analytics&quot;},&lt;br/&gt;{&quot;urlkey&quot;:&quot;hbase&quot;,&quot;topic_name&quot;:&quot;HBase&quot;},&lt;br/&gt;{&quot;urlkey&quot;:&quot;hive&quot;,&quot;topic_name&quot;:&quot;Hive&quot;}],&quot;group_lon&quot;:-121.93},&quot;venue&quot;:&lt;br/&gt;{&quot;lon&quot;:-121.889122,&quot;venue_name&quot;:&quot;San Jose Convention Center, Room &lt;br/&gt;210AE&quot;,&quot;venue_id&quot;:21805972,&quot;lat&quot;:37.330341}}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;一旦Kafka运行起来，数据从Kafka经过Spark Streaming进入Kudu，代码见这里。&lt;/p&gt;&lt;p&gt;流式作业在Kudu上初始化一个表，接着运行Spark Streaming加载数据到数据表。可以创建一个Impala外部表，并指向Kudu上存储的数据。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;CREATE EXTERNAL TABLE `kudu_meetup_rsvps` (&lt;br/&gt;`event_id` STRING,&lt;br/&gt;`member_id` INT,&lt;br/&gt;`rsvp_id` INT,&lt;br/&gt;`event_name` STRING,&lt;br/&gt;`event_url` STRING,&lt;br/&gt;`TIME` BIGINT,&lt;br/&gt;`guests` INT,&lt;br/&gt;`member_name` STRING,&lt;br/&gt;`facebook_identifier` STRING,&lt;br/&gt;`linkedin_identifier` STRING,&lt;br/&gt;`twitter_identifier` STRING,&lt;br/&gt;`photo` STRING,&lt;br/&gt;`mtime` BIGINT,&lt;br/&gt;`response` STRING,&lt;br/&gt;`lat` DOUBLE,&lt;br/&gt;`lon` DOUBLE,&lt;br/&gt;`venue_id` INT,&lt;br/&gt;`venue_name` STRING,&lt;br/&gt;`visibility` STRING&lt;br/&gt;)&lt;br/&gt;TBLPROPERTIES(&lt;br/&gt;  &#x27;storage_handler&#x27; = &#x27;com.cloudera.kudu.hive.KuduStorageHandler&#x27;,&lt;br/&gt;  &#x27;kudu.table_name&#x27; = &#x27;kudu_meetup_rsvps&#x27;,&lt;br/&gt;  &#x27;kudu.master_addresses&#x27; = &#x27;quickstart.cloudera:7051&#x27;,&lt;br/&gt;  &#x27;kudu.key_columns&#x27; = &#x27;event_id, member_id, rsvp_id&#x27;&lt;br/&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;紧接着用Impala表查询获得小时RSVP数据：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;create &lt;br/&gt;table   rsvps_by_hour as&lt;br/&gt;select  from_unixtime(cast(mtime/1000 as bigint), &quot;yyyy-MM-dd&quot;) as mdate &lt;br/&gt;        ,cast(from_unixtime(cast(mtime/1000 as bigint), &quot;HH&quot;) as int) as mhour &lt;br/&gt;        ,count(*) as rsvp_cnt&lt;br/&gt;from    kudu_meetup_rsvps&lt;br/&gt;group &lt;br/&gt;by      1,2&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;有了RSVP数据后可以画随时间的变化图，见下图：&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5203125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpHBnSQvSvh0N30kgGIjLouZI5jWRYiaBXuBF69gjtMVaXFpeOoCQypfg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p&gt;接着可以进行特征工程，为了后续可以直接用Impala建立预测模型：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;create &lt;br/&gt;table rsvps_by_hr_training as&lt;br/&gt;select&lt;br/&gt;      case when mhour=0 then 1 else 0 end as hr0&lt;br/&gt;      ,case when mhour=1 then 1 else 0 end as hr1&lt;br/&gt;      ,case when mhour=2 then 1 else 0 end as hr2&lt;br/&gt;      ,case when mhour=3 then 1 else 0 end as hr3&lt;br/&gt;      ,case when mhour=4 then 1 else 0 end as hr4&lt;br/&gt;      ,case when mhour=5 then 1 else 0 end as hr5&lt;br/&gt;      ,case when mhour=6 then 1 else 0 end as hr6&lt;br/&gt;      ,case when mhour=7 then 1 else 0 end as hr7&lt;br/&gt;      ,case when mhour=8 then 1 else 0 end as hr8&lt;br/&gt;      ,case when mhour=9 then 1 else 0 end as hr9&lt;br/&gt;      ,case when mhour=10 then 1 else 0 end as hr10&lt;br/&gt;      ,case when mhour=11 then 1 else 0 end as hr11&lt;br/&gt;      ,case when mhour=12 then 1 else 0 end as hr12&lt;br/&gt;      ,case when mhour=13 then 1 else 0 end as hr13&lt;br/&gt;      ,case when mhour=14 then 1 else 0 end as hr14&lt;br/&gt;      ,case when mhour=15 then 1 else 0 end as hr15&lt;br/&gt;      ,case when mhour=16 then 1 else 0 end as hr16&lt;br/&gt;      ,case when mhour=17 then 1 else 0 end as hr17&lt;br/&gt;      ,case when mhour=18 then 1 else 0 end as hr18&lt;br/&gt;      ,case when mhour=19 then 1 else 0 end as hr19&lt;br/&gt;      ,case when mhour=20 then 1 else 0 end as hr20&lt;br/&gt;      ,case when mhour=21 then 1 else 0 end as hr21&lt;br/&gt;      ,case when mhour=22 then 1 else 0 end as hr22&lt;br/&gt;      ,case when mhour=23 then 1 else 0 end as hr23&lt;br/&gt;      ,case when mdate in (&quot;2015-02-14&quot;,&quot;2015-02-15&quot;) then 1 else 0 end as weekend_day&lt;br/&gt;      ,mdate&lt;br/&gt;      ,mhour&lt;br/&gt;      ,rsvp_cnt&lt;br/&gt;from  rsvps_by_hour;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;在Impala上安装MADlib，这样就可以直接在Impala上构建回归模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采用MADlib训练回归模型的第一步：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;select  printarray(linr(toarray(hr0,hr1,hr2,hr3,hr4,hr5,hr6,hr7,hr8,hr9,hr10,hr11,hr12,hr13,hr14, hr15,hr16,hr17,hr18,hr19,hr20,hr21,hr22,hr23,weekend_day), rsvp_cnt))&lt;br/&gt;from    rsvps_by_hr_training;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;下面展示回归系数。可看到前面的24个系数显示了一天的按小时趋势，在晚上很少的人在线；最后一个系数是周末，如果是周末的话，系数是负值。&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Feature Coefficient &lt;br/&gt;hr0 8037.43 &lt;br/&gt;hr1 7883.93 &lt;br/&gt;hr2 7007.68 &lt;br/&gt;hr3 6851.91 &lt;br/&gt;hr4 6307.91 &lt;br/&gt;hr5 5468.24 &lt;br/&gt;hr6 4792.58 &lt;br/&gt;hr7 4336.91 &lt;br/&gt;hr8 4330.24 &lt;br/&gt;hr9 4360.91 &lt;br/&gt;hr10 4373.24 &lt;br/&gt;hr11 4711.58 &lt;br/&gt;hr12 5649.91 &lt;br/&gt;hr13 6752.24 &lt;br/&gt;hr14 8056.24 &lt;br/&gt;hr15 9042.58 &lt;br/&gt;hr16 9761.37 &lt;br/&gt;hr17 10205.9 &lt;br/&gt;hr18 10365.6 &lt;br/&gt;hr19 10048.6 &lt;br/&gt;hr20 9946.12 &lt;br/&gt;hr21 9538.87 &lt;br/&gt;hr22 9984.37 &lt;br/&gt;hr23 9115.12 &lt;br/&gt;weekend_day -2323.73&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;通过上述系数进行预测：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;select       mdate,&lt;br/&gt;             mhour,&lt;br/&gt;             cast(linrpredict(toarray(8037.43, 7883.93, 7007.68, 6851.91, 6307.91, 5468.24, 4792.58, 4336.91, 4330.24, 4360.91, 4373.24, 4711.58, 5649.91, 6752.24, 8056.24, 9042.58, 9761.37, 10205.9, 10365.6, 10048.6, 9946.12, 9538.87, 9984.37, 9115.12, -2323.73), toarray(hr0, hr1, hr2, hr3, hr4, hr5, hr6, hr7, hr8, hr9, hr10, hr11, hr12, hr13, hr14, hr15, hr16, hr17, hr18, hr19, hr20, hr21, hr22, hr23, weekend_day)) as int) as rsvp_cnt_pred,&lt;br/&gt;             rsvp_cnt&lt;br/&gt;from         rsvps_by_hr_testing&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;按小时对比预测数据和RSVP真实值，由于数据有限，只列出两天的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.4875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpIOtIGiaZmaiazgNWDlUpzIGaVvvMYcXcLyXianenjPuk2UzQ7CfTKBCTQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3.使用Spark MLlib训练模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面使用Spark MLlib建立类似的模型，在海量数据下这种方式更优吸引力。&lt;br/&gt;首先，Spark加载JSON文件并使用Spark SQL注册为一张表。你也可以直接从Kudu加载数据，但此列子直接用Spark读取JSON文件。&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;val path = &quot;/home/demo/meetupstream1M.json&quot;&lt;br/&gt;val meetup = sqlContext.read.json(path)&lt;br/&gt;meetup.registerTempTable(&quot;meetup&quot;)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以使用Spark SQL运行一个类似在前面Impala中使用的查询语句来获取小时的RSVP数据：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;val meetup2 = sqlContext.sql(&quot;&lt;br/&gt;   select from_unixtime(cast(mtime/1000 as bigint), &#x27;yyyy-MM-dd&#x27;) as dy,&lt;br/&gt;          case when from_unixtime(cast(mtime/1000 as bigint),&#x27;yyyy-MM-dd&#x27;) in (&#x27;2015-02-14&#x27;,&#x27;2015-02-15&#x27;) then 1 else 0 end as weekend_day,&lt;br/&gt;          from_unixtime(cast(mtime/1000 as bigint), &#x27;HH&#x27;) as hr,&lt;br/&gt;          count(*) as rsvp_cnt&lt;br/&gt;    from  meetup&lt;br/&gt;    where from_unixtime(cast(mtime/1000 as bigint), &#x27;yyyy-MM-dd&#x27;) &amp;gt;= &#x27;2015-10-30&#x27;&lt;br/&gt;    group&lt;br/&gt;    by    from_unixtime(cast(mtime/1000 as bigint), &#x27;yyyy-MM-dd&#x27;),&lt;br/&gt;          from_unixtime(cast(mtime/1000 as bigint), &#x27;HH&#x27;)&quot;)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;接下来，创建特征向量。可以参照前面类的方法做特征工程，但这里介绍一个Andrew Ray的简便方法，使用一句话即可实现特征向量：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;val meetup3 = meetup2.groupBy(&quot;dy&quot;,&quot;weekend_day&quot;,&quot;hr&quot;,&quot;rsvp_cnt&quot;).pivot(&quot;hr&quot;).count().orderBy(&quot;dy&quot;)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在有了这些数据，可以训练回归模型了：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import org.apache.spark.mllib.regression.RidgeRegressionWithSGD&lt;br/&gt;import org.apache.spark.mllib.linalg.Vectors&lt;br/&gt;import org.apache.spark.mllib.regression.LabeledPoint&lt;br/&gt;val trainingData = meetup3.map { row =&amp;gt;&lt;br/&gt;      val features = Array[Double](1.0,row(1).toString().toDouble,row(4).toString().toDouble, &lt;br/&gt;                                   row(5).toString().toDouble,row(6).toString().toDouble,&lt;br/&gt;                                   row(7).toString().toDouble,row(8).toString().toDouble,&lt;br/&gt;                                   row(9).toString().toDouble,row(10).toString().toDouble, &lt;br/&gt;                                   row(11).toString().toDouble,row(12).toString().toDouble, &lt;br/&gt;                                   row(13).toString().toDouble,row(14).toString().toDouble, &lt;br/&gt;                                   row(15).toString().toDouble,row(16).toString().toDouble,&lt;br/&gt;                                   row(17).toString().toDouble,row(18).toString().toDouble,&lt;br/&gt;                                   row(19).toString().toDouble,row(20).toString().toDouble, &lt;br/&gt;                                   row(21).toString().toDouble,row(22).toString().toDouble, &lt;br/&gt;                                   row(23).toString().toDouble,row(24).toString().toDouble, &lt;br/&gt;                                   row(25).toString().toDouble,row(26).toString().toDouble, &lt;br/&gt;                                   row(27).toString().toDouble)&lt;br/&gt;      LabeledPoint(row(3).toString().toDouble, Vectors.dense(features))&lt;br/&gt;}&lt;br/&gt;trainingData.cache()&lt;br/&gt;val model = new RidgeRegressionWithSGD().run(trainingData)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;得到一个新的数据集评分&lt;/p&gt;&lt;pre&gt;&lt;code&gt;val scores = meetup3.map { row =&amp;gt;&lt;br/&gt;      val features = Vectors.dense(Array[Double](1.0,row(1).toString().toDouble, &lt;br/&gt;                                                 row(4).toString().toDouble,row(5).toString().toDouble, &lt;br/&gt;                                                 row(6).toString().toDouble,row(7).toString().toDouble,&lt;br/&gt;                                                 row(8).toString().toDouble,row(9).toString().toDouble,&lt;br/&gt;                                                 row(10).toString().toDouble,row(11).toString().toDouble, &lt;br/&gt;                                                 row(12).toString().toDouble,row(13).toString().toDouble,&lt;br/&gt;                                                 row(14).toString().toDouble,row(15).toString().toDouble,&lt;br/&gt;                                                 row(16).toString().toDouble,row(17).toString().toDouble,&lt;br/&gt;                                                 row(18).toString().toDouble,row(19).toString().toDouble,&lt;br/&gt;                                                 row(20).toString().toDouble,row(21).toString().toDouble, &lt;br/&gt;                                                 row(22).toString().toDouble,row(23).toString().toDouble,&lt;br/&gt;                                                 row(24).toString().toDouble,row(25).toString().toDouble, &lt;br/&gt;                                                 row(26).toString().toDouble,row(27).toString().toDouble))&lt;br/&gt;      (row(0),row(2),row(3), model.predict(features)) &lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;scores.foreach(println)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;描述Spark模型结果和真实RSVP数据的对比。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.4671875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPp9al5nwZlgX8iaN6CuTQT0SIQEOlvVwGib8190F1vVheNld3yFXMkvjKQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4.使用Spark Streaming建立回归模型&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前面的两个例子展示了如何基于批处理数据构建模型和即席查询，现在开始建立一个Spark Streaming回归模型。使用流式的方法建立模型使得我们可以更频繁的更新模型，获取最新的数据，预测也更准确。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里可能和批处理的方法稍有不同。为了展示使用流式回归模型，这里简单的使用每分钟的RSVP数据（替代前面批量预测中按小时处理）来生成连续的流数据来预测接下来的十分钟内的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，使用Kafka来输入数据，代码见这里。这部分代码简单的设置Kafka为输入源，设置topic、broker list和Spark Streaming作为输入参数，它可以连接Kafka并获取数据。&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;def loadDataFromKafka(topics: String,&lt;br/&gt;                           brokerList: String,&lt;br/&gt;                           ssc: StreamingContext): DStream[String] = {&lt;br/&gt;            val topicsSet = topics.split(&quot;,&quot;).toSet&lt;br/&gt;            val kafkaParams = Map[String, String](&quot;metadata.broker.list&quot; -&amp;gt; brokerList)&lt;br/&gt;            val messages = KafkaUtils.createDirectStream[String, String, StringDecoder, StringDecoder](ssc, kafkaParams, topicsSet)&lt;br/&gt;            messages.map(_._2)&lt;br/&gt;     }&lt;br/&gt;     val dstream = loadDataFromKafka(topics, brokerList, ssc)&lt;br/&gt;对DStream进行transform操作获得RSVP值：&lt;br/&gt;     val stream = dstream.transform { rdd =&amp;gt;&lt;br/&gt;     val parsed1 = sqlContext.read.json(rdd)&lt;br/&gt;     parsed1.registerTempTable(&quot;parsed1&quot;)&lt;br/&gt;     val parsed2 = sqlContext.sql(&quot;&lt;br/&gt;            select  m,&lt;br/&gt;                    cnt,&lt;br/&gt;                    mtime&lt;br/&gt;            from    (select   (round(mtime/60000)-(&quot; + current_time + &quot;/60000 ))/1000.0 as m,&lt;br/&gt;                              count(*) as cnt,&lt;br/&gt;                              round(mtime/60000) as mtime&lt;br/&gt;                    from      (select distinct * from parsed1) a&lt;br/&gt;                    group&lt;br/&gt;                    by        (round(mtime/60000)-(&quot; + current_time + &quot;/60000 ))/1000.0,&lt;br/&gt;                              round(mtime/60000) ) aa&lt;br/&gt;            where   cnt &amp;gt; 20&lt;br/&gt;            &quot;)&lt;br/&gt;     parsed2.rdd&lt;br/&gt;     }&lt;br/&gt;     stream.print()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;转换数据结构来训练模型：&lt;br/&gt;一个数据流为训练数据，actl_stream；另一个数据流用来预测，pred_stream。预测数据流为当前训练数据流时刻的下一个10分钟时间间隔。&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;val actl_stream = stream.map(x =&amp;gt; &lt;br/&gt;           LabeledPoint(x(1).toString.toDouble,Vectors.dense(Array(1.0,x(0).toString.toDouble))) ).cache()&lt;br/&gt;     actl_stream.print()&lt;br/&gt;     val pred_stream = stream.map(x =&amp;gt; &lt;br/&gt;           LabeledPoint((x(2).toString.toDouble+10)*60000,Vectors.dense(Array(1.0,x(0).toString.toDouble))) )&lt;br/&gt;     pred_stream.print()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;用时间间隔的数据作为特征训练流式模型，这里的场景非常简单，只是为了说明问题。实际的产品模型需要结合前面讨论的按天和周末的模型来提高预测的准确性。&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;val numFeatures = 2&lt;br/&gt;     val model = new StreamingLinearRegressionWithSGD().setInitialWeights(Vectors.zeros(numFeatures)&lt;br/&gt;     model.trainOn(actl_stream)&lt;br/&gt;最后，应用预测模型对下一个时间间隔的数据进行预测：&lt;br/&gt;  val rslt_stream = model.predictOnValues(pred_stream.map(lp =&amp;gt; (lp.label, lp.features)))&lt;br/&gt;     rslt_stream.print()&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;下图为流式模型预测的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.434375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2PZzaFwWqiaBsib4ET36c8XPpgjgstiaXTYiaWoMIo1IYvuZbDD6v975ldI7oJAMUSgIlGCtCxuav7jGw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假如利用最近十分钟的RSVP数据，可以更好的预测接下来的十分钟左右的数据。将来为了更好的预测需要考虑增加更多的特征来提高模型的健壮性。预测的结果流式的写入Kudu，使用API可以很容易的使用这些预测数据来自动的分配资源。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>