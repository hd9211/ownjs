<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>74ac97a80f1c58ba45a80842d2e3896a</guid>
<title>MySQL 索引连环 18 问</title>
<link>https://toutiao.io/k/x7420rp</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;post-topic-des nc-post-content&quot;&gt;
&lt;p&gt;MySQL作为互联网中非常热门的数据库，现在大厂面试题横竖绕不开MySQL，其中MySQL索引是大厂必考面试题。今天带来了MySQL索引的常考面试题，看看你能答对多少~ &lt;/p&gt; 
&lt;p&gt;这是本期的MySQL索引面试题目录，不会的快快查漏补缺~&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;目录&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20210413/540390845_1618325752025/image-20210411230042052.png&quot;/&gt;&lt;/p&gt; 
&lt;h2&gt;1. 索引是什么？&lt;/h2&gt; 
&lt;p&gt;索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;索引是一种数据结构。数据库索引，是数据库管理系统中一个&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。而且索引是一个文件，它是要占据物理空间的。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。比如我们在查字典的时候，前面都有检索的拼音和偏旁、笔画等，然后找到对应字典页码，这样然后就打开字典的页数就可以知道我们要搜索的某一个key的全部值的信息了。&lt;/p&gt; 
&lt;h2&gt;2. 索引有哪些优缺点？&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;索引的优点&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;可以大大加快数据的检索速度，这也是创建索引的最主要的原因。 &lt;/li&gt;
 &lt;li&gt;通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;索引的缺点&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增/改/删的执行效率； &lt;/li&gt;
 &lt;li&gt;空间方面：索引需要占物理空间。 &lt;/li&gt;
&lt;/ul&gt; 
&lt;h2&gt;3. MySQL有哪几种索引类型？&lt;/h2&gt; 
&lt;p&gt;1、从存储结构上来划分：BTree索引（B-Tree或B+Tree索引），Hash索引，full-index全文索引，R-Tree索引。这里所描述的是索引存储时保存的形式，&lt;/p&gt; 
&lt;p&gt;2、从应用层次来分：普通索引，唯一索引，复合索引。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;普通索引：即一个索引只包含单个列，一个表可以有多个单列索引&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;唯一索引：索引列的值必须唯一，但允许有空值&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;复合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;聚簇索引(聚集索引)：并不是一种单独的索引类型，而是一种数据存储方式。具体细节取决于不同的实现，InnoDB的聚簇索引其实就是在同一个结构中保存了B-Tree索引(技术上来说是B+Tree)和数据行。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;非聚簇索引： 不是聚簇索引，就是非聚簇索引&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;3、根据中数据的物理顺序与键值的逻辑（索引）顺序关系： 聚集索引，非聚集索引。&lt;/p&gt; 
&lt;h2&gt;4. 说一说索引的底层实现？&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Hash索引&lt;/strong&gt; &lt;/p&gt; 
&lt;p&gt;&lt;span&gt;基于&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%93%88%E5%B8%8C%E8%A1%A8&quot; target=&quot;_blank&quot;&gt;哈希表&lt;/a&gt;实现，只有精确匹配索引所有列的查询才有效，对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（hash code），并且Hash索引将所有的哈希码存储在索引中，同时在索引表中保存指向每个数据行的指针。&lt;/span&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;图片来源：&lt;a href=&quot;https://www.javazhiyin.com/40232.html&quot; target=&quot;_blank&quot; from-niu=&quot;default&quot;&gt;https://www.javazhiyin.com/40232.html&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20210413/540390845_1618325752261/image-20210411215012443.png&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;B-Tree索引&lt;/strong&gt;（MySQL使用B+Tree）&lt;/p&gt; 
&lt;p&gt;B-Tree能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，数据分布在各个节点之中。&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20210413/540390845_1618325752112/image-20210411215023820.png&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;B+Tree索引&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;是B-Tree的改进版本，同时也是数据库索引索引所采用的存储结构。数据都在叶子节点上，并且增加了顺序访问指针，每个叶子节点都指向相邻的叶子节点的地址。相比B-Tree来说，进行范围查找时只需要查找两个节点，进行遍历即可。而B-Tree需要获取所有节点，相比之下B+Tree效率更高。&lt;/p&gt; 
&lt;p&gt;B+tree性质：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;n棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;B+ 树中，数据对象的插入和删除仅在叶节点上进行。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20210413/540390845_1618325752195/image-20210411215044332.png&quot;/&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;5. 为什么索引结构默认使用B+Tree，而不是B-Tree，Hash，&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E4%BA%8C%E5%8F%89%E6%A0%91&quot; target=&quot;_blank&quot;&gt;二叉树&lt;/a&gt;，&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%BA%A2%E9%BB%91%E6%A0%91&quot; target=&quot;_blank&quot;&gt;红黑树&lt;/a&gt;？&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;B-tree： 从两个方面来回答&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;B+树的磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B(B-)树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对&lt;code&gt;IO读写次数就降低&lt;/code&gt;了。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在&lt;code&gt;区间查询&lt;/code&gt;的情况，所以通常B+树用于数据库索引。&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;Hash： &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;虽然可以快速定位，但是没有顺序，IO复杂度高；&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;基于Hash表实现，只有Memory存储引擎显式支持哈希索引 ；&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;适合&lt;strong&gt;等值查询&lt;/strong&gt;，如=、in()、&amp;lt;=&amp;gt;，不支持范围查询 ；&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;因为不是按照索引值顺序存储的，就不能像B+Tree索引一样利用索引完成&lt;a target=&quot;_blank&quot; from-niu=&quot;default&quot;&gt;排序&lt;/a&gt; ；&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;Hash索引在查询等值时非常快 ；&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;因为Hash索引始终索引的&lt;strong&gt;所有列的全部内容&lt;/strong&gt;，所以不支持部分索引列的匹配查找 ；&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题 。&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E4%BA%8C%E5%8F%89%E6%A0%91&quot; target=&quot;_blank&quot;&gt;二叉树&lt;/a&gt;： 树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%BA%A2%E9%BB%91%E6%A0%91&quot; target=&quot;_blank&quot;&gt;红黑树&lt;/a&gt;： 树的高度随着数据量增加而增加，IO代价高。&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;6. 讲一讲聚簇索引与非聚簇索引？&lt;/h2&gt; 
&lt;p&gt;在 InnoDB 里，索引B+ Tree的叶子节点存储了整行数据的是主键索引，也被称之为聚簇索引，即将数据存储与索引放到了一块，找到索引也就找到了数据。&lt;/p&gt; 
&lt;p&gt;而索引B+ Tree的叶子节点存储了主键的值的是非主键索引，也被称之为非聚簇索引、二级索引。&lt;/p&gt; 
&lt;p&gt;聚簇索引与非聚簇索引的区别：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;非聚集索引与聚集索引的区别在于非聚集索引的叶子节点不存储表中的数据，而是存储该列对应的主键（行号） &lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;对于InnoDB来说，想要查找数据我们还需要根据主键再去聚集索引中进行查找，这个再根据聚集索引查找数据的过程，我们称为&lt;strong&gt;回表&lt;/strong&gt;。第一次索引一般是顺序IO，回表的操作属于随机IO。需要回表的次数越多，即随机IO次数越多，我们就越倾向于使用全表扫描 。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;通常情况下， 主键索引（聚簇索引）查询只会查一次，而非主键索引（非聚簇索引）需要回表查询多次。当然，如果是覆盖索引的话，查一次即可 &lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;注意：MyISAM无论主键索引还是二级索引都是非聚簇索引，而InnoDB的主键索引是聚簇索引，二级索引是非聚簇索引。我们自己建的索引基本都是非聚簇索引。&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;h2&gt;7. 非聚簇索引一定会回表查询吗？&lt;/h2&gt; 
&lt;p&gt;不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。一个索引包含（覆盖）所有需要查询字段的值，被称之为&quot;覆盖索引&quot;。&lt;/p&gt; 
&lt;p&gt;举个简单的例子，假设我们在学生表的成绩上建立了索引，那么当进行&lt;code&gt;select score from student where score &amp;gt; 90&lt;/code&gt;的查询时，在索引的叶子节点上，已经包含了score 信息，不会再次进行回表查询。&lt;/p&gt; 
&lt;h2&gt;8. 联合索引是什么？为什么需要注意联合索引中的顺序？&lt;/h2&gt; 
&lt;p&gt;MySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。&lt;/p&gt; 
&lt;p&gt;具体原因为:&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;MySQL使用索引时需要索引有序，假设现在建立了&quot;name，age，school&quot;的联合索引，那么索引的&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;为: 先按照name&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;，如果name相同，则按照age&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;，如果age的值也相等，则按照school进行&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。&lt;/p&gt; 
&lt;h2&gt;9. 讲一讲MySQL的最左前缀原则?&lt;/h2&gt; 
&lt;p&gt;最左前缀原则就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。&lt;br/&gt;mysql会一直向右匹配直到遇到范围查询(&amp;gt;、&amp;lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &amp;gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。&lt;/p&gt; 
&lt;p&gt;=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。&lt;/p&gt; 
&lt;h2&gt;10. 讲一讲前缀索引？&lt;/h2&gt; 
&lt;p&gt;因为可能我们索引的字段非常长，这既占内存空间，也不利于维护。所以我们就想，如果只把很长字段的前面的公共部分作为一个索引，就会产生超级加倍的效果。但是，我们需要注意，order by不支持前缀索引 。&lt;/p&gt; 
&lt;p&gt; 流程是： &lt;/p&gt; 
&lt;p&gt; 先计算完整列的选择性 :&lt;code&gt;select count(distinct col_1)/count(1) from table_1&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt; 再计算不同前缀长度的选择性 :&lt;code&gt;select count(distinct left(col_1,4))/count(1) from table_1&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt; 找到最优长度之后，创建前缀索引 :&lt;code&gt;create index idx_front on table_1 (col_1(4))&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;11. 了解索引下推吗？&lt;/h2&gt; 
&lt;p&gt;MySQL 5.6引入了索引下推优化。默认开启，使用SET optimizer_switch = ‘index_condition_pushdown=off’;可以将其关闭。 &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;有了索引下推优化，可以在&lt;strong&gt;减少回表次数&lt;/strong&gt; &lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;在InnoDB中只针对二级索引有效&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;官方文档中给的例子和解释如下：&lt;/p&gt; 
&lt;p&gt;在 people_table中有一个二级索引(zipcode，lastname，address)，查询是SELECT * FROM people WHERE zipcode=’95054′ AND lastname LIKE ‘%etrunia%’ AND address LIKE ‘%Main Street%’; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;如果没有使用索引下推技术，则MySQL会通过zipcode=’95054’从存储引擎中查询对应的数据，返回到MySQL服务端，然后MySQL服务端基于lastname LIKE ‘%etrunia%’ and address LIKE ‘%Main Street%’来判断数据是否符合条件 &lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;如果使用了索引下推技术，则MYSQL首先会返回符合zipcode=’95054’的索引，然后根据lastname LIKE ‘%etrunia%’ and address LIKE ‘%Main Street%’来判断索引是否符合条件。如果符合条件，则根据该索引来定位对应的数据，如果不符合，则直接reject掉。&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;h2&gt;12. 怎么查看MySQL语句有没有用到索引？&lt;/h2&gt; 
&lt;p&gt;通过explain，如以下例子：&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;EXPLAIN SELECT * FROM employees.titles WHERE emp_no=&#x27;10001&#x27; AND title=&#x27;Senior Engineer&#x27; AND from_date=&#x27;1986-06-26&#x27;;&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;id&lt;/th&gt; 
   &lt;th&gt;select_type&lt;/th&gt; 
   &lt;th&gt;table&lt;/th&gt; 
   &lt;th&gt;partitions&lt;/th&gt; 
   &lt;th&gt;type&lt;/th&gt; 
   &lt;th&gt;possible_keys&lt;/th&gt; 
   &lt;th&gt;key&lt;/th&gt; 
   &lt;th&gt;key_len&lt;/th&gt; 
   &lt;th&gt;ref&lt;/th&gt; 
   &lt;th&gt;filtered&lt;/th&gt; 
   &lt;th&gt;rows&lt;/th&gt; 
   &lt;th&gt;Extra&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;SIMPLE&lt;/td&gt; 
   &lt;td&gt;titles&lt;/td&gt; 
   &lt;td&gt;null&lt;/td&gt; 
   &lt;td&gt;const&lt;/td&gt; 
   &lt;td&gt;PRIMARY&lt;/td&gt; 
   &lt;td&gt;PRIMARY&lt;/td&gt; 
   &lt;td&gt;59&lt;/td&gt; 
   &lt;td&gt;const,const,const&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td/&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;id：在⼀个⼤的查询语句中每个&lt;strong&gt;SELECT&lt;/strong&gt;关键字都对应⼀个唯⼀的id ，如explain select * from s1 where id = (select id from s1 where name = &#x27;egon1&#x27;);第一个select的id是1，第二个select的id是2。有时候会出现两个select，但是id却都是1，这是因为优化器把子查询变成了连接查询 。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;select_type：select关键字对应的那个查询的类型，如SIMPLE,PRIMARY,SUBQUERY,DEPENDENT,SNION 。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;table：每个查询对应的表名 。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;type：&lt;code&gt;type&lt;/code&gt; 字段比较重要, 它提供了判断查询是否高效的重要依据依据. 通过 &lt;code&gt;type&lt;/code&gt; 字段, 我们判断此次查询是 &lt;code&gt;全表扫描&lt;/code&gt; 还是 &lt;code&gt;索引扫描&lt;/code&gt; 等。如const(主键索引或者唯一二级索引进行等值匹配的情况下),ref(普通的⼆级索引列与常量进⾏等值匹配),index(扫描全表索引的覆盖索引) 。&lt;/p&gt; &lt;p&gt;通常来说, 不同的 type 类型的性能关系如下:&lt;br/&gt;&lt;code&gt;ALL &amp;lt; index &amp;lt; range ~ index_merge &amp;lt; ref &amp;lt; eq_ref &amp;lt; const &amp;lt; system&lt;/code&gt;&lt;br/&gt;&lt;code&gt;ALL&lt;/code&gt; 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.&lt;br/&gt;而 &lt;code&gt;index&lt;/code&gt; 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快.&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;possible_key：查询中可能用到的索引&lt;em&gt;(可以把用不到的删掉，降低优化器的优化时间)&lt;/em&gt; 。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;key：此字段是 MySQL 在当前查询时所真正使用到的索引。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;filtered：查询器预测满足下一次查询条件的百分比 。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;rows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数.&lt;br/&gt;这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;extra：表示额外信息，如Using where,Start temporary,End temporary,Using temporary等。&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;h2&gt;13. 为什么官方建议使用自增长主键作为索引？&lt;/h2&gt; 
&lt;p&gt;结合B+Tree的特点，自增主键是连续的，在插入过程中尽量减少页分裂，即使要进行页分裂，也只会分裂很少一部分。并且能减少数据的移动，每次插入都是插入到最后。总之就是减少分裂和移动的频率。&lt;/p&gt; 
&lt;p&gt;插入连续的数据：&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;图片来自：&lt;a href=&quot;https://www.javazhiyin.com/40232.html&quot; target=&quot;_blank&quot; from-niu=&quot;default&quot;&gt;https://www.javazhiyin.com/40232.html&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20210413/540390845_1618325752160/java10-1562726251.gif&quot;/&gt;&lt;/p&gt; 
&lt;p&gt;插入非连续的数据：&lt;/p&gt; 
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://uploadfiles.nowcoder.com/files/20210413/540390845_1618325752674/java8-1562726251.gif&quot;/&gt;&lt;/p&gt; 
&lt;h2&gt;14. 如何创建索引？&lt;/h2&gt; 
&lt;p&gt;创建索引有三种方式。&lt;/p&gt; 
&lt;p&gt;1、 在执行CREATE TABLE时创建索引&lt;/p&gt; 
&lt;pre class=&quot;prettyprint lang-sql&quot; from-niu=&quot;default&quot;&gt;CREATE TABLE user_index2 (
    id INT auto_increment PRIMARY KEY,
    first_name VARCHAR (16),
    last_name VARCHAR (16),
    id_card VARCHAR (18),
    information text,
    KEY name (first_name, last_name),
    FULLTEXT KEY (information),
    UNIQUE KEY (id_card)
);
&lt;/pre&gt; 
&lt;p&gt;2、 使用ALTER TABLE命令去增加索引。&lt;/p&gt; 
&lt;pre class=&quot;prettyprint lang-sql&quot; from-niu=&quot;default&quot;&gt;ALTER TABLE table_name ADD INDEX index_name (column_list);&lt;/pre&gt; 
&lt;p&gt;ALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。&lt;/p&gt; 
&lt;p&gt;其中table_name是要增加索引的表名，column_list指出对哪些列进行索引，多列时各列之间用逗号分隔。&lt;/p&gt; 
&lt;p&gt;索引名index_name可自己命名，缺省时，MySQL将根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可以在同时创建多个索引。&lt;br/&gt;3、 使用CREATE INDEX命令创建。&lt;/p&gt; 
&lt;pre class=&quot;prettyprint lang-sql&quot; from-niu=&quot;default&quot;&gt;CREATE INDEX index_name ON table_name (column_list);&lt;/pre&gt; 
&lt;h2&gt;15. 创建索引时需要注意什么？&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值； &lt;/li&gt;
 &lt;li&gt;取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高； &lt;/li&gt;
 &lt;li&gt;索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。 &lt;/li&gt;
&lt;/ul&gt; 
&lt;h2&gt;16. 建索引的原则有哪些？&lt;/h2&gt; 
&lt;p&gt;1、最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&amp;gt;、&amp;lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &amp;gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。&lt;/p&gt; 
&lt;p&gt;2、=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。&lt;/p&gt; 
&lt;p&gt;3、尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。&lt;/p&gt; 
&lt;p&gt;4、索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。&lt;/p&gt; 
&lt;p&gt;5、尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。&lt;/p&gt; 
&lt;h2&gt;17. 使用索引查询一定能提高查询的性能吗？&lt;/h2&gt; 
&lt;p&gt;通常通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价。&lt;/p&gt; 
&lt;p&gt;索引需要空间来存储，也需要定期维护， 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的I* NSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询(INDEX RANGE SCAN)适用于两种情况:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;基于一个范围的检索，一般查询返回结果集小于表中记录数的30%。 &lt;/li&gt;
 &lt;li&gt;基于非唯一性索引的检索。 &lt;/li&gt;
&lt;/ul&gt; 
&lt;h2&gt;18. 什么情况下不走索引（索引失效）？&lt;/h2&gt; 
&lt;h5&gt;1、使用!= 或者 &amp;lt;&amp;gt; 导致索引失效&lt;/h5&gt; 
&lt;h5&gt;2、类型不一致导致的索引失效&lt;/h5&gt; 
&lt;h5&gt;3、函数导致的索引失效&lt;/h5&gt; 
&lt;p&gt;如：&lt;/p&gt; 
&lt;pre class=&quot;prettyprint&quot; from-niu=&quot;default&quot;&gt;SELECT * FROM `user` WHERE DATE(create_time) = &#x27;2020-09-03&#x27;;&lt;/pre&gt;
&lt;p&gt;如果你的索引字段使用了函数，对不起，他是真的不走索引的。&lt;/p&gt; 
&lt;h5&gt;4、运算符导致的索引失效&lt;/h5&gt; 
&lt;pre class=&quot;prettyprint&quot; from-niu=&quot;default&quot;&gt;SELECT * FROM `user` WHERE age - 1 = 20;&lt;/pre&gt;
&lt;p&gt;如果你对列进行了（+，-，*，/，!）, 那么都将不会走索引。&lt;/p&gt; 
&lt;h5&gt;5、OR引起的索引失效&lt;/h5&gt; 
&lt;pre class=&quot;prettyprint&quot; from-niu=&quot;default&quot;&gt;SELECT * FROM `user` WHERE `name` = &#x27;张三&#x27; OR height = &#x27;175&#x27;;&lt;/pre&gt;
&lt;p&gt;OR导致索引是在特定情况下的，并不是所有的OR都是使索引失效，如果OR连接的是同一个字段，那么索引不会失效，反之索引失效。&lt;/p&gt; 
&lt;h5&gt;6、模糊搜索导致的索引失效&lt;/h5&gt; 
&lt;pre class=&quot;prettyprint&quot; from-niu=&quot;default&quot;&gt;SELECT * FROM `user` WHERE `name` LIKE &#x27;%冰&#x27;;&lt;/pre&gt;
&lt;p&gt;当&lt;code&gt;%&lt;/code&gt;放在匹配字段前是不走索引的，放在后面才会走索引。&lt;/p&gt; 
&lt;h5&gt;7、NOT IN、NOT EXISTS导致索引失效&lt;/h5&gt; 
&lt;h2 id=&quot;end&quot;&gt;End&lt;/h2&gt; 
&lt;p&gt;整理不易，点个赞呗！&lt;/p&gt; 
&lt;h2&gt;巨人的肩膀&lt;/h2&gt; 
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/ThinkWon/article/details/104778621&quot; target=&quot;_blank&quot; from-niu=&quot;default&quot;&gt;https://blog.csdn.net/ThinkWon/article/details/104778621&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://www.javazhiyin.com/40232.html&quot; target=&quot;_blank&quot; from-niu=&quot;default&quot;&gt;https://www.javazhiyin.com/40232.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://juejin.cn/post/6844904039860142088&quot; target=&quot;_blank&quot; from-niu=&quot;default&quot;&gt;https://juejin.cn/post/6844904039860142088&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/ThinkWon/article/details/104778621&quot; target=&quot;_blank&quot; from-niu=&quot;default&quot;&gt;https://blog.csdn.net/ThinkWon/article/details/104778621&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href=&quot;https://segmentfault.com/a/1190000008131735&quot; target=&quot;_blank&quot; from-niu=&quot;default&quot;&gt;https://segmentfault.com/a/1190000008131735&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>eacdca8e651bb9040c042a3d6cec42c3</guid>
<title>[推荐] 一文理解 Kafka 的选举机制与 Rebalance 机制</title>
<link>https://toutiao.io/k/oaspge5</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-source-line=&quot;1&quot;&gt;Kafka是一个高性能，高容错，多副本，可复制的分布式消息系统。在整个系统中，涉及到多处选举机制，被不少人搞混，这里总结一下，本篇文章大概会从三个方面来讲解。&lt;/p&gt;&lt;ol data-source-line=&quot;3&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;控制器（Broker）选举机制&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;分区副本选举机制&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;消费组选举机制&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;7&quot;&gt;如果对Kafka不了解的话，可以先看这篇博客《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247484251&amp;amp;idx=1&amp;amp;sn=92d6b50c5987f4f80316313db05b56ff&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;一文快速了解Kafka&lt;/a&gt;》。&lt;/p&gt;&lt;h2 data-source-line=&quot;9&quot;&gt;控制器选举&lt;/h2&gt;&lt;p data-source-line=&quot;11&quot;&gt;控制器是Kafka的核心组件，它的主要作用是在Zookeeper的帮助下管理和协调整个Kafka集群。集群中任意一个Broker都能充当控制器的角色，但在运行过程中，只能有一个Broker成为控制器。&lt;/p&gt;&lt;blockquote data-source-line=&quot;13&quot;&gt;&lt;p&gt;控制器的作用可以查看文末&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-source-line=&quot;15&quot;&gt;控制器选举可以认为是Broker的选举。&lt;/p&gt;&lt;p data-source-line=&quot;17&quot;&gt;集群中第一个启动的Broker会通过在Zookeeper中创建临时节点/controller来让自己成为控制器，其他Broker启动时也会在zookeeper中创建临时节点，但是发现节点已经存在，所以它们会收到一个异常，意识到控制器已经存在，那么就会在Zookeeper中创建watch对象，便于它们收到控制器变更的通知。&lt;/p&gt;&lt;p data-source-line=&quot;19&quot;&gt;那么如果控制器由于网络原因与Zookeeper断开连接或者异常退出，那么其他broker通过watch收到控制器变更的通知，就会去尝试创建临时节点/controller，如果有一个Broker创建成功，那么其他broker就会收到创建异常通知，也就意味着集群中已经有了控制器，其他Broker只需创建watch对象即可。&lt;/p&gt;&lt;p data-source-line=&quot;21&quot;&gt;如果集群中有一个Broker发生异常退出了，那么控制器就会检查这个broker是否有分区的副本leader，如果有那么这个分区就需要一个新的leader，此时控制器就会去遍历其他副本，决定哪一个成为新的leader，同时更新分区的ISR集合。&lt;/p&gt;&lt;p data-source-line=&quot;23&quot;&gt;如果有一个Broker加入集群中，那么控制器就会通过Broker ID去判断新加入的Broker中是否含有现有分区的副本，如果有，就会从分区副本中去同步数据。&lt;/p&gt;&lt;h3 data-source-line=&quot;25&quot;&gt;防止控制器脑裂&lt;/h3&gt;&lt;p data-source-line=&quot;27&quot;&gt;如果控制器所在broker挂掉了或者Full GC停顿时间太长超过zookeeper&lt;code&gt;session timeout&lt;/code&gt;出现假死，Kafka集群必须选举出新的控制器，但如果之前被取代的控制器又恢复正常了，它依旧是控制器身份，这样集群就会出现两个控制器，这就是控制器脑裂问题。&lt;/p&gt;&lt;p data-source-line=&quot;29&quot;&gt;解决方法：&lt;/p&gt;&lt;p data-source-line=&quot;31&quot;&gt;为了解决Controller脑裂问题，ZooKeeper中还有一个与Controller有关的持久节点/controller_epoch，存放的是一个整形值的epoch number（纪元编号，也称为隔离令牌），集群中每选举一次控制器，就会通过Zookeeper创建一个数值更大的epoch number，如果有broker收到比这个epoch数值小的数据，就会忽略消息。&lt;/p&gt;&lt;h2 data-source-line=&quot;33&quot;&gt;分区副本选举机制&lt;/h2&gt;&lt;p data-source-line=&quot;35&quot;&gt;由控制器执行。&lt;/p&gt;&lt;ol data-source-line=&quot;37&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;从Zookeeper中读取当前分区的所有ISR(in-sync replicas)集合。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;调用配置的分区选择算法选择分区的leader。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-source-line=&quot;40&quot;&gt;Unclean leader选举&lt;/h3&gt;&lt;p data-source-line=&quot;42&quot;&gt;ISR是动态变化的，所以ISR列表就有为空的时候，ISR为空说明leader副本也挂掉了。此时Kafka要重新选举出新的leader。但ISR为空，怎么进行leader选举呢？&lt;/p&gt;&lt;p data-source-line=&quot;44&quot;&gt;Kafka把不在ISR列表中的存活副本称为“非同步副本”，这些副本中的消息远远落后于leader，如果选举这种副本作为leader的话就可能造成数据丢失。所以Kafka broker端提供了一个参数&lt;code&gt;unclean.leader.election.enable&lt;/code&gt;，用于控制是否允许非同步副本参与leader选举；如果开启，则当 ISR为空时就会从这些副本中选举新的leader，这个过程称为 Unclean leader选举。&lt;/p&gt;&lt;p data-source-line=&quot;46&quot;&gt;可以根据实际的业务场景选择是否开启Unclean leader选举。一般建议是关闭Unclean leader选举，因为通常数据的一致性要比可用性重要。&lt;/p&gt;&lt;h2 data-source-line=&quot;48&quot;&gt;消费组选主&lt;/h2&gt;&lt;p data-source-line=&quot;50&quot;&gt;在Kafka的消费端，会有一个消费者协调器以及消费组，组协调器（Group Coordinator）需要为消费组内的消费者选举出一个消费组的leader。&lt;/p&gt;&lt;p data-source-line=&quot;52&quot;&gt;如果消费组内还没有leader，那么第一个加入消费组的消费者即为消费组的leader，如果某一个时刻leader消费者由于某些原因退出了消费组，那么就会重新选举leader，选举方式如下：&lt;/p&gt;&lt;pre data-source-line=&quot;53&quot;&gt;&lt;code&gt;private val members = new mutable&lt;span&gt;.HashMap&lt;/span&gt;[String, MemberMetadata]&lt;br/&gt;leaderId = members&lt;span&gt;.keys&lt;/span&gt;&lt;span&gt;.headOption&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-source-line=&quot;57&quot;&gt;在组协调器中消费者的信息是以HashMap的形式存储的，其中key为消费者的member_id，而value是消费者相关的元数据信息。而leader的取值为HashMap中的第一个键值对的key（等同于随机）。&lt;/p&gt;&lt;blockquote data-source-line=&quot;59&quot;&gt;&lt;p&gt;消费组的Leader和Coordinator没有关联。消费组的leader负责Rebalance过程中消费分配方案的制定。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-source-line=&quot;61&quot;&gt;消费端Rebalance机制&lt;/h2&gt;&lt;p data-source-line=&quot;63&quot;&gt;就Kafka消费端而言，有一个难以避免的问题就是消费者的重平衡即Rebalance。Rebalance是让一个消费组的所有消费者就如何消费订阅topic的所有分区达成共识的过程，在Rebalance过程中，所有Consumer实例都会停止消费，等待Rebalance的完成。因为要停止消费等待重平衡完成，因此Rebalance会严重影响消费端的TPS，是应当尽量避免的。&lt;/p&gt;&lt;h3 data-source-line=&quot;65&quot;&gt;触发Rebalance的时机&lt;/h3&gt;&lt;p data-source-line=&quot;67&quot;&gt;Rebalance 的触发条件有3个。&lt;/p&gt;&lt;ol data-source-line=&quot;69&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;消费组成员个数发生变化。例如有新的Consumer实例加入或离开该消费组。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;订阅的 Topic 个数发生变化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;订阅 Topic 的分区数发生变化。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;73&quot;&gt;Rebalance 发生时，Group 下所有Consumer 实例都会协调在一起共同参与，kafka 能够保证尽量达到最公平的分配。但是 Rebalance 过程对 consumer group 会造成比较严重的影响。在 Rebalance 的过程中 consumer group 下的所有消费者实例都会停止工作，等待 Rebalance 过程完成。&lt;/p&gt;&lt;h3 data-source-line=&quot;75&quot;&gt;Rebalance过程&lt;/h3&gt;&lt;p data-source-line=&quot;77&quot;&gt;Rebalance过程分为两步：Join和Sync。&lt;/p&gt;&lt;ol data-source-line=&quot;79&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Join。所有成员都向Group Coordinator发送JoinGroup请求，请求加入消费组。一旦所有成员都发送了JoinGroup请求，Coordinator会从中选择一个Consumer担任leader的角色，并把组成员信息以及订阅信息发给leader——注意leader和coordinator不是一个概念。leader负责消费分配方案的制定。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;81&quot;&gt;&lt;img data-ratio=&quot;0.3856812933025404&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7GkYyUQ3uicbnn8hX8n5Q8weyPqYO6CLpXT6VBCqOOk6lufAZF72wCaMfEWg3GQfricGZrVnHI5DyZQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;866&quot;/&gt;&lt;/p&gt;&lt;ol start=&quot;2&quot; data-source-line=&quot;83&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Sync。这一步leader开始分配消费方案，即哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案封装进SyncGroup请求中发给coordinator，非leader也会发SyncGroup请求，只是内容为空。coordinator接收到分配方案之后会把方案塞进SyncGroup的response中发给各个consumer。这样组内的所有成员就都知道自己应该消费哪些分区了。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;85&quot;&gt;&lt;img data-ratio=&quot;0.42032332563510394&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7GkYyUQ3uicbnn8hX8n5Q8wehribjEppQw8B1zjpqOmgPkicKDsSLkjGO55SvbURnI5RrGs8VibLVY9xg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;866&quot;/&gt;&lt;/p&gt;&lt;h3 data-source-line=&quot;87&quot;&gt;避免不必要的Rebalance&lt;/h3&gt;&lt;p data-source-line=&quot;89&quot;&gt;前面说过Rebalance发生的时机有三个，后两个时机是可以人为避免的。发生Rebalance最常见的原因是消费组成员个数发生变化。&lt;/p&gt;&lt;p data-source-line=&quot;91&quot;&gt;这其中消费者成员正常的添加和停掉导致Rebalance，也是无法避免。但是在某些情况下，Consumer实例会被Coordinator错误地认为已停止从而被踢出Group。从而导致rebalance。&lt;/p&gt;&lt;p data-source-line=&quot;93&quot;&gt;这种情况可以通过Consumer端的参数&lt;code&gt;session.timeout.ms&lt;/code&gt;和&lt;code&gt;max.poll.interval.ms&lt;/code&gt;进行配置。&lt;/p&gt;&lt;blockquote data-source-line=&quot;95&quot;&gt;&lt;p&gt;有关这种情况，可以查看博客《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247484391&amp;amp;idx=1&amp;amp;sn=09fc29827f315a20619551473f009531&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;一文理解Kafka重复消费的原因和解决方案&lt;/a&gt;》&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-source-line=&quot;97&quot;&gt;除了这个参数，Consumer还提供了控制发送心跳请求频率的参数，就是&lt;code&gt;heartbeat.interval.ms&lt;/code&gt;。这个值设置得越小，Consumer实例发送心跳请求的频率就越高。频繁地发送心跳请求会额外消耗带宽资源，但好处是能够更快地知道是否开启Rebalance，因为Coordinator通知各个Consumer实例是否开启Rebalance就是将REBALANCE_NEEDED标志封装进心跳请求的响应体中。&lt;/p&gt;&lt;p data-source-line=&quot;99&quot;&gt;总之，要为业务处理逻辑留下充足的时间使Consumer不会因为处理这些消息的时间太长而引发Rebalance，但也不能时间设置过长导致Consumer宕机但迟迟没有被踢出Group。&lt;/p&gt;&lt;h2 data-source-line=&quot;101&quot;&gt;补充&lt;/h2&gt;&lt;h3 data-source-line=&quot;103&quot;&gt;Kafka控制器的作用&lt;/h3&gt;&lt;p data-source-line=&quot;105&quot;&gt;Kafka控制器的作用是管理和协调Kafka集群，具体如下：&lt;/p&gt;&lt;ol data-source-line=&quot;107&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;主题管理：创建、删除Topic，以及增加Topic分区等操作都是由控制器执行。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;分区重分配：执行Kafka的reassign脚本对Topic分区重分配的操作，也是由控制器实现。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Preferred leader选举。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-source-line=&quot;111&quot;&gt;&lt;p&gt;因为在Kafka集群长时间运行中，broker的宕机或崩溃是不可避免的，leader就会发生转移，即使broker重新回来，也不会是leader了。在众多leader的转移过程中，就会产生leader不均衡现象，可能一小部分broker上有大量的leader，影响了整个集群的性能，所以就需要把leader调整回最初的broker上，这就需要Preferred leader选举。&lt;/p&gt;&lt;/blockquote&gt;&lt;ol start=&quot;4&quot; data-source-line=&quot;113&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;集群成员管理：控制器能够监控新broker的增加，broker的主动关闭与被动宕机，进而做其他工作。这也是利用Zookeeper的ZNode模型和Watcher机制，控制器会监听Zookeeper中/brokers/ids下临时节点的变化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数据服务：控制器上保存了最全的集群元数据信息，其他所有broker会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-source-line=&quot;116&quot;&gt;Kafka协调器&lt;/h3&gt;&lt;p data-source-line=&quot;118&quot;&gt;Kafka中主要有两种协调器：&lt;/p&gt;&lt;ol data-source-line=&quot;120&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;组协调器（Group Coordinator）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;消费者协调器（Consumer Coordinator）&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;123&quot;&gt;Kafka为了更好的实现消费组成员管理、位移管理以及Rebalance等，broker服务端引入了组协调器（Group Coordinator），消费端引入了消费者协调器（Consumer Coordinator）。&lt;/p&gt;&lt;p data-source-line=&quot;125&quot;&gt;每个broker启动时，都会创建一个组协调器实例，负责监控这个消费组里的所有消费者的心跳以及判断是否宕机，然后开启消费者Rebalance。&lt;/p&gt;&lt;p data-source-line=&quot;127&quot;&gt;每个Consumer启动时，会创建一个消费者协调器实例并会向Kafka集群中的某个节点发送FindCoordinatorRequest请求来查找对应的组协调器，并跟其建立网络连接。&lt;/p&gt;&lt;p data-source-line=&quot;129&quot;&gt;&lt;img data-ratio=&quot;0.4222222222222222&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7GkYyUQ3uicbnn8hX8n5Q8wefvcZJkrXDj6aj1ibwM2QXUtakFZ5ZfEpU5BLwHo9vDGk0EOIdCtTxxg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;131&quot;&gt;客户端的消费者协调器和服务端的组协调器会通过心跳保持通信。&lt;/p&gt;&lt;h3 data-source-line=&quot;133&quot;&gt;Kafka舍弃ZooKeeper的理由&lt;/h3&gt;&lt;p data-source-line=&quot;135&quot;&gt;Kafka目前强依赖于ZooKeeper：ZooKeeper为Kafka提供了元数据的管理，例如一些Broker的信息、主题数据、分区数据等等，还有一些选举、扩容等机制也都依赖ZooKeeper。&lt;/p&gt;&lt;ol data-source-line=&quot;137&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;运维复杂度&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;139&quot;&gt;运维Kafka的同时需要保证一个高可用的Zookeeper集群，增加了运维和故障排查的复杂度。&lt;/p&gt;&lt;ol start=&quot;2&quot; data-source-line=&quot;141&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;性能差&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ul data-source-line=&quot;143&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;在一些大公司，Kafka集群比较大，分区数很多的时候，ZooKeeper存储的元数据就会很多，性能就会变差。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ZooKeeper需要选举，选举的过程中是无法提供服务的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Zookeeper节点如果频繁发生Full Gc，与客户端的会话将超时，由于无法响应客户端的心跳请求，从而与会话相关联的临时节点也会被删除。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-source-line=&quot;147&quot;&gt;所以Kafka 2.8版本上支持内部的quorum服务来替换ZooKeeper的工作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>22ed3766d45b09a255ec0717186c4442</guid>
<title>[推荐] Redis：我是如何与客户端进行通信的</title>
<link>https://toutiao.io/k/dr4u4yt</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;江湖上说，&lt;strong&gt;天下武功，无坚不摧，唯快不破&lt;/strong&gt;，这句话简直是为我量身定制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我是一个Redis服务，最引以为傲的就是我的速度，我的 QPS 能达到10万级别。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我的手下有数不清的小弟，他们会时不时到我这来存放或者取走一些数据，我管他们叫做客户端，还给他们起了英文名叫 Redis-client。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有时候一个小弟会来的非常频繁，有时候一堆小弟会同时过来，但是，即使再多的小弟我也能管理的井井有条。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有一天，小弟们问我。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.8333333333333334&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyfoy2icYqicT72JftlHDibibSES2rlIOOYyFGNpDvc9lEy5Je4pkIpwpYjdA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;552&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;想当年，为了不让小弟们拖垮我傲人的速度，在设计和他们的通信协议时，我绞尽脑汁，制定了下面的三条原则：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;实现简单&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;针对计算机来说，解析速度快&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;针对人类来说，可读性强&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么这么设计呢？先来看看一条指令发出的过程，首先在客户端需要对指令操作进行封装，使用网络进行传输，最后在服务端进行相应的解析、执行。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.463768115942029&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicaLtJLCXG77p4PNzYoiaRAw5KYTmIWibRvsmxTp149neUMtI3gWFTiageu3ic5KFHm9HlmPkGxkCbZIMA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;690&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一过程如果设计成一种非常复杂的协议，那么封装、解析、传输的过程都将非常耗时，无疑会降低我的速度。什么，你问我为什么要遵循最后一条规则？算是对于程序员们的馈赠吧，我真是太善良了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我把创造出来的这种协议称为 RESP (&lt;code&gt;REdis Serialization Protocol&lt;/code&gt;)协议，它工作在 TCP 协议的上层，作为我和客户端之间进行通讯的标准形式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说到这，我已经有点迫不及待想让你们看看我设计出来的杰作了，但我好歹也是个大哥，得摆点架子，不能我主动拿来给你们看。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以我建议你直接使用客户端发出一条向服务器的命令，然后取出这条命令对应的报文来直观的看一下。话虽如此，不过我已经被封装的很严实了，正常情况下你是看不到我内部进行通讯的具体报文的，所以，你可以&lt;strong&gt;伪装&lt;/strong&gt;成一个Redis的服务端，来截获小弟们发给我的消息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实现起来也很简单，我和小弟之间是基于 Socket 进行通讯，所以在本地先启动一个&lt;code&gt;ServerSocket&lt;/code&gt;，用来监听Redis服务的6379端口：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;server&lt;/span&gt;() &lt;span&gt;throws&lt;/span&gt; IOException &lt;/span&gt;{&lt;br/&gt;    ServerSocket serverSocket = &lt;span&gt;new&lt;/span&gt; ServerSocket(&lt;span&gt;6379&lt;/span&gt;);&lt;br/&gt;    Socket socket = serverSocket.accept();&lt;br/&gt;    &lt;span&gt;byte&lt;/span&gt;[] bytes = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;byte&lt;/span&gt;[&lt;span&gt;1024&lt;/span&gt;];&lt;br/&gt;    InputStream input = socket.getInputStream();&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt;(input.read(bytes)!=&lt;span&gt;0&lt;/span&gt;){&lt;br/&gt;        System.out.println(&lt;span&gt;new&lt;/span&gt; String(bytes));&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后启动&lt;code&gt;redis-cli&lt;/code&gt;客户端，发送一条命令：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;set key1 value1&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时，伪装的服务端就会收到报文了，在控制台打印了：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;*3&lt;br/&gt;$3&lt;br/&gt;set&lt;br/&gt;$4&lt;br/&gt;key1&lt;br/&gt;$6&lt;br/&gt;value1&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到这里，隐隐约约看到了刚才输入的几个关键字，但是还有一些其他的字符，要怎么解释呢，是时候让我对协议报文中的格式进行一下揭秘了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我对小弟们说了，对大哥说话的时候得按规矩来，这样吧，你们在请求的时候要遵循下面的规则：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;*&amp;lt;参数数量&amp;gt; CRLF&lt;br/&gt;$&amp;lt;参数1的字节长度&amp;gt; CRLF&lt;br/&gt;&amp;lt;参数1的数据&amp;gt; CRLF&lt;br/&gt;$&amp;lt;参数2的字节长度&amp;gt; CRLF&lt;br/&gt;&amp;lt;参数2的数据&amp;gt; CRLF&lt;br/&gt;...&lt;br/&gt;$&amp;lt;参数N的字节长度&amp;gt; CRLF&lt;br/&gt;&amp;lt;参数N的数据&amp;gt; CRLF&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先解释一下每行末尾的&lt;code&gt;CRLF&lt;/code&gt;，转换成程序语言就是&lt;code&gt;\r\n&lt;/code&gt;，也就是回车加换行。看到这里，你也就能够明白为什么控制台打印出的指令是竖向排列了吧。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在命令的解析过程中，&lt;code&gt;set&lt;/code&gt;、&lt;code&gt;key1&lt;/code&gt;、&lt;code&gt;value1&lt;/code&gt;会被认为是3个参数，因此参数数量为3，对应第一行的&lt;code&gt;*3&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一个参数&lt;code&gt;set&lt;/code&gt;，长度为3对应&lt;code&gt;$3&lt;/code&gt;；第二个参数&lt;code&gt;key1&lt;/code&gt;，长度为4对应&lt;code&gt;$4&lt;/code&gt;；第三个参数&lt;code&gt;value1&lt;/code&gt;，长度为6对应&lt;code&gt;$6&lt;/code&gt;。在每个参数长度的下一行对应真正的参数数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到这，一条指令被转换为协议报文的过程是不是就很好理解了？&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4444444444444444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyf1BJ8xSic8HRQJKdbo0xVqK3ZpxPW5jFxibEcGeajCuxuoqg8PFDkINEg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;900&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当小弟对我发送完请求后，作为大哥，我就要对小弟的请求进行&lt;strong&gt;指令回复&lt;/strong&gt;了，而且我得根据回复内容进行一下分类，要不然小弟该搞不清我的指示了。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;简单字符串&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单字符串回复只有一行回复，回复的内容以&lt;code&gt;+&lt;/code&gt;作为开头，不允许换行，并以&lt;code&gt;\r\n&lt;/code&gt;结束。有很多指令在执行成功后只会回复一个&lt;code&gt;OK&lt;/code&gt;，使用的就是这种格式，能够有效的将传输、解析的开销降到最低。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.084033613445378&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyfqlJaHViaKC8OqiaoUCnUSleGjticb8hukVjQAVyzfiboxYDvhdCjbBLkgA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;476&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;错误回复&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在RESP协议中，错误回复可以当做简单字符串回复的变种形式，它们之间的格式也非常类似，区别只有第一个字符是以&lt;code&gt;-&lt;/code&gt;作为开头，错误回复的内容通常是错误类型及对错误描述的字符串。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;错误回复出现在一些异常的场景，例如当发送了错误的指令、操作数的数量不对时，都会进行错误回复。在客户端收到错误回复后，会将它与简单字符串回复进行区分，视为异常。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.184873949579832&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyfg3vfSI3FdGySPRlPuGDajnFfmNmqoEyDfwzDzMo1u9fWKw01Qb8PgQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;476&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;整数回复&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整数回复的应用也非常广泛，它以&lt;code&gt;:&lt;/code&gt;作为开头，以&lt;code&gt;\r\n&lt;/code&gt;结束，用于返回一个整数。例如当执行&lt;code&gt;incr&lt;/code&gt;后返回自增后的值，执行&lt;code&gt;llen&lt;/code&gt;返回数组的长度，或者使用&lt;code&gt;exists&lt;/code&gt;命令返回的0或1作为判断一个&lt;code&gt;key&lt;/code&gt;是否存在的依据，这些都使用了整数回复。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.9537815126050421&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyfa4LiaqVYk1TOahicuRq4E2ib6nxDLEyzQsLiaRXzBtoiaKWeYzlETzhDia8Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;476&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;批量回复&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;批量回复，就是多行字符串的回复。它以&lt;code&gt;$&lt;/code&gt;作为开头，后面是发送的字节长度，然后是&lt;code&gt;\r\n&lt;/code&gt;，然后发送实际的数据，最终以&lt;code&gt;\r\n&lt;/code&gt;结束。如果要回复的数据不存在，那么回复长度为-1。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.5126050420168067&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyfBnACFwLBXNNhggIcPH9K5JXQjXeJna8zEqicQBA30rYW7ZnyzfDkic5Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;476&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;多条批量回复&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当服务端要返回多个值时，例如返回一些元素的集合时，就会使用多条批量回复。它以&lt;code&gt;*&lt;/code&gt;作为开头，后面是返回元素的个数，之后再跟随多个上面讲到过的批量回复。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.3907563025210083&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyfq3s6vL0Ud67Ivib4UE6BRUibInIkmiaOUf2OX8ibWpJ4ThDSwGQ4JJZwcw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;476&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到这里，基本上我和小弟之间的通讯协议就介绍完了。刚才你尝试了伪装成一个服务端，这会再来试一试直接写一个客户端来直接和我进行交互吧。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;client&lt;/span&gt;() &lt;span&gt;throws&lt;/span&gt; IOException &lt;/span&gt;{&lt;br/&gt;    String CRLF=&lt;span&gt;&quot;\r\n&quot;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;    Socket socket=&lt;span&gt;new&lt;/span&gt; Socket(&lt;span&gt;&quot;localhost&quot;&lt;/span&gt;, &lt;span&gt;6379&lt;/span&gt;);&lt;br/&gt;    &lt;span&gt;try&lt;/span&gt; (OutputStream out = socket.getOutputStream()) {&lt;br/&gt;        StringBuffer sb=&lt;span&gt;new&lt;/span&gt; StringBuffer();&lt;br/&gt;        sb.append(&lt;span&gt;&quot;*3&quot;&lt;/span&gt;).append(CRLF)&lt;br/&gt;                .append(&lt;span&gt;&quot;$3&quot;&lt;/span&gt;).append(CRLF).append(&lt;span&gt;&quot;set&quot;&lt;/span&gt;).append(CRLF)&lt;br/&gt;                .append(&lt;span&gt;&quot;$4&quot;&lt;/span&gt;).append(CRLF).append(&lt;span&gt;&quot;key1&quot;&lt;/span&gt;).append(CRLF)&lt;br/&gt;                .append(&lt;span&gt;&quot;$6&quot;&lt;/span&gt;).append(CRLF).append(&lt;span&gt;&quot;value1&quot;&lt;/span&gt;).append(CRLF);&lt;br/&gt;        out.write(sb.toString().getBytes());&lt;br/&gt;        out.flush();&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;try&lt;/span&gt; (InputStream inputStream = socket.getInputStream()) {&lt;br/&gt;            &lt;span&gt;byte&lt;/span&gt;[] buff = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;byte&lt;/span&gt;[&lt;span&gt;1024&lt;/span&gt;];&lt;br/&gt;            &lt;span&gt;int&lt;/span&gt; len = inputStream.read(buff);&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; (len &amp;gt; &lt;span&gt;0&lt;/span&gt;) {&lt;br/&gt;                String ret = &lt;span&gt;new&lt;/span&gt; String(buff, &lt;span&gt;0&lt;/span&gt;, len);&lt;br/&gt;                System.out.println(&lt;span&gt;&quot;Recv:&quot;&lt;/span&gt; + ret);&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行上面的代码，控制台输出：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;Recv:+OK&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面模仿了客户端发出&lt;code&gt;set&lt;/code&gt;命令的过程，并收到了回复。依此类推，你也可以自己封装其他的命令，来实现一个自己的Redis客户端，作为小弟，来和我进行通信。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不过记住，要叫我大哥。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4351cba9e1249ab71916435664803bdf</guid>
<title>[推荐] Nginx 最全操作总结</title>
<link>https://toutiao.io/k/0lvuhj9</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1575&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/j3gficicyOvasIjZpiaTNIPReJVWEJf7UGpmokI3LL4NbQDb8fO48fYROmYPXUhXFN8IdDqPcI1gA6OfSLsQHxB4w/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作者：chrootliu，腾讯 QQ 音乐前端开发工程师&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;本文将会从：安装 -&amp;gt; 全局配置 -&amp;gt; 常用的各种配置 来书写，其中常用配置写的炒鸡详细，需要的童鞋可以直接滑倒相应的位置查看。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;安装 nginx&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;下载 nginx 的压缩包文件到根目录，官网下载地址：nginx.org/download/nginx-x.xx.xx.tar.gz&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;yum update &lt;span&gt;#更新系统软件&lt;/span&gt;&lt;br/&gt;&lt;span&gt;cd&lt;/span&gt; /&lt;br/&gt;wget nginx.org/download/nginx-1.17.2.tar.gz&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;解压 tar.gz 压缩包文件，进去 nginx-1.17.2&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;tar -xzvf nginx-1.17.2.tar.gz&lt;br/&gt;&lt;span&gt;cd&lt;/span&gt; nginx-1.17.2&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;进入文件夹后进行配置检查&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;./configure&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;通过安装前的配置检查，发现有报错。检查中发现一些依赖库没有找到，这时候需要先安装 nginx 的一些依赖库&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;yum -y install pcre* &lt;span&gt;#安装使nginx支持rewrite&lt;/span&gt;&lt;br/&gt;yum -y install gcc-c++&lt;br/&gt;yum -y install zlib*&lt;br/&gt;yum -y install openssl openssl-devel&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;再次进行检查操作 ./configure 没发现报错显示，接下来进行编译并安装的操作&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt; // 检查模块支持&lt;br/&gt;  ./configure  --prefix=/usr/&lt;span&gt;local&lt;/span&gt;/nginx  --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_addition_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_auth_request_module --with-http_random_index_module --with-http_secure_link_module --with-http_degradation_module --with-http_slice_module --with-http_stub_status_module --with-mail --with-mail_ssl_module --with-stream --with-stream_ssl_module --with-stream_realip_module --with-stream_ssl_preread_module --with-threads --user=www --group=www&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里得特别注意下，你以后需要用到的功能模块是否存在，不然以后添加新的包会比较麻烦。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;查看默认安装的模块支持&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;命令 &lt;code&gt;ls nginx-1.17.2&lt;/code&gt; 查看 nginx 的文件列表，可以发现里面有一个 auto 的目录。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这个 auto 目录中有一个 options 文件，这个文件里面保存的就是 nginx 编译过程中的所有选项配置。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过命令：&lt;code&gt;cat nginx-1.17.2/auto/options | grep YES&lt;/code&gt;就可以查看&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://jingyan.baidu.com/article/454316ab354edcf7a7c03a81.html&quot; data-linktype=&quot;2&quot;&gt;nginx 编译安装时，怎么查看安装模块&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;编译并安装&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;make &amp;amp;&amp;amp; make install&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里需要注意，模块的支持跟后续的 nginx 配置有关，比如 SSL，gzip 压缩等等，编译安装前最好检查需要配置的模块存不存在。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;查看 nginx 安装后在的目录，可以看到已经安装到 /usr/local/nginx 目录了&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;whereis nginx&lt;br/&gt;&lt;span&gt;$nginx&lt;/span&gt;: /usr/&lt;span&gt;local&lt;/span&gt;/nginx&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;启动 nginx 服务&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;cd&lt;/span&gt; /usr/&lt;span&gt;local&lt;/span&gt;/nginx/sbin/&lt;br/&gt;./nginx&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;服务启动的时候报错了：&lt;code&gt;nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)&lt;/code&gt; ，通过命令查看本机网络地址和端口等一些信息，找到被占用的 80 端口 &lt;code&gt;netstat -ntpl&lt;/code&gt; 的 tcp 连接，并杀死进程(kill 进程 pid)&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;netstat -ntpl&lt;br/&gt;&lt;span&gt;kill&lt;/span&gt; 进程PID&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;继续启动 nginx 服务，启动成功&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;./nginx&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在浏览器直接访问 ip 地址，页面出现 Welcome to Nginx! 则安装成功。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;nginx 配置&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;基本结构&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;main        # 全局配置，对全局生效&lt;br/&gt;├── events  # 配置影响 nginx 服务器或与用户的网络连接&lt;br/&gt;├── http    # 配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置&lt;br/&gt;│   ├── upstream # 配置后端服务器具体地址，负载均衡配置不可或缺的部分&lt;br/&gt;│   ├── server   # 配置虚拟主机的相关参数，一个 http 块中可以有多个 server 块&lt;br/&gt;│   ├── server&lt;br/&gt;│   │   ├── location  # server 块可以包含多个 location 块，location 指令用于匹配 uri&lt;br/&gt;│   │   ├── location&lt;br/&gt;│   │   └── ...&lt;br/&gt;│   └── ...&lt;br/&gt;└── ...&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;主要配置含义&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;main:nginx 的全局配置，对全局生效。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;events:配置影响 nginx 服务器或与用户的网络连接。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;http：可以嵌套多个 server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;server：配置虚拟主机的相关参数，一个 http 中可以有多个 server。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;location：配置请求的路由，以及各种页面的处理情况。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;upstream：配置后端服务器具体地址，负载均衡配置不可或缺的部分。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;nginx.conf 配置文件的语法规则&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;配置文件由指令与指令块构成&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;每条指令以 “;” 分号结尾，指令与参数间以空格符号分隔&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;指令块以 {} 大括号将多条指令组织在一起&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;include 语句允许组合多个配置文件以提升可维护性&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;通过 # 符号添加注释，提高可读性&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;通过 $ 符号使用变量&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;部分指令的参数支持正则表达式，例如常用的 location 指令&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;内置变量&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;nginx 常用的内置全局变量，你可以在配置中随意使用：&lt;img data-ratio=&quot;0.6285362853628537&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvauLdHRFreUAZ7U9Bz4XsHwXCXwgNAhHxPKRibPGxTxtaMqNjeOaot8jEqwDYjyGD5VojZLYIApEMEw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1626&quot;/&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;常用命令&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里列举几个常用的命令：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;nginx -s reload  # 向主进程发送信号，重新加载配置文件，热重启&lt;br/&gt;nginx -s reopen  # 重启 Nginx&lt;br/&gt;nginx -s stop    # 快速关闭&lt;br/&gt;nginx -s quit    # 等待工作进程处理完成后关闭&lt;br/&gt;nginx -T         # 查看当前 Nginx 最终的配置&lt;br/&gt;nginx -t -c &amp;lt;配置路径&amp;gt;  # 检查配置是否有问题，如果已经在配置目录，则不需要 -c&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上命令通过 &lt;code&gt;nginx -h&lt;/code&gt; 就可以查看到，还有其它不常用这里未列出。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Linux 系统应用管理工具 systemd 关于 nginx 的常用命令：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;systemctl start nginx    # 启动 Nginx&lt;br/&gt;systemctl stop nginx     # 停止 Nginx&lt;br/&gt;systemctl restart nginx  # 重启 Nginx&lt;br/&gt;systemctl reload nginx   # 重新加载 Nginx，用于修改配置后&lt;br/&gt;systemctl enable nginx   # 设置开机启动 Nginx&lt;br/&gt;systemctl disable nginx  # 关闭开机启动 Nginx&lt;br/&gt;systemctl status nginx   # 查看 Nginx 运行状态&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;配置 nginx 开机自启&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;利用 systemctl 命令&lt;/strong&gt;：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果用 yum install 命令安装的 nginx，yum 命令会自动创建 nginx.service 文件，直接用命令:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;systemctl &lt;span&gt;enable&lt;/span&gt; nginx   &lt;span&gt;# 设置开机启动 Nginx&lt;/span&gt;&lt;br/&gt;systemctl &lt;span&gt;disable&lt;/span&gt; nginx  &lt;span&gt;# 关闭开机启动 Nginx&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就可以设置开机自启，否则需要在系统服务目录里创建 nginx.service 文件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;创建并打开 nginx.service 文件：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;vi /lib/systemd/system/nginx.service&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内容如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[Unit]&lt;br/&gt;Description=nginx&lt;br/&gt;After=network.target&lt;br/&gt;&lt;br/&gt;[Service]&lt;br/&gt;Type=forking&lt;br/&gt;ExecStart=/usr/local/nginx/sbin/nginx&lt;br/&gt;ExecReload=/usr/local/nginx/sbin/nginx -s reload&lt;br/&gt;ExecStop=/usr/local/nginx/sbin/nginx -s quit&lt;br/&gt;PrivateTmp=true&lt;br/&gt;&lt;br/&gt;[Install]&lt;br/&gt;WantedBy=multi-user.target&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;:wq&lt;/code&gt; 保存退出，运行 &lt;code&gt;systemctl daemon-reload&lt;/code&gt; 使文件生效。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样便可以通过以下命令操作 nginx 了：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;systemctl start nginx.service # 启动nginx服务&lt;br/&gt;systemctl enable nginx.service # 设置开机启动&lt;br/&gt;systemctl disable nginx.service # 停止开机自启动&lt;br/&gt;systemctl status nginx.service # 查看服务当前状态&lt;br/&gt;systemctl restart nginx.service # 重新启动服务&lt;br/&gt;systemctl is-enabled nginx.service #查询服务是否开机启动&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;通过开机启动命令脚本实现开机自启&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;创建开机启动命令脚本文件：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;vi /etc/init.d/nginx&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这个 nginx 文件中插入一下启动脚本代码，启动脚本代码来源网络复制，实测有效：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#! /bin/bash&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# chkconfig: - 85 15&lt;/span&gt;&lt;br/&gt;PATH=/usr/&lt;span&gt;local&lt;/span&gt;/nginx&lt;br/&gt;DESC=&lt;span&gt;&quot;nginx daemon&quot;&lt;/span&gt;&lt;br/&gt;NAME=nginx&lt;br/&gt;DAEMON=&lt;span&gt;$PATH&lt;/span&gt;/sbin/&lt;span&gt;$NAME&lt;/span&gt;&lt;br/&gt;CONFIGFILE=&lt;span&gt;$PATH&lt;/span&gt;/conf/&lt;span&gt;$NAME&lt;/span&gt;.conf&lt;br/&gt;PIDFILE=&lt;span&gt;$PATH&lt;/span&gt;/logs/&lt;span&gt;$NAME&lt;/span&gt;.pid&lt;br/&gt;scriptNAME=/etc/init.d/&lt;span&gt;$NAME&lt;/span&gt;&lt;br/&gt;&lt;span&gt;set&lt;/span&gt; -e&lt;br/&gt;[ -x &lt;span&gt;&quot;&lt;span&gt;$DAEMON&lt;/span&gt;&quot;&lt;/span&gt; ] || &lt;span&gt;exit&lt;/span&gt; 0&lt;br/&gt;&lt;span&gt;&lt;span&gt;do_start&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;&lt;span&gt;$DAEMON&lt;/span&gt; -c &lt;span&gt;$CONFIGFILE&lt;/span&gt; || &lt;span&gt;echo&lt;/span&gt; -n &lt;span&gt;&quot;nginx already running&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;span&gt;&lt;span&gt;do_stop&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;&lt;span&gt;$DAEMON&lt;/span&gt; -s stop || &lt;span&gt;echo&lt;/span&gt; -n &lt;span&gt;&quot;nginx not running&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;span&gt;&lt;span&gt;do_reload&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;&lt;span&gt;$DAEMON&lt;/span&gt; -s reload || &lt;span&gt;echo&lt;/span&gt; -n &lt;span&gt;&quot;nginx can&#x27;t reload&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;&quot;&lt;span&gt;$1&lt;/span&gt;&quot;&lt;/span&gt; &lt;span&gt;in&lt;/span&gt;&lt;br/&gt;start)&lt;br/&gt;&lt;span&gt;echo&lt;/span&gt; -n &lt;span&gt;&quot;Starting &lt;span&gt;$DESC&lt;/span&gt;: &lt;span&gt;$NAME&lt;/span&gt;&quot;&lt;/span&gt;&lt;br/&gt;do_start&lt;br/&gt;&lt;span&gt;echo&lt;/span&gt; &lt;span&gt;&quot;.&quot;&lt;/span&gt;&lt;br/&gt;;;&lt;br/&gt;stop)&lt;br/&gt;&lt;span&gt;echo&lt;/span&gt; -n &lt;span&gt;&quot;Stopping &lt;span&gt;$DESC&lt;/span&gt;: &lt;span&gt;$NAME&lt;/span&gt;&quot;&lt;/span&gt;&lt;br/&gt;do_stop&lt;br/&gt;&lt;span&gt;echo&lt;/span&gt; &lt;span&gt;&quot;.&quot;&lt;/span&gt;&lt;br/&gt;;;&lt;br/&gt;reload|graceful)&lt;br/&gt;&lt;span&gt;echo&lt;/span&gt; -n &lt;span&gt;&quot;Reloading &lt;span&gt;$DESC&lt;/span&gt; configuration...&quot;&lt;/span&gt;&lt;br/&gt;do_reload&lt;br/&gt;&lt;span&gt;echo&lt;/span&gt; &lt;span&gt;&quot;.&quot;&lt;/span&gt;&lt;br/&gt;;;&lt;br/&gt;restart)&lt;br/&gt;&lt;span&gt;echo&lt;/span&gt; -n &lt;span&gt;&quot;Restarting &lt;span&gt;$DESC&lt;/span&gt;: &lt;span&gt;$NAME&lt;/span&gt;&quot;&lt;/span&gt;&lt;br/&gt;do_stop&lt;br/&gt;do_start&lt;br/&gt;&lt;span&gt;echo&lt;/span&gt; &lt;span&gt;&quot;.&quot;&lt;/span&gt;&lt;br/&gt;;;&lt;br/&gt;*)&lt;br/&gt;&lt;span&gt;echo&lt;/span&gt; &lt;span&gt;&quot;Usage: &lt;span&gt;$scriptNAME&lt;/span&gt; {start|stop|reload|restart}&quot;&lt;/span&gt; &amp;gt;&amp;amp;2&lt;br/&gt;&lt;span&gt;exit&lt;/span&gt; 3&lt;br/&gt;;;&lt;br/&gt;&lt;span&gt;esac&lt;/span&gt;&lt;br/&gt;&lt;span&gt;exit&lt;/span&gt; 0&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;设置所有人都有对这个启动脚本 nginx 文件的执行权限：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;chmod a+x /etc/init.d/nginx&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;把 nginx 加入系统服务中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;chkconfig --add nginx&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;把服务设置为开机启动：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;chkconfig nginx on&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;reboot 重启系统生效，可以使用上面 systemctl 方法相同的命令：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;systemctl start nginx.service &lt;span&gt;# 启动nginx服务&lt;/span&gt;&lt;br/&gt;systemctl &lt;span&gt;enable&lt;/span&gt; nginx.service &lt;span&gt;# 设置开机启动&lt;/span&gt;&lt;br/&gt;systemctl &lt;span&gt;disable&lt;/span&gt; nginx.service &lt;span&gt;# 停止开机自启动&lt;/span&gt;&lt;br/&gt;systemctl status nginx.service &lt;span&gt;# 查看服务当前状态&lt;/span&gt;&lt;br/&gt;systemctl restart nginx.service &lt;span&gt;# 重新启动服务&lt;/span&gt;&lt;br/&gt;systemctl is-enabled nginx.service &lt;span&gt;#查询服务是否开机启动&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果服务启动的时候出现 &lt;code&gt;Restarting nginx daemon: nginxnginx: [error] open() &quot;/usr/local/nginx/logs/nginx.pid&quot; failed (2: No such file or directory) nginx not running&lt;/code&gt; 的错误，通过 nginx -c 参数指定配置文件即可解决&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;/usr/&lt;span&gt;local&lt;/span&gt;/nginx/sbin/nginx -c /usr/&lt;span&gt;local&lt;/span&gt;/nginx/conf/nginx.conf&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果服务启动中出现 &lt;code&gt;nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)&lt;/code&gt; 的错误，可以先通过 &lt;code&gt;service nginx stop&lt;/code&gt; 停止服务，再启动就好。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;配置 nginx 全局可用&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当你每次改了 &lt;code&gt;nginx.conf&lt;/code&gt; 配置文件的内容都需要重新到 nginx 启动目录去执行命令，或者通过 -p 参数指向特定目录，会不会感觉很麻烦？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如：直接执行 &lt;code&gt;nginx -s reload&lt;/code&gt; 会报错 &lt;code&gt;-bash: nginx: command not found&lt;/code&gt;，需要到 &lt;code&gt;/usr/local/nginx/sbin&lt;/code&gt; 目录下面去执行，并且是执行 &lt;code&gt;./nginx -s reload&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里有两种方式可以解决，一种是通过脚本对 nginx 命令包装，这里介绍另外一种比较简单：通过把 nginx 配置到环境变量里，用 nginx 执行指令即可。步骤如下：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、编辑 /etc/profile&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;vi /etc/profile&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、在最后一行添加配置，:wq 保存&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;export PATH=$PATH:/usr/local/nginx/sbin&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、使配置立即生效&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;source /etc/profile&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样就可以愉快的直接在全局使用 nginx 命令了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;nginx 常用功能&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;反向代理&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们最常说的反向代理的是通过反向代理解决跨域问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实反向代理还可以用来控制缓存（代理缓存 proxy cache），进行访问控制等等，以及后面说的负载均衡其实都是通过反向代理来实现的。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;    listen    8080;&lt;br/&gt;        # 用户访问 ip:8080/test 下的所有路径代理到 github&lt;br/&gt;        location /test {&lt;br/&gt;         proxy_pass   https://github.com;&lt;br/&gt;        }&lt;br/&gt;&lt;br/&gt;        # 所有 /api 下的接口访问都代理到本地的 8888 端口&lt;br/&gt;        # 例如你本地运行的 java 服务的端口是 8888，接口都是以 /api 开头&lt;br/&gt;        location /api {&lt;br/&gt;            proxy_pass   http://127.0.0.1:8888;&lt;br/&gt;        }&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;访问控制&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;   location ~ ^/index.html {&lt;br/&gt;       # 匹配 index.html 页面 除了 127.0.0.1 以外都可以访问&lt;br/&gt;       deny 192.168.1.1;&lt;br/&gt;       deny 192.168.1.2;&lt;br/&gt;       allow all;&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的命令表示禁止 192.168.1.1 和 192.168.1.2 两个 ip 访问，其它全部允许。从上到下的顺序，匹配到了便跳出，可以按你的需求设置。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;负载均衡&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过负载均衡充利用服务器资源，nginx 目前支持自带 4 种负载均衡策略，还有 2 种常用的第三方策略。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;轮询策略（默认）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个请求按时间顺序逐一分配到不同的后端服务器，如果有后端服务器挂掉，能自动剔除。但是如果其中某一台服务器压力太大，出现延迟，会影响所有分配在这台服务器下的用户。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;http {&lt;br/&gt;    upstream test.com {&lt;br/&gt;        server 192.168.1.12:8887;&lt;br/&gt;        server 192.168.1.13:8888;&lt;br/&gt;    }&lt;br/&gt;    server {&lt;br/&gt;        location /api {&lt;br/&gt;            proxy_pass  http://test.com;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;根据服务器权重&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如要配置：10 次请求中大概 1 次访问到 8888 端口，9 次访问到 8887 端口：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;http {&lt;br/&gt;    upstream test.com {&lt;br/&gt;        server 192.168.1.12:8887 weight=9;&lt;br/&gt;        server 192.168.1.13:8888 weight=1;&lt;br/&gt;    }&lt;br/&gt;    server {&lt;br/&gt;        location /api {&lt;br/&gt;            proxy_pass  http://test.com;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;客户端 ip 绑定（ip_hash）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;来自同一个 ip 的请求永远只分配一台服务器，有效解决了动态网页存在的 session 共享问题。例如：比如把登录信息保存到了 session 中，那么跳转到另外一台服务器的时候就需要重新登录了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以很多时候我们需要一个客户只访问一个服务器，那么就需要用 ip_hash 了。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;http {&lt;br/&gt;    upstream test.com {&lt;br/&gt;     ip_hash;&lt;br/&gt;        server 192.168.1.12:8887;&lt;br/&gt;        server 192.168.1.13:8888;&lt;br/&gt;    }&lt;br/&gt;    server {&lt;br/&gt;        location /api {&lt;br/&gt;            proxy_pass  http://test.com;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;最小连接数策略&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;将请求优先分配给压力较小的服务器，它可以平衡每个队列的长度，并避免向压力大的服务器添加更多的请求。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;http {&lt;br/&gt;    upstream test.com {&lt;br/&gt;     least_conn;&lt;br/&gt;        server 192.168.1.12:8887;&lt;br/&gt;        server 192.168.1.13:8888;&lt;br/&gt;    }&lt;br/&gt;    server {&lt;br/&gt;        location /api {&lt;br/&gt;            proxy_pass  http://test.com;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;最快响应时间策略（依赖于第三方 NGINX Plus）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;依赖于 NGINX Plus，优先分配给响应时间最短的服务器。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;http {&lt;br/&gt;    upstream test.com {&lt;br/&gt;     fair;&lt;br/&gt;        server 192.168.1.12:8887;&lt;br/&gt;        server 192.168.1.13:8888;&lt;br/&gt;    }&lt;br/&gt;    server {&lt;br/&gt;        location /api {&lt;br/&gt;            proxy_pass  http://test.com;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;按访问 url 的 hash 结果（第三方）&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;按访问 url 的 hash 结果来分配请求，使每个 url 定向到同一个后端服务器，后端服务器为缓存时比较有效。在 upstream 中加入 hash 语句，server 语句中不能写入 weight 等其他的参数，hash_method 是使用的 hash 算法&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;br/&gt;http {&lt;br/&gt;    upstream test.com {&lt;br/&gt;     hash $request_uri;&lt;br/&gt;     hash_method crc32;&lt;br/&gt;     server 192.168.1.12:8887;&lt;br/&gt;     server 192.168.1.13:8888;&lt;br/&gt;    }&lt;br/&gt;    server {&lt;br/&gt;        location /api {&lt;br/&gt;            proxy_pass  http://test.com;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;采用 HAproxy 的 loadbalance uri 或者 nginx 的 upstream_hash 模块，都可以做到针对 url 进行哈希算法式的负载均衡转发。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;gzip 压缩&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;开启 gzip 压缩可以大幅减少 http 传输过程中文件的大小，可以极大的提高网站的访问速度，基本是必不可少的优化操作：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;gzip  on; # 开启gzip 压缩&lt;br/&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; gzip_types&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; gzip_static on;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; gzip_proxied expired no-cache no-store private auth;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; gzip_buffers 16 8k;&lt;/span&gt;&lt;br/&gt;gzip_min_length 1k;&lt;br/&gt;gzip_comp_level 4;&lt;br/&gt;gzip_http_version 1.0;&lt;br/&gt;gzip_vary off;&lt;br/&gt;gzip_disable &quot;MSIE [1-6]\.&quot;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;解释一下：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;gzip_types：要采用 gzip 压缩的 MIME 文件类型，其中 text/html 被系统强制启用；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;gzip_static：默认 off，该模块启用后，Nginx 首先检查是否存在请求静态文件的 gz 结尾的文件，如果有则直接返回该 .gz 文件内容；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;gzip_proxied：默认 off，nginx 做为反向代理时启用，用于设置启用或禁用从代理服务器上收到相应内容 gzip 压缩；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;gzip_buffers：获取多少内存用于缓存压缩结果，16 8k 表示以 8k*16 为单位获得；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;gzip_min_length：允许压缩的页面最小字节数，页面字节数从 header 头中的 Content-Length 中进行获取。默认值是 0，不管页面多大都压缩。建议设置成大于 1k 的字节数，小于 1k 可能会越压越大；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;gzip_comp_level：gzip 压缩比，压缩级别是 1-9，1 压缩级别最低，9 最高，级别越高压缩率越大，压缩时间越长，建议 4-6；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;gzip_http_version：默认 1.1，启用 gzip 所需的 HTTP 最低版本；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;gzip_vary：用于在响应消息头中添加 Vary：Accept-Encoding，使代理服务器根据请求头中的 Accept-Encoding 识别是否启用 gzip 压缩；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;gzip_disable 指定哪些不需要 gzip 压缩的浏览器&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中第 2 点，普遍是结合前端打包的时候打包成 gzip 文件后部署到服务器上，这样服务器就可以直接使用 gzip 的文件了，并且可以把压缩比例提高，这样 nginx 就不用压缩，也就不会影响速度。一般不追求极致的情况下，前端不用做任何配置就可以使用啦~&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;附前端 webpack 开启 gzip 压缩配置，在 vue-cli3 的 vue.config.js 配置文件中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;const&lt;/span&gt; CompressionWebpackPlugin = &lt;span&gt;require&lt;/span&gt;(&lt;span&gt;&#x27;compression-webpack-plugin&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;module&lt;/span&gt;.exports = {&lt;br/&gt;  &lt;span&gt;// gzip 配置&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;configureWebpack&lt;/span&gt;: &lt;span&gt;&lt;span&gt;config&lt;/span&gt; =&amp;gt;&lt;/span&gt; {&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (process.env.NODE_ENV === &lt;span&gt;&#x27;production&#x27;&lt;/span&gt;) {&lt;br/&gt;      &lt;span&gt;// 生产环境&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;plugins&lt;/span&gt;: [&lt;span&gt;new&lt;/span&gt; CompressionWebpackPlugin({&lt;br/&gt;          &lt;span&gt;test&lt;/span&gt;: &lt;span&gt;/\.js$|\.html$|\.css/&lt;/span&gt;,    &lt;span&gt;// 匹配文件名&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;threshold&lt;/span&gt;: &lt;span&gt;1024&lt;/span&gt;,               &lt;span&gt;// 文件压缩阈值，对超过 1k 的进行压缩&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;deleteOriginalAssets&lt;/span&gt;: &lt;span&gt;false&lt;/span&gt;     &lt;span&gt;// 是否删除源文件&lt;/span&gt;&lt;br/&gt;        })]&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;  },&lt;br/&gt;  ...&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;HTTP 服务器&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;nginx 本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用 nginx 来做服务器：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;  listen       80;&lt;br/&gt;  server_name  localhost;&lt;br/&gt;&lt;br/&gt;  location / {&lt;br/&gt;      root   /usr/local/app;&lt;br/&gt;      index  index.html;&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样如果访问 http://ip 就会默认访问到 /usr/local/app 目录下面的 index.html，如果一个网站只是静态页面的话，那么就可以通过这种方式来实现部署，比如一个静态官网。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;动静分离&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就是把动态和静态的请求分开。方式主要有两种：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;一种是纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一种方法就是动态跟静态文件混合在一起发布， 通过 nginx 配置来分开&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;# 所有静态请求都由nginx处理，存放目录为 html&lt;/span&gt;&lt;br/&gt;location ~ \.(gif|jpg|jpeg|png|bmp|swf|css|js)$ {&lt;br/&gt;    root    /usr/&lt;span&gt;local&lt;/span&gt;/resource;&lt;br/&gt;    expires     10h; &lt;span&gt;# 设置过期时间为10小时&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# 所有动态请求都转发给 tomcat 处理&lt;/span&gt;&lt;br/&gt;location ~ \.(jsp|&lt;span&gt;do&lt;/span&gt;)$ {&lt;br/&gt;    proxy_pass  127.0.0.1:8888;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;注意上面设置了 expires，当 nginx 设置了 expires 后，例如设置为：expires 10d; 那么，所在的 location 或 if 的内容，用户在 10 天内请求的时候，都只会访问浏览器中的缓存，而不会去请求 nginx 。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;请求限制&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于大流量恶意的访问，会造成带宽的浪费，给服务器增加压力。可以通过 nginx 对于同一 IP 的连接数以及并发数进行限制。合理的控制还可以用来防止 DDos 和 CC 攻击。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于请求限制主要使用 nginx 默认集成的 2 个模块：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;limit_conn_module 连接频率限制模块&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;limit_req_module 请求频率限制模块&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;涉及到的配置主要是：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;limit_req_zone 限制请求数&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;limit_conn_zone 限制并发连接数&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;通过 limit_req_zone 限制请求数&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;http{&lt;br/&gt;    limit_conn_zone $binary_remote_addrzone=limit:10m; // 设置共享内存空间大&lt;br/&gt;    server{&lt;br/&gt;     location /{&lt;br/&gt;            limit_conn addr 5; # 同一用户地址同一时间只允许有5个连接。&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果共享内存空间被耗尽，服务器将会对后续所有的请求返回 503 (Service Temporarily Unavailable) 错误。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当多个 limit_conn_zone 指令被配置时，所有的连接数限制都会生效。比如，下面配置不仅会限制单一 IP 来源的连接数，同时也会限制单一虚拟服务器的总连接数：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;limit_conn_zone $binary_remote_addr zone=perip:10m;&lt;br/&gt;limit_conn_zone $server_name zone=perserver:10m;&lt;br/&gt;server {&lt;br/&gt;    limit_conn perip 10; # 限制每个 ip 连接到服务器的数量&lt;br/&gt;    limit_conn perserver 2000; # 限制连接到服务器的总数&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;通过 limit_conn_zone 限制并发连接数&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;limit_req_zone $binary_remote_addr zone=creq:10 mrate=10r/s;&lt;br/&gt;server{&lt;br/&gt;    location /{&lt;br/&gt;        limit_req zone=creq burst=5;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;限制平均每秒不超过一个请求，同时允许超过频率限制的请求数不多于 5 个。如果不希望超过的请求被延迟，可以用 nodelay 参数,如：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;limit_req zone=creq burst=5 nodelay;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里只是简单讲讲，让大家有这个概念，配置的时候可以深入去找找资料。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;正向代理&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理，比如我们使用的 VPN 服务就是正向代理，直观区别：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.0109409190371992&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvauLdHRFreUAZ7U9Bz4XsHwXNDBe3m58FdgMKvWrqiaribzgPicia1GfpaB7q8D8p5jU7yOjT5t5Fx3Edw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;914&quot;/&gt;&lt;figcaption/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;配置正向代理：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;resolver 8.8.8.8 # 谷歌的域名解析地址&lt;br/&gt;server {&lt;br/&gt;    resolver_timeout 5s; // 设超时时间&lt;br/&gt;    location / {&lt;br/&gt;        # 当客户端请求我的时候，我会把请求转发给它&lt;br/&gt;        # $host 要访问的主机名 $request_uri 请求路径&lt;br/&gt;        proxy_pass http://$host$request_uri;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;正向代理的对象是客户端，服务器端看不到真正的客户端。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;图片防盗链&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;    listen       80;&lt;br/&gt;    server_name  *.test;&lt;br/&gt;&lt;br/&gt;    # 图片防盗链&lt;br/&gt;    location ~* \.(gif|jpg|jpeg|png|bmp|swf)$ {&lt;br/&gt;        valid_referers none blocked server_names ~\.google\. ~\.baidu\. *.qq.com;  # 只允许本机 IP 外链引用，将百度和谷歌也加入白名单有利于 SEO&lt;br/&gt;        if ($invalid_referer){&lt;br/&gt;            return 403;&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上设置就能防止其它网站利用外链访问我们的图片，有利于节省流量&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;适配 PC 或移动设备&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据用户设备不同返回不同样式的站点，以前经常使用的是纯前端的自适应布局，但是复杂的网站并不适合响应式，无论是复杂性和易用性上面还是不如分开编写的好，比如我们常见的淘宝、京东。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据用户请求的 user-agent 来判断是返回 PC 还是 H5 站点：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;    listen 80;&lt;br/&gt;    server_name test.com;&lt;br/&gt;&lt;br/&gt;    location / {&lt;br/&gt;     root  /usr/local/app/pc; # pc 的 html 路径&lt;br/&gt;        if ($http_user_agent ~* &#x27;(Android|webOS|iPhone|iPod|BlackBerry)&#x27;) {&lt;br/&gt;            root /usr/local/app/mobile; # mobile 的 html 路径&lt;br/&gt;        }&lt;br/&gt;        index index.html;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;设置二级域名&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;新建一个 server 即可：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;    listen 80;&lt;br/&gt;    server_name admin.test.com; // 二级域名&lt;br/&gt;&lt;br/&gt;    location / {&lt;br/&gt;        root  /usr/local/app/admin; # 二级域名的 html 路径&lt;br/&gt;        index index.html;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;配置 HTTPS&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里我使用的是 certbot 免费证书，但申请一次有效期只有 3 个月（好像可以用 crontab 尝试配置自动续期，我暂时没试过）：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先安装 certbot&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;wget https://dl.eff.org/certbot-auto&lt;br/&gt;chmod a+x certbot-auto&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;申请证书（注意：需要把要申请证书的域名先解析到这台服务器上，才能申请）:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;sudo ./certbot-auto certonly --standalone --email admin@abc.com -d test.com -d www.test.com&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;执行上面指令，按提示操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Certbot 会启动一个临时服务器来完成验证（会占用 80 端口或 443 端口，因此需要暂时关闭 Web 服务器），然后 Certbot 会把证书以文件的形式保存，包括完整的证书链文件和私钥文件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;文件保存在 /etc/letsencrypt/live/ 下面的域名目录下。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;修改 nginx 配置：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server{&lt;br/&gt;    listen 443 ssl http2; // 这里还启用了 http/2.0&lt;br/&gt;&lt;br/&gt;    ssl_certificate /etc/letsencrypt/live/test.com/fullchain.pem; # 证书文件地址&lt;br/&gt;    ssl_certificate_key /etc/letsencrypt/live/test.com/privkey.pem; # 私钥文件地址&lt;br/&gt;&lt;br/&gt;    server_name test.com www.test.com; // 证书绑定的域名&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;配置 HTTP 转 HTTPS&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;    listen      80;&lt;br/&gt;    server_name test.com www.test.com;&lt;br/&gt;&lt;br/&gt;    # 单域名重定向&lt;br/&gt;    if ($host = &#x27;www.sherlocked93.club&#x27;){&lt;br/&gt;        return 301 https://www.sherlocked93.club$request_uri;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    # 全局非 https 协议时重定向&lt;br/&gt;    if ($scheme != &#x27;https&#x27;) {&lt;br/&gt;        return 301 https://$server_name$request_uri;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    # 或者全部重定向&lt;br/&gt;    return 301 https://$server_name$request_uri;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上配置选择自己需要的一条即可，不用全部加。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;单页面项目 history 路由配置&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;    listen       80;&lt;br/&gt;    server_name  fe.sherlocked93.club;&lt;br/&gt;&lt;br/&gt;    location / {&lt;br/&gt;        root       /usr/local/app/dist;  # vue 打包后的文件夹&lt;br/&gt;        index      index.html index.htm;&lt;br/&gt;        try_files  $uri $uri/ /index.html @rewrites; # 默认目录下的 index.html，如果都不存在则重定向&lt;br/&gt;&lt;br/&gt;        expires -1;                          # 首页一般没有强制缓存&lt;br/&gt;        add_header Cache-Control no-cache;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    location @rewrites { // 重定向设置&lt;br/&gt;        rewrite ^(.+)$ /index.html break;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://router.vuejs.org/zh/guide/essentials/history-mode.html#%E5%90%8E%E7%AB%AF%E9%85%8D%E7%BD%AE%E4%BE%8B%E5%AD%90&quot; data-linktype=&quot;2&quot;&gt;vue-router&lt;/a&gt; 官网只有一句话 &lt;code&gt;try_files $uri $uri/ /index.html;&lt;/code&gt;，而上面做了一些重定向处理。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;配置高可用集群（双机热备）&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当主 nginx 服务器宕机之后，切换到备份的 nginx 服务器&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先安装 keepalived:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;yum install keepalived -y&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后编辑 &lt;code&gt;/etc/keepalived/keepalived.conf&lt;/code&gt; 配置文件，并在配置文件中增加 &lt;code&gt;vrrp_script&lt;/code&gt; 定义一个外围检测机制，并在 &lt;code&gt;vrrp_instance&lt;/code&gt; 中通过定义 &lt;code&gt;track_script&lt;/code&gt; 来追踪脚本执行过程，实现节点转移：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;global_defs{&lt;br/&gt;   notification_email {&lt;br/&gt;        cchroot@gmail.com&lt;br/&gt;   }&lt;br/&gt;   notification_email_from test@firewall.loc&lt;br/&gt;   smtp_server 127.0.0.1&lt;br/&gt;   smtp_connect_timeout 30 // 上面都是邮件配置&lt;br/&gt;   router_id LVS_DEVEL     // 当前服务器名字，用 hostname 命令来查看&lt;br/&gt;}&lt;br/&gt;vrrp_script chk_maintainace { // 检测机制的脚本名称为chk_maintainace&lt;br/&gt;    script &quot;[[ -e/etc/keepalived/down ]] &amp;amp;&amp;amp; exit 1 || exit 0&quot; // 可以是脚本路径或脚本命令&lt;br/&gt;    // script &quot;/etc/keepalived/nginx_check.sh&quot;    // 比如这样的脚本路径&lt;br/&gt;    interval 2  // 每隔2秒检测一次&lt;br/&gt;    weight -20  // 当脚本执行成立，那么把当前服务器优先级改为-20&lt;br/&gt;}&lt;br/&gt;vrrp_instanceVI_1 {   // 每一个vrrp_instance就是定义一个虚拟路由器&lt;br/&gt;    state MASTER      // 主机为MASTER，备用机为BACKUP&lt;br/&gt;    interface eth0    // 网卡名字，可以从ifconfig中查找&lt;br/&gt;    virtual_router_id 51 // 虚拟路由的id号，一般小于255，主备机id需要一样&lt;br/&gt;    priority 100      // 优先级，master的优先级比backup的大&lt;br/&gt;    advert_int 1      // 默认心跳间隔&lt;br/&gt;    authentication {  // 认证机制&lt;br/&gt;        auth_type PASS&lt;br/&gt;        auth_pass 1111   // 密码&lt;br/&gt;    }&lt;br/&gt;    virtual_ipaddress {  // 虚拟地址vip&lt;br/&gt;       172.16.2.8&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中检测脚本 &lt;code&gt;nginx_check.sh&lt;/code&gt;，这里提供一个：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;!/bin/bash&lt;/span&gt;&lt;br/&gt;A=`ps -C nginx --no-header | wc -l`&lt;br/&gt;if [ $A -eq 0 ];then&lt;br/&gt;    /usr/sbin/nginx # 尝试重新启动nginx&lt;br/&gt;    sleep 2         # 睡眠2秒&lt;br/&gt;    if [ `ps -C nginx --no-header | wc -l` -eq 0 ];then&lt;br/&gt;        killall keepalived # 启动失败，将keepalived服务杀死。将vip漂移到其它备份节点&lt;br/&gt;    fi&lt;br/&gt;fi&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;复制一份到备份服务器，备份 nginx 的配置要将 &lt;code&gt;state&lt;/code&gt; 后改为 &lt;code&gt;BACKUP&lt;/code&gt;，&lt;code&gt;priority&lt;/code&gt; 改为比主机小。设置完毕后各自 &lt;code&gt;service keepalived start&lt;/code&gt; 启动，经过访问成功之后，可以把 Master 机的 keepalived 停掉，此时 Master 机就不再是主机了 &lt;code&gt;service keepalived stop&lt;/code&gt;，看访问虚拟 IP 时是否能够自动切换到备机 ip addr。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再次启动 Master 的 keepalived，此时 vip 又变到了主机上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;配置高可用集群的内容来源于：&lt;a href=&quot;https://juejin.im/post/6844904144235413512#heading-11&quot; data-linktype=&quot;2&quot;&gt;Nginx 从入门到实践，万字详解！&lt;/a&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;其它功能和技巧&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;代理缓存&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;nginx 的 http_proxy 模块，提供类似于 Squid 的缓存功能，使用 proxy_cache_path 来配置。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;nginx 可以对访问过的内容在 nginx 服务器本地建立副本，这样在一段时间内再次访问该数据，就不需要通过 nginx 服务器再次向后端服务器发出请求，减小数据传输延迟，提高访问速度：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;proxy_cache_path usr/&lt;span&gt;local&lt;/span&gt;/cache levels=1:2 keys_zone=my_cache:10m;&lt;br/&gt;&lt;br/&gt;server {&lt;br/&gt;  listen       80;&lt;br/&gt;  server_name  test.com;&lt;br/&gt;&lt;br/&gt;  location / {&lt;br/&gt;      proxy_cache my_cache;&lt;br/&gt;      proxy_pass http://127.0.0.1:8888;&lt;br/&gt;      proxy_set_header Host &lt;span&gt;$host&lt;/span&gt;;&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的配置表示：nginx 提供一块 10 M 的内存用于缓存，名字为 my_cache, levels 等级为 1:2，缓存存放的路径为 &lt;code&gt;usr/local/cache&lt;/code&gt;。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;访问日志&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;访问日志默认是注释的状态，需要可以打开和进行更详细的配置，一下是 nginx 的默认配置：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;http {&lt;br/&gt;    log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;&lt;br/&gt;                      &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;&lt;br/&gt;                      &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;&lt;br/&gt;&lt;br/&gt;    access_log  logs/access.log  main;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;错误日志&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;错误日志放在 main 全局区块中，童鞋们打开 nginx.conf 就可以看见在配置文件中和下面一样的代码了：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;error_log  logs/error.log;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;error_log  logs/error.log  notice;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;error_log  logs/error.log  info;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;nginx 错误日志默认配置为：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;error_log logs/error.log error;&lt;/code&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;静态资源服务器&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;    listen       80;&lt;br/&gt;    server_name  static.bin;&lt;br/&gt;    charset utf-8;    &lt;span&gt;# 防止中文文件名乱码&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;    location /download {&lt;br/&gt;        &lt;span&gt;alias&lt;/span&gt;           /usr/share/nginx/static;  &lt;span&gt;# 静态资源目录&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        autoindex               on;    &lt;span&gt;# 开启静态资源列目录，浏览目录权限&lt;/span&gt;&lt;br/&gt;        autoindex_exact_size    off;   &lt;span&gt;# on(默认)显示文件的确切大小，单位是byte；off显示文件大概大小，单位KB、MB、GB&lt;/span&gt;&lt;br/&gt;        autoindex_localtime     off;   &lt;span&gt;# off(默认)时显示的文件时间为GMT时间；on显示的文件时间为服务器时间&lt;/span&gt;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;禁止指定 user_agent&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;nginx 可以禁止指定的浏览器和爬虫框架访问：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; http_user_agent 为浏览器标识&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 禁止 user_agent 为baidu、360和sohu，~*表示不区分大小写匹配&lt;/span&gt;&lt;br/&gt;if ($http_user_agent ~* &#x27;baidu|360|sohu&#x27;) {&lt;br/&gt;    return 404;&lt;br/&gt;}&lt;br/&gt;&lt;span&gt;&lt;br/&gt;#&lt;/span&gt;&lt;span&gt; 禁止 Scrapy 等工具的抓取&lt;/span&gt;&lt;br/&gt;if ($http_user_agent ~* (Scrapy|Curl|HttpClient)) {&lt;br/&gt;    return 403;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;请求过滤&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;根据请求类型过滤&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; 非指定请求全返回 403&lt;/span&gt;&lt;br/&gt;if ( $request_method !~ ^(GET|POST|HEAD)$ ) {&lt;br/&gt;    return 403;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;根据状态码过滤&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;error_page 502 503 /50x.html;&lt;br/&gt;location = /50x.html {&lt;br/&gt;    root /usr/share/nginx/html;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样实际上是一个内部跳转，当访问出现 502、503 的时候就能返回 50x.html 中的内容，这里需要注意是否可以找到 50x.html 页面，所以加了个 location 保证找到你自定义的 50x 页面。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;根据 URL 名称过滤&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;if ($host = zy.com&#x27; ) {&lt;br/&gt;     #其中 $1是取自regex部分()里的内容,匹配成功后跳转到的URL。&lt;br/&gt;     rewrite ^/(.*)$  http://www.zy.com/$1  permanent；&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;location /test {&lt;br/&gt;    // /test 全部重定向到首页&lt;br/&gt;    rewrite  ^(.*)$ /index.html  redirect;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;ab 命令&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ab 命令全称为：Apache bench，是 Apache 自带的压力测试工具，也可以测试 Nginx、IIS 等其他 Web 服务器:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;-n 总共的请求数&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;-c 并发的请求数&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;-t 测试所进行的最大秒数，默认值 为 50000&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;-p 包含了需要的 POST 的数据文件&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;-T POST 数据所使用的 Content-type 头信息&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;ab -n 1000 -c 5000 http://127.0.0.1/ # 每次发送1000并发的请求数，请求数总数为5000。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;测试前需要安装 httpd-tools：&lt;code&gt;yum install httpd-tools&lt;/code&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;泛域名路径分离&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是一个非常实用的技能，经常有时候我们可能需要配置一些二级或者三级域名，希望通过 nginx 自动指向对应目录，比如：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;test1.doc.test.club 自动指向 /usr/local/html/doc/test1 服务器地址；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;test2.doc.test.club 自动指向 /usr/local/html/doc/test2 服务器地址；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;    listen       80;&lt;br/&gt;    server_name  ~^([\w-]+)\.doc\.test\.club$;&lt;br/&gt;&lt;br/&gt;    root /usr/local/html/doc/$1;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;泛域名转发&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;和之前的功能类似，有时候我们希望把二级或者三级域名链接重写到我们希望的路径，让后端就可以根据路由解析不同的规则：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;test1.serv.test.club/api?name=a 自动转发到 127.0.0.1:8080/test1/api?name=a&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;test2.serv.test.club/api?name=a 自动转发到 127.0.0.1:8080/test2/api?name=a&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;    listen       80;&lt;br/&gt;    server_name ~^([\w-]+)\.serv\.test\.club$;&lt;br/&gt;&lt;br/&gt;    location / {&lt;br/&gt;        proxy_set_header        X-Real-IP $remote_addr;&lt;br/&gt;        proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;&lt;br/&gt;        proxy_set_header        Host $http_host;&lt;br/&gt;        proxy_set_header        X-NginX-Proxy true;&lt;br/&gt;        proxy_pass              http://127.0.0.1:8080/$1$request_uri;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;常见问题&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;nginx 中怎么设置变量&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;或许你不知道，nginx 的配置文件使用的是一门微型的编程语言。既然是编程语言，一般也就少不了“变量”这种东西，但是在 nginx 配置中，变量只能存放一种类型的值，因为也只存在一种类型的值，那就是字符串。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;例如我们在 nginx.conf 中有这样一行配置：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;set $name &quot;chroot&quot;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面使用了 set 配置指令对变量 &lt;code&gt;$name&lt;/code&gt;进行了赋值操作，把 &quot;chroot&quot; 赋值给了 &lt;code&gt;$name&lt;/code&gt;。nginx 变量名前面有一个 &lt;code&gt;$&lt;/code&gt; 符号，这是记法上的要求。所有的 Nginx 变量在 Nginx 配置文件中引用时都须带上 &lt;code&gt;$&lt;/code&gt; 前缀。这种表示方法和 Perl、PHP 这些语言是相似的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种表示方法的用处在哪里呢，那就是可以直接把变量嵌入到字符串常量中以构造出新的字符串，例如你需要进行一个字符串拼接：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;  listen       80;&lt;br/&gt;  server_name  test.com;&lt;br/&gt;&lt;br/&gt;  location / {&lt;br/&gt;     set $temp hello;&lt;br/&gt;     return &quot;$temp world&quot;;&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上当匹配成功的时候就会返回字符串 &quot;hello world&quot; 了。需要注意的是，当引用的变量名之后紧跟着变量名的构成字符时（比如后跟字母、数字以及下划线），我们就需要使用特别的记法来消除歧义，例如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;server {&lt;br/&gt;  listen       80;&lt;br/&gt;  server_name  test.com;&lt;br/&gt;&lt;br/&gt;  location / {&lt;br/&gt;     set $temp &quot;hello &quot;;&lt;br/&gt;     return &quot;${temp}world&quot;;&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里，我们在配置指令的参数值中引用变量 &lt;code&gt;$temp&lt;/code&gt; 的时候，后面紧跟着 &lt;code&gt;world&lt;/code&gt; 这个单词，所以如果直接写作 &lt;code&gt;&quot;$tempworld&quot;&lt;/code&gt; 则 nginx 的计算引擎会将之识别为引用了变量 &lt;code&gt;$tempworld&lt;/code&gt;. 为了解决这个问题，nginx 的字符串支持使用花括号在 &lt;code&gt;$&lt;/code&gt; 之后把变量名围起来，比如这里的 &lt;code&gt;${temp}&lt;/code&gt;，所以 上面这个例子返回的还是 &quot;hello world&quot;：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;$&lt;/span&gt;&lt;span&gt; curl &lt;span&gt;&#x27;http://test.com/&#x27;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;    hello world&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还需要注意的是，若是想输出 &lt;code&gt;$&lt;/code&gt; 符号本身，可以这样做：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;geo $dollar {&lt;br/&gt;    default &quot;$&quot;;&lt;br/&gt;}&lt;br/&gt;server {&lt;br/&gt;    listen       80;&lt;br/&gt;    server_name  test.com;&lt;br/&gt;&lt;br/&gt;    location / {&lt;br/&gt;        set $temp &quot;hello &quot;;&lt;br/&gt;        return &quot;${temp}world: $dollar&quot;;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面用到了标准模块 ngx_geo 提供的配置指令 geo 来为变量 &lt;code&gt;$dollar&lt;/code&gt; 赋予字符串 &lt;code&gt;&quot;$&quot;&lt;/code&gt; ，这样，这里的返回值就是 &quot;hello world: $&quot; 了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;附 nginx 内置预定义变量&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;按字母顺序，变量名与对应定义：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$arg_PARAMETER&lt;/code&gt; #GET 请求中变量名 PARAMETER 参数的值&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$args&lt;/code&gt; #这个变量等于 GET 请求中的参数，例如，foo=123&amp;amp;bar=blahblah;这个变量可以被修改&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$binary_remote_addr&lt;/code&gt; #二进制码形式的客户端地址&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$body_bytes_sent&lt;/code&gt; #传送页面的字节数&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$content_length&lt;/code&gt; #请求头中的 Content-length 字段&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$content_type&lt;/code&gt; #请求头中的 Content-Type 字段&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$cookie_COOKIE&lt;/code&gt; #cookie COOKIE 的值&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$document_root&lt;/code&gt; #当前请求在 root 指令中指定的值&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$document_uri&lt;/code&gt; #与 $uri 相同&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$host&lt;/code&gt; #请求中的主机头(Host)字段，如果请求中的主机头不可用或者空，则为处理请求的 server 名称(处理请求的 server 的 server_name 指令的值)。值为小写，不包含端口&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$hostname&lt;/code&gt; #机器名使用 gethostname 系统调用的值&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$http_HEADER&lt;/code&gt; #HTTP 请求头中的内容，HEADER 为 HTTP 请求中的内容转为小写，-变为_(破折号变为下划线)，例如：&lt;code&gt;$http_user_agent&lt;/code&gt;(Uaer-Agent 的值)&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$sent_http_HEADER&lt;/code&gt; #HTTP 响应头中的内容，HEADER 为 HTTP 响应中的内容转为小写，-变为_(破折号变为下划线)，例如：&lt;code&gt;$sent_http_cache_control&lt;/code&gt;、&lt;code&gt;$sent_http_content_type&lt;/code&gt;…&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$is_args&lt;/code&gt; #如果 $args 设置，值为&quot;?&quot;，否则为&quot;&quot;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$limit_rate&lt;/code&gt; #这个变量可以限制连接速率&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$nginx_version&lt;/code&gt; #当前运行的 nginx 版本号&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$query_string&lt;/code&gt; #与 $args 相同&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$remote_addr&lt;/code&gt; #客户端的 IP 地址&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$remote_port&lt;/code&gt; #客户端的端口&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$remote_port&lt;/code&gt; #已经经过 Auth Basic Module 验证的用户名&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$request_filename&lt;/code&gt; #当前连接请求的文件路径，由 root 或 alias 指令与 URI 请求生成&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$request_body&lt;/code&gt; #这个变量（0.7.58+）包含请求的主要信息。在使用 proxy_pass 或 fastcgi_pass 指令的 location 中比较有意义&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$request_body_file&lt;/code&gt; #客户端请求主体信息的临时文件名&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$request_completion&lt;/code&gt; #如果请求成功，设为&quot;OK&quot;；如果请求未完成或者不是一系列请求中最后一部分则设为空&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$request_method&lt;/code&gt; #这个变量是客户端请求的动作，通常为 GET 或 POST。包括 0.8.20 及之前的版本中，这个变量总为 main request 中的动作，如果当前请求是一个子请求，并不使用这个当前请求的动作&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$request_uri&lt;/code&gt; #这个变量等于包含一些客户端请求参数的原始 URI，它无法修改，请查看 $uri 更改或重写 URI&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$scheme&lt;/code&gt; #所用的协议，例如 http 或者是 https，例如 &lt;code&gt;rewrite ^(.+)$$scheme://example.com$1 redirect&lt;/code&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$server_addr&lt;/code&gt; #服务器地址，在完成一次系统调用后可以确定这个值，如果要绕开系统调用，则必须在 listen 中指定地址并且使用 bind 参数&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$server_name&lt;/code&gt; #服务器名称&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$server_port&lt;/code&gt; #请求到达服务器的端口号&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$server_protocol&lt;/code&gt; #请求使用的协议，通常是 HTTP/1.0、HTTP/1.1 或 HTTP/2&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;$uri&lt;/code&gt; #请求中的当前 URI(不带请求参数，参数位于 args ) ， 不 同 于 浏 览 器 传 递 的 args)，不同于浏览器传递的 args)，不同于浏览器传递的 request_uri 的值，它可以通过内部重定向，或者使用 index 指令进行修改。不包括协议和主机名，例如 /foo/bar.html&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;附 nginx 模块&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;nginx 模块分类&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;核心模块：nginx 最基本最核心的服务，如进程管理、权限控制、日志记录；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;标准 HTTP 模块：nginx 服务器的标准 HTTP 功能；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;可选 HTTP 模块：处理特殊的 HTTP 请求&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;邮件服务模块：邮件服务&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;第三方模块：作为扩展，完成特殊功能&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;模块清单&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;核心模块&lt;/strong&gt;：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;ngx_core&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_errlog&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_conf&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_events&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_event_core&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_epll&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_regex&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;标准 HTTP 模块&lt;/strong&gt;：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;ngx_http&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_core #配置端口，URI 分析，服务器相应错误处理，别名控制 (alias) 等&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_log #自定义 access 日志&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_upstream #定义一组服务器，可以接受来自 proxy, Fastcgi,Memcache 的重定向；主要用作负载均衡&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_static&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_autoindex #自动生成目录列表&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_index #处理以/结尾的请求，如果没有找到 index 页，则看是否开启了 random_index；如开启，则用之，否则用 autoindex&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_auth_basic #基于 http 的身份认证 (auth_basic)&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_access #基于 IP 地址的访问控制 (deny,allow)&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_limit_conn #限制来自客户端的连接的响应和处理速率&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_limit_req #限制来自客户端的请求的响应和处理速率&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_geo&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_map #创建任意的键值对变量&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_split_clients&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_referer #过滤 HTTP 头中 Referer 为空的对象&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_rewrite #通过正则表达式重定向请求&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_proxy&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_fastcgi #支持 fastcgi&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_uwsgi&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_scgi&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_memcached&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_empty_gif #从内存创建一个 1×1 的透明 gif 图片，可以快速调用&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_browser #解析 http 请求头部的 User-Agent 值&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_charset #指定网页编码&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_upstream_ip_hash&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_upstream_least_conn&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_upstream_keepalive&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_write_filter&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_header_filter&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_chunked_filter&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_range_header&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_gzip_filter&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_postpone_filter&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_ssi_filter&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_charset_filter&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_userid_filter&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_headers_filter #设置 http 响应头&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_copy_filter&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_range_body_filter&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_not_modified_filter&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;可选 HTTP 模块&lt;/strong&gt;:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;ngx_http_addition #在响应请求的页面开始或者结尾添加文本信息&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_degradation #在低内存的情况下允许服务器返回 444 或者 204 错误&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_perl&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_flv #支持将 Flash 多媒体信息按照流文件传输，可以根据客户端指定的开始位置返回 Flash&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_geoip #支持解析基于 GeoIP 数据库的客户端请求&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_google_perftools&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_gzip #gzip 压缩请求的响应&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_gzip_static #搜索并使用预压缩的以.gz 为后缀的文件代替一般文件响应客户端请求&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_image_filter #支持改变 png，jpeg，gif 图片的尺寸和旋转方向&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_mp4 #支持.mp4,.m4v,.m4a 等多媒体信息按照流文件传输，常与 ngx_http_flv 一起使用&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_random_index #当收到 / 结尾的请求时，在指定目录下随机选择一个文件作为 index&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_secure_link #支持对请求链接的有效性检查&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_ssl #支持 https&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_stub_status&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_sub_module #使用指定的字符串替换响应中的信息&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_dav #支持 HTTP 和 WebDAV 协议中的 PUT/DELETE/MKCOL/COPY/MOVE 方法&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_http_xslt #将 XML 响应信息使用 XSLT 进行转换&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;邮件服务模块&lt;/strong&gt;:&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;ngx_mail_core&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_mail_pop3&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_mail_imap&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_mail_smtp&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_mail_auth_http&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_mail_proxy&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ngx_mail_ssl&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;第三方模块&lt;/strong&gt;：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;echo-nginx-module #支持在 nginx 配置文件中使用 echo/sleep/time/exec 等类 Shell 命令&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;memc-nginx-module&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;rds-json-nginx-module #使 nginx 支持 json 数据的处理&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;lua-nginx-module&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;视频号最新视频&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_iframe&quot; data-pluginname=&quot;videosnap&quot; data-id=&quot;export/UzFfAgtgekIEAQAAAAAAJjUhrlvPsAAAAAstQy6ubaLX4KHWvLEZgBPEkKNMLl9VOfD-zNPgMIuzeC2qwTgrRf13Vpi4lJ-I&quot; data-url=&quot;https://findermp.video.qq.com/251/20304/stodownload?encfilekey=RBfjicXSHKCOONJnTbRmmlD8cOQPXE48ibtBXUEAKtRgl7BUBSYHUNaRHsOibNxVHntKHcVhdahYfW9FUWseOhdjS248icaWhleRjpcWeF4S0IdQrK5SHu1BMb9Trvyiag4jniaQLwJHgicIiaD1lZquAlCCeh83dgIFOAick6HZAT3OH09I&amp;amp;adaptivelytrans=0&amp;amp;bizid=1023&amp;amp;dotrans=0&amp;amp;hy=SH&amp;amp;idx=1&amp;amp;m=dc2dec1cd446892b76a52601807aa35e&amp;amp;token=cztXnd9GyrGhE2iaHGOXDiaIEWMBk1BY6bdAkbtbt3dRnIGnyp8bibIOhicHusCyVODD&quot; data-headimgurl=&quot;http://wx.qlogo.cn/finderhead/I7awtksbibjQe7RZAy84xEecUymmic8cw4v7Y2zbnVDuo/0&quot; data-username=&quot;v2_060000231003b20faec8c6e08e1ac1d4cf06ea31b07760a16cba92d83444bd9a5d9d55ffaede@finder&quot; data-nickname=&quot;腾讯程序员&quot; data-desc=&quot;你很可能不知道的 10 个手机实用技巧，欢迎在评论区分享你的小技巧&amp;#10;#手机 #效率 #技巧 #iPhone&amp;#10;&quot; data-nonceid=&quot;10972294623550344267&quot; data-type=&quot;video&quot;/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;想了解腾讯人的故事，欢迎关注：腾讯技术&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzg5OTE3MDMzOA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/sz_mmbiz_png/YGYGFPll6xzwZBHwh7TgG3bjkhaTibXAC07CklcibMiateyQHO9oWOZBANkVvBichSQBRYf1H5D8PRRqDdWvyPicq1w/0?wx_fmt=png&quot; data-nickname=&quot;腾讯技术&quot; data-alias=&quot;&quot; data-signature=&quot;分享腾讯有料的技术，做有趣的技术人&quot; data-from=&quot;0&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>0e3fc5e2ddde0b3cc9a3aaa782d4e0c7</guid>
<title>[推荐] Java 知识点整理：Spring、MySQL</title>
<link>https://toutiao.io/k/j4kd9qh</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;post-topic-des nc-post-content&quot;&gt;
&lt;h2 id=&quot;spring-10&quot;&gt;Spring 10&lt;/h2&gt; 
&lt;h3&gt;P1：Spring 框架&lt;/h3&gt; 
&lt;p&gt;Spring 是分层的企业级应用轻量级开源框架，以 IoC 和 AOP为内核。Spring 可以降低企业级应用开发的复杂性，对此主要采取了四个关键策略：基于 POJO 的轻量级和最小侵入性编程、通过依赖注入和面向接口实现松耦合、基于切面和惯性进行声明式编程、通过切面和模板减少样板式代码。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;好处&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;降低代码耦合度、简化开发。通过 Spring 提供的 IoC 容器可以将对象间的依赖关系交由 Spring 进行控制，避免硬编码所造成的过度程序耦合。用户也不必再为单例模式类、属性文件解析等这些底层的需求编写代码，可以更专注于上层的应用。&lt;/p&gt; 
&lt;p&gt;AOP 编程以及声明式事务的支持。通过 Spring 的 AOP 功能可以方便进行面向切面的编程，通过声明式事务可以灵活进行事务管理，提高开发效率和质量。&lt;/p&gt; 
&lt;p&gt;方便程序的测试和集成各种框架。可以用非容器依赖的编程方式进行几乎所有的测试工作，可以降低各种框架的使用难度，提供了对 Mybatis 和 Hibernate 等框架的直接支持。&lt;/p&gt; 
&lt;p&gt;降低了 JavaEE API 的使用难度。Spring 对 JDBC、JavaMail、远程调用等 API 进行了封装，使这些 API 的使用难度大幅降低。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;核心容器&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;核心容器由 spring-beans、spring-core、spring-context 和 spring-expression 四个模块组成。&lt;/p&gt; 
&lt;p&gt;spring-beans 和 spring-core 模块是 Spring 的核心模块，包括了控制反转和依赖注入。BeanFactory 使用控制反转对应用程序的配置和依赖性规范与实际的应用代码进行分离，BeanFactory 实例化后并不会自动实例化 Bean，只有当 Bean 被使用时才会对其进行实例化与依赖关系的装配。&lt;/p&gt; 
&lt;p&gt;spring-context 模块构架于核心模块之上，扩展了 BeanFactory，为它添加了 Bean 的生命周期控制、框架事件体系及资源透明化加载等功能。ApplicationConext 是该模块的核心接口，它是 BeanFactory 的子接口，它实例化后会自动对所有单例 Bean 进行实例化与依赖关系的装配，使之处于待用状态。&lt;/p&gt; 
&lt;p&gt;spring-expression 是 EL 语言的扩展模块，可以查询、管理运行中的对象，同时也可以方便地调用对象方法，以及操作数组、集合等。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P2：IoC 控制反转&lt;/h3&gt; 
&lt;p&gt;IoC 即控制反转，是一种给予应用程序中目标组件更多控制的设计范式，简单来说就是把原来代码里需要实现的对象创建、依赖反转给容器来帮忙实现，需要创建一个容器并且需要一种描述来让容器知道要创建的对象之间的关系，在 Spring 框架中管理对象及其依赖关系是通过 Spring 的 IoC 容器实现的，IoC 的作用是降低代码耦合度。&lt;/p&gt; 
&lt;p&gt;IoC 的实现方式有依赖注入和依赖查找，由于依赖查找使用的很少，因此 IoC 也叫做依赖注入。依赖注入指对象被动地接受依赖类而不用自己主动去找，对象不是从容器中查找它依赖的类，而是在容器实例化对象时主动将它依赖的类注入给它。假设一个 Car 类需要一个 Engine 的对象，那么一般需要需要手动 new 一个 Engine，利用 IoC 就只需要定义一个私有的 Engine 类型的成员变量，容器会在运行时自动创建一个 Engine 的实例对象并将引用自动注入给成员变量。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;基于 XML 的容器初始化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;当创建一个 ClassPathXmlApplicationContext 时，构造器做了两件事：首先调用父容器的构造器为容器设置好 Bean 资源加载器，然后调用父类的 setConfigLocations 方法设置 Bean 配置信息的定位路径。&lt;/p&gt; 
&lt;p&gt;ClassPathXmlApplicationContext 通过调用父类 AbstractApplicationContext 的 refresh 方法启动整个 IoC 容器对 Bean 定义的载入过程，refresh 是一个模板方法，规定了 IoC 容器的启动流程。refresh 方法的主要作用是：在创建 IoC 容器之前如果已有容器存在，需要把已有的容器销毁和关闭，以保证在 refresh 方法之后使用的是新创建的 IoC 容器。&lt;/p&gt; 
&lt;p&gt;容器创建后通过 loadBeanDefinitions 方法加载 Bean 配置资源，该方***做两件事：首先调用资源加载器的方法获取要加载的资源，其次真正执行加载功能，由子类 XmlBeanDefinitionReader 实现。在加载资源时，首先会解析配置文件路径，读取配置文件的内容，然后通过 XML 解析器将 Bean 配置信息转换成文档对象，之后再按照 Spring Bean 的定义规则对文档对象进行解析。&lt;/p&gt; 
&lt;p&gt;Spring IoC 容器中注册解析的 Bean 信息存放在一个 HashMap 集合中，key 是 String 字符串，值是 BeanDefinition，在注册过程中需要使用 synchronized 同步块保证线程安全。当 Bean 配置信息中配置的 Bean 被解析后且被注册到 IoC 容器中，初始化就算真正完成了，Bean 定义信息已经可以使用，并且可以被检索。Spring IoC 容器的作用就是对这些注册的 Bean 定义信息进行处理和维护，注册的 Bean 定义信息是控制反转和依赖注入的基础。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;基于注解的容器初始化&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Spring 对注解的处理分为两种方式：① 直接将注解 Bean 注册到容器中，可以在初始化容器时注册，也可以在容器创建之后手动注册，然后刷新容器使其对注册的注解 Bean 进行处理。② 通过扫描指定的包及其子包的所有类处理，在初始化注解容器时指定要自动扫描的路径。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P3：DI 依赖注入&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;可注入的数据类型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;基本数据类型和 String、集合类型、Bean 类型。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;实现方式&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;构造器注入：IoC Service Provider 会检查被注入对象的构造器，取得它所需要的依赖对象列表，进而为其注入相应的对象。这种方法的优点是在对象构造完成后就处于就绪状态，可以马上使用。缺点是当依赖对象较多时，构造器的参数列表会比较长，构造器无法被继承，无法设置默认值。对于非必需的依赖处理可能需要引入多个构造器，参数数量的变动可能会造成维护的困难。&lt;/p&gt; 
&lt;p&gt;setter 方法注入：当前对象只需要为其依赖对象对应的属性添加 setter 方法，就可以通过 setter 方法将依赖对象注入到被依赖对象中。setter 方法注入在描述性上要比构造器注入强，并且可以被继承，允许设置默认值。缺点是无法在对象构造完成后马上进入就绪状态。&lt;/p&gt; 
&lt;p&gt;接口注入：必须实现某个接口，这个接口提供一个方法来为其注入依赖对象。使用较少，因为它强制要求被注入对象实现不必要的接口，侵入性强。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关注解&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Autowired&lt;/code&gt;：自动按类型注入，如果有多个匹配则按照指定 Bean 的 id 查找，查找不到会报错。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Qualifier&lt;/code&gt;：在自动按照类型注入的基础上再按照 Bean 的 id 注入，给变量注入时必须搭配 &lt;code&gt;@Autowired&lt;/code&gt;，给方法注入时可单独使用。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Resource&lt;/code&gt; ：直接按照 Bean 的 id 注入，只能注入 Bean 类型。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Value&lt;/code&gt; ：用于注入基本数据类型和 String 类型。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;依赖注入的过程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;getBean 方法是获取 Bean 实例的方法，该方***调用 doGetBean 方法，doGetBean 真正实现向 IoC 容器获取 Bean 的功能，也是触发依赖注入的地方。如果 Bean 定义为单例模式，容器在创建之前先从缓存中查找以确保整个容器中只存在一个实例对象。如果 Bean 定义为原型模式，则容器每次都会创建一个新的实例。&lt;/p&gt; 
&lt;p&gt;具体创建 Bean 实例对象的过程由 ObjectFactory 的 createBean 方法完成，该方法主要通过 createBeanInstance 方法生成 Bean 包含的 Java 对象实例和 populateBean 方法对 Bean 属性的依赖注入进行处理。&lt;/p&gt; 
&lt;p&gt;在 createBeanInstance 方法中根据指定的初始化策略，通过简单工厂、工厂方法或容器的自动装配特性生成 Java 实例对象，对工厂方法和自动装配特性的 Bean，调用相应的工厂方法或参数匹配的构造器即可完成实例化对象的工作，但最常用的默认无参构造器需要使用 JDK 的反射或 CGLib 来进行初始化。&lt;/p&gt; 
&lt;p&gt;在 populateBean 方法中，注入过程主要分为两种情况：① 属性值类型不需要强制转换时，不需要解析属性值，直接进行依赖注入。② 属性值类型需要强制转换时，首先需要解析属性值，然后对解析后的属性值进行依赖注入。依赖注入的过程就是将 Bean 对象实例设置到它所依赖的 Bean 对象属性上，真正的依赖注入是通过 setPropertyValues 方法实现的，该方法使用了委派模式。&lt;/p&gt; 
&lt;p&gt;BeanWrapperImpl 类负责对容器完成初始化的 Bean 实例对象进行属性的依赖注入，对于非集合类型的属性，大量使用 JDK 的反射机制，通过属性的 getter 方法获取指定属性注入前的值，同时调用属性的 setter 方法为属性设置注入后的值。对于集合类型的属性，将属性值解析为目标类型的集合后直接赋值给属性。&lt;/p&gt; 
&lt;p&gt;当 Spring IoC 容器对 Bean 定义资源的定位、载入、解析和依赖注入全部完成后，就不再需要我们手动创建所需的对象，Spring IoC 容器会自动为我们创建对象并且注入好相关依赖。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P4：Bean 对象&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;生命周期&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 IoC 容器的初始化过程中会对 Bean 定义完成资源定位，加载读取配置并解析，最后将解析的 Bean 信息放在一个 HashMap 集合中。当 IoC 容器初始化完成后，会进行对 Bean 实例的创建和依赖注入过程，注入对象依赖的各种属性值，在初始化时可以指定自定义的初始化方法。经过这一系列初始化操作后 Bean 达到可用状态，接下来就可以使用 Bean 了，当使用完成后会调用 destroy 方法进行销毁，此时也可以指定自定义的销毁方法，最终 Bean 被销毁且从容器中移除。&lt;/p&gt; 
&lt;p&gt;指定 Bean 初始化和销毁的方法：&lt;/p&gt; 
&lt;p&gt;XML 方式通过配置 bean 标签中的 init-Method 和 destory-Method 指定自定义初始化和销毁方法。 &lt;/p&gt; 
&lt;p&gt;注解方式通过 &lt;code&gt;@PreConstruct&lt;/code&gt; 和 &lt;code&gt;@PostConstruct&lt;/code&gt; 注解指定自定义初始化和销毁方法。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;作用范围&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通过 scope 属性指定 bean 的作用范围，包括：① singleton：单例模式，是默认作用域，不管收到多少 Bean 请求每个容器中只有一个唯一的 Bean 实例。② prototype：原型模式，和 singleton 相反，每次 Bean 请求都会创建一个新的实例。③ request：每次 HTTP 请求都会创建一个新的 Bean 并把它放到 request 域中，在请求完成后 Bean 会失效并被垃圾收集器回收。④ session：和 request 类似，确保每个 session 中有一个 Bean 实例，session 过期后 bean 会随之失效。⑤ global session：当应用部署在 Portlet 容器中时，如果想让所有 Portlet 共用全局存储变量，那么这个变量需要存储在 global session 中。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;创建方式&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;XML&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通过默认无参构造器，只需要指明 bean 标签中的 id 和 class 属性，如果没有无参构造器会报错。&lt;/p&gt; 
&lt;p&gt;使用静态工厂方法，通过 bean 标签中的 class 属性指明静态工厂，factory-method 属性指明静态工厂方法。&lt;/p&gt; 
&lt;p&gt;使用实例工厂方法，通过 bean 标签中的 factory-bean 属性指明实例工厂，factory-method 属性指明实例工厂方法。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;注解&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Component&lt;/code&gt; 把当前类对象存入 Spring 容器中，相当于在 xml 中配置一个 bean 标签。value 属性指定 bean 的 id，默认使用当前类的首字母小写的类名。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Controller&lt;/code&gt;，&lt;code&gt;@Service&lt;/code&gt;，&lt;code&gt;@Repository&lt;/code&gt; 三个注解都是 &lt;code&gt;@Component&lt;/code&gt; 的衍生注解，作用及属性都是一模一样的。只是提供了更加明确语义，&lt;code&gt;@Controller&lt;/code&gt; 用于表现层，&lt;code&gt;@Service&lt;/code&gt;用于业务层，&lt;code&gt;@Repository&lt;/code&gt;用于持久层。如果注解中有且只有一个 value 属性要赋值时可以省略 value。&lt;/p&gt; 
&lt;p&gt;如果想将第三方的类变成组件又没有源代码，也就没办法使用 &lt;code&gt;@Component&lt;/code&gt; 进行自动配置，这种时候就要使用 &lt;code&gt;@Bean&lt;/code&gt; 注解。被 &lt;code&gt;@Bean&lt;/code&gt; 注解的方法返回值是一个对象，将会实例化，配置和初始化一个新对象并返回，这个对象由 Spring 的 IoC 容器管理。name 属性用于给当前 &lt;code&gt;@Bean&lt;/code&gt; 注解方法创建的对象指定一个名称，即 bean 的 id。当使用注解配置方法时，如果方法有参数，Spring 会去容器查找是否有可用 bean对象，查找方式和 &lt;code&gt;@Autowired&lt;/code&gt; 一样。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Configuration&lt;/code&gt; 用于指定当前类是一个 spring 配置类，当创建容器时会从该类上加载注解，value 属性用于指定配置类的字节码。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@ComponentScan&lt;/code&gt; 用于指定 Spring 在初始化容器时要扫描的包。basePackages 属性用于指定要扫描的包。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@PropertySource&lt;/code&gt; 用于加载 &lt;code&gt;.properties&lt;/code&gt; 文件中的配置。value 属性用于指定文件位置，如果是在类路径下需要加上 classpath。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Import&lt;/code&gt; 用于导入其他配置类，在引入其他配置类时可以不用再写 &lt;code&gt;@Configuration&lt;/code&gt; 注解。有 &lt;code&gt;@Import&lt;/code&gt; 的是父配置类，引入的是子配置类。value 属性用于指定其他配置类的字节码。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;BeanFactory、FactoryBean 和 ApplicationContext 的区别&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;BeanFactory 是一个 Bean 工厂，实现了工厂模式，是 Spring IoC 容器最顶级的接口，可以理解为含有 Bean 集合的工厂类，它的作用是管理 Bean，包括实例化、定位、配置应用程序中的对象及建立这些对象之间的依赖。BeanFactory 实例化后并不会自动实例化 Bean，只有当 Bean 被使用时才会对其进行实例化与依赖关系的装配，属于延迟加载，适合多例模式。&lt;/p&gt; 
&lt;p&gt;FactoryBean 是一个工厂 Bean，作用是生产其他 Bean 实例，可以通过实现该接口，提供一个工厂方法来自定义实例化 Bean 的逻辑。&lt;/p&gt; 
&lt;p&gt;ApplicationConext 是 BeanFactory 的子接口，扩展了 BeanFactory 的功能，提供了支持国际化的文本消息，统一的资源文件读取方式，事件传播以及应用层的特别配置等。容器会在初始化时对配置的 Bean 进行预实例化，Bean 的依赖注入在容器初始化时就已经完成，属于立即加载，适合单例模式，一般推荐使用 ApplicationContext。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P5：AOP 面向切面编程&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;概念和原理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;AOP 即面向切面编程，简单地说就是将代码中重复的部分抽取出来，在需要执行的时候使用动态代理的技术，在不修改&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%BA%90%E7%A0%81&quot; target=&quot;_blank&quot;&gt;源码&lt;/a&gt;的基础上对方法进行增强。优点是可以减少代码的冗余，提高开发效率，维护方便。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Spring 会根据类是否实现了接口来判断动态代理的方式，如果实现了接口会使用 JDK 的动态代理，核心是 InvocationHandler 接口和 Proxy 类，如果没有实现接口会使用 CGLib 动态代理，CGLib 是在运行时动态生成某个类的子类，如果某一个类被标记为 final，是不能使用 CGLib 动态代理的。&lt;/p&gt; 
&lt;p&gt;JDK 动态代理主要通过重组字节码实现，首先获得被代理对象的引用和所有接口，生成新的类必须实现被代理类的所有接口，动态生成Java 代码后编译新生成的 &lt;code&gt;.class&lt;/code&gt; 文件并重新加载到 JVM 运行。JDK 代理直接写 Class 字节码，CGLib是采用ASM框架写字节码，生成代理类的效率低。但是CGLib调用方法的效率高，因为 JDK 使用反射调用方法，CGLib 使用 FastClass 机制为代理类和被代理类各生成一个类，这个类会为代理类或被代理类的方法生成一个 index，这个 index 可以作为参数直接定位要调用的方法。&lt;/p&gt; 
&lt;p&gt;常用场景包括权限认证、自动缓存、错误处理、日志、调试和事务等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关注解&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Aspect&lt;/code&gt;：声明被注解的类是一个切面 Bean。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Before&lt;/code&gt;：前置通知，指在某个连接点之前执行的通知。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@After&lt;/code&gt;：后置通知，指某个连接点退出时执行的通知（不论正常返回还是异常退出）。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@AfterReturning&lt;/code&gt;：返回后通知，指某连接点正常完成之后执行的通知，返回值使用returning属性接收。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@AfterThrowing&lt;/code&gt;：异常通知，指方法抛出异常导致退出时执行的通知，和&lt;code&gt;@AfterReturning&lt;/code&gt;只会有一个执行，异常使用throwing属性接收。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;相关术语&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Aspect&lt;/code&gt;：切面，一个关注点的模块化，这个关注点可能会横切多个对象。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Joinpoint&lt;/code&gt;：连接点，程序执行过程中的某一行为，即业务层中的所有方法。。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Advice&lt;/code&gt;：通知，指切面对于某个连接点所产生的动作，包括前置通知、后置通知、返回后通知、异常通知和环绕通知。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Pointcut&lt;/code&gt;：切入点，指被拦截的连接点，切入点一定是连接点，但连接点不一定是切入点。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Proxy&lt;/code&gt;：代理，Spring AOP 中有 JDK 动态代理和 CGLib 代理，目标对象实现了接口时采用 JDK 动态代理，反之采用 CGLib 代理。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Target&lt;/code&gt;：代理的目标对象，指一个或多个切面所通知的对象。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Weaving&lt;/code&gt; ：织入，指把增强应用到目标对象来创建代理对象的过程。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AOP 的过程&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Spring AOP 是由 BeanPostProcessor 后置处理器开始的，这个后置处理器是一个***，可以监听容器触发的 Bean 生命周期事件，向容器注册后置处理器以后，容器中管理的 Bean 就具备了接收 IoC 容器回调事件的能力。BeanPostProcessor 的调用发生在 Spring IoC 容器完成 Bean 实例对象的创建和属性的依赖注入之后，为 Bean 对象添加后置处理器的入口是 initializeBean 方法。&lt;/p&gt; 
&lt;p&gt;Spring 中 JDK 动态代理生通过 JdkDynamicAopProxy 调用 Proxy 的 newInstance 方法来生成代理类，JdkDynamicAopProxy 也实现了 InvocationHandler 接口，invoke 方法的具体逻辑是先获取应用到此方法上的拦截器链，如果有拦截器则创建 MethodInvocation 并调用其 proceed 方法，否则直接反射调用目标方法。因此 Spring AOP 对目标对象的增强是通过拦截器实现的。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P6：Spring MVC 核心组件&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;DispatcherServlet&lt;/code&gt;&lt;span&gt;：SpringMVC 中的&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%89%8D%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;前端&lt;/a&gt;控制器，是整个流程控制的核心，负责接收请求并转发给对应的处理组件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Handler&lt;/code&gt;：处理器，完成具体业务逻辑，相当于 Servlet 或 Action。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;HandlerMapping&lt;/code&gt;：完成URL 到 Controller映射的组件，DispatcherServlet 接收到请求之后，通过 HandlerMapping 将不同的请求映射到不同的 Handler。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;HandlerInterceptor&lt;/code&gt;：处理器拦截器，是一个接口，如果需要完成一些拦截处理，可以实现该接口。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;HandlerExecutionChain&lt;/code&gt;：处理器执行链，包括两部分内容：Handler 和 HandlerInterceptor。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;HandlerAdapter&lt;/code&gt;：处理器适配器，Handler执行业务方法前需要进行一系列操作，包括表单数据验证、数据类型转换、将表单数据封装到JavaBean等，这些操作都由 HandlerAdapter 完成。DispatcherServlet 通过 HandlerAdapter 来执行不同的 Handler。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ModelAndView&lt;/code&gt;：装载了模型数据和视图信息，作为 Handler 的处理结果返回给 DispatcherServlet。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;ViewResolver&lt;/code&gt;&lt;span&gt;：视图解析器，DispatcherServlet 通过它将逻辑视图解析为物理视图，最终将渲染的结果响应给&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P7：Spring MVC 处理流程&lt;/h3&gt; 
&lt;p&gt;Web 容器启动时会通知 Spring 初始化容器，加载 Bean 的定义信息并初始化所有单例 Bean，然后遍历容器中的 Bean，获取每一个 Controller 中的所有方法访问的 URL，将 URL 和对应的 Controller 保存到一个 Map 集合中。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;所有的请求会转发给 DispatcherServlet &lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%89%8D%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;前端&lt;/a&gt;处理器处理，DispatcherServlet 会请求 HandlerMapping 找出容器中被 &lt;/span&gt;&lt;code&gt;@Controler&lt;/code&gt; 注解修饰的 Bean 以及被 &lt;code&gt;@RequestMapping&lt;/code&gt; 修饰的方法和类，生成 Handler 和 HandlerInterceptor 并以一个 HandlerExcutionChain 处理器执行链的形式返回。&lt;/p&gt; 
&lt;p&gt;之后 DispatcherServlet 使用 Handler 找到对应的 HandlerApapter，通过 HandlerApapter 调用 Handler 的方法，将请求参数绑定到方法的形参上，执行方法处理请求并得到 ModelAndView。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;最后 DispatcherServlet 根据使用 ViewResolver 试图解析器对得到的 ModelAndView 逻辑视图进行解析得到 View 物理视图，然后对视图渲染，将数据填充到视图中并返回给&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;注解&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Controller&lt;/code&gt;：在类定义处添加，将类交给IoC容器管理。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@RequtestMapping&lt;/code&gt;：将URL请求和业务方法映射起来，在类和方法定义上都可以添加该注解。&lt;code&gt;value&lt;/code&gt; 属性指定URL请求的实际地址，是默认值。&lt;code&gt;method&lt;/code&gt; 属性限制请求的方法类型，包括GET、POST、PUT、DELETE等。如果没有使用指定的请求方法请求URL，会报405 Method Not Allowed 错误。&lt;code&gt;params&lt;/code&gt; 属性限制必须提供的参数，如果没有会报错。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@RequestParam&lt;/code&gt;：如果 Controller 方法的形参和 URL 参数名一致可以不添加注解，如果不一致可以使用该注解绑定。&lt;code&gt;value&lt;/code&gt; 属性表示HTTP请求中的参数名。&lt;code&gt;required&lt;/code&gt; 属性设置参数是否必要，默认false。&lt;code&gt;defaultValue&lt;/code&gt; 属性指定没有给参数赋值时的默认值。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@PathVariable&lt;/code&gt;：Spring MVC 也支持 RESTful 风格的 URL，通过 &lt;code&gt;@PathVariable&lt;/code&gt; 完成请求参数与形参的绑定。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P8：Spring Data JPA 框架&lt;/h3&gt; 
&lt;p&gt;Spring Data JPA 是 Spring 基于 ORM 框架、JPA 规范的基础上封装的一套 JPA 应用框架，可使开发者用极简的代码实现对数据库的访问和操作。它提供了包括增删改查等在内的常用功能，且易于扩展，可以极大提高开发效率。&lt;/p&gt; 
&lt;p&gt;ORM 即 Object-Relational Mapping ，表示对象关系映射，映射的不只是对象的值还有对象之间的关系，通过 ORM 就可以把对象映射到关系型数据库中。操作实体类就相当于操作数据库表，可以不再重点关注 SQL 语句。&lt;/p&gt; 
&lt;p&gt;使用时只需要持久层接口继承 JpaRepository 即可，泛型参数列表中第一个参数是实体类类型，第二个参数是主键类型。运行时通过 &lt;code&gt;JdkDynamicAopProxy&lt;/code&gt; 的 &lt;code&gt;invoke&lt;/code&gt; 方法创建了一个动态代理对象 &lt;code&gt;SimpleJpaRepository&lt;/code&gt;，&lt;code&gt;SimpleJpaRepository&lt;/code&gt; 中封装了 JPA 的操作，通过 &lt;code&gt;hibernate&lt;/code&gt;（封装了JDBC）完成数据库操作。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;注解&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Entity&lt;/code&gt;：表明当前类是一个实体类。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Table&lt;/code&gt; ：关联实体类和数据库表。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Column&lt;/code&gt; ：关联实体类属性和数据库表中字段。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@Id&lt;/code&gt; ：声明当前属性为数据库表主键对应的属性。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@GeneratedValue&lt;/code&gt;： 配置主键生成策略。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@OneToMany&lt;/code&gt; ：配置一对多关系，mappedBy 属性值为主表实体类在从表实体类中对应的属性名。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@ManyToOne&lt;/code&gt; ：配置多对一关系，targetEntity 属性值为主表对应实体类的字节码。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;@JoinColumn&lt;/code&gt;：配置外键关系，name 属性值为外键名称，referencedColumnName 属性值为主表主键名称。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;对象导航查询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通过 get 方法查询一个对象的同时，通过此对象可以查询它的关联对象。&lt;/p&gt; 
&lt;p&gt;对象导航查询一到多默认使用延迟加载的形式， 关联对象是集合，因此使用立即加载可能浪费资源。&lt;/p&gt; 
&lt;p&gt;对象导航查询多到一默认使用立即加载的形式， 关联对象是一个对象，因此使用立即加载。&lt;/p&gt; 
&lt;p&gt;如果要改变加载方式，在实体类注解配置加上 fetch 属性即可，LAZY 表示延迟加载，EAGER 表示立即加载。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P9：Mybatis 框架&lt;/h3&gt; 
&lt;p&gt;Mybatis 是一个实现了数据持久化的 ORM 框架，简单理解就是对 JDBC 进行了封装。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;相比 JDBC 减少了大量代码量，减少冗余代码。&lt;/p&gt; 
&lt;p&gt;使用灵活，SQL 语句写在 XML 里，从程序代码中彻底分离，降低了耦合度，便于管理。&lt;/p&gt; 
&lt;p&gt;提供 XML 标签，支持编写动态 SQL 语句。&lt;/p&gt; 
&lt;p&gt;提供映射标签，支持对象与数据库的 ORM 字段映射关系。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;SQL 语句编写工作量较大，尤其是字段和关联表多时。&lt;/p&gt; 
&lt;p&gt;SQL 语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;映射文件标签&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;select&lt;/code&gt;、&lt;code&gt;insert&lt;/code&gt;、&lt;code&gt;update&lt;/code&gt;、&lt;code&gt;delete&lt;/code&gt; 标签分别对应查询、添加、更新、删除操作。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;parameterType&lt;/code&gt; 属性表示参数的数据类型，包括基本数据类型和对应的包装类型、String 和 Java Bean 类型，当有多个参数时可以使用 &lt;code&gt;#{argn}&lt;/code&gt; 的形式表示第 n 个参数。除了基本数据类型都要以全限定类名的形式指定参数类型。&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;resultType&lt;/code&gt; 表示返回的结果类型，包括基本数据类型和对应的包装类型、String 和 Java Bean 类型。还可以使用把返回结果封装为复杂类型的 &lt;code&gt;resultMap&lt;/code&gt; 。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;缓存&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;使用缓存可以减少程序和数据库交互的次数，从而提高程序的运行效率。第一次查询后会自动将结果保存到缓存中，下一次查询时直接从缓存中返回结果无需再次查询数据库。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;一级缓存&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;SqlSession 级别，默认开启且不能关闭。&lt;/p&gt; &lt;p&gt;操作数据库时需要创建 SqlSession 对象，在对象中有一个 HashMap 用于存储缓存数据，不同 SqlSession 之间缓存数据区域互不影响。&lt;/p&gt; &lt;p&gt;一级缓存的作用域是 SqlSession 范围的，在同一个 SqlSession 中执行两次相同的 SQL 语句时，第一次执行完毕会将结果保存在缓存中，第二次查询直接从缓存中获取。&lt;/p&gt; &lt;p&gt;如果 SqlSession 执行了 DML 操作（insert、update、delete），Mybatis 必须将缓存清空以保证数据的有效性。 &lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;二级缓存&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Mapper 级别，默认关闭。&lt;/p&gt; &lt;p&gt;使用二级缓存时多个 SqlSession 使用同一个 Mapper 的 SQL 语句操作数据库，得到的数据会存在二级缓存区，同样使用 HashMap 进行数据存储，相比于一级缓存，二级缓存范围更大，多个 SqlSession 可以共用二级缓存，作用域是 Mapper 的同一个 namespace，不同 SqlSession 两次执行相同的 namespace 下的 SQL 语句，参数也相等，则第一次执行成功后会将数据保存在二级缓存中，第二次可直接从二级缓存中取出数据。&lt;/p&gt; &lt;p&gt;要使用二级缓存，先在在全局配置文件中配置：&lt;/p&gt; &lt;pre class=&quot;prettyprint lang-xml&quot; from-niu=&quot;default&quot;&gt;&amp;lt;!-- 开启二级缓存 --&amp;gt;
&amp;lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&amp;gt;&lt;/pre&gt; &lt;p&gt;再在对应的映射文件中配置一个 cache 标签即可。&lt;/p&gt; &lt;pre class=&quot;prettyprint lang-xml&quot; from-niu=&quot;default&quot;&gt;&amp;lt;cache/&amp;gt;&lt;/pre&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P10：Spring Cloud 框架&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;单体应用存在的问题&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;随着业务发展，开发越来越复杂。&lt;/p&gt; 
&lt;p&gt;修改、新增某个功能，需要对整个系统进行测试、重新部署。&lt;/p&gt; 
&lt;p&gt;一个模块出现问题，可能导致整个系统崩溃。&lt;/p&gt; 
&lt;p&gt;多个开发团队同时对数据进行管理，容易产生安全漏洞。&lt;/p&gt; 
&lt;p&gt;各个模块使用同一种技术开发，各个模块很难根据实际情况选择更合适的技术框架，局限性很大。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;分布式和集群的区别&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;集群：一台服务器无法负荷高并发的数据访问量，就设置多台服务器一起分担压力，是在物理层面解决问题。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;分布式：将一个复杂的问题拆分成若干简单的小问题，将一个大型的&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A1%B9%E7%9B%AE&quot; target=&quot;_blank&quot;&gt;项目&lt;/a&gt;架构拆分成若干个微服务来协同完成，在软件设计层面解决问题。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;微服务的优点&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;各个服务的开发、测试、部署都相互独立，用户服务可以拆分为独立服务，如果用户量很大，可以很容易对其实现负载。&lt;/p&gt; 
&lt;p&gt;当新需求出现时，使用微服务不再需要考虑各方面的问题，例如兼容性、影响度等。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;使用微服务拆分&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A1%B9%E7%9B%AE&quot; target=&quot;_blank&quot;&gt;项目&lt;/a&gt;后，各个服务之间消除了很多限制，只需要保证对外提供的接口正常可用，而不限制语言和框架等选择。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;服务治理 Eureka&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;服务治理的核心由三部分组成：&lt;strong&gt;服务提供者&lt;/strong&gt;、&lt;strong&gt;服务消费者&lt;/strong&gt;、&lt;strong&gt;注册中心&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;服务注册：在分布式系统架构中，每个微服务在启动时，将自己的信息存储在注册中心。&lt;/p&gt; 
&lt;p&gt;服务发现：服务消费者从注册中心获取服务提供者的网络信息，通过该信息调用服务。&lt;/p&gt; 
&lt;p&gt;Spring Cloud 的服务治理使用 Eureka 实现，Eureka 是 Netflix 开源的基于 REST 的服务治理解决方案，Spring Cloud 集成了 Eureka，提供服务注册和服务发现的功能，可以和基于 Spring Boot 搭建的微服务应用轻松完成整合，将 Eureka 二次封装为 Spring Cloud Eureka。&lt;strong&gt;Eureka Server&lt;/strong&gt; 是注册中心，所有要进行注册的微服务通过 Eureka Client 连接到 Eureka Server 完成注册。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;服务网关 Zuul&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Spring Cloud 集成了 Zuul 组件，实现服务网关。Zuul 是 Netflix 提供的一个开源的 API 网关服务器，是&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;和网站后端所有请求的中间层，对外开放一个 API，将所有请求导入统一的入口，屏蔽了服务端的具体实现逻辑，可以实现方向代理功能，在网关内部实现动态路由、身份认证、IP过滤、数据监控等。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;负载均衡 Ribbon&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Spring Cloud Ribbon 是一个负载均衡的解决方案，Ribbon 是 Netflix 发布的均衡负载器，Spring Cloud Ribbon是基于 Netflix Ribbon 实现的，是一个用于对 HTTP 请求进行控制的负载均衡&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;在注册中心对 Ribbon 进行注册之后，Ribbon 就可以基于某种负载均衡算***循、随机、加权轮询、加权随机等）自动帮助服务消费者调用接口，开发者也可以根据具体需求自定义 Ribbon 负载均衡&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;。实际开发中 Spring Clooud Ribbon 需要结合 Spring Cloud Eureka 使用，Eureka 提供所有可以调用的服务提供者列表，Ribbon 基于特定的负载均衡&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;从这些服务提供者中选择要调用的具体实例。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;声明式接口调用 Feign&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Feign 与 Ribbon 一样也是 Netflix 提供的，Feign 是一个声明式、模板化的 Web Service &lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;，简化了开发者编写 Web 服务&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;的操作，开发者可以通过简单的接口和注解来调用 HTTP API，Spring Cloud Feign 整合了 Ribbon 和 Hystrix，具有可插拔、基于注解、负载均衡、服务熔断等一系列功能。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;相比于 Ribbon + RestTemplate 的方式，Feign 可以大大简化代码开发，支持多种注解，包括 Feign 注解、JAX-RS 注解、Spring MVC 注解等。RestTemplate 是 Spring 框架提供的基于 REST 的服务组件，底层是对 HTTP 请求及响应进行了封装，提供了很多访问 REST 服务的方法，可以简化代码开发。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;服务熔断 Hystrix&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;熔断器的作用是在不改变各个微服务调用关系的前提下，针对错误情况进行预先处理。&lt;/p&gt; 
&lt;p&gt;设计原则：服务隔离机制、服务降级机制、熔断机制、提供实时监控和报警功能和提供实时配置修改功能&lt;/p&gt; 
&lt;p&gt;Hystrix 数据监控需要结合 &lt;code&gt;Spring Boot Actuator&lt;/code&gt; 使用，Actuator 提供了对服务的数据监控、数据统计，可以通过 &lt;code&gt;hystirx-stream&lt;/code&gt; 节点获取监控的请求数据，同时提供了可视化监控界面。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;服务配置 Config&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Spring Cloud Config 通过服务端可以为多个&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;提供配置服务，既可以将配置文件存储在本地，也可以将配置文件存储在远程的 Git 仓库，创建 Config Server，通过它管理所有的配置文件。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;服务跟踪 Zipkin&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Spring Cloud Zipkin 是一个可以采集并跟踪分布式系统中请求数据的组件，让开发者更直观地监控到请求在各个微服务耗费的时间，Zipkin 包括两部分 Zipkin Server 和 Zipkin Client。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h2 id=&quot;mysql-15&quot;&gt;MySQL 15&lt;/h2&gt; 
&lt;h3&gt;P1：逻辑架构&lt;/h3&gt; 
&lt;p&gt;第一层是服务器层，主要提供连接处理、授权认证、安全等功能，该层的服务不是 MySQL 独有的，大多数基于网络的 C/S 服务都有类似架构。&lt;/p&gt; 
&lt;p&gt;第二层实现了 MySQL 核心服务功能，包括查询解析、分析、优化、缓存以及日期、时间等所有内置函数，所有跨存储引擎的功能都在这一层实现，例如存储过程、触发器、视图等。&lt;/p&gt; 
&lt;p&gt;第三层是存储引擎层，存储引擎负责 MySQL 中数据的存储和提取。服务器通过API 与存储引擎通信，这些接口屏蔽了不同存储引擎的差异，使得差异对上层查询过程透明。除了会解析外键定义的 InnoDB 外，存储引擎不会解析SQL，不同存储引擎之间也不会相互通信，只是简单响应上层服务器请求。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P2：锁&lt;/h3&gt; 
&lt;p&gt;当有多个查询需要在同一时刻修改数据时就会产生并发控制的问题，MySQL 在两个层面进行并发控制：服务器层与存储引擎层。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;读写锁&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在处理并发读或写时，可以通过实现一个由两种类型组成的锁系统来解决问题。这两种类型的锁通常被称为共享锁和排它锁，也叫读锁和写锁。读锁是共享的，或者说相互不阻塞的，多个客户在同一时刻可以同时读取同一个资源而不相互干扰。写锁则是排他的，也就是说一个写锁会阻塞其他的写锁和读锁，只有如此才能确保在给定时间内只有一个用户能执行写入并防止其他用户读取正在写入的同一资源。在实际的数据库系统中，每时每刻都在发生锁定，当某个用户在修改某一部分数据时，MySQL 会通过锁定防止其他用户读取同一数据。写锁比读锁有更高的优先级，一个写锁请求可能会被插入到读锁队列的前面，但是读锁不能插入到写锁前面。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;锁策略&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一种提高共享资源并发性的方法就是让锁定对象更有选择性，尽量只锁定需要修改的部分数据而不是所有资源，更理想的方式是只对会修改的数据进行精确锁定。任何时刻在给定的资源上，锁定的数据量越少，系统的并发程度就越高，只要不发生冲突即可。&lt;/p&gt; 
&lt;p&gt;锁策略就是在锁的开销和数据安全性之间寻求平衡，这种平衡也会影响性能。大多数商业数据库系统没有提供更多选择，一般都是在表上加行锁，而 MySQL 提供了多种选择，每种MySQL存储引擎都可以实现自己的锁策略和锁粒度。MySQL最重要的两种锁策略是：&lt;/p&gt; 
 
&lt;p&gt;&lt;strong&gt;死锁&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;死锁是指两个或者多个事务在同一资源上相互占用并请求锁定对方占用的资源，从而导致恶性循环的现象。当多个事务试图以不同顺序锁定资源时就可能会产生死锁，多个事务同时锁定同一个资源时也会产生死锁。&lt;/p&gt; 
&lt;p&gt;为了解决死锁问题，数据库系统实现了各种死锁检测和死锁超时机制。越复杂的系统，例如InnoDB 存储引擎，越能检测到死锁的循环依赖，并立即返回一个错误。这种解决方式很有效，否则死锁会导致出现非常慢的查询。还有一种解决方法，就是当查询的时间达到锁等待超时的设定后放弃锁请求，这种方式通常来说不太好。InnoDB 目前处理死锁的方法是将持有最少行级排它锁的事务进行回滚。&lt;/p&gt; 
&lt;p&gt;锁的行为与顺序是和存储引擎相关的，以同样的顺序执行语句，有些存储引擎会产生死锁有些则不会。死锁的产生有双重原因：有些是真正的数据冲突，这种情况很难避免，有些则完全是由于存储引擎的实现方式导致的。&lt;/p&gt; 
&lt;p&gt;死锁发生之后，只有部分或者完全回滚其中一个事务，才能打破死锁。对于事务型系统这是无法避免的，所以应用程序在设计时必须考虑如何处理死锁。大多数情况下只需要重新执行因死锁回滚的事务即可。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;&lt;font&gt;P3：事务&lt;/font&gt;&lt;/h3&gt; 
&lt;p&gt;事务就是一组原子性的 SQL 查询，或者说一个独立的工作单元。如果数据库引擎能够成功地对数据库应用该组查询的全部语句，那么就执行该组查询。如果其中有任何一条语句因为崩溃或其他原因无法执行，那么所有的语句都不会执行。也就是说事务内的语句要么全部执行成功，要么全部执行失败。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ACID 特性&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一个运行良好的事务处理系统必须具备 ACID 特性，实现了 ACID 的数据库需要更强的CPU处理能力、更大的内存和磁盘空间。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;原子性 atomicity&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;一个事务在逻辑上是必须不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务来说不可能只执行其中的一部分。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;一致性 consistency&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;数据库总是从一个一致性的状态转换到另一个一致性的状态。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;隔离性 isolation&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;针对并发事务而言，隔离性就是要隔离并发运行的多个事务之间的相互影响，一般来说一个事务所做的修改在最终提交以前，对其他事务是不可见的。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;持久性 durability&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;一旦事务提交成功，其修改就会永久保存到数据库中，此时即使系统崩溃，修改的数据也不会丢失。&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;隔离级别&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在 SQL 标准中定义了四种隔离级别，每一种隔离级别都规定了一个事务中所做的修改，哪些在事务内和事务间是可见的，哪些是不可见的。较低级别的隔离通常可以执行更高的并发，系统的开销也更低。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;未提交读 READ UNCOMMITTED&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;在该级别事务中的修改即使没有被提交，对其他事务也是可见的。事务可以读取其他事务修改完但未提交的数据，这种问题称为脏读。这个级别还会导致不可重复读和幻读，从性能上说也没有比其他级别好很多，因此很少使用。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;提交读 READ COMMITTED&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;大多数数据库系统默认的隔离级别就是提交读，但 MySQL 不是。提交读满足了隔离性的简单定义：一个事务开始时只能&quot;看见&quot;已经提交的事务所做的修改。换句话说，一个事务从开始直到提交之前的任何修改对其他事务都是不可见的。这个级别有时也叫不可重复读，因为两次执行同样的查询可能会得到不同结果。提交读存在不可重复读和幻读的问题。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;可重复读 REPEATABLE READ&lt;/strong&gt;（MySQL默认的隔离级别）&lt;/p&gt; &lt;p&gt;可重复读解决了不可重复读的问题，该级别保证了在同一个事务中多次读取同样的记录结果是一致的。但可重复读隔离级别还是无法解决幻读的问题，所谓幻读，指的是当某个事务在读取某个范围内的记录时，会产生幻行。InnoDB 存储引擎通过多版本并发控制MVCC 解决幻读的问题。&lt;/p&gt; &lt;/li&gt;
 &lt;li&gt;&lt;p&gt;&lt;strong&gt;可串行化 SERIALIZABLE&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;该级别是最高的隔离级别，通过强制事务串行执行，避免了幻读的问题。可串行化会在读取的每一行数据上都加锁，可能导致大量的超时和锁争用的问题。实际应用中很少用到这个隔离级别，只有非常需要确保数据一致性且可以接受没有并发的情况下才考虑该级别。&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;MySQL 中的事务&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MySQL 提供了两种事务型的存储引擎：InnoDB 和 NDB Cluster。&lt;/p&gt; 
&lt;p&gt;MySQL 事务默认采用自动提交模式，如果不是显式地开始一个事务，则每个查询都将被当作一个事务执行提交操作。在当前连接中，可以通过设置 AUTOCOMMIT 变量来启用或禁用自动提交模式。&lt;/p&gt; 
&lt;p&gt;1 或 ON 表示启用，0 或 OFF表示禁用，当禁用自动提交时，所有的查询都是在一个事务中，直到显式地执行 COMMIT 或 ROLLBACK 后该事务才会结束，同时又开始了一个新事务。修改 AUTOCOMMIT 对非事务型表，例如 MyISAM 或内存表不会有任何影响，对这类表来说没有 COMMIT 或 ROLLBACK 的概念，也可以理解为一直处于启用自动提交的模式&lt;/p&gt; 
&lt;p&gt;有一些命令在执行之前会强制执行提交当前的活动事务，例如&lt;code&gt;ALTER TABLE&lt;/code&gt;和&lt;code&gt;LOCK TABLES&lt;/code&gt;等。&lt;/p&gt; 
&lt;p&gt;MySQL能够识别所有的 4个 ANSI 隔离级别，InnoDB 引擎也支持所有隔离级别。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P4：MVCC 多版本并发控制&lt;/h3&gt; 
&lt;p&gt;可以认为 MVCC 是行级锁的一个变种，但它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只锁定必要的行。&lt;/p&gt; 
&lt;p&gt;MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。也就是说不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。&lt;/p&gt; 
&lt;p&gt;不同的存储引擎的 MVCC 实现是不同的，典型的有乐观并发控制和悲观并发控制。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;InnoDB 的 MVCC 实现&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;InnoDB 的MVCC 通过在每行记录后面保存两个隐藏的列来实现，这两个列一个保存了行的创建时间，一个保存行的过期时间间。不过存储的不是实际的时间值而是系统版本号，每开始一个新的事务系统版本号都会自动递增，事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;REPEATABLE READ 级别下 MVCC 的具体实现&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;SELECT：InnoDB 会根据以下两个条件检查每行记录：&lt;/p&gt; 
 
&lt;p&gt;INSERT ：为新插入的每一行保存当前系统版本号作为行版本号。&lt;/p&gt; 
&lt;p&gt;DELETE：为删除的每一行保存当前系统版本号作为行删除标识。&lt;/p&gt; 
&lt;p&gt;UPDATE：为插入的每一行新记录保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。&lt;/p&gt; 
&lt;p&gt;保存这两个额外系统版本号使大多数读操作都可以不用加锁。这样设计使读数据操作简单且高效，并且能保证只会读取到符合标准的行。不足之处是每行记录都需要额外存储空间，需要做更多行检查工作以及一些额外维护工作。&lt;/p&gt; 
&lt;p&gt;MVCC 只能在 &lt;code&gt;READ COMMITTED&lt;/code&gt; 和 &lt;code&gt;REPEATABLE READ&lt;/code&gt; 两个隔离级别下工作，因为 &lt;code&gt;READ UNCOMMITTED&lt;/code&gt; 总是读取最新的数据行，而不是符合当前事务版本的数据行，而 &lt;code&gt;SERIALIZABLE&lt;/code&gt; 则会对所有读取的行都加锁。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P5：InnoDB 存储引擎&lt;/h3&gt; 
&lt;p&gt;InnoDB 是 MySQL 的默认事务型引擎，它被设计用来处理大量的短期事务。InnoDB 的性能和自动崩溃恢复特性，使得它在非事务型存储需求中也很流行，除非有特别原因否则应该优先考虑 InnoDB 引擎。&lt;/p&gt; 
&lt;p&gt;InnoDB 的数据存储在表空间中，表空间由一系列数据文件组成。MySQL4.1 后 InnoDB 可以将每个表的数据和索引放在单独的文件中。&lt;/p&gt; 
&lt;p&gt;InnoDB 采用 MVCC 来支持高并发，并且实现了四个标准的隔离级别。其默认级别是 &lt;code&gt;REPEATABLE READ&lt;/code&gt;，并且通过间隙锁策略防止幻读，间隙锁使 InnoDB 不仅仅锁定查询涉及的行，还会对索引中的间隙进行锁定防止幻行的插入。&lt;/p&gt; 
&lt;p&gt;InnoDB 表是基于聚簇索引建立的，InnoDB 的索引结构和其他存储引擎有很大不同，聚簇索引对主键查询有很高的性能，不过它的二级索引中必须包含主键列，所以如果主键很大的话其他所有索引都会很大，因此如果表上索引较多的话主键应当尽可能小。&lt;/p&gt; 
&lt;p&gt;InnoDB 的存储格式是平***立的，可以将数据和索引文件从一个平台复制到另一个平台。&lt;/p&gt; 
&lt;p&gt;InnoDB 内部做了很多优化，包括从磁盘读取数据时采用的可预测性预读，能够自动在内存中创建加速读操作的自适应哈希索引，以及能够加速插入操作的插入缓冲区等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;选择合适的存储引擎&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MySQL5.5 将 InnoDB 作为默认存储引擎，除非需要用到某些 InnoDB 不具备的特性，并且没有其他方法可以代替，否则都应该优先选用InnoDB。&lt;/p&gt; 
&lt;p&gt;如果应用需要事务支持，那么 InnoDB 是目前最稳定并且经过验证的选择。如果不需要事务并且主要是 SELECT 和 INSERT 操作，那么MyISAM 是不错的选择。相对而言，MyISAM 崩溃后发生损坏的概率要比 InnoDB 大很多而且恢复速度也要慢，因此即使不需要事务支持，也可以选择InnoDB。&lt;/p&gt; 
&lt;p&gt;如果可以定期地关闭服务器来执行备份，那么备份的因素可以忽略。反之如果需要在线热备份，那么 InnoDB 就是基本的要求。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P6：MyISAM 存储引擎&lt;/h3&gt; 
&lt;p&gt;在 MySQL5.1及之前，MyISAM 是默认的存储引擎，MyISAM 提供了大量的特性，包括全文索引、压缩、空间函数等，但不支持事务和行锁，最大的缺陷就是崩溃后无法安全恢复。对于只读的数据或者表比较小、可以忍受修复操作的情况仍然可以使用 MyISAM。&lt;/p&gt; 
&lt;p&gt;MyISAM 将表存储在数据文件和索引文件中，分别以 &lt;code&gt;.MYD&lt;/code&gt; 和 &lt;code&gt;.MYI&lt;/code&gt; 作为扩展名。MyISAM 表可以包含动态或者静态行，MySQL 会根据表的定义决定行格式。MyISAM 表可以存储的行记录数一般受限于可用磁盘空间或者操作系统中单个文件的最大尺寸。&lt;/p&gt; 
&lt;p&gt;MyISAM 对整张表进行加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但是在表有读取查询的同时，也支持并发往表中插入新的记录。&lt;/p&gt; 
&lt;p&gt;对于MyISAM 表，MySQL 可以手动或自动执行检查和修复操作，这里的修复和事务恢复以及崩溃恢复的概念不同。执行表的修复可能导致一些数据丢失，而且修复操作很慢。&lt;/p&gt; 
&lt;p&gt;对于 MyISAM 表，即使是 BLOB 和 TEXT 等长字段，也可以基于其前 500 个字符创建索引。MyISAM 也支持全文索引，这是一种基于分词创建的索引，可以支持复杂的查询。&lt;/p&gt; 
&lt;p&gt;创建 MyISAM 表时如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时不会立刻将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理缓冲区或关闭表的时候才会将对应的索引库写入磁盘。这种方式可以极大提升写性能，但在数据库或主机崩溃时会造成索引损坏，需要执行修复。延迟更新索引键的特性可以在全局设置也可以单个表设置。&lt;/p&gt; 
&lt;p&gt;MyISAM 设计简单，数据以紧密格式存储，所以在某些场景下性能很好。MyISAM 最典型的性能问题还是表锁问题，如果所有的查询长期处于 Locked 状态，那么原因毫无疑问就是表锁。&lt;/p&gt; 
&lt;h3&gt;P7：Memory 存储引擎&lt;/h3&gt; 
&lt;p&gt;如果需要快速访问数据，并且这些数据不会被修改，重启以后丢失也没有关系，那么使用 Memory 表是非常有用的。Memory 表至少要比 MyISAM 表快一个数量级，因为所有的数据都保存在内存中，不需要进行磁盘 IO，Memory 表的结构在重启以后还会保留，但数据会丢失。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;Memory 表适合的场景：查找或者映射表、缓存周期性聚合数据的结果、保存&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90&quot; target=&quot;_blank&quot;&gt;数据分析&lt;/a&gt;中产生的中间数据。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;Memory 表支持哈希索引，因此查找速度极快。虽然速度很快但还是无法取代传统的基于磁盘的表，Memory 表使用表级锁，因此并发写入的性能较低。它不支持 BLOB 和 TEXT 类型的列，并且每行的长度是固定的，所以即使指定了 VARCHAR 列，实际存储时也会转换成CHAR，这可能导致部分内存的浪费。&lt;/p&gt; 
&lt;p&gt;如果 MySQL 在执行查询的过程中需要使用临时表来保持中间结果，内部使用的临时表就是 Memory 表。如果中间结果太大超出了Memory 表的限制，或者含有 BLOB 或 TEXT 字段，临时表会转换成 MyISAM 表。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P8：数据类型&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;整数类型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如果存储整数可以使用这几种整数类型：TINYINT、SMALLINT、MEDIUMINT、INT，BIGINT，它们分别使用8、16、24、32、64 位存储空间。&lt;/p&gt; 
&lt;p&gt;整数类型有可选的 UNSIGNED 属性，表示不允许负值，可以使整数的上限提高一倍。有符号和无符号类型使用相同的存储空间并具有相同的性能，可以根据实际情况选择合适的类型。&lt;/p&gt; 
&lt;p&gt;MySQL 可以为整数类型指定宽度，例如 INT(11)，这对大多数应用没有意义，不会限制值的范围，只是规定了 MySQL 的交互工具显示字符的个数，对于存储和计算来说 INT(1) 和 INT(11) 是相同的。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;实数类型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;实数是带有小数部分的数字，但它们不只是为了存储小数，也可以使用 DECIMAL 存储比 BIGINT 还大的整数。MySQL既支持精确类型，也支持不精确类型。&lt;/p&gt; 
&lt;p&gt;FLOAT 和 DOUBLE 支持使用标准的浮点运算进行近似运算，DECIMAL 用于存储精确的小数。&lt;/p&gt; 
&lt;p&gt;浮点类型在存储同样范围的值时，通常比 DECIMAL 使用更少的空间。FLOAT 使用 4 字节存储，DOUBLE 占用8字节，MySQL 内部使用DOUBLE 作为内部浮点计算的类型。&lt;/p&gt; 
&lt;p&gt;因为需要额外空间和计算开销，所以应当尽量只在对小数进行精确计算时才使用 DECIMAL。在数据量较大时可以考虑 BIGINT 代替DECIMAL，将需要存储的货币单位根据小数的位数乘以相应的倍数即可。假设要存储的数据精确到万分之一分，则可以把所有金额乘以一百万将结果存储在 BIGINT 中，这样可以同时避免浮点存储计算不精确和 DECIMAL 精确计算代价高的问题。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;VARCHAR&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;VARCHAR 用于存储可变字符串，是最常见的字符串数据类型。它比定长字符串更节省空间，因为它仅使用必要的空间。VARCHAR 需要 1或 2 个额外字节记录字符串长度，如果列的最大长度不大于 255 字节则只需要1 字节。VARCHAR 不会删除末尾空格。&lt;/p&gt; 
&lt;p&gt;VARCHAR 节省了存储空间，但由于行是变长的，在 UPDATE 时可能使行变得比原来更长，这就导致需要做额外的工作。如果一个行占用的空间增长并且页内没有更多的空间可以存储，这种情况下不同存储引擎处理不同，InnoDB 会分裂页而 MyISAM 会将行拆分成不同片。&lt;/p&gt; 
&lt;p&gt;适用场景：字符串列的最大长度比平均长度大很多、列的更新很少、使用了 UTF8 这种复杂字符集，每个字符都使用不同的字节数存储。&lt;/p&gt; 
&lt;p&gt;InnoDB 可以把过长的 VARCHAR 存储为 BLOB。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CHAR&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;CHAR 是定长的，根据定义的字符串长度分配足够的空间。CHAR 会删除末尾空格。&lt;/p&gt; 
&lt;p&gt;CHAR 适合存储很短的字符串，或所有值都接近同一个长度，例如存储密码的 MD5 值。对于经常变更的数据，CHAR 也比 VARCHAR更好，因为定长的 CHAR 不容易产生碎片。对于非常短的列，CHAR 在存储空间上也更有效率，例如用 CHAR 来存储只有 Y 和 N 的值只需要一个字节，但是 VARCHAR 需要两个字节，因为还有一个记录长度的额外字节。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;BLOB 和 TEXT 类型&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;BLOB 和TEXT 都是为了存储大数据而设计的字符串数据类型，分别采用二进制和字符串方式存储。MySQL会把每个 BLOB 和 TEXT 值当作一个独立的对象处理，存储引擎在存储时通常会做特殊处理。当值太大时，InnoDB 会使用专门的外部存储区来进行存储。BLOB 和TEXT 仅有的不同是 BLOB 存储的是二进制数据，没有&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;规则或字符集，而 TEXT 有字符集和&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;规则。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;MySQL 对 BLOB 和TEXT 列进行&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;与其他类型不同：它只对每个列最前 &lt;/span&gt;&lt;code&gt;max_sort_length&lt;/code&gt;&lt;span&gt; 字节而不是整个字符串做&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;，如果只需要&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;前面一小部分字符，则可以减小 &lt;/span&gt;&lt;code&gt;max_sort_length&lt;/code&gt;&lt;span&gt; 的配置。MySQL 不能将 BLOB 和 TEXT 列全部长度的字符串进行索引，也不能使用这些索引消除&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;DATETIME&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;这个类型能保存大范围的值，从 1001 年到 9999 年，精度为秒。它把日期和时间封装到了一个整数中，与时区无关，使用 8 字节的存储空间。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TIMESTAMP&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;它和 UNIX 时间戳相同。TIMESTAMP 只使用 4 字节的存储空间，因此它的范围比DATETIME 小得多，只能表示1970年到2038年，并且依赖于时区。通常应该选择 TIMESTAMP，因为它比 DATETIME 空间效率更高。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P9：索引的分类&lt;/h3&gt; 
&lt;p&gt;索引在也叫做键，是存储引擎用于快速找到记录的一种数据结构。索引对于良好的性能很关键，尤其是当表中数据量越来越大时，索引对性能的影响愈发重要。在数据量较小且负载较低时，不恰当的索引对性能的影响可能还不明显，但数据量逐渐增大时，性能会急剧下降。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;索引大大减少了服务器需要扫描的数据量、可以帮助服务器避免&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;和临时表、可以将随机 IO 变成顺序 IO。但索引并不总是最好的工具，对于非常小的表，大部分情况下会采用全表扫描。对于中到大型的表，索引就非常有效。但对于特大型的表，建立和使用索引的代价也随之增长，这种情况下应该使用分区技术。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;在MySQL中，首先在索引中找到对应的值，然后根据匹配的索引记录找到对应的数据行。索引可以包括一个或多个列的值，如果索引包含多个列，那么列的顺序也十分重要，因为 MySQL 只能高效地使用索引的最左前缀列。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;B-Tree 索引&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;大多数 MySQL 引擎都支持这种索引，使用术语 B-Tree 是因为 MySQL 在 CREATE TABLE 和其他语句中也使用该关键字。不过底层的存储引擎可能使用不同的存储结构，例如 NDB 集群实际使用 T-Tree，而 InnoDB 则使用 B+Tree。&lt;/p&gt; 
&lt;p&gt;存储引擎以不同方式使用 B-Tree 索引，性能也不同。例如 MyISAM 使用前缀压缩技术使得索引更小，但 InnoDB 则按照原数据格式进行存储。再例如 MyISAM 索引通过数据的物理位置引用被索引的行，而 InnoDB 则根据主键引用被索引的行。&lt;/p&gt; 
&lt;p&gt;B-Tree 通常意味着所有的值都是按顺序存储的，并且每个叶子页到根的距离相同。B-Tree 索引能够加快访问数据的速度，因为存储引擎不再需要进行全表扫描来获取需要的数据，取而代之的是从索引的根节点开始进行搜索。根节点的槽中存放了指向子节点的指针，存储引擎根据这些指针向下层查找。通过比较节点页的值和要查找的值可以找到合适的指针进入下层子节点，这些指针实际上定义了子节点页中值的上限和下限。最终存储引擎要么找到对应的值，要么该记录不存在。叶子节点的指针指向的是被索引的数据，而不是其他的节点页。&lt;/p&gt; 
&lt;p&gt;B-Tree索引适用于全键值、键值范围或键前缀查找，其中键前缀查找只适用于最左前缀查找。索引对如下类型的查询有效：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;全值匹配：全值匹配指的是和索引中的所有列进行匹配。 &lt;/li&gt;
 &lt;li&gt;匹配最左前缀：只使用索引的第一列。 &lt;/li&gt;
 &lt;li&gt;匹配列前缀：只匹配某一列的值的开头部分。 &lt;/li&gt;
 &lt;li&gt;匹配范围值：查找某两个值之间的范围。 &lt;/li&gt;
 &lt;li&gt;精确匹配某一列并范围匹配另一列：有一列全匹配而另一列范围匹配。 &lt;/li&gt;
 &lt;li&gt;只访问索引的查询：B-Tree 通常可以支持只访问索引的查询，即查询只需要访问索引而无需访问数据行。 &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;&lt;span&gt;因为索引树中的节点有序，所以除了按值查找之外索引还可以用于查询中的 ORDER BY 操作。一般如果 B-Tree 可以按照某种方式查找到值，那么也可以按照这种方式&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;B-Tree索引的限制：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;如果不是按照索引的最左列开始查找，则无法使用索引。 &lt;/li&gt;
 &lt;li&gt;不能跳过索引中的列，例如索引为 (id,name,sex)，不能只使用 id 和 sex 而跳过 name。 &lt;/li&gt;
 &lt;li&gt;如果查询中有某个列的范围查询，则其右边的所有列都无法使用索引。 &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;哈希索引&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;哈希索引基于&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%93%88%E5%B8%8C%E8%A1%A8&quot; target=&quot;_blank&quot;&gt;哈希表&lt;/a&gt;实现，只有精确匹配索引所有列的查询才有效。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码，哈希码是一个较小的值，并且不同键值的行计算出的哈希码也不一样。哈希索引将所有的哈希码存储在索引中，同时在&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%93%88%E5%B8%8C%E8%A1%A8&quot; target=&quot;_blank&quot;&gt;哈希表&lt;/a&gt;中保存指向每个数据行的指针。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;只有 Memory 引擎显式支持哈希索引，这也是 Memory 引擎的默认索引类型。&lt;/p&gt; 
&lt;p&gt;因为索引自身只需存储对应的哈希值，所以索引的结构十分紧凑，这让哈希索引的速度非常快，但它也有一些限制：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;哈希索引只包含哈希值和行指针而不存储字段值，所以不能使用索引中的值来避免读取行。 &lt;/li&gt;
 &lt;li&gt;&lt;span&gt;哈希索引数据并不是按照索引值顺序存储的，因此无法用于&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;。 &lt;/span&gt;&lt;/li&gt;
 &lt;li&gt;哈希索引不支持部分索引列匹配查找，因为哈希索引始终是使用索引列的全部内容来计算哈希值的。例如在数据列(a,b)上建立哈希索引，如果查询的列只有a就无法使用该索引。 &lt;/li&gt;
 &lt;li&gt;哈希索引只支持等值比较查询，不支持任何范围查询。 &lt;/li&gt;
 &lt;li&gt;&lt;span&gt;访问哈希索引的数据非常快，除非有很多哈希冲突。当出现哈希冲突时，存储引擎必须遍历&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%93%BE%E8%A1%A8&quot; target=&quot;_blank&quot;&gt;链表&lt;/a&gt;中所有的行指针，逐行进行比较直到找到所有符合条件的行。 &lt;/span&gt;&lt;/li&gt;
 &lt;li&gt;如果哈希冲突很高的话，索引维护的代价也会很高。 &lt;/li&gt;
&lt;/ul&gt; 
&lt;p&gt;自适应哈希索引是 InnoDB 引擎的一个特殊功能，当它注意到某些索引值被使用的非常频繁时，会在内存中基于 B-Tree 索引之上再创键一个哈希索引，这样就让 B-Tree 索引也具有哈希索引的一些优点，比如快速哈希查找。这是一个完全自动的内部行为，用户无法控制或配置，但如果有必要可以关闭该功能。&lt;/p&gt; 
&lt;p&gt;如果存储引擎不支持哈希索引，可以创建自定义哈希索引，在 B-Tree基础 上创建一个伪哈希索引，它使用哈希值而不是键本身进行索引查找，需要在查询的 WHERE 子句中手动指定哈希函数。当数据表非常大时，CRC32 会出现大量的哈希冲突，可以考虑自己实现 64 位哈希函数，或者使用 MD5 函数返回值的一部分作为自定义哈希函数。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;空间索引&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MyISAM 表支持空间索引，可以用作地理数据存储。和 B-Tree 索引不同，这类索引无需前缀查询。空间索引会从所有维度来索引数据，查询时可以有效地使用任意维度来组合查询。必须使用 MySQL 的 GIS 即地理信息系统的相关函数来维护数据，但 MySQL 对 GIS 的支持并不完善，因此大部分人都不会使用这个特性。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;全文索引&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通过数值比较、范围过滤等就可以完成绝大多数需要的查询，但如果希望通过关键字的匹配进行查询过滤，那么就需要基于相似度的查询，而不是精确的数值比较，全文索引就是为这种场景设计的。全文索引有自己独特的语法，没有索引也可以工作，如果有索引效率会更高。&lt;/p&gt; 
&lt;p&gt;全文索引可以支持各种字符内容的搜索，包括 CHAR、VARCHAR 和 TEXT 类型，也支持自然语言搜索和布尔搜索。在 MySQL 中全文索引有很多限制，例如表锁对性能的影响、数据文件的崩溃恢复等，这使得 MyISAM 的全文索引对很多应用场景并不合适。MyISAM 的全文索引作用对象是一个&quot;全文集合&quot;，可能是某个数据表的一列，也可能是多个列。具体的对某一条记录，MySQL 会将需要索引的列全部拼接成一个字符串然后进行索引。&lt;/p&gt; 
&lt;p&gt;MyISAM 的全文索引是一种特殊的 B-Tree 索引，一共有两层。第一层是所有关键字，然后对于每一个关键字的第二层，包含的是一组相关的&quot;文档指针&quot;。全文索引不会索引文档对象中的所有词语，它会根据规则过滤掉一些词语，例如停用词列表中的词都不会被索引。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;聚簇索引&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。InnoDB 的聚簇索引实际上在同一个结构中保存了 B-Tree 索引和数据行。当表有聚餐索引时，它的行数据实际上存放在索引的叶子页中，因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。&lt;/p&gt; 
&lt;p&gt;优点：① 可以把相关数据保存在一起，例如实现电子邮箱时可以根据用户 ID 聚集数据，这样只需要从磁盘读取少数数据页就能获取某个用户的全部邮件，如果没有使用聚簇索引，每封邮件可能都导致一次磁盘 IO。② 数据访问更快，聚簇索引将索引和数据保存在同一个 B-Tree 中，因此获取数据比非聚簇索引要更快。③ 使用覆盖索引扫描的查询可以直接使用页节点中的主键值。&lt;/p&gt; 
&lt;p&gt;缺点：① 聚簇索引最大限度提高了 IO 密集型应用的性能，如果数据全部在内存中将会失去优势。② 插入速度验证依赖于插入顺序，按照主键的顺序插入是加载数据到 InnoDB 引擎最快的方式。③ 更新聚簇索引列的代价很高，因为会强制每个被更新的行移动到新位置。④ 基于聚簇索引的表插入新行或主键被更新导致行移动时，可能导致页分裂，表会占用更多磁盘空间。④ 当行稀疏或由于页分裂导致数据存储不连续时，全表扫描可能很慢。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;覆盖索引&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;覆盖索引指一个索引包含或覆盖了所有需要查询的字段的值，不再需要根据索引回表查询数据。覆盖索引必须要存储索引列的值，因此 MySQL 只能使用 B-Tree 索引做覆盖索引。&lt;/p&gt; 
&lt;p&gt;优点：① 索引条目通常远小于数据行大小，可以极大减少数据访问量。② 因为索引按照列值顺序存储，所以对于 IO 密集型防伪查询回避随机从磁盘读取每一行数据的 IO 少得多。③ 由于 InnoDB 使用聚簇索引，覆盖索引对 InnoDB 很有帮助。InnoDB 的二级索引在叶子节点保存了行的主键值，如果二级主键能覆盖查询那么可以避免对主键索引的二次查询。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;&lt;font&gt;P10：索引使用原则&lt;/font&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;建立索引&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;对查询频次较高，且数据量比较大的表建立索引。索引字段的选择，最佳候选列应当从 WHERE 子句的条件中提取，如果 WHERE 子句中的组合比较多，那么应当挑选最常用、过滤效果最好的列的组合。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;使用前缀索引&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;索引列开始的部分字符，索引创建后也是使用硬盘来存储的，因此短索引可以提升索引访问的 IO 效率。对于 BLOB、TEXT 或很长的 VARCHAR 列必须使用前缀索引，MySQL 不允许索引这些列的完整长度。前缀索引是一种能使索引更小更快的有效方法，但缺点是 MySQL 无法使用前缀索引做 ORDER BY 和 GROUP BY，也无法使用前缀索引做覆盖扫描。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;选择合适的索引顺序&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;当不需要考虑&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;和分组时，将选择性最高的列放在前面。索引的选择性是指不重复的索引值和数据表的记录总数之比，索引的选择性越高则查询效率越高，唯一索引的选择性是 1，因此也可以使用唯一索引提升查询效率。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;删除无用索引&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MySQL 允许在相同列上创建多个索引，重复的索引需要单独维护，并且优化器在优化查询时也需要逐个考虑，这会影响性能。重复索引是指在相同的列上按照相同的顺序创建的相同类型的索引，应该避免创建重复索引。如果创建了索引 (A,B) 再创建索引 (A) 就是冗余索引，因为这只是前一个索引的前缀索引，对于 B-Tree 索引来说是冗余的。解决重复索引和冗余索引的方法就是删除这些索引。除了重复索引和冗余索引，可能还会有一些服务器永远不用的索引，也应该考虑删除。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;减少碎片&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;B-Tree 索引可能会碎片化，碎片化的索引可能会以很差或无序的方式存储在磁盘上，这会降低查询的效率。表的数据存储也可能碎片化，包括行碎片、行间碎片、剩余空间碎片，对于 MyISAM 这三类碎片化都有可能发生，对于 InnoDB 不会出现短小的行碎片，它会移动短小的行重写到一个片段中。可以通过执行 OPTIMIZE TABLE 或者导出再导入的方式重新整理数据，对于 MyISAM 可以通过&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;重建索引消除碎片。InnoDB 可以通过先删除再重新创建索引的方式消除索引碎片。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;索引失效情况&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如果索引列出现了隐式类型转换，则 MySQL 不会使用索引。常见的情况是在 SQL 的 WHERE 条件中字段类型为字符串，其值为数值，如果没有加引号那么 MySQL 不会使用索引。&lt;/p&gt; 
&lt;p&gt;如果 WHERE 条件中含有 OR，除非 OR 前使用了索引列而 OR 之后是非索引列，索引会失效。&lt;/p&gt; 
&lt;p&gt;MySQL 不能在索引中执行 LIKE 操作，这是底层存储引擎 API 的限制，最左匹配的 LIKE 比较会被转换为简单的比较操作，但如果是以通配符开头的 LIKE 查询，存储引擎就无法做笔记。这种情况下 MySQL 服务器只能提取数据行的值而不是索引值来做比较。&lt;/p&gt; 
&lt;p&gt;如果查询中的列不是独立的，则 MySQL 不会使用索引。独立的列是指索引列不能是表达式的一部分，也不能是函数的参数。&lt;/p&gt; 
&lt;p&gt;对于多个范围条件查询，MySQL 无法使用第一个范围列后面的其他索引列，对于多个等值查询则没有这种限制。&lt;/p&gt; 
&lt;p&gt;如果 MySQL 判断全表扫描比使用索引查询更快，则不会使用索引。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P11：优化数据类型&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;更小的通常更好&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;一般情况下尽量使用可以正确存储数据的最小数据类型，更小的数据类型通常也更快，因为它们占用更少的磁盘、内存和 CPU 缓存。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;尽可能简单&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;简单数据类型的操作通常需要更少的 CPU 周期，例如整数比字符操作代价更低，因为字符集和校对规则使字符相比整形更复杂。应该使用 MySQL 的内建类型 date、time 和 datetime 而不是字符串来存储日期和时间，另一点是应该使用整形存储 IP 地址。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;尽量避免 NULL&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;通常情况下最好指定列为 NOT NULL，除非需要存储 NULL值。因为如果查询中包含可为 NULL 的列对 MySQL 来说更难优化，可为 NULL 的列使索引、索引统计和值比较都更复杂，并且会使用更多存储空间。当可为 NULL 的列被索引时，每个索引记录需要一个额外字节，在MyISAM 中还可能导致固定大小的索引变成可变大小的索引。&lt;/p&gt; 
&lt;p&gt;通常把可为 NULL 的列设置为 NOT NULL 带来的性能提升较小，因此调优时没必要首先查找并修改这种情况。但如果计划在列上建索引，就应该尽量避免设计成可为 NULL 的列。&lt;/p&gt; 
&lt;p&gt;在为列选择数据类型时，第一步需要确定合适的大类型：数字、字符串、时间等。下一步是选择具体类型，很多 MySQL 数据类型可以存储相同类型的数据，只是存储的长度和范围不一样，允许的精度不同或需要的物理空间不同。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P12：优化查询概述&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;优化数据访问&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;如果把查询看作一个任务，那么它由一系列子任务组成，每个子任务都会消耗一定时间。如果要优化查询，要么消除一些子任务，要么减少子任务的执行次数。查询性能低下最基本的原因是访问的数据太多，大部分性能低下的查询都可以通过减少访问的数据量进行优化。可以通过以下两个步骤分析。&lt;/p&gt; 
&lt;p&gt;是否向数据库请求了不需要的数据：有些查询会请求超过实际需要的数据，然后这些多余的数据会被应用程序丢弃，这会给 MySQL 服务器造成额外负担并增加网络开销，另外也会消耗应用服务器的 CPU 和内存资源。例如多表关联时返回全部列，取出全部列会让优化器无法完成索引覆盖扫描这类优化，还会为服务器带来额外的 IO、内存和 CPU 的消耗，因此使用 SELECT * 时需要仔细考虑是否真的需要返回全部列。再例如总是重复查询相同的数据，比较好的解决方案是初次查询时将数据缓存起来，需要的时候从缓存中取出。&lt;/p&gt; 
&lt;p&gt;MySQL 是否在扫描额外的记录：在确定查询只返回需要的数据后，应该看看查询为了返回结果是否扫描了过多的数据，最简单的三个衡量指标时响应时间、扫描的行数和返回的行数。如果发现查询需要扫描大量数据但只返回少数的行，可以使用以下手动优化：① 使用覆盖索引扫描，把所有需要用的列都放到索引中，这样存储引擎无需回表查询对应行就可以返回结果。② 改变库表结构。 ③ 重写这个复杂的查询，让 MySQL 优化器能够以更优化的方式执行这个查询。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;重构查询方式&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在优化有问题的查询时，目标应该是找到一个更优的方法获取实际需要的结果，而不一定总是需要从 MySQL 获取一模一样的结果集。&lt;/p&gt; 
&lt;p&gt;切分查询：有时候对于一个大查询可以将其切分成小查询，每个查询功能完全一样，只完成一小部分，每次只返回一小部分查询结果。例如删除旧数据，定期清除大量数据时，如果用一个大的语句一次性完成的话可能需要一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。将一个大的 DELETE 语句切分成多个较小的查询可以尽可能小地影响 MySQL 的性能，同时还可以减少MySQL 复制的延迟。&lt;/p&gt; 
&lt;p&gt;分解关联查询：很多高性能应用都会对关联查询进行分解，可以对每一个表进行单表查询，然后将结果在应用程序中进行关联。分解关联查询可以让缓存的效率更高、减少锁的竞争、提升查询效率、还可以减少冗余记录的查询。&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P13：查询执行流程&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;简单来说分为五步：① &lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;发送一条查询给服务器。② 服务器先检查查询缓存，如果命中了缓存则立刻返回存储在缓存中的结果，否则进入下一阶段。③ 服务器端进行 SQL 解析、预处理，再由优化器生成对应的执行计划。④ MySQL 根据优化器生成的执行计划，调用存储引擎的 API 来执行查询。⑤ 将结果返回给&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;。 &lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查询缓存&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;在解析一个查询语句之前，如果查询缓存是打开的，那么 MySQL 会优先检查这个查询是否命中查询缓存中的数据。这个检查是通过一个对大小写敏感的哈希查找实现的。查询和缓存中的查询即使只有一个字节不同，也不会匹配缓存结果，这种情况下会进行下一个阶段的处理。如果当前的查询恰好命中了查询缓存，那么在返回查询结果之前 MySQL 会检查一次用户权限。如果权限没有问题，MySQL 会跳过其他阶段，直接从缓冲中拿到结果并返回给&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;，这种情况下查询不会被解析，不用生成执行计划，不会被执行。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查询优化处理&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;该阶段包括多个子阶段：解析 SQL、预处理、优化 SQL 执行计划。首先 MySQL 通过关键字将 SQL 语句进行解析，并生成一颗对应的解析树，MySQL 解析器将使用 MySQL 语法规则验证和解析查询。例如它将验证是否使用了错误的关键字，或者使用关键字的顺序是否正确等。预处理器则根据一些 MySQL 规则进一步检查解析树是否合法，例如检查数据表和数据列是否存在，还会解析名字和别名看它们是否有歧义。下一步预处理器会验证权限，这一步通常很快，除非服务器上有非常多的权限配置。&lt;/p&gt; 
&lt;p&gt;语法树被认为合法后，查询优化器将其转成执行计划。一条查询可以有多种查询方式，最后都返回相同的结果，优化器的作用就是找到这其中最好的执行计划。MySQL 使用基于成本的优化器，它将尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。优化策略可以简单分为两种，一种是静态优化，可以直接对解析树分析并完成优化，不依赖于特别的数值，可以认为是一种编译时优化。另一种是动态优化，和查询的上下文有关，每次查询时都需要重新评估。&lt;/p&gt; 
&lt;p&gt;MySQL 可以处理的优化类型包括：重新定义表的关联顺序、将外连接转化成内连接、使用等价变换规则、优化 COUNT() 和 MIN() 以及 MAX() 函数、预估并转为常数表达式、覆盖索引扫描、子查询优化等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;查询执行引擎&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在解析和优化阶段，MySQL 将生成查询对应的执行计划，MySQL 的查询执行引擎则根据这个计划来完成整个查询。执行计划是一个数据结构，而不是其他关系型数据库那样会生成对应的字节码。查询执行阶段并不复杂，MySQL 只是简单的根据执行计划给出的指令逐步执行，再根据执行计划执行的过程中，有大量操作需要通过调用存储引擎实现的接口来完成。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;span&gt;返回结果给&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;查询执行的最后一个阶段是将结果返回给&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;，即使查询不需要返回结果集，MySQL 仍然会返回这个查询的一些信息，如该查询影响到的行数。如果查询可以被缓存，那么 MySQL 会在这个阶段将结果存放到查询缓冲中。MySQL 将结果集返回&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;是一个增量、逐步返回的过程，这样做的好处是服务器无需存储太多的结果，减少内存消耗，也可以让&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;第一时间获得响应结果。结果集中的每一行给都会以一个满足 MySQL &lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;/服务器通信协议的包发送，再通过 TCP 协议进行传输，在 TCP 传输过程中可能对包进行缓存然后批量传输。&lt;/span&gt;&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;&lt;font&gt;P14：优化 SQL&lt;/font&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;优化 COUNT 查询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;COUNT 是一个特殊的函数，它可以统计某个列值的数量，在统计列值时要求列值是非空的，不会统计 NULL 值。如果在 COUNT 中指定了列或列的表达式，则统计的就是这个表达式有值的结果数，而不是 NULL。&lt;/p&gt; 
&lt;p&gt;COUNT 的另一个作用是统计结果集的行数，当 MySQL 确定括号内的表达式不可能为 NULL 时，实际上就是在统计行数。当使用 COUNT(&lt;em&gt;) 时，\&lt;/em&gt; 不会扩展成所有列，它会忽略所有的列而直接统计所有的行数。&lt;/p&gt; 
&lt;p&gt;某些业务场景并不要求完全精确的 COUNT 值，此时可以使用近似值来代替，EXPLAIN 出来的优化器估算的行数就是一个不错的近似值，因为执行 EXPLAIN 并不需要真正地执行查询。&lt;/p&gt; 
&lt;p&gt;通常来说 COUNT 都需要扫描大量的行才能获取精确的结果，因此很难优化。在 MySQL 层还能做的就只有覆盖扫描了，如果还不够就需要修改应用的架构，可以增加汇总表或者外部缓存系统。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优化关联查询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;确保 ON 或 USING 子句中的列上有索引，在创建索引时就要考虑到关联的顺序。&lt;/p&gt; 
&lt;p&gt;确保任何 GROUP BY 和 ORDER BY 的表达式只涉及到一个表中的列，这样 MySQL 才有可能使用索引来优化这个过程。&lt;/p&gt; 
&lt;p&gt;在 MySQL 5.5 及以下版本尽量避免子查询，可以用关联查询代替，因为执行器会先执行外部的 SQL 再执行内部的 SQL。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优化 GROUP BY&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;如果没有通过 ORDER BY 子句显式指定要&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;的列，当查询使用 GROUP BY 子句的时候，结果***自动按照分组的字段进行&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;，如果不关心结果集的顺序，可以使用 ORDER BY NULL 禁止&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优化 LIMIT 分页&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在偏移量非常大的时候，需要查询很多条数据再舍弃，这样的代价非常高。要优化这种查询，要么是在页面中限制分页的数量，要么是优化大偏移量的性能。最简单的办法是尽可能地使用覆盖索引扫描，而不是查询所有的列，然后根据需要做一次关联操作再返回所需的列。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;还有一种方法是从上一次取数据的位置开始扫描，这样就可以避免使用 OFFSET。其他优化方法还包括使用预先计算的汇总表，或者关联到一个冗余表，冗余表只包含主键列和需要做&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;的数据列。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优化 UNION 查询&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;MySQL 通过创建并填充临时表的方式来执行 UNION 查询，除非确实需要服务器消除重复的行，否则一定要使用 UNION ALL，如果没有 ALL 关键字，MySQL 会给临时表加上 DISTINCT 选项，这会导致对整个临时表的数据做唯一性检查，这样做的代价非常高。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;使用用户自定义变量&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在查询中混合使用过程化和关系化逻辑的时候，自定义变量可能会非常有用。用户自定义变量是一个用来存储内容的临时容器，在连接 MySQL 的整个过程中都存在，可以在任何可以使用表达式的地方使用自定义变量。例如可以使用变量来避免重复查询刚刚更新过的数据、统计更新和插入的数量等。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;优化 INSERT&lt;/strong&gt; &lt;/p&gt; 
&lt;p&gt;&lt;span&gt;需要对一张表插入很多行数据时，应该尽量使用一次性插入多个值的 INSERT 语句，这种方式将缩减&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;与数据库之间的连接、关闭等消耗，效率比多条插入单个值的 INSERT 语句高。也可以关闭事务的自动提交，在插入完数据后提交。当插入的数据是按主键的顺序插入时，效率更高。&lt;/span&gt;&lt;/p&gt; 
&lt;hr/&gt; 
&lt;h3&gt;P15：复制&lt;/h3&gt; 
&lt;p&gt;复制解决的基本问题是让一台服务器的数据与其他服务器保持同步，一台主库的数据可以同步到多台备库上，备库本身也可以被配置成另外一台服务器的主库。主库和备库之间可以有多种不同的组合方式。&lt;/p&gt; 
&lt;p&gt;MySQL 支持两种复制方式：基于行的复制和基于语句的复制，基于语句的复制也称为逻辑复制，从 MySQL 3.23 版本就已存在，基于行的复制方式在 5.1 版本才被加进来。这两种方式都是通过在主库上记录二进制日志、在备库重放日志的方式来实现异步的数据复制。因此同一时刻备库的数据可能与主库存在不一致，并且无法包装主备之间的延迟。&lt;/p&gt; 
&lt;p&gt;MySQL 复制大部分是向后兼容的，新版本的服务器可以作为老版本服务器的备库，但是老版本不能作为新版本服务器的备库，因为它可能无法解析新版本所用的新特性或语法，另外所使用的二进制文件格式也可能不同。&lt;/p&gt; 
&lt;p&gt;复制解决的问题：数据分布、负载均衡、备份、高可用性和故障切换、MySQL 升级测试。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;复制步骤&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;概述：① 在主库上把数据更改记录到二进制日志中。② 备库将主库的日志复制到自己的中继日志中。 ③ 备库读取中继日志中的事件，将其重放到备库数据之上。&lt;/p&gt; 
&lt;p&gt;第一步是在主库上记录二进制日志，每次准备提交事务完成数据更新前，主库将数据更新的事件记录到二进制日志中。MySQL 会按事务提交的顺序而非每条语句的执行顺序来记录二进制日志，在记录二进制日志后，主库会告诉存储引擎可以提交事务了。&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;下一步，备库将主库的二进制日志复制到其本地的中继日志中。备库首先会启动一个工作的 IO 线程，IO 线程跟主库建立一个普通的&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AE%A2%E6%88%B7%E7%AB%AF&quot; target=&quot;_blank&quot;&gt;客户端&lt;/a&gt;连接，然后在主库上启动一个特殊的二进制转储线程，这个线程会读取主库上二进制日志中的事件。它不会对事件进行轮询。如果该线程追赶上了主库将进入睡眠状态，直到主库发送信号量通知其有新的事件产生时才会被唤醒，备库 IO 线程会将接收到的事件记录到中继日志中。&lt;/span&gt;&lt;/p&gt; 
&lt;p&gt;备库的 SQL 线程执行最后一步，该线程从中继日志中读取事件并在备库执行，从而实现备库数据的更新。当 SQL 线程追赶上 IO 线程时，中继日志通常已经在系统缓存中，所以中继日志的开销很低。SQL 线程执行的时间也可以通过配置选项来决定是否写入其自己的二进制日志中。&lt;/p&gt; 
&lt;p&gt;这种复制架构实现了获取事件和重放事件的解耦，允许这两个过程异步进行，也就是说 IO 线程能够独立于 SQL 线程工作。但这种架构也限制了复制的过程，在主库上并发允许的查询在备库只能串行化执行，因为只有一个 SQL 线程来重放中继日志中的事件。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>