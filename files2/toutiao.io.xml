<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>0ce40fc8ffb2902f5ee8392e07f804f5</guid>
<title>架构设计资料合集</title>
<link>https://toutiao.io/k/iqlrz7b</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;body class=&quot;logged-out env-production page-responsive page-blob&quot; id=&quot;readabilityBody&quot;&gt;
    

    

  &lt;p id=&quot;start-of-content&quot; class=&quot;show-on-focus&quot;/&gt;







    


    

  &lt;include-fragment class=&quot;js-notification-shelf-include-fragment&quot; data-base-src=&quot;https://github.com/notifications/beta/shelf&quot;/&gt;





  &lt;div class=&quot;application-main &quot; data-commit-hovercards-enabled=&quot;&quot; data-discussion-hovercards-enabled=&quot;&quot; data-issue-and-pr-hovercards-enabled=&quot;&quot;&gt;
        &lt;div itemscope=&quot;&quot; itemtype=&quot;http://schema.org/SoftwareSourceCode&quot; class=&quot;&quot;&gt;
    &lt;main id=&quot;js-repo-pjax-container&quot; data-pjax-container=&quot;&quot;&gt;
      

    
    








  



&lt;div id=&quot;repo-content-pjax-container&quot; class=&quot;repository-content &quot;&gt;
  
  


  
      
  &lt;div class=&quot;clearfix container-xl px-3 px-md-4 px-lg-5 mt-4&quot;&gt;
    
    
&lt;div&gt;
  




    
&lt;a class=&quot;d-none js-permalink-shortcut&quot; data-hotkey=&quot;y&quot; href=&quot;/toutiaoio/weekly.manong.io/blob/9de8d0b1c1d02892af76f584466bb9731561a79c/archives/architecture.md?hmsr=toutiao.io&amp;amp;utm_campaign=toutiao.io&amp;amp;utm_medium=toutiao.io&amp;amp;utm_source=toutiao.io&quot;&gt;Permalink&lt;/a&gt;







    &lt;div id=&quot;spoof-warning&quot; class=&quot;mt-0 pb-3&quot; hidden=&quot;&quot; aria-hidden=&quot;&quot;&gt;
  &lt;div data-view-component=&quot;true&quot; class=&quot;flash flash-warn mt-0 clearfix&quot;&gt;
  
  
    &lt;svg aria-hidden=&quot;true&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; data-view-component=&quot;true&quot; class=&quot;octicon octicon-alert float-left mt-1&quot;&gt;
    &lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z&quot;/&gt;
&lt;/svg&gt;

      &lt;p class=&quot;overflow-hidden&quot;&gt;This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.&lt;/p&gt;


  
&lt;/div&gt;&lt;/div&gt;

    &lt;include-fragment src=&quot;/toutiaoio/weekly.manong.io/spoofed_commit_check/9de8d0b1c1d02892af76f584466bb9731561a79c&quot; data-test-selector=&quot;spoofed-commit-check&quot;/&gt;

    &lt;div class=&quot;Box d-flex flex-column flex-shrink-0 mb-3&quot;&gt;
  &lt;include-fragment src=&quot;/toutiaoio/weekly.manong.io/contributors/master/archives/architecture.md&quot; class=&quot;commit-loader&quot;&gt;
    

    &lt;div class=&quot;Box-body d-flex flex-items-center&quot;&gt;
      &lt;p class=&quot;Skeleton Skeleton--text col-1&quot;&gt; &lt;/p&gt;
      &lt;span class=&quot;color-fg-danger h6 loader-error&quot;&gt;Cannot retrieve contributors at this time&lt;/span&gt;
    &lt;/div&gt;
&lt;/include-fragment&gt;&lt;/div&gt;







    &lt;readme-toc&gt;

    &lt;div data-target=&quot;readme-toc.content&quot; class=&quot;Box mt-3 position-relative&quot;&gt;
      
  &lt;div class=&quot;Box-header js-blob-header blob-header js-sticky js-position-sticky top-0 p-2 d-flex flex-shrink-0 flex-md-row flex-items-center&quot;&gt;

      &lt;details data-target=&quot;readme-toc.trigger&quot; data-menu-hydro-click=&quot;{&amp;quot;event_type&amp;quot;:&amp;quot;repository_toc_menu.click&amp;quot;,&amp;quot;payload&amp;quot;:{&amp;quot;target&amp;quot;:&amp;quot;trigger&amp;quot;,&amp;quot;repository_id&amp;quot;:193332705,&amp;quot;originating_url&amp;quot;:&amp;quot;https://github.com/toutiaoio/weekly.manong.io/blob/master/archives/architecture.md?hmsr=toutiao.io&amp;amp;utm_campaign=toutiao.io&amp;amp;utm_medium=toutiao.io&amp;amp;utm_source=toutiao.io&amp;quot;,&amp;quot;user_id&amp;quot;:null}}&quot; data-menu-hydro-click-hmac=&quot;254204da5c660a71b13b6e6f1c0a2f8173b5db645f006610ab5622186dfe217e&quot; class=&quot;dropdown details-reset details-overlay&quot;&gt;
  &lt;summary class=&quot;btn btn-octicon m-0 mr-2 p-2&quot; aria-haspopup=&quot;true&quot; aria-label=&quot;Table of Contents&quot;&gt;
    &lt;svg aria-hidden=&quot;true&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; data-view-component=&quot;true&quot; class=&quot;octicon octicon-list-unordered&quot;&gt;
    &lt;path fill-rule=&quot;evenodd&quot; d=&quot;M2 4a1 1 0 100-2 1 1 0 000 2zm3.75-1.5a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5zm0 5a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5zm0 5a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5zM3 8a1 1 0 11-2 0 1 1 0 012 0zm-1 6a1 1 0 100-2 1 1 0 000 2z&quot;/&gt;
&lt;/svg&gt;
  &lt;/summary&gt;


  &lt;details-menu class=&quot;SelectMenu&quot; role=&quot;menu&quot;&gt;
    
  &lt;/details-menu&gt;
&lt;/details&gt;


  &lt;p class=&quot;text-mono f6 flex-auto pr-3 flex-order-2 flex-md-order-1&quot;&gt;

      271 lines (259 sloc)
      &lt;span class=&quot;file-info-divider&quot;/&gt;
    38.7 KB
  &lt;/p&gt;

  

    
&lt;/div&gt;


        &lt;div id=&quot;readme&quot; class=&quot;Box-body readme blob js-code-block-container p-5 p-xl-6 gist-border-0&quot;&gt;
    &lt;article class=&quot;markdown-body entry-content container-lg&quot; itemprop=&quot;text&quot;&gt;&lt;h2 dir=&quot;auto&quot;&gt;&lt;a id=&quot;user-content-架构设计---往期存档---码农周刊&quot; class=&quot;anchor&quot; aria-hidden=&quot;true&quot; href=&quot;#架构设计---往期存档---码农周刊&quot;&gt;&lt;svg class=&quot;octicon octicon-link&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;架构设计 - 往期存档 - 码农周刊&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p dir=&quot;auto&quot;&gt;本项目是《码农周刊》往期存档 &amp;amp; VIP会员专属邮件周报。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p dir=&quot;auto&quot;&gt;&lt;a href=&quot;#%E7%AE%80%E4%BB%8B&quot;&gt;码农周刊简介&lt;/a&gt;｜&lt;a href=&quot;#VIP%E4%BC%9A%E5%91%98%E7%89%B9%E6%9D%83&quot;&gt;VIP会员特权&lt;/a&gt;｜&lt;a href=&quot;#%E6%88%90%E4%B8%BA%E7%A0%81%E5%86%9C%E5%91%A8%E5%88%8AVIP%E4%BC%9A%E5%91%98&quot;&gt;成为码农周刊VIP会员&lt;/a&gt;｜&lt;a href=&quot;#VIP%E4%BC%9A%E5%91%98%E4%B8%93%E5%B1%9E%E9%82%AE%E4%BB%B6%E5%91%A8%E6%8A%A5&quot;&gt;VIP会员专属邮件周报&lt;/a&gt;｜&lt;a href=&quot;#%E5%BE%80%E6%9C%9F%E5%AD%98%E6%A1%A3&quot;&gt;往期存档&lt;/a&gt;&lt;/p&gt;
&lt;h2 dir=&quot;auto&quot;&gt;&lt;a id=&quot;user-content-简介&quot; class=&quot;anchor&quot; aria-hidden=&quot;true&quot; href=&quot;#简介&quot;&gt;&lt;svg class=&quot;octicon octicon-link&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;简介&lt;/h2&gt;
&lt;ul dir=&quot;auto&quot;&gt;
&lt;li&gt;码农周刊是一份专为广大程序员、编程爱好者们打造的 IT 技术周刊。每周发送。&lt;/li&gt;
&lt;li&gt;2013 年 9 月 12 日创刊至今，已发送 300 多期，订阅用户超 20 万&lt;/li&gt;
&lt;li&gt;专业、简单、有用，是我们一直坚持的办刊宗旨。一路走来，我们见证了不少订阅用户从编程新手进阶成了高级程序员、架构师、CTO……&lt;/li&gt;
&lt;li&gt;2020 年 4 月，为了给用户提供更优质的服务，我们推出了「码农周刊VIP会员」服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 dir=&quot;auto&quot;&gt;&lt;a id=&quot;user-content-vip会员特权&quot; class=&quot;anchor&quot; aria-hidden=&quot;true&quot; href=&quot;#vip会员特权&quot;&gt;&lt;svg class=&quot;octicon octicon-link&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;VIP会员特权&lt;/h2&gt;
&lt;ul dir=&quot;auto&quot;&gt;
&lt;li&gt;52 期码农周刊VIP会员专属邮件周报，让你及时掌握技术动向；&lt;/li&gt;
&lt;li&gt;只限VIP会员加入的交流圈子，让你与技术大牛切磋学习；&lt;/li&gt;
&lt;li&gt;VIP会员独享的工作机会，为你介绍好公司的好机会；&lt;/li&gt;
&lt;li&gt;更多会员特权，持续更新……&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 dir=&quot;auto&quot;&gt;&lt;a id=&quot;user-content-成为码农周刊vip会员&quot; class=&quot;anchor&quot; aria-hidden=&quot;true&quot; href=&quot;#成为码农周刊vip会员&quot;&gt;&lt;svg class=&quot;octicon octicon-link&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;成为码农周刊VIP会员&lt;/h2&gt;
&lt;ol dir=&quot;auto&quot;&gt;
&lt;li&gt;微信扫描下方二维码，加入码农周刊VIP会员知识星球。&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://camo.githubusercontent.com/3bec7a23a8e3a8db753f5664ebe0979b29115a4dc348968d4acd1181bfdcff7a/68747470733a2f2f696d672e746f757469616f2e696f2f6164732f7669705f6769746875622e6a706567&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/3bec7a23a8e3a8db753f5664ebe0979b29115a4dc348968d4acd1181bfdcff7a/68747470733a2f2f696d672e746f757469616f2e696f2f6164732f7669705f6769746875622e6a706567&quot; data-canonical-src=&quot;https://img.toutiao.io/ads/vip_github.jpeg&quot;/&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;加入码农周刊VIP会员知识星球后，客服会联系您，请留意知识星球内的私信。&lt;/li&gt;
&lt;li&gt;客服向您发送码农周刊VIP会员欢迎邮件，开启您的码农周刊VIP会员之旅。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 dir=&quot;auto&quot;&gt;&lt;a id=&quot;user-content-vip会员专属邮件周报&quot; class=&quot;anchor&quot; aria-hidden=&quot;true&quot; href=&quot;#vip会员专属邮件周报&quot;&gt;&lt;svg class=&quot;octicon octicon-link&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;VIP会员专属邮件周报&lt;/h2&gt;
&lt;h2 dir=&quot;auto&quot;&gt;&lt;a id=&quot;user-content-往期存档&quot; class=&quot;anchor&quot; aria-hidden=&quot;true&quot; href=&quot;#往期存档&quot;&gt;&lt;svg class=&quot;octicon octicon-link&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;往期存档&lt;/h2&gt;

&lt;h2 dir=&quot;auto&quot;&gt;&lt;a id=&quot;user-content-程序设计&quot; class=&quot;anchor&quot; aria-hidden=&quot;true&quot; href=&quot;#程序设计&quot;&gt;&lt;svg class=&quot;octicon octicon-link&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&quot;/&gt;&lt;/svg&gt;&lt;/a&gt;程序设计&lt;/h2&gt;

&lt;/article&gt;
  &lt;/div&gt;

    &lt;/div&gt;

  &lt;/readme-toc&gt;

  

  &lt;details class=&quot;details-reset details-overlay details-overlay-dark&quot; id=&quot;jumpto-line-details-dialog&quot;&gt;
    &lt;summary data-hotkey=&quot;l&quot; aria-label=&quot;Jump to line&quot;/&gt;
    &lt;details-dialog class=&quot;Box Box--overlay d-flex flex-column anim-fade-in fast linejump&quot; aria-label=&quot;Jump to line&quot;&gt;
          &lt;/details-dialog&gt;
  &lt;/details&gt;


&lt;/div&gt;

  &lt;/div&gt;


&lt;/div&gt;

    &lt;/main&gt;
  &lt;/div&gt;

  &lt;/div&gt;

          &lt;footer class=&quot;footer width-full container-xl p-responsive&quot; role=&quot;contentinfo&quot;&gt;


  
  &lt;p class=&quot;d-flex flex-justify-center pb-6&quot;&gt;
    &lt;span class=&quot;f6 color-fg-muted&quot;/&gt;
  &lt;/p&gt;
&lt;/footer&gt;




  &lt;div id=&quot;ajax-error-message&quot; class=&quot;ajax-error-message flash flash-error&quot; hidden=&quot;&quot;&gt;
    &lt;svg aria-hidden=&quot;true&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; data-view-component=&quot;true&quot; class=&quot;octicon octicon-alert&quot;&gt;
    &lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z&quot;/&gt;
&lt;/svg&gt;
    &lt;button type=&quot;button&quot; class=&quot;flash-close js-ajax-error-dismiss&quot; aria-label=&quot;Dismiss error&quot;&gt;
      &lt;svg aria-hidden=&quot;true&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; data-view-component=&quot;true&quot; class=&quot;octicon octicon-x&quot;&gt;
    &lt;path fill-rule=&quot;evenodd&quot; d=&quot;M3.72 3.72a.75.75 0 011.06 0L8 6.94l3.22-3.22a.75.75 0 111.06 1.06L9.06 8l3.22 3.22a.75.75 0 11-1.06 1.06L8 9.06l-3.22 3.22a.75.75 0 01-1.06-1.06L6.94 8 3.72 4.78a.75.75 0 010-1.06z&quot;/&gt;
&lt;/svg&gt;
    &lt;/button&gt;&lt;p&gt;
    You can’t perform that action at this time.
  &lt;/p&gt;&lt;/div&gt;

  &lt;div class=&quot;js-stale-session-flash flash flash-warn flash-banner&quot; hidden=&quot;&quot;&gt;
    &lt;svg aria-hidden=&quot;true&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; data-view-component=&quot;true&quot; class=&quot;octicon octicon-alert&quot;&gt;
    &lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z&quot;/&gt;
&lt;/svg&gt;
    &lt;span class=&quot;js-stale-session-flash-signed-in&quot; hidden=&quot;&quot;&gt;You signed in with another tab or window. &lt;a href=&quot;&quot;&gt;Reload&lt;/a&gt; to refresh your session.&lt;/span&gt;
    &lt;span class=&quot;js-stale-session-flash-signed-out&quot; hidden=&quot;&quot;&gt;You signed out in another tab or window. &lt;a href=&quot;&quot;&gt;Reload&lt;/a&gt; to refresh your session.&lt;/span&gt;
  &lt;/div&gt;
    &lt;template id=&quot;site-details-dialog&quot;&gt;
  &lt;details class=&quot;details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm&quot; open=&quot;&quot;&gt;
    &lt;summary role=&quot;button&quot; aria-label=&quot;Close dialog&quot;/&gt;
    &lt;details-dialog class=&quot;Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal&quot;&gt;
      &lt;button class=&quot;Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0&quot; type=&quot;button&quot; aria-label=&quot;Close dialog&quot; data-close-dialog=&quot;&quot;&gt;
        &lt;svg aria-hidden=&quot;true&quot; viewbox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; data-view-component=&quot;true&quot; class=&quot;octicon octicon-x&quot;&gt;
    &lt;path fill-rule=&quot;evenodd&quot; d=&quot;M3.72 3.72a.75.75 0 011.06 0L8 6.94l3.22-3.22a.75.75 0 111.06 1.06L9.06 8l3.22 3.22a.75.75 0 11-1.06 1.06L8 9.06l-3.22 3.22a.75.75 0 01-1.06-1.06L6.94 8 3.72 4.78a.75.75 0 010-1.06z&quot;/&gt;
&lt;/svg&gt;
      &lt;/button&gt;
      &lt;p class=&quot;octocat-spinner my-6 js-details-dialog-spinner&quot;/&gt;
    &lt;/details-dialog&gt;
  &lt;/details&gt;
&lt;/template&gt;

    

    &lt;template id=&quot;snippet-clipboard-copy-button&quot;&gt;
  
&lt;/template&gt;




  &lt;/body&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c344c5d89e1ed30969174271fd3070a9</guid>
<title>SLICK: Facebook 基于 SLO 的可靠性保障实践</title>
<link>https://toutiao.io/k/wlzt3ro</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;article&gt;&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;定义服务的SLI和SLO，通过全局系统呈现、处理所有服务的SLI/SLO，从而帮助SRE实践在系统中的落地。本文介绍了Facebook（Meta）在这方面的实践。原文：SLICK: Adopting SLOs for improved reliability&lt;span&gt;[1]&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0V9NQlANKoELKWuvicYibiaF8ChJa0SXFwd6hSzXCCQdTbaEZPocskKibtVIibZ55kyP15jWqXEQ8R8Whw/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1200&quot;/&gt;&lt;/p&gt;&lt;p&gt;我们需要与使用我们的应用程序和产品的人们和社区不断保持联系，从而为他们提供足够的支持。我们希望将可靠性方面的经验提供出来，与我们支持的更大的社区建立信任关系。在像Meta（Facebook的新名字）这样大规模、快速发展的环境中，有成千上万的工程师在频繁部署代码、创建特性原型，并对更改进行迭代，因此保障可靠性的工作尤其具有挑战性。我们需要对每个产品、功能和服务有明确的期望，从而可以更好的为使用我们服务的用户提供可视化的体验，并分析系统之间的任何瓶颈或复杂的交互。&lt;/p&gt;&lt;p&gt;我们开始研究服务水平指标（SLIs，service-level indicators）和服务水平目标（SLOs，service-level objectives），将其作为期望的设置，并根据这些期望度量服务的性能。为了提供工具支持，我们构建了SLICK，这可以看作是一个专门的SLO商店。有了SLICK，我们能够集中SLI和SLO定义，从而轻松找到和理解另一个服务的可靠性。SLICK可以利用高留存率，以及其他工具无法找到的关键服务指标的完整粒度数据，为服务开发团队提供洞见，并将SLO与公司的其他各种工作流集成起来，以确保SLO成为日常工作的一部分。&lt;/p&gt;&lt;p&gt;在SLICK出现之前，SLO和其他性能指标存储在定制的仪表板、文档或其他工具中。如果想要定位团队的SLO，可能需要花费一个小时的时间来搜索或要求人们找到相关的数据。此外，之前的系统并没有以完整的粒度长时间（超过几周）保留这些指标，这使得对SLO进行更长时间的分析几乎是不可能的。有了SLICK，我们现在能够：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;以一致的方式为服务定义SLO&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;精度高达分钟级别的度量数据，最多可保留两年&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;对SLI/SLO指标有标准的可视化和洞见&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;定期向内部小组发送可靠性报告，允许团队基于这些报告进行可靠性检查&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;可发现性（Discoverability）&lt;/h2&gt;&lt;p&gt;SLICK定义了一个标准的模型，帮助公司里的每个人用同样的术语讨论可靠性。这使得新的服务开发团队能够无缝遵循公司范围的标准，在服务的早期设计阶段就考虑到服务需要达到的可靠性期望。&lt;/p&gt;&lt;p&gt;只要知道服务名，SLICK就可以帮助我们定位特定服务的可靠性指标和性能数据。SLICK通过构建内置的服务索引来实现这一点，该索引链接到带有标准可视化的仪表板，以分析和评估服务的可靠性。因此，只需单击一下，就可以知道服务当前是否满足用户的期望，如果有任何问题，就可以马上开始寻找答案。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0V9NQlANKoELKWuvicYibiaF8CHLgsDZoL2sHO41lQ3Cv7nXrBabyTRB4kVhU1h6OV17gCjYQWaNEf2A/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;SLICK的SLO索引搜索示例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;长期洞察（Long-term insights）&lt;/h2&gt;&lt;p&gt;服务可靠性的问题非常复杂。在某些情况下，单个错误的部署或某一段代码的变更可能就会导致服务突然退化。而在其他情况下，有可能随着服务的发展，不断累积微小的不可靠因素。&lt;/p&gt;&lt;p&gt;SLICK允许服务所有者使用最长可达两年的完整粒度的度量和性能数据。SLICK中的存储过程每小时运行一次数据管道，捕获所有SLI时间序列数据，并将它们存储在分片的MySQL数据库中。然后分析这些内容，形成可消费的洞见。这使得每个人——从工程师到TPM到领导——都能够了解随着时间的推移，可能会出现的服务可靠性的退化，而这些信息在之前很有可能会被忽视。&lt;/p&gt;&lt;h2&gt;工作流（Workflows）&lt;/h2&gt;&lt;p&gt;为了放大价值并帮助我们使用新的长期洞见来推动决策，SLI和SLO需要使用一种人人都能理解和使用的语言来规划和评估影响。为了实现这一点，我们将SLO集成到公共工作流中。&lt;/p&gt;&lt;p&gt;当大规模事件发生时，通过查看实时工具中的SLO，服务开发团队可以评估其对整体用户体验的影响。另一方面，当发生重大事件时，也可以基于SLO来驱动处理流程。我们首先使用SLO作为公司内部事件的标准，其他系统可以使用这些标准来获得用户看到的问题的警报。&lt;/p&gt;&lt;p&gt;从本质上说，将SLI和SLO集成到其他工具中，可以方便的将尚未引入的服务引入到SLICK中，从而以易于访问和易于使用的方式获得有效的见解。&lt;/p&gt;&lt;h2&gt;SLICK引入（SLICK onboarding）&lt;/h2&gt;&lt;p&gt;服务开发团队通过UI或者编写一个简单的配置文件来支持SLICK，该文件遵循带有服务名称等信息的DSL，可以查询SLI时间序列以及相应的SLO。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0V9NQlANKoELKWuvicYibiaF8CzKKBaWYiaLf1b8c5cCEG1WkIZSwZxyImN8tHVSBZ94PjeaqTMa5ZAsw/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p&gt;在用户测试并提交配置之后，SLICK会自动将服务添加到索引中，然后生成特定于服务的指示板，并开始收集数据以进行长期观测。除了这个配置文件，其他所有集成都是开箱即用的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;使用SLICK&lt;/h2&gt;&lt;p&gt;1）仪表板&lt;/p&gt;&lt;p&gt;SLICK仪表板为服务开发团队提供了监控实时SLI数据以及基于高留存率、长期数据的历史趋势的能力。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6220703125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0V9NQlANKoELKWuvicYibiaF8CWPBtaiaud3cU7D0PDzQGf1x3ywwX4utBUibAj3XQE9cZWZRwRS6cCxKQ/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;左边以完整的粒度说明了SLI时间序列。右侧显示基于时间的SLI值的每周聚合和SLO的相对差距。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;2）周期性报告&lt;/p&gt;&lt;p&gt;SLICK为工程师提供了SLO性能总结报告的能力，这些报告会定期发布给内部团队。报告为服务开发团队提供了一种简单的方法来关注回归并进行回顾，我们经常看到服务开发团队在这些帖子的评论中讨论可靠性问题。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.2141666666666666&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0V9NQlANKoELKWuvicYibiaF8C0licZUCTKSUsWiciayYoCw8ghialRVAbrYyjo0HwwxAgULPibxB0z9EicZ3g/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1200&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一周内的SLO性能的SLICK示例报告。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;3）CLI&lt;/p&gt;&lt;p&gt;SLICK提供了命令行接口，使服务所有者能够执行某些操作，比如回填数据、根据需要生成报告，或者测试对SLICK配置的更改的效果。&lt;/p&gt;&lt;h2&gt;SLICK架构&lt;/h2&gt;&lt;h4&gt;总体架构&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0V9NQlANKoELKWuvicYibiaF8ChJa0SXFwd6hSzXCCQdTbaEZPocskKibtVIibZ55kyP15jWqXEQ8R8Whw/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1200&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;SLICK配置（SLICK CONFIGS）：使用SLICK的DSL编写的配置文件，由用户提交到SLICK配置存储区。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SLICK同步器（SLICK SYNCER）：将对SLICK配置所做的更改同步到SLICK配置元数据存储的服务。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SLICK UI：为每个服务生成的SLICK仪表板，SLICK UI还提供了前面提到的索引。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SLICK服务（SLICK SERVICE）：提供API的服务器，能够回答诸如“如何为特定的可视化计算SLO？”这样的问题。服务器允许我们抽象出关于数据存储和分片的所有细节，使调用者能够轻松找到所需数据。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SLICK数据流水线（SLICK DATA PIPELINES）：周期性运行的流水线，以便长期获取SLI数据。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;数据获取详细设计（Zooming in on the data ingestion）&lt;/h4&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0V9NQlANKoELKWuvicYibiaF8Cz887Tgq5iblO5Zz0xr6RV3CHp9LIvd8MBGibRUGEsicZavSHwbj9UoNcQ/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p&gt;SLICK每小时运行一次数据流水线，这些流水线通过查询SLICK的配置元数据来查找所有SLI。流水线对被监控的数据集执行所有需要的查询，以获得以分钟为粒度的当前时刻每个SLI的原始时间序列数据。&lt;/p&gt;&lt;p&gt;然后，流水线参考SLICK分片映射确定每个SLI的数据应该存储在哪里，然后将数据批量插入到适当的分片中。&lt;/p&gt;&lt;p&gt;此外，可以执行数据质量检查，从而使我们对数据流水线的操作方式充满信心，并快速捕获真正的错误。数据质量检查针对一组确定性测试时间序列运行，用处理真实SLI序列同样的方式处理这些确定性时间序列，也就是说，对它们执行流水线，将它们插入到分片数据库中，最后，将数据库中的行与预期的时间序列进行比较，以验证系统的行为。&lt;/p&gt;&lt;h2&gt;Meta应用SLICK的SLO的当前状态&lt;/h2&gt;&lt;p&gt;在2019年创建了SLICK后，我们发现到2021年，全公司已经有超过1000个服务接入了SLICK。我们还看到其他许多公司在可靠性方面的成功案例，下面会分享其中的一部分。请注意，出于保密原因，下面图表使用了模拟数据，我们删除了日期并略微修改了数值，但图表的整体形状保持不变。&lt;/p&gt;&lt;h5&gt;LogDevice：回归检测和修复示例&lt;/h5&gt;&lt;p&gt;LogDevice&lt;span&gt;[2]&lt;/span&gt;是我们的分布式日志存储系统。服务开发团队可以通过SLICK对读可用性进行回归检查，并且可以基于这些数据修复回归发现的问题，并通过SLICK确认修复恢复了读取可用性的服务级别。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4677734375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0V9NQlANKoELKWuvicYibiaF8CEwR3h7ibafUPNEQTp5y32cEGicPQxKx1Cv4e3BIg0qv2G8s2BKzNjT0w/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;LogDevice可靠性(读可用性)。此图不按比例绘制，仅供讨论之用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h5&gt;后端ML服务可靠性示例&lt;/h5&gt;&lt;p&gt;2020年，Meta公司一个关键后端ML系统开始出现显著的可靠性退化，而这是一个影响到我们终端应用用户的ML服务。&lt;/p&gt;&lt;p&gt;SLICK数据显示，该服务始终没有达到SLO要求，服务开发团队能够识别这种回归，并帮助启动了可靠性评估，从而帮助他们调查、发现和修复可靠性问题的根本原因。团队解决了根本原因，服务回到了满足SLO的状态。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4462890625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/9utHkjMdE0V9NQlANKoELKWuvicYibiaF8C8CnO6Uic3icE3NlRDibxiaY8Vyicfia0gn5Pu2E2tKxPzdYFhic5TECSTk3tw/640?wx_fmt=other&quot; data-type=&quot;other&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后端ML服务可靠性(可用性)。此图不按比例绘制，仅供讨论之用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;我们的收获&lt;/h2&gt;&lt;p&gt;在推进SLO的过程中，我们走过了很长的一段路，并从中吸取了一些经验教训：&lt;/p&gt;&lt;p&gt;SLICK团队将继续致力于平台的发展以提供更多的价值。我们特别希望在以下领域进行投资：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;使服务的SLO与其依赖项的SLO保持一致。这将允许团队理解他们的依赖关系如何影响他们的性能，还能帮助我们揭示调用栈中服务之间不匹配的期望值，而这些不匹配因素有可能触发级联失败。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;为服务开发团队提供如何提高服务可靠性的反馈和建议。我们希望利用在提高可靠性方面的经验，为服务开发团队提供可操作的见解，以帮助他们提高可靠性并满足SLO。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;进一步发展SLICK的覆盖范围。我们希望在SLICK上搭载更多的团队和服务，为了做到这一点，SLICK需要保持可靠性和可扩展性（满足我们自己的SLO）。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;References:&lt;/span&gt;&lt;br/&gt;[1] SLICK: Adopting SLOs for improved reliability: https://engineering.fb.com/2021/12/13/production-engineering/slick/&lt;br/&gt;[2] LogDevice: https://engineering.fb.com/2017/08/31/core-data/logdevice-a-distributed-data-store-for-logs/&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;你好，我是俞凡，在Motorola做过研发，现在在Mavenir做技术工作，对通信、网络、后端架构、云原生、DevOps、CICD、区块链、AI等技术始终保持着浓厚的兴趣，平时喜欢阅读、思考，相信持续学习、终身成长，欢迎一起交流学习。&lt;br/&gt;微信公众号：DeepNoMind&lt;/p&gt;&lt;/blockquote&gt;&lt;/article&gt;
          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>bc8224d8d1f7701729c5ae51383013a1</guid>
<title>斯坦福教授曼宁AAAS特刊发文：大模型已成突破，展望通用人工智能</title>
<link>https://toutiao.io/k/a5dqsp0</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;section data-mpa-powered-by=&quot;yiban.io&quot; data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; data-style=&quot;white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &amp;quot;Helvetica Neue&amp;quot;, Helvetica, &amp;quot;Hiragino Sans GB&amp;quot;, &amp;quot;Microsoft YaHei&amp;quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__0&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-id=&quot;85660&quot; data-custom=&quot;rgb(117, 117, 118)&quot; data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;section data-darkmode-bgcolor-16095509242984=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16095509242984=&quot;rgb(255, 255, 255)&quot; data-style=&quot;margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__1&quot; mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;29.75&quot;&gt;&lt;span mp-original-font-size=&quot;15&quot; mp-original-line-height=&quot;29.75&quot;&gt;机器之心报道&lt;/span&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;29.75&quot;&gt;&lt;span mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;29.75&quot;&gt;&lt;strong mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;29.75&quot;&gt;编辑：泽南、小舟&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;blockquote data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;31&quot; data-source-title=&quot;&quot; mp-original-font-size=&quot;15&quot; mp-original-line-height=&quot;24&quot;&gt;&lt;p mp-original-font-size=&quot;15&quot; mp-original-line-height=&quot;26.25&quot;&gt;&lt;span mp-original-font-size=&quot;15&quot; mp-original-line-height=&quot;26.25&quot;&gt;&lt;span&gt;NLP 正在推动人工智能进入激动人心的新时代。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当前人工智能领域热度最高的方向就是预训练大模型了，很多人相信，这项研究已在通用人工智能领域初显成效。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;自然语言处理领域著名学者，斯坦福大学教授克里斯托弗 · 曼宁（Christopher Manning）近期在美国人文与科学学院（AAAS）期刊的 AI &amp;amp; Society 特刊上发表了题为《Human Language Understanding &amp;amp; Reasoning》的文章，探讨了语义、语言理解的本质，展望了大模型的未来。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;曼宁认为，随着 NLP 领域的技术突破，我们或许已在通用人工智能（Artificial general intelligence, AGI）方向上迈出了坚定的一步。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9oDibO0lcNicVtTE6rTiaQQZPzkLVu9vgIic9WwQfsgr42zUg37VTicKgcKXmzVIQNHywRpy9BibzTqxtQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;摘要&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在过去十年中，简单的神经网络计算方式在自然语言处理方面取得了巨大而令人惊讶的突破，人们在超大规模情况下复制了成功，并在大量数据上进行了训练。由此产生的预训练语言模型，如 BERT 和 GPT-3，提供了强大的通用语言理解和生成基础，可以轻松适应许多理解、写作和推理任务。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这些模型展示了一种更为通用的人工智能形式的初步迹象，这可能会在感知体验领域产生强大的基础模型，而不仅仅局限于语言。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;NLP 领域的四个时代&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当科学家思考人工智能时，大多会首先想到建模或重建单个人脑的能力。不过，现代人类智慧远不止单个大脑的智能。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;人类的语言很强大，并且对我们的物种产生了深远影响，因为它为人群整体提供了一种将大脑联网的方式。一个人可能并不比我们的黑猩猩或倭黑猩猩的近亲聪明太多。这些猿类已被证明拥有人类智能的许多标志性技能，例如使用工具和计划。此外，它们的短期记忆力甚至比我们强。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;人类发明语言的时间也许永远是个谜，但可以相对肯定的是，在地球生命漫长的进化史中，人类直到最近才发展出语言。原猴、猴子和猿类的共同祖先可以追溯到大约 6500 万年前。人类大约在 600 万年前与黑猩猩分离，而人类语言的历史通常被认为只有几十万年。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;人类发展了语言后，交流的力量让智人迅速超越其他生物，尽管我们没有大象那么强壮，也没有猎豹那么快。直到最近，人类才发明了文字（可能仅在五千多年前），让知识可以跨越时空界限进行交流。在短短几千年时间里，这种信息共享机制将我们从青铜时代带到了今天的智能手机。允许人类之间进行理性讨论和信息分发的高保真代码，允许复杂社会的文化演变，催生着现代技术背后的知识。语言的力量是人类社会智能的基础，在人工智能工具增强人类能力的未来世界中，语言将继续发挥重要作用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;由于这些原因，自然语言处理（NLP）领域与人工智能的最早发展同步出现。事实上，机器翻译 NLP 问题的初步工作，包括 1954 年著名的 Georgetown-IBM 实验，实现了史上首例机器翻译，略早于 1956 年人工智能」一词的创造。在本文中，我简要概述了自然语言的历史加工。然后，我描述了 NLP 最近的戏剧性发展，这些发展来自使用在大量数据上训练的大型人工神经网络模型。我追溯了使用这些技术构建有效 NLP 系统所取得的巨大进步，并总结了一些关于这些模型实现了什么，以及下一步将走向何方的想法。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;迄今为止，自然语言处理的历史大致可以分为四个时代。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;第一个时代从 1950 年到 1969 年。NLP 研究始于机器翻译研究。人们想象，翻译可以迅速建立在计算机在二战期间破译密码巨大成功的基础上。冷战时期的双方研究人员都在寻求开发能够转化其他国家科研成果的系统。然而在这个时代的开始，人们对人类语言、人工智能或机器学习的结构几乎一无所知。回想起来，可用的计算量和数据量小得可怜。尽管最初的系统被大肆宣传，但这些系统仅提供了词级翻译查找和一些简单的，不是很有原则的基于规则的机制来处理词的屈折形式（词形变化）和词序。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;第二个时代，从 1970 年到 1992 年，我们见证了一系列 NLP 演示系统的发展，这些演示系统在处理人类语言中的句法和引用等现象方面表现出复杂性和深度。这些系统包括 Terry Winograd 的 SHRDLU、Bill Woods 的 LUNAR、Roger Schank 的系统，如 SAM、Gary Hendrix 的 LIFER 和 Danny Bobrow 的 GUS。这些都是人们手工构建的基于规则的系统，但他们开始建模和使用人类语言理解的一些复杂性。一些系统甚至被部署用于数据库查询等任务。语言学和基于知识的人工智能正在迅速发展，在这个时代的第二个十年里出现了新一代的手工构建系统，它与声明性和语言知识及其程序处理区分开来，并受益于一系列更现代的语言理论的发展。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;然而我们的工作方向在 1993 年到 2012 年间的第三个时代发生了显著变化。在此期间，数字文本变得丰富，最适用的方向是开发能够在大量自然语言内容上实现某种程度语言理解的算法，并利用文本的存在来帮助获得这种能力。这导致该领域围绕 NLP 的经验机器学习模型在根本上被重新定位，这一方向至今仍占主导地位。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在这个时期初期，我们主要的方法是掌握合理数量的在线文本——当时的文本集合一般在几千万字以下——并从中提取某种模型数据，主要是通过计算特定事实。例如，你可能发现人识别的事物类型在人的位置（如城市、城镇或堡垒）和隐喻概念（如想象力、注意力或本质）之间相当均衡。但是对单词的计数仅能提供语言理解设备，早期从文本集合中学习语言结构的经验尝试相当不成功。这导致该领域的大部分人专注于构建带注释的语言资源，例如标记单词、文本中的人名或公司名称的实例，或树库中句子的语法结构，然后使用监督机器学习技术构建模型，该模型可以在运行时在新文本片段上生成类似的标签。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;自 2013 年至今，我们扩展了第三个时代的经验方向，但由于引入了深度学习 / 人工神经网络方法，工作已经发生了巨大的变化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在新方法中，单词和句子由（数十或千维）实值向量空间中的位置表示，含义或句法的相似性由该空间中的接近度表示。从 2013 年到 2018 年，深度学习为构建高性能模型提供了一种更强大的方法，其更容易对更远距离的上下文进行建模，并且模型可以更好地泛化到具有相似含义的单词或短语上，因为它们可以利用向量空间中的邻近性，而不是依赖于符号的同一性（例如词形或词性）。然而，该方法在构建监督机器学习模型以执行特定分析任务方面没有改变。 &lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在 2018 年，一切都发生了变化，超大规模自监督（self-supervised）神经网络学习的第一个重大成功就在 NLP 上。在这种方法中，系统可以通过接触大量文本（现在通常是数十亿字）来学习大量的语言和世界知识。实现这一点的自监督方法是让 AI 系统从文本中自行创建预测挑战，例如在给定先前单词的情况下连续识别文本中的每个「下一单词」，或填充文本中遮掩的单词或短语。通过数十亿次重复这样的预测任务并从错误中学习，模型在下一次给定类似的文本上下文时会做得更好，积累了对语言和世界的一般知识，然后可以将这些知识部署到更多人们感兴趣的任务中，例如问答或文本分类。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;为什么大模型是突破&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;事后看来，大规模自监督学习方法的发展很可能被视为一次革命，第三个时代可能会延长到 2017 年。预训练自监督方法的影响是一个突破：现在我们可以在大量未标记的人类语言材料上训练，生成一个大型预训练模型，其可以很容易地通过微调或提示进行调整，在各种自然语言理解和生成任务上提供强大的结果。现在，人们对 NLP 的进步和关注爆发了。出现了一种乐观的感觉，我们开始看到具有一定程度通用智能的知识灌输系统的出现。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我无法在此完整描述目前占主导地位的人类语言神经网络模型。大体上，这些模型通过实数向量表示一切，并且能够在接触到许多数据后通过从某些预测任务到单词表示的错误（归结为进行微积分）的反向传播来学习很好地表示一段文字。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;自 2018 年以来，NLP 应用的主要神经网络模型一直是 Transformer 架构神经网络。Transformer 是一个比几十年前人类探索的用于单词序列的简单神经网络更复杂的模型，主要思想之一是注意力机制——通过它，一个位置的表示被计算为来自其他位置的表示的加权组合。Transformer 模型中一个常见的自监督目标是屏蔽文本中的偶尔出现的单词，该模型要计算空位上曾经存在的单词。它通过从每个单词位置（包括掩码位置）计算表示该位置的查询、键和值的向量来做到这一点。将某个位置的查询与每个位置的值进行比较，算法计算出每个位置的注意力。基于此，计算所有位置的值的加权平均值。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这种操作在 Transformer 神经网络的每一层重复多次，结果值通过一个全连接的神经网络层进一步操作，并通过使用归一化层和残差连接为每个单词生成一个新的向量。整个过程重复多次，为 Transformer 神经网络提供了额外的深度层。最后，掩码位置上方的表示应捕获原始文本中的单词：例如，如图 1 所示的 committee。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.784375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9oDibO0lcNicVtTE6rTiaQQZP0tRicejgOMvhe6OMhNMGAk3Jo4ndiaDLE53sX2YAfbPGic9kiaF5z3fnzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;通过 Transformer 神经网络的简单计算可以实现或学习什么并不明显，起初它更像是某种复杂的统计关联学习器。然而，利用像 Transformer 这样非常强大、灵活的超参数模型和大量数据来练习预测，模型发现并表征了人类语言的大部分结构。研究表明这些模型学习和表征句子的句法结构，并学习记忆许多事实，这些有助于模型成功预测自然语言中被掩码的词。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;此外，虽然预测一个被掩码的词最初似乎是一项相当简单和低级的任务，但这个任务的结果却有着强大和普遍的作用。这些模型汇集了它们所接触的语言和广泛的现实知识。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;只需要再给出进一步的指令，这样的大型预训练模型 (LPLM) 就可以部署于许多特定的 NLP 任务。从 2018 年到 2020 年，领域内的标准方法是通过少量额外的监督学习来微调模型，在感兴趣的确切任务上对其进行训练。但最近，研究人员惊讶地发现，这些模型中最大的模型，例如 GPT-3（生成式预训练 Transformer），只需提示（prompt）即可很好地执行新任务。给模型一个人类语言描述或几个例子，说明人们希望模型做什么，模型就可以执行许多它们从未接受过训练的任务。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;大模型带来的 NLP 新范式&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;传统的自然语言处理模型通常由几个独立开发的组件组合而成，通常构建成一个 pipeline，其中首先尝试捕获文本的句子结构和低级实体，然后是高级含义的词汇，这也是馈入一些特定领域的执行组件。在过去的几年里，业内已经用 LPLM 取代了这种传统的 NLP 解决方案，通常经过微调来执行特定的任务。我们可以期待一下 LPLM 在 2020 年代能够完成哪些目标。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;早期的机器翻译系统涵盖了有限领域中的有限语言结构。从广泛的翻译文本的平行语料库（parallel corpora）构建大型统计模型，这种方法是可以覆盖机器翻译的，这也成就了 2006 年首次推出的 Google 翻译。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;十年后，即 2016 年底，当人们转向使用神经机器翻译时，Google 的机器翻译性能获得了显著提高。但新型系统的更新换代越来越快，2020 年基于 Transformer 的神经翻译系统用不同的神经架构和方法进行了改进。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;新系统不是在两种语言之间进行翻译的大型系统，而是利用一个巨大的神经网络，同时在谷歌翻译涵盖的所有语言上进行训练，仅用一个简单的 token 标记不同的语言。虽然这个系统仍会出错，但机器翻译不断在发展，今天的自动翻译的质量已经非常出色。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;例如，将法语翻译成英语：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;158&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;Il avait été surnommé, au milieu des années 1930, le « Fou chantant », alors qu’il faisait ses débuts d’artiste soliste après avoir créé, en 1933, un duo à succès avec le pianiste Johnny Hess.&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;204&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;Pour son dynamisme sur scène, silhouette agile, ses yeux écarquillés et rieurs, ses cheveux en bataille, surtout pour le rythme qu’il donnait aux mots dans ses interprétations et l’écriture de ses textes.&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;136&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;He was nicknamed the Singing Madman in the mid-1930s when he was making his debut as a solo artist after creating a successful duet with pianist Johnny Hess in 1933.&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;185&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;For his dynamism on stage, his agile figure, his wide, laughing eyes, his messy hair, especially for the rhythm he gave to the words in his interpretations and the writing of his texts.&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;在问答系统中，系统在一组文本中查找相关信息，然后提供特定问题的答案（而不是像早期的 Web 搜索那样仅返回建议相关信息的页面）。问答系统有许多直接的商业应用，包括售前和售后客户咨询。现代神经网络问答系统在提取文本中存在的答案方面具有很高的准确性，甚至可以很好地找出不存在的答案。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;例如，从以下英文文本中找到问题的答案：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;240&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;Samsung saved its best features for the Galaxy Note 20 Ultra, including a more refined design than the Galaxy S20 Ultra–a phone I don’t recommend. You’ll find an exceptional 6.9-inch screen, sharp 5x optical zoom camera and a swifter stylus for annotating screenshots and taking notes.&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;178&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;The Note 20 Ultra also makes small but significant enhancements over the Note 10 Plus, especially in the camera realm. Do these features justify the Note 20 Ultra’s price? It begins at $1,300 for the 128GB version.&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;122&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;The retail price is a steep ask, especially when you combine a climate of deep global recession and mounting unemployment.&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;152&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;三星 Galaxy Note 20 Ultra 的价格是多少？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt; 128GB 版本 1300 美元&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Galaxy Note 20 Ultra 有 20 倍光学变焦吗？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt; 没有&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Galaxy Note 20 Ultra 的光学变焦是多少？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt; 5x&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Galaxy Note 20 Ultra 的屏幕有多大？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt; 6.9 英寸&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;对于常见的传统 NLP 任务，例如在一段文本中标记人或组织名称或对文本进行情感倾向分类（正面或负面），当前最好的系统还是基于 LPLM 的，对于特定任务通过提供一组以所需方式标记的样本进行微调。尽管这些任务在大型语言模型出现之前就可以很好地完成，但大型模型中语言和世界知识的广度进一步提高了在这些任务上的性能。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;最后，LPLM 引发了在生成流畅和连续文本的能力方面的一场革命。除了许多创造性用途之外，此类系统还具有工具性质的用途，例如编写公式化的新闻文章、自动生成摘要。此外，这样的系统可以根据放射科医生的发现提出（或总结）要点来帮助放射科医生诊断病情。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这些 NLP 系统在许多任务上都表现得非常好。事实上，给出一个特定的任务，它们通常可以被训练成像人类一样执行这些任务。尽管如此，仍有理由怀疑这些系统是否真的理解它们在做什么，或者它们是否只是单纯地重复一些操作，没有意义。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以较复杂的编程语言理解为例，编程语言中描述单词意义主要借助指称语义学：单词、短语或句子的含义是对象或情况的集合，用这种方法描述世界或其数学抽象。这与 NLP 中现代实验研究的简单分布语义（或使用意义理论）形成鲜明对比，单词的含义不再只是对上下文的描述。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;大模型真的理解人类语言吗？&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我认为语言的意义源于理解语言形式与其他事物之间的关联网络。如果我们拥有一个密集的关联网络，那么我们就可以很好地理解语言形式的含义。例如，如果我已知「shehnai」是个印度语词汇，那么我对这个词的含义就能够有一个合理的概念，它是印度唢呐；如果我能听到这种乐器演奏的声音，那么我对 shehnai 这个词会有更丰富的含义理解。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;反过来，如果我从未见过或听过 shehnai 的声音，但有人告诉我它就像传统的印度双簧管，那么这个词对我来说也有一些意义：它与印度有关，与管乐器有关，并用来演奏音乐。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果有人补充说 shehnai 有孔，有多个簧片和像双簧管一样的喇叭形末端，那么我就有更多连接到 shehnai 这个对象的属性网络。相反，我可能没有这些信息，只有几段使用该词的上下文，例如：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;77&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;从一周前开始，有人坐在房子入口处的竹林里吹奏着 shehnai；Bikash Babu 不喜欢 shehnai 的哀号，但决心满足新郎家人的所有传统期望。&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;尽管在某些方面，我对 shehnai 这个词的含义理解会较少，但我仍然知道它是一种管状乐器，这也基于我知道一些额外的文化关联。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;因此，理解语言的含义包括理解语言形式的关联网络，预训练语言模型能够学习语言的含义。除了词汇本身的含义，预训练语言模型也掌握了很多实际的知识。很多模型都经过了在百科全书上的训练，它们知道亚伯拉罕 · 林肯于 1809 年出生于肯塔基州；知道《Destiny’s Child》的主唱是碧昂丝。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;就像人类一样，机器也可以从人类知识存储库中受益匪浅。然而，模型对词义和世界知识的理解往往非常不完整，需要用其他感官数据（sensory data）和知识来增强。大量文本数据首先为探索和构建这些模型提供了一种非常容易访问的方法，但扩展到其他类型的数据也是非常有必要的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;LPLM 在语言理解任务上的成功，以及将大规模自监督学习扩展到其他数据模式（如视觉、机器人技术、知识图谱、生物信息学和多模态数据）令人兴奋的前景表明了更通用方向的希望。我们提出了通用类模型的术语基础模型，通过自监督在大量数据上训练了数百万个参数，然后可以轻松地适应执行广泛的下游任务。例如 BERT（来自 Transformers 的双向编码器表示) 和 GPT-3 是这种基础模型的早期示例，但现在正在进行更广泛的工作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;一个方向是将语言模型与更加结构化的知识存储连接起来，这些知识存储表示为知识图神经网络或运行时要查阅的大量文本。不过最令人兴奋和有希望的方向是建立基础模型（foundation model），使其还可以吸收来自世界的其他感官数据，以实现集成的多模态学习。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这方面的一个例子是最近的 DALL-E 模型，在对成对的图像和文本的语料库进行自监督学习后，该算法可以通过生成相应的图片来表达新文本的含义。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7407862407862408&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9oDibO0lcNicVtTE6rTiaQQZP8ezq9P7j5PuBP3zFDjd8W8iaPnCD4GFA74TCFqicm6ytEkWbFsLibMZQg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;814&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们现在还处于基础模型时代的早期，但在这里，让我勾勒出一个可能的未来：大多数信息处理和分析任务，甚至可能像机器人控制这样的事情，都将由少数几个基础模型之一的特化版接手。这些模型训练起来既昂贵又耗时，但让它们适应不同的任务将非常容易。事实上，人们也许可以简单地使用自然语言指令来做到这一点。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这种在少数模型上的收敛带来了几个风险：能够构建这些模型的机构可能拥有过多的权力和影响力，许多最终用户可能会受到这些模型中存在偏见的影响，且很难判断模型是否正确。另外，在特定环境中使用的安全性也存疑，因为模型及其训练数据非常大。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;不论如何，这些模型把大量训练数据中获得的知识部署到许多不同任务的能力，将使其变得非常强大，它们还将成为首批在执行许多特定任务时，只需要人类下指示，告诉它如何做就能做到的人工智能。虽然这些模型最终可能只是模糊地了解一些知识，它们的可能性或许仍然有限，缺乏人类水平的精细逻辑或因果推理能力。但基础模型的通用有效性意味着它们将得到非常广泛的部署，它们将在未来十年让人们第一次看到更普遍的人工智能形式。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;原文链接：&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://www.amacad.org/publication/human-language-understanding-reasoning&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;2.135782747603834&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibTwShQsfJziaJL4v4u50HHPibmnKy1DbNmkWm1SNT5qvj8iauzshvSWQIDq3xcgUDayFjF0s6SD6dRg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2504&quot;/&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;br mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;/&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt;© THE END &lt;/span&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;/&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/p&gt;&lt;p mp-original-font-size=&quot;17&quot; mp-original-line-height=&quot;27.200000762939453&quot;&gt;&lt;span mp-original-font-size=&quot;12&quot; mp-original-line-height=&quot;19.200000762939453&quot;&gt;投稿或寻求报道：content@jiqizhixin.com&lt;/span&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>71318b9cf8b24b845c3e115a51c1d68d</guid>
<title>聊聊如何让springboot拦截器的执行顺序按我们想要的顺序执行</title>
<link>https://toutiao.io/k/j78i4x6</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2857142857142857&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/Fe4uQ1C2h1kkNNOq5qntr0Xia3X4QLF1mXCIzFp0SibDCicf065icZXrv6JDBYpPIm0X2XjKezSSkXuFuibkZqGEHhg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;84&quot;/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;点击上方&lt;span data-mid=&quot;&quot;&gt;蓝字&lt;/span&gt;关注我们&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;01&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;span&gt;前言&lt;/span&gt;&lt;/p&gt;&lt;span data-mid=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;p&gt;最近朋友和我提了一个挺有趣的问题：他们有个项目用了他们框架部提供的jwt token校验填充组件，实现原理大概是，通过springboot拦截器来校验token，如果token合法，就解析token，将token携带的业务信息map填充到threadlocal里面，方便后续业务使用。&lt;/p&gt;&lt;p&gt;朋友的问题就是他想往这个threalocal里面的业务map再扩展一些业务字段，但因为这个组件不是朋友的部门开发的，他就不能改源码，只能通过扩展的方式。&lt;/p&gt;&lt;p&gt;他的思路就是他也写一个拦截器，在这个拦截器里面做业务填充。这边有个前提就是框架部的执行时机得在朋友写的拦截器之前，朋友的做法是在他写的拦截器上面加@Order注解，不过发现不管用。于是就找我讨论一下这个问题。&lt;/p&gt;&lt;p&gt;抽象出来的问题就是标题说的如何让springboot拦截器的执行顺序按我们想要的顺序执行&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;02&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;span&gt;思路&lt;/span&gt;&lt;/p&gt;&lt;span data-mid=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;方法一：自己的业务项目写一个和框架组一模一样的类&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img data-ratio=&quot;0.5&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/o7XlPeoeYMUgmQjQDVic3XMmyYXmDcWjPQLtYTFXjTGmtu8Doicdy7LMXicepIV3KPd2PKGQn8sM4Rgr9XpwXqVPQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;40&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即这个类和框架组提供的包名和类名一样，然后改这个类，这个实现原理是利用了类的加载顺序&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;方法二：利用org.springframework.web.servlet.config.annotation.InterceptorRegistration#order()&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img data-ratio=&quot;0.5&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/o7XlPeoeYMUgmQjQDVic3XMmyYXmDcWjPQLtYTFXjTGmtu8Doicdy7LMXicepIV3KPd2PKGQn8sM4Rgr9XpwXqVPQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;40&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不过这个order方法是spring 4.3+版本后才提供。&lt;/p&gt;&lt;p&gt;具体使用形如下&lt;/p&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-preserve=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;@Override&lt;/span&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    public void addInterceptors(InterceptorRegistry registry) {&lt;br mpa-from-tpl=&quot;t&quot;/&gt;        &lt;span&gt;registry&lt;/span&gt;&lt;span&gt;.addInterceptor&lt;/span&gt;(helloHandlerInterceptor)&lt;span&gt;.addPathPatterns&lt;/span&gt;(&lt;span&gt;&quot;/**&quot;&lt;/span&gt;)&lt;span&gt;.order&lt;/span&gt;(&lt;span&gt;100&lt;/span&gt;);&lt;br mpa-from-tpl=&quot;t&quot;/&gt;        &lt;span&gt;registry&lt;/span&gt;&lt;span&gt;.addInterceptor&lt;/span&gt;(otherHelloHandlerInterceptor)&lt;span&gt;.addPathPatterns&lt;/span&gt;(&lt;span&gt;&quot;/**&quot;&lt;/span&gt;)&lt;span&gt;.order&lt;/span&gt;(-&lt;span&gt;1&lt;/span&gt;);&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    }&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;p&gt;通过配置order()的值，值越小，优先级越高。不配默认是0&lt;/p&gt;&lt;p&gt;那为啥要配置这个呢，如果对springmvc有稍微深入一下的话，拦截器链最终是会用到&lt;/p&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-preserve=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;protected&lt;/span&gt; &lt;span&gt;List&lt;/span&gt;&amp;lt;Object&amp;gt; getInterceptors() {&lt;br mpa-from-tpl=&quot;t&quot;/&gt;    &lt;span&gt;return&lt;/span&gt; this.registrations.stream()&lt;br mpa-from-tpl=&quot;t&quot;/&gt;        .sorted(INTERCEPTOR_ORDER_COMPARATOR)&lt;br mpa-from-tpl=&quot;t&quot;/&gt;        .map(InterceptorRegistration::getInterceptor)&lt;br mpa-from-tpl=&quot;t&quot;/&gt;        .collect(Collectors.toList());&lt;br mpa-from-tpl=&quot;t&quot;/&gt;  }&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;排序就是根据这个order来的&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;03&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/p&gt;&lt;span data-mid=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文提供的方案二适用于spring 4.3+版本，低于该版本，请慎重。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;04&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;span&gt;demo链接&lt;/span&gt;&lt;/p&gt;&lt;span data-mid=&quot;&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;https://github.com/lyb-geek/springboot-learning/tree/master/springboot-interceptor-order&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img data-ratio=&quot;0.5&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/o7XlPeoeYMUgmQjQDVic3XMmyYXmDcWjPQLtYTFXjTGmtu8Doicdy7LMXicepIV3KPd2PKGQn8sM4Rgr9XpwXqVPQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;40&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br mpa-from-tpl=&quot;t&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>091135cfa78f11041c7790aa6a4d0456</guid>
<title>B站基于AIFlow+Flink在批流融合调度上的实践</title>
<link>https://toutiao.io/k/our58ue</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;本期作者&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;张杨&amp;amp;王丁&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;bilibili资深开发工程师&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;负责B站实时团队flink引擎sql方向工作，专注于flinksql性能提升优化。同时也关注flink引擎在机器学习、数仓等场景的应用落地。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;1. 背景&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;B站在机器学习方面有非常丰富的应用场景和工程实践，尤其是推荐、广告、搜索等业务，经过数年的积累，B站的AI团队已经形成了相当成熟和稳定的机器学习训练平台和实验平台。随着技术和业务的不断演进，目前AI团队的机器学习工程已经开始从离线逐步向实时方向发展。当前B站的实时平台团队基于Flink开发的流计算平台已经在AI团队中广泛使用，将推广搜场景的效果进一步提升。&lt;/p&gt;&lt;p&gt;但是与离线训练不同，实时训练和实验往往涉及到很多不同系统资源的整合,如Kafka、Flink以及其他KV存储等资源，这些相比离线资源更加难以统一管理。在现有的工程架构下，创建一个完整的AI实验流程非常复杂，需要了解多个不同系统的使用和调试，申请各种存储、计算资源。这些流程性的东西往往会消耗非常多的时间精力，导致聚焦在实验本身的时间被大大减少，同时在流程和数据的版本管控，结果可重复性,以及流批的相互迁移转化上也都难以满足业务。我们希望提供一套完整的实验流平台，从创建实验到最终的效果验证，都能在平台上通过简单的Python代码或者可视化配置完成，简化整个流程，提升实验效率，同时优化流程和数据的管理能力，具备基本的流批迁移能力。基于阿里开源的AIFlow项目，我们设计了B站的AI协作平台。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;2. 基本架构&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;AIFlow是阿里Flink生态团队开源的一套机器学习工作流框架，对工作流模型进行了统一抽象，通过Event机制进行流批混合的调度。它通过把机器学习的工作流抽象成一个AIGraph，引入了数据依赖和控制依赖，能够从多个维度进行Event调度。尤其是AIFlow可以使用Python脚本定义工作流，类似于Apache Airflow，对于AI同学来说学习成本是比较低的，能够快速上手。&lt;/p&gt;&lt;p&gt;AIFlow项目在设计上保留了极大的拓展性，既可以直接兼容Apache Airflow的原生DAG任务，也可以根据Plugin接口自定义不同的任务插件，甚至可以根据插件接口自定义底层的调度器。同时，AIFlow也内置了很多常见的插件，比如存储插件：OSS、S3、HDFS等存储插件，不同类型的Job插件如：Python、Bash、Flink等。&lt;/p&gt;&lt;p&gt;在使用AIFlow时，可以直接部署好Server，各个Client直接在本机运行，在本机进行数据流开发，开发完成后直接提交Project和Workflow到Server，这样对于测试环境或者调试来说是非常方便的。如果有更加定制化的需求，可以自行添加各种所需的插件，甚至可以修改提交模式，将Client端也部署到远程服务器中，在Client之上进行业务封装。B站使用的就是后者，我们在Client端进行了二次开发，并设计了一套基于AIFlow的数据产品。&lt;/p&gt;&lt;p&gt;B站基于AIFlow开发的AI协作平台架构主要经历了三个阶段。第一阶段主要是验证阶段，在这个阶段我们和Flink生态社区团队一起，通过了业务化的改造，完成了AIFlow在B站的第一版设计和落地。第二阶段主要是数据产品形态的打磨和迭代，也包括了对新调度引擎的适配。第三个阶段是优化，将当前的系统进行一次改动比较大的改造，并能够适配社区的最新版本和后续的迭代。当前处于第三阶段，下面对每个阶段分别进行介绍。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;2.1 第一阶段&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;机器学习的全链路包含多个阶段，从数据的采集，到样本的生成，再到特征生成、模型训练、预测，以及效果评估等。B站的这些任务最开始都是离线的，包括Spark、Hive任务等。将这些阶段的任务进行了实时化改造后，我们实时平台将相当一部分任务转为基于Flink的实时任务。但是对于全链路而言，每个阶段的任务配置都是相对独立的，新模型的实验和验收需要经过多个任务的不同实验阶段，这个链路是非常长的。而且对于算法同学而言，理解一条链路上的全部任务和实验克隆是有一定的学习成本的。同时，在流任务计算的上下游，或多或少还存着一定的批任务，它们的触发条件也和流计算任务是紧密关联。如何解决流任务和批任务的混合调度，以及如何以一个全局视角总览整个机器学习的全链路任务，成为了我们的当务之急。&lt;/p&gt;&lt;p&gt;在2020年8月份前后，AIFlow进入我们的视野中。在和社区经过了深入交流和探讨后，我们对AIFlow进行了相应的业务开发和改造，逐步在B站落地AIFlow。在落地过程中，我们针对AIFlow提供的特性，主要做了以下几个方面的工作。&lt;/p&gt;&lt;p&gt;首先就是结合B站内部的技术栈，完成了基于Spark和Flink的RemoteOperator。这个比较好理解，我们的任务都是在远程执行，所以每个Operator基本上都是在结合业务属性构造和提交远程任务，然后定时轮询远程任务的状态。这里有一个点，由于我们所有的服务都是部署在k8s的容器中的，所以本地Operator可能会遇到容器宕机或发布重启等各种失败场景，但是实际上远程任务依然是在正常运行的，所以我们在RemoteOperator里做了一层恢复机制，能够保证在local task重新调度时，远程任务不会重启或重复提交。同时，我们完善了一般业务场景下流批依赖语义，支持流批任务互相触发与数据依赖。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5444444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1BMf5Ir754SpdhLmEuPfmotDyBMMIGXic0nLg88IRxVA3VQK1mWicN3piczib8eJ0hSGhHKpcMqokTs2fJYRmEqTrQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;还有一块工作是针对快慢节点导致的特征穿越问题。尤其是在实时训练过程的Flink任务中，如果两个或多个任务互相关联，但是处理速度又不相同，很容易引起工作流中的特征穿越问题。那么针对这个问题，我们通过改造Flink，植入对应的aiflow定制operator，通过notification模块互相使不同的任务之间通过Watermark保持协同工作，控制进度。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;下图是我们系统初版的架构图：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7303253&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1BMf5Ir754SpdhLmEuPfmotDyBMMIGXictmW34P0icX07ZX1jGJrjfKVmz4sl1GUP1hyXXzmxRibqYYhYe4Zlfvfw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;953&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;2.2 第二阶段&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;在完成了AIFlow在B站实时平台的初步落地后，这套系统也逐步在AI场景中应用于在线的流计算任务。在使用一段时间后，业务方不断地沟通和反馈。我们开始了下一个阶段的设计和改造。这一阶段主要解决了一些性能、稳定性和产品设计方面的问题。&lt;/p&gt;&lt;p&gt;在第一阶段的落地过程中，我们确实是遇到了一些性能和稳定性问题。2021年2月份左右，随着Airflow2.0的发布，AIFlow社区团队对底层调度器进行了很大的改造，基于Airflow2.0的Scheduler实现了EventBasedScheduler，不管是调度的稳定性还是性能都大大提高，我们也跟随社区版本，对我们的系统进行了升级。&lt;/p&gt;&lt;p&gt;另一块比较重要的工作就是对数据产品的打磨。B站内部这套基于AIFlow设计的数据产品代号为Ultron。在解决了性能和稳定性问题后，我们对Ultron的产品形态进行了精细化的打磨以及快速迭代。比如，在和业务方多次沟通后，我们决定去掉工作流中关于业务信息和参数的定义，将业务属性彻底和工作流的定义分离，减少业务方与业务无关的开发量，把参数、任务属性等信息转移到前端页面上，通过页面填参即可实现快速调试和修改任务的能力。在这个过程中，我们也是向AIFlow社区贡献了B站展现带数据节点和数据依赖的工作流前端代码。&lt;/p&gt;&lt;p&gt;下图是系统的内部截图：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6462963&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1BMf5Ir754SpdhLmEuPfmotDyBMMIGXic6b6WrMygnU7aic2lnYkjSlwWicRSCvu3KQo03tvt7UwbS7rPCyzWIDicQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;除了工作流定义简化和前端展示方面的优化，我们还阵对工作流的版本管理做了优化工作。Ultron的版本管理包括工作流版本管理和节点版本管理。不管是工作流Owner修改了工作流中节点的定义、关系、依赖，还是某个节点的参数信息，都会在我们的系统里生成一个版本快照，方便AI同学在遇到问题或者实验回退时能够快速恢复到之前的一个可正常运行状态。&lt;/p&gt;&lt;p&gt;除了上面提到的版本管理，还有一些比如元数据和数据源管理、工作流监控、运维面板、节点预检查、权限管理等方面的工作。总体来说，在这个阶段，Ultron系统已经具备了标准的工程系统能力，具有了更加成熟的产品形态和产品功能，开始承载更多的业务方在机器学习工作流方面的需求。&lt;/p&gt;&lt;p&gt;下图是我们第二阶段时的系统架构图。其中蓝色区域内是AIFlow原生的架构，绿色区域是Ultron在AIFLow基础上增加的一些功能，紫色区域是我们和业务逻辑相关的一些系统，包括处理业务逻辑的WebServer和定制开发的Flink版本，以及B站的大数据平台Berserker平台。&lt;/p&gt;&lt;p&gt;Ultron系统的主要业务方包括AI、广告等部门。业务方在使用Ultron时，仅需要写很少的Python代码来定义一个DAG格式的数据流，定义数据源类型和节点之间的依赖关系。之后剩下就是纯页面化操作。目前我们使用内部的git进行项目管理，将一个数据流所需的资源和Python定义文件按照约定结构推送到git后，在我们的平台上以git链接的方式去初始化一个数据流，接下来就是在页面上配置各个节点和数据源相关的配置或参数等等。配置过程中，为了减少平台用户的繁琐操作，我们还打通了数据源和元数据系统的关系，直接获取对应数据源的schema，而无需手动填参定义。&lt;/p&gt;&lt;p&gt;配置好数据流后，平台用户可以一键拉起整条数据流，也可以在数据流运行过程中修改单个节点配置后重启这个节点，而无需对整个数据流进行重启操作。也可以很方便地一键操作复制整个数据流，形成一条新的实验流，极大减少了用户的时间成本和学习成本。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4842593&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1BMf5Ir754SpdhLmEuPfmotDyBMMIGXicia9IXYR42KWFhibWXLeIJyfIpT6lZTG8SqB5kt4niaYC8koRKoRg4zcSw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;2.3 第三阶段&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;从第二阶段的工作可以看出，我们对AIFlow有了比较深入的理解，相对应地，为了适配我们的业务，也是做了很多的开发工作，这其中也包括了一部分对AIFlow源码的魔改。我们和AIFlow社区团队也是保持了定期的交流，也是愈发发现我们魔改的AIFlow版本和社区近期release的版本差异越来越大。主要有几方面的原因：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;1）我们在内部数据产品形态上花了比较长的时间，底层AIFlow相关的部分在稳定性和性能满足要求后大的改动比较少；&lt;/p&gt;&lt;p&gt;2）我们在第二阶段迭代时，依然使用了早期的架构设计，使工作流的提交、编译、部署等全部过程都在Server端实现，随着业务量的增长，这种单体式的系统设计不方便横向扩缩，存在着性能瓶颈的风险；&lt;/p&gt;&lt;p&gt;3）对AIFlow魔改过多，不方便底层AIFlow随着社区版本升级。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;那么基于以上考虑，我们开始了第三阶段的工作，这也是我们目前正在进行的内容。&lt;/p&gt;&lt;p&gt;最核心的是，减少对AIFlow源码的魔改，所以我们决定对工作流引擎层进行重新设计，将编译工作流和调度工作流的过程分离，分为Client端和Server端。Client端负责与WebServer进行RPC交互，提供对外的访问接口，同时负责将业务信息翻译成AIFlow可识别的标准Project结构，也就是编译过程；Server端几乎与AIFlow完全一致，只是出于B站技术环境的因素，做了一些简单的容器化改造，比如使配置能适应服务发现，增加了几个BlobManager，将原本的RemoteOperator改造为标准的AIFlow可识别的Plugin等。这也得益于AIFlow社区同学对AIFlow不断地迭代，使得绝大部分与业务相关的功能都能够通过插件形式加载到系统中，而无需对源码做过多修改。这样改造后，Client端会彻底无状态化，可以方便扩缩容，承载更高的并发度，而Server端仅修改了极小部分的源码，后续版本升级也会非常方便。&lt;/p&gt;&lt;p&gt;下图是我们在第三阶段时的系统架构图。途中蓝色区域是AIFlow原生的组件和功能，绿色区域是我们在AIFlow提供的接口上做的Plugin拓展和自定义的一些业务代码翻译组件。紫色区域是数据产品层面的一些组件功能。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6191489&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1BMf5Ir754SpdhLmEuPfmotDyBMMIGXicv4HPqDMjyb9ib6M3at7ibN6ZSbrlYicqgqiaHOPNT9miczb3mshaY2u8JmA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;940&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;3. 流批融合&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们在进行实时特征计算的时候,一个非常大的诉求就是特征回溯,对于长时间窗口的特征，业务是很难等到在累积到足够时间的数据之后才开始使用，因此希望使用离线的历史数据进行特征填充，但是离线的数据在hdfs上，基于hdfs有两种计算方案，第一种按照实时的逻辑开发一套离线特征的计算，专门用来做数据回补，第二种是直接把离线的hdfs数据，灌到实时计算的流程里面，但是需要解决时序问题，实时数据本身就隐含了时序特性。在考虑到换引擎开发任务的巨大成本，我们决定基于第二种方案来做特征回溯，流批数据使用一套计算逻辑。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1BMf5Ir754SpdhLmEuPfmotDyBMMIGXicsmPaiclpibuJCR2WPuyta3MLN280Ty3oduibF8B5UJDjzTS7eTYHH4UeQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;3.1 流批融合的问题&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;第一是如何保证数据的顺序性。实时数据有个隐含的语义就是数据是顺序进来的，生产出来立马处理，天然有一定的顺序性。但是离线的 HDFS 不是，HDFS 是有分区的，分区内的数据完全乱序，实际业务里面大量计算过程是依赖时序的，如何解决离线数据的乱序是一个很大的问题。&lt;/p&gt;&lt;p&gt;第二是如何保证特征和样本版本的一致性。比如有两条链路，一条是特征的生产，一条是样本生产，样本生产依赖特征生产，如何保证它们之间版本的一致性，没有穿越？&lt;/p&gt;&lt;p&gt;第三就是如何保证实时链路和回溯链路计算逻辑的一致？这个问题其实对我们来说不用担心，我们是直接在实时链路上回溯离线数据。&lt;/p&gt;&lt;p&gt;第四是一些性能方面的问题，怎么快速得算完大量的历史数据，这块我们在计算过程中做了大量的异步和预加载工作。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;3.2 流批融合问题的解决方案&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们重点讲下上面问题1和问题2的解决方案。&lt;/p&gt;&lt;p&gt;针对第一个问题，为了数据的顺序性，我们 HDFS 的离线数据进行 kafka 化处理，这里不是把它灌到 kafka 里面去，而是模拟 kafka 的数据架构，分区并且分区内有序，我们把 HDFS 数据也处理成类似的架构，模拟成逻辑上的分区，并且逻辑分区内有序，Flink 读取的 hdfssource 也进行了对应的开发支持这种模拟的数据架构。这块的模拟计算目前是使用 spark 做的，后面我们会改成 Flink。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5592593&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1BMf5Ir754SpdhLmEuPfmotDyBMMIGXicEibEmEvpnrPMgWv1lcH1zDLTtryp7Vcg2dQuGvIco0boSOe2ibTic0JUQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;第二个问题分为两部分,第一个实时特征部分的解决依赖于 Hbase 存储，Hbase 支持根据版本查询。特征计算完后直接按照版本写入 Hbase，样本生成的时候去查 Hbase 带上对应的版本号即可，这里面的版本通常是数据时间。&lt;/p&gt;&lt;p&gt;第二个离线特征部分，因为不需要重新计算了，离线存储 hdfs 都有，但是不支持点查，这块进行 kv 化处理就好，为了性能我们做了异步预加载。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3925926&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1BMf5Ir754SpdhLmEuPfmotDyBMMIGXicRgl1vAv7K48NWnFw5V7Yfx4MeEUzgdIRw7w7UJxmhkbDyBqVI8zIaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;4. 展望&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;基础架构上我们会继续在基于AIFlow的实验流平台上继续努力，解决当前依然存在的几个问题：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;1）目前受限于Server端底层使用了基于Airflow2.0改造的EventSchedulerJob，所以在高可用方面也是收到了数据库锁的影响，目前尚不支持。不过AIFlow社区已经在开发改造中，估计下一个release版本就可以支持调度器的高可用特性。&lt;/p&gt;&lt;p&gt;2）我们另外考虑的一个比较重要的点是，希望可以通过AIFlow无缝兼容Airflow2.0的任务。在B站内部目前还有若干个Airflow调度的集群，大部分场景是和机器学习都是有关联的，随着流批一体的逐步成熟，我们在AIFlow中看到了可以兼容Airflow2.0的可能性，当前我们正在推进原生Airflow调度任务向2.0兼容的版本迁移，在后续第三阶段的工作内容中，我们也会不断推进AIFlow和Airflow工作流的融合进程。&lt;/p&gt;&lt;p&gt;3）后续我们希望拓展AIFlow在pyFlink和Alink方面的应用，增加更丰富的流式机器学习算子，也会积极拓展Ultron在特征管理等方面的能力。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;流批融合上我们会继续探索flink batch能力在特征回溯上的应用，做到真正的流批一体，在batch的基础上也能提升特征回溯的效率。&lt;/p&gt;&lt;p&gt;B站目前基于AIFlow的机器学习工作流平台已经在线上承接了AI部门推荐相关的大部分流式计算任务，广告相关的业务也在推进中。从目前来看，AIFlow对流批一体的支持比较好，对于流触发批，批触发流，流到流，批到批都做到了比较好的抽象。后续我们也会不断探索新的解决方案来满足我们在机器学习方面的一些典型场景。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;点击阅读原文或以下链接，获取更多 AIFlow 相关资料：https://github.com/flink-extended/ai-flow&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;钉钉扫描下方二维码加入 AIFlow 用户钉钉交流群，了解框架最新功能及相关原理。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.32&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1BMf5Ir754SpdhLmEuPfmotDyBMMIGXicicC0JfQgC9tliaFpS79waia2gvBtLraf5n0FhwHMAd5ga6GwSYFUyKNiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;hr/&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>