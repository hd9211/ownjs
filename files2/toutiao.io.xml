<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>ff0ec71eb06a7364ed41de60eb86c2e6</guid>
<title>亿级流量架构演进实战：从零构建亿级流量 API 网关（二）</title>
<link>https://toutiao.io/k/56161ss</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p id=&quot;js_tags&quot; class=&quot;article-tag__list single-tag__wrp js_single&quot; data-len=&quot;1&quot; role=&quot;link&quot; aria-labelledby=&quot;js_article-tag-card__left&quot; aria-describedby=&quot;js_article-tag-card__right&quot;&gt;
                                            
                                                                                    &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__left&quot; class=&quot;article-tag-card__left&quot;&gt;
                                    &lt;span class=&quot;article-tag-card__title&quot;&gt;收录于话题&lt;/span&gt;
                                    &lt;span class=&quot;article-tag__item-wrp no-active js_tag&quot; data-url=&quot;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI3MDU5OTU0MA==&amp;amp;action=getalbum&amp;amp;album_id=2087433865563832322#wechat_redirect&quot; data-tag_id=&quot;&quot; data-album_id=&quot;2087433865563832322&quot; data-tag_source=&quot;0&quot;&gt;
                                        &lt;span class=&quot;article-tag__item&quot;&gt;#亿级流量架构演进实战&lt;/span&gt;
                                    &lt;/span&gt;
                                &lt;/span&gt;
                                &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__right&quot; class=&quot;article-tag-card__right&quot;&gt;2个&lt;span class=&quot;weui-hidden_abs&quot;&gt;内容&lt;/span&gt;&lt;/span&gt;
                                                                                        &lt;/p&gt;

                
                                
                
                

                
                                                                

                
                                


                
                
                
                
                                                
                                                                
                                
                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;这不是一个讲概念的专栏，而且我也不擅长讲概念，每一篇文章都是一个故事，我希望你可以通过这些故事了解我当时在实际工作中遇到问题和背后的思考，架构设计是种经验，我有幸参与到多个亿级系统的架构设计中，有所收获的同时也希望把这些收获分享与大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;承接上篇，统一了接口之后并没有彻底改变被客户端碾着走的局面，因为还有一个根本的点没有被解决，就是网关对上游服务的适配问题，说白了就是每当上游有一个新的 API 要发布，网关都需要进行开发适配，我们曾经出过一个 API 标准接入的解决方案去推动上游去改造，不过遇到了很大的阻力。这个痛点直到网关实现了 API 的服务泛化调用之后才有所突破，功能一经上线，API 发布在网关就不需要再适配一行代码，完全解耦了网关与平台的业务逻辑，使网关的效能得到释放。不过，内部协议直接被转化成外部协议使得 API 在定义和格式上变得晦涩难懂和似乎不受控制，而且上游 API 的变更让网关很难处理兼容性问题，这就是所谓的有得必有失吧。再后来随着开放平台、共建生态迎来了大潮，这时已经是2015年了，我们又反客为主迅速推动上游进行 API 标准化的接入和改造，这只能说之前网关更关注 API 接入的效率，后来更关注 API 接入的质量。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;1。泛化调用&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;泛化调用在当时起到了非常重要的作用，虽然现在已经很少在网关直接粗暴的提供泛化调用的 API，但是泛化调用在其它地方有了更广泛的应用，比如 API 测试等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下面我们就结合着泛化调用来说下网关服务调用的那点事，回顾上文我画的一张 API 网关的架构示意图。首先，泛化调用是网关服务调用组件提供的一种服务调用方式，而整个服务调用概括的讲主要有路由寻址、协议转换、分发调度三个步骤。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3925925925925926&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/FAeR52xeN391DpyUN48jy9BsjXmbZ31icqiaYUn6A9SXSxweIicnOOeHqztpF5ascdgVaDqjMFIJYqgMLQ2tuF20Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;br/&gt;&lt;/h2&gt;&lt;h2&gt;&lt;span&gt;1.1 路由寻址&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;一个 API 请求在调用上游服务之前，首先要通过请求方法名进行上游服务的路由寻址，寻址包括上游服务端的接口名、方法以及分组。具体来讲，网关会通过请求方法名在内存路由表中去寻找对应的服务实例地址，如果没有找到，就会去 API 元数据库中读取配置并完成服务的实例化。这是因为网关的泛化调用是一种基于配置的实现方式，所有 API 的方法和参数都以配置的方式存储在元数据库中。所以，这类 API 服务在网关是一种动态实例化的方式，它不是在服务端启动时就初始化好的服务，而是一种懒加载的方式。&lt;/p&gt;&lt;p&gt;在 API 服务初始化的时候我曾有过这样的设计考量，API 服务是否可以改成配置发布加载的方式？之所以没有这么做，主要因为 API 实在是太多了，有很多 API 都没有被调用过，另外就是1～2次调用 API 只会被初始化在少量的 API 网关上，对整体而言也不会有太多的资源占用。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;1.2 协议转换&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;在获取到对应的服务地址之后，就需要对请求参数进行协议的转换和解析。当时在没有泛化调用之前，网关依赖上游提供二方包，并需要依据二方包的接口定义，才能完成请求参数的解析与协议的转换。而在有了泛化调用之后，网关可以不依赖于上游服务提供的二方包，就可以进行协议转换了，这是因为泛化调度在实现上采用了反射和动态代理的方式。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;1.3 分发调度&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;泛化调用不仅可以去掉对上游二方包的依赖，网关还在泛化调用的基础上实现了一套通用协议的适配模型，基于代理模式实现对上游不同服务的分发调用，解决了之前每个服务在网关都需要开发一套适配逻辑的实现。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;1.4 配置中心&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在网关实现了统一接口和泛化调用之后，服务端似乎进入开挂的时代，主要是彻底释放了服务端的研发效能，需要哪个 API 客户端去配置一下就好了，不过好景不长，此时网关已经进入了深水区，出现的问题就比较难解决了。接下来面对的就是 API 元数据的即时更新问题，由于泛化调用是依赖于配置的，所以当配置变更后，就需要对网关的服务实例进行重新初始化，所以为了解决这个问题，一个网关 API 元数据配置中心的系统就这样诞生了，以下简称为配置中心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.359375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/FAeR52xeN391DpyUN48jy9BsjXmbZ31icHj22UIQfhkkBw2d65yMc6BRsxibTBDVkEDcNe9CvUnkCkUaGj1zPsBw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;配置中心的演进主要有3个版本，第一个版本是定时检查数据库变更配置的处理方式，第二个版本是消息广播变更配置的处理方式，第三种是基于 Zookeeper 监听配置的处理方式。下面我们就逐一来看下这三个不同版本的实现方式。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;v1 定时检查数据库变更配置&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;其实无论哪个版本都是采用数据库作为元数据的持久化存储的，不同之处主要是在触发网关进行服务重载的机制不同。&lt;/p&gt;&lt;p&gt;由于泛化调用是一种懒加载的实现方式，所以只有当一个请求需要获取元数据信息时，网关才会去查询元数据库，并将获取到的配置信息缓存到网关的内存中，同时进行服务实例的初始化。而当数据发生变更时，网关是如何感知到配置变更的呢？所以网关采用的是线程轮训的方式，通过对比数据进行判断，如果对比数据不一致，就进行服务实例的重载，如果一致，就不做任何处理。不过，这个方案有个硬伤，就是即时性的问题，由于线程轮训的间隔不能过快，以防止对数据库造成不必要的压力，而且，元数据库变更也不会很频繁，过于频繁的轮训也是一种资源的浪费，所以，我们设置的时间间隔大概是10分钟，当然，网关只有一个轮询线程，不是每个 API 都有一个。&lt;/p&gt;&lt;p&gt;除了线程轮训的方式，我也思考过有没有别的方式，比如使用缓存定时过期的方式，缓存过期了就去数据库里查询一次，Guava 的 LocalCache 就可以实现多种本地缓存策略 ，不过这种方式比较适合在防止热点数据穿透缓存的场景里，在网关里缓存过期了是要与服务重载相关联的，所以什么场景下网关去检查缓存是否过期了，这之间并没有建立起直接的关系，总不能每调用一次接口就去检查一下缓存吧。而且缓存穿透本身也是有风险的，尤其是冷数据加载，可能直接将下层的数据库打爆，这种方式造成的线上问题也是屡见不鲜。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;v2 消息广播变更配置&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;后来我们又上线了一版消息广播变更配置的版本，改造点是网关的配置中心客户端里将线程轮训的方式替换消费 MQ 的方式，MQ 是在配置中心 OPS 里变更配置时进行生产，以广播的方式发送给网关所有实例。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;v3 基于 Zookeeper 监听配置&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;再后来终于迎来主流版本 —— 基于 ZooKeeper 构建配置中心的实现方式，ZooKeeper 是一个分布式的协同系统，它有很多优势，比如，基于树型的存储方式、分布式的部署架构、Leader 选举机制、基于长连接的双向通道等，我还是比较推崇它的。&lt;/p&gt;&lt;p&gt;基于 ZooKeeper 的 Watcher 特性，我们把网关的 API 配置信息存到 ZooKeeper 节点里，在网关的配置中心客户端加载到 API 服务后，就去订阅 Zookeeper 中对应节点的数据变更事件，当 ZooKeeper 数据节点变更后，ZooKeeper 就可以以事件驱动的方式通知到网关实例，从而进行配置变更和服务重载。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;如何解决配置中心的一些小问题？&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;其实在整个演变过程中，除了技术选型有了大的调整外，在细节方面我们也&lt;/span&gt;在&lt;span&gt;不断优化，与线上的各种小问题进行坚持不懈的斗争。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;小问题1：首次获取配置失败&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;为什么强调一下首次，因为重启服务器就会造成内存数据的丢失，网关就需要去配置中心重新获取配置，这就是首次获取，不过这时如果获取配置失败了，网关就尴尬了。所以为了应对异常情况下可能无法获取到配置信息的情况，最开始的解决办法是接口调用时传入一个默认值，在异常情况下会返回默认值，简单又有效。不过这种方式在某些场景下，又往往会产生一些意想不到是小事故，我说的就是那种有新老流程需要切流而设置的开关场景，默认配置设置为 false 走老流程，可是在逐步切流完成之后，这个配置开关和老流程并应该被遗弃，而是由于各种原因活了下来，随后又随着各种演进，老流程逐渐变成了僵尸代码，然后某一次重启一个网络抖动就把系统的僵尸炸醒了，紧接着报警就想起了，而这种情况，我还真的遇到不止一次。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.33125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/FAeR52xeN391DpyUN48jy9BsjXmbZ31ic1nzoKJl7osziaib4KTzwQiaYoXOkstpglUwZQ168QrXV4ZrxjGOHfL7cg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;所以，后来在配置中心客户端里做了一点过度的设计，为啥说是过度，因为废弃的代码还是要删掉的，不能指望着别人去保障你的业务。所谓的过度设计其实只是增加了通过本地 Properties 文件对配置数据进行落地存储的容灾策略，其策略是服务器重启后，如果无法从 ZooKeeper 获取配置后，就从本地 Properties 文件获取上一次的配置数据进行加载，如果也无法从本地 Properties 文件获取配置，才返回设置的默认值。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.36796875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/FAeR52xeN391DpyUN48jy9BsjXmbZ31icaqsxCDbQCb5oCiaMOZhiahedH4OUXKoRaichwpy4bFAenjGKZB3qafQZg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;这里再说下在 v1 基于数据库通过线程轮询的实现方式里，网络抖动导致大量回源查询，如果查询没有设好超时时间和重试次数，就可能会产生大量的异常日志和线程阻塞，严重的还会把服务器拖死了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;小问题2：更新配置失败了&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;这里的更新失败不是指数据库更新失败，而是指发送 MQ 或写 Zookeeper 失败，这里提醒一下，千万不要把这步操作放到数据库事务里，否则一个网络抖动你的数据库可能就死了，这样写的我看到过好几例。大多数场景下配置中心都是要一定先数据库成功后再进行别的操作，这里我们取了个巧，就是先发送 MQ 或写 Zookeeper 然后再保存数据库，因为这里的每个操作都是幂等的，而且数据保存失败了也容易识别出来，所以即使数据库保存失败进行了重试，对 MQ 和 Zookeeper 也不会有任何影响。&lt;/p&gt;&lt;p&gt;之前曾考虑在保存操作完成后在后端启动一个线程，对两个数据源的数据进行校对，如果不一致就进行订正，订正成功就结束线程，订正失败的话，就短暂休眠，然后继续订正。对比来看，这种实现方式就已经有些复杂了，更别说分布式事务了，所以一个先后策略的调整就可以解决的问题，不一定非要把系统做的很复杂，这在我后来的架构修炼之路上，遇到过很多这样的情况，大道至简方是王道。&lt;/p&gt;&lt;p&gt;再后来随着微服务框架的逐步完善和成熟，配置中心已经有越来越的产品被推出，比如 spring cloud config、diamond、apollo、disconf 等等，而不必要自己去开发了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;3。总结&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;言而总之，本篇文章重点讲述了流量调度的配置中心、泛化调用。下篇文章，我将继续介绍架构演进构建TCP长连接网关。如果你觉得有收获，欢迎你把今天的内容分享给更多的朋友。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;4。扩展阅读&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;故事1：从零构建亿级流量API网关&lt;/strong&gt;&lt;br/&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3MDU5OTU0MA==&amp;amp;mid=2247484496&amp;amp;idx=1&amp;amp;sn=30a3646447bf11623a0467edb1902b67&amp;amp;chksm=eacfd04bddb8595d6d4f94fa44733d887a7dd1b747ddf16c1b4d157daba375d0fce8304d0d82&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;01 | API网关：统一接入、分层架构、高可用架构&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;01 | API网关：统一接入、分层架构、高可用架构&lt;/a&gt;&lt;br/&gt;02 | 流量调度：配置中心、泛化调用&lt;/p&gt;&lt;p&gt;&lt;strong&gt;故事2：架构演进构建TCP长连接网关&lt;/strong&gt;&lt;br/&gt;03 | TCP网关：Netty框架、Protobuf格式、业务线程池&lt;br/&gt;04 | TCP长连接：心跳、Session管理、断线重连&lt;/p&gt;&lt;p&gt;&lt;strong&gt;故事3：架构演进重构消息PUSH系统&lt;/strong&gt;&lt;br/&gt;05 | 消息PUSH：消息推送、消息送达率、APNs&lt;/p&gt;&lt;p&gt;&lt;strong&gt;故事4：从焦油坑爬出来的交易系统&lt;/strong&gt;&lt;br/&gt;06 | 交易平台：订单管道、订单状态机、服务编排、任务引擎&lt;br/&gt;07 | 微服务化：服务治理、领域设计&lt;/p&gt;&lt;p&gt;&lt;strong&gt;故事5：烦人的焦油开始到处都是&lt;/strong&gt;&lt;br/&gt;08 | 新老系统：业务整合、数据融合、系统迁移&lt;br/&gt;09 | 高可用架构：隔离部署、系统监控与日志、可灰度、可降级&lt;/p&gt;&lt;p&gt;&lt;strong&gt;故事6：稳定性架构与大促保障&lt;/strong&gt;&lt;br/&gt;10 | 大道至简：系统复杂度、三明治架构&lt;br/&gt;11 | 大促保障：自动化测试、故障演练、性能压测&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>17603399ee4dca547a9cbdf2617741c2</guid>
<title>深入理解云原生下自适应限流技术原理与应用</title>
<link>https://toutiao.io/k/7iizpj1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;作者简介：乔卓越，于19年毕业，热爱开源，乐于思考。拥有基础架构和游戏领域的一线开发经验。独立负责过大规模后端服务的开发与性能测试平台搭建。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;前言&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;本文将深入讨论现今后端服务关于负载的测量、优化、治理手段，通过对比分析TCP-BBR技术核心痛点，进而带读者尽可能理解并掌握自适应限流技术。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;背景&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;负载（load)，通常与并发关系密切。对于后端服务而言，任意时间内的并发用户访问都会提升服务负载，进而进一步消耗计算资源。然而计算资源是有限的，如CPU、memory、network等等，过载将会导致服务性能下降，进而回复滞缓甚至不可用。描述服务应对日益增长的负载的能力称之为&lt;strong&gt;Scalability&lt;/strong&gt;， 即可伸缩/扩展性。以下是DDIA（Designing Data Intensive Application）中的解释：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Scalability is the term we use to describe a system’s ability to cope with increased load&lt;/p&gt;&lt;/blockquote&gt;&lt;h1&gt;&lt;span&gt;测量负载&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span&gt;负载的具体指标&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;为了提升可扩展性，我们第一步要做的是固定资源下对服务请求接口进行测试，进行服务能力上限评估以及相应优化。显然，单纯将并发用于对负载的测量是不够具体的。对于后端服务，我们会进一步关注以下两个指标。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;负载因子(load parameter)&lt;/span&gt;&lt;/h3&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000010&quot; data-ratio=&quot;0.3372093023255814&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWycU1yRW5JCEshmuDluf2GIMsBbvgS0GwnDNEdNzbG9TWxhqDGWSMFQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;430&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;本服务中最能引起现负载增加的指标&lt;/strong&gt;。对&lt;/span&gt;于&lt;span&gt;web服务而言，显然就是每秒请求数QPS；&lt;/span&gt;&lt;span&gt;对于数据库等服务来说，可能就是读写率的上升。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;关键结果(performance number)&lt;/span&gt;&lt;/h3&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000011&quot; data-ratio=&quot;0.2920892494929006&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWPiag2IxibSxnNO7ZdB7IibzCApib8ZZVzrYUwPKp00TGeOzAsjoKRLEZZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;493&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;本服务负载增加时最需要关注的指标&lt;/strong&gt;。对&lt;/span&gt;于&lt;span&gt;web服务而言，显然就是用户的等待时间即respond time/latency；&lt;/span&gt;&lt;span&gt;对于数据库等服务来说，就是对吞吐率的影响。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;性能观测&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;以web服务为例，我们通过增加请求数来收集对应的时延消耗如下图。其中X轴表示请求的数量，Y轴表示对应消耗的时间。其中，每次请求所消耗的时间通过灰色柱如所示。从实践经历来看，同类型的请求每次消耗的时延会受到多种因素的影响，因而都不是固定的。（后文会详细解释）&lt;/p&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000014&quot; data-ratio=&quot;0.28&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWlAXOFCc8lHWZzqrf27lLcoQyib1I2Seicw2xt4RymLm7rDc1RBcOhAHA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1225&quot;/&gt;&lt;/figure&gt;&lt;p&gt;所以，单纯将总请求数/总耗时的平均结果不具代表性。为此业内广泛使用百分位数，又称水位线来表示用户实际经历的时延情况。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;p &lt;code&gt;N&lt;/code&gt; th&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;其中N表示百分比，例如图中95th，又称95线。假设95线对应的时延为1.5s，总请求数为100， 那么&lt;strong&gt;p95&lt;/strong&gt;就表示在100个请求中有95个请求的时延小于1.5s。&lt;/p&gt;&lt;p&gt;在大型后端服务中，工程师会更倾向于关注高水位线如99th下的时延分布，因为这是最直接对用户产生影响的&lt;strong&gt;关键结果&lt;/strong&gt;。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;定位优化&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;通过水位线获得的时延分布可以针对性的优化相应接口逻辑，以尽可能减少业务层导致的延迟较大的问题。如优化代码数据结构、缓存部署、数据隔离以提高命中率等等。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;资源与性能瓶颈&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;请求时延的增高不仅与业务逻辑有关，在有限的硬件资源下(cpu、memory、带宽)，负载升高同样会进一步影响用户请求时延。在对预期正常流量下的请求表现出的时延进行业务优化后，我们还需要对服务进一步压测以至&lt;strong&gt;过载&lt;/strong&gt;情况下服务对请求的响应情况，尽可能找出负载上限，保护服务。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;压测视图&lt;/span&gt;&lt;/h3&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000012&quot; data-ratio=&quot;0.6028571428571429&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWX7l4jPnpkzAzwbY2QnDTb2ggyM84hxGXMB1Des0Tt0tO1m1TvqVrgQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;700&quot;/&gt;&lt;/figure&gt;&lt;p&gt;当我们使用压测工具一步步加大强度时，关于负载各项指标的宏观理想变化基本如上图所示。其中&lt;strong&gt;红色曲线&lt;/strong&gt;表示每秒请求被处理的用户数TPS（throughput per second），&lt;strong&gt;蓝色曲线&lt;/strong&gt;表示对应请求时延，X轴表示QPS量。&lt;/p&gt;&lt;p&gt;可以直观的看出：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;初始阶段&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;随着QPS的上升，TPS也在逐步提高，时延相对稳定。因为此时CPU和内存等计算资源相对充裕，请求在系统中无需排队就可以处理。&lt;/p&gt;&lt;ol start=&quot;2&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;瓶颈阶段&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;当QPS加大到对应TPS曲线顶点附近时，此时计算资源负载接近满额，服务中的请求处理出现排队情况，时间非线性上涨。&lt;/p&gt;&lt;ol start=&quot;3&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;过载阶段&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;此时进一步加压QPS，计算资源超额负载，进一步导致GC、进程调度、网络等资源压力导致TPS迅速下降，同理请求排队过长导致时延进一步类指数级上升，最终导致服务资源耗尽出现宕机无响应等情况。&lt;/p&gt;&lt;p&gt;直观来看，由于固定计算资源的限制，当QPS加压超过TPS峰值时系统的处理能力会被反噬。从服务保护、资源利用的角度，我们会认为&lt;strong&gt;将TPS顶点附近值作为对QPS的限制阈值&lt;/strong&gt;相对理想。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;过载保护&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;本节将着重介绍基于具体阈值的限流办法以及相关的局限性，提出服务稳定前提下的核心预期。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;基于QPS阈值的限流&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;在很长一段时间内，工程师都会采用上述阈值作为服务的兜底QPS限制以防止过载。此时就出现了优秀的限流算法，即令牌桶（Token-bucket）和漏桶（leak-bucket）以及众多衍生。&lt;/p&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000013&quot; data-ratio=&quot;0.2898120672601385&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWIyQyxT3uDiaMMLtkMmdj1WxoHSENFBtSAd5EHHDFey94uWjhr7jBOoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1011&quot;/&gt;&lt;/figure&gt;&lt;p&gt;互联网上关于这两种算法原理的介绍多如牛毛，在这就不再赘述。总的来说，桶算法对流量提供了整形的功能，以防止瞬时流量等极端情况打垮服务。在小规模后端服务而言基于阈值的限流方式简单高效，能够应付绝大多数问题。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;基于具体阈值的局限性&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;上节在进行阈值测量时，对测试的整体描述为&lt;strong&gt;理想情况&lt;/strong&gt;下。这意味着在大规模分布式系统中，测量结果从工程的角度忽略了很多必要细节。这其中包括测试方式、硬件资源配额、线上scale、服务环境、阈值可用性等等众多情况。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;测试之痛&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;现如今后端领域已经进入了云原生时代，微服务架构早已经是事实标准。其中通讯方面是以典型的事件驱动方式（Event-driven），这表示所有的请求都是通过RPC即以接口调用的方式实现的。一个合理划分的微服务，在稍具规模的情况下拥有的接口数量保守估计至少是在十位数以上，因此对接口级别、服务级别的阈值获取将变得相当繁琐和困难。在Netflix的技术博客中，他们使用&lt;code&gt;arduous task&lt;/code&gt;来形容测试的艰巨。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;接口压测&lt;/p&gt;&lt;p&gt;如前文提到的，即使是同一个接口，每轮压测的结果也会有差距。这是因为机器资源在测试中同时会受到垃圾回收、线程/进程资源抢占、磁盘I/O抖动、网络带宽质量等因素的影响。在服务级别的测试、线上环境中，此类问题会被进一步放大。为此，测试人员不得不多次测量求个均值以求准确。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;服务级压测&lt;/p&gt;&lt;p&gt;不同接口显然对资源的消耗程度不同，因其包含读、写、下游扇出等各种情况时延也会产生差异。对于服务级别的限流阈值确定可以说是相当困难，因为基于接口级的阈值组合会在不同用户请求不同接口时产生波动。为此进行流量录制并全链路压测虽能够阈值的范围，但仍无法做到精准，且成本过大。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;维护之痛&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;所有测试以及线上环境中，最关键其实是计算资源的配置。所测试机器的CPU核心数和内存等配置时刻影响着测试结果。再者，如今基于容器网络如k8s的自动资源scale能力，会使得基于具体数字的阈值设定难以维护。再者，秒级的流量限制显然对于100ms内突发流量洪峰无法做出有效干预，导致服务异常过载。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;干预成本&lt;/p&gt;&lt;p&gt;当无论遇到线上激增流量机器指标异常、自动扩容等导致阈值不再适用，进而要增加或者减小时，工程师从发现问题到上机操作发布配置的耗时已经错过了干预的最佳时机。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;认知负担&lt;/p&gt;&lt;p&gt;从上述测量流程来看，工程师必须对计算资源、接口业务、容器配合、调度时机等各方面有足够认知才能应对各种流量突发状况，显然会消耗大量的精力和时间。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;综上所述，基于具体数字的阈值方式在大规模后端服务中会进一步捉襟见肘，可延展和可伸缩性较差。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;过载下的服务预期&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;在讨论进一步的解决方案之前，我们要明确在负载加大时对服务情况的&lt;strong&gt;预期&lt;/strong&gt;。即在使服务不垮掉情况下，充分利用计算资源服务用户。结合具体的负载因素预期如下：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;尽可能多的处理request，即高TPS&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;尽可能快的处理request，即低时延&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;尽可能使得request不产生堆积，当前计算资源下存在的最佳处理量&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000015&quot; data-ratio=&quot;1.0561797752808988&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWTWjmlYC72GjXYdwrqm6IDtY1bxDfmoFjbzS5piaEWANKV6BnMrLeKibg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;445&quot;/&gt;&lt;/figure&gt;&lt;p&gt;很明显，想要同时获取上述指标是相悖的。对于高TPS，意味着尽可能要将计算资源利用，请求产生拥塞进而导致&lt;strong&gt;关键结果&lt;/strong&gt;——时延的指数上升；对于时延，那么就尽可能需要服务中处理的请求相对宽松。虽然时延低下来了但同时TPS也会很低，造成计算资源的浪费；对于服务进程中的请求最佳处理量，结合各种变化因素也不好确定。那么有最佳的解决办法吗？&lt;/p&gt;&lt;h1&gt;&lt;span&gt;传输层自适应拥塞控制&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;本节将引出传输层TCP-BBR算法要解决的问题，以及和我们上述服务预期问题的同质性。进一步挖出共通点。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;传输层TCP现状&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;TCP是面向字节流保序的传输层协议。在面对未知的网络中转节点以及对端网络状态，如果最大化利用网络带宽是其要面对的首要问题之一。为此，应运而生了经典的拥塞控制算法。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100000020&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5072869955156951&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWlopuLiaIy1y6U6vFyMhpAgpgIGzfSDib2Qv9x4N4m4FMAiaDdev6SQOdQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1784&quot;/&gt;&lt;/p&gt;&lt;p&gt;上图是传统的基于丢包检测的拥塞控制算法，代表有CUBIC、RENO等实现。详细解析已经超出本文的讨论范围，此处简述基本原理以及其核心特点。其控制周期基本上有四个组成部分，分别是慢启动、拥塞避免、快重传、快恢复。其中CWND表示拥塞窗口，也就是可以向网络中一次性发送的数据量，最终窗口大小由其与对端接收窗口中的较小值来决定。&lt;/p&gt;&lt;p&gt;在不考虑对端窗口的影响下，由于网络状况未知，算法会依据不同状态针对性的加大CWND窗口的大小。当出现丢包时CWND大小会大幅度减小，如图中陡降部分所示。在后续的优化重传等策略之下，仍然能够看到当出现丢包时CWND的减幅程度十分明显。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;基于丢包的控制算法局限&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000016&quot; data-ratio=&quot;1.4430379746835442&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWXVo8AfCat3GTskZIVP3hTuCDhqGkEc4ibo5Y23CS0oV4qZVAibTEOWdQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;474&quot;/&gt;&lt;/figure&gt;&lt;p&gt;该类算法的核心思想在于对丢包数据的测量，然而在现代网络设施的发展下某些场景如长肥网络（高延迟、高带宽）等已经不再适用。结合上图，由于路由节点的buffer大小日益增长，同时增加了数据包在队列中等待时间。再加上多跳路由节点的计算、传输等能力的不同会很容易导致CUBIC等算法的认为丢包，采取锐减CWND窗口的行为。也就说当开始介入拥塞避免时，拥塞早已发生且会进一步负反馈导致吞吐下降。也就是说，基于检测&lt;strong&gt;丢包&lt;/strong&gt;信号这单一指标来衡量拥塞达不到最优解。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;基于真实的网络负载特点分析&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;显然网络拥塞的发生同样是由各个路由节点网络负载升高产生的，既然是负载，那么就需要对其具体负载指标的分析。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;负载因子&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;抛开网络拓扑现状的复杂性，能够首要引起网络负载升高的显然是网络流量的增加。那么，对应的指标就是网络&lt;strong&gt;Bps&lt;/strong&gt;（bytes per second），即每秒的数据传输量。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;关键结果&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;面对负载Bps的增加，会影响到的关键结果就是网络传输的往返时延&lt;strong&gt;RTT&lt;/strong&gt;（Round-trip time）上升，导致传输拥塞。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;传输观测&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;下图是理想情况下网络设备在传输过程中的负载变化图，上半部分为流量传输速度（Delivery rate&lt;span&gt;≈&lt;/span&gt;Bps）和对应时延（RTT）的变化，下半部分为对应网络设备的物理状态变化。分为三个阶段：&lt;/p&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000017&quot; data-ratio=&quot;1.3038167938931298&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWcumM4EDnMonLEmz0GibJcf4NgNL15LmB7lBtFdCJU1pRNZPRwnvicAhA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;655&quot;/&gt;&lt;/figure&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;初始阶段&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;初始阶段网络设备中的队列为空，数据包无需排队。随着发送速率的增加RTT保持稳定。&lt;/p&gt;&lt;ol start=&quot;2&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;瓶颈阶段&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;此时排队已经逐渐形成，设备的传输吞吐能力即带宽达到上限，保持稳定。对于RTT而言，由于排队的原因逐渐增加。&lt;/p&gt;&lt;ol start=&quot;3&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;拥塞阶段&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;此时网络设备的队列已经被流量完全打满，多余的数据包被拒绝，进一步导致RTT大幅上升。&lt;/p&gt;&lt;p&gt;从图中红圈标注的RTT和传输率折线图出看到，RTT在瓶颈阶段开始大幅度上升，传输速率在该阶段同样达到了瓶颈即带宽上限。可以看出，从此处开始拥塞就要发生了，然而基于丢包的拥塞控制算法反而在上述第三阶段才能够生效，这显然滞后太多了。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;最佳预期&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;从上述理想分析，我们相对确定出了在一波数据传输过程中RTT的下限，即minRTT；数据传输带宽能达到的上限 max BW（max bandwidth）。对于这两个网络层的负载指标，至今已经有了很成熟的衡量体系，在网络传输中其关系如下图所示。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100000021&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5852272727272727&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWMuQgib4DRGSbg6FB2hHHdkQNx8lYc2fWrBuX1hyFkF6zx8Z3aMv86Vw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;880&quot;/&gt;&lt;/p&gt;&lt;p&gt;我们可通过 &lt;strong&gt;网络节点每秒传输数据的能力&lt;/strong&gt;即带宽（bandwidth）&lt;strong&gt;乘&lt;/strong&gt; &lt;strong&gt;数据包在节点中的传输处理时间时延&lt;/strong&gt;（即latency&lt;span&gt;≈&lt;/span&gt;RTT）的结果作为网络上正在处理的报文数量，即&lt;strong&gt;带宽时延积BDP&lt;/strong&gt;。BDP决定了需要向网络中发送的数据包量。&lt;/p&gt;&lt;p&gt;综合上述，我们可以确定理想情况下向网络传输数据的最佳数量，即瓶颈期指标特征： &lt;code&gt;BestBDP = maxBW * minRTT&lt;/code&gt;&lt;/p&gt;&lt;p&gt;显然，我们应对负载的关键指标测量已经不仅要关注&lt;strong&gt;关键结果&lt;/strong&gt;，还与&lt;strong&gt;负载因子&lt;/strong&gt;进行综合。相对的，多年来基于丢包的拥塞控制算法都只关注了&lt;strong&gt;时延&lt;/strong&gt;这单一指标。&lt;/p&gt;&lt;p&gt;虽然有了理论预期，但同样出现摆在工程师面前的难题：&lt;strong&gt;如何在拓扑结构复杂，路由情况多变的网络环境中测得这两个指标？&lt;/strong&gt; 这个测试过程本质上和上节我们提出的业务负载预期指标相悖论如出一辙。那么该如何解决这一难题呢？接下来就是BBR登场的时刻。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;TCP-BBR算法&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;BBR（Bottleneck Bandwidth and Round-trip propagation time）是Google近年来提出的拥塞控制算法，诞生后大幅度提高了在高延迟等情况下网络传输的吞吐。从命名就可以看到带宽（Bandwidth）和往返时延（Round-trip time)关键字，在上述铺垫过程中，对应的就是&lt;strong&gt;maxBW&lt;/strong&gt;和&lt;strong&gt;minRTT&lt;/strong&gt;。对于多变的网络环境BBR大胆的采用了&lt;strong&gt;以预期公式驱动，实时交替探测两个负载指标的办法&lt;/strong&gt;，下文会对此详细解释。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;算法核心解读&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;BBR认为：既然网络多变，且最佳带宽和时延不好同时测量，那么就采取实时交替探测的方式。通过滑动窗口细粒度的交替收集一段时间内的每秒最大传输量和最小的RTT，通过计算就可以获得目前最佳的BDP。即 &lt;code&gt;BestBDP = BtlBw (bottleneck bandwidth) * RTprop (round-trip propagation time)&lt;/code&gt;&lt;/p&gt;&lt;p&gt;表示目前网络中的瓶颈带宽，也就是上节中的maxBW，是网络设施传输的上限。BBR会取得一段时间内滑动窗口的统计的最大BtlBw值作为参考。其测量方式简述为一段时间内的数据包总量除以他们所抵达花费的时间。&lt;/p&gt;&lt;p&gt;表示抛开任何外在噪音，如ack重发耗时，网络抖动等等导致RTT偏高情况。即在滑动窗口统计中的RTT最小值作为参考，其测量方式为数据包发送和回复耗时。&lt;/p&gt;&lt;p&gt;这指的是，在BBR工作期间内，已经发送至网络但是还是没有收到答复的数据包。也就说真实的，在网络设备里正在传输的数据量，即负载。有了预期公式计算出的BestBDP指导将RTprop与BtlBW相乘，BBR就可以得出&lt;strong&gt;当前时刻外界网络最佳的负载量与实际inflight的关系&lt;/strong&gt;。有了这样的简单的数值比对，算法就可以控制发包的最佳量以进行拥塞控制。&lt;/p&gt;&lt;p&gt;以下伪代码直观的体现了BBR算法在发包和收包时的处理逻辑。&lt;/p&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000022&quot; data-ratio=&quot;0.34957882069795426&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAW40LzBIIFgHmJEN63h1zstp3iaCC5NWctzsGS2CRsXu3tTUyula8VMrg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1662&quot;/&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000023&quot; data-ratio=&quot;0.5678670360110804&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAW1gZX0DKQzYVrWI5lmcgicdcTEmcNngE3uMuBvibhkoFibJBz5bEpGwDSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1444&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;算法组成&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;了解了核心的算法逻辑，接下来将简述其运作周期，进一步了解算法是如何充分利用未知网络设备传输能力的。算法运行状态主要分为启动阶段（Startup）、排空阶段（Drain）、带宽探测（ProbeBW）、时延探测（ProbeRTT)。同样，本文将不会阐述具体细节，具体细节可以参考文末的reference。我们回到核心关注点，BBR是如何探测以及适应当前网络设备传输能力的。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100000024&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.9152777777777777&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWmj5DUH8VOVtqnYVCjNicTgvUYZWQk8YJV7kibJucvzyricpX6v3kkKoDA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot;/&gt;&lt;/p&gt;&lt;p&gt;上图摘自google BBR论文，展示了在稳定网络传输节点下BBR算法中关键指标RTT、BW、inflight的变化图。其中灰色&lt;strong&gt;cycle gain&lt;/strong&gt;数组，相当于滑动窗口。其中每个元素装载了带宽探测时的增益系数，通过与当前最大BW相乘可以实现增加/减少向网络中的数据发送，从而实现适应未知网络传输能力目的；同理，对于时延探测，简单来说BBR同样会周期性的发送小体量数据包收集最佳RTT。&lt;/p&gt;&lt;p&gt;可见，基于预期的负载控制算法，即同时集合负载因子和关键结果的计算，相比只关注一个指标的实现方式在高吞吐场景下具备一定的优越性。同时，基于滑动窗口细粒度的动态探测极值，使得测量结果更具时效性与说服力。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;自适应限流算法&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;经过上面长篇大论的分析和讨论，我们终于到了本章最为核心的自适应限流算法介绍。目的在于找到应用层与传输层面对负载、过载情况应对措施的共同点，以及如何应用于后端服务。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;负载在传输层的同质性&lt;/span&gt;&lt;span/&gt;&lt;/h2&gt;&lt;p&gt;综合来看，传输层在面对网络负载的测量、治理、实施历程与应用层负载有很多共同点，如下表所示。&lt;/p&gt;&lt;section&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;br/&gt;&lt;/th&gt;&lt;th&gt;传输层&lt;/th&gt;&lt;th&gt;应用层&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;负载因子&lt;/td&gt;&lt;td&gt;Bps&lt;/td&gt;&lt;td&gt;Qps&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;关键结果&lt;/td&gt;&lt;td&gt;RTT&lt;/td&gt;&lt;td&gt;latency&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;加压负载因子时处理端表现&lt;/td&gt;&lt;td&gt;delivery Rate（带宽传输速率）上涨直至瓶颈&lt;/td&gt;&lt;td&gt;TPS上涨直至瓶颈，由于进程资源抢占等压力会进一步反噬下跌&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;加压负载因子时关键结果表现&lt;/td&gt;&lt;td&gt;RTT从理想稳定状态升高至瓶颈，伴随拥塞指数上升&lt;/td&gt;&lt;td&gt;latency请求等待时延理想情况下至瓶颈期处于稳定状态，伴随排队导致服务过载指数上升&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;核心预期&lt;/td&gt;&lt;td&gt;尽可能大利用网络传输带宽，即最大传输速率maxBW；最小的包等待RTT；不拥塞前提下最佳发包量BestBDP&lt;/td&gt;&lt;td&gt;尽可能多的处理请求，即高TPS；尽可能快的处理请求，即低时延；极可能充分的利用服务计算资源，不产生堆积的数量&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;核心需求&lt;/td&gt;&lt;td&gt;能够得到网络设施的最佳处理数据量，以避免拥塞且实现高吞吐&lt;/td&gt;&lt;td&gt;能够得到服务进程在当前计算资源下的最佳请求处理量，以避免请求排队资源抢占实现高吞吐，进一步保护服务防止过载&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;难点&lt;/td&gt;&lt;td&gt;无法同时测量最佳带宽和最低时延，基于复杂的网络拓扑和设施数量难以确定数值&lt;/td&gt;&lt;td&gt;无法同时测量最佳TPS和最佳latency，众多接口耗时不同，且包含进程GC、网络抖动、资源scale多变的情况下基于服务级别的限流数值不好确定&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;历史阶段&lt;/td&gt;&lt;td&gt;基于RTT耗时检测，即丢包认为网络发生拥塞进行干预&lt;/td&gt;&lt;td&gt;基于压测得到的qps阈值作为限流标准&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;现阶段&lt;/td&gt;&lt;td&gt;TCP-BBR&lt;/td&gt;&lt;td&gt;Sentinel、Kratos ……&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/section&gt;&lt;p&gt;（我们会在后文介绍sentinel与kratos）&lt;/p&gt;&lt;h3&gt;&lt;span&gt;利特尔法则&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;通过上表可看出应用层和传输层在应对负载时本质需求是相同的，那么关于应用层的核心预期公式的推导显然具有相似性，那就是最佳请求数&lt;code&gt;TW（当前最佳处理任数目） = TPS * latency&lt;/code&gt;。如下所示&lt;/p&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000025&quot; data-ratio=&quot;0.5978339350180505&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWKspTibOJkARyk3dLfuzRmM5jE48Or5TciakTSnWNdsSHsZ1hmFNLpxrg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1385&quot;/&gt;&lt;/figure&gt;&lt;p&gt;其实这个公式的依据是显赫有名的利特尔法则little&#x27;s law，为通过对工业中平均生产数量和对应耗时提供了理论基础，以进一步衡量生产能力。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;基于TCP-BBR的自适应算法&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;我们已经具备充分的理论基础和传输层实现指导，下一步就是因地制宜的实施在应用层后台服务。在业内最初版目前所知是由阿里的sentinel组件引入，由kratos进行了进一步拓展。在此我们需要搞清楚两个关键问题，才能保证最大化吞吐的同时防止服务过载。&lt;/p&gt;&lt;p&gt;BBR作为数据发送方，需要面临的问题&lt;strong&gt;未知&lt;/strong&gt;网络设施传输能力。由于网络设施的传输能力、拥塞状态对发送方是非直接可见的，所以才有了上文提到的BBR带宽&lt;strong&gt;探测&lt;/strong&gt;。滑动窗口内通过cycle gain变化，来适应不同时刻的传输能力。&lt;/p&gt;&lt;p&gt;应用层作为请求处理方，无论是在容器网络和物理机上部署，计算资源是相对&lt;strong&gt;固定&lt;/strong&gt;的。这意味着存在着最佳处理量上限，我们要保证的是在流量上升或者因为其他因素导致计算资源紧张时，通过计算出的最佳TW来&lt;strong&gt;限制入口流量&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;了解了控制时机，可就是当计算资源紧张时进行干预。那么该如何确定资源紧张信号呢？总的来说就是CPU利用率或者操作系统负载，或者内存、磁盘等资源。以入口流量特征来看（进程RPC调用下游服务按照业务需求进行组装、计算、返回），无论时内存资源不足导致的GC（依赖CPU）、磁盘I/O吞吐下降、调度抢占等等因素，都会导致用户请求增加、序列化成本增加（CPU）进而时延上升恶性循环。所以在sentinel和kratos的实现中都选择了适用CPU作为资源信号限流，只不过前者使用的是cpu load1，后者使用的是服务基于cgroup对CPU的实时采样使用率。&lt;/p&gt;&lt;p&gt;两者使用各有千秋，但我们认为，基于load1作为控制信号仍不够敏感。在linux下操作系统load1表示一分钟内CPU的平均负载值，对于流量洪峰等过载的发生干预有效性较慢。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;具体方案&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;em&gt;本部分屏蔽到绝大部分代码与设施细节，关注应用方式与过程中上线效果、遇到的问题以及优化。基于bbr算法的完整kratos代码可进入referenc阅读&lt;/em&gt;&lt;/p&gt;&lt;p&gt;kratos以是当前容器网络服务CPU利用率的80%作为控制信号临界点，通过为此服务会开启独立的goroutine每隔250ms进行基于本服务的cgroup(&lt;code&gt;/sys/fs/cgroup/cpu/*&lt;/code&gt;)CPU占用信息采集，以及系统总cpu tick（&lt;code&gt;proc/stat&lt;/code&gt;)占用采集。&lt;/p&gt;&lt;p&gt;对CPU占用率的计算本质是间隔内 &lt;strong&gt;本进程占用的CPU时间增量/系统的总CPU时间占用增量&lt;/strong&gt;。显然CPU的变化是相当迅速的，会受到各种因素的影响来回抖动动。为此我们采用了滑动均值（算法原理参考）的办法进行降噪稳定。通过确定参考衰退率β(&amp;lt;1)，使得最终结果等于：&lt;code&gt;β*上次的CPU占用率 + (1-β)*本次的时机测得CPU占用率&lt;/code&gt;。如下所示：&lt;/p&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000026&quot; data-ratio=&quot;0.6774193548387096&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWEWDo5UziaSA4yJsCaIKOp555icop2qgEVAjiawjZosjwcqaf7pEeKCiakA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;651&quot;/&gt;&lt;/figure&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;深蓝色折线代表了正常实际测量下CPU的变化折线图，可以看到抖动十分不稳定。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;橘色公式折线表示了在滑动均值算法下趋于平稳变动的CPU变化图，但是能看到前提CPU数值较低。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;绿色公式折线是在具体滑动均值算法作用下，对前期数据量不足导致CPU起点低的问题进行的&lt;strong&gt;偏差修正&lt;/strong&gt;。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;最终经过上述修正，我们得到线上具有参考使用价值的CPU占用率。&lt;/p&gt;&lt;p&gt;pass和RT分别表示处理完成请求数和对应请求所消耗的时间，即TPS和Latency。相应的，我们的测量办法同样是通过滑动窗口对pass和RT进行统计，如下图。&lt;/p&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000018&quot; data-ratio=&quot;0.33587786259541985&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAW6HBcNdpxX8DggsbFibyo5gUZDd3oXGahKHibem4Y7uvFSSZFLOnL1AwQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;655&quot;/&gt;&lt;/figure&gt;&lt;p&gt;sample window表示窗口采样周期，sample bucket表示周期内的采样批次。假设现在采样窗口时间为1000ms，bucket采样批次时间持续500ms，那么就表示在前500ms内完成的请求数和这些请求消耗的平均时延都会被原子（atomic）统计在bucket1中。同理，当第501ms会被统计在bucket2中，当第1001ms时会再次回到bucket1，以此类推。可见当bucket足够多，以及统计间隔足够小时最能够得到真实的数据，更有效的应对秒内流量洪峰。&lt;/p&gt;&lt;p&gt;当CPU利用率过载时，就需要通过预期公式进行干预了。我们会在服务运行期间持续统计当前服务的请求数，即inflight，通过在滑动窗口内的所有buckets中比较得出最多请求完成数maxPass，以及最小的耗时minRT，相乘就得出了预期的最佳请求数maxFlight。通过inflight与maxFlight对比，如果前者大于后者那么就已经过载，进而拒绝后续到来的请求防止服务过载。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;线上效果与调优&lt;/span&gt;&lt;/h3&gt;&lt;figure&gt;&lt;img data-fileid=&quot;100000019&quot; data-ratio=&quot;0.42209072978303747&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gvgwWZq1lBZ5ImdKpUQib3PfriciblIaXAWWSHmf2KER7k6lbHnRicSzUjMHYdmzdPjKjyWJVyYos6OW0Fzw4tqz3g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1014&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是在线上部署了基于kratos的自适应算法后的效果图，其中蓝色曲线代表了并发访问的用户数，深黄色代表对应请求的时延，浅绿色则表示成功处理的请求数。左侧为最终版，右侧为第一版。&lt;/p&gt;&lt;p&gt;不难看出，第一版时当算法控制后黄色的时延仍然很高，成功处理的请求数也并非稳定。产生这样结果的原因其实依然是CPU利用率很敏感且粒度很细，当CPU大于80%利用率阈值时算法生效，当微量请求被拒绝时算法便停止了干预。最终的结果便是算法会因为流量的涌入与拒绝中频繁开启与关闭，导致结果不符合预期。&lt;/p&gt;&lt;p&gt;为此我们简单加入了1s的冷却时间，也就是说算法开启后会持续至少1s的冷却时间，再次期间保持算法开启。当冷却时间过后会再次统计当前CPU利用率，并根据阈值对比进行持续或者关闭。最终测试结果如最终版左图所示，在流量持续涌入的情况下请求的成功处理数和时延都十分稳定。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;后记&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;本文尽可能通过应对负载的迭代历程优劣分析，抽丝剥茧完整的引出基于TCP-BBR的自适应算法实现与优势。自适应过载保护同样不是完美的，一方面在请求等排队过长的情况下虽然计算资源未满载，但是同样增加了等待时间。为此，可以选择结合排队论相关算法如CoDel进行干预；另一方面，在极端流量的涌入下可能单纯的拒绝回复成本就会打垮CPU，从而导致宕机，此时可以参考reference中google sre里的自适应熔断等策略合力保障服务的可用性。&lt;/p&gt;&lt;p&gt;另外，对于自适应限流技术的发展，从Netflix最早基于传输层vegas的限流手段推出中间件&lt;code&gt;concurrency-limits&lt;/code&gt;， 再到如今基于TCP-BBR的自适应限流算法改进与实现，都体现了很强的发散性和优化空间。期待读者的进一步讨论！&lt;/p&gt;&lt;h1&gt;&lt;span&gt;Reference&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;Google SRE：https://sre.google/sre-book/handling-overload/&lt;/p&gt;&lt;p&gt;Alibaba Sentinel：https://sentinelguard.io/zh-cn/docs/system-adaptive-protection.html&lt;/p&gt;&lt;p&gt;Netflix 限流技术：https://netflixtechblog.medium.com/performance-under-load-3e6fa9a60581&lt;/p&gt;&lt;p&gt;TensorFlow滑动窗口简读：https://blog.csdn.net/m0_38106113/article/details/81542863&lt;/p&gt;&lt;p&gt;Kratos 自适应限流源码：https://github.com/go-kratos/kratos/tree/v1.0.x/pkg/ratelimit/bbr&lt;/p&gt;&lt;p&gt;CoDel 排队论简读：https://blog.csdn.net/dog250/article/details/72849893&lt;/p&gt;&lt;p&gt;TCP-BBR: https://queue.acm.org/detail.cfm?id=3022184&lt;/p&gt;&lt;p&gt;https://www.net.in.tum.de/fileadmin/bibtex/publications/papers/IFIP-Networking-2018-TCP-BBR.pdf&lt;/p&gt;&lt;p&gt;https://blog.csdn.net/russell_tao/article/details/98723451&lt;/p&gt;&lt;p&gt;Golang进阶训练营之微服务可用性设计-毛剑&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>626182ba998fbb71bb42ef2e601eaffd</guid>
<title>技术人必备的 6 种思维</title>
<link>https://toutiao.io/k/zc4cuah</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;weui-dialog&quot;&gt;
      &lt;p class=&quot;weui-dialog__hd&quot;&gt;&lt;strong class=&quot;weui-dialog__title&quot;&gt;&quot;Top Stories&quot; is disabled&lt;/strong&gt;&lt;/p&gt;
      &lt;p class=&quot;weui-dialog__bd&quot;&gt;
        Enable &quot;Top Stories&quot; in &quot;Settings&quot; &amp;gt; &quot;General&quot; &amp;gt; &quot;Manage Discover&quot;      &lt;/p&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e4a5101a4ed2e07f460b8ed71ada8574</guid>
<title>流量控制还能这么搞</title>
<link>https://toutiao.io/k/4m9r0nc</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;一个优秀的RPC框架，流量控制是必不可少的功能之一。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上一篇文章&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg3MTE5MDM2Ng==&amp;amp;mid=2247484641&amp;amp;idx=1&amp;amp;sn=70f4ead708d0b6607ba4c51091b8c173&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;聊聊服务注册与发现&lt;/a&gt;中，我们讲了微服务架构中核心功能之一服务注册与发现。在本文中，我们将着重讲下微服务的另外一个核心功能点：&lt;em&gt;&lt;strong&gt;流量控制&lt;/strong&gt;&lt;/em&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在微服务系统中，整个系统是以一系列固有功能的微服务组成，如果某一个服务，因为流量异常或者其他原因，导致响应异常，那么同样的也会影响到调用该服务的其他服务，从而引起了一系列连锁反应，最终导致整个系统崩溃。针对此种问题，我们在之前的文章&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg3MTE5MDM2Ng==&amp;amp;mid=2247483754&amp;amp;idx=1&amp;amp;sn=a53c59b102b2622c059a29d49b630e24&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;微服务架构之雪崩效应&lt;/a&gt;有讲解过解决方案，今天我们针对方案中的限流控制来进行深入讲解。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;引言&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;限流这件事，对于微服务架构来说，最直接的就是跟系统承载能力正相关。任何系统都有它服务能力上限，如果在请求链路上，某个子服务的请求量超过其承载能力，那么该链路上的请求将无法正常响应，而此时，如果在client端对于不能返回的请求不断重试(retry)，那么对原本已经超过负载上限的子服务来说，无异于雪上加霜。而这一的模式在拖垮了链路上的某个子服务后，可能会影响到其上游服务，导致影响范围持续扩大，进而让其它原本正常的服务也跟着失效，从而引起雪崩，雪崩效应会加速整个系统无法提供服务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;解决这个问题的方式，就是限流。如果监测到这个现象时候(错误率增高，rt变大或者是服务负载高于其安全阈值)，就直接开启某些策略，在服务负载恢复前，丢弃新的request，以使得整个系统安全可靠。这个就是限流的目的。不过，这个机制困难的不在于要挑选哪种框架或者给某个服务来使用，而是是否有办法精准掌握系统内各个子服务的负载上限，并且有能力做好整合，进一步做到自动化调节限流策略。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;2&lt;/span&gt;&lt;/span&gt;&lt;span&gt;概念&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在解释什么是限流之前，我们先了解一个点，就是服务的请求上限，也可以理解为是服务承载量，即该服务支持一定时间内最多能够支持多少请求。只有将服务承载量进行量化，能够被测量，才能根据这个测量值，采取一定的对应措施。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;服务承载量，指的是单位时间内的处理量。北京地铁早高峰，地铁站都会做一件事情，就是限流了！想法很直接，就是想在一定时间内把请求限制在一定范围内，保证系统不被冲垮，同时尽可能提升系统的吞吐量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;再以我家里的带宽为例，是联通100m的，也就是说，每一秒钟，联通提供最大100m bits的数据传输量。那么联通是如何限制这个上限的呢？假如我是联通，可能有以下几个方面：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;每秒总共传输量，在1秒内只要不超过100m bits，能传多快就多块&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;按照位来平均，每传1bit需要花费0.01ns，因此没传完1bits后必须得到0.01ns后才能继续传&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;只要60秒内不超过60*100Mb就行&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;....&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到上面这些方案，就会发现，做到真正的限制，不是那么容易的。因为每一个方案实现原理都不同，也就意味着代码实现不同。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在，假如我们使用方案2来实现，等真正测试或者上线后，会崩溃吧，因为流量控制根本不是像我们预期的那样进行控制，这是因为重新计算流量的过程有可能已经超了0.01ns。显然要尽可能精准的控制流量，需要回答下面两个问题：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;如何定义流量的计算方式？是选择1s、10s还是60s？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果流量超了之后，该怎么做？是直接返回空值还是一个默认值？&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;显然，我们在想清楚上面两个问题后，实现方案基本就能定下来了。收到了新的request，只要确认目前的服务是否还有能力处理这个request即可。这个时候流量是直接丢弃，还是返回其他值，根据具体情况进行具体分析。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;3&lt;/span&gt;&lt;/span&gt;&lt;span&gt;常用方式&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;限流常用的方式有：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我将深入讲解上述的四种限流方式，先讲解原理，然后是实现，最后分析其特点。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;4&lt;/span&gt;&lt;/span&gt;&lt;span&gt;计数器&lt;/span&gt;&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;确定方法的最大访问量MAX，每次进入方法前计数器+1，将结果和最大并发量MAX比较，如果大于等于MAX，则直接返回；如果小于MAX，则继续执行。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;计数器的实现方式，简单粗暴。在一段时间内，进行计数，与阀值进行比较，到了时间临界点，将计数器清0。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.27647058823529413&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/nHhIb6Amn3kAH3N2YuuItLpgBkqsAvWy3wibpibeEtoGarMmq3eUhGj30UPGpNTibhyUrjK275xMrN4l0Kr2EKglw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1020&quot;/&gt;&lt;figcaption&gt;图一、计数器&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在上图中，我们以1分钟即60秒为一个时间片，在该时间片内最多处理请求为1000，如果超过了上限，则拒绝服务(具体依赖于实际业务场景)。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;原理&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们将计数器的思路在明确下就是：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;设置单位时间T（如10s）内的最大访问量req_max，在单位时间T内维护计数器count；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;当请求到达时，判断时间是否进入下一个单位时间；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果是，则重置计数器为0；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果不是，计数器count,并判断计数器count是否超过最大访问量req_max，如超过，则拒绝访问。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;实现&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对上面的计数器原理，代码实现如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;class CounterController {&lt;br/&gt; public:&lt;br/&gt;  CounterController(int max, int duration) {&lt;br/&gt;    max_ = max;&lt;br/&gt;    duration_ = duration;&lt;br/&gt;    last_update_time_ = time(nullptr);&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  bool &lt;span&gt;&lt;span&gt;IsValid&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;     uint64_t now = time(nullptr);&lt;br/&gt;     &lt;span&gt;if&lt;/span&gt; (now &amp;lt; last_update_time_ + duration_) {&lt;br/&gt;        ++req_num_;&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; max_ &amp;gt; req_num_;&lt;br/&gt;     } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;       last_update_time_ = now;&lt;br/&gt;       req_num_ = 1;&lt;br/&gt;       &lt;span&gt;return&lt;/span&gt; max_ &amp;gt; req_num_;&lt;br/&gt;     }&lt;br/&gt;  }&lt;br/&gt; private:&lt;br/&gt;  int max_;&lt;br/&gt;  int duration_;&lt;br/&gt;  int last_update_time_;&lt;br/&gt;  int req_num_ = 0;&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在实现代码中，其中有四个成员变量：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;max_ 代表时间片内最多处理的请求个数&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;duration_ 代表时间片，单位为秒&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;last_update_time_ 上一次更新计数器的时间&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;req_num_ 当前时间片内的处理的请求数&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中，计数器限流方案的实现是在成员函数IsValid()中实现的，即为该次请求是否有效。在该函数中，我们首先判断当前时间戳与上次更新时间戳之差是否超过了时间片，如果当前时间戳处于上次更新后的时间片内，则请求数+1，然后判断请求数是否超过了该时间片的处理上限。如果不处于上次更新后的时间片内，则重置更新时间以及请求数。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;特点&lt;span/&gt;&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;优点：实现简单，容易理解&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;缺点：&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;一段时间内（不超过时间窗口）系统服务不可用。以图一为例，时间片为60s，在时间片内的第一秒内，处理请求量就达到了上限，那么在后面的59s内，所有的请求都将被拒绝&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在时间片切换时刻，可能会产生两倍于上限的请求。仍然以图一为例，时间片为60s，在时间片内的前59s都无请求过来，在第60s的时候来了1000个请求，然后时间片切换，在新的时间片内的第一秒内，来了1000个请求，也就是说在2秒内(上一个时间片的最后一秒 + 当前时间片的第一秒)来了2000个请求，这个时候明显超过我们的时间片内的上限值，可能导致系统崩溃&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5316973415132924&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/nHhIb6Amn3kAH3N2YuuItLpgBkqsAvWyPiaUORAC1WgutgBiaz0SQ7T1NEBY3ycwrBNwVWu26MQ1iaKGvY48Aon2Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;978&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;5&lt;/span&gt;&lt;/span&gt;&lt;span&gt;滑动窗口&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;计数器滑动窗口算法是计数器固定窗口算法的改进，解决了固定窗口切换时可能会产生两倍于阈值流量请求的缺点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;滑动窗口的意思是说把固定时间片，进行划分，并且随着时间的流逝，进行移动，这样就巧妙的避开了计数器的临界点问题。也就是说这些固定数量的可以移动的格子，将会进行计数判断阀值，因此格子的数量影响着滑动窗口算法的精度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在TCP中，也使用了滑动窗口来进行网络流量控制，感兴趣的同学可以阅读&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=Mzg3MTE5MDM2Ng==&amp;amp;mid=2247484218&amp;amp;idx=1&amp;amp;sn=da79859aed397a1084840e12e08595dd&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;TCP之滑动窗口原理&lt;/a&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3094928478543563&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/nHhIb6Amn3kAH3N2YuuItLpgBkqsAvWyt3YN3OEVcEEUMRGL2nBDkNoGRo5WFESK0YemUM0SiaCQJauesKl8Haw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1538&quot;/&gt;&lt;figcaption&gt;滑动窗口&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;em&gt;计数器方式是一种特殊的滑动窗口，其窗口大小为1个时间片&lt;/em&gt;;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;原理&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;滑动窗口算法在固定窗口的基础上，将一个计时窗口分成了若干个小窗口，然后每个小窗口维护一个独立的计数器。当请求的时间大于当前窗口的最大时间时，则将计时窗口向前平移一个小窗口。平移时，将第一个小窗口的数据丢弃，然后将第二个小窗口设置为第一个小窗口，同时在最后面新增一个小窗口，将新的请求放在新增的小窗口中。同时要保证整个窗口中所有小窗口的请求数目之后不能超过设定的阈值。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3727087576374745&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/nHhIb6Amn3kAH3N2YuuItLpgBkqsAvWyYiaW1icbGurtJt3Oria4TTwFt0JSAN4stPuibibEVJUgs7aD01tqVhu0iasA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;982&quot;/&gt;&lt;figcaption&gt;滑动窗口&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;实现&lt;span/&gt;&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;class SlidingWindowController {&lt;br/&gt; public:&lt;br/&gt;  SlidingWindowController(int window_size, int &lt;span&gt;limit&lt;/span&gt;, int split_num) {&lt;br/&gt;    limit_ = &lt;span&gt;limit&lt;/span&gt;;&lt;br/&gt;    window_size_ = window_size;&lt;br/&gt;    counters_.resize(split_num);&lt;br/&gt;    split_num_ = split_num;&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  int &lt;span&gt;&lt;span&gt;IsValid&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;    uint64_t now_ms = 0;&lt;br/&gt;    GetCurrentTimeMs(&amp;amp;now_ms);&lt;br/&gt;    int window_num = std::max(now_ms - window_size_ - start_time_, 0) / (window_size_ / split_num_);&lt;br/&gt;&lt;br/&gt;    SlidingWindow(window_num);&lt;br/&gt;&lt;br/&gt;    int count = 0;&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt;(int i = 0;i &amp;lt; split_num_; ++i){&lt;br/&gt;        count += counters_[i];&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt;(count &amp;gt;= &lt;span&gt;limit&lt;/span&gt;){&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;    }&lt;span&gt;else&lt;/span&gt;{&lt;br/&gt;      counters_[index] ++;&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;;&lt;br/&gt;  }&lt;br/&gt; private:&lt;br/&gt;  void SlidingWindow(int window_num) {&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (window_num == 0) {&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    int slide_num = std::min(window_num, split_num_);&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; (int i = 0; i &amp;lt; slide_num; ++i) {&lt;br/&gt;      index_ = (index_ + 1) % split_num;&lt;br/&gt;      counters_[index_] = 0;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    start_time_ = start_time_ + wind_num * (window_size_ / split_num_); // 更新滑动窗口时间&lt;br/&gt;  }&lt;br/&gt;  &lt;br/&gt;  int window_size_; // 窗口大小，单位为毫秒&lt;br/&gt;  int limit_; // 窗口内限流大小&lt;br/&gt;  std::vector&amp;lt;int&amp;gt; counters_;&lt;br/&gt;  uint64_t start_time_; // 窗口开始时间&lt;br/&gt;  int index_ = 0; // 当前窗口计时器索引&lt;br/&gt;  int split_num_;&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;特点&lt;span/&gt;&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;避免了计数器固定窗口算法固定窗口切换时可能会产生两倍于阈值流量请求的问题&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;实现精度依赖于窗口的细分粒度，分的越细，即窗口分块越多，控制的流量越平滑&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;6&lt;/span&gt;&lt;/span&gt;&lt;span&gt;漏桶&lt;/span&gt;&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以固定速率从桶中流出水滴，以任意速率往桶中放入水滴，桶容量大小是不会发生改变的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;流入：以任意速率往桶中放入水滴。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;流出：以固定速率从桶中流出水滴。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为桶中的容量是固定的，如果流入水滴的速率&amp;gt;流出的水滴速率，桶中的水滴可能会溢出。那么溢出的水滴请求都是拒绝访问的，或者直接调用服务降级方法。前提是同一时刻。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是对于很多场景来说，除了要求能够限制数据的平均传输速率外，还要求允许某种程度的突发传输。这时候漏桶算法可能就不合适了，令牌桶算法更为适合。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.242537313432836&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/nHhIb6Amn3kAH3N2YuuItLpgBkqsAvWyyzjCag13XDM0iaU7PRuZ7O5S37AKW7TdU8xEM2HMjszQ38w9RkY6Qbw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;536&quot;/&gt;&lt;figcaption&gt;漏桶&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;原理&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;请求来了之后会首先进到漏斗里，然后漏斗以恒定的速率将请求流出进行处理，从而起到平滑流量的作用。当请求的流量过大时，漏斗达到最大容量时会溢出，此时请求被丢弃。从系统的角度来看，我们不知道什么时候会有请求来，也不知道请求会以多大的速率来，这就给系统的安全性埋下了隐患。但是如果加了一层漏斗算法限流之后，就能够保证请求以恒定的速率流出。在系统看来，请求永远是以平滑的传输速率过来，从而起到了保护系统的作用。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;实现&lt;span/&gt;&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;class LeakyBucketController {&lt;br/&gt; public:&lt;br/&gt;  LeakyBucketController(int rate) {&lt;br/&gt;    capacity_ = rate;&lt;br/&gt;    last_update_time_ = time(nullptr);&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  bool &lt;span&gt;&lt;span&gt;IsValid&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;&lt;br/&gt;    // 计算这段时间，漏了多少水&lt;br/&gt;    uint64_t now = time(nullptr);&lt;br/&gt;    int out = (new - last_update_time_) * rate;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (out &amp;gt; 0) {&lt;br/&gt;      last_update_time_ = now;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    // 计算桶中剩余的水&lt;br/&gt;    water_ = std::max(0, water_ - out);&lt;br/&gt;&lt;br/&gt;    // 如果桶没有满，则表示有效&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (water_ &amp;lt; capacity_) {&lt;br/&gt;      ++water_;&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt; private:&lt;br/&gt;  int capacity_;&lt;br/&gt;  int water_ = 0;&lt;br/&gt;  uint64_t last_update_time_;&lt;br/&gt;};&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;特点&lt;span/&gt;&lt;/h4&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;漏桶的漏出速率是固定的
由于漏出速率固定，因此即使流量流入速率不定，但是经过漏斗之后，变成了有固定速率的稳定流量，可以对下游系统起到保护作用&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;不能解决流量突发的问题。假设我们设置漏斗速率为10个/秒，桶的容量为50个。此时突然来了100个请求，那么只有50个请求被接收，另外50个被拒绝。这个时候，你可能会认为瞬间接受了50个请求，不就解决了流量突发问题么？不，这50个请求只是被接受了，但是没有马上被处理，处理的速度仍然是我们设定的10个/秒，所以没有解决流量突发的问题。而接下来我们要谈的令牌桶算法能够在一定程度上解决流量突发的问题。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;7&lt;/span&gt;&lt;/span&gt;&lt;span&gt;令牌桶&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;令牌桶算法是对漏斗算法的一种改进，除了能够起到限流的作用外，还允许一定程度的流量突发。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;令牌桶算法是以恒定的速率将令牌放入桶中，这个时候如果来了突发流量，如果桶中有令牌，则可以直接获取令牌，并处理请求，基于该原理，就解决了漏桶算法中不能 &lt;em&gt;处理突发流量&lt;/em&gt; 的问题。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;原理&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在令牌桶算法中，令牌以恒定速率放入桶中。桶也有一定的容量，如果满了令牌就无法放进去了。当请求来了之后，会受限到桶中去拿令牌，如何取到了令牌，则该请求被处理，并消耗掉拿到的令牌，否则，该请求被丢弃。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.3076923076923077&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/nHhIb6Amn3kAH3N2YuuItLpgBkqsAvWy1e2OqYY0qz9vVYzQngYjfMjdbCaFfc5ylgzYgH04icABDsb5PqibfChA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;624&quot;/&gt;&lt;figcaption&gt;令牌桶&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;实现&lt;span/&gt;&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;class TokenBucketController {&lt;br/&gt; public:&lt;br/&gt;  TokenBucketController(int num, uint64_t duration) :&lt;br/&gt;    duration_(duration), rate_(num &amp;gt; 0 ? (num / duration_ / 1000) : 0),  &lt;br/&gt;    limit_(num), modulo_(num &amp;gt; 0 ?(num % (duration * 1000)) : 0) {&lt;br/&gt;    GetCurrentTimeMs(&amp;amp;last_update_time_);&lt;br/&gt;    ::curr_idx = 0;&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  bool IsValid();&lt;br/&gt; private:&lt;br/&gt;  void Update();&lt;br/&gt;&lt;br/&gt;  const uint64_t duration_;&lt;br/&gt;  const int rate_;&lt;br/&gt;  const int limit_;&lt;br/&gt;  const uint64_t modulo_;&lt;br/&gt;  uint64_t last_update_time_;&lt;br/&gt;  uint64_t loss_ = 0;&lt;br/&gt;  uint64_t counts_ = 0;&lt;br/&gt;};&lt;br/&gt;&lt;br/&gt;void TokenBucketController::&lt;span&gt;&lt;span&gt;Update&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;  uint64_t cur_time_ms;&lt;br/&gt;  GetCurrentTimeMs(&amp;amp;cur_time_ms);&lt;br/&gt;  uint64_t time_passed_since_last_update = cur_time_ms - last_update_time_;&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (time_passed_since_last_update == 0) {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt;;&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (counts_ == static_cast&amp;lt;uint64_t&amp;gt;(limit_)) {&lt;br/&gt;    last_update_time_ = cur_time_ms;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt;;&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  uint64_t count_to_add = rate_ * time_passed_since_last_update;&lt;br/&gt;  loss_ += modulo_ * time_passed_since_last_update;&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (loss_ &amp;gt;= duration_ * 1000) {&lt;br/&gt;    count_to_add += loss_ / duration_ / 1000;&lt;br/&gt;    loss_ %= (duration_ * 1000);&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  counts_ += count_to_add;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (counts_ &amp;gt; static_cast&amp;lt;uint64_t&amp;gt;(limit_)) {&lt;br/&gt;    counts_ = limit_;&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;  last_update_time_ = cur_time_ms;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;bool TokenBucketController::&lt;span&gt;&lt;span&gt;IsValid&lt;/span&gt;&lt;/span&gt;() {&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (limit_ &amp;lt; 0) {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;;&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (counts_ &amp;gt;= 1) {&lt;br/&gt;    counts_ -= 1;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;;&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  Update();&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; (counts_ &amp;gt;= 1) {&lt;br/&gt;    counts_ -= 1;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;;&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在实现上，令牌桶跟漏桶的区别，是一个控制进，一个控制出。在InValid函数中，先判断桶中是否有令牌，如果有则返回true，否则，进行更新桶中令牌(Update函数)，然后再进行判断是否有令牌可用。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;特点&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;令牌桶算法来作为限流，在业界使用最多，除了能够在限制调用的平均速率的同时还允许一定程度的流量突发。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;8&lt;/span&gt;&lt;/span&gt;&lt;span&gt;结语&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面我们把本文中的四种限流策略做下简单对比，来作为对本文的一个总结。计数器算法：该算法实现简单，容易理解。但是在时间片切换时刻，容易出现两倍于阈值的流量，也可以说是滑动窗口算法的简版(窗口只有一个)。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;滑动窗口算法：解决了计数器算法中的2倍阈值的问题，其流量控制精度依赖于窗口个数，窗口个数越多，精度控制越准。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;漏桶算法：以任意速率往桶中放入水滴，如果桶中的水滴没有满的话，可以访问服务，不能处理突发流量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;令牌桶算法：以固定的速率(平均速率)生成对应的令牌放到桶中，客户端只需要在桶中获取到令牌后，就可以访问服务请求，与漏桶算法相比，其可以处理一定的突发流量。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;令牌桶算法是通过控制令牌生成的速度进行限流，&lt;/p&gt;&lt;p&gt;漏桶算法是控制请求从桶中流出的速度进行限流。&lt;/p&gt;&lt;p&gt;简单理解为：令牌桶控制进，漏桶控制出。&lt;/p&gt;&lt;p&gt;如果要让自己的系统不被打垮，用令牌桶。如果保证被别人的系统不被打垮，用漏桶算法。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上四种限流算法都有自身的特点，具体使用时还是要结合自身的场景进行选取，没有最好的算法，只有最合适的算法。比如令牌桶算法一般用于保护自身的系统，对调用者进行限流，保护自身的系统不被突发的流量打垮。如果自身的系统实际的处理能力强于配置的流量限制时，可以允许一定程度的流量突发，使得实际的处理速率高于配置的速率，充分利用系统资源。而漏斗算法一般用于保护第三方的系统，比如自身的系统需要调用第三方的接口，为了保护第三方的系统不被自身的调用打垮，便可以通过漏斗算法进行限流，保证自身的流量平稳的打到第三方的接口上。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;算法是死的，而算法中的思想精髓才是值得我们学习的。实际的场景中完全可以灵活运用，还是那句话，没有最好的算法，只有最合适的算法。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;推荐阅读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTE5MDM2Ng==&amp;amp;mid=2247484641&amp;amp;idx=1&amp;amp;sn=70f4ead708d0b6607ba4c51091b8c173&amp;amp;chksm=ce831ed0f9f497c603388a1c594b798cd5f5088548a89180dae6ff696259435ad0a761053c33&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;聊聊服务注册与发现&lt;/a&gt;&lt;strong&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTE5MDM2Ng==&amp;amp;mid=2247484641&amp;amp;idx=1&amp;amp;sn=70f4ead708d0b6607ba4c51091b8c173&amp;amp;chksm=ce831ed0f9f497c603388a1c594b798cd5f5088548a89180dae6ff696259435ad0a761053c33&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTE5MDM2Ng==&amp;amp;mid=2247484537&amp;amp;idx=1&amp;amp;sn=0fa2d38a2c18bd0ddb6cf03476b101f6&amp;amp;chksm=ce831e48f9f4975e31f13a017ab4099ffc224622673504657f7f9f89d025e4edfcd2e2269fa5&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;技术十年&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTE5MDM2Ng==&amp;amp;mid=2247484475&amp;amp;idx=1&amp;amp;sn=ce5cd6b0e1f3bf269f335c5c61c7a184&amp;amp;chksm=ce831e0af9f4971cb0d630e1b94f833484aec4fb3bb8f918167f056d339e94295f1c8e86e7b7&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;亿级流量实验平台设计实践&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTE5MDM2Ng==&amp;amp;mid=2247484251&amp;amp;idx=1&amp;amp;sn=cc4fb0a9711b6c47a1af717d53ee2118&amp;amp;chksm=ce83196af9f4907c145cfcb132dec11c3afbcdcf39925fcf18ba44662db138ead805b18ab129&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;TCP之深入浅出send&amp;amp;recv&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c89ad90fa3635f2f1c7f5a30c50cf547</guid>
<title>二叉树的序列化和反序列化</title>
<link>https://toutiao.io/k/33uzmac</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;entry-content&quot;&gt;

&lt;p&gt;昨天看到这道题目，我有点头皮发麻，主要是想到了字符串的处理，不过，我想到，既然要写算法，怕麻烦的心态不能有，算法题再麻烦，能有业务麻烦？&lt;/p&gt;



&lt;p&gt;对一个二叉树进行序列化，其实就是把一个非线性的数据结构，转化成线性的数据结构。比如，我们按照某种顺序去遍历二叉树，就会把二叉树转换成一个序列，就相当于序列化了。我们可以使用：&lt;/p&gt;



&lt;ol&gt;&lt;li&gt;前序遍历&lt;/li&gt;&lt;li&gt;中序遍历&lt;/li&gt;&lt;li&gt;后序遍历&lt;/li&gt;&lt;/ol&gt;



&lt;p&gt;反序列化是什么呢？就是从一个给定的序列，恢复出原来的树。这个过程毛想想可能有点麻烦，不过真写出来，其实又不那么麻烦了。&lt;/p&gt;



&lt;p&gt;先来说序列化的部分。我们选择前序遍历作为序列化的方法：&lt;/p&gt;



&lt;pre class=&quot;EnlighterJSRAW&quot; data-enlighter-language=&quot;python&quot; data-enlighter-theme=&quot;&quot; data-enlighter-highlight=&quot;&quot; data-enlighter-linenumbers=&quot;&quot; data-enlighter-lineoffset=&quot;&quot; data-enlighter-title=&quot;&quot; data-enlighter-group=&quot;&quot;&gt;def serialize(self, root):
    res = []
    def _serialize(tree):
        if not tree:
            res.append(&#x27;None&#x27;)
        else:
            res.append(str(tree.val))
            _serialize(tree.left)
            _serialize(tree.right)
    _serialize(root)
    return &#x27;,&#x27;.join(res)&lt;/pre&gt;



&lt;p&gt;我使用了一个内部函数，用一个变量 &lt;code&gt;res&lt;/code&gt; 来存储结果数组，然后内部函数是一个递归前序遍历算法。这里注意的主要就是根节点被表示成了 None，也可以是别的，等会儿反正反序列化的时候，你照着反解就行了，这其实就是所谓的“协议”了。&lt;/p&gt;



&lt;div class=&quot;wp-block-image&quot;&gt;&lt;figure class=&quot;aligncenter size-full&quot;&gt;&lt;a href=&quot;https://sexywp.com/wp-content/uploads/2021/10/serdeser.jpeg&quot;&gt;&lt;img loading=&quot;lazy&quot; src=&quot;https://sexywp.com/wp-content/uploads/2021/10/serdeser.jpeg&quot; alt=&quot;&quot; class=&quot;wp-image-1095&quot; srcset=&quot;https://sexywp.com/wp-content/uploads/2021/10/serdeser.jpeg 442w, https://sexywp.com/wp-content/uploads/2021/10/serdeser-300x220.jpeg 300w&quot; sizes=&quot;(max-width: 442px) 100vw, 442px&quot;/&gt;&lt;/a&gt;&lt;figcaption&gt;二叉树的例子&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;



&lt;p&gt;对于图例里的二叉树，我们前序遍历后，得到的是什么呢？&lt;/p&gt;



&lt;pre class=&quot;EnlighterJSRAW&quot; data-enlighter-language=&quot;generic&quot; data-enlighter-theme=&quot;&quot; data-enlighter-highlight=&quot;&quot; data-enlighter-linenumbers=&quot;&quot; data-enlighter-lineoffset=&quot;&quot; data-enlighter-title=&quot;&quot; data-enlighter-group=&quot;&quot;&gt;1, 2, None, None, 3, 4, None, None, 5, None, None&lt;/pre&gt;



&lt;p&gt;接下来说反序列化，可能，这是大家可能会觉得难的部分，因为每次看到二叉树这个主题，研究怎么遍历这个树的次数，要远远多于研究怎么构建这个树的次数，所以，当我们想从一个字符串构建这个树的时候，就会感觉陌生，从而提高了难度。&lt;/p&gt;



&lt;p&gt;我也是实际写了一下，才发现，好像写出来以后，也并不是很复杂。我写了一个递归方法，方法的功能是：&lt;strong&gt;把输入的序列当成一个前序遍历结果，然后返回恢复后的树的根&lt;/strong&gt;。递归方法的构造过程很有意思，就是我们总是&lt;strong&gt;&lt;span class=&quot;has-inline-color has-medium-pink-color&quot;&gt;先假设我们已经写出了这个函数，再去写这个函数&lt;/span&gt;&lt;/strong&gt;。有点像哆啦A梦穿越时空的糊涂账。这也就是递归有趣的地方。&lt;/p&gt;



&lt;p&gt;二叉树为什么这么有意思？因为二叉树也是个典型的递归结构。一棵二叉树和这棵树的左右子树，在性质上是完全一样的东西，只是差了一层而已。&lt;/p&gt;



&lt;p&gt;当我们恢复一个前序序列为树的时候，我们知道，第一个元素是根节点，然后，后面就是左子树，然后再后面是右子树，恢复左子树的时候，就可以递归使用自己来完成了，所以根本不用头疼后面怎么办，也不用头疼左右子树的分界点在哪里这种问题了，毕竟“&lt;meta charset=&quot;utf-8&quot;/&gt;&lt;strong&gt;&lt;span class=&quot;has-inline-color has-medium-pink-color&quot;&gt;我们已经写出了这个函数&lt;/span&gt;&lt;/strong&gt;”，对不对？哈哈&lt;/p&gt;



&lt;pre class=&quot;EnlighterJSRAW&quot; data-enlighter-language=&quot;python&quot; data-enlighter-theme=&quot;&quot; data-enlighter-highlight=&quot;&quot; data-enlighter-linenumbers=&quot;&quot; data-enlighter-lineoffset=&quot;&quot; data-enlighter-title=&quot;&quot; data-enlighter-group=&quot;&quot;&gt;def deserialize(self, data):
    l = data.split(&#x27;,&#x27;) # 字符串切割成列表
    i = 0               # 遍历列表的下标指针
    def _deserialize():
        nonlocal i # 解决 Python 的闭包问题
        if l[i] == &#x27;None&#x27;:
            i += 1
            return None
        root = TreeNode(int(l[i]))  # 第一个遇到的元素是根节点
        i += 1                      # 元素用掉后，下标后移
        root.left = _deserialize()  # 递归构造左子树
        root.right = _deserialize() # 递归构造右子树
        return root
    return _deserialize()&lt;/pre&gt;



&lt;p&gt;写完后，才发现，很意外，这个反序列化的方法，几乎和序列化一毛一样，也是一个前序遍历的递归过程。&lt;/p&gt;



&lt;p&gt;好，到这里，序列化和反序列化就都写完了。还蛮有趣的。&lt;/p&gt;



&lt;p&gt;– End –&lt;/p&gt;
&lt;h3&gt;相关阅读&lt;/h3&gt;&lt;/div&gt;


&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>