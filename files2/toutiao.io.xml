<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>3d118c2e31438a47014e34138dfd3c44</guid>
<title>精通那么多技术，你为何还是受不到重用？| 码农周刊第 324 期</title>
<link>https://toutiao.io/k/3ininot</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;body class=&quot;issue&quot; id=&quot;readabilityBody&quot;&gt;
        &lt;h1&gt;精通那么多技术，你为何还是受不到重用？| 码农周刊第 324 期&lt;/h1&gt;
        &lt;h2&gt;码农周刊第324期（2020-11-11）&lt;/h2&gt;
        &lt;p&gt;☞ &lt;a href=&quot;https://weekly.manong.io/bounce?nid=324&amp;amp;aid=19568&amp;amp;url=https%3A%2F%2Fvip.manong.io%2F%3F3240&quot; target=&quot;_blank&quot;&gt;双十一，买它买它买它！&lt;/a&gt;&lt;br/&gt;&amp;#13;
&lt;a href=&quot;https://weekly.manong.io/bounce?nid=324&amp;amp;aid=19568&amp;amp;url=https%3A%2F%2Fvip.manong.io%2F%3F3240&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_324.png&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;br/&gt;&amp;#13;
&lt;small&gt;&lt;a href=&quot;https://weekly.manong.io/bounce?nid=324&amp;amp;aid=19185&amp;amp;url=https%3A%2F%2Fjinshuju.net%2Ff%2FV7DxN9&quot; target=&quot;_blank&quot;&gt;商务合作&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
        
        &lt;h3 id=&quot;程序设计&quot;&gt;程序设计&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;经验分享&lt;/p&gt;
        
        &lt;p&gt;基于 Kubernetes 的云原生批量计算平台&lt;/p&gt;
        
        &lt;p&gt;详细介绍&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_3041.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
        &lt;h3 id=&quot;VIP会员专区&quot;&gt;VIP会员专区&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;工作地点：成都 | 薪资：15-30K | 简历投递邮箱：xiexiaofang@huobi.com&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;对以 Transformer 为基础的序列特征提取器 (Encoder) 和自回归的序列解码器 (Decoder) 做了深度优化&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;技术雷达是 ThoughtWorks 每半年发布一次的技术趋势报告&amp;#13;
&lt;/p&gt;
        
        &lt;p&gt;这是德勤第 11 年发布技术趋势年度报告&lt;/p&gt;
        &lt;h3 id=&quot;工具资料&quot;&gt;工具资料&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;个人经历&lt;/p&gt;
        
        &lt;p&gt;你知道吗？&lt;/p&gt;
        
        &lt;p&gt;试试吧&lt;/p&gt;
        
        &lt;p&gt;简明介绍&lt;/p&gt;
        
        &lt;p&gt;供参考&lt;/p&gt;
        
        &lt;p&gt;经验总结&lt;/p&gt;
        
        &lt;p&gt;经验分享&lt;/p&gt;
        
        &lt;p&gt;详细介绍&lt;/p&gt;
        
        &lt;p&gt;欢迎探讨&lt;/p&gt;
        
        &lt;p&gt;经验分享&lt;/p&gt;
        
        &lt;p&gt;图文并茂&lt;/p&gt;
        
        &lt;p&gt;供参考&lt;/p&gt;
        
        &lt;p&gt;欢迎探讨&lt;/p&gt;
        
        &lt;p&gt;系列文章&lt;/p&gt;
        
        &lt;p&gt;适合入门&lt;/p&gt;
        
        &lt;p&gt;结合代码&lt;/p&gt;
        
        &lt;p&gt;深入探讨&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_3041.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
        &lt;h3 id=&quot;编程语言&quot;&gt;编程语言&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;简明介绍&lt;/p&gt;
        
        &lt;p&gt;详解&lt;/p&gt;
        
        &lt;p&gt;基于 Swift 推出的函数响应框架&lt;/p&gt;
        
        &lt;p&gt;使用 JavaScript 来自动化 iOS&lt;/p&gt;
        
        &lt;p&gt;系列文章&lt;/p&gt;
        
        &lt;p&gt;实践总结&lt;/p&gt;
        
        &lt;p&gt;供参考&lt;/p&gt;
        
        &lt;p&gt;细致讲解&lt;/p&gt;
        
        &lt;p&gt;代码示例&lt;/p&gt;
        
        &lt;p&gt;详细介绍&lt;/p&gt;
        
        &lt;p&gt;简明介绍&lt;/p&gt;
        
        &lt;p&gt;详解&lt;/p&gt;
        
        &lt;p&gt;试试吧&lt;/p&gt;
        &lt;h3 id=&quot;每周独家号推荐&quot;&gt;每周独家号推荐&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;7年工作经验，技术总监&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 451915 即可&lt;/p&gt;
        
        &lt;p&gt;坚持原创，持续分享技术，包括但不限于：分布式、微服务架构，spring cloud、Dubbo微服务框架，Java核心技术，Redis缓存、Kafka消息队列中间件等。&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 450130 即可&lt;/p&gt;
        
        &lt;p&gt;一个工作10年的程序猿，分享技术干货及内心的声音。&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 413084 即可&lt;/p&gt;
        
        &lt;p&gt;详解数据结构与算法&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 142771 即可&lt;/p&gt;
        
        &lt;p&gt;Web前端、服务端、小程序、App、学习资料、工具、资讯&lt;br/&gt;订阅方法：使用&lt;a href=&quot;http://toutiao.io/download?ref=v4.1.0&quot; target=&quot;_blank&quot;&gt;开发者头条客户端&lt;/a&gt;，发现 &amp;gt; 搜索 125297 即可&lt;/p&gt;
        &lt;h3 id=&quot;每周一书&quot;&gt;每周一书&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;&lt;a href=&quot;https://weekly.manong.io/bounce?nid=324&amp;amp;aid=20115&amp;amp;url=http%3A%2F%2Fproduct.dangdang.com%2F29132383.html&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.toutiao.io/ads/book_324.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
        &lt;h3 id=&quot;编程之外&quot;&gt;编程之外&lt;/h3&gt;
        &lt;p/&gt;
        
        &lt;p&gt;一个技术总监的忠告&lt;/p&gt;
        
        &lt;p&gt;写作不易&lt;/p&gt;
        
        &lt;p&gt;同理心&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://img.toutiao.io/ads/vip_3041.jpeg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
        &lt;p&gt;
        &lt;/p&gt;
        
        
        
        
        &lt;div class=&quot;qrcode&quot;&gt;
  &lt;img src=&quot;https://img.toutiao.io/ads/vip_qrcode.png&quot; alt=&quot;Qrcode 258&quot;/&gt;&lt;span&gt;加入码农周刊VIP会员&lt;/span&gt;
&lt;/div&gt;
    &lt;/body&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>bda09fbd596d202c5763c8c7293dc891</guid>
<title>[推荐] 分布式一致性协议：ZAB</title>
<link>https://toutiao.io/k/r6571za</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;post-content&quot;&gt;&lt;h3 id=&quot;ZAB-背景&quot;&gt;&lt;a href=&quot;#ZAB-背景&quot; class=&quot;headerlink&quot; title=&quot;ZAB 背景&quot;/&gt;ZAB 背景&lt;/h3&gt;&lt;p&gt;学习ZAB，非常有必要聊聊它诞生的背景。因为在paxos的光芒下，还有必要折腾这样类似的算法吗？这个问题是我们初步了解ZAB关键。&lt;/p&gt;
&lt;p&gt;看到这里，我断定大家都使用过zookeeper，并且知道zookeeper的核心就是ZAB协议。如果没有的话，需要先学习下zookeeper。毕竟基础不牢，地动山摇。&lt;/p&gt;
&lt;p&gt;这里多提一句，ZAB的作者说ZAB不是paxos，但是后面我们又把ZAB归纳为paxos。这里我认为啊，这两个说法都对，只是他们描述的时间不一致。在ZAB诞生的时候，它解决了paxos不能保证顺序执行的问题，从某些角度来说ZAB是要paxos优秀的，说它不是paxos也没问题。但是后来随来越来越多分布式算法诞生，例如raft，因为他们都类似paxos执行逻辑，所以将这类算法归纳为paxos的变种。&lt;/p&gt;
&lt;h4 id=&quot;为何不使用paxos来实现zookeeper&quot;&gt;&lt;a href=&quot;#为何不使用paxos来实现zookeeper&quot; class=&quot;headerlink&quot; title=&quot;为何不使用paxos来实现zookeeper&quot;/&gt;为何不使用paxos来实现zookeeper&lt;/h4&gt;&lt;p&gt;回过头来，ZAB诞生的原因，我们先考虑zookeeper能不能直接使用paxos作为分布式一致性算法？答案肯定是否定的，我们举个例子，假设有个客户端需要分别创建目录：/foo, /foo/ofcoder。&lt;/p&gt;
&lt;p&gt;在前文我们学习过了paxos，知道paxos能集群就某个值达成共识，但是却不关心达成共识的值是什么。如果zookeeper直接使用paxos，就会出现在没有创建/foo的时候，创建/foo/ofcoder。显然这就报错了，因为ofcoder的上级目录不存在。为了描述这个问题，我们描述下过程。&lt;/p&gt;
&lt;p&gt;假如有同一个业务请求，因为入参不一样，导致最后要达成共识的值也不一样。例如proposerA，收到请求先后创建/foo, /foo/ofcoder两个节点。proposerB收到请求先后创建/method，/method/far节点。&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_1.png&quot; alt=&quot;paxos不适合实现zookeeper&quot;/&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;proposerB先发起paxos的prepare阶段，并获得大多数选票，开始accept阶段。&lt;/li&gt;
&lt;li&gt;在proposerB的accept阶段，只有acceptA接收了提案[1, /method]，其他节点都通过了proposerA的prepare请求。&lt;/li&gt;
&lt;li&gt;根据规定，proposeA的accept的提案应该为[2, /method]，并通过该提案。&lt;/li&gt;
&lt;li&gt;此时proposerB重新开始paxos的两个阶段，得到达成共识的提案是[2, /method]。&lt;/li&gt;
&lt;li&gt;proposerA开始第二个值的paxos过程，即/foo/ofcoder。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;到此为止，可以看到当proposerA开始创建/foo/ofcoder时，则会发现/foo没有创建而导致失败。因为在第一轮paxos在集群中达成共识的值/method。&lt;/p&gt;
&lt;p&gt;通过上面的过程，我们更加论证了，paxos只适合在集群中使某个值达成共识，而不关心达成共识的值是什么。而在zookeeper中，这显然是不能满足业务需求的。&lt;/p&gt;
&lt;h3 id=&quot;ZAB术语科普&quot;&gt;&lt;a href=&quot;#ZAB术语科普&quot; class=&quot;headerlink&quot; title=&quot;ZAB术语科普&quot;/&gt;ZAB术语科普&lt;/h3&gt;&lt;p&gt;ZAB并不像paxos，是一种通用的分布式一致性算法，ZAB是一种专门为zookeeper设计的崩溃可恢复的原子广播协议。相比于paxos，&lt;strong&gt;ZAB主要解决了事务操作的顺序性&lt;/strong&gt;，在ZAB协议中，如果一个事务操作被处理了，那么所有其依赖的事务操作都应该被提前处理了。&lt;/p&gt;
&lt;p&gt;在学习ZAB之前，我们需要先整理几个术语、因为在ZAB的论文中，术语相对比较多，并且概念冗余。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提案（proposal）：进行协商的基本单元，在一些文档中，也有称之为操作（operation）、指令（command）。&lt;/li&gt;
&lt;li&gt;事务（transaction）：也是指提案，常出现在代码中，并非指具有ACID特性的一组操作。&lt;/li&gt;
&lt;li&gt;已提出的Proposal：指广播的第一阶段所提出的Proposal，未提交到状态机的Proposal。&lt;/li&gt;
&lt;li&gt;已提交的Proposal：指广播的第二阶段已提交到状态机的Proposal。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了帮助我们理解，ZAB定义了三个角色、四种节点状态、四种ZAB运行状态、以及两种运行模式。大家别看到我罗列了这么多，就打退堂鼓。从多个角度来归纳，只是为了更好的给大家呈现ZAB内部原理。&lt;/p&gt;
&lt;h4 id=&quot;三个角色&quot;&gt;&lt;a href=&quot;#三个角色&quot; class=&quot;headerlink&quot; title=&quot;三个角色&quot;/&gt;三个角色&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;观察者（observer）&lt;br/&gt;跟paxos中学习者类似，增加observer，可以在不影响集群写性能的情况下，提升读性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;四种节点状态&quot;&gt;&lt;a href=&quot;#四种节点状态&quot; class=&quot;headerlink&quot; title=&quot;四种节点状态&quot;/&gt;四种节点状态&lt;/h4&gt;&lt;p&gt;这是一个容易忽视的点，ZAB虽然规定了三种角色，但是他是通过定义四种状态来描述当前节点所处的角色的。包含以下状态：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LOOKING，竞选状态，当前集群不存在Leader。该状态下会发起领导者选举。&lt;/li&gt;
&lt;li&gt;FOLLOWING，随从状态，同步Leader状态，参与投票。&lt;/li&gt;
&lt;li&gt;OBSERVING，观察状态，同步Leader状态，不参与投票。&lt;/li&gt;
&lt;li&gt;LEADING，领导者状态，对应Leader角色。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里与角色对应多出来一个状态，是因为ZAB是支持自动Leader选举的，LOOKING是属于选举中的一个过渡状态。&lt;/p&gt;
&lt;h4 id=&quot;四种ZAB运行状态&quot;&gt;&lt;a href=&quot;#四种ZAB运行状态&quot; class=&quot;headerlink&quot; title=&quot;四种ZAB运行状态&quot;/&gt;四种ZAB运行状态&lt;/h4&gt;&lt;p&gt;这里是指ZAB集群的运行状态，因为ZAB除了正常向外部提供服务，还得有故障恢复功能。从整个集群的状态，我们可以了解ZAB的运行过程。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ELECTION，选举状态，表明节点正在进行Leader选举&lt;/li&gt;
&lt;li&gt;DISCOVERY，成员发现状态，在选举出新Leader后集群所处的状态，用于节点协商沟通Leader的合法性&lt;/li&gt;
&lt;li&gt;SYNCHRONIZATION，数据同步状态，在确认新Leader后，以Leader的数据为基础，修复各个节点的数据一致性&lt;/li&gt;
&lt;li&gt;BROADCARST，广播状态，集群处于正常运行状态，可向外提供服务&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;两种运行模式&quot;&gt;&lt;a href=&quot;#两种运行模式&quot; class=&quot;headerlink&quot; title=&quot;两种运行模式&quot;/&gt;两种运行模式&lt;/h4&gt;&lt;p&gt;从上述ZAB运行状态中，可以归纳为两种运行模式，即消息广播模式、崩溃恢复模式。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;崩溃恢复模式：&lt;br/&gt;在整个服务框架启动过程中、或者Leader服务器出现网络中断、崩溃退出等异常情况时，ZAB协议就会进入崩溃恢复模式并选举新的Leader服务器。当新的Leader服务器在集群中有过半的Follower与其完成成数据同步后，ZAB就会退出崩溃恢复模式。&lt;/li&gt;
&lt;li&gt;消息广播模式：&lt;br/&gt;当集群中已有过半的Follower与Leader完成数据同步，那么整个集群就会进入消息广播模式。此时整个集群才可以对外提供服务，即数据的查询、修改。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;值得注意是，当一台新的ZAB节点加入集群时，该节点会先进入崩溃恢复模式，找到Leader，并与其进行数据同步，然后一起参与到消息广播流程中。所以崩溃恢复模式还分为两个阶段：发现、同步。具体后文会详细讲解。&lt;/p&gt;
&lt;p&gt;后文讲解思路也是从这两种模式入手，在崩溃恢复模式中，再细分为三个阶段，也就是四种运行状态的前三种（ELECTION、DISCOVERY、SYNCHRONIZATION）。&lt;/p&gt;
&lt;h4 id=&quot;zxid&quot;&gt;&lt;a href=&quot;#zxid&quot; class=&quot;headerlink&quot; title=&quot;zxid&quot;/&gt;zxid&lt;/h4&gt;&lt;p&gt;这里把zxid单独拎出来描述，zxid在ZAB占据很重要的位置。Leader在收到事务请求，将其封装成Proposal时，会为每个Proposal生成对应的zxid。&lt;/p&gt;
&lt;p&gt;在消息广播模式中zxid标志者事务请求的先后顺序，在崩溃恢复模式中zxid是Leader的选举的判断依据，以及在Leader选举后，数据同步中zxid能方便的帮助ZAB抛弃上一个Leader没完成的Proposal。所以在学习下面的内容时，要及时参考zxid的设计逻辑。&lt;/p&gt;
&lt;p&gt;zxid它是一个64位，其中低32位可以看成一个简单的&lt;strong&gt;计数器&lt;/strong&gt;，而高32位则代表了Leader周期的&lt;strong&gt;epoch编号&lt;/strong&gt;。后文中使用&amp;lt;epoch, counter&amp;gt;标示一个zxid，例如&amp;lt;1, 101&amp;gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;epoch，则标示者当前集群所处的周期（年代），或者说当前Leader的周期（年代）。在每一次Leader变更后，新Leader产生的epoch则会在上一任Leader的epoch上进行加1，作为自己的epoch。&lt;/li&gt;
&lt;li&gt;计数器，则是针对客户端每一个事务请求，Leader在产生新的Proposal事务时，都会对该计数器加1。而Leader变更后，该计数器则会重置为0。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样做的好处：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;计数器，可以定义Proposal的先后顺序，保证发送提交事务消息广播顺序。&lt;/li&gt;
&lt;li&gt;epoch+计数器，能有效的避免zxid的冲突，不会出现Leader使用了相同编号的zxid提出了不一样的Proposal。&lt;/li&gt;
&lt;li&gt;能随时获取到最新的Leader周期（epoch），当Leader收到在网络故障后，收到比他大的epoch的Proposal，则证明集群中已有其他Leader，自己则变更为Follower。&lt;/li&gt;
&lt;li&gt;新Leader产生的zxid一定比上一任Leader产生zxid大。当上一任Leader宕机恢复后（以Follower角色）加入集群，如果有尚未提交的事务，则可以对比zxid进行抛弃（回退）那一些Proposal，直到回退到一个确实已经被集群中过半机器Commit的最新Proposal。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第3, 4点如果现在看不明白，在讲述崩溃恢复模式时，我会回过头来再讲讲的。&lt;/p&gt;
&lt;h3 id=&quot;消息广播模式&quot;&gt;&lt;a href=&quot;#消息广播模式&quot; class=&quot;headerlink&quot; title=&quot;消息广播模式&quot;/&gt;消息广播模式&lt;/h3&gt;&lt;p&gt;总的来说，消息广播模式是一个类似于二阶段提交（2PC）过程，针对客户端事务请求，Leader将其生成对应的Proposal，并发给所有的Follower，收集各自的选票后，最后进行事务提交。&lt;strong&gt;与2PC不同的是，ZAB移除了第二阶段的中断逻辑&lt;/strong&gt;。所有的Follower要么接收该Proposal，要么抛弃Leader服务器。这意味着Leader收到过半的Ack响应后就可以提交该事务了，而不需要等待所有的Follower都返回Ack。&lt;/p&gt;
&lt;p&gt;由于ZAB为了严格保证Proposal的因果关系，即事务请求的顺序性，ZAB为每个Proposal生成对应的zxid，并严格按照zxid的顺序，进行消息的广播。具体的，Leader会为了Follower分配一个单独的队列，将消息广播前，先将Proposal按照zxid顺序依次放入这些队列中，并根据FIFO策略进行消息发送。&lt;/p&gt;
&lt;p&gt;Follower在收到事务Proposal之后，都会将其以事务日志的形式写入本地磁盘中，并在写入成功后，返回给Leader一个Ack响应。当Leader服务器收到过半的Follower的Ack响应后，就会广播Commit消息给所有Follower通知其进行事务提交，同时Leader自身也会完成事务的提交。至此整个消息广播模式完成。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/theory/distributed/zab_4.png&quot; alt=&quot;消息广播&quot;/&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;客户端发起事务请求，由Leader进行处理&lt;/li&gt;
&lt;li&gt;Leader将该请求转换为事务Proposal，同时为Proposal分配一个全局的ID，即zxid&lt;/li&gt;
&lt;li&gt;Leader为每个Follower维护一个FIFO队列，将上一步生成的Proposal放入队列中，进行广播&lt;/li&gt;
&lt;li&gt;Follower收到Proposal后，会首先将其以事务日志的方式写入本地磁盘中，写入成功后向Leader反馈一个&lt;/li&gt;
&lt;li&gt;响应消息&lt;/li&gt;
&lt;li&gt;Leader收到过半的Ack响应后，自己完成对该Proposal的提交后，向每个Follower的队列中，写入Commit消息进行广播&lt;/li&gt;
&lt;li&gt;Follower接收到Commit消息后，会将上一条事务提交&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;如何保证事务执行的顺序&quot;&gt;&lt;a href=&quot;#如何保证事务执行的顺序&quot; class=&quot;headerlink&quot; title=&quot;如何保证事务执行的顺序&quot;/&gt;如何保证事务执行的顺序&lt;/h4&gt;&lt;p&gt;此时，我们得回到zxid的构成那部分，ZAB就是通过zxid中计数器，来保证提交顺序的，具体如下：&lt;/p&gt;
&lt;p&gt;在Leader收到客户端&lt;code&gt;set X、set Y&lt;/code&gt;两个请求后，会将其封装成两个Proposal（&amp;lt;1, 101&amp;gt;: X， &amp;lt;1, 102&amp;gt;: Y）进行广播所有的Follower。&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_5.png&quot; alt=&quot;消息广播&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当Leader收到过半的Ack响应后，则会进行Commit消息的广播。这里需要注意，&lt;strong&gt;Leader提交提案是有顺序性的&lt;/strong&gt;，按照zxid的大小，按顺序提交提案，&lt;strong&gt;如果前一个提案未提交，此时是不会提交后一个提案的&lt;/strong&gt;。因此X一定在Y之前提交。&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_6.png&quot; alt=&quot;消息广播&quot;/&gt;&lt;/p&gt;
&lt;p&gt;最后，Leader返回执行成功响应给客户端。完成本次消息广播。&lt;/p&gt;
&lt;h3 id=&quot;崩溃恢复模式&quot;&gt;&lt;a href=&quot;#崩溃恢复模式&quot; class=&quot;headerlink&quot; title=&quot;崩溃恢复模式&quot;/&gt;崩溃恢复模式&lt;/h3&gt;&lt;p&gt;通过上面的了解，我们知道了ZAB其实是一个强领导者模型的协议。消息广播模式，只能在ZAB正常运行中向外部提供服务。这也要求ZAB设计者不得不考虑，当Leader宕机或者失去过半的Follower节点后，如何恢复整个集群。&lt;/p&gt;
&lt;p&gt;为了更好理解崩溃恢复模式原理，通常会把他分为两个阶段或者三个阶段，即（Leader选举、Leader发现）、数据同步。&lt;/p&gt;
&lt;h4 id=&quot;基本约定&quot;&gt;&lt;a href=&quot;#基本约定&quot; class=&quot;headerlink&quot; title=&quot;基本约定&quot;/&gt;基本约定&lt;/h4&gt;&lt;p&gt;在选举新的Leader后，向外部提供服务之前，ZAB还需要保证数据正确性，即上一个Leader崩溃之时，正在处理的事务请求，可能会出现两个数据不一致的隐患。针对这样情况，ZAB保证一下特性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ZAB需要确保那些已经在Leader上&lt;strong&gt;提交&lt;/strong&gt;的事务最终被所有服务器都提交&lt;br/&gt;即：ProposalA在Leader上被提出后，收到过半的Follower的Ack响应，但是在将Commit请求广播给所有Follower机器之前，Leader宕机了。&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_2.png&quot; alt=&quot;ZAB崩溃恢复&quot;/&gt;&lt;br/&gt;在该图中，Leader先后广播了P1, P2, C1, P3, C2。其中Leader在广播C2（P2的Commit请求）之前宕机，ZAB会在崩溃恢复模式中，让所有的服务器都提交C2。&lt;/li&gt;
&lt;li&gt;ZAB需要确保丢弃那些仅仅只在Leader上被&lt;strong&gt;提出&lt;/strong&gt;的事务&lt;br/&gt;即：该约定是指，ZAB会抛弃那些只在Leader上被提出的事务，还没有任何Follower收到该请求。&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_3.png&quot; alt=&quot;ZAB崩溃恢复&quot;/&gt;&lt;br/&gt;在该场景中，Leader提出P3后宕机，还没有任何Follower收到该请求，则崩溃恢复模式中，整个集群会丢弃P3的事务。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Leader选举（ELECTION）&quot;&gt;&lt;a href=&quot;#Leader选举（ELECTION）&quot; class=&quot;headerlink&quot; title=&quot;Leader选举（ELECTION）&quot;/&gt;Leader选举（ELECTION）&lt;/h4&gt;&lt;p&gt;Leader的选举，关乎着整个集群的故障容错和集群可用性，是ZAB非常核心的设计之一。而Leader选举说白了，就是对比集群中各节点的信息，选举出最合适的节点当做Leader。而最合适的节点标准是什么，则是理解Leader选举（FastLeaderElection方式）的关键。&lt;/p&gt;
&lt;p&gt;ZAB采用的各节点广播自己所提议的Leader，收到其他节点提议的Leader后，与自己所提议的Leader进行PK，根据PK的规则重新选择提议的Leader，直到有过半的节点都提议某一节点，即结束Leader选举。&lt;/p&gt;
&lt;p&gt;Leader选举PK的规则包含以下几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;任期编号（epoch），优先判断epoch，epoch大的节点当选Leader&lt;/li&gt;
&lt;li&gt;事务标示符（zxid），epoch相同，则比较zxid，zxid大的当选Leader&lt;/li&gt;
&lt;li&gt;节点ID，epoch、zxid都一致，则比较节点ID（在myid文件中指定的值）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因为选举规则包含上述三个方面，则每个节点在广播自己所提议的Leader时，选票中都会包含上面三个值。后文使用&amp;lt;proposeLeader, epoch, zxid, node&amp;gt;，来表示一张选票，表明自己所有提议的Leader。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;proposeLeader，表示自己所提议的Leader的节点ID&lt;/li&gt;
&lt;li&gt;epoch，表示所提议的Leader节点所处的任期编号&lt;/li&gt;
&lt;li&gt;zxid，表示所提议的Leader节点拥有的Proposal最大的事务编号&lt;/li&gt;
&lt;li&gt;node，表示本次提议的节点&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里需要注意的是，这里的zxid是指ZAB在消息广播模式第一阶段的收到Proposal最大的zxid，即：&lt;strong&gt;节点收到被提出的Proposal最大的zxid，而不是已提交的Proposal最大的zxid&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;这里需要单独拎出来强调，有的伙计，在看zookeeper源码时，会看到Leader选举时，使用的是dataTree.lastProcessedZxid。而dataTree.lastProcessedZxid表示的是已提交的Proposal最大的zxid。这里没错，在正常运行时dataTree.lastProcessedZxid确实表示的是已提交的Proposal最大的zxid。但是当跟随者检测到异常，退出FOLLOWING状态时，在follower.shutdown()中，会使用lastProcessedZxid表示节点上收到已提出的Proposal的zxid。而后续的Leader选举使用的lastProcessedZxid，即为节点收到被提出的Proposal最大的zxid。&lt;/p&gt;
&lt;h5 id=&quot;算法陈述&quot;&gt;&lt;a href=&quot;#算法陈述&quot; class=&quot;headerlink&quot; title=&quot;算法陈述&quot;/&gt;算法陈述&lt;/h5&gt;&lt;p&gt;集群中存在三个节点A, B, C，各自节点ID依次为1, 2, 3。其中A为Leader，已提交两个Proposal（&amp;lt;1, 101&amp;gt;，&amp;lt;1, 102&amp;gt;），B、C为Follower，B已提交两个Proposal（&amp;lt;1, 101&amp;gt;，&amp;lt;1, 102&amp;gt;），C只提交了&amp;lt;1, 101&amp;gt;&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_7.png&quot; alt=&quot;Leader选举&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当A节点宕机后，跟随者检测Leader异常，则退出FOLLOWING状态，变更为LOOKING，发起Leader选举。&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_8.png&quot; alt=&quot;Leader选举&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当Follower开始第一轮提议Leader时，都会推荐自己为Leader，并向所有节点广播自己的提议，即B的选票为&amp;lt;2, 1, 102, B&amp;gt;，C的选票为&amp;lt;3, 1, 101, C&amp;gt;。各自将选票发给其他节点，B的选票发送给B、C，C的选票也发送给B、C。&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_9.png&quot; alt=&quot;Leader选举&quot;/&gt;&lt;/p&gt;
&lt;p&gt;B, C收到对方的选票后，根据上面描述的规则进行PK，依次比较epoch、zxid、节点ID。B、C首先会收到来自自己的提议的选票，因为收到选票与自己提议的选票相同，只需要接受和保存该选票。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当B收到来自C的选票&amp;lt;3, 1, 101, C&amp;gt;，由于epoch相同，B的zxid大于C的zxid，则B的选票获胜，不需要变更选票信息，保存即可。&lt;/li&gt;
&lt;li&gt;C收到来自B的选票&amp;lt;2, 1, 102, B&amp;gt;，由于epoch相同，C的zxid小于B的zxid，则C的选票落选。需要保存B的选票&amp;lt;2, 1, 102, B&amp;gt;，并变更自己的选票为&amp;lt;2, 1, 102, C&amp;gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/theory/distributed/zab_10.png&quot; alt=&quot;Leader选举&quot;/&gt;&lt;/p&gt;
&lt;p&gt;C节点在变更自己的选票信息后，会重新广播选票&amp;lt;2, 1, 102, C&amp;gt;给其他节点。B, C节点都收到来自C的新选票信息&amp;lt;2, 1, 102, C&amp;gt;，根据规则继续PK，结果肯定是B, C都保存两个选票（&amp;lt;2, 1, 102, B&amp;gt;, &amp;lt;2, 1, 102, C&amp;gt;）&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_11.png&quot; alt=&quot;Leader选举&quot;/&gt;&lt;/p&gt;
&lt;p&gt;最后，B, C所提议的领导者节点ID为2（即B节点），赢得了过半选票。则B竞选为准Leader，退出LOOKING状态，变更为LEADING，C节点变更状态为FOLLOWING，完成Leader选举。&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_12.png&quot; alt=&quot;Leader选举&quot;/&gt;&lt;/p&gt;
&lt;h5 id=&quot;逻辑时钟&quot;&gt;&lt;a href=&quot;#逻辑时钟&quot; class=&quot;headerlink&quot; title=&quot;逻辑时钟&quot;/&gt;逻辑时钟&lt;/h5&gt;&lt;p&gt;这里需要补充的是逻辑时钟，逻辑时钟也会影响Leader的选举，单独拎出来是为了描述选举算法时思路更清晰。&lt;/p&gt;
&lt;p&gt;逻辑时钟（logicclock），即选举的轮次，避免接收到旧的选票信息。每进行一轮选举，逻辑时钟变会增加。在选举中，逻辑时钟大的节点不会接收来自逻辑时钟小的节点的选票。&lt;/p&gt;
&lt;p&gt;比如，节点A, B的逻辑时钟分别为1, 2，那么B将拒绝接收来自A的选票信息。即使A的zxid大于B的zxid，B也会拒绝接收该选票。&lt;/p&gt;
&lt;h4 id=&quot;发现（DISCOVERY）&quot;&gt;&lt;a href=&quot;#发现（DISCOVERY）&quot; class=&quot;headerlink&quot; title=&quot;发现（DISCOVERY）&quot;/&gt;发现（DISCOVERY）&lt;/h4&gt;&lt;p&gt;在上一阶段，也就是ELECTION完成后，每个节点都有自己所保存的选票池，当选池中有过半的选票都提议同一节点为Leader时，则进入发现（DISCOVERY）状态。&lt;/p&gt;
&lt;p&gt;本节思路：会先按每一小步介绍过程，后面会画出整个过程的周期，所以每一小步会记作一个标记，方便后面描述整个过程。&lt;/p&gt;
&lt;p&gt;继续上一小节的案例。A, B, C三个节点，A宕机了，B为新选举的准Leader。其中B已提交两个Proposal（&amp;lt;1, 101&amp;gt;，&amp;lt;1, 102&amp;gt;），C只提交了&amp;lt;1, 101&amp;gt;。&lt;/p&gt;
&lt;p&gt;在该状态期间，由Follower会主动联系准Leader，并将自己最后接受的事务Proposal的epoch值发送给准Leader，这里记作FOLLOWERINFO。&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_13.png&quot; alt=&quot;发现（DISCOVERY）&quot;/&gt;&lt;/p&gt;
&lt;p&gt;准Leader收到来自过半（包含B节点自己）的FOLLOWERINFO消息后，会从这个FOLLOWERINFO中选取最大的epoch值，对其进行加1，作为新的epoch值，并封装成LEADERINFO消息发给这些过半的Follower。&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_14.png&quot; alt=&quot;发现（DISCOVERY）&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当Follower收到LEADERINFO消息后，会先校验LEADERINFO消息正确性。校验自己的epoch是否小于LEADERINFO消息中的epoch，如果小于，就将LEADERINFO消息中的epoch赋值给自己的epoch。并向准Leader返回Ack响应（ACKEPOCH），并将自己的运行状态变更为SYNCHRONIZATION。&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_15.png&quot; alt=&quot;发现（DISCOVERY）&quot;/&gt;&lt;/p&gt;
&lt;p&gt;最后Leader收到过半的ACKEPOCH消息后，也将自己的运行状态修改为SYNCHRONIZATION。至此完成发现阶段的工作，集群确立Leader的领导关系。&lt;/p&gt;
&lt;h4 id=&quot;数据同步（SYNCHRONIZATION）&quot;&gt;&lt;a href=&quot;#数据同步（SYNCHRONIZATION）&quot; class=&quot;headerlink&quot; title=&quot;数据同步（SYNCHRONIZATION）&quot;/&gt;数据同步（SYNCHRONIZATION）&lt;/h4&gt;&lt;p&gt;进入到数据同步阶段，我们需要先了解三种同步方式（DIFF、TRUNC、SNAP）。Leader会根据每个Follower的最大zxid，采用不同方式处理不一致的数据。&lt;/p&gt;
&lt;p&gt;在ZAB的设计中，Leader为了更高效的将Proposal复制给Follower，会在自己的内存队列中缓存一定数量（默认500）的已提交的Proposal。在内存中的Proposal就有zxid的最大值和最小值，即：maxCommittedZxid和minCommittedZxid。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DIFF：当Follower最大的zxid小于maxCommittedZxid且大于minCommittedZxid&lt;/li&gt;
&lt;li&gt;TRUNC：当Follower最大的zxid大于maxCommittedZxid时，该方式要求Follower丢弃超出的那部分Proposal&lt;/li&gt;
&lt;li&gt;SNAP：当Follower最大的zxid小于minCommittedZxid时，该方式直接同步快照给Follower&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;了解了同步方式，接下来来看看具体怎么交互的吧。该阶段由Leader根据Follower的最大zxid来发送数据同步消息。由于B已提交两个Proposal（&amp;lt;1, 101&amp;gt;，&amp;lt;1, 102&amp;gt;），C只提交了&amp;lt;1, 101&amp;gt;。该情况下Leader会选择DIFF的方式将其封装为NEWLEADER消息发给Follower。&lt;/p&gt;
&lt;p&gt;Follower在收到NEWLEADER消息后，进行修复不一致数据，并返回给Leader响应Ack消息。&lt;br/&gt;&lt;img src=&quot;/images/theory/distributed/zab_16.png&quot; alt=&quot;数据同步（SYNCHRONIZATION）&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Leader在收到过半Ack消息后，则完成数据同步阶段，将自己运行状态修改为BROADCARST（广播状态），并发送UPTODATE消息给过半的Follower，通知他们完成数据同步，修改运行状态修改为BROADCARST。&lt;/p&gt;
&lt;h4 id=&quot;整体回顾&quot;&gt;&lt;a href=&quot;#整体回顾&quot; class=&quot;headerlink&quot; title=&quot;整体回顾&quot;/&gt;整体回顾&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;/images/theory/distributed/zab_17.png&quot; alt=&quot;整体回顾&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;与paxos区别&quot;&gt;&lt;a href=&quot;#与paxos区别&quot; class=&quot;headerlink&quot; title=&quot;与paxos区别&quot;/&gt;与paxos区别&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;ZAB采用的是主备模式的系统架构，相比于paxos不同的是，paxos可以同时存在多个提议者进行提案，而ZAB同一时间只允许一个领导者进行提案，这样即解决客户端并发处理，又能规定提案的顺序性。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;思考几个题目吧&quot;&gt;&lt;a href=&quot;#思考几个题目吧&quot; class=&quot;headerlink&quot; title=&quot;思考几个题目吧&quot;/&gt;思考几个题目吧&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;zookeeper提供的最终一致性，任何节点都能处理读请求，但是读到的可能会是旧数据，如果必须要读到最新数据，怎么办？&lt;/p&gt;
&lt;figure class=&quot;highlight dart&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;zookeeper提供解决方案就是：&lt;span class=&quot;keyword&quot;&gt;sync&lt;/span&gt;命令。&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;你可以在读操作之前，先执行&lt;span class=&quot;keyword&quot;&gt;sync&lt;/span&gt;命令，这样客户端就能读到最新数据了。&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A, B, C三个节点，A为Leader，B有2个已提交的Proposal(&amp;lt;1, 101&amp;gt;, &amp;lt;1, 102&amp;gt;)，C有3个未提交Proposal(&amp;lt;1, 101&amp;gt;, &amp;lt;1, 102&amp;gt;, &amp;lt;1, 103&amp;gt;)。当A故障后，B和C谁会当选Leader呢？&lt;/p&gt;
&lt;figure class=&quot;highlight angelscript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;答案是C。&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;因为竞选Leader时，使用的是所有已提出的Proposal最大zxid。&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;C最大的zxid为&lt;span class=&quot;number&quot;&gt;103&lt;/span&gt;，而B最大的zxid为&lt;span class=&quot;number&quot;&gt;102&lt;/span&gt;。&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;那么C当选Leader。&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在选举中，会出现选票被瓜分、选举失败的问题吗？&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;不会出现选票被瓜分导致选举失败的情况。&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;因为每个节点的节点ID都是不同的，而节点ID会参与选票的判断。&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;在epoch、zxid都一致情况下，还有节点ID可以兜底来保证选票给哪一个节点。&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;有一个Proposal，在广播之前Leader宕机，经过崩溃恢复模式后，该Proposal是否会被提交？&lt;/p&gt;
&lt;figure class=&quot;highlight sqf&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;不一定，取决新当选的&lt;span class=&quot;built_in&quot;&gt;Leader&lt;/span&gt;是否包含该Proposal&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;如果上一任&lt;span class=&quot;built_in&quot;&gt;Leader&lt;/span&gt;，在广播第一阶段有个Follower收到了。而新当选的&lt;span class=&quot;built_in&quot;&gt;Leader&lt;/span&gt;又是该Follower&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;则该Proposal会被提交。&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在崩溃恢复后，Leader首先将自己的状态设置为广播，然后再通知其他节点修改。那么这是有写请求进来，会执行成功吗？&lt;/p&gt;
&lt;figure class=&quot;highlight sqf&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;会，这就是ZAB设计消息发送队列的原因，在&lt;span class=&quot;built_in&quot;&gt;Leader&lt;/span&gt;为广播状态时即可对外服务。&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;line&quot;&gt;因为新封装的Proposal请求，一定会在通知其他节点数据同步完成的消息（UPTODATE）之后处理&lt;/span&gt;&lt;br/&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d7688ebfa2ce07ef4eb7d86d3d36d558</guid>
<title>[推荐] 4 万字全面掌握数据库、数据仓库、数据集市、数据湖、数据中台</title>
<link>https://toutiao.io/k/y490i6z</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;如今，随着诸如互联网以及物联网等技术的不断发展，越来越多的数据被生产出来-据统计，每天大约有超过2.5亿亿字节的各种各样数据产生。这些数据需要被存储起来并且能够被方便的分析和利用。&lt;/p&gt;&lt;p&gt;随着大数据技术的不断更新和迭代，数据管理工具得到了飞速的发展，相关概念如雨后春笋一般应运而生，如从最初决策支持系统(DSS)到商业智能(BI)、数据仓库、数据湖、数据中台等，这些概念特别容易混淆，本文对这些名词术语及内涵进行系统的解析，便于读者对数据平台相关的概念有全面的认识。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;1.1 数据库&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;关系数据库本质上是一个二元关系，说的简单一些，就是一个二维表格，对普通人来说，最简单的理解就是一个Excel表格。这种数据库类型，具有结构化程度高，独立性强，冗余度低等等优点，一下子就促进了计算机的发展。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavib5LGVIKsw1TRywJkFZzRpvVSYGeghn8Y3icg56rzJyO5JnWAIpWbr7Uw/640?wx_fmt=png&quot; data-ratio=&quot;0.3575883575883576&quot; data-w=&quot;481&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;1.2 操作型数据库和分析型数据库&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;随着关系数据库理论的提出，诞生了一系列经典的RDBMS，如Oracle，MySQL，SQL Server等。这些RDBMS被成功推向市场，并为社会信息化的发展做出的重大贡献。然而随着数据库使用范围的不断扩大，它被逐步划分为两大基本类型：&lt;/p&gt;&lt;h4&gt;操作型数据库&lt;/h4&gt;&lt;p&gt;主要用于业务支撑。一个公司往往会使用并维护若干个操作型数据库，这些数据库保存着公司的日常操作数据，比如商品购买、酒店预订、学生成绩录入等；&lt;/p&gt;&lt;h4&gt;分析型数据库&lt;/h4&gt;&lt;p&gt;主要用于历史数据分析。这类数据库作为公司的单独数据存储，负责利用历史数据对公司各主题域进行统计分析；&lt;/p&gt;&lt;p&gt;那么为什么要&quot;分家&quot;？在一起不合适吗？能不能构建一个同样适用于操作和分析的统一数据库？答案是NO。一个显然的原因是它们会&quot;打架&quot;…如果操作型任务和分析型任务抢资源怎么办呢？再者，它们有太多不同，以致于早已&quot;貌合神离&quot;。接下来看看它们到底有哪些不同吧。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;1.3 操作型数据库 VS 分析型数据库&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibIfnQvAOunKXHAoarED9Ql6VxtgglTnkXrFPCFAHYPZwmNicpq3Mbnzg/640?wx_fmt=png&quot; data-ratio=&quot;0.45706371191135736&quot; data-w=&quot;722&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为主导功能的不同(面向操作/面向分析)，两类数据库就产生了很多细节上的差异。这就好像同样是人，但一个和尚和一个穆斯林肯定有很多行为/观念上的不同。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来本文将详细分析两类数据库的不同点：&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数据组成差别 - 数据时间范围差别&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般来讲，操作型数据库只会存放90天以内的数据，而分析型数据库存放的则是数年内的数据。这点也是将操作型数据和分析型数据进行物理分离的主要原因。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数据组成差别 - 数据细节层次差别&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;操作型数据库存放的主要是细节数据，而分析型数据库中虽然既有细节数据，又有汇总数据，但对于用户来说，重点关注的是汇总数据部分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;操作型数据库中自然也有汇总需求，但汇总数据本身不存储而只存储其生成公式。这是因为操作型数据是动态变化的，因此汇总数据会在每次查询时动态生成。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而对于分析型数据库来说，因为汇总数据比较稳定不会发生改变，而且其计算量也比较大(因为时间跨度大)，因此它的汇总数据可考虑事先计算好，以避免重复计算。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数据组成差别 - 数据时间表示差别&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;操作型数据通常反映的是现实世界的当前状态；而分析型数据库既有当前状态，还有过去各时刻的快照，分析型数据库的使用者可以综合所有快照对各个历史阶段进行统计分析。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;技术差别 - 查询数据总量和查询频度差别&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;操作型查询的数据量少而频率多，分析型查询则反过来，数据量大而频率少。要想同时实现这两种情况的配置优化是不可能的，这也是将两类数据库物理分隔的原因之一。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;技术差别 - 数据更新差别&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;操作型数据库允许用户进行增，删，改，查；分析型数据库用户则只能进行查询。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;技术差别 - 数据冗余差别&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据的意义是什么？就是减少数据冗余，避免更新异常。而如5所述，分析型数据库中没有更新操作。因此，减少数据冗余也就没那么重要了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在回到开篇是提到的第二个问题&quot;某大公司Hadoop Hive里的关系表不完全满足完整/参照性约束，也不完全满足范式要求，甚至第一范式都不满足。这种情况正常吗？&quot;，答曰是正常的。因为Hive是一种数据仓库，而数据仓库和分析型数据库的关系非常紧密(后文会讲到)。它只提供查询接口，不提供更新接口，这就使得消除冗余的诸多措施不需要被特别严格地执行了。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;功能差别 - 数据读者差别&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;操作型数据库的使用者是业务环境内的各个角色，如用户，商家，进货商等；分析型数据库则只被少量用户用来做综合性决策。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;功能差别 - 数据定位差别&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里说的定位，主要是指以何种目的组织起来。操作型数据库是为了支撑具体业务的，因此也被称为&quot;面向应用型数据库&quot;；分析型数据库则是针对各特定业务主题域的分析任务创建的，因此也被称为&quot;面向主题型数据库&quot;。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1 概述&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库就是为了解决数据库不能解决的问题而提出的。那么数据库无法解决什么样的问题呢？这个我们得先说说什么是OLAP和OLTP。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.2 OLTP和OLAP&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2.1 OLTP&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;OLTP（OnLine Transaction Processing 联机事务处理） 。简单一些，就是数据库的增删查改。举个例子，你到银行，去取一笔钱出来，或者转账，或者只是想查一下你还有多少存款，这些都是面向“事务”类型的操作。这样的操作有几个显著的特点:&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先要求速度很快，
基本上都是高可靠的在线操作（比如银行），
还有这些操作涉及的数据内容不会特别大（否则速度也就相应的降低），
最后，“事务”型的操作往往都要求是精准操作，比如你去银行取款，必须要求一个具体的数字，你是不可能对着柜台员工说我大概想取400到500快之间吧，那样人家会一脸懵逼。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.2.2 OLAP&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个东西又是上面发明关系型数据库的科德发明的。OLAP略有复杂，但这里我举一个简单的例子，大家就很容易理解了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如说，沃尔玛超市的数据库里有很多张表格，记录着各个商品的交易记录。超市里销售一种运动饮料，我们不妨称之为红牛。数据库中有一张表A，记录了红牛在一年的各个月份的销售额；还有一张表B，记录了红牛每个月在美国各个州的销售额：；甚至还有一张表C，记录了这家饮料公司在每个州对红牛饮料的宣传资金投入；甚至后来沃尔玛又从国家气象局拿到了美国各个州的一年365天每天的天气表。好，最后问题来了，请根据以上数据分析红牛在宣传资金不超过三百万的情况下，什么季节，什么天气，美国哪个州最好卖？凭借我们的经验，可能会得出，夏季的晴天，在美国的佛罗里达，最好卖，而且宣传资金投入越高销售额应该也会高。可能这样的结论是正确的，但决策者想要看到的是确凿的数据结论，而不是“可能”这样的字眼。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;科学是不相信直觉的，如果我们人工进行手动分析，会发现这个要考虑的维度实在太多了，根本无法下手，何况这才四五个维度，要是更多了怎么办？OLAP就是为了解决这样的问题诞生的，但糟糕的是，传统数据库是无法满足OLAP所需要的数据信息的。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.3 数据仓库概念&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3.1 概述&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据库的大规模应用，使得信息行业的数据爆炸式的增长，为了研究数据之间的关系，挖掘数据隐藏的价值，人们越来越多的需要使用OLAP来为决策者进行分析，探究一些深层次的关系和信息。但很显然，不同的数据库之间根本做不到数据共享，就算同一家数据库公司，数据库之间的集成也存在非常大的挑战（最主要的问题是庞大的数据如何有效合并、存储）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1988年，为解决企业的数据集成问题，IBM（卧槽，又是IBM）的两位研究员（Barry Devlin和Paul Murphy）创造性地提出了一个新的术语：数据仓库（Data Warehouse）。看到这里读者朋友们可能要问了，然后呢？然后…然后就没然后了。就在这个创世纪的术语诞生了之后，IBM就哑火了，只是将这个名词作为市场宣传的花哨概念，并没有在技术领域有什么实质性的研究和突破（可悲我大IBM=。=）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，尽管IBM不为所动，其他企业却在加紧对数据仓库的研究和开发，大家都想在这个领域寻找到第一桶金。终于，到了1992年，后来被誉为“数据仓库之父”的比尔 恩门（Bill Inmon）给出了数据仓库的定义，二十多年后的今天他的定义依然没有被时代淘汰。我们来看看他是怎么定义的：数据仓库是一个面向主题的、集成的、相对稳定的、反映历史变化的数据集合，用于支持管理中的决策制定。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于数据仓库的概念我们可以从两个层次予以理解：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先,数据仓库用于支持决策,面向分析型数据处理,它不同于企业现有的操作型数据库;
其次,数据仓库是对多个异构的数据源有效集成,集成后按照主题进行了重组,并包含历史数据,而且存放在数据仓库中的数据一般不再修改。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以不用管这个定义，简单的理解，其实就是我们为了进行OLAP，把分布在各个散落独立的数据库孤岛整合在了一个数据结构里面，称之为数据仓库。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个数据仓库在技术上是怎么建立的读者朋友们并不需要关心，但是我们要知道，原来各个数据孤岛中的数据，可能会在物理位置（比如沃尔玛在各个州可能都有自己的数据中心）、存储格式（比如月份是数值类型，但但天气可能是字符类型）、商业平台（不同数据库可能用的是Oracle数据库，有的是微软SQL Server数据库）、编写的语言（Java或者Scale等）等等各个方面完全不同，数据仓库要做的工作就是将他们按照所需要的格式提取出来，再进行必要的转换（统一数据格式）、清洗（去掉无效或者不需要的数据）等，最后装载进数据仓库（我们所说的ETL工具就是用来干这个的）。这样，拿我们上面红牛的例子来说，所有的信息就统一放在了数据仓库中了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;自从数据仓库出现之后，信息产业就开始从以关系型数据库为基础的运营式系统慢慢向决策支持系统发展。这个决策支持系统，其实就是我们现在说的商务智能（Business Intelligence）即BI。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以这么说，数据仓库为OLAP解决了数据来源问题，数据仓库和OLAP互相促进发展，进一步驱动了商务智能的成熟，但真正将商务智能赋予“智能”的，正是我们现在热谈的下一代技术：数据挖掘。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3.2 数据仓库特点&lt;span/&gt;&lt;/h3&gt;&lt;/section&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibsibpkmqKQbicdkGgbjGjNtuwV9WXvFfXHIuZp5CPicYuSDBHJddGCJ2icQ/640?wx_fmt=png&quot; data-ratio=&quot;0.2855191256830601&quot; data-w=&quot;732&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;面向主题&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;面向主题特性是数据仓库和操作型数据库的根本区别。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;操作型数据库是为了支撑各种业务而建立，&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而分析型数据库则是为了对从各种繁杂业务中抽象出来的分析主题(如用户、成本、商品等)进行分析而建立；所谓主题：是指用户使用数据仓库进行决策时所关心的重点方面，如：收入、客户、销售渠道等；所谓面向主题，是指数据仓库内的信息是按主题进行组织的，而不是像业务支撑系统那样是按照业务功能进行组织的。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;集成性&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;集成性是指数据仓库会将不同源数据库中的数据汇总到一起；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体来说，是指数据仓库中的信息不是从各个业务系统中简单抽取出来的，而是经过一系列加工、整理和汇总的过程，因此数据仓库中的信息是关于整个企业的一致的全局信息。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;企业范围&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库内的数据是面向公司全局的。比如某个主题域为成本，则全公司和成本有关的信息都会被汇集进来；&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;历史性&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;较之操作型数据库，数据仓库的时间跨度通常比较长。前者通常保存几个月，后者可能几年甚至几十年；&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;时变性&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;时变性是指数据仓库包含来自其时间范围不同时间段的数据快照。有了这些数据快照以后，用户便可将其汇总，生成各历史阶段的数据分析报告；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库内的信息并不只是反映企业当前的状态，而是记录了从过去某一时点到当前各个阶段的信息。通过这些信息，可以对企业的发展历程和未来趋势做出定量分析和预测。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3.3 数据仓库与BI&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库平台逐步从BI报表为主到分析为主、到预测为主、再到操作智能为目标。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibLZ5e75ynGN3SbssROczD4hJPtWNEdDnSjaN3swiaArGQNaRq1yavMXw/640?wx_fmt=png&quot; data-ratio=&quot;0.5054151624548736&quot; data-w=&quot;554&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从过去报表发生了什么—&amp;gt;分析为什么过去会发生----&amp;gt;将来会发生什么----&amp;gt;什么正在发生-----&amp;gt;让正确的事情发生&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;商务智能（BI，Business Intelligence）是一种以提供决策分析性的运营数据为目的而建立的信息系统。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;是属于在线分析处理：On Line Analytical Processing(OLAP)，将预先计算完成的汇总数据，储存于魔方数据库(Cube) 之中，针对复杂的分析查询，提供快速的响应。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在前10年，BI报表项目比较多，是数据仓库项目的前期预热项目（主要分析为主的阶段，是数据仓库的初级阶段），制作一些可视化报表展现给管理者:&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;它利用信息科技，将分散于企业内、外部各种数据加以整合并转换成知识，并依据某些特定的主题需求，进行决策分析和运算；用户则通过报表、图表、多维度分析的方式，寻找解决业务问题所需要的方案；这些结果将呈报给决策者，以支持策略性的决策和定义组织绩效，或者融入智能知识库自动向客户推送。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3.4 数据仓库系统作用和定位&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库系统的作用能实现跨业务条线、跨系统的数据整合，为管理分析和业务决策提供统一的数据支持。数据仓库能够从根本上帮助你把公司的运营数据转化成为高价值的可以获取的信息（或知识），并且在恰当的时候通过恰当的方式把恰当的信息传递给恰当的人。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibDDpbEZY8V5iaOib6BQusBl6V870x1ISeUmqujt1PQMQyhbRricTh5vH9w/640?wx_fmt=png&quot; data-ratio=&quot;0.4368231046931408&quot; data-w=&quot;554&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;是面向企业中、高级管理进行业务分析和绩效考核的数据整合、分析和展现的工具；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;是主要用于历史性、综合性和深层次数据分析；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据来源是ERP（例:SAP）系统或其他业务系统；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;能够提供灵活、直观、简洁和易于操作的多维查询分析;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;不是日常交易操作系统，不能直接产生交易数据。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;传统离线数据仓库针对实时数据处理，非结构化数据处理能力较弱，以及在业务在预警预测方面应用相对有限。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但现在已经开始兴起实时数仓。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.3.5 数据仓库能提供什么&lt;span/&gt;&lt;/h3&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibkOWZ45twz9OuBma29ZUqFK7RibV1vFjt9L7AoCDU3tZkJIib6Z1cdEXQ/640?wx_fmt=png&quot; data-ratio=&quot;0.45&quot; data-w=&quot;580&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.4 数据仓库组件&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库的核心组件有四个：业务系统各源数据库，ETL，数据仓库，前端应用。如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQaviblcqIs2ykMhar2y5L40f0bVKcfYWM0ibic8kfTfeC1a7UHswfFBpeduyQ/640?wx_fmt=png&quot; data-ratio=&quot;0.3568215892053973&quot; data-w=&quot;667&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;业务系统&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;业务系统包含各种源数据库，这些源数据库既为业务系统提供数据支撑，同时也作为数据仓库的数据源(注：除了业务系统，数据仓库也可从其他外部数据源获取数据)；&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;ETL&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库会周期不断地从源数据库提取清洗好了的数据，因此也被称为&quot;目标系统&quot;。ETL分别代表：&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;提取extraction&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;表示从操作型数据库搜集指定数据&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;转换transformation&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;表示将数据转化为指定格式，并进行数据清洗保证数据质量&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;加载load&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;加载过程表示将转换过后满足指定格式的数据加载进数据仓库。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;前端应用&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;和操作型数据库一样，数据仓库通常提供具有直接访问数据仓库功能的前端应用，这些应用也被称为BI(商务智能)应用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库系统除了包含分析产品本身之外，还包含数据集成、数据存储、数据计算、门户展现、平台管理等其它一系列的产品。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibU7cKeKPicZhQlacVCjHa52wcA8nqLWydexdtIekJahG3iaznUANr2TGg/640?wx_fmt=png&quot; data-ratio=&quot;0.6750902527075813&quot; data-w=&quot;554&quot; data-type=&quot;png&quot;/&gt;&lt;span&gt;数据仓库系统除了包含分析产品本身之外，还包含数据集成、数据存储、数据计算、门户展现、平台管理等其它一系列的产品。&lt;/span&gt; &lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibmIezPicKuZel2djo5LeauEjRmKCwzpLXqicp4Uc1u9btxrXgY25TkWYA/640?wx_fmt=png&quot; data-ratio=&quot;0.6895306859205776&quot; data-w=&quot;554&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.5 数据仓库开发流程&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5.1 概述&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库的开发流程和数据库的比较相似，因此本文仅就其中区别进行分析。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下图为数据仓库的开发流程：&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavib8RNyG00BlnxJMq63SWpVUu9JbfMmM5pPcJ1SYN2EYjyUycV0VWTqibw/640?wx_fmt=png&quot; data-ratio=&quot;0.3128834355828221&quot; data-w=&quot;652&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5.2 数据仓库需求&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;需求搜集是所有环节中最重要的一步，吃透了用户需求，往往就成功了大半。这些需求将指导后面如需求建模、实现、以及前端应用程序开发等。通常来说，需求都会通过ER图来表示(参考数据库需求与ER建模)，并和各业务方讨论搜集得到，最终整理成文档。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要特别强调的一点是数据仓库系统开发需求阶段过程是循环迭代式的，一开始的需求集并不大，但随着项目的进展，需求会越来越多。而且不论是以上哪个阶段发生了需求变动，整个流程都需要重新走一遍，决不允许隐式变更需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如为一个学生选课系统进行ER建模，得到如下结果：&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibUSXsDuZfBVI35GjiamrpTa3x4dJuNftEvlBmJ8T9EgcyGjyVLOibFOnQ/640?wx_fmt=png&quot; data-ratio=&quot;0.31479289940828403&quot; data-w=&quot;845&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5.3 数据仓库建模&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也就是逻辑模型建模，可参考第二篇：数据库关系建模&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ER建模环节完成后，需求就被描述成了ER图。之后，便可根据这个ER图设计相应的关系表了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但从ER图到具体关系表的建立还需要经过两个步骤：1. 逻辑模型设计 2. 物理模型设计。其中前者将ER图映射为逻辑意义上的关系表，后者则映射为物理意义上的关系表。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;逻辑意义上的关系表可以理解为单纯意义上的关系表，它不涉及到表中字段数据类型，索引信息，触发器等等细节信息。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibwde0L5zpIdmF0m9fNpJ7WysDLzuewr1EnicHEfUOBdBkW9IxFDXwTqw/640?wx_fmt=png&quot; data-ratio=&quot;1.049689440993789&quot; data-w=&quot;644&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;概念模型 VS 逻辑模型&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们首先可以认为【概念模型建模和ER建模，需求可视化】表达的是一个意思。在这个环节中，数据开发人员绘制ER图，并和项目各方人员协同需求，达成一致。由于这部分的工作涉及到的人员开发能力比较薄弱，甚至不懂开发，因此ER图必须清晰明了，不能涉及到过多的技术细节，比如：要给多对多联系/多值属性等多建一张表，要设置外码，各种复合主码等，它们应当对非开发人员透明。而且ER图中每个属性只会出现一次，减少了蕴含的信息量，是更好的交流和文档化工具。在ER图绘制完毕之后，才开始将它映射为关系表。这个映射的过程，就叫做逻辑模型建模或者关系建模。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有，ER模型所蕴含的信息，也没有全部被逻辑模型包含。比如联系的自定义基数约束，比如实体的复合属性，派生属性，用户的自定义约束等等。因此ER模型在整个开发流程(如物理模型建模，甚至前端开发)中是都会用到的，不能认为ER模型转换到逻辑模型后就可以扔一边了。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;逻辑模型VS物理模型&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;逻辑模型设计好后，就可以开始着手数据仓库的物理实现了，他也被称为物理模型建模，这个阶段不但需要参照逻辑模型，还应当参照ER图。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5.4 数据仓库实现&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一步的本质就是在空的数据仓库里实现2种前面创建的关系模型，一般通过使用SQL或者提供的前端工具实现。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5.5 开发前端应用程序&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前端应用开发在需求搜集好了之后就开始进行，主要有网站、APP等前端形式。另外前端程序的实际实现涉及到和数据仓库之间交互，因此这一步的最终完成在数据库建模之后。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5.6 ETL工程&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;较之数据库系统开发流程，数据仓库开发只多出ETL工程部分。然而这一部分极有可能是整个数据仓库开发流程中最为耗时耗资源的一个环节。因为该环节要整理各大业务系统中杂乱无章的数据并协调元数据上的差别，所以工作量很大。在很多公司都专门设有ETL工程师这样的岗位，大的公司甚至专门聘请ETL专家。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5.7 数据仓库部署&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;顾名思义，这一步就是部署数据库系统的软硬件环境。数据库部署往往还包含将初始数据填入数据库中的意思。对于云数据仓库，这一步就叫&quot;数据上云&quot;。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5.8 数据仓库使用&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一步没啥多讲的，就再讲一个有关的故事吧。同样是在A公司，有一次某政企私有云项目完成后，我们有人被派去给他们培训如何使用。结果去的人回来后说政企意见很大，认为让他们学习SQL以外的东西都不行。拒绝用Python写UDF，更拒绝MR编程接口，只要SQL和图形界面操作方式。一开始我对政企的这种行为有点看不起，但后来我想，就是因为有这群挑剔的用户，才使得A公司云产品的易用性如此强大，从而占领国内云计算的大部分市场。用户的需求才是技术的唯一试金石。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2.5.9 数据库管理和维护&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;严格来讲，这部分不算开发流程，属于数据库系统开发完成后的工作。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.6 数据仓库系统管理&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库系统发行后，控制权便从数据仓库设计、实现、部署的团队移交给了数据仓库管理员，并由他们来对系统进行管理，涵盖了确保一个已经部署的数据仓库系统正确运行的各种行为。为了实现这一目标，具体包含以下范畴：&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibSkEmlAqRQ3eWnemfKib2MialUuo20hgRict42HSBg8IEZdyETyNyNOaGA/640?wx_fmt=png&quot; data-ratio=&quot;0.4458161865569273&quot; data-w=&quot;729&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.7 数据质量体系&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库系统需要重视数据质量问题。用一句话概括，数据质量就是衡量数据能否真实、及时反映客观世界的指标。具体来说，数据质量包含以下几大指标：&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibF8HYdiaBKE9KyBe9JRbkt0KvWPuibtFXqN6SIQGIKIXQgHQs7sTwDUtA/640?wx_fmt=png&quot; data-ratio=&quot;0.43010752688172044&quot; data-w=&quot;651&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibPic6MxkBLICicylib0vdYsK1DHtWZK8t7sGAXExiceXrOv6Pcibq3jYarrA/640?wx_fmt=png&quot; data-ratio=&quot;0.48736462093862815&quot; data-w=&quot;554&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;准确性&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;准确性要求数据能够正确描述客观世界。比如某用户姓名拼音mu chen错误的录入成了muc hen，就应该弹出警告语；&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;唯一性（视情况而定）&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;唯一性要求数据不能被重复录入，或者不能有两个几乎相同的关系。比如张三李四在不同业务环境下分别建立了近乎相同的关系，这时应将这两个关系合并；&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;完整性&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;完整性要求进行数据搜集时，需求数据的被描述程度要高。比如一个用户的购买记录中，必然要有支付金额这个属性；规则验证。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;一致性&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一致性要求不同关系、或者同一关系不同字段的数据意义不发生冲突。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如某关系中昨天存货量字段+当天进货量字段-当天销售量字段等于当天存货量就可能是数据质量有问题；&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;及时性&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;及时性要求数据库系统中的数据&quot;保鲜&quot;。比如当天的购买记录当天就要入库；&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;统一性&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;统一性要求数据格式统一。比如nike这个品牌，不能有的字段描述为&quot;耐克&quot;，而有的字段又是&quot;奈克&quot;；&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;小结&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据质量和数据具体意义有很大相关性，因此无法单凭理论来保证。且由于具体业务及真实世界的复杂性，数据质量问题必然会存在，不可能完全预防得了。因此很多公司都提供了数据质量工程服务/软件，用来识别和校正数据库系统中的各种数据质量问题。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibvQYh8WaA3eTpM7y7HrOtEhOaib66SylvecIRgcV9Q0yeqmE3qf7QjFQ/640?wx_fmt=png&quot; data-ratio=&quot;0.75&quot; data-w=&quot;480&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Bill Inmon说过一句话叫“IT经理们面对最重要的问题就是到底先建立数据仓库还是先建立数据集市”，足以说明搞清楚这两者之间的关系是十分重要而迫切的！通常在考虑建立数据仓库之前，会涉及到如下一些问题：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;采取自上而下还是自下而上的设计方法&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;企业范围还是部门范围&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;先建立数据仓库还是数据集市&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;建立领航系统还是直接实施&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据集市是否相互独立&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据集市可以理解为是一种&quot;小型数据仓库&quot;，它只包含单个主题，且关注范围也非全局。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据集市可以分为两种:&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一种是独立数据集市(independent data mart)，这类数据集市有自己的源数据库和ETL架构；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另一种是非独立数据集市(dependent data mart)，这种数据集市没有自己的源系统，它的数据来自数据仓库。当用户或者应用程序不需要/不必要/不允许用到整个数据仓库的数据时，非独立数据集市就可以简单为用户提供一个数据仓库的子集。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.1 概述&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Pentaho首席技术官James Dixon创造了“数据湖”一词。它把数据集市描述成一瓶水（清洗过的，包装过的和结构化易于使用的）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而数据湖更像是在自然状态下的水，数据流从源系统流向这个湖。用户可以在数据湖里校验，取样或完全的使用数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个也是一个不精确的定义。数据湖还有以下特点：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;从源系统导入所有的数据，没有数据流失。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据存储时没有经过转换或只是简单的处理。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据转换和定义schema 用于满足分析需求。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibeCbOdeMribMEibgBsRSiacbpQnEMYBQ7LvVqLltvwyicicm4l4pXhsia6QRg/640?wx_fmt=png&quot; data-ratio=&quot;0.46488294314381273&quot; data-w=&quot;598&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖为什么叫数据湖而不叫数据河或者数据海？一个有意思的回答是：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;“河”强调的是流动性，“海纳百川”，河终究是要流入大海的，而企业级数据是需要长期沉淀的，因此叫“湖”比叫“河”要贴切；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同时，湖水天然是分层的，满足不同的生态系统要求，这与企业建设统一数据中心，存放管理数据的需求是一致的，“热”数据在上层，方便应用随时使用；温数据、冷数据位于数据中心不同的存储介质中，达到数据存储容量与成本的平衡。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不叫“海”的原因在于，海是无边无界的，而“湖”是有边界的，这个边界就是企业/组织的业务边界；因此数据湖需要更多的数据管理和权限管理能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;叫“湖”的另一个重要原因是数据湖是需要精细治理的，一个缺乏管控、缺乏治理的数据湖最终会退化为“数据沼泽”，从而使应用无法有效访问数据，使存于其中的数据失去价值。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.2 数据湖定义&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.2.1 维基百科对数据湖的定义&lt;span/&gt;&lt;/h3&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibfXRwXf2TvbIa2SqGP0wR14LmNvonwlib7cCmAjjYQKPx7Ru9J6MXPSw/640?wx_fmt=png&quot; data-ratio=&quot;0.6361940298507462&quot; data-w=&quot;536&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖（Data Lake）是一个存储企业的各种各样原始数据的大型仓库，其中的数据可供存取、处理、分析及传输。数据湖是以其自然格式存储的数据的系统或存储库，通常是对象blob或文件。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖通常是企业所有数据的单一存储，包括源系统数据的原始副本，以及用于报告、可视化、分析和机器学习等任务的转换数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖从企业的多个数据源获取原始数据，并且针对不同的目的，同一份原始数据还可能有多种满足特定内部模型格式的数据副本。因此，数据湖中被处理的数据可能是任意类型的信息，从结构化数据到完全非结构化数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;企业对数据湖寄予厚望，希望它能帮助用户快速获取有用信息，并能将这些信息用于数据分析和机器学习算法，以获得与企业运行相关的洞察力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖可以包括:&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;来自关系数据库（行和列）的结构化数据&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;半结构化数据（CSV，日志，XML，JSON）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;非结构化数据（电子邮件，文档，PDF）和二进制数据（图像，音频，视频）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目前，HDFS是最常用的部署数据湖的技术，所以很多人会觉得数据湖就是HDFS集群。数据湖是一个概念，而HDFS是用于实现这个概念的技术。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.2.2 AWS对数据湖的定义&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;AWS定义数据湖是一个集中式存储库，允许您以任意规模存储所有结构化和非结构化数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;A data lake is a centralized repository that allows you to store all your structured and unstructured data at any scale. You can store your data as-is, without having to first structure the data, and run different types of analytics—from dashboards and visualizations to big data processing, real-time analytics, and machine learning to guide better decisions.&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖是一个集中式存储库，允许您以任意规模存储所有结构化和非结构化数据。您可以按原样存储数据（无需先对数据进行结构化处理），并运行不同类型的分析 – 从控制面板和可视化到大数据处理、实时分析和机器学习，以指导做出更好的决策。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.2.3 微软对数据湖的定义&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;微软的定义就更加模糊了，并没有明确给出什么是Data Lake，而是取巧的将数据湖的功能作为定义，数据湖包括一切使得开发者、数据科学家、分析师能更简单的存储、处理数据的能力，这些能力使得用户可以存储任意规模、任意类型、任意产生速度的数据，并且可以跨平台、跨语言的做所有类型的分析和处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Azure Data Lake includes all the capabilities required to make it easy for developers, data scientists, and analysts to store data of any size, shape, and speed, and do all types of processing and analytics across platforms and languages. It removes the complexities of ingesting and storing all of your data while making it faster to get up and running with batch, streaming, and interactive analytics. Azure Data Lake works with existing IT investments for identity, management, and security for simplified data management and governance. It also integrates seamlessly with operational stores and data warehouses so you can extend current data applications. We’ve drawn on the experience of working with enterprise customers and running some of the largest scale processing and analytics in the world for Microsoft businesses like Office 365, Xbox Live, Azure, Windows, Bing, and Skype. Azure Data Lake solves many of the productivity and scalability challenges that prevent you from maximizing the value of your data assets with a service that’s ready to meet your current and future business needs.&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Azure的数据湖包括一切使得开发者、数据科学家、分析师能更简单的存储、处理数据的能力，这些能力使得用户可以存储任意规模、任意类型、任意产生速度的数据，并且可以跨平台、跨语言的做所有类型的分析和处理。数据湖在能帮助用户加速应用数据的同时，消除了数据采集和存储的复杂性，同时也能支持批处理、流式计算、交互式分析等。数据湖能同现有的数据管理和治理的IT投资一起工作，保证数据的一致、可管理和安全。它也能同现有的业务数据库和数据仓库无缝集成，帮助扩展现有的数据应用。Azure数据湖吸取了大量企业级用户的经验，并且在微软一些业务中支持了大规模处理和分析场景，包括Office 365, Xbox Live, Azure, Windows, Bing和Skype。Azure解决了许多效率和可扩展性的挑战，作为一类服务使得用户可以最大化数据资产的价值来满足当前和未来需求。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.2.4 数据湖定义小结&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖需要提供足够用的数据存储能力
这个存储保存了一个企业/组织中的所有数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖可以存储海量的任意类型的数据
包括结构化、半结构化和非结构化数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖中的数据是原始数据，是业务数据的完整副本。数据湖中的数据保持了他们在业务系统中原来的样子。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖需要具备完善的数据管理能力（完善的元数据）
可以管理各类数据相关的要素，包括数据源、数据格式、连接信息、数据schema、权限管理等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖需要具备多样化的分析能力
包括但不限于批处理、流式计算、交互式分析以及机器学习；同时，还需要提供一定的任务调度和管理能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖需要具备完善的数据生命周期管理能力。不光需要存储原始数据，还需要能够保存各类分析处理的中间结果，并完整的记录数据的分析处理过程，能帮助用户完整详细追溯任意一条数据的产生过程。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibVOjI8aAp9RAZH0EhoI0icZ43epejkyicUnV5lQRqXGiantXvWbj8el9Pg/640?wx_fmt=png&quot; data-ratio=&quot;0.471253534401508&quot; data-w=&quot;1061&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖需要具备完善的数据获取和数据发布能力。数据湖需要能支撑各种各样的数据源，并能从相关的数据源中获取全量/增量数据；然后规范存储。数据湖能将数据分析处理的结果推送到合适的存储引擎中，满足不同的应用访问需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于大数据的支持，包括超大规模存储以及可扩展的大规模数据处理能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上，个人认为数据湖应该是一种不断演进中、可扩展的大数据存储、处理、分析的基础设施；以数据为导向，实现任意来源、任意速度、任意规模、任意类型数据的全量获取、全量存储、多模式处理与全生命周期管理；并通过与各类外部异构数据源的交互集成，支持各类企业级应用。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.3 数据湖的处理架构&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.3.1 概述&lt;span/&gt;&lt;/h3&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibvn6aDleTjkqBUPrJs0jdmXgypjJJ6bajCOwarbeY1EZicnsZ2SoiaQKg/640?wx_fmt=png&quot; data-ratio=&quot;0.3953068592057762&quot; data-w=&quot;554&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖引擎介于管理数据系统、分析可视化和数据处理工具之间。数据湖引擎不是将数据从数据源移动到单个存储库，而是部署在现有数据源和数据使用者的工具(如BI工具和数据科学平台)之上。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibTID2oA7XyfAEGWGSBOWtyH59GQHBqTbxIxialeo3w9NNdZI8ia5II4jQ/640?wx_fmt=png&quot; data-ratio=&quot;0.5069444444444444&quot; data-w=&quot;720&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;BI分析工具，如Tableau、Power BI、R、Python和机器学习模型，是为数据生活在一个单一的、高性能的关系数据库中的环境而设计的。然而，多数组织使用不同的数据格式和不同的技术在多种解决方案中管理他们的数据。多数组织现在使用一个或多个非关系型数据存储，如云存储(如S3、ADLS)、Hadoop和NoSQL数据库(如Elasticsearch、Cassandra)。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当数据存储在一个独立的高性能关系数据库中时，BI工具、数据科学系统和机器学习模型可以很好运用这部分数据。然而，就像我们上面所说的一样，数据这并不是存在一个地方。因此，我们通常应用自定义ETL开发来集成来自不同系统的数据，以便于我们后续分析。通常分析技术栈分为以下几类：&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;ODS&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据从不同的数据库转移到单一的存储区域，如云存储服务(如Amazon S3、ADLS)、HDFS。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数据仓库&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然可以在Hadoop和云存储上直接执行SQL查询，但是这些系统的设计目的并不是提供交互性能。因此，数据的子集通常被加载到关系数据仓库或MPP数据库中，也就是构建数据仓库。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数据集市&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了在大型数据集上提供交互性能，必须通过在OLAP系统中构建多维数据集或在数据仓库中构建物化聚合表对数据进行预聚合&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种多层体系架构带来了许多挑战。例如：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;灵活性，比如数据源的变化或新的数据需求，必须重新访问数据仓库每一层，以确保后续应用人员来使用，可能会花费较长的实施周期。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;复杂性，数据分析人员必须了解所有存储数据的查询语法，增加了不必要的复杂性。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;技术成本，该架构需要广泛的定制ETL开发、DBA专业知识和数据工程来满足业务中不断发展的数据需求。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;基础设施成本，该架构需要大量的专有技术，并且通常会导致存储在不同系统中的数据产生许多副本。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据治理，该架构如果血缘关系搞的不好，便使得跟踪、维护变得非常困难。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据及时性，在ETL的过程中需要时间，所以一般数据是T-1的统计汇总。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖引擎采用了一种不同的方法来支持数据分析。数据湖引擎不是将数据移动到单个存储库中，而是在数据原本存储的地方访问数据，并动态地执行任何必要的数据转换和汇总。此外，数据湖引擎还提供了一个自助服务模型，使数据使用者能够使用他们喜欢的工具(如Power BI、Tableau、Python和R)探索、分析数据，而不用关心数据在哪存、结构如何。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有些数据源可能不适合分析处理，也无法提供对数据的有效访问。数据湖引擎提供了优化数据物理访问的能力。有了这种能力，可以在不改变数据使用者访问数据的方式和他们使用的工具的情况下优化各个数据集。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;与传统的解决方案相比，数据湖引擎使用多种技术使数据消费者能够访问数据，并集成这些技术功能到一个自助服务的解决方案中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖可以认为是新一代的大数据基础设施。为了更好的理解数据湖的基本架构，我们先来看看大数据基础设施架构的演进过程。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.3.2 第一阶段-以Hadoop为代表的离线数据处理基础设施&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖可以认为是新一代的大数据基础设施。为了更好的理解数据湖的基本架构，我们先来看看大数据基础设施架构的演进过程。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下图所示，Hadoop是以HDFS为核心存储，以MapReduce（简称MR）为基本计算模型的批量数据处理基础设施。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibgoFxaOiagRoDhgFmVUMJ4icwBKLU5z6S5K3mxDfSRXzVu4A8qVNmPLYQ/640?wx_fmt=png&quot; data-ratio=&quot;0.5990220048899756&quot; data-w=&quot;409&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;围绕HDFS和MR，产生了一系列的组件，不断完善整个大数据平台的数据处理能力，例如面向在线KV操作的HBase、面向SQL的HIVE、面向工作流的PIG等。同时，随着大家对于批处理的性能要求越来越高，新的计算模型不断被提出，产生了Tez、Spark、Presto、Flink等计算引擎，MR模型也逐渐进化成DAG模型。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DAG模型一方面增加计算模型的抽象并发能力：对每一个计算过程进行分解，根据计算过程中的聚合操作点对任务进行逻辑切分，任务被切分成一个个的stage，每个stage都可以有一个或者多个Task组成，Task是可以并发执行的，从而提升整个计算过程的并行能力；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另一方面，为减少数据处理过程中的中间结果写文件操作，Spark、Presto等计算引擎尽量使用计算节点的内存对数据进行缓存，从而提高整个数据过程的效率和系统吞吐能力。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.3.3 第二阶段：lambda架构&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;随着数据处理能力和处理需求的不断变化，越来越多的用户发现，批处理模式无论如何提升性能，也无法满足一些实时性要求高的处理场景，流式计算引擎应运而生，例如Storm、Spark Streaming、Flink等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，随着越来越多的应用上线，大家发现，其实批处理和流计算配合使用，才能满足大部分应用需求；而对于用户而言，其实他们并不关心底层的计算模型是什么，用户希望无论是批处理还是流计算，都能基于统一的数据模型来返回处理结果，于是Lambda架构被提出，如下图所示。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibxtOppwx4zTO0yfVsrYBHq2h6f3yzCY8o08BicTcHY4eRBdnSI6p25PA/640?wx_fmt=png&quot; data-ratio=&quot;0.6547619047619048&quot; data-w=&quot;420&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Lambda架构的核心理念是“流批一体”，如上图所示，整个数据流向自左向右流入平台。进入平台后一分为二，一部分走批处理模式，一部分走流式计算模式。无论哪种计算模式，最终的处理结果都通过统一服务层对应用提供，确保访问的一致性，底层到底是批或流对用户透明。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.3.4 第三阶段：Kappa架构&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Lambda架构虽然解决了应用读取数据的统一性问题，但是“流批分离”的处理链路增大了研发的复杂性。因此，有人就提出能不能用一套系统来解决所有问题。目前比较流行的做法就是基于流计算来做。流计算天然的分布式特征，注定了他的扩展性更好。通过加大流计算的并发性，加大流式数据的“时间窗口”，来统一批处理与流式处理两种计算模式。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavib0k9HQ2CRgiaQCicph4yzeYYWedvvsmCgW8OIW3BFIiaSfibHpknGB49Qtg/640?wx_fmt=png&quot; data-ratio=&quot;0.4519230769230769&quot; data-w=&quot;416&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;    &lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.3.5 大数据基础设施架构小结&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上，从传统的hadoop架构往lambda架构，从lambda架构往Kappa架构的演进，大数据平台基础架构的演进逐渐囊括了应用所需的各类数据处理能力，大数据平台逐渐演化成了一个企业/组织的全量数据处理平台。当前的企业实践中，除了关系型数据库依托于各个独立的业务系统；其余的数据，几乎都被考虑纳入大数据平台来进行统一的处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然而，目前的大数据平台基础架构，都将视角锁定在了存储和计算，而忽略了对于数据的资产化管理，这恰恰是数据湖作为新一代的大数据基础设施所重点关注的方向之一。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大数据基础架构的演进，其实反应了一点：在企业/组织内部，数据是一类重要资产已经成为了共识；为了更好的利用数据，企业/组织需要对数据资产进行如下操作：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;进行长期的原样存储，以便可回溯重放原始数据&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;进行有效管理与集中治理；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提供多模式的计算能力满足处理需求；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以及面向业务，提供统一的数据视图、数据模型与数据处理结果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖就是在这个大背景下产生的，除了有大数据平台所拥有的各类基础能力之外，数据湖更强调对于数据的管理、治理和资产化能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;落到具体的实现上，数据湖需要包括一系列的数据管理组件，包括：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据接入；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据搬迁；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据治理；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据质量管理；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;资产目录；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;访问控制；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;任务管理；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;任务编排；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;元数据管理等。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如下图所示，给出了一个数据湖系统的参考架构。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibDU5BKNhhibbYoV6mYaSG5pt47giaSAIBoiaraDU4pWv5Ghpta8yzy718w/640?wx_fmt=png&quot; data-ratio=&quot;0.5397590361445783&quot; data-w=&quot;830&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于一个典型的数据湖而言，它与大数据平台相同的地方在于它也具备处理超大规模数据所需的存储和计算能力，能提供多模式的数据处理能力；增强点在于数据湖提供了更为完善的数据管理能力，具体体现在：&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;更强大的数据接入能力。&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据接入能力体现在对于各类外部异构数据源的定义管理能力，以及对于外部数据源相关数据的抽取迁移能力，抽取迁移的数据包括外部数据源的元数据与实际存储的数据。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;更强大的数据管理能力。&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;管理能力具体又可分为基本管理能力和扩展管理能力：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;基本管理能力包括对各类元数据的管理、数据访问控制、数据资产管理，是一个数据湖系统所必须的，后面我们会在“各厂商的数据湖解决方案”一节相信讨论各个厂商对于基本管理能力的支持方式。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;扩展管理能力包括任务管理、流程编排以及与数据质量、数据治理相关的能力。任务管理和流程编排主要用来管理、编排、调度、监测在数据湖系统中处理数据的各类任务，通常情况下，数据湖构建者会通过购买/研制定制的数据集成或数据开发子系统/模块来提供此类能力，定制的系统/模块可以通过读取数据湖的相关元数据，来实现与数据湖系统的融合。而数据质量和数据治理则是更为复杂的问题，一般情况下，数据湖系统不会直接提供相关功能，但是会开放各类接口或者元数据，供有能力的企业/组织与已有的数据治理软件集成或者做定制开发。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;可共享的元数据。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖中的各类计算引擎会与数据湖中的数据深度融合，而融合的基础就是数据湖的元数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好的数据湖系统，计算引擎在处理数据时，能从元数据中直接获取数据存储位置、数据格式、数据模式、数据分布等信息，然后直接进行数据处理，而无需进行人工/编程干预。更进一步，好的数据湖系统还可以对数据湖中的数据进行访问控制，控制的力度可以做到“库表列行”等不同级别。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有一点应该指出的是，前面数据湖系统的参考架构图的集中式存储更多的是业务概念上的集中，本质上是希望一个企业/组织内部的数据能在一个明确统一的地方进行沉淀。事实上，数据湖的存储应该是一类可按需扩展的分布式文件系统，大多数数据湖实践中也是推荐采用S3/OSS/OBS/HDFS等分布式系统作为数据湖的统一存储。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以再切换到数据维度，从数据生命周期的视角来看待数据湖对于数据的处理方式，数据在数据湖中的整个生命周期如下图所示。理论上，一个管理完善的数据湖中的数据会永久的保留原始数据，同时过程数据会不断的完善、演化，以满足业务的需要。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibBiakqst3HnrcbjxCpp657djWTtOrZmdyTOicLQISSIxKrbybZ2ohyAsQ/640?wx_fmt=png&quot; data-ratio=&quot;0.35917312661498707&quot; data-w=&quot;774&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.4 数据湖能给企业带来多种能力&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖能给企业带来多种能力，例如，能实现数据的集中式管理，在此之上，企业能挖掘出很多之前所不具备的能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，数据湖结合先进的数据科学与机器学习技术，能帮助企业构建更多优化后的运营模型，也能为企业提供其他能力，如预测分析、推荐模型等，这些模型能刺激企业能力的后续增长。数据湖能从以下方面帮助到企业：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实现数据治理（data governance）；&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;通过应用机器学习与人工智能技术实现商业智能；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;预测分析，如领域特定的推荐引擎；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;信息追踪与一致性保障；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;根据对历史的分析生成新的数据维度；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;有一个集中式的能存储所有企业数据的数据中心，有利于实现一个针对数据传输优化的数据服务；&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;帮助组织或企业做出更多灵活的关于企业增长的决策。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.5 数据湖与数据仓库区别&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibJKFSLjCka5d1gMV5yQY048D7EiccMzJgVXhPJfBRbnegc6TDHF13F2Q/640?wx_fmt=png&quot; data-ratio=&quot;0.7011884550084889&quot; data-w=&quot;589&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibRrDOCGicuMG6B8VS7iaHcdweN9fxrxPz4PoDBlZ28kkd3WEGGZSECCyA/640?wx_fmt=png&quot; data-ratio=&quot;4.270833333333333&quot; data-w=&quot;480&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.5.1 概述&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于数据仓库与数据湖的不同之处，你可以想象一下仓库和湖泊的区别：仓库存储着来自特定来源的货物，而湖泊的水来自河流、溪流和其他来源，并且是原始数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库供应商包括AWS、Cloudera、IBM、谷歌、微软、甲骨文、Teradata、SAP、SnapLogic和Snowflake等。数据湖提供商包括AWS、谷歌、Informatica、微软、Teradata等。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.5.2 数据湖保留全部的数据&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;存储范围&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库开发期间，大量的时间花费在分析数据源，理解商业处理和描述数据。结果就是为报表设计高结构化的数据模型。这一过程大部分的工作就是来决定数据应不应该导入数据仓库。通常情况下，如果数据不能满足指定的问题，就不会导入到数据仓库。这么做是为了简化数据模型和节省数据存储空间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相反，数据湖保留所有的数据。不仅仅是当前正在使用的数据，甚至不被用到的数据也会导进来。数据会一直被保存所有我们可以回到任何时间点来做分析。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为数据湖使用的硬件与数据仓库的使用的不同，使这种方法成为了可能。现成的服务器与便宜的存储相结合，使数据湖扩展到TB级和PB级非常经济。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;存储来源&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库主要存储来自运营系统的大量数据&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而数据湖则存储来自更多来源的数据，包括来自企业的运营系统和其他来源的各种原始数据资产集。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.5.3 数据湖支持所有数据类型&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在储存方面上，数据湖中数据为非结构化的，所有数据都保持原始形式，并且仅在分析时再进行转换。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库一般由从事务系统中提取的数据组成，并由定量度量和描述它们的属性组成。诸如Web服务器日志，传感器数据，社交网络活动，文本和图像等非传统数据源在很大程度上被忽略。这些数据类型的新用途不断被发现，但是消费和存储它们可能是昂贵和困难的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖方法包含这些非传统数据类型。在数据湖中，我们保留所有数据，而不考虑源和结构。我们保持它的原始形式，并且只有在我们准备好使用它时才会对其进行转换。这种方法被称为“读时模式”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库则是捕获结构化数据并将其按模式组织。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.5.4 适用人群&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于数据湖中的数据可能不准确，并且可能来自企业运营系统之外的来源，因此不是很适合普通的业务分析用户;数据湖更适合数据科学家和其他数据分析专家，使用他们需要的非常庞大和多样化的数据集。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其他用户则可以使用更为结构化的数据视图如数据仓库来提供他们使用的数据，数据仓库非常适用于月度报告等操作用途，因为它具有高度结构化。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.5.5 数据湖很容易适应变化&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于数据仓库的主要抱怨之一是需要多长时间来改变它们。在开发过程中花费大量时间来获得仓库的结构。一个好的仓库设计可以适应变化，但由于数据加载过程的复杂性以及为简化分析和报告所做的工作，这些更改必然会消耗一些开发人员资源并需要一些时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;许多业务问题都迫不及待地让数据仓库团队适应他们的系统来回答问题。日益增长的对更快答案的需求促成了自助式商业智能的概念。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另一方面，在数据湖中，由于所有数据都以其原始形式存储，并且始终可供需要使用它的人访问，因此用户有权超越仓库结构以新颖方式探索数据并回答它们问题在他们的步伐。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果一个探索的结果被证明是有用的并且有重复的愿望，那么可以应用更正式的模式，并且可以开发自动化和可重用性来帮助将结果扩展到更广泛的受众。如果确定结果无用，则可以丢弃该结果，并且不会对数据结构进行任何更改，也不会消耗开发资源。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，在架构方面：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖通常在存储数据之后定义架构，使用较少的初始工作并提供更大的灵活性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在数据仓库中存储数据之前定义架构。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.5.6 数据湖支持快速洞察数据&lt;span/&gt;&lt;/h3&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibeUpYeXwNKodlt6F3lIiaYH4cnoVOgib8VnjOl2DvShbv2eSvNHYTDM8g/640?wx_fmt=png&quot; data-ratio=&quot;0.32037037037037036&quot; data-w=&quot;1080&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后的区别实际上是其他区别结果。由于数据湖包含所有数据和数据类型，因为它使用户能够在数据转换，清理和结构化之前访问数据，从而使用户能够比传统数据仓库方法更快地获得结果。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，这种对数据的早期访问是有代价的。通常由数据仓库开发团队完成的工作可能无法完成分析所需的部分或全部数据源。这让驾驶座位的用户可以根据需要探索和使用数据，但上述第一层业务用户可能不希望这样做。他们仍然只想要他们的报告和KPI。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在数据湖中，这些操作报告的使用者将利用更加结构化的数据湖中数据的结构视图，这些视图与数据仓库中以前一直存在的数据相似。不同之处在于，这些视图主要存在于位于湖泊中的数据之上的元数据，而不是需要开发人员更改的物理刚性表格。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.6 数据湖和数据仓库理解误区&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;很多人认为数据仓库和数据湖在架构上只能二选一，其实这种理解是错误的。数据湖和数据仓库并不是对立关系，相反它们的并存可以互补给企业架构带来更多的好处：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库存储结构化的数据，适用于快速的BI和决策支撑，&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而数据湖可以存储任何格式的数据，往往通过挖掘能够发挥出数据的更大作为。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以在一些场景上二者的并存是可以给企业带来更多效益的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;人工智能（AI）和机器学习项目的成功往往需要数据湖来做支撑。因为数据湖可让您存储几乎任何类型的数据而无需先准备或清理，所以可以保留尽可能多的潜在价值。而数据仓库存储的数据都是经过清洗，往往会丢失一些有价值的信息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库虽然是这两种中比较知名的，但是随着数据挖掘需求的发展，数据湖的受欢迎程度可能会继续上升。数据仓库对于某些类型的工作负载和用例工作良好，而数据湖则是为其他类型的工作负载提供服务的另一种选择。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;确实，数据湖需要数据工程师和数据科学家的特定技能，才能对存储在其中的数据进行分类和利用。数据的非结构化性质使那些不完全了解数据湖如何工作的人更难以访问它。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是，一旦数据科学家和数据工程师建立了数据模型或管道，业务用户就可以利用建立的数据模型以及流行的业务工具（定制或预先构建）的来访问和分析数据，而不在乎该数据存储在数据仓库中还是数据湖中。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.7 数据湖建设的基本过程&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;个人认为数据湖是比传统大数据平台更为完善的大数据处理基础支撑设施，完善在数据湖是更贴近客户业务的技术存在。所有数据湖所包括的、且超出大数据平台存在的特性，例如元数据、数据资产目录、权限管理、数据生命周期管理、数据集成和数据开发、数据治理和质量管理等，无一不是为了更好的贴近业务，更好的方便客户使用。数据湖所强调的一些基本的技术特性，例如弹性、存储计算独立扩展、统一的存储引擎、多模式计算引擎等等，也是为了满足业务需求，并且给业务方提供最具性价比的TCO。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖的建设过程应该与业务紧密结合；但是数据湖的建设过程与传统的数据仓库，甚至是大热的数据中台应该是有所区别的。区别在于，数据湖应该以一种更敏捷的方式去构建，“边建边用，边用边治理”。为了更好的理解数据湖建设的敏捷性，我们先来看一下传统数仓的构建过程。业界对于传统数仓的构建提出了“自下而上”和“自顶而下”两种模式，分别由Inmon和KimBall两位大牛提出。具体的过程就不详述了，不然可以再写出几百页，这里只简单阐述基本思想。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1）Inmon提出自下而上（EDW-DM）的数据仓库建设模式，即操作型或事务型系统的数据源，通过ETL抽取转换和加载到数据仓库的ODS层；ODS层中的数据，根据预先设计好的EDW（企业级数据仓库）范式进行加工处理，然后进入到EDW。EDW一般是企业/组织的通用数据模型，不方便上层应用直接做数据分析；因此，各个业务部门会再次根据自己的需要，从EDW中处理出数据集市层（DM）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优势：易于维护，高度集成；劣势：结构一旦确定，灵活性不足，且为了适应业务，部署周期较长。此类方式构造的数仓，适合于比较成熟稳定的业务，例如金融。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2）KimBall提出自顶而下（DM-DW）的数据架构，通过将操作型或事务型系统的数据源，抽取或加载到ODS层；然后通过ODS的数据，利用维度建模方法建设多维主题数据集市（DM）。各个DM，通过一致性的维度联系在一起，最终形成企业/组织通用的数据仓库。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优势：构建迅速，最快的看到投资回报率，敏捷灵活；劣势：作为企业资源不太好维护，结构复杂，数据集市集成困难。常应用于中小企业或互联网行业。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实上述只是一个理论上的过程，其实无论是先构造EDW，还是先构造DM，都离不开对于数据的摸底，以及在数仓构建之前的数据模型的设计，包括当前大热的“数据中台”，都逃不出下图所示的基本建设过程。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibic0VqtSV0wic2EL1YILwsHqhMUbibuiaH81oBLxjeL1Y3evaMr9ticeNJgQ/640?wx_fmt=png&quot; data-ratio=&quot;0.3057692307692308&quot; data-w=&quot;520&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1） 数据摸底。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于一个企业/组织而言，在构建数据湖初始工作就是对自己企业/组织内部的数据做一个全面的摸底和调研，包括数据来源、数据类型、数据形态、数据模式、数据总量、数据增量等。在这个阶段一个隐含的重要工作是借助数据摸底工作，进一步梳理企业的组织结构，明确数据和组织结构之间关系。为后续明确数据湖的用户角色、权限设计、服务方式奠定基础。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2） 模型抽象。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对企业/组织的业务特点梳理归类各类数据，对数据进行领域划分，形成数据管理的元数据，同时基于元数据，构建通用的数据模型。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3） 数据接入。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据第一步的摸排结果，确定要接入的数据源。根据数据源，确定所必须的数据接入技术能力，完成数据接入技术选型，接入的数据至少包括：数据源元数据、原始数据元数据、原始数据。各类数据按照第二步形成的结果，分类存放。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4） 融合治理。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单来说就是利用数据湖提供的各类计算引擎对数据进行加工处理，形成各类中间数据/结果数据，并妥善管理保存。数据湖应该具备完善的数据开发、任务管理、任务调度的能力，详细记录数据的处理过程。在治理的过程中，会需要更多的数据模型和指标模型。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5） 业务支撑。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在通用模型基础上，各个业务部门定制自己的细化数据模型、数据使用流程、数据访问服务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上述过程，对于一个快速成长的互联网企业来说，太重了，很多情况下是无法落地的，最现实的问题就是第二步模型抽象，很多情况下，业务是在试错、在探索，根本不清楚未来的方向在哪里，也就根本不可能提炼出通用的数据模型；没有数据模型，后面的一切操作也就无从谈起，这也是很多高速成长的企业觉得数据仓库/数据中台无法落地、无法满足需求的重要原因之一。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖应该是一种更为“敏捷”的构建方式，我们建议采用如下步骤来构建数据湖。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibauHtsp7zR6j8fyiaLWoCoELcG93Pb2L5w1x5MicfU21heuiaMlHZqwTSQ/640?wx_fmt=png&quot; data-ratio=&quot;0.3057692307692308&quot; data-w=&quot;520&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对比，依然是五步，但是这五步是一个全面的简化和“可落地”的改进。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1） 数据摸底。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;依然需要摸清楚数据的基本情况，包括数据来源、数据类型、数据形态、数据模式、数据总量、数据增量。但是，也就需要做这么多了。数据湖是对原始数据做全量保存，因此无需事先进行深层次的设计。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2） 技术选型。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据数据摸底的情况，确定数据湖建设的技术选型。事实上，这一步也非常的简单，因为关于数据湖的技术选型，业界有很多的通行的做法，基本原则个人建议有三个：“计算与存储分离”、“弹性”、“独立扩展”。建议的存储选型是分布式对象存储系统（如S3/OSS/OBS）；计算引擎上建议重点考虑批处理需求和SQL处理能力，因为在实践中，这两类能力是数据处理的关键，关于流计算引擎后面会再讨论一下。无论是计算还是存储，建议优先考虑serverless的形式；后续可以在应用中逐步演进，真的需要独立资源池了，再考虑构建专属集群。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3） 数据接入。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;确定要接入的数据源，完成数据的全量抽取与增量接入。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4） 应用治理。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一步是数据湖的关键，我个人把“融合治理”改成了“应用治理”。从数据湖的角度来看，数据应用和数据治理应该是相互融合、密不可分的。从数据应用入手，在应用中明确需求，在数据ETL的过程中，逐步形成业务可使用的数据；同时形成数据模型、指标体系和对应的质量标准。数据湖强调对原始数据的存储，强调对数据的探索式分析与应用，但这绝对不是说数据湖不需要数据模型；恰恰相反，对业务的理解与抽象，将极大的推动数据湖的发展与应用，数据湖技术使得数据的处理与建模，保留了极大的敏捷性，能快速适应业务的发展与变化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从技术视角来看，数据湖不同于大数据平台还在于数据湖为了支撑数据的全生命周期管理与应用，需要具备相对完善的数据管理、类目管理、流程编排、任务调度、数据溯源、数据治理、质量管理、权限管理等能力。在计算能力上，目前主流的数据湖方案都支持SQL和可编程的批处理两种模式（对机器学习的支持，可以采用Spark或者Flink的内置能力）；在处理范式上，几乎都采用基于有向无环图的工作流的模式，并提供了对应的集成开发环境。对于流式计算的支持，目前各个数据湖解决方案采取了不同的方式。在讨论具体的方式之前，我们先对流计算做一个分类：&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;1） 模式一：实时模式。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种流计算模式相当于对数据采用“来一条处理一条”/“微批”的方式进行处理；多见于在线业务，如风控、推荐、预警等。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;2） 模式二：类流式。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种模式需要获取指定时间点之后变化的数据/读取某一个版本的数据/读取当前的最新数据等，是一种类流式的模式；多见于数据探索类应用，如分析某一时间段内的日活、留存、转化等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;二者的本质不同在于，模式一处理数据时，数据往往还没有存储到数据湖中，仅仅是在网路/内存中流动；模式二处理数据时，数据已经存储到数据湖中了。综上，我个人建议采用如下图模式：&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibY78yeQQW9PIRflP3WRXanGlp2xgta1uINYeL3Kbweiaib1Z7yt004c7w/640?wx_fmt=png&quot; data-ratio=&quot;0.4679334916864608&quot; data-w=&quot;842&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图24 数据湖数据流向示意图&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如图24所示，在需要数据湖具备模式一的处理能力时，还是应该引入类Kafka中间件，作为数据转发的基础设施。完整的数据湖解决方案方案应该提供将原始数据导流至Kafka的能力。流式引擎具备从类Kafka组件中读取数据的能力。流式计算引擎在处理数据过后，根据需要，可以将结果写入OSS/RDBMS/NoSQL/DW，供应用访问。某种意义上，模式一的流计算引擎并非一定要作为数据湖不可分割的一部分存在，只需要在应用需要时，能够方便的引入即可。但是，这里需要指出的是：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1）流式引擎依然需要能够很方便的读取数据湖的元数据；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2）流式引擎任务也需要统一的纳入数据湖的任务管理；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3）流式处理任务依然需要纳入到统一的权限管理中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于模式二，本质上更接近于批处理。现在许多经典的大数据组件已经提供了支持方式，如HUDI/IceBerg/Delta等，均支持Spark、Presto等经典的计算引擎。以HUDI为例，通过支持特殊类型的表（COW/MOR），提供访问快照数据（指定版本）、增量数据、准实时数据的能力。目前AWS、腾讯等已经将HUDI集成到了其EMR服务中，阿里云的DLA也正在计划推出DLA on HUDI的能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;让我们再回到本文开头的第一章，我们说过，数据湖的主要用户是数据科学家和数据分析师，探索式分析和机器学习是这类人群的常见操作；流式计算（实时模式）多用于在线业务，严格来看，并非数据湖目标用户的刚需。但是，流式计算（实时模式）是目前大多数互联网公司在线业务的重要组成部分，而数据湖作为企业/组织内部的数据集中存放地，需要在架构上保持一定的扩展能力，可以很方便的进行扩展，整合流式计算能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;5） 业务支撑。虽然大多数数据湖解决方案都对外提供标准的访问接口，如JDBC，市面上流行的各类BI报表工具、大屏工具也都可以直接访问数据湖中的数据。但是在实际的应用中，我们还是建议将数据湖处理好的数据推送到对应的各类支持在线业务的数据引擎中去，能够让应用有更好的体验。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.8 主流厂商数据湖解决方案&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.8.1 AWS数据湖解决方案&lt;span/&gt;&lt;/h3&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibW3PDlRImHz9WoXQ2L2q3XibONMPR1541BqaWR3SiaKiciaGjCl7Jt3TtOQ/640?wx_fmt=png&quot; data-ratio=&quot;0.4119170984455959&quot; data-w=&quot;772&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整个方案基于AWS Lake Formation构建，AWS Lake Formation本质上是一个管理性质的组件，它与其他AWS服务互相配合，来完成整个企业级数据湖构建功能。上图自左向右，体现了数据流入、数据沉淀、数据计算、数据应用四个步骤。我们进一步来看其关键点：&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数据流入&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据流入是整个数据湖构建的起始，包括元数据的流入和业务数据流入两个部分。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;元数据流入包括数据源创建、元数据抓取两步，最终会形成数据资源目录，并生成对应的安全设置与访问控制策略。解决方案提供专门的组件，获取外部数据源的相关元信息，该组件能连接外部数据源、检测数据格式和模式（schema），并在对应的数据资源目录中创建属于数据湖的元数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;业务数据的流入是通过ETL来完成的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在具体的产品形式上，元数据抓取、ETL和数据准备AWS将其单独抽象出来，形成了一个产品叫AWS GLUE。AWS GLUE与AWS Lake Formation共享同一个数据资源目录，在AWS GLUE官网文档上明确指出：“Each AWS account has one AWS Glue Data Catalog per AWS region”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于异构数据源的支持。AWS提供的数据湖解决方案，支持S3、AWS关系型数据库、AWS NoSQL数据库，AWS利用GLUE、EMR、Athena等组件支持数据的自由流动。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数据沉淀&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;采用Amazon S3作为整个数据湖的集中存储，按需扩展/按使用量付费。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数据计算&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整个解决方案利用AWS GLUE来进行基本的数据处理。GLUE基本的计算形式是各类批处理模式的ETL任务，任务的出发方式分为手动触发、定时触发、事件触发三种。不得不说，AWS的各类服务在生态上实现的非常好，事件触发模式上，可以利用AWS Lambda进行扩展开发，同时触发一个或多个任务，极大的提升了任务触发的定制开发能力；同时，各类ETL任务，可以通过CloudWatch进行很好的监控。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数据应用。&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在提供基本的批处理计算模式之外，AWS通过各类外部计算引擎，来提供丰富的计算模式支持，例如通过Athena/Redshift来提供基于SQL的交互式批处理能力；通过EMR来提供各类基于Spark的计算能力，包括Spark能提供的流计算能力和机器学习能力。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;权限管理&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;AWS的数据湖解决方案通过Lake Formation来提供相对完善的权限管理，粒度包括“库-表-列”。但是，有一点例外的是，GLUE访问Lake Formation时，粒度只有“库-表”两级；这也从另一个侧面说明，GLUE和Lake Formation的集成是更为紧密的，GLUE对于Lake Formation中的数据有更大的访问权限。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Lake Formation的权限进一步可以细分为数据资源目录访问权限和底层数据访问权限，分别对应元数据与实际存储的数据。实际存储数据的访问权限又进一步分为数据存取权限和数据存储访问权限：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据存取权限类似于数据库中对于库表的访问权限&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据存储权限则进一步细化了对于S3中具体目录的访问权限（分为显示和隐式两种）。如下图所示，用户A在只有数据存取的权限下，无法创建位于S3指定bucket下的表。&lt;/p&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibSPj1wBoe7rxHoDasSiaUHkrfOtIH87cVh28uldiclPfqlwdQztia6ZIMg/640?wx_fmt=png&quot; data-ratio=&quot;0.775623268698061&quot; data-w=&quot;361&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;个人认为这进一步体现了数据湖需要支持各种不同的存储引擎，未来的数据湖可能不只S3/OSS/OBS/HDFS一类核心存储，可能根据应用的访问需求，纳入更多类型的存储引擎，例如，S3存储原始数据，NoSQL存储处理过后适合以“键值”模式访问的数据，OLAP引擎存储需要实时出各类报表/adhoc查询的数据。虽然当前各类材料都在强调数据湖与数据仓库的不同；但是，从本质上，数据湖更应该是一类融合的数据管理思想的具体实现，“湖仓一体化”也很可能是未来的一个发展趋势。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上，AWS数据湖方案成熟度高，特别是元数据管理、权限管理上考虑充分，打通了异构数据源与各类计算引擎的上下游关系，让数据能够自由“移动”起来。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在流计算和机器学习上，AWS的解决方案也比较完善：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;流计算方面AWS推出了专门的流计算组件Kinesis，Kinesis中的Kinesis data Firehose服务可以创建一个完全被托管的数据分发服务，通过Kinesis data Stream实时处理的数据，可以借助Firehose方便的写入S3中，并支持相应的格式转换，如将JSON转换成Parquet格式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;AWS整个方案最牛的地方还在与Kinesis可以访问GLUE中的元数据，这一点充分体现了AWS数据湖解决方案在生态上的完备性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同样，在机器学习方面，AWS提供了SageMaker服务，SageMaker可以读取S3中的训练数据，并将训练好的模型回写至S3中。但是，有一点需要指出的是，在AWS的数据湖解决方案中，流计算和机器学习并不是固定捆绑的，只是作为计算能力扩展，能方便的集成。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，让我们回到数据湖组件参考架构，看看AWS的数据湖解决方案的组件覆盖情况，参见下图 AWS 数据湖解决方案在参考架构中的映射。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/ul&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibKfKUzzKcCEUqgXxo50rN7COD1TCZH1K0f7MSnBchyRr7AugzwQKVicA/640?wx_fmt=png&quot; data-ratio=&quot;0.5927710843373494&quot; data-w=&quot;830&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上，AWS的数据湖解决方案覆盖了除质量管理和数据治理的所有功能。其实质量管理和数据治理这个工作和企业的组织结构、业务类型强相关，需要做大量的定制开发工作，因此通用解决方案不囊括这块内容，也是可以理解的。事实上，现在也有比较优秀的开源项目支持这个项目，比如Apache Griffin，如果对质量管理和数据治理有强诉求，可以自行定制开发。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.8.2 华为数据湖解决方案&lt;span/&gt;&lt;/h3&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibIchtKZCQic18KCoOXeb9nm9h01CtWebpB1Ip5akYh7qYG8HQaJjkENQ/640?wx_fmt=png&quot; data-ratio=&quot;0.633423180592992&quot; data-w=&quot;742&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;华为的数据湖解决方案相关信息来自华为官网。目前官网可见的相关产品包括数据湖探索（Data Lake Insight，DLI）和智能数据湖运营平台（DAYU）：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中DLI相当于是AWS的Lake Formation、GLUE、Athena、EMR（Flink&amp;amp;Spark）的集合。官网上没找到关于DLI的整体架构图，我根据自己的理解，尝试画了一个，主要是和AWS的解决方案有一个对比，所以形式上尽量一致。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;华为的数据湖解决方案比较完整，DLI承担了所有的数据湖构建、数据处理、数据管理、数据应用的核心功能。DLI最大的特色是在于分析引擎的完备性，包括基于SQL的交互式分析以及基于Spark+Flink的流批一体处理引擎。在核心存储引擎上，DLI依然通过内置的OBS来提供，和AWS S3的能力基本对标。华为数据湖解决方案在上下游生态上做的比AWS相对完善，对于外部数据源，几乎支持所有目前华为云上提供的数据源服务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DLI可以与华为的CDM（云数据迁移服务）和DIS（数据接入服务）对接：1）借助DIS，DLI可以定义各类数据点，这些点可以在Flink作业中被使用，做为source或者sink；2）借助CDM，DLI甚至能接入IDC、第三方云服务的数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了更好的支持数据集成、数据开发、数据治理、质量管理等数据湖高级功能，华为云提供了DAYU平台。DAYU平台是华为数据湖治理运营方法论的落地实现。DAYU涵盖了整个数据湖治理的核心流程，并对其提供了相应的工具支持；甚至在华为的官方文档中，给出了数据治理组织的构建建议。DAYU的数据治理方法论的落地实现如下图所示（来自华为云官网）。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavib3HUEqjIPKsv4qFzgy88B5qjbhVaKHeTGrcPnXaRONN4ialiaK2zxKr6Q/640?wx_fmt=png&quot; data-ratio=&quot;0.4703703703703704&quot; data-w=&quot;1080&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以看到，本质上DAYU数据治理的方法论其实是传统数据仓库治理方法论在数据湖基础设施上的延伸：从数据模型来看，依然包括贴源层、多源整合层、明细数据层，这点与数据仓库完全一致。根据数据模型和指标模型会生成质量规则和转换模型，DAYU会和DLI对接，直接调用DLI提供的相关数据处理服务，完成数据治理。华为云整个的数据湖解决方案，完整覆盖了数据处理的生命周期，并且明确支持了数据治理，并提供了基于模型和指标的数据治理流程工具，在华为云的数据湖解决方案中逐渐开始往“湖仓一体化”方向演进。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.8.3 阿里云数据湖解决方案&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阿里云上数据类产品众多，因为本人目前在数据BU，所以本节方案将关注在如何使用数据库BU的产品来构建数据湖，其他云上产品会略有涉及。阿里云的基于数据库产品的数据湖解决方案更加聚焦，主打数据湖分析和联邦分析两个场景。阿里云数据湖解决方案如下图所示。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibXJLBsZa9sDadKoicibb50GRicrodicO5XVFEBqxI7sSckJC95ryia1GUznA/640?wx_fmt=png&quot; data-ratio=&quot;0.5689655172413793&quot; data-w=&quot;870&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整个方案依然采用OSS作为数据湖的集中存储。在数据源的支持上，目前也支持所有的阿里云数据库，包括OLTP、OLAP和NoSQL等各类数据库。核心关键点如下：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据接入与搬迁。在建湖过程中，DLA的Formation组件具备元数据发现和一键建湖的能力，在本文写作之时，目前“一键建湖”还只支持全量建湖，但是基于binlog的增量建湖已经在开发中了，预计近期上线。增量建湖能力会极大的增加数据湖中数据的实时性，并将对源端业务数据库的压力降到最下。这里需要注意的是，DLA Formation是一个内部组件，对外并没有暴露。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据资源目录。DLA提供Meta data catalog组件对于数据湖中的数据资产进行统一的管理，无论数据是在“湖中”还是在“湖外”。Meta data catalog也是联邦分析的统一元数据入口。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在内置计算引擎上，DLA提供了SQL计算引擎和Spark计算引擎两种。无论是SQL还是Spark引擎，都和Meta data catalog深度集成，能方便的获取元数据信息。基于Spark的能力，DLA解决方案支持批处理、流计算和机器学习等计算模式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在外围生态上，除了支持各类异构数据源做数据接入与汇聚之外，在对外访问能力上，DLA与云原生数据仓库（原ADB）深度整合。一方面，DLA处理的结果可之际推送至ADB中，满足实时、交互式、ad hoc复杂查询；另一方面，ADB里的数据也可以借助外表功能，很方便的进行数据回流至OSS中。基于DLA，阿里云上各类异构数据源可以完全被打通，数据自由流动。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在数据集成和开发上，阿里云的数据湖解决方案提供两种选择：一种是采用dataworks完成；另一种是采用DMS来完成。无论是选择哪种，都能对外提供可视化的流程编排、任务调度、任务管理能力。在数据生命周期管理上，dataworks的数据地图能力相对更加成熟。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在数据管理和数据安全上，DMS提供了强大的能力。DMS的数据管理粒度分为“库-表-列-行”，完善的支持企业级的数据安全管控需求。除了权限管理之外，DMS更精细的地方是把原来基于数据库的devops理念扩展到了数据湖，使得数据湖的运维、开发更加精细化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;进一步细化整个数据湖方案的数据应用架构，如下图所示。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibedgmhxGT3oPcZ9ZPF0L2AOPmHiaJHzG8s3BBJbytNh9JlT1S5FaCZdA/640?wx_fmt=png&quot; data-ratio=&quot;0.4323308270676692&quot; data-w=&quot;532&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;自左向右从数据的流向来看，数据生产者产生各类数据（云下/云上/其他云），利用各类工具，上传至各类通用/标准数据源，包括OSS/HDFS/DB等。针对各类数据源，DLA通过数据发现、数据接入、数据迁移等能力，完整建湖操作。对于“入湖”的数据，DLA提供基于SQL和Spark的数据处理能力，并可以基于Dataworks/DMS，对外提供可视化的数据集成和数据开发能力；在对外应用服务能力上，DLA提供标准化的JDBC接口，可以直接对接各类报表工具、大屏展示功能等。阿里云的DLA的特色在于背靠整个阿里云数据库生态，包括OLTP、OLAP、NoSQL等各类数据库，对外提供基于SQL的数据处理能力，对于传统企业基于数据库的开发技术栈而言，转型成本相对较低，学习曲线比较平缓。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阿里云的DLA解决方案的另一个特色在于“基于云原生的湖仓一体化”。传统的企业级数据仓库在大数据时代的今天，在各类报表应用上依然是无法替代的；但是数仓无法满足大数据时代的数据分析处理的灵活性需求；因此，我们推荐数据仓库应该作为数据湖的上层应用存在：即数据湖是原始业务数据在一个企业/组织中唯一官方数据存储地；数据湖根据各类业务应用需求，将原始数据进行加工处理，形成可再次利用的中间结果；当中间结果的数据模式（Schema）相对固定后，DLA可以将中间结果推送至数据仓库，供企业/组织开展基于数仓的业务应用。阿里云在提供DLA的同时，还提供了云原生数仓（原ADB），DLA和云原生数仓在以下两点上深度融合。1） 使用同源的SQL解析引擎。DLA的SQL与ADB的SQL语法上完全兼容，这意味着开发者使用一套技术栈即能同时开发数据湖应用和数仓应用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2） 都内置了对于OSS的访问支持。OSS直接作为DLA的原生存储存在；对于ADB而言，可以通过外部表的能力，很方便的访问OSS上的结构化数据。借助外部表，数据可以自由的在DLA和ADB之间流转，做到真正的湖仓一体。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DLA+ADB的组合真正做到了云原生的湖仓一体（关于什么是云原生，不在本文的讨论范畴）。本质上，DLA可以看成一个能力扩展的数据仓库贴源层。与传统数仓相比，该贴源层：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;（1）可以保存各类结构化、半结构化和非结构化数据；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;（2）可以对接各类异构数据源；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;（3）具备元数据发现、管理、同步等能力；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;（4）内置的SQL/Spark计算引擎具备更强的数据处理能力，满足多样化的数据处理需求；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;（5）具备全量数据的全生命周期管理能力。基于DLA+ADB的湖仓一体化方案，将同时覆盖“大数据平台+数据仓库”的处理能力。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavib55MlibljsPdoONvSiatzW1UH8Fu9Hgo099XUdODDT7osbEuBVpJNdv2Q/640?wx_fmt=png&quot; data-ratio=&quot;0.576&quot; data-w=&quot;500&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DLA还有一个重要能力是构建了一个“四通八达”的数据流动体系，并以数据库的体验对外提供能力，无论数据在云上还是云下，无论数据在组织内部还是外部；借助数据湖，各个系统之间的数据不再存在壁垒，可以自由的流进流出；更重要的是，这种流动是受监管的，数据湖完整的记录了数据的流动情况。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.8.4 Microsoft Azure数据湖解决方案&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Azure的数据湖解决方案包括数据湖存储、接口层、资源调度与计算引擎层，如下图所示（来自Azure官网）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;存储层是基于Azure object Storage构建的，依然是对结构化、半结构化和非结构化数据提供支撑。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接口层为WebHDFS，比较特别的是在Azure object Storage实现了HDFS的接口，Azure把这个能力称为“数据湖存储上的多协议存取”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在资源调度上，Azure基于YARN实现。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;计算引擎上，Azure提供了U-SQL、hadoop和Spark等多种处理引擎。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibVkwlh4H06gRlacibp8YRQSVEpRgCjKy5hEJwEO3kZ9003eF75ic6rn3w/640?wx_fmt=png&quot; data-ratio=&quot;0.3886113886113886&quot; data-w=&quot;1001&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Azure的特别之处是基于visual studio提供给了客户开发的支持。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;开发工具的支持
与visual studio的深度集成；Azure推荐使用U-SQL作为数据湖分析应用的开发语言。Visual studio为U-SQL提供了完备的开发环境；同时，为了降低分布式数据湖系统开发的复杂性，visual studio基于项目进行封装，在进行U-SQL开发时，可以创建“U-SQL database project”，在此类项目中，利用visual studio，可以很方便的进行编码与调试，同时，也提供向导，将开发好的U-SQL脚本发布到生成环境。U-SQL支持Python、R进行扩展，满足定制开发需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;多计算引擎的适配：SQL, Apache Hadoop和Apache Spark。这里的hadoop包括Azure提供的HDInsight（Azure托管的Hadoop服务），Spark包括Azure Databricks。- 多种不同引擎任务之间的自动转换能力。微软推荐U-SQL为数据湖的缺省开发工具，并提供各类转换工具，支持U-SQL脚本与Hive、Spark（HDSight&amp;amp;databricks）、Azure Data Factory data Flow之间的转化。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.8.5 小结&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文所讨论的是数据湖的解决方案，不会涉及到任何云厂商的单个产品。我们从数据接入、数据存储、数据计算、数据管理、应用生态几个方面，简单做了一个类似下表的总结。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibvN1TialhbMHEPFnOyObnqwx4Qya8ibcqIibQk9yUq0jPMdaFv4wePrR2g/640?wx_fmt=png&quot; data-ratio=&quot;0.3924050632911392&quot; data-w=&quot;553&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;出于篇幅关系，其实知名云厂商的数据湖解决方案还有谷歌和腾讯的。这两家从其官方网站上看，数据湖解决方案相对来讲比较简单，也仅仅是一些概念上的阐述，推荐的落地方案是“oss+hadoop（EMR）”。其实数据湖不应该从一个简单的技术平台视角来看，实现数据湖的方式也多种多样，评价一个数据湖解决方案是否成熟，关键应该看其提供的数据管理能力，具体包括但不限于元数据、数据资产目录、数据源、数据处理任务、数据生命周期、数据治理、权限管理等；以及与外围生态的对接打通能力。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.9 典型的数据湖应用案例&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.9.1 广告数据分析&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;近年来，流量获取的成本就越来越高，线上渠道获客成本的成倍增长让各行各业都面临着严峻的挑战。在互联网广告成本不断攀升的大背景下，以花钱买流量拉新为主要的经营策略必然行不通了。流量前端的优化已成强弩之末，利用数据工具提高流量到站后的目标转化，精细化运营广告投放的各个环节，才是改变现状更为直接有效的方式。说到底，要提高广告流量的转化率，必须依靠大数据分析。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了能够提供更多的决策支撑依据，需要采取更多的埋点数据的收集和分析，包括但不限于渠道、投放时间、投放人群，以点击率为数据指标进行数据分析，从而给出更好的、更迅速的方案和建议，实现高效率高产出。因此，面对广告投放领域多维度、多媒体、多广告位等结构化、半结构化和非结构化数据采集、存储、分析和决策建议等要求，数据湖分析产品解决方案在广告主或者发布商进行新一代技术选型中上受到了很热烈的青睐。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;DG是一家全球领先的企业国际化智能营销服务商，基于先进的广告技术、大数据和运营能力，为客户提供全球高质量用户获取及流量变现服务。DG从成立之初就决定以公有云为基础来构建其IT基础设施，最初DG选择了AWS云平台，主要将其广告数据在S3中以数据湖的形态进行存放，通过Athena进行交互式分析。然而随着互联网广告的飞速发展，广告行业带来了几大挑战，移动广告的发布与追踪系统必须解决几个关键问题：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1） 并发性与峰值问题。在广告行业，流量高峰时常出现，瞬间的点击量可能达到数万，甚至数十万，这就要求系统具备非常好的可扩展性以快速响应和处理每一次点击&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2） 如何实现对海量数据的实时分析。为了监控广告投放效果，系统需要实时对用户的每一次点击和激活数据进行分析，同时把相关数据传输到下游的媒体；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3） 平台的数据量在急剧增长，每天的业务日志数据在持续的产生和上传，曝光、点击、推送的数据在持续处理，每天新增的数据量已经在10-50TB左右，对整个数据处理系统提出了更高的要求。如何高效地完成对广告数据的离线/近实时统计，按照广告客户的维度要求进行聚合分析。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对上述三点业务挑战，同时DG这个客户日增量数据正在急剧变大（当前日数据扫描量达到100+TB），继续在AWS平台使用遇到Athena读取S3数据带宽瓶颈、数据分析滞后时间越来越长、为应对数据和分析需求增长而急剧攀升的投入成本等，经过认真、仔细的测试和分析，最终决定从AWS云平台全量搬站到阿里云平台，新架构图如下：&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibfLMA57KNzuNbVhoOcsbseSicrT17GuVXw2dJUaribpPhSqBRnHUPSLUA/640?wx_fmt=png&quot; data-ratio=&quot;0.4376130198915009&quot; data-w=&quot;553&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图16. 改造后的广告数据湖方案架构&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从AWS搬站到阿里云后，我们为该客户设计了“利用Data Lake Analytics + OSS”极致分析能力来应对业务波峰波谷。一方面轻松应对来自品牌客户的临时分析。另一方面利用Data Lake Analytics的强大计算能力，分析按月、季度广告投放，精确计算出一个品牌下面会有多少个活动，每个活动分媒体，分市场，分频道，分DMP的投放效果，进一步增强了加和智能流量平台为品牌营销带来的销售转化率。并且在广告投放与分析的总拥有成本上，Data Lake Analytics提供的Serverless的弹性服务为按需收费，不需要购买固定的资源，完全契合业务潮汐带来的资源波动，满足弹性的分析需求，同时极大地降低了运维成本和使用成本。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavib9y15uic1WBUMAF09YDUB532nqVVTbpBS2EFH6PnXeerk0pTNXnobEwQ/640?wx_fmt=png&quot; data-ratio=&quot;0.42857142857142855&quot; data-w=&quot;553&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图17 数据湖部署示意图&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总体上，DG从AWS切换到阿里云后，极大地节省了硬件成本、人力成本和开发成本。由于采用DLA serverless云服务，DG无需先期投入大量的资金去购买服务器、存储等硬件设备，也无需一次性购买大量的云服务，其基础设施的规模完全是按需扩展：需求高的时候增加服务数量，需求减少的时候减少服务数量，提高了资金的利用率。使用阿里云平台带来的第二个显著好处是性能的提升。在DG业务的快速增长期以及后续多条业务线接入期，DG在移动广告系统的访问量经常呈爆发式增长，然而原先AWS方案和平台在Athena读取S3数据遇到数据读取带宽的极大瓶颈，数据分析的时间变得越来越长，阿里云DLA联合OSS团队等进行了极大的优化和改造，同时，DLA数据库分析在计算引擎上（与TPC-DS打榜世界第一的AnalyticDB共享计算引擎）比Presto原生计算引擎的能力提升数十倍性能，也极大的为DG提升了分析性能。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.9.2 游戏运营分析&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖是一类TCO表现极其优秀的大数据基础设施。对于很多快速增长的游戏公司而言，一个爆款游戏，往往在短期内相关数据增长极快；同时，公司的研发人员的技术栈很难在短期内与数据的增量和增速进行匹配；此时，呈爆发增长的数据很难被有效利用。数据湖是一个解决此类问题的技术选择。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;YJ是一家高速成长的游戏公司，公司希望能依托相关用户行为数据进行深入分析，指导游戏的开发和运营。数据分析背后的核心逻辑在于随着游戏行业市场竞争局面的扩大，玩家对于品质的要求越来越高，游戏项目的生命周期越来越短，直接影响项目的投入产出比，通过数据运营则可以有效的延长项目的生命周期，对各个阶段的业务走向进行精准把控。而随着流量成本的日益上升，如何构建经济、高效的精细化数据运营体系，以更好的支撑业务发展，也变得愈发重要起来。数据运营体系就需要有其配套的基础支撑设施，如何选择这类基础支撑设施，是公司技术决策者需要思考的问题。思考的出发点包括：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1） 要有足够的弹性。对于游戏而言，往往就是短时间爆发，数据量激增；因此，能否适应数据的爆发性增长，满足弹性需求是一个重点考量的点；无论是计算还是存储，都需要具备足够的弹性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2） 要有足够的性价比。对于用户行为数据，往往需要拉到一个很长的周期去分析去对比，比如留存率，不少情况下需要考虑90天甚至180天客户的留存率；因此，如何以最具性价比的方式长期存储海量数据是需要重点考虑的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3） 要有够用的分析能力，且具备可扩展性。许多情况下，用户行为体现在埋点数据中，埋点数据又需要与用户注册信息、登陆信息、账单等结构化数据关联分析；因此，在数据分析上，至少需要有大数据的ETL能力、异构数据源的接入能力和复杂分析的建模能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4） 要与公司现有技术栈相匹配，且后续利于招聘。对于YJ，其在技术选型的时候一个重要点就是其技术人员的技术栈，YJ的技术团队大部分只熟悉传统的数据库开发，即MySQL；并且人手紧张，做数据运营分析的技术人员只有1个，短时间内根本没有能力独立构建大数据分析的基础设施。从YJ的角度出发，最好绝大多数分析能够通过SQL完成；并且在招聘市场上，SQL开发人员的数量也远高于大数据开发工程师的数量。针对客户的情况，我们帮助客户对现有方案做了改造。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibsyj8qrsn7TmQImicicmgKnyzYLFOXZrJzWaKpPp8DdbAgmGeMPv7R5lA/640?wx_fmt=png&quot; data-ratio=&quot;0.4219409282700422&quot; data-w=&quot;474&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图18. 改造前的方案&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;改造前，客户所有的结构化数据都在一个高规格的MySQL里面；而玩家行为数据则是通过LogTail采集至日志服务（SLS）中，然后从日志服务中分别投递到OSS和ES里。这个架构的问题在于：1）行为数据和结构化数据完全割裂，无法联动分析；2）对于行为数据智能提供检索功能，无法做深层次的挖掘分析；3）OSS仅仅作为数据存储资源使用，并没有挖掘出足够的数据价值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事实上，我们分析客户现存架构其实已经具备了数据湖的雏形：全量数据已经在OSS中保存下来了，现在需要进一步补齐客户对于OSS中的数据的分析能力。而且数据湖基于SQL的数据处理模式也满足客户对于开发技术栈的需求。综上，我们对客户的架构做了如下调整，帮助客户构建了数据湖。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibcCdhrKAo5eDmoy9KgIAdMQmpJ6YHx6trqE3Rib0uhpU4TmgficlD9OHA/640?wx_fmt=png&quot; data-ratio=&quot;0.6059225512528473&quot; data-w=&quot;439&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图19. 改造后的数据湖解决方案&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总体上，我们没有改变客户的数据链路流转，只是在OSS的基础上，增加了DLA组件，对OSS的数据进行二次加工处理。DLA提供了标准SQL计算引擎，同时支持接入各类异构数据源。基于DLA对OSS的数据进行处理后，生成业务直接可用的数据。但是DLA的问题在于无法支撑低延迟需求的交互式分析场景，为了解决这个问题，我们引入了云原生数据仓库ADB来解决交互式分析的延迟性问题；同时，在最前端引入QuickBI作为客户的可视化分析工具。YJ方案是图14所示的湖仓一体化解决方案在游戏行业的一个经典落地案例。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;YM是一家数据智能服务提供商，面向各类中小商家提供一系列数据分析运营服务。具体实现的技术逻辑如下图所示。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibiaeia4QmzC7lVm7u0fGlCBhTMapLpGa3sicjicBRrunkBNvoHbpjdgaQFQ/640?wx_fmt=png&quot; data-ratio=&quot;0.3547486033519553&quot; data-w=&quot;716&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图20. YM智能数据服务SaaS模式示意&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;平台方提供多端SDK供用户（商家提供网页、APP、小程序等多种接入形式）接入各类埋点数据，平台方以SaaS的形式提供统一的数据接入服务和数据分析服务。商家通过访问各类数据分析服务来进行更细粒度的埋点数据分析，完成行为统计、客户画像、客户圈选、广告投放监测等基本分析功能。然而，这种SaaS模式下，会存在一定的问题：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1） 由于商家类型和需求的多样化，平台提供SaaS类分析功能很难覆盖所有类型的商家，无法满足商家的定制化需求；如有些商家关注销量，有些关注客户运营，有些关注成本优化，很难满足所有的需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2） 对于一些高级分析功能，如依赖于自定义标签的客户圈选、客户自定义扩展等功能，统一的数据分析服务无法满足的；特别是一些自定义的标签依赖于商家自定义的算法，无法满足客户的高级分析需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3） 数据的资产化管理需求。在大数据时代，数据是一个企业/组织的资产已经成为了大家的共识，如何能让属于商家的数据合理、长期的沉淀下来，也是SaaS服务需要考虑的事情。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上，我们在上图的基本模式上引入了数据湖模式，让数据湖作为商家沉淀数据、产出模型、分析运营的基础支撑设施。引入数据湖后的SaaS数据智能服务模式如下。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibVb2icLGJib6Zc7d7zN0qR3EibleJIufiaq4Mrrulae02HMhfGcmI3VBM6g/640?wx_fmt=png&quot; data-ratio=&quot;0.5111731843575419&quot; data-w=&quot;716&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图21. 基于数据湖的数据智能服务&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如图21所示，平台方为每个用户提供一键建湖服务，商家使用该功能构建自己的数据湖，“一键建湖”能力一方面帮助商家将所有埋点数据的数据模型（schema）同步至数据湖中；另一方面，将属于该商家的所有埋点数据全量同步至数据湖中，并基于“T+1”的模式，将每天的增量数据归档入湖。基于数据湖的服务模式在传统的数据分析服务的基础上，赋予了用户数据资产化、分析模型化和服务定制化三大能力：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1） 数据资产化能力。利用数据湖，商家可以将属于自己的数据持续沉淀下来，保存多长时间的数据，耗费多少成本，完全由商家自主决定。数据湖还提供了数据资产管理能力，商家除了能管理原始数据外，还能将处理过的过程数据和结果数据分门别类保存，极大的提升了埋点数据的价值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2） 分析模型化能力。数据湖中不仅仅有原始数据，还有埋点数据的模型（schema）。埋点数据模型体现了全域数据智能服务平台对于业务逻辑的抽象，通过数据湖，除了将原始数据作为资产输出外，还将数据模型进行了输出，借助埋点数据模型，商家可以更深入的理解埋点数据背后所体现的用户行为逻辑，帮助商家更好的洞察客户行为，获取用户需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3） 服务定制化能力。借助数据湖提供的数据集成和数据开发能力，基于对埋点数据模型的理解，商家可以定制数据处理过程，不断对原始数据进行迭代加工，从数据中提炼有价值的信息，最终获得超越原有数据分析服务的价值。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.10 LakeHouse&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibcusibjTpSCAL5v8icFCb6Wa7RP0jjcSrhPpyeLk64iaer9dKTamgpKrQQ/640?wx_fmt=png&quot; data-ratio=&quot;0.525&quot; data-w=&quot;1080&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;4.11 数据湖总结&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖作为新一代大数据分析处理的基础设施，需要超越传统的大数据平台。个人认为目前在以下方面，是数据湖解决方案未来可能的发展方向。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;云原生架构&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关于什么是云原生架构，众说纷纭，很难找到统一的定义。但是具体到数据湖这个场景，个人认为就是以下三点特征：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;存储和计算分离，计算能力和存储能力均可独立扩展；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;多模态计算引擎支持，SQL、批处理、流式计算、机器学习等；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;提供serverless态服务，确保足够的弹性以及支持按需付费。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;足够用的数据管理能力&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖需要提供更为强大的数据管理能力，包括但不限于数据源管理、数据类目管理、处理流程编排、任务调度、数据溯源、数据治理、质量管理、权限管理等。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;大数据的能力，数据库的体验&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目前绝大多数数据分析人员都只有数据库的使用经验，大数据平台的能力虽强，但是对于用户来说并不友好，数据科学家和数据数据分析师应该关注数据、算法、模型及其与业务场景的适配，而不是花大量的时间精力去学习大数据平台的开发。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖要想快速发展，如何为用户提供良好的使用体验是关键。基于SQL的数据库应用开发已经深入人心，如何将数据湖的能力通过SQL的形式释放出来，是未来的一个主要方向。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;完善的数据集成与数据开发能力&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对各种异构数据源的管理与支持，对异构数据的全量/增量迁移支持，对各种数据格式的支持都是需要不断完善的方向。同时，需要具备一个完备的、可视化的、可扩展的集成开发环境。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;与业务的深度融合与集成&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;典型数据湖架构的构成基本已经成为了业界共识：分布式对象存储+多模态计算引擎+数据管理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;决定数据湖方案是否胜出的关键恰恰在于数据管理，无论是原始数据的管理、数据类目的管理、数据模型的管理、数据权限的管理还是处理任务的管理，都离不开与业务的适配和集成；未来，会有越来越多的行业数据湖解决方案涌现出来，与数据科学家和数据分析师形成良性发展与互动。如何在数据湖解决方案中预置行业数据模型、ETL流程、分析模型和定制算法，可能是未来数据湖领域差异化竞争的一个关键点。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5.1 基础概念&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1.1 产生的背景&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;企业在过去信息化的历程中形成了大量生产经营及专业业务应用成果，同时也累积了大量的企业数据资产。限于传统的数据仓库技术手段，数据管理和分析能力成为信息化工作中的短板。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;企业信息系统众多，系统管理独立，数据存储分散，横向的数据共享和分析应用仅由具体业务驱动，难以对全局数据开展价值挖掘，从规模上和效果上都无法真正体现集团庞大数据资产的价值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;市场竞争和产业链日益全球化，企业不只满足于内部数据的分析，更要通过互联网、微信、APP等新技术手段结合外部市场数据进行整体分析。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;传统的数据仓库不能满足数据分析需求
企业在数据分析应用方面呈现“五大转变”（从统计分析向预测分析转变、从单领域分析向跨领域转变、从被动分析向主动分析转变、从非实时向实时分析转变、从结构化数据向多元化转变），并且对统一的数据中台平台诉求强烈，对数据中台的运算能力、核心算法、及数据全面性提出了更高的要求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据中台的处理架构发生了变化&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;传统的数据仓库集成处理架构是ETL结构，这是构建数据仓库的重要一环，即用户从数据源抽取出所需的数据，经过数据清洗，将数据加载到数据仓库中去。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而大数据背景下的架构体系是ELT结构，其根据上层的应用需求，随时从数据中台中抽取想要的原始数据进行建模分析。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一是以Hadoop、Spark等分布式技术和组件为核心的“计算&amp;amp;存储混搭”的数据处理架构，能够支持批量和实时的数据加载以及灵活的业务需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;二是数据的预处理流程正在从传统的ETL结构向ELT转变：&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1.2 阿里集团为什么要建立一个“大中台、小前台“？&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们从阿里共享业务事业部的发展史说起。起初，阿里只有一个淘宝事业部，后来成立了天猫事业部，此时淘宝的技术团队同时支撑着这两个事业部。当时的淘宝和天猫的电商系统像我们很多大型企业的一样是分为两套独立的烟囱式体系，两套体系中都包含的有商品、交易、支付、评价、物流等功能。因为上述原因，阿里集团又成立了共享业务事业部，其成员主要来自之前的淘宝技术团队，同时将两套电商业务做了梳理和沉淀&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;中台其实就是一个共享服务的体系结构。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们需要在日常的开发过程中将通用的服务抽离出来做到共享服务的体系结构当中。大中台，小前台的体系结构可以使得管理更加高效，小团队更加扁平化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于资源的共享可以让开发更加敏捷，更能够知道需要做什么，该怎么做？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过抽象各条业务线，把共用的服务抽象出来共享，不限于用户、订单等基础模块服务，还包括具体的业务的抽象，比如教育培训相关的课程、讲师、学员等服务，通过抽象并以微服务的形式实现，避免重复投入资源造轮子。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1.3 中台目标&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先、把当前系统中各个业务的前端应用与后端服务解耦。将各个功能中的服务能力进行梳理、并沉淀。例如我们从外呼业务中梳理出工单管理和问卷管理的能力；从知识库中梳理出知识搜索的能力；从85电商平台中梳理出商品销售和库存管理的能力等等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其次、将重复、类似的服务进行整合。同时在单个服务的完善和增强的过程中注意服务的通用性，避免其他相似“双胞胎”服务的出现。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后，由于服务能力的集中管控，很大程度会促进我们一体化运维的能力，但在“大中台、小前台”的模式下，每一个服务都负责对N多个前端业务应用提供支持，这就要求运维在信息安全、备份、监控等方面要有更强的能力。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.1.4 中台分类&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;甄别是不是中台，还要回到中台要解决的问题上，一切以“以用户为中心的持续规模化创新”为目的，将后台各式各样的资源转化为前台易于使用的能力，帮助我们打赢这场以用户为中心的战争的平台，我们都可以称之为中台：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;业务中台提供重用服务
例如用户中心，订单中心之类的开箱即用可重用能力，为战场提供了强大的后台炮火支援能力，随叫随到，威力强大；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据中台提供了数据分析能力
帮助我们从数据中学习改进，调整方向，为战场提供了强大及时的雷达监测能力，帮助我们掌控战场；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;移动及算法中台提供了战场一线火力支援能力
帮助我们提供更加个性化的服务，增强用户体验，为战场提供了陆军支援能力，随机应变，所向披靡；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;技术中台提供了自建系统部分的技术支撑能力
帮助我们解决了基础设施，分布式数据库等底层技术问题，为前台特种兵提供了精良的武器装备；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;研发中台提供了自建系统部分的管理和技术实践支撑能力
帮助我们快速搭建项目，管理进度，测试，持续集成，持续交付，是前台特种兵的训练基地及快速送达战场的机动运输部队；&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;组织中台为我们的项目提供投资管理、风险管理、资源调度等，
是战场的指挥部，战争的大脑，指挥前线，调度后方。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，评判一个平台是否称得上中台，最终评判标准不是技术也不是长什么模样，最终还是得前台说了算，毕竟前台才是战争的关键，才是感受得到战场的残酷、看得见用户的那部分人。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5.2 数据中台和数仓的关系&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.1 传统数仓&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;传统数仓有几个特点：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据具有历史性&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于文件存储&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以表为形态，自带元数据存储（比如Hive）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在数仓的数据是其他原始数据的拷贝或者拷贝的加工
传统数仓需要拷贝数据的重要原因是数据计算和数据存储需要尽可能的近。所以我们需要把MySQL等数据源的数据同步到数仓，才能进行进一步处理。（这里有点疑问，我觉得是因为需要直接对数仓数据进行离线操作，而不是对业务数据库进行繁重的操作，也就是说数据分析不能影响业务）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外传统数仓更关注的是数据的历史状态，所以导致数据规模庞大。数仓本身也具备计算能力，同时也可以作为存储供其他计算系统使用。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.2 数据中台&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据中台概念，不同于数据平台。数据中台，业务侧包含&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据触手(埋点)&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据接入(标准化)&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据仓库(抽象化)&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据治理(可靠性)&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;数据服务(产品化)&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整体是一个闭环的解决方案
其中，闭环是最重要的一点。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数据服务接口&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据中台设计立足点本身是数据计算和存储分离的。那就意味着，数据中台本身并没有数据，数据来源是其他地方，比如传统数仓、业务数据库、用户在中台上传的文件（临时使用）、各个业务系统的API(瞬时，我们不关心API之前的数据结果是什么样的)。因为数据中台拥有这些数据源的适配器，所以相当于建立了互联管道。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;关于元数据&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们知道数仓的优势是有元数据，通过表的方式很好的规整了数据。数据需要加工，所以一般数仓是有分层的，往上走一层，数据信息损耗就高一些。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据中台也有一个全局的元数据管理系统，管理也是以表为主，粒度到字段级别。数据中台这个元信息包含了各个子存储的元信息，以数据中台需要的形态进行组织。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;数据地图&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据中台的元数据其中承载的一个重要功能是数据地图，虽然在数据中台中，修建了通往所有数据的道路，但是当用户进来的时候无法知道具体某个数据的地址，也就没办法利用这些修好的道路。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据地图就是解决这个问题 我们需要结合自然语言处理，检索技术，目录分类技术，机器学习以及数据规范化来帮助找到数据地址。数据地址从来都不是面向人类友好的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过数据中台的数据地图，以及数据中台到各数据源的建立好的管道，那么我们就可以很好的找到我们要的数据以及对他们进行关联和处理，分析，甚至进一步成为机器学习的素材。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据地图和传统数仓元数据的区别在于：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;它记录了散落在各个孤岛的数据，而不像传统数仓，只是在自己的数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据格式是异构的，不仅仅是文件或表。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;他不仅仅存储表以及字段相关信息，同时还让这些信息可检索，可查询，可以更好的面向人而不是机器。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.2.3 结论&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数仓是数据中台的一个重要组成部分，也是元数据的一个重要来源，但是随着技术的发展，数据计算和存储必定是分离的，这就需要一个新的元信息系统（数据地图）来进行承载。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;5.3 数据中台建设是数字化转型的支撑&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据中台成为热点，“中台”这个概念，是相对于前台和后台而生，是前台和后台的链接点，将业务共同的工具和技术予以沉淀。数据中台是指数据采集交换、共享融合、组织处理、建模分析、管理治理和服务应用于一体的综合性数据能力平台，在大数据生态中处于承上启下的功能，提供面向数据应用支撑的底座能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;广义上来给数据中台一个企业级的定义：“聚合和治理跨域数据，将数据抽象封装成服务，提供给前台以业务价值的逻辑概念”。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavib1OibfqpzuPAalHGDW3VX5Z9JTpnFkbIXlgmMSI6xqj4xKyzI6kxSdsw/640?wx_fmt=png&quot; data-ratio=&quot;0.7111913357400722&quot; data-w=&quot;554&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;中台战略核心是数据服务的共享。中台战略并不是搭建一个数据平台，但是中台的大部分服务都是围绕数据而生，数据中台是围绕向上层应用提供数据服务构建的，中台战略让数据在数据平台和业务系统之间形成了一个良性的闭环，也就是实现应用与数据之间解藕，并实现紧密交互。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5.4 公司平台分层与大中台小前台战略&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.4.1 互联网巨头“大中台，小前台”战略&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阿里巴巴在2015年12月进行组织升级，就是“大中台，小前台”的模式。主要的思路是打破原来树状结构，小前台距离一线更近，业务全能，这样便于快速决策、敏捷行动；支持类的业务放在中台，扮演平台支撑的角色。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实，这个最早由阿里在2015年提出的“大中台，小前台”战略中延伸出来的概念，灵感来源于一家芬兰的小公司Supercell——一家仅有300名员工，却接连推出爆款游戏，是全球最会赚钱的明星游戏公司:&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这家看似很小的公司，设置了一个强大的技术平台，来支持众多的小团队进行游戏研发。这样一来，他们就可以专心创新，不用担心基础却又至关重要的技术支撑问题。恰恰是这家小公司，开创了中台的“玩法”，并将其运用到了极致。对于这种多项目并行，各项目相对独立，但业务需求所需要的支持类似的公司，“中台”就有存在的价值。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种类似的思维应用到大企业中，就是需要一个资源整合和能力沉淀的平台，对不同的部门进行总协调和支持，“中台”也就应运而生。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;中台战略是构建符合DT时代的更具备创新性和灵活性的组织机制和业务机制，实现管理模式的创新。将公共的业务、数据、技术等公共能力从前台下沉，成为独立的中台，并且通过组织结构的调整物理拆分为独立的中台部门。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;大中台，小前台”适用场景&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不适合初创公司！初创公司的初创阶段没有任何的公共资源的积累，没有下沉为中台的内容。初创公司的首要任务是积累所有资源活下来，快速迭代主要业务，保存自己和核心竞争力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;适合高速发展公司或者快速成长公司。有一定的公共资源的积累，公共部分下沉为中台，保其高可用高性能，为前端业务百花齐放，快速迭代提供坚实的后盾。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.4.2 公司平台分层&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.4.2.1 概述&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;阿里组织架构，业务中台、数据中台、技术中台公共组成中台。：&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibSnRg9J5Lt43FqN647nyyHBuJicjSBCbOqcicunx7Oojlw5f5ep89wLibA/640?wx_fmt=png&quot; data-ratio=&quot;0.36203703703703705&quot; data-w=&quot;1080&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;前台&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由各类前台系统组成的前端平台。每个前台系统就是一个用户触点，即企业的最终用户直接使用或交互的系统，是企业与最终用户的交点。例如用户直接使用的网站，手机 app，微信公众号等都属于前台范畴。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;中台&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;“中台”的设置就是为了提炼各个业务条线的共性需求，并将这些打造成组件化的资源包，然后以接口的形式提供给前台各业务部门使用，可以使产品在更新迭代、创新拓展的过程中研发更灵活、业务更敏捷，最大限度地减少“重复造轮子”的KPI项目。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;“前台”要做什么业务，需要什么资源可以直接同公共服务部要。搜索、共享组件、数据技术等模块不需要每次去改动底层进行研发，而是在底层不变动的情况下，在更丰富灵活的“大中台”基础上获取支持，让“小前台”更加灵活敏捷。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;后台&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由后台系统组成的后端平台。每个后台系统一般管理了企业的一类核心资源（数据+计算），例如财务系统，产品系统，客户管理系统，仓库物流管理系统等，这类系统构成了企业的后台。基础设施和计算平台作为企业的核心计算资源，也属于后台的一部分。后台并不为前台而生&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外，由于后台往往并不能很好的支撑前台快速创新响应用户的需求，后台更多解决的是企业管理效率问题，而中台要解决的才是前台的创新问题。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.4.2.2 敏捷前台/小前台&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一线作战单元，强调敏捷交互及稳定交付的组织能力建设。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于阿里来说，小前台就是各个业务部门，个性化的各种前台服务，例如阿里的天猫、淘宝、河马、支付宝等一系列的品牌。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.4.2.3 业务中台&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;能力固化与赋能，固化通用能力，赋能前线部队，提升配置效率，加快前线响应，产品化业务化，开辟全新生态。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体来说，业务中台对应公司的公共基础业务和通用服务，例如短信中心、用户中心、支付中心交易中心、搜索服务等。下图中的公共逻辑层，就是业务中台。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibfGOQAdkKm6h9kfOsp4kLFf1VupFMKngNYryTZiboLveN88NV5sD5Qkg/640?wx_fmt=png&quot; data-ratio=&quot;0.7509259259259259&quot; data-w=&quot;1080&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.4.2.4 技术中台&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;技术中台主要负责基础服务、基础组件、基础平台、存储体系、云平台、运维相关等技术支撑。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibwIABBWg0WWlxB3mbndCbZe1D4icQVBBkIPlLfcBa13wRCqbX4Zk6R4Q/640?wx_fmt=png&quot; data-ratio=&quot;0.8153998025666338&quot; data-w=&quot;1013&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.4.2.5 数据中台&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;负责大数据统计分析相关的DaaS（数据即服务）和PaaS（平台即服务）相关服务建设，资产整合与共享，整合多维数据，统一资产管理，连通数据孤岛，共享数据资源，深入挖掘数据，盘活资产价值。&lt;/p&gt;&lt;/section&gt;&lt;h4&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQaviboplORg0rEG9x4gYXsaKRibXFTM5ibobP6uS7VVM70KIhL3M0FcHDB5Zg/640?wx_fmt=png&quot; data-ratio=&quot;0.7722222222222223&quot; data-w=&quot;1080&quot; data-type=&quot;png&quot;/&gt;&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;5.4.2.6 稳定后台&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以共享中心建设为核心，为前中台提供专业的内部服务支撑。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5.5 数据中台定义及处理架构&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据中台是指通过企业内外部多源异构的数据采集、治理、建模、分析，应用，使数据对内优化管理提高业务，对外可以数据合作价值释放，成为企业数据资产管理中枢。数据中台建立后，会形成数据API，为企业和客户提供高效各种数据服务。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibdICdYdvcGFTNNIBS8oib7LkC7FcUGHKruYt3JiawMW8S6brjcXzBxRibg/640?wx_fmt=png&quot; data-ratio=&quot;0.6390625&quot; data-w=&quot;640&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据中台整体技术架构上采用云计算架构模式，将数据资源、计算资源、存储资源充分云化，并通过多租户技术进行资源打包整合，并进行开放，为用户提供“一站式”数据服务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;利用大数据技术，对海量数据进行统一采集、计算、存储，并使用统一的数据规范进行管理，将企业内部所有数据统一处理形成标准化数据，挖掘出对企业最有价值的数据，构建企业数据资产库，提供一致的、高可用大 数据服务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据中台不是一套软件，也不是一个信息系统，而是一系列数据组件的集合，企业基于自身的信息化建设基础、数据基础以及业务特点对数据中台的能力进行定义，基于能力定义利用数据组件搭建自己的数据中台。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5.6 数据中台带来价值&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据中台对一个企业的数字化转型和可持续发展起着至关重要的作用。数据中台为解耦而生，企业建设数据中台的最大意义就是应用与数据解藕。这样企业就可以不受限制地按需构建满足业务需求的数据应用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;构建了开放、灵活、可扩展的企业级统一数据管理和分析平台， 将企业内、外部数据随需关联，打破了数据的系统界限。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;利用大数据智能分析、数据可视化等技术，实现了数据共享、日常报表自动生成、快速和智能分析，满足集团总部和各分子公司各级数据分析应用需求。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;深度挖掘数据价值，助力企业数字化转型落地。实现了数据的目录、模型、标准、认责、安全、可视化、共享等管理，实现数据集中存储、处理、分类与管理，建立大数据分析工具库、算法服务库，实现报表生成自动化、数据分析敏捷化、数据挖掘可视化，实现数据质量评估、落地管理流程。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5.7 传统数据仓库与数据中台的差异点&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibngaA7auKKEibJUZNCdmbxLCncFpusHfaxXcic9HkPZT1KnsP7qFxVyIQ/640?wx_fmt=png&quot; data-ratio=&quot;0.3303249097472924&quot; data-w=&quot;554&quot; data-type=&quot;png&quot;/&gt;&lt;br/&gt; &lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibianS6lpkcjicnT88R9wWXicA9C9H9C9H9wQJqoM3gEXicb99WKOKxIeAdg/640?wx_fmt=png&quot; data-ratio=&quot;0.48194945848375453&quot; data-w=&quot;554&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作为工业企业，一般采用混搭架构：&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibTXQnX3uib0qJfjQEQAQavibV2H9EW8TT27Wxh3cKAYUwI6toMtDWh5U1456RW0WnNhxRhicwqHx2TA/640?wx_fmt=png&quot; data-ratio=&quot;0.17669172932330826&quot; data-w=&quot;532&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;6.1 数据仓库vs.数据集市&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据集市和数据仓库经常会被混淆，但两者的用途明显不同。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据集市通常是数据仓库的子集;它等数据通常来自数据仓库 – 尽管还可以来自其他来源。数据集市的数据专门针对特定的用户社区(例如销售团队)，以便他们能够快速找到所需的数据。通常，数据保存在那里用于特定用途，例如财务分析。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据集市也比数据仓库小得多 – 它们可以容纳数十千兆字节，相比之下，数据仓库可以存储数百千兆字节到PB级数据，并可用于数据处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据集市可从现有数据仓库或其他数据源系统构建，你只需设计和构建数据库表，使用相关数据填充数据库表并决定谁可以访问数据集即可。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;6.2 数据仓库vs.ODS&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;操作数据存储(ODS)是一种数据库，用作所有原始数据的临时存储区域，这些数据即将进入数据仓库进行数据处理。我们可以将其想象成仓库装卸码头，货物在此处交付、检查和验证。在ODS中，数据在进入仓库前可以被清理、检查(因为冗余目的)，也可检查是否符合业务规则。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在ODS中，我们可以对数据进行查询，但是数据是临时的，因此它仅提供简单信息查询，例如正在进行的客户订单状态。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ODS通常运行在关系数据库管理系统(RDBMS)或Hadoop平台。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;6.3 关系型数据库vs.数据仓库和数据湖&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据仓库、数据湖与关系数据库系统之间的主要区别在于：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关系数据库用于存储和整理来自单个来源(例如事务系统)的结构化数据，&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而数据仓库则用于存储来自多个来源的结构化数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;数据湖的不同之处在于它可存储非结构化、半结构化和结构化数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;关系数据库创建起来相对简单，可用于存储和整理实时数据，例如交易数据等。关系数据库的缺点是它们不支持非结构化数据库数据或现在不断生成的大量数据。这使得我们只能在数据仓库与数据湖间做出选择。尽管如此，很多企业仍然继续依赖关系数据库来完成运营数据分析或趋势分析等任务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;内部或云端可用的关系数据库包括Microsoft SQL Server、Oracle数据库、MySQL和IBM Db2、以及Amazon Relational Database Service、Google Cloud Spanner等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;可参考&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;解读阿里巴巴集团的“大中台、小前台”组织战略&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;互联网中台重要性&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;What is a Lakehouse?
by Ben Lorica, Michael Armbrust, Ali Ghodsi, Reynold Xin and Matei Zaharia Posted in COMPANY BLOGJanuary 30, 2020&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;带你读《企业数据湖》之一：数据导论&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;带你读《企业数据湖》之二：数据湖概念概览&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;带你读《企业数据湖》之三：Lambda架构：一种数据湖实现模式&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;阿里云-什么是数据湖分析&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;   &lt;/p&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;97836&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;历史好文推荐&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4MzE4MjQxOQ==&amp;amp;mid=2649359416&amp;amp;idx=1&amp;amp;sn=42e67d8c8ce58d426e211f8f3f282145&amp;amp;chksm=f3903004c4e7b9127b2de3f761cfc57fd5265bc8aa6cd4908cbd13fea7d39bc70b1f347bc0d9&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;从0到1搭建大数据平台之计算存储系统&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4MzE4MjQxOQ==&amp;amp;mid=2649359342&amp;amp;idx=1&amp;amp;sn=2607bc9d074ae20ef861bd0f46f14880&amp;amp;chksm=f39037d2c4e7bec4c65872248003b150013bbc9d3a9dbeba59578ef495473a7ae06daf104396&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;从0到1搭建大数据平台之调度系统&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4MzE4MjQxOQ==&amp;amp;mid=2649359314&amp;amp;idx=1&amp;amp;sn=0650b017466e9a571cee9b03b62519e2&amp;amp;chksm=f39037eec4e7bef88473d7c8d9d99e266c81b7699c2b9865df2685f6f3f330728fdd32487132&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;从0到1搭建大数据平台之数据采集系统&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI4MzE4MjQxOQ==&amp;amp;mid=2649359274&amp;amp;idx=1&amp;amp;sn=fa545fd207e2acf41a0c36b5d60482fe&amp;amp;chksm=f3903796c4e7be802317b9a9e27133099f110b3de571a3706ebcff5739c53e4d431a7505f4d9&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;如何从0到1搭建大数据平台&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.35934664246823955&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicicjiccLAibDxc3jzFr1RLnMh7RPgIsXXib0Nl4hh3fo9SOm1K3iaPS97lic4VPqjiaKN9Iia11yKDpahI0zg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;551&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>1105f2d72fce32c238bcffed38e431fd</guid>
<title>[推荐] 网易云音乐基于 Flink + Kafka 的实时数仓建设实践</title>
<link>https://toutiao.io/k/rtixudv</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;weui-dialog&quot;&gt;
      &lt;p class=&quot;weui-dialog__hd&quot;&gt;&lt;strong class=&quot;weui-dialog__title&quot;&gt;&quot;Top Stories&quot; is disabled&lt;/strong&gt;&lt;/p&gt;
      &lt;p class=&quot;weui-dialog__bd&quot;&gt;
        Enable &quot;Top Stories&quot; in &quot;Settings&quot; &amp;gt; &quot;General&quot; &amp;gt; &quot;Manage Discover&quot;      &lt;/p&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>5e7b69cce47f8726b8aecdf05d5de70f</guid>
<title>[推荐] 消息队列和任务队列有什么区别？</title>
<link>https://toutiao.io/k/cfr4egg</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;前言&lt;/span&gt;&lt;/h2&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;昨天发了一篇文章是关于&lt;code&gt;machinery&lt;/code&gt;的入门教程，有一位读者在留言中问我 这个和kafka有什么区别？一时我也有点懵，这两个的概念很近，到底有什么不同呢？根据我自己的理解，简单分析了一下，有不足之处欢迎指出。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;消息队列&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;消息队列这个概念其实在我之前的文章：&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzIzMDU0MTA3Nw==&amp;amp;mid=2247483933&amp;amp;idx=1&amp;amp;sn=45c609694ef8cd34c98f5bd74903c754&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;手把手教姐姐写消息队列&lt;/a&gt;，自己动手用go写一个简易版的消息队列，有兴趣的小伙伴们可以看一下这篇文章。回归正题，我们再来介绍一下什么是消息队列。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;消息队列，一般我们会简称它为MQ(Message Queue)。他是由两个单词组成，我们应该对队列(Queue)很熟悉吧。队列是一种先进先出的数据结构。再配合上消息，消息队列可以简单理解为：把要传输的数据放在队列中。使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ。这里我们就不具体讲解消息队列实现细节，这不是本文的主题，只知道概念就可以了。了解了什么是消息队列，我们一起来看看他在什么场景使用。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;1.2676470588235293&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/k5430ljpYPPdxicxQeIHia5x6mJbpxRVngrRpYBaYeNFibHYMRQJousyymjcMwdDdwbeOsZr2bRBqR7rGckXZGUFg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;340&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;场景&lt;span/&gt;&lt;br/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题。这里举一个消息队列的使用场景：日志处理。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;日志处理是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。架构简化如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.42524271844660194&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/k5430ljpYPPdxicxQeIHia5x6mJbpxRVngPn0KBGKuB2fptLtTjDdenhO9KMiaq5jbHqm7iaDnFTUSGAVQu1JCJGXA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1030&quot;/&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;日志采集客户端，负责日志数据采集，定时写入&lt;code&gt;Kfaka&lt;/code&gt;队列。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;Kfaka&lt;/code&gt;消息队列，负责日志数据的接收，存储和转发。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;日志处理应用，订阅并消费kafka队列中日志数据。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;任务队列&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;既然消息队列称为MQ，那么任务队列我们就可以叫其TQ(Task Message)。任务队列可以简单理解为：把要执行的任务放在队列中。使用较多的任务队列有&lt;code&gt;machiney&lt;/code&gt;、&lt;code&gt;Celery&lt;/code&gt;、&lt;code&gt;goWorker&lt;/code&gt;、&lt;code&gt;YTask&lt;/code&gt;。每一个任务队列都有自己的特点，这里就不细讲了。我写了一篇&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzIzMDU0MTA3Nw==&amp;amp;mid=2247484084&amp;amp;idx=1&amp;amp;sn=6177ef00ffe5c0acd428b90540a8d6d3&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;&lt;code&gt;machinery&lt;/code&gt;入门教程&lt;/a&gt;，并且翻译了&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzIzMDU0MTA3Nw==&amp;amp;mid=2247484084&amp;amp;idx=2&amp;amp;sn=8671d9ab75a42e8a83d03d390bf7e3f7&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;一篇&lt;code&gt;machinery&lt;/code&gt;中文文档&lt;/a&gt;，有需要的公众号自取。具体任务队列的细节就不讲了。这不是本文的主题，下面我们看一看任务队列的使用场景。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;场景&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;任务队列是用来执行一个耗时任务。大家可能都使用过马爸爸的花呗，每当我们还款时，就会增加自己的芝麻信用分。这就可以用到任务队列来计算用户的积分和等级了。架构简化如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.42524271844660194&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/k5430ljpYPPdxicxQeIHia5x6mJbpxRVngawZHGjHBBkyoPyqzVcO59Wia9YtaHwpftu0Rngt7GJEFgrIPDNdibgUg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1030&quot;/&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;用户还款，当用户还款成功时，发送一个计算用户积分计算的任务到任务队列。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;任务队列，可以是&lt;code&gt;mq&lt;/code&gt;，也可是&lt;code&gt;redis&lt;/code&gt;，用来存储任务。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;任务执行者，任务的执行者，监听任务队列，当任务队列中有任务时，便会执行。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;区别&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;消息队列和任务队列，我觉得最大的不同就是理念的不同：任务队列传递的是&quot;任务&quot;，消息队列传递的是&quot;消息&quot;。任务队列可以说是消息队列的二次开发。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4497716894977169&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/k5430ljpYPPdxicxQeIHia5x6mJbpxRVngg47VJ7qPoibPAJ8tsEw2y39X2KNkmbq9PCWAhPJu0yYWxVbJuKI62Tg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;876&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过上面两个场景例子，我们可以总结一下两者区别：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;消息队列更侧重于消息的吞吐、处理，具有有处理海量信息的能力。另外利用消息队列的生产者和消费者的概念，也可以实现任务队列的功能，但是还需要进行额外的开发处理。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;任务队列则提供了执行任务所需的功能，比如任务的重试，结果的返回，任务状态记录等。虽然也有并发的处理能力，但一般不适用于高吞吐量快速消费的场景。其实任务队列和远程函数调用很像，不过和rpc调用不同，他的调用不是网络请求的方式，而是通过利用消息队列传递任务信息。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上所述，个人认为任务队列就是消息队列在异步场景下的深度二次开发，根据实际项目开发根据实际场景做相应选择即可。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;后言&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上全是个人理解，有什么不对的，欢迎指出。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;好啦，这一篇文章到这就结束了，我们下期见～～。希望对你们有用。可添加我的golang交流群，我们一起学习交流。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;结尾给大家发一个小福利吧，最近我在看[微服务架构设计模式]这一本书，讲的很好，自己也收集了一本PDF，有需要的小伙可以到自行下载。获取方式：关注公众号：[Golang梦工厂]，后台回复：[微服务]，即可获取。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;我翻译了一份GIN中文文档，会定期进行维护，有需要的小伙伴后台回复[gin]即可下载。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;自己翻译了一份&lt;code&gt;machinery&lt;/code&gt;官方中文文档，会定期维护，有需要的小伙伴后台回复[machinery]即可下载。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;我是asong，一名普普通通的程序猿，让gi我一起慢慢变强吧。我自己建了一个&lt;code&gt;golang&lt;/code&gt;交流群，有需要的小伙伴加我&lt;code&gt;vx&lt;/code&gt;,我拉你入群。欢迎各位的关注，我们下期见~~~&lt;/strong&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/k5430ljpYPPdxicxQeIHia5x6mJbpxRVngE5pd6l3ksDM088Zo9PWZ8FVWbQnNQbKPtkr2wia42nuSKtW8GojrwdA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;258&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;推荐往期文章：&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;mp-qa class=&quot;js_uneditable custom_select_card qa_iframe&quot; data-pluginname=&quot;insertquestion&quot; data-id=&quot;1589461370889109505&quot; data-bizuin=&quot;MzIzMDU0MTA3Nw==&quot; data-title=&quot;你们有什么理解，欢迎讨论～～～&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;div class=&quot;reward_qrcode_area reward_area tc&quot; id=&quot;js_reward_qrcode&quot;&gt;
                                &lt;p class=&quot;tips_global&quot;&gt;Long-press QR code to transfer me a reward&lt;/p&gt;
                                                                &lt;p class=&quot;reward_tips&quot;/&gt;
                                &lt;span class=&quot;reward_qrcode_img_wrp&quot;&gt;&lt;img class=&quot;reward_qrcode_img&quot; id=&quot;js_reward_qrcode_img&quot;/&gt;&lt;/span&gt;
                                &lt;p class=&quot;tips_global&quot;&gt;As required by Apple&#x27;s new policy, the Reward feature has been disabled on Weixin for iOS. You can still reward an Official Account by transferring money via QR code.&lt;/p&gt;
                            &lt;/div&gt;
                                                                            
                              
            &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>