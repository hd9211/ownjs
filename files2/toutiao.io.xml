<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>7b3449029cf924331cb2b7255a984759</guid>
<title>聊聊风口上的 eBPF</title>
<link>https://toutiao.io/k/53qmmzi</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;RichText ztext Post-RichText&quot;&gt;&lt;p&gt;大家好，今天分享的主题是《eBPF 探索之旅》，围绕三部分展开：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;eBPF 是什么&lt;/li&gt;&lt;li&gt;eBPF 能做什么&lt;/li&gt;&lt;li&gt;如何编写 eBPF 程序&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;认识 eBPF&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;eBPF 是什么，从字面上来看是扩展伯克利包处理器，那伯克利包处理器是什么呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-70c924dc4c4075e7711fa4d66e6668b3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;352&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-70c924dc4c4075e7711fa4d66e6668b3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;352&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-70c924dc4c4075e7711fa4d66e6668b3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-70c924dc4c4075e7711fa4d66e6668b3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在此之前先来了解一个性能优秀的常用抓包工具：tcpdump&lt;/p&gt;&lt;p&gt;&lt;b&gt;tcpdump&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74e334c6b676966f9d7d1d91c52f0485_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-74e334c6b676966f9d7d1d91c52f0485_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-74e334c6b676966f9d7d1d91c52f0485_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-74e334c6b676966f9d7d1d91c52f0485_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图中展示了两个常用指令&lt;/p&gt;&lt;p&gt;指令一：指定 IP 和端口，可以抓到 IP 为 220.173.103.227，端口为 80 的包&lt;/p&gt;&lt;p&gt;指令二：加上 grep，可以过滤出带有 route 字段的数据&lt;/p&gt;&lt;p&gt;那么 tcpdump 又是如何做到通过用户提供的规则处理网络上收到的包，再 copy 给用户的呢？如果放在用户层，就需要在系统里所有 socket 读写的时候做一层处理，把规则放上去，这样做难度太大。而 tcpdump 是基于 libpcap 库实现的，libpcap 能做到在驱动将包交给内核网络时，把包取过来，通过用户传给 libpcap 的规则将需要的网络包 copy 一份给用户，再把包传给内核网络栈，而之所以 libpcap 能做到这点全靠 BPF。&lt;/p&gt;&lt;p&gt;&lt;b&gt;BPF&lt;/b&gt;&lt;/p&gt;&lt;p&gt;BPF 是基于寄存器虚拟机实现的，支持 jit，比基于栈实现的性能高很多。它能载入用户态代码并且在内核环境下运行，内核提供 BPF 相关的接口，用户可以将代码编译成字节码，通过 BPF 接口加载到 BPF 虚拟机中，当然用户代码跑在内核环境中是有风险的，如有处理不当，可能会导致内核崩溃。因此在用户代码跑在内核环境之前，内核会先做一层严格的检验，确保没问题才会被成功加载到内核环境中。&lt;/p&gt;&lt;p&gt;&lt;b&gt;eBPF：BPF 的扩展&lt;/b&gt;&lt;/p&gt;&lt;p&gt;回到 eBPF，它作为一个 BPF 的扩展，都扩展了些什么呢？&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先在功能上，不仅仅局限于网络，它能够借助 kprobe 获取内核函数运行信息，这样调试内核就不需要 gdb 或者加入内核探点重新编译内核。&lt;/li&gt;&lt;li&gt;可以借助 uprobe 获取用户函数的运行信息，kprobe 和 uprobe 不仅能获取函数运营信息，还可以获取代码执行到了哪一行时的寄存器以及栈信息，其原理可以理解为在某个指令打断点，当 cpu 执行到这个断点的时候，cpu 会保存当前的寄存器信息，然后单步执行断点持载的 handler，也是想要在内核中执行的逻辑，执行完成后 cpu 会回到这个断点的位置，恢复寄存器的状态，然后继续运行下去。&lt;/li&gt;&lt;li&gt;支持 tracepoint，即在写代码中加入 trace 点，获取执行到这点时的信息。&lt;/li&gt;&lt;li&gt;可以嵌入到 perf_event 中。我们熟知的 XDP 以及 tc 都是基于 eBPF 实现的，并且在性能上有着不俗的表现。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;eBPF 的功能&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;系统性能监控/分析工具：能够实现性能监控工具、分析工具等常用的系统分析工具，比如 sysstate 工具集，里面提供了 vmstate，pidstat 等多种工具，一些常用的 top、netstat（netstat 可被 SS 替换掉），uptime、iostat 等这些工具多数都是从 /proc、/sys、/dev 中获取的会对系统产生一定的开销，不适合频繁的调用。比如在使用 top 的时候通过 cpu 排序可以看到 top cpu 占用也是挺高的，使用 eBPF 可以在开销相对小的情况下获取系统信息，定时将 eBPF 采集的数据 copy 到用户态，然后将其发送到分析监控平台。&lt;/li&gt;&lt;li&gt;用户程序活体分析：做用户程序活体分析，比如 openresty 中 lua 火焰图绘制，程序内存使用监控，cdn 服务异常请求分析，程序运行状态的查看，这些操作都可以在程序无感的情况下做到，可以有效提供服务质量。&lt;/li&gt;&lt;li&gt;防御攻击：比如 DDoS 攻击，DDoS 攻击主要是在第七层、第三层以及第四层。第七层的攻击如 http 攻击，需要应用服务这边处理。第四层攻击，如 tcp syn 可以通过 iptable 拒绝异常的 ip，当然前提是能发现以及难点是如何区分正常流量和攻击流量，简单的防攻击会导致一些误伤，另外 tcp syn 也可以通过内核参数保护应用服务。第 3 层攻击，如 icmp。对于攻击一般会通过一些特殊的途径去发现攻击，而攻击的防御则可以通过 XDP 直接在网络包未到网络栈之前就处理掉，性能非常的优秀。&lt;/li&gt;&lt;li&gt;流控：可以控制网络传输速率，比如 tc。&lt;/li&gt;&lt;li&gt;替换 iptable：在 k8s 中 iptable 的规则往往会相当庞大，而 iptable 规则越多，性能也越差，使用 eBP 就可以解决，关于这方面有很多开源的实践可以参考。&lt;/li&gt;&lt;li&gt;服务调优：如下图所示，在 cdn 服务中难免会出现一些指标突刺的情况，这种突刺拉高整体的指标，对于这种突刺时常会因为找不到切入点而无从下手，eBPF 存在这种潜力能帮助分析解决该问题，当 eBPF 发现网络抖动，会主动采集当时应用的运行状态。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6808b8bcc1e71126df8ef35122feaef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;210&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6808b8bcc1e71126df8ef35122feaef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;210&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6808b8bcc1e71126df8ef35122feaef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b6808b8bcc1e71126df8ef35122feaef_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;eBPF 程序实践&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;编写 eBPF 程序的内核最低也要是 3.15，此版本刚好可以支持 eBPF ，但这时 eBPF 支持的特性比较少，不建议使用，最好是 4.8 以上的内核，内核越新 eBPF 支持的功能就越成熟。另外像 kprobe、uprobe、traceport 相关的参数要开起来，否则只能用 BPF的某些特性，而无法使用eBPF 的特性，相当于是空壳。通过路径 /lib/modules/`uname-r`/source/.config 或者在 /boot/  下查找对应版本的内核 config 来查看系统是否开启了所需的参数。&lt;/p&gt;&lt;p&gt;编写 eBPF 程序的对环境也有一定的要求。eBPF 代码需要编译成 llvm 的字节码，才能够在 eBPF 及虚拟机中运行，因此需要安装 llvm 以及 clang，安装好之后可以通过 llc 来查看是否支持 BPF。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4115ea24e2d0496e1aa32f34889935d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;373&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-4115ea24e2d0496e1aa32f34889935d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;373&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-4115ea24e2d0496e1aa32f34889935d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4115ea24e2d0496e1aa32f34889935d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;eBPF 代码示例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;内核、环境都准备好后就可以开始编写工作了。如果是不借助任何工具直接手写一个 eBPF 程序会非常的困难，因为内核提供的文档对如何编写 eBPF 程序的说明是比较缺乏的。当然内核也有提供工具，在内核包中的 bpftool 工具。推荐是使用工具 bcc，它能够降低写 BPF 程序的难度，提供了python、lua 的前端。以 python 为例，只需要写好需要载入 eBPF 的 C代码，再通过 bcc 提供的 BPF 类就可以将代码载入到 eBPF 虚拟机中，执行 python 程序，代码就可以运行起来了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0f3a8eb5657f13da587efebd2da41082_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;195&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-0f3a8eb5657f13da587efebd2da41082_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;195&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-0f3a8eb5657f13da587efebd2da41082_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0f3a8eb5657f13da587efebd2da41082_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图中是 bcc 工具的使用例子，代码非常简单，导入一下 BPF，进行 BPF 初始化。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;text 是要执行的代码，里面是一个函数&lt;/li&gt;&lt;li&gt;kprobe__schedule 内容是调用 bpf_trace_printk(“hello world\n”)；return 0&lt;/li&gt;&lt;li&gt;kprobe__schedule 的含义是用 kprobe的 特性在内核调用 schedule 函数的时候调用 bpf_trace_printk，打出 hello world&lt;/li&gt;&lt;li&gt;bpf_trace_printk 会把这些输出到 /sys/kernel/debug/tracing/trace_pipe 里，后面的 trace_print 就可以把数据打印出来&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面是通过 kprobe 监控机器 tcp（ipv4）的连接状态变化。首先需要知道 tcp 状态变化时内核会调用哪些函数。除了 time-wait 状态之外，其他状态基本上是通过 tcp_set_state 设置的。在 time-wait 阶段的时候，内核会创建一个新的结构体去存 time-wait 的 socket，内核考虑到内存的开销问题，之前的 socket 会释放掉。先不考虑 time-wait。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bad7494f6662f2c2a8d832f7f1ea2b31_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;859&quot; data-rawheight=&quot;1064&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-bad7494f6662f2c2a8d832f7f1ea2b31_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;859&quot; data-rawheight=&quot;1064&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-bad7494f6662f2c2a8d832f7f1ea2b31_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bad7494f6662f2c2a8d832f7f1ea2b31_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;接下来看看具体的代码，上图中是载入到 eBPF 的 C 代码。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;最上面的 BPF_HASH 表示创建一个 BPF 提供的 HASH 表；last 是 HASH 表的名称；struct sock* 是指 key 的大小，这里表示指针大小；uint64_t 是 value 的大小，为 64 位；最后的 10240 表示 map 最多能够放多少个元素。 &lt;/li&gt;&lt;li&gt;往下是一个结构体 bcc_tcp_state，可以看到后面有一个 BPF_PERF_OUTPUT，它是利用到了 perf ring buffer 的一个特性。&lt;/li&gt;&lt;li&gt;再下面是函数 get_tcp_state_change，该函数会在内核调用 tcp_set_state 的时候调用。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过内核的几个参数，内核的结构体 socket，以及这个函数传进来的一些 state，可以获取当时 tcp 连接的状态转化情况，上图函数的第一个参数 ctx 实际上是寄存器，后面是要介入函数的两个参数。这里会把一些 tcp 的状态存起来，使用 perf_submit 将这些状态更新到 perf ring buffer 中，就可以在用户态把 perf ring buffer 东西给读出来，这就是 tcp 的一些状态变化。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8182a890da19f69cdcbb69e8c806f0b4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;758&quot; data-rawheight=&quot;830&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-8182a890da19f69cdcbb69e8c806f0b4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;758&quot; data-rawheight=&quot;830&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-8182a890da19f69cdcbb69e8c806f0b4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8182a890da19f69cdcbb69e8c806f0b4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是 python 代码。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先把 C 代码读进来，通过调用 bpf 初始化，将代码编译成 eBPF 字节码，载入到 eBPF 虚拟机中运行。&lt;/li&gt;&lt;li&gt;下面是 attach_kprobe，就是在内核调用 tcp，event 是指内核在调用 tcp_set_state 的时候，fn_name 是指内核在调用 tcp_set_state 时会执行 get_tcp_state_change 函数，就是前面 C 代码中的函数。&lt;/li&gt;&lt;li&gt;打开 perf ring buffer，即后面调用的 bpf[“state_events”].open_perf_buffer，里面的参数是一个 Callback 函数，在ring buffer 有数据的时候就会调用一次 print_state，也就是说在 C 代码中调用 perf_sumbit 时候就可以调用一次 print_tcpstats 函数，并会输出存入的数据。&lt;/li&gt;&lt;li&gt;最下面调用了 perf_buffer_poll的功能，只会在 ring buffer 有消息时被唤醒，再调用 Callback 函数，这样就不会无谓地浪费 CPU。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;利用 uprobe 查看应用服务信息&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fb5627b50d34b917a8f505096a32096c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;713&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic1.zhimg.com/v2-fb5627b50d34b917a8f505096a32096c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;713&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic1.zhimg.com/v2-fb5627b50d34b917a8f505096a32096c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fb5627b50d34b917a8f505096a32096c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是通过 uprobe 查看 nginx 请求分布的情况。首先要看 nginx 创建请求的位置，是在 ngx_http_create_request，和之前一样写一个要嵌入 eBPF 虚拟机的 C 代码，还是创建一个 HASH 表，名称是 req_distr，key 是 32 位大小，value 是 64 位，核心函数是 check_ngx_http_create_request，在 nginx 调用该函数时，会执行这个钩子函数，函数内部调用的是 count_req。把 PID 和 PID 上创建的请求次数对应起来，当 PID 调用过 ngx_http_create_request 时，请求计数就会 +1。如此也就可以看到整个请求在各个 work 上的分布情况。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d83044a7d70f4fd1de698ca445437ac2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;722&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic3.zhimg.com/v2-d83044a7d70f4fd1de698ca445437ac2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;722&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic3.zhimg.com/v2-d83044a7d70f4fd1de698ca445437ac2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d83044a7d70f4fd1de698ca445437ac2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图中是 python 代码，同样把 C 代码读进来，并调用 bbf 把代码编译成 llvm 字节码，载入到 eBPF 虚拟机中，再调用 attach_uprobe。name 是指 nginx 的一个二进制文件，sym 是指要在哪个函数中打个断点，上图是 ngx_http_create_request 函数。fn_name 是在 ngx_http_create_request 函数执行的时候需要调用的函数。另外需要注意二进制文件必须要把编译符号开放出来，比如编译的时加个 -g，否则会找不到这个函数。最下面是简单地获取 HASH 表，去输出 HASH 表的 key 和 value，这样就能看到 pid 对应的 request 数量，pid 也就会对应着 worker，如此就能够查看到运行 nginx 的请求分布情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;查看运行中的 eBPF 程序与 map&lt;/b&gt;&lt;/p&gt;&lt;p&gt;可以通过内核包中 bpftool 提供的 bpftool 工具查看，它的目录是在 /lib/modules/`uname-r`/tools/bpf/bpftool 中，需要自己编译一下，在  /lib/modules/`uname-r`/tools 下执行 make-C/bpf/bpftool 就可以了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-272dc2a55aed54d5fe2148a255198fdd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-272dc2a55aed54d5fe2148a255198fdd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-original=&quot;https://pic2.zhimg.com/v2-272dc2a55aed54d5fe2148a255198fdd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-272dc2a55aed54d5fe2148a255198fdd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是 bpftool 工具查看 map（前面 BPF_HASH 创建的）情况的效果，-p 参数，能够展示得好看一些。prog 参数可以把在虚拟机中跑的程序给展示出来。这样就能看到到底运行了那些 eBPF 程序以及申请的 map。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;eBPF 在又拍云的发展&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;完善 cdn 系统监控体系&lt;/li&gt;&lt;li&gt;强化 cdn 业务链路 traceing，提高服务水平，提供更多的性能分析的途径&lt;/li&gt;&lt;li&gt;解决 cdn 服务中遇到的某些难以解决的问题 注：目前通过 systemtap 可以解决&lt;/li&gt;&lt;li&gt;将 XDP 引入又拍云边缘机器，给予防范 DDoS 攻击提供帮助&lt;/li&gt;&lt;li&gt; 替换 tcpdump 工具，加快抓包效率，减少抓包时对系统性能的影响&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;演讲视频查看：&lt;/b&gt;&lt;/p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://link.zhihu.com/?target=https%3A//shangzhibo.tv/watch/10201448&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-665b3050e2ea3f93aae1032705125c52_ipico.jpg&quot; data-image-width=&quot;320&quot; data-image-height=&quot;320&quot; class=&quot;LinkCard LinkCard--hasImage&quot;&gt;&lt;span class=&quot;LinkCard-backdrop&quot;/&gt;&lt;span class=&quot;LinkCard-content&quot;&gt;&lt;span class=&quot;LinkCard-text&quot;&gt;&lt;span class=&quot;LinkCard-title&quot; data-text=&quot;true&quot;&gt;聊聊风口上的 eBPF&lt;/span&gt;&lt;span class=&quot;LinkCard-meta&quot;&gt;&lt;span&gt;​&lt;svg class=&quot;Zi Zi--InsertLink&quot; fill=&quot;currentColor&quot; viewbox=&quot;0 0 24 24&quot;&gt;&lt;path d=&quot;M13.414 4.222a4.5 4.5 0 1 1 6.364 6.364l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005a2.5 2.5 0 1 0-3.536-3.536l-3.005 3.005a.5.5 0 0 1-.707 0l-.707-.707a.5.5 0 0 1 0-.707l3.005-3.005zm-6.187 6.187a.5.5 0 0 1 .638-.058l.07.058.706.707a.5.5 0 0 1 .058.638l-.058.07-3.005 3.004a2.5 2.5 0 0 0 3.405 3.658l.13-.122 3.006-3.005a.5.5 0 0 1 .638-.058l.069.058.707.707a.5.5 0 0 1 .058.638l-.058.069-3.005 3.005a4.5 4.5 0 0 1-6.524-6.196l.16-.168 3.005-3.005zm8.132-3.182a.25.25 0 0 1 .353 0l1.061 1.06a.25.25 0 0 1 0 .354l-8.132 8.132a.25.25 0 0 1-.353 0l-1.061-1.06a.25.25 0 0 1 0-.354l8.132-8.132z&quot;/&gt;&lt;/svg&gt;&lt;/span&gt;shangzhibo.tv&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;LinkCard-imageCell&quot;&gt;&lt;img class=&quot;LinkCard-image LinkCard-image--square&quot; alt=&quot;图标&quot; src=&quot;https://pic3.zhimg.com/v2-665b3050e2ea3f93aae1032705125c52_ipico.jpg&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;p/&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>1bd95cb265c5f43909eff10a6276c3bf</guid>
<title>下一代消息队列 Pulsar 到底是什么？</title>
<link>https://toutiao.io/k/zdb2zbb</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;h1&gt;&lt;span&gt;背景&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h1&gt;&lt;p&gt;之前琢磨了很久一直想写一篇pulsar相关的文章，但是一直知识储备不够，对于很多细节还是不了解，于是查了很多资料，总算是可以凑出一篇文章了。&lt;/p&gt;&lt;p&gt;Pulsar是一个由yahoo公司于2016年开源的消息中间件，2018年成为Apache的顶级项目。在我之前的文章中写过很多其他消息中间件的文章，比如kafka,rocketmq等等，如果大家对于消息队列不了解的可以阅读以下我之前的文章：&lt;/p&gt;&lt;p&gt;在开源的业界已经有这么多消息队列中间件了，pulsar作为一个新势力到底有什么优点呢？pulsar自从出身就不断的再和其他的消息队列(kafka,rocketmq等等)做比较，但是Pulsar的设计思想和大多数的消息队列中间件都不同，具备了高吞吐，低延迟，计算存储分离，多租户，异地复制等功能，所以pulsar也被誉为下一代消息队列中间件，接下来我会一一对其进行详细的解析。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;pulsar架构原理&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h1&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.64625&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpdPPsZbeAvrrzUdzaiaWOlGJNWAfwjkvl812I4DN1EZ0mWJmQiaHuAFGQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;br/&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6613039796782387&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicp2Z2rQo555PBQwJo0ESGSUZUj47QhaYiaficfPYabicImNjmehiaO0bNENg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1181&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;br/&gt;整体的架构和其他的消息队列中间件差别不是太大，相信大家也看到了很多熟悉的名词，接下来会给大家一一解释这些名词的含义。&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;名词解释&lt;/span&gt;&lt;/h2&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Producer:消息生产者，将消息发送到broker。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Consumer:消息消费者，从Broker读取消息到客户端，进行消费处理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Broker: 可以看作是pulsar的server,Producer和Consumer都看作是client.消息处理的节点，pulsar的Broker和其他消息中间件的都不一样，他是无状态的没有存储，所以可以无限制的扩展，这个后面也会详解讲到。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Bookie: 负责所有消息的持久化，这里采用的是Apache Bookeeper。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ZK: 和kafka一样pulsar也是使用zk保存一些元数据，比如配置管理,topic分配，租户等等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Service Discovery：可以理解为Pulsar中的nginx，只用一个url就可以和整个broker进行打交道，当然也可以使用自己的服务发现。客户端发出的读取，更新或删除主题的初始请求将发送给可能不是处理该主题的 broker 。如果这个 broker 不能处理该主题的请求，broker 将会把该请求重定向到可以处理主题请求的 broker。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;不论是kafka,rocketmq还是我们的pulsar其实作为消息队列中间件最为重要的大概就是分为三个部分：&lt;/p&gt;&lt;p&gt;而我们后面也会围绕着这三个部分进行展开讲解。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;Producer生产消息&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;先简单看一下如何用代码进行消息发送：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;PulsarClient client = PulsarClient.create(&lt;span&gt;&quot;pulsar://pulsar.us-west.example.com:6650&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;Producer producer = client.createProducer(&lt;br/&gt;                &lt;span&gt;&quot;persistent://sample/standalone/ns1/my-topic&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// Publish 10 messages to the topic&lt;/span&gt;&lt;br/&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;10&lt;/span&gt;; i++) {&lt;br/&gt;    producer.send(&lt;span&gt;&quot;my-message&quot;&lt;/span&gt;.getBytes());&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;url的格式为：{persistent|non-persistent}://tenant/namespace/topic&lt;/p&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;组成&lt;/th&gt;&lt;th&gt;含义&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;persistent/non-persistent&lt;/td&gt;&lt;td&gt;Pulsar 提供持久化、非持久化两种主题，如果选择的是非持久化主题的话，所有消息都在内存中保存，如果broker重启，消息将会全部丢失。如果选择的是持久化主题，所有消息都会持久化到磁盘，重启broker，消息也可以正常消费。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;tenant&lt;/td&gt;&lt;td&gt;顾名思义就是租户，pulsar最开始在雅虎内部是作为全公司使用的中间件使用的，需要给topic指定一些层级，租户就是其中一层，比如这个可以是一个大的部门，例如电商中台租户。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;namespace&lt;/td&gt;&lt;td&gt;命名空间，可以看作是第二层的层级，比如电商中台下的订单业务组&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;topic&lt;/td&gt;&lt;td&gt;消息队列名字&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;上面三个步骤中，步骤1，2属于我们准备阶段，用于构建客户端，构建Producer，我们真的核心逻辑在send中，那这里我先提几个小问题，大家可以先想想在其他消息队列中是怎么做的，然后再对比pulsar的看一下：&lt;/p&gt;&lt;h3&gt;&lt;span&gt;发送模式&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;我们上面说了send分为async和sync两种模式，但实际上在pulsar内部sync模式也是采用的async模式，在sync模式下模拟回调阻塞，达到同步的效果，这个在kafka中也是采用的这个模式，但是在rocketmq中，所有的send都是真正的同步，都会直接请求到broker。&lt;/p&gt;&lt;p&gt;基于这个模式，在pulsar和kafka中都支持批量发送，在rocketmq中是直接发送，批量发送有什么好处呢？当我们发送的TPS特别高的时候，如果每次发送都直接和broker直连，可能会做很多的重复工作，比如压缩，鉴权，创建链接等等。比如我们发送1000条消息，那么可能会做1000次这个重复的工作，如果是批量发送的话这1000条消息合并成一次请求，相对来说压缩，鉴权这些工作就只需要做一次。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.6829268292682927&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpicYSEb74hicQiajAdXicp7FAhKtwNddrnzlrZN7CzZZ7drtKEOxvIrHdBA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;615&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;有同学可能会问，批量发送会不会导致发送的时间会有一定的延误？这个其实不需要担心，在pulsar中默认定时每隔1ms发送一次batch,或者当batchsize默认到了1000都会进行发送，这个发送的频率都还是很快的。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;发送负载均衡&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;在消息队列中通常会将topic进行水平扩展，在pulsar和kafka中叫做partition,在rocketmq中叫做queue，本质上都是分区，我们可以将不同分区落在不同的broker上，达到我们水平扩展的效果。&lt;/p&gt;&lt;p&gt;在我们发送的时候可以自己制定选择partition的策略，也可以使用它默认轮训partition策略。当我们选择了partition之后，我们怎么确定哪一个partition对应哪一个broker呢？&lt;/p&gt;&lt;p&gt;可以先看看下面这个图：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5947441217150761&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpxp5CtL6ECZQiageZabTicmAwjUmOoAqPiabY9zIC1wcuMjpniciarNB5rUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;723&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step1: 我们所有的信息分区映射信息在zk和broker的缓存中都有进行存储。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step2: 我们通过查询broker，可以获取到分区和broker的关系，并且定时更新。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step3: 在pulsar中每个分区在发送端的时候都被抽象成为一个单独的Producer,这个和kafka,rocketmq都不一样，在kafka里面大概就是选择了partition之后然后再去找partition对应的broker地址，然后进行发送。pulsar将每一个partition都封装成Producer，在代码实现上就不需要去关注他具体对应的是哪个broker,所有的逻辑都在producer这个代码里面，整体来说比较干净。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.1120527306967985&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicp381RgagAa1GiaQVaV0LjgwZqKicgNSCu4JnrpYmRmktbK7D0XNkcV8ZQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1062&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;压缩消息&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;消息压缩是优化信息传输的手段之一，我们通常看见一些大型文件都会是以一个压缩包的形式提供下载，在我们消息队列中我们也可以用这种思想，我们将一个batch的消息，比如有1000条可能有1M的传输大小，但是经过压缩之后可能就只会有几十kb，增加了我们和broker的传输效率，但是与之同时我们的cpu也带来了损耗。Pulsar客户端支持多种压缩类型，如 lz4、zlib、zstd、snappy 等。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;client&lt;/span&gt;&lt;span&gt;.newProducer&lt;/span&gt;()&lt;br/&gt;    &lt;span&gt;.topic&lt;/span&gt;(“&lt;span&gt;test-topic&lt;/span&gt;”)&lt;br/&gt;    &lt;span&gt;.compressionType&lt;/span&gt;(&lt;span&gt;CompressionType&lt;/span&gt;&lt;span&gt;.LZ4&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;.create&lt;/span&gt;();&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;&lt;span&gt;Broker&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;接下来我们来说说第二个比较重要的部分&lt;code&gt;Broker&lt;/code&gt;,在Broker的设计中pulsar和其他所有的消息队列差别比较大，而正是因为这个差别也成为了他的特点。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;计算和存储分离&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;首先我们来说说他最大的特点：计算和存储分离。我们在开始的说过Pulsar是下一代消息队列，就非常得益于他这个架构设计，无论是kafka还是RocketMQ,所有的计算和存储都放在同一个机器上，这个模式有几个弊端：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;扩展困难：当我们需要扩展的集群的时候，我们通常是因为cpu或者磁盘其中一个原因影响，但是我们却要申请一个可能cpu和磁盘配置都很好的机器，造成了资源浪费。并且kafka这种进行扩展，还需要进行迁移数据，过程十分繁杂。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;负载不均衡：当某些partion数据特别多的时候，会导致broker负载不均衡,如下面图，如果某个partition数据特别多，那么就会导致某个broker(轮船)承载过多的数据，但是另外的broker可能又比较空闲&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.593103448275862&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpEVU4vddk4D1d2axUczn6YuicY8AaJIibH2meTJktH4AwZRZdXwgicG1jw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;725&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;pulsar计算分离架构能够非常好的解决这个问题:&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于计算：也就是我们的broker,提供消息队列的读写,不存储任何数据，无状态对于我们扩展非常友好，只要你机器足够，就能随便上。扩容Broker往往适用于增加Consumer的吞吐，当我们有一些大流量的业务或者活动，比如电商大促，可以提前进行broker的扩容。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于存储：也就是我们的bookie,只提供消息队列的存储，如果对消息量有要求的，我们可以扩容bookie,并且我们不需要迁移数据，扩容十分方便。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;消息存储&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;名词解析：&lt;/span&gt;&lt;/h4&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5368916797488226&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpTEBtembhB7CAZzYw9A3Labib9AwibiaiamkkVXPKZrUicuOuKPeqecRibmFg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;637&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是bookie的读写架构图，里面有一些名词需要先介绍一下：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Entry,Entry是存储到bookkeeper中的一条记录，其中包含Entry ID，记录实体等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Ledger，可以认为ledger是用来存储Entry的，多个Entry序列组成一个ledger。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Journal，其实就是bookkeeper的WAL(write ahead log)，用于存bookkeeper的事务日志，journal文件有一个最大大小，达到这个大小后会新起一个journal文件。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Entry log，存储Entry的文件，ledger是一个逻辑上的概念，entry会先按ledger聚合，然后写入entry log文件中。同样，entry log会有一个最大值，达到最大值后会新起一个新的entry log文件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Index file，ledger的索引文件，ledger中的entry被写入到了entry log文件中，索引文件用于entry log文件中每一个ledger做索引，记录每个ledger在entry log中的存储位置以及数据在entry log文件中的长度。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MetaData Storage，元数据存储，是用于存储bookie相关的元数据，比如bookie上有哪些ledger，bookkeeper目前使用的是zk存储，所以在部署bookkeeper前，要先有zk集群。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.7194092827004219&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpDgRkSN5YPz4iblP9Dk1icKWib4JaVvhWVNb0I71unGicpwkKCz96kE6TJQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;474&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;整体架构上的写流程：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step1: broker发起写请求，首先对Journal磁盘写入WAL，熟悉mysql的朋友知道redolog，journal和redolog作用一样都是用于恢复没有持久化的数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step2: 然后再将数据写入index和ledger，这里为了保持性能不会直接写盘，而是写pagecache,然后异步刷盘。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Step3: 对写入进行ack。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;读流程为：&lt;/p&gt;&lt;h4&gt;&lt;span&gt;如何高效读写？&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;在kafka中当我们的topic变多了之后，由于kafka一个topic一个文件，就会导致我们的磁盘IO从顺序写变成随机写。在rocketMq中虽然将多个topic对应一个写入文件，让写入变成了顺序写，但是我们的读取很容易导致我们的pagecache被各种覆盖刷新，这对于我们的IO的影响是非常大的。所以pulsar在读写两个方面针对这些问题都做了很多优化：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;写流程：顺序写 + pagecache。在写流程中我们的所有的文件都是独立磁盘，并且同步刷盘的只有Journal，Journal是顺序写一个journal-wal文件,顺序写效率非常高。ledger和index虽然都会存在多个文件，但是我们只会写入pagecache,异步刷盘，所以随机写不会影响我们的性能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;读流程：broker cache + bookie cache，在pulsar中对于追尾读(tailing read)非常友好基本不会走io,一般情况下我们的consumer是会立即去拿producer发送的消息的，所以这部分在持久化之后依然在broker中作为cache存在，当然就算broker没有cache（比如broker是新建的），我们的bookie也会在memtable中有自己的cache,通过多重cache减少读流程走io。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们可以发现在最理想的情况下读写的io是完全隔离开来的，所以在Pulsar中能很容易就支持百万级topic，而在我们的kafka和rocketmq中这个是非常困难的。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;无限流式存储&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;一个Topic实际上是一个ledgers流(Segment)，通过这个设计所以Pulsar他并不是一个单纯的消息队列系统，他也可以代替流式系统，所以他也叫流原生平台,可以替代flink等系统。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.38769804287045667&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicprrSP1onDszchvSbiapf9iaft1It8BPn4oTz3MqnE6ibHh7un92nlUpRIw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1073&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;br/&gt;可以看见我们的Event Stream（topic/partition），由多个Segment存储组成，而每个segment由entry组成，这个可以看作是我们每批发送的消息通常会看作是一个entry。&lt;p&gt;&lt;/p&gt;&lt;p&gt;Segment可以看作是我们写入文件的一个基本维度，同一个Segment的数据会写在同一个文件上面，不同Segment将会是不同文件，而Segment之间的在metadata中进行保存。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;1.0059171597633136&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpV5xoM9uL8KVPtWia1iae1vKYuJVqD1mmQK1QyxrFDj0Zdtp1Mvk1OFdw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;845&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;h4&gt;&lt;span&gt;分层存储&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;在kafka和rocketmq中消息是会有一定的保存时间的，因为磁盘会有空间限制，在pulsar中也提供这个功能，但是如果你想让自己的消息永久存储，那么可以使用分级存储，我们可以将一些比较老的数据，定时的刷新到廉价的存储中，比如s3,那么我们就可以无限存储我们的消息队列了。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5384615384615384&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpX9dGI1Vfa4NkTb5H2SALfUVq0RlYSM1bcADrvSIakNicNu7VvVSMAWA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;780&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;span&gt;数据复制&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;在pulsar中的数据复制和kafka,rocketmq都有很大的不同，在其他消息队列中通常是其他副本主动同步，通常这个时间就会变得不可预测，而在pulsar采用了类似qurom协议，给一组可用的bookie池，然后并发的写入其中的一部分bookie,只要返回部分成功（通常大于1/2）就好。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.44237485448195574&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpvMVswByR0dpicngA7ch9sybZYvWg3AFaFfMxKqiag9gbolia1y6YibOibHw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;859&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Ensemble Size（E）决定给定 ledger 可用的 bookie 池大小。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Write Quorum Size（Qw）指定 Pulsar 向其中写入 entry 的 bookie 数量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Ack Quorum Size（Qa）指定必须 ack 写入的 bookie 数量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;采用这种并发写的方式，会更加高效的进行数据复制，尤其是当数据副本比较多的时候。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;Consumer&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;接下来我们来聊聊pulsar中最后一个比较重要的组成&lt;code&gt;consumer&lt;/code&gt;。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;订阅模式&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;订阅模式是用来定义我们的消息如何分配给不同的消费者，不同消息队列中间件都有自己的订阅模式，一般我们常见的订阅模式有：&lt;/p&gt;&lt;p&gt;在pulsar中提供了4种订阅模式，分别是独占，灾备，共享，键共享：&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.7243589743589743&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicp1KMujmD0WuSzbbnN7XvW3Xn53jLYy4FHpiaLhst5TtmthL4NLt8QbgQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;936&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;独占：顾名思义只能由一个消费者独占，如果同一个集群内有第二个消费者去注册，第二个就会失败，这个适用于全局有序的消息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;灾备：加强版独占，如果独占的那个挂了，会自动的切换到另外一个好的消费者，但是还是只能由一个独占。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;共享模式：这个模式看起来有点像集群模式，一条消息也是只能被一个集群内消费者消费，但是和rocketmq不同的是，rocketmq是以partition维度，同一个Partition的数据都会被发到一个机器上。在Pulsar中消费不会以partition维度，而是轮训所有消费者进行消息发送。这有个什么好处呢？如果你有100台机器，但是你只有10个partition其实你只有10台消费者能运转，但是在pulsar中100台机器都可以进行消费处理。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;键共享：类似上面说的partition维度去发送，在rocketmq中同一个key的顺序消息都会被发送到一个partition，但是这里不会有partition维度，而只是按照key的hash去分配到固定的consumer,也解决了消费者能力限制于partition个数问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;消息获取模式&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;不论是在kafka还是在rocketmq中我们都是client定时轮训我们的broker获取消息，这种模式叫做长轮训（Long-Polling）模式。这种模式有一个缺点网络开销比较大，我们来计算一下consumer被消费的时延，我们假设broker和consumer之间的一次网络延时为R,那么我们总共的时间为：&lt;/p&gt;&lt;p&gt;如果只考虑网络时延，我们可以看见我们这条消息的消费时延大概是3R，所以我们必须想点什么对其进行一些优化，有同学可能马上就能想到，我们消息来了直接推送给我们的consumer不就对了，这下我们的时延只会有一次R,这个就是我们常见的推模式，但是简单的推模式是有问题的，如果我们有生产速度远远大于消费速度，那么推送的消息肯定会干爆我们的内存，这个就是背压。那么我们怎么解决背压呢？我们就可以优化推送方式，将其变为动态推送，我们结合Long-polling,在long-polling请求时将Buffer剩余空间告知给Broker，由Broker负责推送数据。此时Broker知道最多可以推送多少条数据，那么就可以控制推送行为，不至于冲垮Consumer。&lt;/p&gt;&lt;p&gt;举个例子：&lt;/p&gt;&lt;p&gt;Consumer发起请求时Buffer剩余容量为100，Broker每次最多返回32条消息，那么Consumer的这次long-polling请求Broker将在执行3次push(共push96条消息)之后返回response给Consumer（response包含4条消息）。&lt;/p&gt;&lt;p&gt;如果采用long-polling模型，Consumer每发送一次请求Broker执行一次响应，这个例子需要进行4次long-polling交互（共4个request和4个response，8次网络操作；Dynamic Push/Pull中是1个request，三次push和一个response，共5次网络操作）。&lt;/p&gt;&lt;p&gt;所以pulsar就采用了这种消息获取模式，从consumer层进一步优化消息达到时间。我觉得这个设计非常巧妙，很多中间件的这种long-polling模式都可以参考这种思想去做一个改善。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;Apache Pulsar很多设计思想都和其他中间件不一样，但无疑于其更加贴近于未来，大胆预测一下其他的一些消息中间件未来的发展也都会向其靠拢，目前国内的Pulsar使用者也是越来越多，腾讯云提供了pulsar的云版本TDMQ，当然还有一些其他的知名公司华为，知乎，虎牙等等有都在对其做一个逐步的尝试，我相信pulsar真的是一个趋势。最后也让我想起了最近大江大河大结局的一句话：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;所有的变化,都可能伴随着痛苦和弯路,开放的道路,也不会是阔野坦途,但大江大河,奔涌向前的趋势,不是任何险滩暗礁,能够阻挡的。道之所在，虽千万人吾往矣。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我在这里其实只说了一些大概，更多的一些细节，大家可以看一下下面的学习参考资料吧：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;首先大家可以去看看pulsar的官网的文档，首先了解一个大概。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;大家也可以关注pulsar的公众号，每天都会发一些pulsar相关的文章，我觉得写得非常好。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可以去B站搜索TGIP，这个是pulsar每周都会由一个项目组的成员去讲相关的资料，如果想学习可以看看这个视频。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;push or pull?: https://www.cnblogs.com/hzmark/p/mq_push_pull.html&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;架构决策之消息中间件-Pulsar:https://blog.csdn.net/tcy83/article/details/106731392&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;p&gt;如果大家觉得这篇文章对你有帮助，你的关注和转发是对我最大的支持，O(∩_∩)O:&lt;/p&gt;&lt;/blockquote&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.75&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/WLIGprPy3z6ibh9GlSJhAqFWWRhSyXGicpLdMFV81zLYP1iaJRxCNEevut3q6tRzADYvhMoYns3ppkydeLtSowUnQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;500&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>762d5e611b573ec28af826eb9d8d1b67</guid>
<title>数据仓库组件：Hive 环境搭建和基础用法</title>
<link>https://toutiao.io/k/8igq6ef</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;h1&gt;&lt;span&gt;一、Hive基础简介&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;1、基础描述&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Hive是基于Hadoop的一个数据仓库工具，用来进行数据提取、转化、加载，是一个可以对Hadoop中的大规模存储的数据进行查询和分析存储的组件，Hive数据仓库工具能将结构化的数据文件映射为一张数据库表，并提供SQL查询功能，能将SQL语句转变成MapReduce任务来执行，使用成本低，可以通过类似SQL语句实现快速MapReduce统计，使MapReduce变得更加简单，而不必开发专门的MapReduce应用程序。hive十分适合对数据仓库进行统计分析。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、组成与架构&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.51640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBtMEBLgsvMJM2s5RF73CpP7PrGAmYmPLAvTCFKG1bib4nc3wEdicL4ialAaQqO6G1Bia93UdLchy0dQA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;用户接口&lt;/strong&gt;：ClientCLI、JDBC访问Hive、WEBUI浏览器访问Hive。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;元数据&lt;/strong&gt;：Hive将元数据存储在数据库中，如mysql、derby。Hive中的元数据包括表的名字，表的列和分区以及属性，表的属性（是否为外部表等），表的数据所在目录等。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;驱动器&lt;/strong&gt;：基于解释器、编辑器、优化器完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;执行器引擎&lt;/strong&gt;：ExecutionEngine把逻辑执行计划转换成可以运行的物理计划。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hadoop底层&lt;/strong&gt;：基于HDFS进行存储，使用MapReduce进行计算，基于Yarn的调度机制。&lt;/p&gt;&lt;p&gt;Hive收到给客户端发送的交互请求，接收到操作指令(SQL)，并将指令翻译成MapReduce，提交到Hadoop中执行，最后将执行结果输出到客户端。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;二、Hive环境安装&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;1、准备安装包&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;hive-1.2，依赖Hadoop集群环境，位置放在hop01服务上。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、解压重命名&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;tar&lt;/span&gt; -zxvf apache-hive-&lt;span&gt;1&lt;/span&gt;.&lt;span&gt;2&lt;/span&gt;.&lt;span&gt;1&lt;/span&gt;-bin.tar.gz&lt;br/&gt;mv apache-hive-&lt;span&gt;1&lt;/span&gt;.&lt;span&gt;2&lt;/span&gt;.&lt;span&gt;1&lt;/span&gt;-bin/ hive1.&lt;span&gt;2&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3、修改配置文件&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;创建配置文件&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 conf]&lt;span&gt;# pwd&lt;/span&gt;&lt;br/&gt;/opt/hive1&lt;span&gt;.2&lt;/span&gt;/conf&lt;br/&gt;[root@hop01 conf]&lt;span&gt;# mv hive-env.sh.template hive-env.sh&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;添加内容&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 conf]&lt;span&gt;# vim hive-env.sh&lt;/span&gt;&lt;br/&gt;&lt;span&gt;export&lt;/span&gt; HADOOP_HOME=/opt/hadoop2&lt;span&gt;.7&lt;/span&gt;&lt;br/&gt;&lt;span&gt;export&lt;/span&gt; HIVE_CONF_DIR=/opt/hive1&lt;span&gt;.2&lt;/span&gt;/conf&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置内容一个是Hadoop路径，和hive配置文件路径。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、Hadoop配置&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;首先启动hdfs和yarn；然后在HDFS上创建/tmp和/user/hive/warehouse两个目录并修改赋予权限。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;bin/hadoop fs -&lt;span&gt;mkdir&lt;/span&gt; /tmp&lt;br/&gt;bin/hadoop fs -&lt;span&gt;mkdir&lt;/span&gt; -p /user/hive/warehouse&lt;br/&gt;bin/hadoop fs -&lt;span&gt;chmod&lt;/span&gt; g+w /tmp&lt;br/&gt;bin/hadoop fs -&lt;span&gt;chmod&lt;/span&gt; g+w /user/hive/warehouse&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;5、启动Hive&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 hive1&lt;span&gt;.2&lt;/span&gt;]&lt;span&gt;# bin/hive&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;6、基础操作&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;查看数据库&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;hive&amp;gt;&lt;/span&gt;&lt;span&gt; show databases ;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;选择数据库&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hive&amp;gt; &lt;span&gt;use&lt;/span&gt; &lt;span&gt;default&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;查看数据表&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;hive&amp;gt;&lt;/span&gt;&lt;span&gt; show tables;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;创建数据库使用&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hive&amp;gt; create database mytestdb;&lt;br/&gt;hive&amp;gt; show databases ;&lt;br/&gt;&lt;span&gt;default&lt;/span&gt;&lt;br/&gt;mytestdb&lt;br/&gt;hive&amp;gt; &lt;span&gt;use&lt;/span&gt; &lt;span&gt;mytestdb&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;创建表&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;create&lt;/span&gt; &lt;span&gt;table&lt;/span&gt; hv_user (&lt;span&gt;id&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;, &lt;span&gt;name&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;, age &lt;span&gt;int&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;查看表结构&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hive&amp;gt; desc hv_user;&lt;br/&gt;id                      &lt;span&gt;int&lt;/span&gt;                                         &lt;br/&gt;name                    &lt;span&gt;string&lt;/span&gt;                                      &lt;br/&gt;age                     &lt;span&gt;int&lt;/span&gt; &lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;添加表数据&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;insert&lt;/span&gt; &lt;span&gt;into&lt;/span&gt; hv_user &lt;span&gt;values&lt;/span&gt; (&lt;span&gt;1&lt;/span&gt;, &lt;span&gt;&quot;test-user&quot;&lt;/span&gt;, &lt;span&gt;23&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;查询表数据&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hive&amp;gt; &lt;span&gt;select&lt;/span&gt; * &lt;span&gt;from&lt;/span&gt; hv_user ;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;注意：这里通过对查询日志的观察，明显看出Hive执行的流程。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;删除表&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;hive&amp;gt;&lt;/span&gt;&lt;span&gt; drop table hv_user ;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;退出Hive&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;hive&amp;gt;&lt;/span&gt;&lt;span&gt; quit;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;查看Hadoop目录&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;# hadoop fs -ls /user/hive/warehouse       &lt;/span&gt;&lt;br/&gt;/user/hive/warehouse/mytestdb.db&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过Hive创建的数据库和数据存储在HDFS上。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;三、整合MySQL5.7环境&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;这里默认安装好MySQL5.7的版本，并配置好相关登录账号，配置root用户的Host为%模式。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1、上传MySQL驱动包&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;将MySQL驱动依赖包上传到hive安装目录的lib目录下。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 &lt;span&gt;lib&lt;/span&gt;]&lt;span&gt;# pwd&lt;/span&gt;&lt;br/&gt;/opt/hive1&lt;span&gt;.2&lt;/span&gt;/&lt;span&gt;lib&lt;/span&gt;&lt;br/&gt;[root@hop01 &lt;span&gt;lib&lt;/span&gt;]&lt;span&gt;# ll&lt;/span&gt;&lt;br/&gt;mysql-connector-java&lt;span&gt;-5.1&lt;/span&gt;&lt;span&gt;.27&lt;/span&gt;-bin.jar&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2、创建hive-site配置&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 conf]&lt;span&gt;# pwd&lt;/span&gt;&lt;br/&gt;/opt/hive1&lt;span&gt;.2&lt;/span&gt;/conf&lt;br/&gt;[root@hop01 conf]&lt;span&gt;# touch hive-site.xml&lt;/span&gt;&lt;br/&gt;[root@hop01 conf]&lt;span&gt;# vim hive-site.xml&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3、配置MySQL存储&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&amp;lt;&lt;span&gt;configuration&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionURL&lt;span&gt;&amp;lt;/&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;jdbc:mysql://hop01:3306/metastore?createDatabaseIfNotExist=true&lt;span&gt;&amp;lt;/&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;JDBC connect string for a JDBC metastore&lt;span&gt;&amp;lt;/&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;/&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionDriverName&lt;span&gt;&amp;lt;/&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;com.mysql.jdbc.Driver&lt;span&gt;&amp;lt;/&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;Driver class name for a JDBC metastore&lt;span&gt;&amp;lt;/&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;/&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionUserName&lt;span&gt;&amp;lt;/&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;root&lt;span&gt;&amp;lt;/&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;username to use against metastore database&lt;span&gt;&amp;lt;/&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;/&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionPassword&lt;span&gt;&amp;lt;/&lt;span&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;123456&lt;span&gt;&amp;lt;/&lt;span&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;&amp;lt;&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;password to use against metastore database&lt;span&gt;&amp;lt;/&lt;span&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;&amp;lt;/&lt;span&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&amp;lt;/&lt;span&gt;configuration&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置完成后，依次重启MySQL、hadoop、hive环境，查看MySQL数据库信息，多了metastore数据库和相关表。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、后台启动hiveserver2&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[root@hop01 hive1&lt;span&gt;.2&lt;/span&gt;]&lt;span&gt;# bin/hiveserver2 &amp;amp;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;5、Jdbc连接测试&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[&lt;span&gt;root@hop01 hive1.2&lt;/span&gt;]&lt;span&gt;# bin/beeline&lt;/span&gt;&lt;br/&gt;Beeline version &lt;span&gt;1.2&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; Apache Hive&lt;br/&gt;beeline&amp;gt; !connect jdbc:hive2:&lt;span&gt;//hop01:10000&lt;/span&gt;&lt;br/&gt;Connecting to jdbc:hive2:&lt;span&gt;//hop01:10000&lt;/span&gt;&lt;br/&gt;Enter username &lt;span&gt;for&lt;/span&gt; jdbc:hive2:&lt;span&gt;//hop01:10000: hiveroot (账户回车)&lt;/span&gt;&lt;br/&gt;Enter password &lt;span&gt;for&lt;/span&gt; jdbc:hive2:&lt;span&gt;//hop01:10000: ******   (密码123456回车)&lt;/span&gt;&lt;br/&gt;Connected to: &lt;span&gt;Apache &lt;span&gt;Hive&lt;/span&gt; (&lt;span&gt;version &lt;span&gt;1.2&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;&lt;/span&gt;)&lt;br/&gt;Driver: Hive &lt;span&gt;JDBC&lt;/span&gt; (&lt;span&gt;version &lt;span&gt;1.2&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;&lt;/span&gt;)&lt;br/&gt;0: jdbc:hive2:&lt;span&gt;//hop01:10000&amp;gt; show databases;&lt;/span&gt;&lt;br/&gt;+----------------+--+&lt;br/&gt;| database_name  |&lt;br/&gt;+----------------+--+&lt;br/&gt;| &lt;span&gt;default&lt;/span&gt;        |&lt;br/&gt;+----------------+--+&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h1&gt;&lt;span&gt;四、高级查询语法&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;1、基础函数&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;count&lt;/span&gt;(*) count_user &lt;span&gt;from&lt;/span&gt; hv_user;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;sum&lt;/span&gt;(age) sum_age &lt;span&gt;from&lt;/span&gt; hv_user;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;min&lt;/span&gt;(age) min_age,&lt;span&gt;max&lt;/span&gt;(age) max_age &lt;span&gt;from&lt;/span&gt; hv_user;&lt;br/&gt;+&lt;span&gt;----------+----------+--+&lt;/span&gt;&lt;br/&gt;| min_age  | max_age  |&lt;br/&gt;+&lt;span&gt;----------+----------+--+&lt;/span&gt;&lt;br/&gt;| 23       | 25       |&lt;br/&gt;+&lt;span&gt;----------+----------+--+&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;2、条件查询语句&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;select&lt;/span&gt; * &lt;span&gt;from&lt;/span&gt; hv_user &lt;span&gt;where&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;=&lt;span&gt;&#x27;test-user&#x27;&lt;/span&gt; &lt;span&gt;limit&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;| hv_user.id  | hv_user.name  | hv_user.age  |&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;| 1           | test-user     | 23           |&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt; * &lt;span&gt;from&lt;/span&gt; hv_user &lt;span&gt;where&lt;/span&gt; &lt;span&gt;id&lt;/span&gt;&amp;gt;&lt;span&gt;1&lt;/span&gt; &lt;span&gt;AND&lt;/span&gt; &lt;span&gt;name&lt;/span&gt; &lt;span&gt;like&lt;/span&gt; &lt;span&gt;&#x27;dev%&#x27;&lt;/span&gt;;&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;| hv_user.id  | hv_user.name  | hv_user.age  |&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;| 2           | dev-user      | 25           |&lt;br/&gt;+&lt;span&gt;-------------+---------------+--------------+--+&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;count&lt;/span&gt;(*) count_name,&lt;span&gt;name&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; hv_user &lt;span&gt;group&lt;/span&gt; &lt;span&gt;by&lt;/span&gt; &lt;span&gt;name&lt;/span&gt;;&lt;br/&gt;+&lt;span&gt;-------------+------------+--+&lt;/span&gt;&lt;br/&gt;| count_name  |    name    |&lt;br/&gt;+&lt;span&gt;-------------+------------+--+&lt;/span&gt;&lt;br/&gt;| 1           | dev-user   |&lt;br/&gt;| 1           | test-user  |&lt;br/&gt;+&lt;span&gt;-------------+------------+--+&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;3、连接查询&lt;/strong&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;select&lt;/span&gt; t1.*,t2.* &lt;span&gt;from&lt;/span&gt; hv_user t1 &lt;span&gt;join&lt;/span&gt; hv_dept t2 &lt;span&gt;on&lt;/span&gt; t1.id=t2.dp_id;&lt;br/&gt;+&lt;span&gt;--------+------------+---------+-----------+-------------+--+&lt;/span&gt;&lt;br/&gt;| t1.id  |  t1.name   | t1.age  | t2.dp_id  | t2.dp_name  |&lt;br/&gt;+&lt;span&gt;--------+------------+---------+-----------+-------------+--+&lt;/span&gt;&lt;br/&gt;| 1      | test-user  | 23      | 1         | 技术部      |&lt;br/&gt;+&lt;span&gt;--------+------------+---------+-----------+-------------+--+&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h1&gt;&lt;span&gt;五、源代码地址&lt;/span&gt;&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;GitHub·地址&lt;br/&gt;https:&lt;span&gt;//github.com/cicadasmile/big-data-parent&lt;/span&gt;&lt;br/&gt;GitEE·地址&lt;br/&gt;https:&lt;span&gt;//gitee.com/cicadasmile/big-data-parent&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.3783359497645212&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvCjMheLZtcM2iaVMBOpIUKR4CDRCG9FLT5K6NmGXvG7exrW0TSuDjnTKJQ5PDq8j8Y7PHDd17Z3gicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1274&quot;/&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>46bfb077978831f4e41faabbf9f16d3d</guid>
<title>Spring Boot 集成 JUnit 单元测试</title>
<link>https://toutiao.io/k/60g50xw</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;entry-content&quot;&gt;&amp;#13;

&lt;p&gt;为自己的应用编写单元测试是一个很好的习惯。在Java开发中最流行的测试工具非JUnit莫属，它已经成为Java单元测试的事实标准。Spring Boot测试模块不仅集成JUnit框架，还提供了许多实用程序和注解，方便我们测试应用。&lt;/p&gt;



&lt;span id=&quot;more-103&quot;/&gt;



&lt;h3 class=&quot;has-black-color has-text-color has-background&quot; id=&quot;1-添加依赖-spring-boot-starter-test&quot;&gt;&lt;strong&gt;1. 添加依赖&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;在 pom.xml 文件中引入 spring-boot-starter-test&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${version}&amp;lt;/version&amp;gt;
    &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;



&lt;p&gt;Spring Boot 2.2.x 开始集成的是JUnit 5。如果之前是使用的JUnit 4，可以使用JUnit 5中提供的老式引擎运行，需要添加 junit-vintage-engine 依赖。&lt;/p&gt;



&lt;p&gt;Spring Boot 2.2.x发布很久了，现在最新稳定版是2.4.x。旧的总要被替代，所以本篇只用JUnit 5，关于JUnit 4的文章相信网上很多，官方也有给出使用说明，请自行查找。&lt;/p&gt;



&lt;h3 class=&quot;has-black-color has-text-color has-background&quot; id=&quot;2-编写单元测试&quot;&gt;&lt;strong&gt;2. 编写单元测试&lt;/strong&gt;&lt;/h3&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;@SpringBootTest(classes = Application.class, webEnvironment = SpringBootTest.WebEnvironment.DEFINED_PORT)
public class JUnitTest {

    @Test
    public void test() {
        &lt;em&gt;// 测试代码&lt;/em&gt;
    }
}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 id=&quot;springboottest-重要参数&quot;&gt;@SpringBootTest 重要参数&lt;/h3&gt;



&lt;ul&gt;&lt;li&gt;&lt;strong&gt;args&lt;/strong&gt;&lt;br/&gt;应用程序参数，如:args = “–app.test=one”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;classes&lt;/strong&gt;&lt;br/&gt;Spring Boot应用启动入口类名，该参数不指定时由Spring Boot默认查找。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;webEnvironment&lt;/strong&gt;&lt;br/&gt;默认情况下@SpringBootTest不会启动服务器。当测试Web应用时，需指定该参数以便加载上下文环境。&lt;/li&gt;&lt;/ul&gt;



&lt;p&gt;WebEnvironment枚举值说明：&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;&lt;strong&gt;MOCK&lt;/strong&gt;&lt;br/&gt;默认值，加载WebApplicationContext并提供模拟Web环境。使用此注释时，不会启动嵌入式服务器。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;RANDOM_PORT&lt;/strong&gt;&lt;br/&gt;启动应用并随机监听一个端口。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;DEFINED_PORT&lt;/strong&gt;&lt;br/&gt;启动应用并监听自定义的端口(来自application.properties)或使用默认端口8080。&lt;/li&gt;&lt;li&gt;&lt;strong&gt;NONE&lt;/strong&gt;&lt;br/&gt;ApplicationContext通过使用加载，SpringApplication但不提供任何网络环境(模拟或其他方式)。&lt;/li&gt;&lt;/ul&gt;



&lt;h3 id=&quot;test&quot;&gt;@Test&lt;/h3&gt;



&lt;p&gt;注意 JUnit 5 的 @Test 注解在 org.junit.jupiter.api 包下。&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator&quot;/&gt;



&lt;p&gt;如果应用使用Spring MVC和 Spring WebFlux，则优先MVC。测试WebFlux应用必须设置：&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;@SpringBootTest(properties = &quot;spring.main.web-application-type=reactive&quot;)
public class MyWebFluxTests {

}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 class=&quot;has-black-color has-text-color has-background&quot; id=&quot;3-自动装配测试&quot;&gt;&lt;strong&gt;3. 自动装配测试&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;有时候我们只需要测试框架模块集成是否正常，不需要加载整个项目。可以使用 spring-boot-test-autoconfigure 模块中一些注解。整个框架被“切片”成独立的测试模块。&lt;/p&gt;



&lt;h3 id=&quot;json-测试&quot;&gt;JSON 测试&lt;/h3&gt;



&lt;p&gt;测试JSON序列化与反序列化。如果是GSON或JSONB，使用 @GsonTester 或 @JsonbTester 注解。&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;&lt;em&gt;/**
 * @author Engr-Z
 * @since 2021/1/18
 */&lt;/em&gt;
@JsonTest
public class MyJsonTest {

    @Autowired
    private JacksonTester&amp;lt;Map&amp;gt; json;

    @Test
    void testSerialize() throws Exception {
        Map&amp;lt;String, Object&amp;gt; map = new HashMap&amp;lt;&amp;gt;();
        map.put(&quot;name&quot;, &quot;攻城狮·正&quot;);
        map.put(&quot;websit&quot;, &quot;engr-z.com&quot;);
        
        Assertions.assertThat(this.json.write(map)).isEqualToJson(&quot;expected.json&quot;);
        Assertions.assertThat(this.json.write(map)).hasJsonPathStringValue(&quot;@.make&quot;);
        Assertions.assertThat(this.json.write(map)).extractingJsonPathStringValue(&quot;@.make&quot;)
                .isEqualTo(&quot;Honda&quot;);
    }

    @Test
    void testDeserialize() throws Exception {
        String content = &quot;{\&quot;name\&quot;:\&quot;攻城狮·正\&quot;,\&quot;website\&quot;:\&quot;engr-z.com\&quot;}&quot;;
        Assertions.assertThat(this.json.parse(content));
        Assertions.assertThat(this.json.parseObject(content).get(&quot;website&quot;)).isEqualTo(&quot;engr-z.com&quot;);
    }

}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 id=&quot;spring-mvc-测试&quot;&gt;Spring MVC 测试&lt;/h3&gt;



&lt;p&gt;测试 /demo/hello 接口是否正常&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;&lt;em&gt;/**
 * @author Engr-Z
 * @since 2021/1/18
 */&lt;/em&gt;
@WebMvcTest(DemoController.class)
public class SpringMVCTest {

    @Autowired
    private MockMvc mvc;

    @Test
    void test() throws Exception {
        RequestBuilder builder = MockMvcRequestBuilders.get(&quot;/demo/hello&quot;);
        ResultActions resultActions = mvc.perform(builder);
        int status = resultActions.andReturn().getResponse().getStatus();
        Assertions.assertEquals(200, status);
    }
}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 id=&quot;spring-webflux-测试&quot;&gt;Spring WebFlux 测试&lt;/h3&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;&lt;em&gt;/**
 * @author Engr-Z
 * @since 2021/1/18
 */&lt;/em&gt;
@WebFluxTest(DemoController.class)
public class SpringWebFluxTest {

    @Autowired
    private WebTestClient webClient;

    @Test
    void test() throws Exception {
        webClient.get().uri(&quot;/demo/webflux&quot;)
                .accept(MediaType.TEXT_PLAIN)
                .exchange()
                .expectStatus().isOk();
    }
}&lt;/code&gt;&lt;/pre&gt;



&lt;h3 id=&quot;jdbc-测试&quot;&gt;JDBC 测试&lt;/h3&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;@JdbcTest
@Transactional(propagation = Propagation.NOT_SUPPORTED)
class JdbcTransactionalTests {

}&lt;/code&gt;&lt;/pre&gt;



&lt;hr class=&quot;wp-block-separator&quot;/&gt;



&lt;p&gt;自动装配还支持 JPA，Redis，Rest Client 等模块测试。更多请参考：&lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-testing-spring-boot-applications-testing-autoconfigured-tests&quot;&gt;Auto-configured Tests&lt;/a&gt;&lt;/p&gt;



&lt;h3 class=&quot;has-black-color has-text-color has-background&quot; id=&quot;mockbean-和-spybean&quot;&gt;&lt;strong&gt;@MockBean 和 @SpyBean&lt;/strong&gt;&lt;/h3&gt;



&lt;p&gt;如果一个服务依赖于远程调用的结果。为了不影响我们做单元测试，可以使用&lt;code&gt;@MockBean&lt;/code&gt;。以下是官方代码示例：&lt;/p&gt;



&lt;pre class=&quot;wp-block-code&quot;&gt;&lt;code&gt;@SpringBootTest
class MyTests {

    @MockBean
    private RemoteService remoteService;

    @Autowired
    private Reverser reverser;

    @Test
    void exampleTest() {
        &lt;em&gt;// RemoteService has been injected into the reverser bean&lt;/em&gt;
        BDDMockito.given(this.remoteService.someCall()).willReturn(&quot;mock&quot;);
        String reverse = reverser.reverseSomeCall();
        Assertions.assertThat(reverse).isEqualTo(&quot;kcom&quot;);
    }

}&lt;/code&gt;&lt;/pre&gt;



&lt;p&gt;&lt;code&gt;@SpyBean&lt;/code&gt; 和 &lt;code&gt;@MockBean&lt;/code&gt; 不同之处是：对于未指定mock的方法，spy默认会调用真实的方法，有返回值的返回真实的返回值，而mock默认不执行，有返回值的，默认返回null&lt;/p&gt;



&lt;hr class=&quot;wp-block-separator&quot;/&gt;



&lt;p&gt;本篇只介绍 Spring Boot 集成 JUnit 单元测试，关于 JUnit 用法会在以后篇章详细讲解。&lt;/p&gt;
&lt;hr/&gt;&lt;/div&gt;&amp;#13;
&amp;#13;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>86e0fc7b19721b3a8418bcea74af8e97</guid>
<title>基于 Prometheus + Grafana 打造企业级 Flink 监控系统</title>
<link>https://toutiao.io/k/9zevvwo</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span&gt;点击上方&lt;/span&gt;&lt;strong&gt;&lt;span&gt;蓝色字体&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，选择“&lt;/span&gt;&lt;span&gt;&lt;strong&gt;设为星标&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;”&lt;/span&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-paragraph-type=&quot;ignored&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-paragraph-type=&quot;ignored&quot;&gt;&lt;p&gt;&lt;span&gt;回复”资源“获取更多资源&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;img data-type=&quot;jpeg&quot; data-ratio=&quot;0.0625&quot; data-w=&quot;640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/ow6przZuPIENb0m5iawutIf90N2Ub3dcPuP2KXHJvaR1Fv2FnicTuOy3KcHuIEJbd9lUyOibeXqW8tEhoJGL98qOw/640?wx_fmt=jpeg&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;在进入本文之前，我先问大家一个问题，你们公司或者业务系统上是如何对生产集群上的数据同步任务、实时计算任务或者是调度任务本身的执行情况和日志进行监控的呢？可能你会回答是自研或者ELK系统或者Zabbix系统。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;今天我们要介绍的主角可能会吊打上面的监控系统哦。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;随着容器技术的发展，Kubernetes 已然成为大家追捧的容器集群管理系统。Prometheus 作为生态圈 Cloud Native Computing Foundation（简称：CNCF）中的重要一员，其活跃度仅次于 Kubernetes，现已广泛用于 Kubernetes 集群的监控系统中。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在 Flink 任务的监控上，本文将简要介绍 Prometheus 体系中的组件如何使用，实例演示 Prometheus 的安装，配置及使用。并最终形成一套 Flink 任务监控的解决方案。&lt;/span&gt;&lt;/section&gt;&lt;h4&gt;Prometheus来龙去脉&lt;/h4&gt;&lt;section&gt;&lt;span&gt;Prometheus 是由前 Google 工程师从 2012 年开始在 Soundcloud 以开源软件的形式进行研发的系统监控和告警工具包，自此以后，许多公司和组织都采用了 Prometheus 作为监控告警工具。Prometheus 的开发者和用户社区非常活跃，它现在是一个独立的开源项目，可以独立于任何公司进行维护。为了证明这一点，Prometheus 于 2016 年 5 月加入 CNCF 基金会，成为继 Kubernetes 之后的第二个 CNCF 托管项目。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;最初，Prometheus 被用在微服务系统的监控上，微服务的落地一直都是业界重点关注的问题，其中除了部署难外，最大的问题就是集群监控、系统配置和系统治理等方面的带来的挑战。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2019 年 Flink 横空出世后，随之而来的运维、监控成为大家关注的重点。作为新一代的监控框架，就像网易在实践过程提出的一样，Prometheus 具有以下特点：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;灵活的数据模型：在Prometheus里，监控数据是由值、时间戳和标签表组成的，其中监控数据的源信息是完全记录在标签表里的；同时Prometheus支持在监控数据采集阶段对监控数据的标签表进行修改，这使其具备强大的扩展能力；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;强大的查询能力：Prometheus提供有数据查询语言PromQL。从表现上来看，PromQL提供了大量的数据计算函数，大部分情况下用户都可以直接通过PromQL从Prometheus里查询到需要的聚合数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;健全的生态: Prometheus能够直接对常见操作系统、中间件、数据库、硬件及编程语言进行监控；同时社区提供有Java/Golang/Ruby语言客户端SDK，用户能够快速实现自定义监控项及监控逻辑；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;良好的性能：在性能方面来看，Prometheus提供了PromBench基准测试，从最新测试结果来看，在硬件资源满足的情况下，Prometheus单实例在每秒采集10w条监控数据的情况下，在数据处理和查询方面依然有着不错的性能表现；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更契合的架构：采用推模型的监控系统，客户端需要负责在服务端上进行注册及监控数据推送；而在Prometheus采用的拉模型架构里，具体的数据拉取行为是完全由服务端来决定的。服务端是可以基于某种服务发现机制来自动发现监控对象，多个服务端之间能够通过集群机制来实现数据分片。推模型想要实现相同的功能，通常需要客户端进行配合，这在微服务架构里是比较困难的；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;成熟的社区：Prometheus是CNCF组织第二个毕业的开源项目，拥有活跃的社区；成立至今，社区已经发布了一百多个版本，项目在 GitHub 上获得的star数超过了3.8万。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1wZz13O7vSI0yx91kiaicoO6icic7I7pH3IRYnpiboovROiaYvZEq1uUiaby8vQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.15&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;可以这么说，Prometheus 天生为监控而生。&lt;/span&gt;&lt;/section&gt;&lt;h4&gt;Prometheus架构和组件&lt;/h4&gt;&lt;section&gt;&lt;span&gt;Prometheus 的整体架构以及生态系统组件如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1wsZKGhGWQhlb56icrOy9icIXfgDiajdibUFCkfS3oP06ib07zYwqqicoibqyyA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.6&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;Prometheus Server 直接从监控目标中或者间接通过推送网关来拉取监控指标，它在本地存储所有抓取到的样本数据，并对此数据执行一系列规则，以汇总和记录现有数据的新时间序列或生成告警。可以通过 Grafana 或者其他工具来实现监控数据的可视化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Prometheus 生态圈中包含了多个组件，Prometheus 的主要模块包括：Prometheus server, exporters, Pushgateway, PromQL, Alertmanager 以及图形界面。其中许多组件是可选的：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Prometheus Server: 用于收集和存储时间序列数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Client Library: 客户端库，为需要监控的服务生成相应的 metrics 并暴露给 Prometheus server。当 Prometheus server 来 pull 时，直接返回实时状态的 metrics。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短，可能在 Prometheus 来 pull 之前就消失了。为此，这次 jobs 可以直接向 Prometheus server 端推送它们的 metrics。这种方式主要用于服务层面的 metrics，对于机器层面的 metrices，需要使用 node exporter。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Exporters: 用于暴露已有的第三方服务的 metrics 给 Prometheus。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Alertmanager: 从 Prometheus server 端接收到 alerts 后，会进行去除重复数据，分组，并路由到对收的接受方式，发出报警。常见的接收方式有：电子邮件，pagerduty，OpsGenie, webhook 等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一些其他的工具。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;Prometheus 的工作流程如下：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Prometheus通过配置文件中指定的服务发现方式来确定要拉取监控指标的目标(Target)。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;接着从要拉取的目标(应用容器和Pushgateway)，发起HTTP请求到特定的端点(Metric Path)，将指标持久化至本身的TSDB中，TSDB最终会把内存中的时间序列压缩落到硬盘。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Prometheus会定期通过PromQL计算设置好的告警规则，决定是否生成告警到Alertmanager，后者接收到告警后会负责把通知发送到邮件或企业内部群聊中。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Prometheus的数据模型和核心概念&lt;/h4&gt;&lt;section&gt;&lt;span&gt;Prometheus 所有采集的监控数据均以指标（metric）的形式保存在内置的时间序列数据库当中（TSDB）：属于同一指标名称，同一标签集合的、有时间戳标记的数据流。除了存储的时间序列，Prometheus 还可以根据查询请求产生临时的、衍生的时间序列作为返回结果。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上面这段话是不是听起来十分拗口？我们用人话来解释一下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Prometheus 所采集到的数据被定义为【指标】。存储的数据为【时间序列】，所谓时间序列（或称动态数列）是指将同一统计指标的数值按其发生的时间先后顺序排列而成的数列。而存储的数据库为自带的时序数据库TSDB。&lt;/span&gt;&lt;/section&gt;&lt;h5&gt;&lt;span&gt;指标名称和标签&lt;/span&gt;&lt;/h5&gt;&lt;section&gt;&lt;span&gt;Prometheus 中每一条时间序列由指标名称（Metrics Name）以及一组标签（键值对）唯一标识。其中指标的名称（metric name）可以反映被监控样本的含义（例如，http_requests_total — 表示当前系统接收到的 HTTP 请求总量），指标名称只能由 ASCII 字符、数字、下划线以及冒号组成，同时必须匹配正则表达式 [a-zA-Z_:][a-zA-Z0-9_:]*。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;标签的名称只能由 ASCII 字符、数字以及下划线组成并满足正则表达式 [a-zA-Z_][a-zA-Z0-9_]*。其中以 _作为前缀的标签，是系统保留的关键字，只能在系统内部使用。标签的值则可以包含任何 Unicode 编码的字符。&lt;/span&gt;&lt;/section&gt;&lt;h5&gt;&lt;span&gt;样本&lt;/span&gt;&lt;/h5&gt;&lt;section&gt;&lt;span&gt;在时间序列中的每一个点称为一个样本（sample），样本由以下三部分组成：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;指标（metric）：指标名称和描述当前样本特征的 labelsets；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;时间戳（timestamp）：一个精确到毫秒的时间戳；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;样本值（value）：一个 folat64 的浮点型数据表示当前样本的值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h5&gt;&lt;span&gt;指标类型&lt;/span&gt;&lt;/h5&gt;&lt;section&gt;&lt;span&gt;Prometheus 的客户端库中提供了四种核心的指标类型。&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Counter：代表一种样本数据单调递增的指标，即只增不减，通常用来统计如服务的请求数，错误数等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Gauge：代表一种样本数据可以任意变化的指标，即可增可减，通常用来统计如服务的CPU使用值，内存占用值等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Histogram 和 Summary：用于表示一段时间内的数据采样和点分位图统计结果，通常用来统计请求耗时或响应大小等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;讲到这里，读者是不是有所顿悟？还记得 Flink 中的指标类型吗？Flink 也提供了四种类型的监控指标，分别是：Counter、Gauge、Histogram、Meter。&lt;/span&gt;&lt;/section&gt;&lt;h4&gt;Prometheus的安装&lt;/h4&gt;&lt;section&gt;&lt;span&gt;我们可以在官网下载Prometheus的安装包：https://prometheus.io/download/ 。这里我们同时安装Prometheus和Grafana，然后进行解压：&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section&gt;tar xvfz prometheus-*.tar.gz&lt;br/&gt;cd prometheus-*&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;启动：&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section&gt;$ cd prometheus/&lt;br/&gt;// 查看版本&lt;br/&gt;$ ./prometheus --version&lt;br/&gt;// 运行server&lt;br/&gt;$ ./prometheus --config.file=prometheus.yml&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;访问本地的http://localhost:9090/ 即可以看到Prometheus的graph页面。&lt;/span&gt;&lt;/section&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1wiaMkcnAvxmtSEAUvtPARqLHW9gaicpR43bzfnPYgYr1xA0OR74kVoqSQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.6865671641791045&quot; data-w=&quot;670&quot;/&gt;&lt;section&gt;&lt;span&gt;安装grafana&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section&gt;rpm -ivh grafana-6.5.2-1.x86_64.rpm&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;启动：&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section&gt;service grafana-server start&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;访问http://localhost:3000/ 可以看到grafana 界面。&lt;/span&gt;&lt;/section&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1wqEkNleQ8lFEgYm6YzKlbfjpWfSS2G3rTSergvVVHr4X8cGn4xKd5Ag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.4546296296296296&quot; data-w=&quot;1080&quot;/&gt;&lt;section&gt;&lt;span&gt;当然，Prometheus还有很多其他组件服务于不同的场景，例如pushgateway和nodeexporter。他们各自的作用可以在官网查看。我们暂时不做介绍。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这里假设我们要监控每一个服务器的状态，这时候我们就需要node_manager这个组件。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们也是直接安装启动：&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section&gt;$ tar xvfz node_exporter-xxx.tar.gz&lt;br/&gt;// 进入解压出的目录&lt;br/&gt;$ cd node_exporter-xxx&lt;br/&gt;// 运行监控采集服务&lt;br/&gt;$ ./node_exporter&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;将node_exporter添加到Prometheus服务器，我们请求一下本地的http://localhost:9090/ 可以看到当前机器的一些指标：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1wsMI3ejhBSxnwSlt9mibDnZPoP9vg9hHT1SYhcfmz2nAllwHCdlG2n0g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5675925925925925&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;总之，如果你要监控不同的目标，那么就需要安装Prometheus体系中不同的组件。关于详细的安装过程和配置过程我们不做过多展开，大家可以网上搜索有非常多的教程。&lt;/span&gt;&lt;/section&gt;&lt;h4&gt;Prometheus+Grafana+nodeManager+pushgateway打造企业级Flink平台监控系统&lt;/h4&gt;&lt;section&gt;&lt;span&gt;我们先来看一下整体的监控架构：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1w2mL0NSVf6Y7WBQtZMMDBhtfs03HxWYHa3iaib5so0hibcHiavnOFkRKJlg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;1.1161473087818696&quot; data-w=&quot;706&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;这里面有几个核心的组件：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;关于这四个组建的安装，我们不在仔细描述，大家可以参考网上的资源，我们重点讲述一下配置文件。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;首先，flink.yaml文件的配置：&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section&gt;metrics.reporter.promgateway.class: org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter&lt;br/&gt;metrics.reporter.promgateway.host: node1&lt;br/&gt;metrics.reporter.promgateway.port: 9091&lt;br/&gt;metrics.reporter.promgateway.jobName: flinkjobs&lt;br/&gt;metrics.reporter.promgateway.randomJobNameSuffix: false&lt;br/&gt;metrics.reporter.promgateway.deleteOnShutdown: true&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;prometheus.yml中的配置：&lt;/span&gt;&lt;/section&gt;&lt;pre&gt;&lt;section&gt;scrape_configs:&lt;br/&gt;  - job_name: &#x27;prometheus&#x27;&lt;br/&gt;    static_configs:&lt;br/&gt;      - targets: [&#x27;localhost:9090&#x27;]&lt;br/&gt;        labels:&lt;br/&gt;          instance: &#x27;prometheus&#x27;&lt;br/&gt;  - job_name: &#x27;linux&#x27;&lt;br/&gt;    static_configs:&lt;br/&gt;      - targets: [&#x27;localhost:9100&#x27;]&lt;br/&gt;        labels:&lt;br/&gt;          instance: &#x27;localhost&#x27;&lt;br/&gt;  - job_name: &#x27;pushgateway&#x27;&lt;br/&gt;    static_configs:&lt;br/&gt;      - targets: [&#x27;localhost:9091&#x27;]&lt;br/&gt;        labels:&lt;br/&gt;          instance: &#x27;pushgateway&#x27;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;然后我们把 Flink集群、nodeManager、pushGateway、Prometheus、Grafana分别启动起来。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;由于上面一句配置好Flink、 nodeManager、pushGateway，并且在Grafana中已经添加了prometheus 数据源，所以Grafana中会自动获取到 flink job的metrics 。我们进入 Grafana 首页，点击New dashboard，创建一个新的dashboard。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1wN3RC7iaA4u2ib8yD2a0icVT8ibP8qazgdAObx5zAuG6SXW1BShVGEWn80Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5990740740740741&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;选中之后，即会出现对应的监控指标&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-croporisrc=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1wHWfWaxXZnjibAvY1O1UFU76FKVR3nNCIibSP1RYfL4BJhDaPT4iboD3rg/640?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;1000.6451612903226&quot; data-cropy1=&quot;0&quot; data-cropy2=&quot;361.93548387096774&quot; data-ratio=&quot;0.361&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1wOJvsaEDk3sQ0e2dIH9ZA2SVT91EJOCkgq3kPpjyibNRZvjt0zia2kt4g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1000&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;对于 Flink 任务，我们需要监控的指标包括JobManager 服务器状态、Checkpoint情况、程序运行时长、Taskmanager内存，流量。甚至可以加上operator的进出流量用来定位反压问题。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1wHFhLP4z4UsoV5dWbcOFZLVWyVn03np3U3hdwKAe8V0GVRQc9jmm7yQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.4842592592592593&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h4&gt;业界典型应用&lt;/h4&gt;&lt;section&gt;&lt;span&gt;事实上Prometheus自从一出世，便受到了关注，我们用同程艺龙数据库监控系统的实践来看一下生产上是如何使用Prometheus的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;目前同程的整体监控架构设计如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1wy7VBUmeSnHALd1nEYX0DOfMpJFILyaKSgk0JxOhle4L2cprlWBzzOw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5601851851851852&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;其中几个关键的组件如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;Agent&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这是同程用 golang 开发的监控信息采集 agent，负责采集监控指标和实例日志。监控指标包括了该宿主机的相关信息(实例、容器)。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;Pushgateway&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;官方提供的组件，因为 Prometheus 是通过 pull 的方式获取数据的，如果让 Prometheus Server 去每个节点拉数据，那么监控服务的压力就会很大，我们是在监控几千个实例的情况下做到 10s 的采集间隔(当然采用联邦集群的模式也可以，但是这样就要需要部署 Prometheus Server。再加上告警相关的东西以后，整个架构会变的比较复杂。)。所以 agent 采取数据推送至 pushgateway，然后由 Prometheus Server 去 pushgateway 上面 pull 数据。这样在 Prometheus Server 在写入性能满足的情况下，单台机器就可以承载整个系统的监控数据。考虑到跨机房采集监控数据的问题，可以在每个机房都部署 pushgateway 节点，同时还能缓解单个 pushgateway 的压力。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;Prometheus Server&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Prometheus Server 去 pushgateway 上面拉数据的时间间隔设置为 10s。多个 pushgateway 的情况下，就配置多个组即可。为了确保 Prometheus Server 的高可用，可以再加一个 Prometheus Server 放到异地容灾机房，配置和前面的 Prometheus Server 一样。如果监控需要保留时间长的话，也可以配置一个采集间隔时间较大的 Prometheus Server，比如 5 分钟一次，数据保留 1 年。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;Alertmanager&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;使用 Alertmanager 前，需要先在 Prometheus Server 上面定义好告警规则。支持邮件、微信、webhook 多种类型，告警是通过 webhook 的方式，将触发的告警推送至指定 API，然后通过这个接口的服务进行二次加工。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;Grafana&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Prometheus 完美支持 Grafana，可以通过 PromQL 语法结合 Grafana，快速实现监控图的展示。为了和运维平台关联，通过 url 传参的方式，实现了运维平台直接打开指定集群和指定实例的监控图。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1wJichk95SyEUvsv4vbzcCLsjt23FY55QS2iatzibl8H09GtOp9usnyndKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.4861111111111111&quot; data-w=&quot;1080&quot;/&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2OayUkAYEZMQMOH3nV1Ot1wVamAURylabxXlxCllsfRe4bSibPEMXKibFZjsSYYSIFzmW719OeJu2icw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-ratio=&quot;0.5324074074074074&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;目前同程基于 Prometheus 的监控系统，承载了整个平台所有实例、宿主机、容器的监控。采集周期 10S，Prometheus 一分钟内每秒平均摄取样本数 9-10W。仅仅使用一台物理机(不包括高可用容灾资源)就可以承载当前的流量，并且还有很大的容量空间(CPU\Memory\Disk)。如果未来单机无法支撑的情况下，可以扩容成联邦集群模式。&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/BSBqCXrZtzAicMToibKuIysLrB62M5A5YaLhZg6z86tI7ZeEZqTLLYyNrmlzrkyKUN5kNeUFicVC3bMP1GEqKz1OQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.10979228486646884&quot; data-w=&quot;1011&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247491911&amp;amp;idx=1&amp;amp;sn=ba027a574fd1a531cb3bec943c949363&amp;amp;chksm=fd3ea7d2ca492ec49f636ab5162b7d9f09730cfa9e4b9ff03589ca9eb1cf564c899aaef79ab3&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;利用InfluxDB+Grafana搭建Flink on YARN作业监控大屏&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247490610&amp;amp;idx=1&amp;amp;sn=f435639d0392156082a997411bf42f6c&amp;amp;chksm=fd3d5aa7ca4ad3b1a239b8ac29f156ce7b6198cee7ec613e44dc27579b8bcf27fede954a2883&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;干掉ELK | 使用Prometheus+Grafana搭建监控平台&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MzgwNTU2Mg==&amp;amp;mid=2247488492&amp;amp;idx=1&amp;amp;sn=6059d4f245afad8230ee71a96e8a3d4e&amp;amp;chksm=fd3d5579ca4adc6f9b66549757ea8e3ac6bacdcdd17185ac87073f6fbbc88827d0b789606aa3&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;一篇文章全面了解监控知识体系&lt;/a&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;欢迎点赞+收藏+转发朋友圈素质三连&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.3897707231040564&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/UdK9ByfMT2MPL7m13Yrluz8WJicNiaVRsiaSxQRmWibSZ7tUBG7dphsEKmKTY0fMr4SvFSGrAMulFdr0TsvekC51Uw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1134&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;文章不错？&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;点个【&lt;/span&gt;&lt;span&gt;在看&lt;/span&gt;&lt;span&gt;】吧！&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>