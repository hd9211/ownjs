<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>23dc34fb3e873717715e479644f7325c</guid>
<title>阿里巴巴开源的，帮助你快速搭建本地和云端 IDE 的框架</title>
<link>https://toutiao.io/k/d51049l</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MzA0ODkyMA==&amp;amp;mid=2655078480&amp;amp;idx=2&amp;amp;sn=0e1f1297ea15bcd312f3fcfd37380149&amp;amp;chksm=bd2918678a5e917191830addbc44d575b07a2448d2b7db07311a4b7394e6b276b9bbfbc2fc95&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;‍‍&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;325&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AjN1jquNavicnodGjU9WYsic7gYCGWGVx28sXibCia11tG9g6AQCZ3XKlcO3FX3e4WB9Eic6uhs3nWDYtQNHQfqCbRQ/640?wx_fmt=png&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MzA0ODkyMA==&amp;amp;mid=2655078480&amp;amp;idx=2&amp;amp;sn=0e1f1297ea15bcd312f3fcfd37380149&amp;amp;chksm=bd2918678a5e917191830addbc44d575b07a2448d2b7db07311a4b7394e6b276b9bbfbc2fc95&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;拒绝焦虑，不妨从这份Newsletter开始！&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;拒绝焦虑，不妨从这份Newsletter开始！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一款帮助你快速搭建本地和云端 IDE 的框架，旨在解决阿里经济体内部 IDE 产品研发的重复建设问题，满足 IDE 在更多垂直场景的定制能力；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时实现 Web 与本地客户端共用底层，让 IDE 研发从早期的“刀耕火种”时代向“机器化大生产”时代迈进。&lt;br/&gt;官网地址：https://opensumi.com/zh&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;2.3493333333333335&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;750&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AjN1jquNav94kTiaIPic70szhhGGzvY9b8Yhxicn9gX1CmdUtECm5FTpSqfKmX9TMpXJAL75sjw6anibmVNibq8O2rA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e33e1a6f9e1a15645d4c6c33e408b97f</guid>
<title>腾讯二面：引入RabbitMQ后，你如何保证全链路数据100%不丢失 ？</title>
<link>https://toutiao.io/k/amngpn8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们都知道，消息从生产端到消费端消费要经过3个步骤：&lt;/span&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;生产端发送消息到RabbitMQ；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;RabbitMQ发送消息到消费端；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;消费端消费这条消息；&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.46880907372400754&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/19cc2hfD2rBpAmcg7EOYKR0pzvwzdRrJ6umALmmwAaxkX6kOeFzOny9WfFT9BjydBT4VCXL9v5vmtiaUYhlsFSg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;529&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这3个步骤中的每一步都有可能导致消息丢失，消息丢失不可怕，可怕的是丢失了我们还不知道，所以要有一些措施来保证系统的可靠性。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这里的可靠并不是一定就100%不丢失了，磁盘损坏，机房爆炸等等都能导致数据丢失，当然这种都是极小概率发生，能做到99.999999%消息不丢失，就是可靠的了。下面来具体分析一下问题以及解决方案。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;生产端可靠性投递&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;生产端可靠性投递，即生产端要确保将消息正确投递到RabbitMQ中。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;生产端投递的消息丢失的原因有很多，比如消息在网络传输的过程中发生网络故障消息丢失，或者消息投递到RabbitMQ时RabbitMQ挂了，那消息也可能丢失，而我们根本不知道发生了什么。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;针对以上情况，RabbitMQ本身提供了一些机制。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;事务消息机制&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;事务消息机制由于会严重降低性能，所以一般不采用这种方法，我就不介绍了，而采用另一种轻量级的解决方案：confirm消息确认机制。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;confirm消息确认机制&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;什么是confirm消息确认机制？顾名思义，就是生产端投递的消息一旦投递到RabbitMQ后，RabbitMQ就会发送一个确认消息给生产端，让生产端知道我已经收到消息了，否则这条消息就可能已经丢失了，需要生产端重新发送消息了。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6330472103004292&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/19cc2hfD2rBpAmcg7EOYKR0pzvwzdRrJmeibuMA4fbqU95CrBahibxCh596rocsnEibbibchic3bjm3NBUyIprGoBIQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;466&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;通过下面这句代码来开启确认模式：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;channel.confirmSelect();&lt;span&gt;// 开启发送方确认模式&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;然后异步监听确认和未确认的消息：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;channel.addConfirmListener(&lt;span&gt;new&lt;/span&gt; ConfirmListener() {&lt;br/&gt;    &lt;span&gt;//消息正确到达broker&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;handleAck&lt;/span&gt;&lt;span&gt;(&lt;span&gt;long&lt;/span&gt; deliveryTag, &lt;span&gt;boolean&lt;/span&gt; multiple)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; IOException &lt;/span&gt;{&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;已收到消息&quot;&lt;/span&gt;);&lt;br/&gt;        &lt;span&gt;//做一些其他处理&lt;/span&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;//RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;@Override&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;handleNack&lt;/span&gt;&lt;span&gt;(&lt;span&gt;long&lt;/span&gt; deliveryTag, &lt;span&gt;boolean&lt;/span&gt; multiple)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; IOException &lt;/span&gt;{&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;未确认消息，标识：&quot;&lt;/span&gt; + deliveryTag);&lt;br/&gt;        &lt;span&gt;//做一些其他处理，比如消息重发等&lt;/span&gt;&lt;br/&gt;    }&lt;br/&gt;});&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这样就可以让生产端感知到消息是否投递到RabbitMQ中了，当然这样还不够，稍后我会说一下极端情况。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;消息持久化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;那消息持久化呢？我们知道，RabbitMQ收到消息后将这个消息暂时存在了内存中，那这就会有个问题，如果RabbitMQ挂了，那重启后数据就丢失了，所以相关的数据应该持久化到硬盘中，这样就算RabbitMQ重启后也可以到硬盘中取数据恢复。那如何持久化呢？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;message消息到达RabbitMQ后先是到exchange交换机中，然后路由给queue队列，最后发送给消费端。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4131386861313869&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/19cc2hfD2rBpAmcg7EOYKR0pzvwzdRrJelfGUFkicg6Bfia9Z0ErSlngGMicuMNqxILnLM9ojrcpaJCTg0Uss3L0g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;685&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;所有需要给exchange、queue和message都进行持久化：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;exchange持久化：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;//第三个参数true表示这个exchange持久化&lt;/span&gt;&lt;br/&gt;channel.exchangeDeclare(EXCHANGE_NAME, &lt;span&gt;&quot;direct&quot;&lt;/span&gt;, &lt;span&gt;true&lt;/span&gt;);&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;queue持久化：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;//第二个参数true表示这个queue持久化&lt;/span&gt;&lt;br/&gt;channel.queueDeclare(QUEUE_NAME, &lt;span&gt;true&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;false&lt;/span&gt;, &lt;span&gt;null&lt;/span&gt;);&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;message持久化：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;//第三个参数MessageProperties.PERSISTENT_TEXT_PLAIN表示这条消息持久化&lt;/span&gt;&lt;br/&gt;channel.basicPublish(EXCHANGE_NAME, ROUTING_KEY, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes(StandardCharsets.UTF_8));&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这样，如果RabbitMQ收到消息后挂了，重启后会自行恢复消息。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;到此，RabbitMQ提供的几种机制都介绍完了，但这样还不足以保证消息可靠性投递RabbitMQ中，上面我也提到了会有极端情况，比如RabbitMQ收到消息还没来得及将消息持久化到硬盘时，RabbitMQ挂了，这样消息还是丢失了，或者RabbitMQ在发送确认消息给生产端的过程中，由于网络故障而导致生产端没有收到确认消息，这样生产端就不知道RabbitMQ到底有没有收到消息，就不好做接下来的处理。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.47007042253521125&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/19cc2hfD2rBpAmcg7EOYKR0pzvwzdRrJ4g4iaG3oBllNLY2mGjyBJTwXQLiaC0QgJQ2XR406neic3VKYo57pBhCRQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;568&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;所以除了RabbitMQ提供的一些机制外，我们自己也要做一些消息补偿机制，以应对一些极端情况。接下来我就介绍其中的一种解决方案——消息入库。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;消息入库&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;消息入库，顾名思义就是将要发送的消息保存到数据库中。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;首先发送消息前先将消息保存到数据库中，有一个状态字段&lt;/span&gt;&lt;code&gt;&lt;span&gt;status=0&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，表示生产端将消息发送给了RabbitMQ但还没收到确认。在生产端收到确认后将status设为1，表示RabbitMQ已收到消息。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这里有可能会出现上面说的两种情况，所以生产端这边开一个定时器，定时检索消息表，将status=0并且超过固定时间后（可能消息刚发出去还没来得及确认这边定时器刚好检索到这条status=0的消息，所以给个时间）还没收到确认的消息取出重发（第二种情况下这里会造成消息重复，消费者端要做幂等性），可能重发还会失败，所以可以做一个最大重发次数，超过就做另外的处理。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5558343789209536&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/19cc2hfD2rBpAmcg7EOYKR0pzvwzdRrJ5kPpNphkQj2cOQass91fm5VBqdUbE8JvXv5zWibBnhlqEojTNmibxwWA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;797&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这样消息就可以可靠性投递到RabbitMQ中了，而生产端也可以感知到了。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;消费端消息不丢失&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;既然已经可以让生产端100%可靠性投递到RabbitMQ了，那接下来就改看看消费端的了，如何让消费端不丢失消息。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;默认情况下，以下3种情况会导致消息丢失：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在RabbitMQ将消息发出后，消费端还没接收到消息之前，发生网络故障，消费端与RabbitMQ断开连接，此时消息会丢失；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在RabbitMQ将消息发出后，消费端还没接收到消息之前，消费端挂了，此时消息会丢失；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;消费端正确接收到消息，但在处理消息的过程中发生异常或宕机了，消息也会丢失。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4109985528219971&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/19cc2hfD2rBpAmcg7EOYKR0pzvwzdRrJnInRhSgYqY3R6Y5G44dWTAb99zO4dmRh3KyxGPrPR1EqenvicOsRfmg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;691&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;其实，上述3中情况导致消息丢失归根结底是因为RabbitMQ的自动ack机制，即默认RabbitMQ在消息发出后就立即将这条消息删除，而不管消费端是否接收到，是否处理完，导致消费端消息丢失时RabbitMQ自己又没有这条消息了。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6323232323232323&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/19cc2hfD2rBpAmcg7EOYKR0pzvwzdRrJdxQkRwXuTM2jU3vlojQNtUuYoD7f0DxWZbjUW7Pxa8EicPSvZnggiaFw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;495&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;所以就需要将自动ack机制改为手动ack机制。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;消费端手动确认消息：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;DeliverCallback deliverCallback = (consumerTag, delivery) -&amp;gt; {&lt;br/&gt;    &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;        &lt;span&gt;//接收到消息，做处理&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;//手动确认&lt;/span&gt;&lt;br/&gt;        channel.basicAck(delivery.getEnvelope().getDeliveryTag(), &lt;span&gt;false&lt;/span&gt;);&lt;br/&gt;    } &lt;span&gt;catch&lt;/span&gt; (Exception e) {&lt;br/&gt;        &lt;span&gt;//出错处理，这里可以让消息重回队列重新发送或直接丢弃消息&lt;/span&gt;&lt;br/&gt;    }&lt;br/&gt;};&lt;br/&gt;&lt;span&gt;//第二个参数autoAck设为false表示关闭自动确认机制，需手动确认&lt;/span&gt;&lt;br/&gt;channel.basicConsume(QUEUE_NAME, &lt;span&gt;false&lt;/span&gt;, deliverCallback, consumerTag -&amp;gt; {});&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这样，当autoAck参数置为false，对于RabbitMQ服务端而言，队列中的消息分成了两个部分：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;一部分是等待投递给消费端的消息；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;一部分是已经投递给消费端，但是还没有收到消费端确认信号的消息。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果RabbitMQ一直没有收到消费端的确认信号，并且消费此消息的消费端已经断开连接或宕机（RabbitMQ会自己感知到），则RabbitMQ会安排该消息重新进入队列（放在队列头部），等待投递给下一个消费者，当然也有能还是原来的那个消费端，当然消费端也需要确保幂等性。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;好了，到此从生产端到RabbitMQ再到消费端的全链路，就可以保证数据的不丢失。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;原文：&lt;/span&gt;&lt;/span&gt;&lt;span&gt;blog.csdn.ne&lt;/span&gt;&lt;span&gt;t/hsz2568952354/article/details/86559470&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;pre&gt;&lt;pre&gt;&lt;section data-mpa-template=&quot;t&quot;&gt;&lt;section data-mpa-template=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.037096774193548385&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/b96CibCt70iabxGraSfbk6yTjATjwMNXW8ibsPbATicsud3NfaS24FNreYJxJ77DPw6ibbMopSJcW3ys8Ga6HrSkAIA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;620&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/pre&gt;&lt;pre data-darkmode-bgcolor-15923650965579=&quot;rgb(36, 36, 36)&quot; data-darkmode-original-bgcolor-15923650965579=&quot;rgb(255, 255, 255)&quot; data-darkmode-color-15923650965579=&quot;rgb(167, 167, 167)&quot; data-darkmode-original-color-15923650965579=&quot;rgb(63, 63, 63)&quot; data-style=&quot;letter-spacing: 0.544px; font-size: 16px; color: rgb(63, 63, 63); word-spacing: 1px; line-height: inherit;&quot; class=&quot;js_darkmode__91&quot;&gt;&lt;pre&gt;&lt;section&gt;&lt;span&gt;2022年粉丝福利 &lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;http://download.java1234.com/&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;每月送 &lt;span&gt;666 &lt;/span&gt;套Java海量资源网站 &lt;span&gt;VIP会员&lt;/span&gt;，供大伙一起学Java&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果没过锋哥微信的&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;加一下锋哥微信备注 &lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;VIP &lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;即可开通&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;230&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;230&quot; data-fileid=&quot;100045181&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/UkT70O7175OeI5YGI4W3DSwdhV9sWe15wib5F3ibiaaJXibYriarqrFIIJ5dOg1x7RR1PrAoQRZ4LY71Cpp0SRKCUSQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;430&quot;/&gt;&lt;/p&gt;&lt;/pre&gt;&lt;pre&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;点个&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;在看 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;喜欢是一种感觉&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在看是一种支持&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;↘&lt;/span&gt;↘↘&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;/section&gt;
          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>71d0c6e6497f26bc37436fa8940c0953</guid>
<title>Koa在实际的业务场景中，路由如何做分割？【文末留言送书】</title>
<link>https://toutiao.io/k/76glzpy</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span&gt;大家好，我是&lt;/span&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5MjQwMzQyNw==&amp;amp;mid=2650757158&amp;amp;idx=1&amp;amp;sn=1f1cad678916031fb0e77eefcfa1dddc&amp;amp;chksm=88665baabf11d2bc7dce837e90cbe0b755d4e082362363e1ebc8912a77367b79ba59ea43a32e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;若川&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;若川&lt;/a&gt;&lt;/span&gt;&lt;span&gt;。文末留言送书，具体规则文末说明。另外为了鼓励大家多写&lt;/span&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5MjQwMzQyNw==&amp;amp;mid=2650761981&amp;amp;idx=2&amp;amp;sn=59881daa5d9e29130c81ab696849af84&amp;amp;chksm=88666971bf11e06798113e1420ed019e38460b9d6c4e6d9424163174df08f3b3f546c7f6d971&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;源码共读&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;源码共读&lt;/a&gt;&lt;/span&gt;&lt;span&gt;笔记，我会在写了5次及以上笔记的作者群里也抽奖送这本书。以后也会有更多福利倾斜。&lt;/span&gt;&lt;/p&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;95693&quot;&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.7&quot; data-type=&quot;png&quot; data-w=&quot;40&quot; data-width=&quot;100%&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9fRTdvQaGDIMXYuukwCBib8cWqvLFOkicSyraL7xXh0lgwSO3GCGibcLtoL7e6IEOUhT6eEcQUpGRa8zOGjTou4Jg/640?wx_fmt=png&quot;/&gt;&lt;/section&gt;&lt;section data-autoskip=&quot;1&quot;&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;导读：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Koa是一个Node框架，在Node开源社区中，Koa的使用范围非常广，掌握Koa的使用方法，就能轻松应对业界的一些BFF框架&lt;span&gt;。本文介绍Koa在实际的业务场景中，路由如何做分割。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.06387225548902195&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9fRTdvQaGDIMXYuukwCBib8cWqvLFOkicSKJwy0P0ostywNAjmzic3brtPsqkDASnOQkmZ1afaZCNZV4KdZHh5N5Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;501&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;‍&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;作者：刘江虹&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;来源：华章计算机（hzbook_jsj）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在实际的复杂业务场景中，简单的路由堆砌会使得路由文件越来越大，随着后续的项目不断迭代，开发人员的不断更替，如果所有的路由都写在一个文件里，会使得路由模块变得越来越难维护。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;那么，Koa的项目要如何去解决路由难维护的问题呢？对于这个问题，由抖音电商前端架构师撰写的&lt;strong&gt;《Koa开发：入门、进阶与实战》&lt;/strong&gt;给出了很好的解决方案，下面让我们结合这本书的内容来详细看一看Koa中路由的使用技巧。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在介绍路由分割以及文件路由之前，我们回忆一下koa-router这个中间件的使用。假如需要两个路由，一个是获取货物信息，一个是获取用户信息，那用koa-router实现的代码应该是这样的：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;typescript&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const Koa = require(&#x27;koa&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const app = new Koa()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const Router = require(&#x27;koa-router&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const router = new Router()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; router.get(&#x27;/goods/getInfo&#x27;, async ( ctx ) =&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   ctx.body = &#x27;this is koa book.&#x27;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; })&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; router.get(&#x27;/user/getInfo&#x27;, async ( ctx ) =&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   ctx.body = &#x27;my name is liujianghong.&#x27;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; })&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; app.use(router.routes())&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; app.listen(4000, () =&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   console.log(&#x27;server is running, port is 4000&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; })&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;这样的写法相信读者应该已经掌握了，但这样写其实有个弊端，如果在一个实际的项目中，Node.js层的接口可能会很多，所有的路由都放在一个文件里，最终会变得越来越难维护，那实战中我们应该如何维护好路由的编写呢？本节将阐述两种方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;1、路由分割&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所谓路由分割，就是把所有路由按照类别划分，分别维护在不同的文件里。在实际的项目中，通常情况下，一个项目是由多人开发维护的，比如张三只维护货物相关的路由，李四只维护用户相关的路由，如果让两人在一个文件里维护，那随着项目越来越大，接口越来越多，难免会出现不好维护的情况。所以，路由分割就一定程度上解决了这样的问题，让路由易迭代、易维护。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文提到的实例中有两个类型的路由，一个是货物的，一个是用户的，那么接下来，我们就对这两类路由进行分割。首先，按照类型可以把不同的路由写在不同的文件里，货物的路由文件代码如下：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;typescript&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; // routers/goods.js&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const Router = require(&#x27;koa-router&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const router = new Router()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; // 设置路由前缀&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; router.prefix(&#x27;/goods&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; router.get(&#x27;/getInfo&#x27;, (ctx, next)=&amp;gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     ctx.body = &quot;this is koa book.&quot;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; })&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; module.exports = router&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;用户的路由文件代码如下：&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;typescript&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; // routers/user.js&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const Router = require(&#x27;koa-router&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const router = new Router()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; router.prefix(&#x27;/user&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; router.get(&#x27;/getInfo&#x27;, (ctx, next)=&amp;gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     ctx.body = &quot;my name is liujianghong.&quot;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; })&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; module.exports = router&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;每个路由文件里面都使用了一个路由前缀的设置，这样方便分类。每个文件封装了不同类型的路由，接下来要做的就是把这些路由进行整合。Koa源码中有一个非常重要的实现是中间件的合并，其中就使用了koa-compose包，读者可以返回&lt;strong&gt;《Koa开发：入门、进阶与实战》&lt;/strong&gt;一书的第3章复习一下。路由的合并也会用到koa-compose来进行实现，代码如下：&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;javascript&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;// routers/index.js&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const compose = require(&#x27;koa-compose&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const glob = require(&#x27;glob&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const { resolve } = require(&#x27;path&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; registerRouter = () =&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     let routers = [];&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     // 递归式获取当前文件夹下所有的js文件&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     glob.sync(resolve(__dirname, &#x27;./&#x27;, &#x27;**/*.js&#x27;))&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;         // 排除index.js文件，因为这个文件不是具体的路由文件&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;         .filter(value =&amp;gt; (value.indexOf(&#x27;index.js&#x27;) === -1))&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;         .forEach(router =&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;             routers.push(require(router).routes())&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;             routers.push(require(router).allowedMethods())&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;         })&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     return compose(routers)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; module.exports = registerRouter&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这里可以使用koa-compose来对koa-router进行整合，是因为koa-router里面的routers方法和allowedMethods方法和我们平时用的中间件里面的回调是一样的，读者如果感兴趣的话，可以看一下koa-router的源码。最后实现一个简单的server，即把整合后的路由引进来，代码如下：&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;typescript&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;// app.js&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const Koa = require(&#x27;koa&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const registerRouter  = require(&#x27;./routers&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const app = new Koa()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; app.use(registerRouter())&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; app.listen(4000, () =&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   console.log(&#x27;server is running, port is 4000&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; })&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;运行app.js，我们在浏览器访问http://127.0.0.1:4000/goods/getInfo，效果如图1所示。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;317&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5494830132939439&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9fRTdvQaGDKcRz8BJPLBv6qcicoGOvAGj7E68wwa6kT13HpQoycvrwJQdFYicslTrdh847v9P2Bmu9EjVGmBktpw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;677&quot;/&gt;&lt;span&gt; &lt;span&gt;图&lt;/span&gt;1 &lt;span&gt;访问货物路由运行结果&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;访问http://127.0.0.1:4000/user/getInfo，效果如图2所示。 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;318&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5501474926253688&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9fRTdvQaGDKcRz8BJPLBv6qcicoGOvAGjPHh0Ed586z3ibr0NkbSh2bBiaqkvr7b5RvGxeXVGX1Iaiccq6a9a8A8PA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;678&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图&lt;/span&gt;&lt;span&gt;2 &lt;/span&gt;&lt;span&gt;访问用户路由运行结果&lt;/span&gt;&lt;/section&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;2、文件路由&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据文件路径来匹配路由，也是实际的项目可能采取的一种方式，我们先了解一下什么是文件路由，比如，现在有这样一个项目，组织结构如图3所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;233&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4023494860499266&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9fRTdvQaGDKcRz8BJPLBv6qcicoGOvAGjWxuGdPJUZTTGrFdQ3xEIichS4W2dWrb0L9fBl3WOCAxgiaqvomzVG3oQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;681&quot;/&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;图&lt;/span&gt;&lt;span&gt;3 &lt;/span&gt;&lt;span&gt;文件路由的项目结构&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;actions目录下的内容就是匹配路由的，比如前端有一个GET请求http://127.0.0.1:4000/goods/getInfo，那么最终会匹配到actions目录下goods/getInfo.js文件，最终会执行getInfo.js里面的逻辑。这么设计有以下几点优势：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;● 依据项目中文件目录就能了解本项目都有哪些路由，不用查看路由文件，非常方便。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;● 用文件路径来组织路由，对用户非常友好，便于开发。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接下来我们详细分析这种文件路由该如何实现。总共有两个步骤：第一步，定义goods/getInfo.js和user/getInfo.js两个文件内容，主要是定义一些属性，包括请求的方法类型（GET、POST等）、执行的回调；第二步，把请求的path映射到对应的文件路径上，当请求过来后，能够执行对应的文件内容。接下来看代码如何实现。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;1）定义两个文件内容&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;actions/goods/getInfo.js文件的定义代码如下：&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;javascript&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; // actions/goods/getInfo.js&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; module.exports = {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   method: &#x27;GET&#x27;,  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   handler: (ctx) =&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     ctx.body = &quot;this is koa book.&quot;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   }    &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; }&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;actions/user/getInfo.js文件的定义代码如下：&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;javascript&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;两个文件都定义了两个属性，一个是method，一个是handler。method指的是请求的类型，这里method的配置主要是为了映射到唯一请求，比如请求路径都是/goods/getInfo，那方法类型既可以是GET请求，也可以POST请求，两个请求是不一样的。hander方法就是一个回调方法，用来处理相应的业务逻辑。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2）请求的path映射到对应的文件&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;首先请求的path可通过context对象来获取，比较方便，主要问题是文件路径如何处理。其实我们可以通过glob这个包来获取所有的文件，然后对路径再做相应的处理即可，代码如下：&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;typescript&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const glob = require(&#x27;glob&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const path = require(&#x27;path&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const Koa = require(&#x27;koa&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const app = new Koa()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; // actions的绝对路径&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const basePath = path.resolve(__dirname, &#x27;./actions&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; // 获取actions目录下所有的js文件，并返回其绝对路径&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; const filesList = glob.sync(path.resolve(__dirname, &#x27;./actions&#x27;, &#x27;**/*.js&#x27;))&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; // 文件路由映射表&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; let routerMap = {}&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; filesList.forEach(item =&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   // 解构的方式获取，当前文件导出对象中的method属性和handler属性&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   const { method, handler } = require(item)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   // 获取和actions目录的相对路径，例如：goods/getInfo.js&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   const relative = path.relative(basePath, item)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   // 获取文件后缀.js&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   const extname = path.extname(item)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   // 剔除后缀.js,并在前面加一个&quot;/&quot;,例如：/goods/getInfo&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   const fileRouter = &#x27;/&#x27; + relative.split(extname)[0]&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   // 连接method，形成一个唯一请求，例如: _GET_/goods/getInfo&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   const key = &#x27;_&#x27; + method + &#x27;_&#x27; + fileRouter&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   // 保存在路由表里&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   routerMap[key] = handler&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; })&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; app.use(async (ctx, next) =&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   const { path, method } = ctx&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   // 构建和文件路由匹配的形式：_GET_路由&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   const key = &#x27;_&#x27; + method + &#x27;_&#x27; + path&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   // 如果匹配到，就执行对应到handler&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   if (routerMap[key]) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     routerMap[key](ctx)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   } else {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     ctx.body = &#x27;no this router&#x27;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; })&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; app.listen(4000, () =&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;   console.log(&#x27;server is running, port is 4000&#x27;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt; })&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;文件路由书写起来比较优雅，并且可以做到高度可配置，这样对每个请求可以实行个性化定制，我们在Koa实战中也会使用这种方式来做路由，到时候详细讲述企业级别的BFF架构中文件路由该如何设计。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;无论是通过中间件的路由分割还是通过文件的路由分割，都在一定程度上能够优化路由的组织方式，方便后续的需求迭代。如果您想要了解更多有关Koa的高级应用，如用户鉴权机制、数据存储、进程管理等，推荐您详细阅读刘江虹老师的新作&lt;strong&gt;《Koa开发：入门、进阶与实战》。&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_iframe&quot; data-pluginname=&quot;videosnap&quot; data-id=&quot;export/UzFfAgtgekIEAQAAAAAAC2QoikRa-gAAAAstQy6ubaLX4KHWvLEZgBPExKM4ElRJKqP8zNPgMIuiUKGe0tb4eDzb0-QWx6lB&quot; data-url=&quot;https://findermp.video.qq.com/251/20304/stodownload?encfilekey=rjD5jyTuFrIpZ2ibE8T7YmwgiahniaXswqzGWFZL9zd3vRnZkSYWT5QFFqLPtBzhtYExhyJBK9qS5Q4ZgP9KyeVyNxRdfaPAibs5gAtzs99xA5IdS71q8q5Fibg&amp;amp;adaptivelytrans=0&amp;amp;bizid=1023&amp;amp;dotrans=0&amp;amp;hy=SH&amp;amp;idx=1&amp;amp;m=&amp;amp;scene=0&amp;amp;token=x5Y29zUxcibDPqlbFdq7Uv62Co3NZGiaCC4f5OiaC3ER0qayLKtgheBibBbzPvOB7bKuic7Xl4KdqUZQ&quot; data-headimgurl=&quot;http://wx.qlogo.cn/finderhead/wLYvKbshCBkgChhlYMguCaW7IVClDib5pOaLPQ5VklW4/0&quot; data-username=&quot;v2_060000231003b20faec8c5e1891ec3d4cc06ed37b0778b2294321e59f859f1803ad4991bd141@finder&quot; data-nickname=&quot;华章计算机&quot; data-desc=&quot;&amp;#10;抖音电商前端架构师 刘江虹 带你轻松入门 #Koa开发&quot; data-nonceid=&quot;4784423201733813198&quot; data-type=&quot;video&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt; &lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;作者介绍：&lt;/span&gt;&lt;span&gt;刘&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;江虹，字&lt;/span&gt;&lt;span&gt;节跳动抖音电商前端架构师，目前主要负责业务架构中工程化等相关方向，拥有多年前端架构工作经验。&lt;/span&gt;&lt;span&gt;独立开发过一款可对标&lt;/span&gt;&lt;span&gt;Egg&lt;/span&gt;&lt;span&gt;的&lt;/span&gt;&lt;span&gt;BFF&lt;/span&gt;&lt;span&gt;企业级框架，支撑公司线上服务超&lt;/span&gt;&lt;span&gt;1000&lt;/span&gt;&lt;span&gt;个，全栈前端技术专家，具有丰富的&lt;/span&gt;&lt;span&gt;Node&lt;/span&gt;&lt;span&gt;实战经验。&lt;/span&gt;&lt;span&gt;著有畅销书《&lt;/span&gt;&lt;span&gt;React.js实战》。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.8613333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/9fRTdvQaGDKcRz8BJPLBv6qcicoGOvAGjXpBYUlibOoflibE9LcG0IxRHiafVLqNKLFBHKSoUM3Y6oSfob4dwohCGg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;‍&lt;/span&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;抽奖规则：在留言区留言&lt;strong&gt;为什么想要这本书&lt;/strong&gt;，随机抽取「2位&lt;span&gt;」&lt;/span&gt;&lt;strong&gt;理由充分&lt;/strong&gt; &lt;strong&gt;&amp;amp;&amp;amp; 关注比较久 &amp;amp;&amp;amp; 留言互动相对多的小伙伴&lt;/strong&gt;。包邮送出本书。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;另外为了鼓励大家多写源码共读笔记，我会在写了5次及以上&lt;strong&gt;笔记&lt;/strong&gt;的作者群里也抽奖送这本书。以后也会有更多福利倾斜。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;开奖时间4月18日（周一）晚8点。中奖者在开奖后1天内与我取得联系，否则视为放弃。我会在微信留言区回复中奖人。&lt;/p&gt;&lt;p&gt;&lt;span&gt;中奖者开奖前必须是我的微信好友，且需是前端。羊毛党绕路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总之最终解释权归我。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;记得扫码加我微信 ruochuan12 ， 参加&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzA5MjQwMzQyNw==&amp;amp;mid=2650761981&amp;amp;idx=2&amp;amp;sn=59881daa5d9e29130c81ab696849af84&amp;amp;chksm=88666971bf11e06798113e1420ed019e38460b9d6c4e6d9424163174df08f3b3f546c7f6d971&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;源码共读&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;源码共读&lt;/a&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;503274950&quot; data-ratio=&quot;1.013210039630119&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/Mpt86EGjlpsufP8ibpYqicTCtU9OoPZlRYp0UI2nh9DSQvGeblm59Imic1uHJgomic9mrBrJ6GjNzbQM83ogP338yg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;757&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-id=&quot;90215&quot; data-tools=&quot;135编辑器&quot;&gt;&lt;section&gt;&lt;section data-id=&quot;90215&quot; data-tools=&quot;135编辑器&quot;&gt;&lt;section&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;paragraph&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;98891&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;img data-ratio=&quot;1&quot; data-type=&quot;gif&quot; data-w=&quot;300&quot; class=&quot;__bg_gif&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/qrlXAFW0OmHC5pSecpc1GsbSBEb9qToOs2OltarxXF2bzL6DOIfewe5QhD9iaBshnMlSKSXdicfRQDfS6dZ5O44A/640?wx_fmt=gif&quot;/&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;点击&lt;/span&gt;&lt;span&gt;&lt;strong&gt;阅读全文&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;购买&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8d2eb9e82fb2d35f8507216647dd9299</guid>
<title>别再说你不懂规则引擎了！</title>
<link>https://toutiao.io/k/edts5o5</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;p&gt;&lt;/p&gt;&lt;h1&gt;背景&lt;/h1&gt;&lt;p&gt;一提到规则引擎这四个字，大家肯定多多少少在工作中或者各种文章里面都有过听说，但是很多同学往往被引擎这两个字吓到了，以为这是什么黑科技。时值最近在调研规则引擎，在这里给大家介绍一下什么是规则引擎。&lt;/p&gt;&lt;h1&gt;为什么需要规则引擎&lt;/h1&gt;&lt;p&gt;规则引擎带来的好处是比较多的，这里我们从不同的角度去剖析一下。&lt;/p&gt;&lt;h2&gt;从开发人员视角来看&lt;/h2&gt;&lt;p&gt;在没有规则引擎的时代，有些逻辑比较复杂的业务，只有不断的增添if-else去满足我们这个复杂的业务场景，对于开发者来说还好，对于后面接手的同学一看到处都是if-else，体验过的同学就会知道，当然if-else可以通过一些模式去优化，比如使用策略模式，或者使用一些注解进行扩展点优化，这样的确可以解决一部分代码不清晰的问题，但是依然无法解决开发缓慢，需要上线等问题。举个例子，在风控系统中，因为风控的逻辑在不断的发生一个改变，如果我们在代码中去写死，那么发生一个改变就改一下代码，上一下线，这明显是我们不能接受的。所以我们需要规则引擎去改变这个现状，通过高效可靠的方式去做这些业务规则的改变。&lt;/p&gt;&lt;h2&gt;从业务人员视角来看&lt;/h2&gt;&lt;p&gt;以前的开发模式是业务人员提出业务规则叫开发人员做出相对应的业务开发，到底这个最后开发出来的业务规则是否和业务人员所提出来的是否一致，需要通过大量的测试去进行验证。而我们的开发人员理解业务很容易和业务人员的提出的业务有偏差，就会导致开发成本上升。有了规则引擎之后，我们就可以有下面几点提升：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;业务人员独立配置业务规则，开发人员无需理解，让业务人员的规则和真正的实际情况一致。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;增加业务的透明程度，业务人员配置了之后其他业务人员也能够知道，以前只能通过代码扣扣相传。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;规则高效改动和上线，一般业务人员提出需求之后都是希望能尽快上线，但是之前都需要有代码开发，项目上线等环节，现在业务人员配置好了之后即配即用。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;减少业务人员和开发人员的矛盾，开发人员通常会因为一些时间因素或者一些理解不到位导致业务人员的规则实现有偏差，最后业务同学会对开发同学产生一些小小的矛盾，这下完全业务配置解除开了之后，只要不断的升级规则引擎，业务规则就不会再对开发人员有依赖。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1&gt;什么是规则引擎&lt;/h1&gt;&lt;p&gt;说了这么多好处可能很多同学都会疑问，规则引擎到底长啥样呢？一般来说分为下面三类：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;低配版：没有配置界面，靠业务人员编写引擎规则DSL，一般存储在数据库或者文件中，这种没有彻底解放业务人员和开发人员的耦合，但是加快了业务代码的上线速度，以及很容易就能进行规则变更。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;进阶版：这个一般是某种特定的系统，我们针对这种系统设置一些有针对性的页面，比如下面是某风控系统的截图，风控系统的规则引擎是相对来说比较简单的，只需要判断某些参数是否符合某些条件即可，然后返回固定的值即可。 &lt;img data-ratio=&quot;0.218705035971223&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z62dlFO8L5otKLY57v4qmobtwaWrJp1N63yC33J5eKUFsZicib5u5vE618EW6icV0OKyjgXsvpK9qMCg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;695&quot;/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;完全版：在进阶版中规则引擎只是其中的一个部件，一般这种都很难复用于其他场景。但是一个完全版的规则引擎，追求的超高的通用性，下面是从一个商业的规则引擎中截图：&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img data-ratio=&quot;1.1428571428571428&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z62dlFO8L5otKLY57v4qmobSIrxLq58yZc81zvhMHsoHaFCRiaWTmLKArhutCcLQybjo1OHbDnSIGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;259&quot;/&gt;&lt;/p&gt;&lt;p&gt;可以看见提供了多种规则引擎的表达：比如决策集，决策表，决策树等等，适用于我们很多需要使用规则引擎的地方，下面暂时了一下决策树的配置，这个就和我们上面风控的配置有点类似，只不过通用性更强。 &lt;img data-ratio=&quot;0.5575221238938053&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z62dlFO8L5otKLY57v4qmobdsFyaDgR7qJGgGm09KrmGDYXWlCt05LQvbPOm6ToedsbATgNiawFibUw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1921&quot;/&gt;&lt;/p&gt;&lt;p&gt;讲到这里基本上规则引擎是什么大家基本上心里面有个大概了，下面我们来讲下有哪些开源的规则引擎。&lt;/p&gt;&lt;h1&gt;有哪些规则引擎&lt;/h1&gt;&lt;p&gt;在社区中开源的规则引擎是比较多的，说明不同的业务团队，公司都对这个是比较看中的，但是整体上大的分类分为下面几类：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;通过界面配置的成熟规则引擎：这种规则引擎相对来说就比较重，但是因为功能全，也有部分业务会选择这个，一般出名的有:drools,urule。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;基于jvm脚本语言：这种其实不是一个成熟的规则引擎，他应该算是规则引擎中的核心技术，有很多公司比如美团，他会觉得drools这种太重了，然后会基于一些jvm的脚本语言，去自己开发一个轻量级的规则引擎，这里比较出名的有，groovy,aviator,qlexpress。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;基于java代码的规则引擎：上面是基于jvm脚本语言去做的，会有一些语法学习的成本，所以就有基于java代码去做的规则引擎，比如通过一些注解实现抽象的方式去做到规则的扩展，比较出名的有: easyRules。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;成熟的规则引擎&lt;/h2&gt;&lt;p&gt;作为完全版的成熟的规则引擎，往往可以当作sass产品进行售卖，urule再开源部分的同时，也再卖着自己的高级功能，drools是一个纯开源的产品，如果想体验这种规则引擎可以直接去http://urule.bstek.com/可以体验他的产品，不需要自行搭建。&lt;/p&gt;&lt;p&gt;作为完全版到底是怎么满足各种奇奇怪怪的规则场景呢？在这些规则引擎里面都会分为好几种规则设计器来满足你想要的规则场景：&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5416666666666666&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z62dlFO8L5otKLY57v4qmobQNAVBmqkR5vhVXZ3RDib7bnA0bibyndghFBNWicK13qfueRmGuBmM4Tmw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;480&quot;/&gt;&lt;/p&gt;&lt;p&gt;这个是我们的向导式规则集，比如我们要写一些if/else/and/or 以及 while循环逻辑的时候我们的规则集是一个非常好的选择。如果要用dsl去写他，需要遵循一些规则语法，下面是drools的dsl： &lt;img data-ratio=&quot;0.6468172484599589&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z62dlFO8L5otKLY57v4qmobPsRh7TNhSwpzokkeNTc258tPln97rdicahic3LPyj0ibFC1ZeUR2UQWAQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;487&quot;/&gt;&lt;/p&gt;&lt;p&gt;整体语法来说和我们java差别还是挺大的，有一定的学习成本。&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.34552845528455284&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z62dlFO8L5otKLY57v4qmobRMvcl6icSn4vAY1a0ibuOUnEpDZy32YrtIN3Rfc60doVJ8mLq9Sk0Agw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;738&quot;/&gt; 如果我们想用规则集来实现，也是可以的，但是整体比较复杂，需要大量的写if/else，所以直接使用我们的决策表，就能完成我们的需求：&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5206106870229008&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z62dlFO8L5otKLY57v4qmobn2VwQOr8j7giaNRM4Vdsjadxz2agggTyQofibsQCD2Sic0ybbIzplzaHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;655&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.42410714285714285&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z62dlFO8L5otKLY57v4qmobxb0aDy7hcsHib5Aj5fN4VicJE7SibNkWBjA3RKs6gc3nqtaicRbysWHdpw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;896&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.6814469078179697&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_png/WLIGprPy3z62dlFO8L5otKLY57v4qmobszYnd09icpfhxDribCDoVOZCq90IUvjuMkicQFUKzotP3lYkgnNURZicfg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;857&quot;/&gt;&lt;/p&gt;&lt;p&gt;我们通过这些不同的规则设计器，可以设计出我们不同的规则场景，那么我们应该怎么去调用这些规则呢，一般来说提供了下面三种方式：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;生成jar包：配置好了之后会生成jar包，然后我们引入到我们项目中，项目调用这个jar包即可。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;热更新模式：由规则引擎帮助你对这个jar包文件进行热更新，动态的加载到我们的jvm内存中，这种方式不需要重启机器。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;服务模式：规则引擎自己提供机器，然后通过远程调用的方式，进行规则的计算。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;可以根据自己的场景选择合适的调用模式。&lt;/p&gt;&lt;h3&gt;Rete算法&lt;/h3&gt;&lt;p&gt;不论是drools还是urule，他们都选择了rete算法用作规则匹配。Rete 是一种进行大量模式集合和大量对象集合间比较的高效方法，通过网络筛选的方法找出所有匹配各个模式的对象和规则。其基本原理是通过空间换时间，达到了规则匹配的加速。有兴趣的同学可以下来自行搜索。&lt;/p&gt;&lt;h2&gt;jvm脚本语言的规则引擎&lt;/h2&gt;&lt;p&gt;drools在互联网公司进行规则引擎调研的时候都会进入备选项，但是往往最后都会以太重，学习成本高而最终落选。往往这种轻量级的脚本语言受互联网公司的青睐。一般来说有下面三种脚本语言比较多的被大家用来做规则引擎：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Groovy:Groovy是Apache基金会维护的一个脚本语言，它是基于JVM的语言，它结合了Python、Ruby和Smalltalk的许多强大的特性，Groovy 代码能够与 Java 代码很好地结合，也能用于扩展现有代码。由于其运行在 JVM 上的特性，Groovy也可以使用其他非Java语言编写的库。开源的风控引擎radar就是使用的Groovy去实现的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;aviator：aviator又叫AviatorScript，是一门高性能、轻量级寄宿于 JVM 之上的脚本语言。又叫做表达式语言，提供的语法有限制，和js一样函数是一等公民，支持闭包和函数式编程。最主要它是google开源出来的一个项目，对于他的品质还是非常有保证的。在美团内部基本大部分使用规则引擎的场景比如风控，数据规则等等都选择了aviator这个轻量级的语言作为规则引擎。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;qlexpress：qlexpress是阿里开发的一个脚本语言，在阿里内部以及部分java系的公司都有使用，但是这个我不是太推荐，因为现在这个的社区活跃程度整体的确比较低，上一次更新是一年多前了。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;那么这三个jvm脚本语言我们怎么做选择呢？我个人来看的话还是比较推荐aviator，aviator和其他的两个语言不同，他只提供了有限的语法功能，不像groovy是一整套完整的语言，比如可以做一些危险的操作,如果输入了 &lt;code&gt;&lt;span&gt;System&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;exit&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/code&gt;可以直接退出我们的进程，但是在aviator是不会提供这种能力的，aviator最开始的时候连if/else,循环都不支持，在最新的5.0版本才支持这些功能，所以他提供的整体功能算是一个安全的沙箱。&lt;/p&gt;&lt;p&gt;Aviator 的基本过程是将表达式直接翻译成对应的 java 字节码执行，整个过程最多扫两趟（开启执行优先模式，如果是编译优先模式下就一趟），这样就保证了它的性能超越绝大部分解释性的表达式引擎，测试也证明如此；其次，除了依赖 commons-beanutils 这个库之外（用于做反射）不依赖任何第三方库，因此整体非常轻量级，整个 jar 包大小哪怕发展到现在 5.0 这个大版本，也才 430K。&lt;/p&gt;&lt;p&gt;回到上面的风控规则引擎，如果我们想实现订单金额大于100元并且用户属于vip这个规则在aviator中应该怎么做呢？&lt;/p&gt;&lt;pre&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;static&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; main&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;String&lt;/span&gt;&lt;span&gt;[]&lt;/span&gt;&lt;span&gt; args&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;//首先构造参数&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;Map&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;String&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;Object&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; env &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;HashMap&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;String&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;Object&lt;/span&gt;&lt;span&gt;&amp;gt;();&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        env&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&quot;orderAmount&quot;&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;101&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        env&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&quot;vip&quot;&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;true&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;// 执行表达式逻辑&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;Boolean&lt;/span&gt;&lt;span&gt; result &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Boolean&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;AviatorEvaluator&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;execute&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&quot;orderAmount &amp;gt; 100 &amp;amp;&amp;amp; vip&quot;&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; env&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;System&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;out&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;println&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;result&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;// 输出true&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/pre&gt;&lt;p&gt;可以看见首先我们构造用户是否是vip和订单金额这两个属性，接下来只需要定义 &lt;code&gt;&lt;span&gt;orderAmount&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span/&gt;&lt;span&gt;100&lt;/span&gt;&lt;span/&gt;&lt;span&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span&gt;vip&lt;/span&gt;&lt;/code&gt; 这句表达式，就可以得到我们想到的结果。所以只要运营人员或者产品想到不同的规则，我们这边都可以马上进行配置，可以将这一条规则存到数据库里面，然后进行读取，执行。对于有界面的需求话需要和前端进行配合，让前端的一些控件能自动转换成这种表达式语言，就能完成自动化。&lt;/p&gt;&lt;p&gt;aviator虽然是区别于java的语言，但是其上手成本整体比较低，对于aviator语法有兴趣的可以看看5.0的文档: https://www.yuque.com/boyan-avfmj/aviatorscript&lt;/p&gt;&lt;h2&gt;java代码的规则引擎&lt;/h2&gt;&lt;p&gt;基于java的代码规则引擎往往是一种框架，我们基于框架限定的一些条件来进行实现。下面来看一个实例：如果我们有多个加编号的流程，比如猿辅导的我们加上编号前缀 &lt;code&gt;&lt;span&gt;tutor&lt;/span&gt;&lt;/code&gt;,斑马的我们加上编号前缀 &lt;code&gt;&lt;span&gt;conan&lt;/span&gt;&lt;/code&gt;,搜题的加上编号前缀 &lt;code&gt;&lt;span&gt;solar&lt;/span&gt;&lt;/code&gt;，我们的普通写法是怎么写的呢？&lt;/p&gt;&lt;pre&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;biz &lt;/span&gt;&lt;span&gt;==&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&quot;猿辅导&quot;&lt;/span&gt;&lt;span&gt;){&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;            tradeNo &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&quot;tutor&quot;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; tradeNo&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;biz &lt;/span&gt;&lt;span&gt;==&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&quot;斑马&quot;&lt;/span&gt;&lt;span&gt;){&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;            tradeNo &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&quot;conan&quot;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; tradeNo&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;biz &lt;/span&gt;&lt;span&gt;==&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&quot;搜题&quot;&lt;/span&gt;&lt;span&gt;){&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;            tradeNo &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&quot;solar&quot;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; tradeNo&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/pre&gt;&lt;p&gt;通过if/else 进行处理，看起来这种写法也没什么大毛病，其实他破坏了开闭原则，比如我们增加或者修改逻辑的时候都需要去动这一段代码，如果不小心改错了影响到其他逻辑这就得不偿失了。那么我们如何通过easyRule完成我们的这个功能呢？&lt;/p&gt;&lt;pre&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;@Rule&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;priority &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;FudaoRule&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;@Condition&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; isFudao&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;@Fact&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&quot;biz&quot;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;String&lt;/span&gt;&lt;span&gt; biz&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; biz &lt;/span&gt;&lt;span&gt;==&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&quot;猿辅导&quot;&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;@Action&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; process&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Facts&lt;/span&gt;&lt;span&gt; facts&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;String&lt;/span&gt;&lt;span&gt; tradeNo &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; facts&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;get&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&quot;tradeNo&quot;&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        facts&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&quot;tradeNo&quot;&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&quot;tutor&quot;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; tradeNo&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;@Rule&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;priority &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;BanmaRule&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;@Condition&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; isBanma&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;@Fact&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&quot;biz&quot;&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;String&lt;/span&gt;&lt;span&gt; biz&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; biz &lt;/span&gt;&lt;span&gt;==&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&quot;斑马&quot;&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;@Action&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;void&lt;/span&gt;&lt;span&gt; process&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Facts&lt;/span&gt;&lt;span&gt; facts&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        &lt;/span&gt;&lt;span&gt;String&lt;/span&gt;&lt;span&gt; tradeNo &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; facts&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;get&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&quot;tradeNo&quot;&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;        facts&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;&quot;tradeNo&quot;&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;&quot;conan&quot;&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt; tradeNo&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;&lt;span&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/pre&gt;&lt;p&gt;我们实现这两个不同的类, &lt;code&gt;&lt;span&gt;@Rule&lt;/span&gt;&lt;/code&gt;注解中定义priority代表我们的if/else优先级， &lt;code&gt;&lt;span&gt;@Condition&lt;/span&gt;&lt;/code&gt;就是我们的条件判断，如果属于则进入条件判断， &lt;code&gt;&lt;span&gt;@Action&lt;/span&gt;&lt;/code&gt;是我们匹配之后的动作。通过这种方式如果后面再增加或者修改相关逻辑我们可以在不同的类里面去进行修改,也满足了我们的开闭原则。&lt;/p&gt;&lt;p&gt;easyRules也支持使用yaml文件来进行规则的定义，类似我们之前的dsl，但是我觉得实现java类注解的方式是它的大特点，很多同学如果只想选择一些java的扩展框架它的设计思想是一个值得参考，值得学习的框架。&lt;/p&gt;&lt;h1&gt;最后&lt;/h1&gt;&lt;p&gt;随着互联网平台，中台的兴起，规则引擎也随之渐渐更多的出现在大家的视野里面。如果大家好后面遇到这种灵活多变的业务，如果你还在被if/else的逻辑所困扰，如果你的产品或者运营人员老是吐槽你的开发更不上他的需求，那么请选择一款趁手的规则引擎去解决这些问题把。最后如果大家有什么想和我对于规则引擎有什么沟通的，都可以关注我的公众号和我取得联系。&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;如果大家觉得这篇文章对你有帮助，你的关注和转发是对我最大的支持，O(∩_∩)O:&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.75&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/WLIGprPy3z62dlFO8L5otKLY57v4qmobnhIy8eyiaQXMwEccjhiaXH27tCJibxib1JYeEM9E6wyozbgMJg8oiaR994A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;500&quot;/&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                          
              &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>51a4f0b0098d9da2af6848f78cf9d79f</guid>
<title>开源消息引擎系统 Kafka 3 新特性</title>
<link>https://toutiao.io/k/s838tzi</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1575&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/j3gficicyOvasIjZpiaTNIPReJVWEJf7UGpmokI3LL4NbQDb8fO48fYROmYPXUhXFN8IdDqPcI1gA6OfSLsQHxB4w/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;作者：kylequ，腾讯 PCG 数据工程师&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;kafka3.0 的版本已经试推行去 zk 的 kafka 架构了，如果去掉了 zk，那么在 kafka 新的版本当中使用什么技术来代替了 zk 的位置呢，接下来我们一起来一探究竟，了解 kafka 的内置共识机制和 raft 算法。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1、Kafka 简介&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4952100221075903&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvm9gfDpdpqEFbd7ygNMRsPSL05tbR6pHFnVpp2btQVyYAwPBnP9vMtNQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1357&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Kafka 是一款开源的消息引擎系统。一个典型的 Kafka 体系架构包括若干 Producer、若干 Broker、若干 Consumer，以及一个 ZooKeeper 集群，如上图所示。其中 ZooKeeper 是 Kafka 用来负责集群元数据的管理、控制器的选举等操作的。Producer 将消息发送到 Broker，Broker 负责将收到的消息存储到磁盘中，而 Consumer 负责从 Broker 订阅并消费消息。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.1、Kafka 核心组件&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1.producer&lt;/strong&gt;：消息生产者，就是向 broker 发送消息的客户端。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2.consumer&lt;/strong&gt;：消息消费者，就是从 broker 拉取数据的客户端。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;3.consumer group&lt;/strong&gt;：消费者组，由多个消费者 consumer 组成。消费者组内每个消费者负责消费不同的分区，一个分区只能由同一个消费者组内的一个消费者消费；消费者组之间相互独立，互不影响。所有的消费者都属于某个消费者组，即消费者组是一个逻辑上的订阅者。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;4.broker&lt;/strong&gt;：一台服务器就是一个 broker，一个集群由多个 broker 组成，一个 broker 可以有多个 topic。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;5.topic&lt;/strong&gt;：可以理解为一个队列，所有的生产者和消费者都是面向 topic 的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;6.partition&lt;/strong&gt;：分区，kafka 中的 topic 为了提高拓展性和实现高可用而将它分布到不同的 broker 中，一个 topic 可以分为多个 partition，每个 partition 都是有序的，即消息发送到队列的顺序跟消费时拉取到的顺序是一致的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;7.replication&lt;/strong&gt;：副本。一个 topic 对应的分区 partition 可以有多个副本，多个副本中只有一个为 leader，其余的为 follower。为了保证数据的高可用性，leader 和 follower 会尽量均匀的分布在各个 broker 中，避免了 leader 所在的服务器宕机而导致 topic 不可用的问题。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.2、kafka2 当中 zk 的作用&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.2887700534759359&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvm3GozhnmiaR4CUpGwLy0yicH4tE6PZ9H0EabFBeUyibnIiazXUxfvXcq2RA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;748&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;/admin&lt;/strong&gt; ：主要保存 kafka 当中的核心的重要信息，包括类似于已经删除的 topic 就会保存在这个路径下面&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;/brokers&lt;/strong&gt; ：主要用于保存 kafka 集群当中的 broker 信息，以及没被删除的 topic 信息&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;/cluster&lt;/strong&gt; : 主要用于保存 kafka 集群的唯一 id 信息，每个 kafka 集群都会给分配要给唯一 id，以及对应的版本号&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;/config&lt;/strong&gt; : 集群配置信息&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;/controller&lt;/strong&gt; ：kafka 集群当中的控制器信息，控制器组件（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;/controller_epoch&lt;/strong&gt; ：主要用于保存记录 controller 的选举的次数&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;/isr_change_notification&lt;/strong&gt; ：isr 列表发生变更时候的通知，在 kafka 当中由于存在 ISR 列表变更的情况发生,为了保证 ISR 列表更新的及时性，定义了 isr_change_notification 这个节点，主要用于通知 Controller 来及时将 ISR 列表进行变更&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;/latest_producer_id_block&lt;/strong&gt; ：使用&lt;code&gt;/latest_producer_id_block&lt;/code&gt;节点来保存 PID 块，主要用于能够保证生产者的任意写入请求都能够得到响应。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;/log_dir_event_notification&lt;/strong&gt; ：主要用于保存当 broker 当中某些 LogDir 出现异常时候,例如磁盘损坏,文件读写失败等异常时候,向 ZK 当中增加一个通知序号，controller 监听到这个节点的变化之后，就会做出对应的处理操作。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上就是 kafka 在 zk 当中保留的所有的所有的相关的元数据信息，这些元数据信息保证了 kafka 集群的正常运行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2、kafka3 的安装配置&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 kafka3 的版本当中已经彻底去掉了对 zk 的依赖，如果没有了 zk 集群，那么 kafka 当中是如何保存元数据信息的呢，这里我们通过 kafka3 的集群来一探究竟。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.1、kafka 安装配置核心重要参数&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Controller 服务器&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不管是 kafka2 还是 kafka3 当中，controller 控制器都是必不可少的，通过 controller 控制器来维护 kafka 集群的正常运行，例如 ISR 列表的变更，broker 的上线或者下线，topic 的创建，分区的指定等等各种操作都需要依赖于 Controller，在 kafka2 当中，controller 的选举需要通过 zk 来实现，我们没法控制哪些机器选举成为 Controller,而在 kafka3 当中,我们可以通过配置文件来自己指定哪些机器成为 Controller,这样做的好处就是我们可以指定一些配置比较高的机器作为 Controller 节点,从而保证 controller 节点的稳健性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;被选中的 controller 节点参与元数据集群的选举，每个 controller 节点要么是 Active 状态，或者就是 standBy 状态。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5601300108342362&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvm8A7QeGtXeVhUxn0U0TWsM86o7wDmZVVKlntNT0IQYjB2HVibWRxicAUg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;923&quot;/&gt;&lt;/figure&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;2.1.1、Process.Roles&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用 KRaft 模式来运行 kafka 集群的话，我们有一个配置叫做 Process.Roles 必须配置，这个参数有以下四个值可以进行配置：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;Process.Roles = Broker, 服务器在 KRaft 模式中充当 Broker。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Process.Roles = Controller, 服务器在 KRaft 模式下充当 Controller。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Process.Roles = Broker,Controller，服务器在 KRaft 模式中同时充当 Broker 和 Controller。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果 process.roles 没有设置。那么集群就假定是运行在 ZooKeeper 模式下。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果需要从 zookeeper 模式转换成为 KRaft 模式，那么需要进行重新格式化。如果一个节点同时是 Broker 和 Controller 节点,那么就称之为组合节点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实际工作当中，如果有条件的话，尽量还是将 Broker 和 Controller 节点进行分离部署。避免由于服务器资源不够的情况导致 OOM 等一系列的问题&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;2.1.2、Quorum Voters&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过 controller.quorum.voters 配置来实习哪些节点是 Quorum 的投票节点,所有想要成为控制器的节点,都必须放到这个配置里面。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个 Broker 和每个 Controller 都必须配置 Controller.quorum.voters，该配置当中提供的节点 ID 必须与提供给服务器的节点 ID 保持一直。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个 Broker 和每个 Controller 都必须设置 **&lt;code&gt;controller.quorum.voters&lt;/code&gt;**。需要注意的是，controller.quorum.voters 配置中提供的节点 ID 必须与提供给服务器的节点 ID 匹配。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如在 Controller1 上，node.Id 必须设置为 1，以此类推。注意，控制器 id 不强制要求你从 0 或 1 开始。然而，分配节点 ID 的最简单和最不容易混淆的方法是给每个服务器一个数字 ID，然后从 0 开始。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.2、下载并解压安装包&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;bigdata01 下载 kafka 的安装包，并进行解压：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[hadoop@bigdata01 kraft]$ cd /opt/soft/&lt;br/&gt;[hadoop@bigdata01 soft]$ wget http://archive.apache.org/dist/kafka/3.1.0/kafka_2.12-3.1.0.tgz&lt;br/&gt;[hadoop@bigdata01 soft]$ tar -zxf kafka_2.12-3.1.0.tgz -C /opt/install/&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;修改 kafka 的配置文件 broker.properties：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[hadoop@bigdata01 kafka_2.12-3.1.0]$ cd /opt/install/kafka_2.12-3.1.0/config/kraft/&lt;br/&gt;[hadoop@bigdata01 kraft]$ vim broker.properties&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;修改编辑内容如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;node.id=1&lt;br/&gt;controller.quorum.voters=1@bigdata01:9093&lt;br/&gt;listeners=PLAINTEXT://bigdata01:9092&lt;br/&gt;advertised.listeners=PLAINTEXT://bigdata01:9092&lt;br/&gt;log.dirs=/opt/install/kafka_2.12-3.1.0/kraftlogs&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;创建两个文件夹：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[hadoop@bigdata01 kafka_2.12-3.1.0]$ mkdir -p /opt/install/kafka_2.12-3.1.0/kraftlogs&lt;br/&gt;[hadoop@bigdata01 kafka_2.12-3.1.0]$ mkdir -p /opt/install/kafka_2.12-3.1.0/topiclogs&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同步安装包到其他机器上面去&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.3、服务器集群启动&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;启动 kafka 服务：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[hadoop@bigdata01 kafka_2.12-3.1.0]$  ./bin/kafka-storage.sh random-uuid&lt;br/&gt;YkJwr6RESgSJv-sxa1R1mA&lt;br/&gt;[hadoop@bigdata01 kafka_2.12-3.1.0]$  ./bin/kafka-storage.sh format -t YkJwr6RESgSJv-sxa1R1mA -c ./config/kraft/server.properties&lt;br/&gt;Formatting /opt/install/kafka_2.12-3.1.0/topiclogs&lt;br/&gt;[hadoop@bigdata01 kafka_2.12-3.1.0]$ ./bin/kafka-server-start.sh ./config/kraft/server.properties&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.4、创建 kafka 的 topic&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;集群启动成功之后，就可以来创建 kafka 的 topic 了，使用以下命令来创建 kafka 的 topic&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;./bin/kafka-topics.sh --create --topic kafka_test --partitions 3 --replication-factor 2 --bootstrap-server bigdata01:9092,bigdata02:9092,bigdata03:9092&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.5、任意一台机器查看 kafka 的 topic&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;组成集群之后，任意一台机器就可以通过以下命令来查看到刚才创建的 topic 了&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[hadoop@bigdata03 ~]$ cd /opt/install/kafka_2.12-3.1.0/&lt;br/&gt;[hadoop@bigdata03 kafka_2.12-3.1.0]$ bin/kafka-topics.sh  --list --bootstrap-server bigdata01:9092,bigdata02:9092,bigdata03:9092&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2.6、消息生产与消费&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用命令行来生产以及消费 kafka 当中的消息&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[hadoop@bigdata01 kafka_2.12-3.1.0]$ bin/kafka-console-producer.sh --bootstrap-server bigdata01:9092,bigdata02:9092,bigdata03:9092 --topic kafka_test&lt;br/&gt;&lt;br/&gt;[hadoop@bigdata02 kafka_2.12-3.1.0]$ bin/kafka-console-consumer.sh --bootstrap-server bigdata01:9092,bigdata02:9092,bigdata03:9092 --topic kafka_test --from-beginning&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3、Kafka 当中 Raft 的介绍&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3.1、kafka 强依赖 zk 所引发的问题&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面我们已经看到了 kafka3 集群在没有 zk 集群的依赖下，也可以正常运行，那么 kafka2 在 zk 当中保存的各种重要元数据信息，在 kafka3 当中如何实现保存的呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;kafka 一直都是使用 zk 来管理集群以及所有的 topic 的元数据，并且使用了 zk 的强一致性来选举集群的 controller，controller 对整个集群的管理至关重要，包括分区的新增，ISR 列表的维护，等等很多功能都需要靠 controller 来实现，然后使用 zk 来维护 kafka 的元数据也存在很多的问题以及存在性能瓶颈。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以下是 kafka 将元数据保存在 zk 当中的诸多问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1、元数据存取困难&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;元数据的存取过于困难，每次重新选举的 controller 需要把整个集群的元数据重新 restore，非常的耗时且影响集群的可用性。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2、元数据更新网络开销大&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整个元数据的更新操作也是以全量推的方式进行，网络的开销也会非常大。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;3、强耦合违背软件设计原则&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Zookeeper 对于运维来说，维护 Zookeeper 也需要一定的开销，并且 kafka 强耦合与 zk 也并不好，还得时刻担心 zk 的宕机问题，违背软件设计的高内聚，低耦合的原则。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;4、网络分区复杂度高&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Zookeeper 本身并不能兼顾到 broker 与 broker 之间通信的状态，这就会导致网络分区的复杂度成几何倍数增长。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;5、zk 本身不适合做消息队列&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;zookeeper 不适合做消息队列，因为 zookeeper 有 1M 的消息大小限制 zookeeper 的 children 太多会极大的影响性能 znode 太大也会影响性能 znode 太大会导致重启 zkserver 耗时 10-15 分钟 zookeeper 仅使用内存作为存储，所以不能存储太多东西。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;6、并发访问 zk 问题多&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最好单线程操作 zk 客户端，不要并发，临界、竞态问题太多&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;基于以上各种问题，所以提出了脱离 zk 的方案，转向自助研发强一致性的元数据解决方案，也就是 KIP-500。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;KIP-500 议案提出了在 Kafka 中处理元数据的更好方法。基本思想是&quot;&lt;strong&gt;Kafka on Kafka&lt;/strong&gt;&quot;，将 Kafka 的元数据存储在 Kafka 本身中，无需增加额外的外部存储比如 ZooKeeper 等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;去 zookeeper 之后的 kafka 新的架构&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5601300108342362&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvm8A7QeGtXeVhUxn0U0TWsM86o7wDmZVVKlntNT0IQYjB2HVibWRxicAUg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;923&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 KIP-500 中，Kafka 控制器会将其元数据存储在 Kafka 分区中，而不是存储在 ZooKeeper 中。但是，由于控制器依赖于该分区，因此分区本身不能依赖控制器来进行领导者选举之类的事情。而是，管理该分区的节点必须实现自我管理的 Raft 仲裁。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 kafka3.0 的新的版本当中，使用了新的 KRaft 协议，使用该协议来保证在元数据仲裁中准确的复制元数据，这个协议类似于 zk 当中的 zab 协议以及类似于 Raft 协议，但是 KRaft 协议使用的是基于事件驱动的模式，与 ZAB 协议和 Raft 协议还有点不一样&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 kafka3.0 之前的的版本当中，主要是借助于 controller 来进行 leader partition 的选举，而在 3.0 协议当中，使用了 KRaft 来实现自己选择 leader，并最终令所有节点达成共识，这样简化了 controller 的选举过程，效果更加高效。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3.2、kakfa3 Raft&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面我们已经知道了在 kafka3 当中可以不用再依赖于 zk 来保存 kafka 当中的元数据了，转而使用 Kafka Raft 来实现元数据的一致性，简称&lt;strong&gt;KRaft&lt;/strong&gt;，并且将元数据保存在 kafka 自己的服务器当中，大大提高了 kafka 的元数据管理的性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;KRaft 运行模式的 Kafka 集群，不会将元数据存储在 Apache ZooKeeper 中。即部署新集群的时候，无需部署 ZooKeeper 集群，因为 Kafka 将元数据存储在 Controller 节点的 KRaft Quorum 中。KRaft 可以带来很多好处，比如可以支持更多的分区，更快速的切换 Controller，也可以避免 Controller 缓存的元数据和 Zookeeper 存储的数据不一致带来的一系列问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在新的版本当中，控制器 Controller 节点我们可以自己进行指定,这样最大的好处就是我们可以自己选择一些配置比较好的机器成为 Controller 节点，而不像在之前的版本当中，我们无法指定哪台机器成为 Controller 节点，而且 controller 节点与 broker 节点可以运行在同一台机器上，并且控制器 controller 节点不再向 broker 推送更新消息,而是让 Broker 从这个 Controller Leader 节点进行拉去元数据的更新。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7484407484407485&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmsmSuxkgVjgyPCDJxsZADibiaupTmF6J5UO7vquZAozrjWaETKgzgwOJA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;481&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3.3、如何查看 kafka3 当中的元数据信息&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 kafka3 当中，不再使用 zk 来保存元数据信息了，那么在 kafka3 当中如何查看元数据信息呢，我们也可以通过 kafka 自带的命令来进行查看元数据信息，在 KRaft 中，有两个命令常用命令脚本，kafka-dump-log.sh 和 kakfa-metadata-shell.sh 需要我们来进行关注，因为我们可以通过这两个脚本来查看 kafka 当中保存的元数据信息。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3.3.1、&lt;strong&gt;Kafka-dump-log.sh&lt;/strong&gt; 脚本来导出元数据信息&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;KRaft 模式下，所有的元数据信息都保存到了一个内部的 topic 上面，叫做@metadata，例如 Broker 的信息,Topic 的信息等,我们都可以去到这个 topic 上面进行查看,我们可以通过 kafka-dump-log.sh 这个脚本来进行查看该 topic 的信息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Kafka-dump-log.sh 是一个之前就有的工具，用来查看 Topic 的的文件内容。这工具加了一个参数--cluster-metadata-decoder 用来，查看元数据日志，如下所示:&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[hadoop@bigdata01 kafka_2.12-3.1.0]$ cd /opt/install/kafka_2.12-3.1.0&lt;br/&gt;[hadoop@bigdata01 kafka_2.12-3.1.0]$ bin/kafka-dump-log.sh  --cluster-metadata-decoder --skip-record-metadata  --files  /opt/install/kafka_2.12-3.1.0/topiclogs/__cluster_metadata-0/00000000000000000000.index,/opt/install/kafka_2.12-3.1.0/topiclogs/__cluster_metadata-0/00000000000000000000.log  &amp;gt;&amp;gt;/opt/metadata.txt&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;3.3.2、kafka-metadata-shell.sh 直接查看元数据信息&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;平时我们用 zk 的时候，习惯了用 zk 命令行查看数据，简单快捷。bin 目录下自带了 kafka-metadata-shell.sh 工具，可以允许你像 zk 一样方便的查看数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;使用 kafka-metadata-shell.sh 脚本进入 kafka 的元数据客户端&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;[hadoop@bigdata01 kafka_2.12-3.1.0]$ bin/kafka-metadata-shell.sh --snapshot /opt/install/kafka_2.12-3.1.0/topiclogs/__cluster_metadata-0/00000000000000000000.log&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4、Raft 算法介绍&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;raft 算法中文版本翻译介绍：https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;著名的&lt;strong&gt;CAP&lt;/strong&gt;原则又称 CAP 定理的提出，真正奠基了分布式系统的诞生，CAP 定理指的是在一个分布式系统中，[一致性]、[可用性]（Availability）、[分区容错性]（Partition tolerance），这三个要素最多只能同时实现两点，不可能三者兼顾(nosql)。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分布式系统为了提高系统的可靠性，一般都会选择使用多副本的方式来进行实现，例如 hdfs 当中数据的多副本，kafka 集群当中分区的多副本等，但是一旦有了多副本的话，那么久面临副本之间一致性的问题，而一致性算法就是 用于解决分布式环境下多副本的数据一致性的问题。业界最著名的一致性算法就是大名鼎鼎的 Paxos，但是&lt;strong&gt;Paxos&lt;/strong&gt;比较晦涩难懂，不太容易理解，所以还有一种叫做 Raft 的算法，更加简单容易理解的实现了一致性算法。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.1、Raft 协议的工作原理&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.1.1、Raft 协议当中的角色分布&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Raft 协议将分布式系统当中的角色分为 Leader（领导者），Follower（跟从者）以及 Candidate（候选者）&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Leader&lt;/strong&gt;：主节点的角色，主要是接收客户端请求，并向 Follower 同步日志，当日志同步到过半及以上节点之后，告诉 follower 进行提交日志&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Follower&lt;/strong&gt;：从节点的角色，接受并持久化 Leader 同步的日志，在 Leader 通知可以提交日志之后，进行提交保存的日志&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;Candidate&lt;/strong&gt;：Leader 选举过程中的临时角色。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.975609756097561&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmgeSr1iclMTtPRdAUiaRt4uYfuNH64bmIFXsZ6qoBe8KqIuJnQ0v4lwtw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;656&quot;/&gt;&lt;/figure&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.1.2、Raft 协议当中的底层原理&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Raft 协议当中会选举出 Leader 节点，Leader 作为主节点，完全负责 replicate log 的管理。Leader 负责接受所有客户端的请求，然后复制到 Follower 节点，如果 leader 故障，那么 follower 会重新选举 leader，Raft 协议的一致性，概括主要可以分为以下三个重要部分&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中 Leader 选举和日志复制是 Raft 协议当中最为重要的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Raft 协议要求系统当中，任意一个时刻，只有一个 leader，正常工作期间，只有 Leader 和 Follower 角色，并且 Raft 协议采用了类似网络租期的方式来进行管理维护整个集群，Raft 协议将时间分为一个个的时间段（term），也叫作任期，每一个任期都会选举一个 Leader 来管理维护整个集群，如果这个时间段的 Leader 宕机，那么这一个任期结束，继续重新选举 leader。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;Raft 算法将时间划分成为任意不同长度的任期（term）&lt;/strong&gt;。任期用连续的数字进行表示。&lt;strong&gt;每一个任期的开始都是一次选举（election），一个或多个候选人会试图成为领导人&lt;/strong&gt;。如果一个候选人赢得了选举，它就会在该任期的剩余时间担任领导人。在某些情况下，选票会被瓜分，有可能没有选出领导人，那么，将会开始另一个任期，并且立刻开始下一次选举。&lt;strong&gt;Raft 算法保证在给定的一个任期最多只有一个领导人&lt;/strong&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.40355677154582764&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmJoib2KIOKGGaGyMwk93L8qBUcribOeg6iapNET2TwDGJ9z8HdMkXBcgyA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1462&quot;/&gt;&lt;/figure&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.1.3、Leader 选举的过程&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Raft 使用心跳来进行触发 leader 选举，当服务器启动时，初始化为 follower 角色。leader 向所有 Follower 发送周期性心跳，如果 Follower 在选举超时间内没有收到 Leader 的心跳，就会认为 leader 宕机，稍后发起 leader 的选举。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每个 Follower 都会有一个倒计时时钟，是一个随机的值，表示的是 Follower 等待成为 Leader 的时间，倒计时时钟先跑完，就会当选成为 Leader，这样做得好处就是每一个节点都有机会成为 Leader。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.41264667535853977&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmbCDqokgAeicKCsicspKFGJXIDzk9t2RnWDIrCXWiaNhQC1L2JWrK26uaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1534&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当满足以下三个条件之一时，Quorum 中的某个节点就会触发选举：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;向 Leader 发送 Fetch 请求后，在超时阈值 quorum.fetch.timeout.ms 之后仍然没有得到 Fetch 响应，表示 Leader 疑似失败；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;从当前 Leader 收到了 EndQuorumEpoch 请求，表示 Leader 已退位；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Candidate 状态下，在超时阈值 quorum.election.timeout.ms 之后仍然没有收到多数票，也没有 Candidate 赢得选举，表示此次选举作废，重新进行选举。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体详细过程实现描述如下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;增加节点本地的 current term，切换到 candidate 状态&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;自己给自己投一票&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;给其他节点发送 RequestVote RPCs，要求其他节点也投自己一票&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;等待其他节点的投票回复&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整个过程中的投票过程可以用下图进行表述：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6893854748603352&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvm4kuRb9mYmOcQy9teZaicviaicFkryuuKvd3jyGBAy8H5ZaxsMzamob02w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;895&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;leader 节点选举的限制&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;每个节点只能投一票，投给自己或者投给别人&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;候选人所知道的日志信息，一定不能比自己的更少，即能被选举成为 leader 节点，一定包含了所有已经提交的日志&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;先到先得的原则&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.1.4、数据一致性保证（日志复制机制）&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面通过选举机制之后，选举出来了 leader 节点，然后 leader 节点对外提供服务，所有的客户端的请求都会发送到 leader 节点，由 leader 节点来调度这些并发请求的处理顺序，保证所有节点的状态一致，&lt;strong&gt;leader 会把请求作为日志条目（Log entries）加入到他的日志当中，然后并行的向其他服务器发起 AppendEntries RPC 复制日志条目。&lt;/strong&gt;当这条请求日志被成功复制到大多数服务器上面之后，Leader 将这条日志应用到它的状态机并向客户端返回执行结果。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;客户端的每个请求都包含被复制状态机执行的指令&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;leader 将客户端请求作为一条心得日志添加到日志文件中，然后并行发起 RPC 给其他的服务器，让他们复制这条信息到自己的日志文件中保存。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果这条日志被成功复制，也就是大部分的 follower 都保存好了执行指令日志，leader 就应用这条日志到自己的状态机中，并返回给客户端。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果 follower 宕机或者运行缓慢或者数据丢失，leader 会不断地进行重试，直至所有在线的 follower 都成功复制了所有的日志条目。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.555366269165247&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmo7b5vcfmfDlcp2xmTFuicjevvqa6ad2p4vib7VILhkibtr42k2WqJ942g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1174&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;与维护 Consumer offset 的方式类似，脱离 ZK 之后的 Kafka 集群将元数据视为日志，保存在一个内置的 Topic 中，且该 Topic 只有一个 Partition。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.36203703703703705&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmqHK3CLP8yUhoXichnPkz0fMWut8azic9ZOlv7zAZ1j23Q59E5oX9ee0A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;元数据日志的消息格式与普通消息没有太大不同，但必须携带 Leader 的纪元值(即之前的 Controller epoch)：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;Record =&amp;gt; Offset LeaderEpoch ControlType Key Value Timestamp&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样，Follower 以拉模式复制 Leader 日志，就相当于以 Consumer 角色消费元数据 Topic，符合 Kafka 原生的语义。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么在 KRaft 协议中，是如何维护哪些元数据日志已经提交——即已经成功复制到多数的 Follower 节点上的呢？Kafka 仍然借用了原生副本机制中的概念——high watermark(HW，高水位线)保证日志不会丢失，HW 的示意图如下。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2744310575635877&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmGTgpgnoneFSGNTtkh3xIHNQvhuHctHgmCI2erDPGuwCtTmNCFdb3jg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;747&quot;/&gt;&lt;/figure&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;状态机说明&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要让所有节点达成一致性的状态，大部分都是基于复制状态机来实现的（Replicated state machine）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单来说就是：&lt;strong&gt;初始相同的状态 + 相同的输入过程 = 相同的结束状态&lt;/strong&gt;，这个其实也好理解，就类似于一对双胞胎，出生时候就长得一样，然后吃的喝的用的穿的都一样，你自然很难分辨。其中最重要的就是一定要注意中间的相同输入过程，各个不同节点要以相同且确定性的函数来处理输入，而不要引入一个不确定的值。使用 replicated log 来实现每个节点都顺序的写入客户端请求，然后顺序的处理客户端请求，最终就一定能够达到最终一致性。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;状态机安全性保证&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在安全性方面，KRaft 与传统 Raft 的选举安全性、领导者只追加、日志匹配和领导者完全性保证都是几乎相同的。下面只简单看看状态机安全性是如何保证的，仍然举论文中的极端例子：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.026246719160105&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmhU1vxgL3emUxu2KXr5UtbALa7N77hN1c2m4IMjwlpdSjZpSdib195WA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;762&quot;/&gt;&lt;/figure&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;在时刻 a，节点 S1 是 Leader，epoch=2 的日志只复制给了 S2 就崩溃了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在时刻 b，S5 被选举为 Leader，epoch=3 的日志还没来得及复制，也崩溃了；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在时刻 c，S1 又被选举为 Leader，继续复制日志，将 epoch=2 的日志给了 S3。此时该日志复制给了多数节点，但还未提交；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在时刻 d，S1 又崩溃，并且 S5 重新被选举为领导者，将 epoch=3 的日志复制给 S0~S4。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时日志与新 Leader S5 的日志发生了冲突，如果按上图中 d1 的方式处理，消息 2 就会丢失。传统 Raft 协议的处理方式是：在 Leader 任期开始时，立刻提交一条空的日志，所以上图中时刻 c 的情况不会发生，而是如同 d2 一样先提交 epoch=4 的日志，连带提交 epoch=2 的日志。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;与传统 Raft 不同，KRaft 附加了一个较强的约束：当新的 Leader 被选举出来，但还没有成功提交属于它的 epoch 的日志时，不会向前推进 HW。也就是说，即使上图中时刻 c 的情况发生了，消息 2 也被视为没有成功提交，所以按照 d1 方式处理是安全的。&lt;/p&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;日志格式说明&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所有节点持久化保存在本地的日志，大概就是类似于这个样子：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5288888888888889&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmss90x7Qv7S8BvlK3tkZibtnticj731PruZRcfaXF5ic3TIq0jSgLiblP8w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1125&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上图显示，共有八条日志数据，其中已经提交了 7 条，提交的日志都将通过状态机持久化到本地磁盘当中，防止宕机。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;日志复制的保证机制&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;如果两个节点不同的日志文件当中存储着相同的索引和任期号，那么他们所存储的命令是相同的。（原因：leader 最多在一个任期里的一个日志索引位置创建一条日志条目，日志条目所在的日志位置从来不会改变）。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果不同日志中两个条目有着相同的索引和任期号，那么他们之前的所有条目都是一样的（原因：每次 RPC 发送附加日志时，leader 会把这条日志前面的日志下标和任期号一起发送给 follower，如果 follower 发现和自己的日志不匹配，那么就拒绝接受这条日志，这个称之为一致性检查）&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;日志的不正常情况&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般情况下，Leader 和 Followers 的日志保持一致，因此 Append Entries 一致性检查通常不会失败。然而，Leader 崩溃可能会导致日志不一致：&lt;strong&gt;旧的 Leader 可能没有完全复制完日志中的所有条目&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下图阐述了一些 Followers 可能和新的 Leader 日志不同的情况。&lt;strong&gt;一个 Follower 可能会丢失掉 Leader 上的一些条目，也有可能包含一些 Leader 没有的条目，也有可能两者都会发生&lt;/strong&gt;。丢失的或者多出来的条目可能会持续多个任期。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6148919135308246&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmJUB7bhvjGoTicmThXSusE8Jq9IL4bFJvjKOCsl7EVIs8AM6uPqXYkhg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1249&quot;/&gt;&lt;/figure&gt;&lt;h5 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;如何保证日志的正常复制&lt;/span&gt;&lt;span/&gt;&lt;/h5&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果出现了上述 leader 宕机，导致 follower 与 leader 日志不一致的情况，那么就需要进行处理，保证 follower 上的日志与 leader 上的日志保持一致，leader 通过强制 follower 复制它的日志来处理不一致的问题，follower 与 leader 不一致的日志会被强制覆盖。&lt;strong&gt;leader 为了最大程度的保证日志的一致性，且保证日志最大量，leader 会寻找 follower 与他日志一致的地方，然后覆盖 follower 之后的所有日志条目，从而实现日志数据的一致性。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体的操作就是：leader 会从后往前不断对比，每次 Append Entries 失败后尝试前一个日志条目，直到成功找到每个 Follower 的日志一致的位置点，然后向该 Follower 所在位置之后的条目进行覆盖。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;详细过程如下：&lt;/strong&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;Leader 维护了每个 Follower 节点下一次要接收的日志的索引，即 nextIndex&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Leader 选举成功后将所有 Follower 的 nextIndex 设置为自己的最后一个日志条目+1&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Leader 将数据推送给 Follower，如果 Follower 验证失败（nextIndex 不匹配），则在下一次推送日志时缩小 nextIndex，直到 nextIndex 验证通过&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总结一下就是：&lt;strong&gt;当 leader 和 follower 日志冲突的时候&lt;/strong&gt;，leader 将&lt;strong&gt;校验 follower 最后一条日志是否和 leader 匹配&lt;/strong&gt;，如果不匹配，&lt;strong&gt;将递减查询，直到匹配，匹配后，删除冲突的日志&lt;/strong&gt;。这样就实现了主从日志的一致性。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;4.2、Raft 协议算法代码实现&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前面我们已经大致了解了 Raft 协议算法的实现原理，如果我们要自己实现一个 Raft 协议的算法，其实就是将我们讲到的理论知识给翻译成为代码的过程，具体的开发需要考虑的细节比较多，代码量肯定也比较大，好在有人已经实现了 Raft 协议的算法了，我们可以直接拿过来使用&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;创建 maven 工程并导入 jar 包地址如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&amp;lt;dependencies&amp;gt;&lt;br/&gt;&lt;br/&gt;        &amp;lt;dependency&amp;gt;&lt;br/&gt;            &amp;lt;groupId&amp;gt;com.github.wenweihu86.raft&amp;lt;/groupId&amp;gt;&lt;br/&gt;            &amp;lt;artifactId&amp;gt;raft-java-core&amp;lt;/artifactId&amp;gt;&lt;br/&gt;            &amp;lt;version&amp;gt;&lt;span&gt;1.8&lt;/span&gt;&lt;span&gt;.0&lt;/span&gt;&amp;lt;/version&amp;gt;&lt;br/&gt;        &amp;lt;/dependency&amp;gt;&lt;br/&gt;&lt;br/&gt;        &amp;lt;dependency&amp;gt;&lt;br/&gt;            &amp;lt;groupId&amp;gt;com.github.wenweihu86.rpc&amp;lt;/groupId&amp;gt;&lt;br/&gt;            &amp;lt;artifactId&amp;gt;rpc-java&amp;lt;/artifactId&amp;gt;&lt;br/&gt;            &amp;lt;version&amp;gt;&lt;span&gt;1.8&lt;/span&gt;&lt;span&gt;.0&lt;/span&gt;&amp;lt;/version&amp;gt;&lt;br/&gt;        &amp;lt;/dependency&amp;gt;&lt;br/&gt;&lt;br/&gt;        &amp;lt;dependency&amp;gt;&lt;br/&gt;            &amp;lt;groupId&amp;gt;org.rocksdb&amp;lt;/groupId&amp;gt;&lt;br/&gt;            &amp;lt;artifactId&amp;gt;rocksdbjni&amp;lt;/artifactId&amp;gt;&lt;br/&gt;            &amp;lt;version&amp;gt;&lt;span&gt;5.1&lt;/span&gt;&lt;span&gt;.4&lt;/span&gt;&amp;lt;/version&amp;gt;&lt;br/&gt;        &amp;lt;/dependency&amp;gt;&lt;br/&gt;&lt;br/&gt;    &amp;lt;/dependencies&amp;gt;&lt;br/&gt;    &amp;lt;build&amp;gt;&lt;br/&gt;        &amp;lt;plugins&amp;gt;&lt;br/&gt;            &amp;lt;plugin&amp;gt;&lt;br/&gt;                &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;&lt;br/&gt;                &amp;lt;artifactId&amp;gt;maven-compiler-plugin&amp;lt;/artifactId&amp;gt;&lt;br/&gt;                &amp;lt;version&amp;gt;&lt;span&gt;3.5&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;&amp;lt;/version&amp;gt;&lt;br/&gt;                &amp;lt;configuration&amp;gt;&lt;br/&gt;                    &amp;lt;source&amp;gt;&lt;span&gt;1.8&lt;/span&gt;&amp;lt;/source&amp;gt;&lt;br/&gt;                    &amp;lt;target&amp;gt;&lt;span&gt;1.8&lt;/span&gt;&amp;lt;/target&amp;gt;&lt;br/&gt;                &amp;lt;/configuration&amp;gt;&lt;br/&gt;            &amp;lt;/plugin&amp;gt;&lt;br/&gt;        &amp;lt;/plugins&amp;gt;&lt;br/&gt;    &amp;lt;/build&amp;gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;定义 Server 端代码实现：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;Server1&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;// parse args&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// peers, format is &quot;host:port:serverId,host2:port2:serverId2&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;//localhost:16010:1,localhost:16020:2,localhost:16030:3 localhost:16010:1&lt;/span&gt;&lt;br/&gt;        String servers = &lt;span&gt;&quot;localhost:16010:1,localhost:16020:2,localhost:16030:3&quot;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// local server&lt;/span&gt;&lt;br/&gt;        RaftMessage.Server localServer = parseServer(&lt;span&gt;&quot;localhost:16010:1&quot;&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;        String[] splitArray = servers.split(&lt;span&gt;&quot;,&quot;&lt;/span&gt;);&lt;br/&gt;        List&amp;lt;RaftMessage.Server&amp;gt; serverList = &lt;span&gt;new&lt;/span&gt; ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;        &lt;span&gt;for&lt;/span&gt; (String serverString : splitArray) {&lt;br/&gt;            RaftMessage.Server server = parseServer(serverString);&lt;br/&gt;            serverList.add(server);&lt;br/&gt;        }&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;// 初始化RPCServer&lt;/span&gt;&lt;br/&gt;        RPCServer server = &lt;span&gt;new&lt;/span&gt; RPCServer(localServer.getEndPoint().getPort());&lt;br/&gt;        &lt;span&gt;// 设置Raft选项，比如：&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// just for test snapshot&lt;/span&gt;&lt;br/&gt;        RaftOptions raftOptions = &lt;span&gt;new&lt;/span&gt; RaftOptions();&lt;br/&gt;      &lt;span&gt;/*  raftOptions.setSnapshotMinLogSize(10 * 1024);&lt;br/&gt;        raftOptions.setSnapshotPeriodSeconds(30);&lt;br/&gt;        raftOptions.setMaxSegmentFileSize(1024 * 1024);*/&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;// 应用状态机&lt;/span&gt;&lt;br/&gt;        ExampleStateMachine stateMachine = &lt;span&gt;new&lt;/span&gt; ExampleStateMachine(raftOptions.getDataDir());&lt;br/&gt;        &lt;span&gt;// 初始化RaftNode&lt;/span&gt;&lt;br/&gt;        RaftNode raftNode = &lt;span&gt;new&lt;/span&gt; RaftNode(raftOptions, serverList, localServer, stateMachine);&lt;br/&gt;        raftNode.getLeaderId();&lt;br/&gt;        &lt;span&gt;// 注册Raft节点之间相互调用的服务&lt;/span&gt;&lt;br/&gt;        RaftConsensusService raftConsensusService = &lt;span&gt;new&lt;/span&gt; RaftConsensusServiceImpl(raftNode);&lt;br/&gt;        server.registerService(raftConsensusService);&lt;br/&gt;        &lt;span&gt;// 注册给Client调用的Raft服务&lt;/span&gt;&lt;br/&gt;        RaftClientService raftClientService = &lt;span&gt;new&lt;/span&gt; RaftClientServiceImpl(raftNode);&lt;br/&gt;        server.registerService(raftClientService);&lt;br/&gt;        &lt;span&gt;// 注册应用自己提供的服务&lt;/span&gt;&lt;br/&gt;        ExampleService exampleService = &lt;span&gt;new&lt;/span&gt; ExampleServiceImpl(raftNode, stateMachine);&lt;br/&gt;        server.registerService(exampleService);&lt;br/&gt;        &lt;span&gt;// 启动RPCServer，初始化Raft节点&lt;/span&gt;&lt;br/&gt;        server.start();&lt;br/&gt;        raftNode.init();&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; RaftMessage.&lt;span&gt;Server &lt;span&gt;parseServer&lt;/span&gt;&lt;span&gt;(String serverString)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        String[] splitServer = serverString.split(&lt;span&gt;&quot;:&quot;&lt;/span&gt;);&lt;br/&gt;        String host = splitServer[&lt;span&gt;0&lt;/span&gt;];&lt;br/&gt;        Integer port = Integer.parseInt(splitServer[&lt;span&gt;1&lt;/span&gt;]);&lt;br/&gt;        Integer serverId = Integer.parseInt(splitServer[&lt;span&gt;2&lt;/span&gt;]);&lt;br/&gt;        RaftMessage.EndPoint endPoint = RaftMessage.EndPoint.newBuilder()&lt;br/&gt;                .setHost(host).setPort(port).build();&lt;br/&gt;        RaftMessage.Server.Builder serverBuilder = RaftMessage.Server.newBuilder();&lt;br/&gt;        RaftMessage.Server server = serverBuilder.setServerId(serverId).setEndPoint(endPoint).build();&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; server;&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;定义客户端代码实现如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ClientMain&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;// parse args&lt;/span&gt;&lt;br/&gt;        String ipPorts = args[&lt;span&gt;0&lt;/span&gt;];&lt;br/&gt;        String key = args[&lt;span&gt;1&lt;/span&gt;];&lt;br/&gt;        String value = &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (args.length &amp;gt; &lt;span&gt;2&lt;/span&gt;) {&lt;br/&gt;            value = args[&lt;span&gt;2&lt;/span&gt;];&lt;br/&gt;        }&lt;br/&gt;        &lt;span&gt;// init rpc client&lt;/span&gt;&lt;br/&gt;        RPCClient rpcClient = &lt;span&gt;new&lt;/span&gt; RPCClient(ipPorts);&lt;br/&gt;        ExampleService exampleService = RPCProxy.getProxy(rpcClient, ExampleService&lt;span&gt;.&lt;span&gt;class&lt;/span&gt;)&lt;/span&gt;;&lt;br/&gt;        &lt;span&gt;final&lt;/span&gt; JsonFormat.Printer printer = JsonFormat.printer().omittingInsignificantWhitespace();&lt;br/&gt;        &lt;span&gt;// set&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (value != &lt;span&gt;null&lt;/span&gt;) {&lt;br/&gt;            ExampleMessage.SetRequest setRequest = ExampleMessage.SetRequest.newBuilder()&lt;br/&gt;                    .setKey(key).setValue(value).build();&lt;br/&gt;            ExampleMessage.SetResponse setResponse = exampleService.set(setRequest);&lt;br/&gt;            &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;                System.out.printf(&lt;span&gt;&quot;set request, key=%s value=%s response=%s\n&quot;&lt;/span&gt;,&lt;br/&gt;                        key, value, printer.print(setResponse));&lt;br/&gt;            } &lt;span&gt;catch&lt;/span&gt; (Exception ex) {&lt;br/&gt;                ex.printStackTrace();&lt;br/&gt;            }&lt;br/&gt;        } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;            &lt;span&gt;// get&lt;/span&gt;&lt;br/&gt;            ExampleMessage.GetRequest getRequest = ExampleMessage.GetRequest.newBuilder().setKey(key).build();&lt;br/&gt;            ExampleMessage.GetResponse getResponse = exampleService.get(getRequest);&lt;br/&gt;            &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;                String value1 = getResponse.getValue();&lt;br/&gt;                System.out.println(value1);&lt;br/&gt;                System.out.printf(&lt;span&gt;&quot;get request, key=%s, response=%s\n&quot;&lt;/span&gt;,&lt;br/&gt;                        key, printer.print(getResponse));&lt;br/&gt;            } &lt;span&gt;catch&lt;/span&gt; (Exception ex) {&lt;br/&gt;                ex.printStackTrace();&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;&lt;br/&gt;        rpcClient.stop();&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先启动服务端，然后启动客户端，就可以将实现客户端向服务端发送消息，并且服务端会向三台机器进行保存消息了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;5、Kafka 常见问题&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;1.消息队列模型知道吗?Kafka 是怎么做到支持这两种模型的？&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于传统的消息队列系统支持两个模型：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1.点对点：也就是消息只能被一个消费者消费，消费完后消息删除&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2.发布订阅：相当于广播模式，消息可以被所有消费者消费&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;kafka 其实就是通过 Consumer Group 同时支持了这两个模型。如果说所有消费者都属于一个 Group，消息只能被同一个 Group 内的一个消费者消费，那就是点对点模式。如果每个消费者都是一个单独的 Group，那么就是发布订阅模式。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;2.说说 Kafka 通信过程原理吗?&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1.首先 kafka broker 启动的时候，会去向 Zookeeper 注册自己的 ID（创建临时节点），这个 ID 可以配置也可以自动生成，同时会去订阅 Zookeeper 的 brokers/ids 路径，当有新的 broker 加入或者退出时，可以得到当前所有 broker 信。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2.生产者启动的时候会指定 bootstrap.servers，通过指定的 broker 地址，Kafka 就会和这些 broker 创建 TCP 连接（通常我们不用配置所有的 broker 服务器地址，否则 kafka 会和配置的所有 broker 都建立 TCP 连接）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3.随便连接到任何一台 broker 之后，然后再发送请求获取元数据信息（包含有哪些主题、主题都有哪些分区、分区有哪些副本，分区的 Leader 副本等信息）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;4.接着就会创建和所有 broker 的 TCP 连接&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;5.之后就是发送消息的过程&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;6.消费者和生产者一样，也会指定 bootstrap.servers 属性，然后选择一台 broker 创建 TCP 连接，发送请求找到协调者所在的 broker&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;7.然后再和协调者 broker 创建 TCP 连接，获取元数据&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;8.根据分区 Leader 节点所在的 broker 节点，和这些 broker 分别创建连接&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;9.最后开始消费消息&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4703703703703704&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmP9kDkliaKThbQz8hfTz8KanLYxXWlU3FQTRibZUZgybtgug0oI2Pa0Ow/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;3.发送消息时如何选择分区的?&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主要有两种方式：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1.轮询，按照顺序消息依次发送到不同的分区&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2.随机，随机发送到某个分区&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果消息指定 key，那么会根据消息的 key 进行 hash，然后对 partition 分区数量取模，决定落在哪个分区上，所以，对于相同 key 的消息来说，总是会发送到同一个分区上，也是我们常说的消息分区有序性。很常见的场景就是我们希望下单、支付消息有顺序，这样以订单 ID 作为 key 发送消息就达到了分区有序性的目的。如果没有指定 key，会执行默认的轮询负载均衡策略，比如第一条消息落在 P0，第二条消息落在 P1，然后第三条又在 P1。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除此之外，对于一些特定的业务场景和需求，还可以通过实现 Partitioner 接口，重写 configure 和 partition 方法来达到自定义分区的效果。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;4.为什么需要分区?有什么好处?&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个问题很简单，如果说不分区的话，我们发消息写数据都只能保存到一个节点上，这样的话就算这个服务器节点性能再好最终也支撑不住。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实际上分布式系统都面临这个问题，要么收到消息之后进行数据切分，要么提前切分，kafka 正是选择了前者，通过分区可以把数据均匀地分布到不同的节点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;分区带来了负载均衡和横向扩展的能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;发送消息时可以根据分区的数量落在不同的 Kafka 服务器节点上，提升了并发写消息的性能，消费消息的时候又和消费者绑定了关系，可以从不同节点的不同分区消费消息，提高了读消息的能力。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外一个就是分区又引入了副本，冗余的副本保证了 Kafka 的高可用和高持久性。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;5.详细说说消费者组和消费者重平衡？&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Kafka 中的消费者组订阅 topic 主题的消息，一般来说消费者的数量最好要和所有主题分区的数量保持一致最好（举例子用一个主题，实际上当然是可以订阅多个主题）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当消费者数量小于分区数量的时候，那么必然会有一个消费者消费多个分区的消息。而消费者数量超过分区的数量的时候，那么必然会有消费者没有分区可以消费。所以，消费者组的好处一方面在上面说到过，可以支持多种消息模型，另外的话根据消费者和分区的消费关系，支撑横向扩容伸缩。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.25462962962962965&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvm2HWVcvmGNXXg2Kswpco1jbjCdic3oQDu5u5eunHiaRF3eBsQYv0VeEhw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当我们知道消费者如何消费分区的时候，就显然会有一个问题出现了，消费者消费的分区是怎么分配的，有先加入的消费者时候怎么办？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;旧版本的重平衡过程主要通过 ZK 监听器的方式来触发，每个消费者客户端自己去执行分区分配算法。新版本则是通过协调者来完成，每一次新的消费者加入都会发送请求给协调者去获取分区的分配，这个分区分配的算法逻辑由协调者来完成。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而重平衡 Rebalance 就是指的有新消费者加入的情况，比如刚开始我们只有消费者 A 在消费消息，过了一段时间消费者 B 和 C 加入了，这时候分区就需要重新分配，这就是重平衡，也可以叫做再平衡，但是重平衡的过程和我们的 GC 时候 STW 很像，会导致整个消费群组停止工作，重平衡期间都无法消息消息。另外，发生重平衡并不是只有这一种情况，因为消费者和分区总数是存在绑定关系的，上面也说了，消费者数量最好和所有主题的分区总数一样。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那只要&lt;strong&gt;消费者数量&lt;/strong&gt;、&lt;strong&gt;主题数量&lt;/strong&gt;（比如用的正则订阅的主题）、&lt;strong&gt;分区数量&lt;/strong&gt;任何一个发生改变，都会触发重平衡。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面说说重平衡的过程。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;重平衡的机制依赖消费者和协调者之间的心跳来维持，消费者会有一个独立的线程去定时发送心跳给协调者，这个可以通过参数 heartbeat.interval.ms 来控制发送心跳的间隔时间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;1.每个消费者第一次加入组的时候都会向协调者发送 JoinGroup 请求，第一个发送这个请求的消费者会成为“群主”，协调者会返回组成员列表给群主&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;2.群主执行分区分配策略，然后把分配结果通过 SyncGroup 请求发送给协调者，协调者收到分区分配结果&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;3.其他组内成员也向协调者发送 SyncGroup，协调者把每个消费者的分区分配分别响应给他们&lt;/strong&gt;&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;6.具体讲讲分区分配策略?&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主要有 3 种分配策略：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;Range&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对分区进行排序，排序越靠前的分区能够分配到更多的分区。比如有 3 个分区，消费者 A 排序更靠前，所以能够分配到 P0\P1 两个分区，消费者 B 就只能分配到一个 P2。如果是 4 个分区的话，那么他们会刚好都是分配到 2 个。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5583333333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvm1nLZAVoPhEcme6uaaKjib832G30ZcWf4ssyyPUlDqdib2t6wsziaQibvDw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是这个分配策略会有点小问题，他是根据主题进行分配，所以如果消费者组订阅了多个主题，那就有可能导致分区分配不均衡。比如下图中两个主题的 P0\P1 都被分配给了 A，这样 A 有 4 个分区，而 B 只有 2 个，如果这样的主题数量越多，那么不均衡就越严重。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0787037037037037&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmfNAEWY8G60RnFAFBc75tZ2afaib1PBmX1Z5VQeeU0ibeaRhOPsLTUeicw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;RoundRobin&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也就是我们常说的轮询了，这个就比较简单了，不画图你也能很容易理解。这个会根据所有的主题进行轮询分配，不会出现 Range 那种主题越多可能导致分区分配不均衡的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;P0-&amp;gt;A，P1-&amp;gt;B，P1-&amp;gt;A。。。以此类推&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0787037037037037&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmkzq0moRTV5Eamtrx0vK53WVibia9SKLXFJKibGzuHIuJw0YhUoaZa5zibw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;Sticky&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个从字面看来意思就是粘性策略，大概是这个意思。主要考虑的是在分配均衡的前提下，让分区的分配更小的改动。比如之前 P0\P1 分配给消费者 A，那么下一次尽量还是分配给 A。这样的好处就是连接可以复用，要消费消息总是要和 broker 去连接的，如果能够保持上一次分配的分区的话，那么就不用频繁的销毁创建连接了。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;7.如何保证消息可靠性?&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;生产者发送消息丢失&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;kafka 支持 3 种方式发送消息，这也是常规的 3 种方式，发送后不管结果、同步发送、异步发送，基本上所有的消息队列都是这样玩的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1.发送并忘记，直接调用发送 send 方法，不管结果，虽然可以开启自动重试，但是肯定会有消息丢失的可能&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2.同步发送，同步发送返回 Future 对象，我们可以知道发送结果，然后进行处理&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3.异步发送，发送消息，同时指定一个回调函数，根据结果进行相应的处理&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了保险起见，一般我们都会使用异步发送带有回调的方式进行发送消息，再设置参数为发送消息失败不停地重试。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;acks=all，这个参数有可以配置 0|1|all。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;0 表示生产者写入消息不管服务器的响应，可能消息还在网络缓冲区，服务器根本没有收到消息，当然会丢失消息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1 表示至少有一个副本收到消息才认为成功，一个副本那肯定就是集群的 Leader 副本了，但是如果刚好 Leader 副本所在的节点挂了，Follower 没有同步这条消息，消息仍然丢失了。配置 all 的话表示所有 ISR 都写入成功才算成功，那除非所有 ISR 里的副本全挂了，消息才会丢失。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;retries=N，设置一个非常大的值，可以让生产者发送消息失败后不停重试&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;Kafka 自身消息丢失&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;kafka 因为消息写入是通过 PageCache 异步写入磁盘的，因此仍然存在丢失消息的可能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此针对 kafka 自身丢失的可能设置参数：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;replication.factor=N，设置一个比较大的值，保证至少有 2 个或者以上的副本。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;min.insync.replicas=N，代表消息如何才能被认为是写入成功，设置大于 1 的数，保证至少写入 1 个或者以上的副本才算写入消息成功。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;unclean.leader.election.enable=false，这个设置意味着没有完全同步的分区副本不能成为 Leader 副本，如果是 true 的话，那些没有完全同步 Leader 的副本成为 Leader 之后，就会有消息丢失的风险。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;消费者消息丢失&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;消费者丢失的可能就比较简单，关闭自动提交位移即可，改为业务处理成功手动提交。因为重平衡发生的时候，消费者会去读取上一次提交的偏移量，自动提交默认是每 5 秒一次，这会导致重复消费或者丢失消息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;enable.auto.commit=false，设置为手动提交。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有一个参数我们可能也需要考虑进去的：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;auto.offset.reset=earliest，这个参数代表没有偏移量可以提交或者 broker 上不存在偏移量的时候，消费者如何处理。earliest 代表从分区的开始位置读取，可能会重复读取消息，但是不会丢失，消费方一般我们肯定要自己保证幂等，另外一种 latest 表示从分区末尾读取，那就会有概率丢失消息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综合这几个参数设置，我们就能保证消息不会丢失，保证了可靠性。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;8.聊聊副本和它的同步原理吧?&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Kafka 副本的之前提到过，分为 Leader 副本和 Follower 副本，也就是主副本和从副本，和其他的比如 Mysql 不一样的是，Kafka 中只有 Leader 副本会对外提供服务，Follower 副本只是单纯地和 Leader 保持数据同步，作为数据冗余容灾的作用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 Kafka 中我们把所有副本的集合统称为 AR（Assigned Replicas），和 Leader 副本保持同步的副本集合称为 ISR（InSyncReplicas）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;ISR 是一个动态的集合，维持这个集合会通过 replica.lag.time.max.ms 参数来控制，这个代表落后 Leader 副本的最长时间，默认值 10 秒，所以只要 Follower 副本没有落后 Leader 副本超过 10 秒以上，就可以认为是和 Leader 同步的（简单可以认为就是同步时间差）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外还有两个关键的概念用于副本之间的同步：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;HW（High Watermark）：&lt;/strong&gt;高水位，也叫做复制点，表示副本间同步的位置。如下图所示，0~4 绿色表示已经提交的消息，这些消息已经在副本之间进行同步，消费者可以看见这些消息并且进行消费，4~6 黄色的则是表示未提交的消息，可能还没有在副本间同步，这些消息对于消费者是不可见的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;LEO（Log End Offset）：&lt;/strong&gt;下一条待写入消息的位移&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.35555555555555557&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmGnGiaTMIY8pyhXKqKqKNvzHODxYMSyNVmDdyKibO4biaAGoNlvy05QuBg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;副本间同步的过程依赖的就是 HW 和 LEO 的更新，以他们的值变化来演示副本同步消息的过程，绿色表示 Leader 副本，黄色表示 Follower 副本。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先，生产者不停地向 Leader 写入数据，这时候 Leader 的 LEO 可能已经达到了 10，但是 HW 依然是 0，两个 Follower 向 Leader 请求同步数据，他们的值都是 0。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6416666666666667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmFVSIGGBM45pibdr8lMuLV20K7nhfFS95jHjXVuy9fhcZRcD6yWkrGQA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时，Follower 再次向 Leader 拉取数据，这时候 Leader 会更新自己的 HW 值，取 Follower 中的最小的 LEO 值来更新。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6416666666666667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvmON8tMhJqQA3X5jkfTITqbu1ZVqiaSwLeD7yibe3HJzVnuHQ5bpYDpnsA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之后，Leader 响应自己的 HW 给 Follower，Follower 更新自己的 HW 值，因为又拉取到了消息，所以再次更新 LEO，流程以此类推。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6416666666666667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/j3gficicyOvasdu5HPSTYVr2l1icQNcuSvm69ia4wD7oibCI0UfeEVGcnpgZAocvBvr4eJ2j6z9UjOJhQ7KfYnXGp3g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;&lt;strong&gt;9.Kafka 为什么快?&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主要是 3 个方面：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;顺序 IO&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;kafka 写消息到分区采用追加的方式，也就是顺序写入磁盘，不是随机写入，这个速度比普通的随机 IO 快非常多，几乎可以和网络 IO 的速度相媲美。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;Page Cache 和零拷贝&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;kafka 在写入消息数据的时候通过 mmap 内存映射的方式，不是真正立刻写入磁盘，而是利用操作系统的文件缓存 PageCache 异步写入，提高了写入消息的性能，另外在消费消息的时候又通过 sendfile 实现了零拷贝。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;批量处理和压缩&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Kafka 在发送消息的时候不是一条条的发送的，而是会把多条消息合并成一个批次进行处理发送，消费消息也是一个道理，一次拉取一批次的消息进行消费。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;并且 Producer、Broker、Consumer 都使用了优化后的压缩算法，发送和消息消息使用压缩节省了网络传输的开销，Broker 存储使用压缩则降低了磁盘存储的空间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;参考文档&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_iframe&quot; data-pluginname=&quot;videosnap&quot; data-id=&quot;export/UzFfAgtgekIEAQAAAAAACesl2A9hlAAAAAstQy6ubaLX4KHWvLEZgBPEz6JYezpKHO2DzNPgMIuqFO6vWj3owO52P7hBJaXi&quot; data-url=&quot;https://findermp.video.qq.com/251/20304/stodownload?encfilekey=rjD5jyTuFrIpZ2ibE8T7Ym3K77SEULgkiaLDNh3hAibdiafxRS4L7KOfnWk2tSezfPNLhsVAZeh73qgZRrOxepnLeFqTBcaY0icQaNDCJVcYnv6suuq0ic4PjnSw&amp;amp;adaptivelytrans=0&amp;amp;bizid=1023&amp;amp;dotrans=0&amp;amp;hy=SZ&amp;amp;idx=1&amp;amp;m=&amp;amp;scene=0&amp;amp;token=AxricY7RBHdWEqVjWX9z6pmnicd4UxFW8ObHiaOyojhdzicqAKBEsNsBUFa9Sv1iaw4PENtyd4EDN5s8&quot; data-headimgurl=&quot;http://wx.qlogo.cn/finderhead/I7awtksbibjQe7RZAy84xESOBAfIZ8xQ9ApXt4uTe8po/0&quot; data-username=&quot;v2_060000231003b20faec8c6e08e1ac1d4cf06ea31b07760a16cba92d83444bd9a5d9d55ffaede@finder&quot; data-nickname=&quot;腾讯程序员&quot; data-desc=&quot;腾讯会议居然还可以这么玩？！&amp;#10;#腾讯会议&amp;#10;&quot; data-nonceid=&quot;11264342744746376585&quot; data-type=&quot;video&quot;/&gt;&lt;/section&gt;&lt;/section&gt;
          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>