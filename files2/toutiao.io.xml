<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>0c3954cece9861e72f99179c5006aacf</guid>
<title>接下来或许是一年中跳槽的最佳时间</title>
<link>https://toutiao.io/k/0y276l8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般来说，很多人都认为一年中最佳的跳槽时间是三、四月份，也就是我们常说的“金三银四”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但我认为“金三银四”不一定是性价比最佳的时间。为什么这么说？听我从团队管理者、面试官的角度给大家解释一下。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;三、四月份是跳槽的旺季，背后主要的原因就是年终奖。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就拿我管理的技术团队来说吧，我们团队有 100 多人。每年三、四月份跳槽的人确实是最多。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;原因也很简单，一般来说，上一年底最晚年初，每个人的绩效分数都出来了。其中绩效好的人，年终奖拿到手之后可以踏踏实实、美滋滋的走了。绩效不好的人，估计自己心里也有数，也不指望年终奖了，可能春节前后更早就开始找下家了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有一些人，春节回老家过了个年，在年味中内心也有点小波动，打算春节之后换一个离家近的城市工作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总之，每年三、四月份，我最怕同事给我微信说&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;“四哥有空吗？我想单独和你聊聊”&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;每次看到微信里同事头像一闪，我心里就默念“不是离职，不是离职”。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然我也知道“铁打的营盘，流水的兵”，但是面对同事离职，尤其是核心骨干离职，还是非常不舍的，肯定要诚心挽留。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;老实说，挽留的成功率不高，所以留不住人的那种挫败感、无力感，可能会弄得我一天都心情不好，无心工作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;烦死了！&lt;img data-ratio=&quot;0.9576059850374065&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/6nbNnibOq5KQPpbulMSDmceTicw4Cms19Cs9Sjmic60q775yYibF2LA1ibpPo6KiccQJBc5pjvzwbCAm4Mibj2R7On11w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;401&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有人跳槽，就有岗位空出来了，就需要招人来补缺。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然是要招的人多，但是那时候看机会找工作的人也多，HR 天天都能给我发不少简历，反正是不缺简历。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;三、四月份是我看简历、面试最忙的时候。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一天面试四、五个人是常有的事儿。幸亏我是最后一轮的面试官，有些人到不了最后一轮，否则一天的时间都花在面试上了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时候我们招人就是优中选优了，或者选性价比最好的那个人。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，我认为：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;金三银四跳槽的人多，招人的岗位多，但是候选人也多，面试求职的难度随之也变大，并不一定是性价比最好的时候。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另一个跳槽旺季“金九银十”，差不多也是这个道理（因为有一些公司有半年绩效）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面重点来了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;要说性价比最好的时候，我觉得是&quot;金三银四&quot;、&quot;金九银十&quot;之后的一两个月。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还是说我们团队，旺季的时候简历多、人选多，有时候我们自己就开始嘚瑟了，总想花同样的钱找个更 NB 的人。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但是 NB 的人，别的公司也看上了，别的公司给的钱也多，NB 的人不缺 Offer，最后也没来我们这里。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在嘚瑟和犹豫不决中，旺季很快就过去了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时候我们就着急了，得赶紧招人干活啊，老板定的任务得完成啊。所以越是往后越着急，一着急招人条件也放松了，薪资也好商量了，只求你赶紧来入职吧。谈好条件，我恨不得你下周就能来上班。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你看上面我们招人是不是有点像娶媳妇找老公，年轻的时候不着急，眼光贼高，年龄大了越往后越着急……&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不只是我们团队，很多公司招人都是这么回事。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来，咱们再重点说说年末：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;年末的时候很多公司都会突击招人&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如我们部门，年初都会做 HC 预算。解释一下，HC = HeadCount 缩写，简单说就是人数、坑位数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假如 HC 预算是 100 个程序员，快到年底了，我一看现在有 90 个程序员，离预算还差 10 个人。这时候，我会尽量再招 10 个人，把预算招满。不招满的话，明年预算会减少。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以，临近年末的突击招人，也会比较着急，招聘条件自然也会放松。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;综上，我认为跳槽旺季之后的一两个月，尤其是临近年末的时候，或许是跳槽性价比最高的时间。对程序员来说，虽然年末岗位不一定很多，但是大部分程序员都在等年终奖，所以求职竞争没那么激烈，薪资也好商量。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面这张图就可以看出来，10月、11月 Offer 给的年薪明显高于其他月份。虽然是 16 年的图，但是大差不差。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3709677419354839&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/6nbNnibOq5KQPpbulMSDmceTicw4Cms19Cc6JsHAjbltWLyZ3gZRHAyjib1OH2Z5LWIbicaK2bouSGZUoUVAjwcEJg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;620&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总结一下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;跳槽旺季，岗位多，和你竞争的人也多。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;旺季之后的一两个月，可能性价比高。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;尤其临近年末，因为预算，因为别人都在等年终奖，所以竞争者少，薪资或许有惊喜。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上我是从团队管理者、面试管的角度去说的。对程序员来说，我建议大家，如果计划年后跳槽的，现在可以开始准备了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一边背题、刷题，一边看看机会，换工作要提前看，找个满意的坑不容易，早下手，多看看多比较比较。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果真遇到合适的坑了，也果断点，别太纠结年终奖啥的，如果工资涨幅满意，早去几个月，年终奖就能赚回来了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如，因为跳槽少了两个月的奖金，如果工资涨幅在 30% 以上，早去 6 个月就赚回来了，今年 10 月跳和明年 4 月跳，正好差 6 个月。这还只算了工资，还没算公积金。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;而且你在新公司的下一年，能待满一整年，能拿到足额的年终奖。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有最重要的一点，&lt;strong&gt;早就是优势&lt;/strong&gt;。同样的岗位，同样的工作，你比别人早去几个月，就能早熟悉早上手，将来的好处收益不是几个月工资能比的了的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你想想，是不是你身边有的同事，论能力、背景，你俩差不多，但是就是因为人家比你入职早，人家对业务更熟悉，和领导、同事关系更好，结果他就更受重视，发展的更好。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;就说这么多吧，今天文章字少。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;字越少，事越大。&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这篇文章不适合点在看，防止被你领导看到。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以点赞，点赞不会被别人知道，让我看看有多少人喜欢这篇文章。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果觉得有帮助，可以转发给你的朋友，让更多的人看到。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;最后推荐几篇和跳槽相关的旧文，一篇是讲简历、面试、谈薪酬技巧经验的，一篇是讲大公司、小公司区别的：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MTg3NDYwNg==&amp;amp;mid=2247484503&amp;amp;idx=1&amp;amp;sn=c7a006ddd9acb1cb104128c7d8601eab&amp;amp;chksm=fcd8c816cbaf4100d648d55111b3c360b14777a9e94c599ed6ad3e200045956df75db8e7164a&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;最全干货：从写简历，到面试、谈薪酬的那些技巧和防坑指南&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MTg3NDYwNg==&amp;amp;mid=2247485653&amp;amp;idx=1&amp;amp;sn=51e729143b9bccc28f1527c934a47ca6&amp;amp;chksm=fcd8c494cbaf4d82fb5ef9fdd0e9b3558545700ea22b13c2ce036acfa5fa1e29c38b844cf1e0&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;当年，我从小公司翻身进大公司之后……&lt;/a&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;你好，我是四猿外。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一家上市公司的技术总监，管理的技术团队一百余人。想了解我如何管理团队——&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3MTg3NDYwNg==&amp;amp;mid=2247485282&amp;amp;idx=1&amp;amp;sn=f368ffae1845809ccf06859f988a88a8&amp;amp;chksm=fcd8cb23cbaf4235db644759c3d8099045d10fc952b950d429e4a5e07ed9a806fddf85c451d3&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;我，管理100多人团队的二三事&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我从一名非计算机专业的毕业生，转行到程序员，一路打拼，一路成长。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我会通过公众号，&lt;br/&gt;把自己的成长故事写成文章，&lt;br/&gt;把枯燥的技术文章写成故事。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我建了一个读者交流群，里面大部分是程序员，一起聊技术、工作、八卦。欢迎加我微信，拉你入群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.9852216748768473&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/6nbNnibOq5KQibCDibpTo0kqofPehQvDDibibcb3bQUELdY3Knsl4r0RcgsV9l4icr3icmZQfaBXtSFNTxmdQlAZT1OQg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;609&quot;/&gt;&lt;/p&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>76023c705f4f6e2a95cc4f8dc060756a</guid>
<title>分布式服务下，消息中间件改造</title>
<link>https://toutiao.io/k/hseh6pt</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p id=&quot;js_tags&quot; class=&quot;article-tag__list single-tag__wrp js_single&quot; data-len=&quot;1&quot; role=&quot;link&quot; aria-labelledby=&quot;js_article-tag-card__left&quot; aria-describedby=&quot;js_article-tag-card__right&quot;&gt;
                                            
                                                                                    &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__left&quot; class=&quot;article-tag-card__left&quot;&gt;
                                    &lt;span class=&quot;article-tag-card__title&quot;&gt;收录于话题&lt;/span&gt;
                                    &lt;span class=&quot;article-tag__item-wrp no-active js_tag&quot; data-url=&quot;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU4Njg0MzYwNw==&amp;amp;action=getalbum&amp;amp;album_id=1327025063014596608#wechat_redirect&quot; data-tag_id=&quot;&quot; data-album_id=&quot;1327025063014596608&quot; data-tag_source=&quot;4&quot;&gt;
                                        &lt;span class=&quot;article-tag__item&quot;&gt;#分布式-数据源-中间件&lt;/span&gt;
                                    &lt;/span&gt;
                                &lt;/span&gt;
                                &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__right&quot; class=&quot;article-tag-card__right&quot;&gt;34个&lt;span class=&quot;weui-hidden_abs&quot;&gt;内容&lt;/span&gt;&lt;/span&gt;
                                                                                        &lt;/p&gt;

                
                                
                
                

                
                                                                

                
                                


                
                
                
                
                                                
                                                                
                                
                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;h1&gt;&lt;span&gt;一、背景简介&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;在系统开发初期，很容易出现这样一种情况：不同业务线上开发人员，因为技术栈和版本时间的影响，在选型的时候会优先使用自己熟悉的，例如MQ中间件常用的：Kafka、Rocket、Rabbit等，这样很容易忽略各个项目之间的组件差异问题；&lt;/p&gt;&lt;p&gt;在系统开发中后期，业务相对稳定之后，通常都会对资源占用较高的模块逐步重构，公共服务进行整合管理，从而使系统更具有整体性，在这个过程中，解决不同项目的中间件差异通常首当其冲，例如常见的缓存中心，MQ消息管理等；&lt;/p&gt;&lt;p&gt;这种情况一般来说很难避免，系统初期为了快速支撑业务，埋下很多坑点，一旦业务可以稳定发展，并且可持续性得到验证，就会开始适当考虑逐步进行模块重构，降低成本。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;二、重构思路&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;2.1 初期问题&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;在某创业公司研发初期，业务线上存在五个项目并行开发的情况，当时对于MQ的使用状况如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5730337078651685&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvDI1nPxvzGOiaxicUwtvExjhEb6qEJiaAmvFqDp1LYUsOvZuL45KENuA6oQ1IfLAttt2Siaz4ds9x3alQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;890&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Rocket：核心业务3个项目，版本有差异；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Kafka：数据权重偏高，1个项目采用；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Redis：基于Python连接，队列消息模式；&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;刚开始因为用的不多，整体还在可控范围内，后续随着业务的持续迭代，项目间出现需要通信的情况，就开始混乱难以维护，然后就是被迫开始重构，统一消息组件。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.2 二次选型&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;基于业务的综合考量，对现有几个项目进行MQ重新设计，形成的整体架构思路如下：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.42775665399239543&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvDI1nPxvzGOiaxicUwtvExjhEVPjHJXRUGfZJoTicjWH7Cfia9HO0N9nozVD0UOzPOf4ibKqnAJ09d7L2g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1052&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;MQ组件选择：采用RocketMQ；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;换掉Redis组件的队列模式；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;将基于Python的系统改Java语言；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;提供消息生产与消费两个服务；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;MQ的功能由上述服务进行统一维护；&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里在核心业务线上没有改变组件选择，换掉kafka的一个原因是涉及大量结算业务，Redis队列模式弃用，基于Python的管理系统功能不多，这里只是顺手换掉，统一业务线的编程语言。这样设计之后，从整体思路上看就会合理很多。&lt;/p&gt;&lt;h1&gt;&lt;span&gt;三、改造过程&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;3.1 整体思路&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.44064748201438847&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvDI1nPxvzGOiaxicUwtvExjhEoSChbPL7SZzqBDbWnxicV2xicCbZ7D0tApnKvwfkDtFVrk7wVTrdKEfQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1112&quot;/&gt;&lt;/p&gt;&lt;p&gt;涉及核心角色说明，从左向右依次：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;生产客户端：需要请求服务端通信的节点，调用生产服务端封装的消息发送接口即可；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;生产服务端：封装消息发送API，并维护路由管理，权限识别等，消息落地存储等；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;消息存储层：主要基于消息中间件进行存储，数据库层面用来处理特定情况下的二次调度；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;消费服务端：封装消息接收API，并根据路由标识，请求指定的消费端接口，完成通信；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;消费客户端：响应消费服务端的请求，封装消费时具体的业务逻辑；&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在整体的技术难度上没有太多差别，但是引入两个服务【生产和消费】，用来管理MQ通信流程，适配特定的业务逻辑，引入数据库做一次落地存储，在异常流程的处理上更加灵活，这样整个消息模块具有很强的可扩展性。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3.2 细节描述&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;消息中间件的选择是比较多的，但是鉴于业务线上开发人员的熟悉程度，以及参考多方提供的测试对比报告，最终确定选用RocketMQ组件，同时RocketMQ相关特点：高性能、高可靠性，以及对分布式事务的支持，也是核心的考虑因素。&lt;/p&gt;&lt;p&gt;基于当前微服务的架构模式，把MQ功能本身集成在两个核心服务中，进行统一管理和迭代，以及组件的版本控制，对于所有生产的消息，进行全局路由控制，以及特定情况下的，通过应用服务层面功能设计，实现消息延时消费，以及失败消息的二次调度执行，和部分单条消息的手动触发。&lt;/p&gt;&lt;p&gt;对消息实体进行二次存储，主要还是适配部分特定的功能点，有些消息可以延时处理，例如当MQ队列出现堆积的时候，或者达到监控的预警线时，可以通过配置手段，干预一部分消息只存储入库，不推送MQ，等待服务相对空闲的时候再去发送。&lt;/p&gt;&lt;p&gt;消息中间件作为系统间解耦的稳定支撑，在服务层面管理时，需要具备清晰的设计路线，以及流程关键节点的监控和记录，确保整个链路的稳定和容错。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;同系列&lt;/strong&gt;：&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU4Njg0MzYwNw==&amp;amp;mid=2247484591&amp;amp;idx=1&amp;amp;sn=52f4a51cb9901a208e0d6d96c0f25a1e&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;分布式概念&lt;/a&gt; | &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU4Njg0MzYwNw==&amp;amp;mid=2247484811&amp;amp;idx=1&amp;amp;sn=4dfb7feaa0e660ece9a6d91fd9731f48&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;分布式事务&lt;/a&gt; | &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU4Njg0MzYwNw==&amp;amp;mid=2247484633&amp;amp;idx=1&amp;amp;sn=ee8fcc2ce2a5b2adcd4dffe8bd0dd4cd&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;Kafka集群&lt;/a&gt; | &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU4Njg0MzYwNw==&amp;amp;mid=2247483755&amp;amp;idx=1&amp;amp;sn=9d78e7714ad4621fe5e643593069b186&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;RocketMQ组件&lt;/a&gt; | &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzU4Njg0MzYwNw==&amp;amp;mid=2247483886&amp;amp;idx=1&amp;amp;sn=2158323687acc7713d5d45c21c9558ee&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;Redis集群&lt;/a&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;四、源代码地址&lt;/span&gt;&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;GitEE·地址&lt;br/&gt;https://gitee.com/cicadasmile&lt;br/&gt;Wiki·地址&lt;br/&gt;https://gitee.com/cicadasmile/butte-java-note/wikis&lt;/code&gt;&lt;/pre&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU4Njg0MzYwNw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/uUIibyNXbAvBCuF3zfJnqPKpUia4wfn1FUtTHpxxkR5HvbicPgOjibPicX0goMOkny1NdkLAJvBaqrYh3UdwMjiaDQMA/0?wx_fmt=png&quot; data-nickname=&quot;知了一笑&quot; data-alias=&quot;cicada_smile&quot; data-signature=&quot;积累是一个孤独且枯燥的过程&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c6e2b0fcf83c2caf36a39cf00e36b1df</guid>
<title>并发编程：乱序执行的那些事儿</title>
<link>https://toutiao.io/k/qus2pec</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;什么是乱序执行&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;乱序执行&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;，简单说就是程序里面的代码的执行顺序，有可能会被编译器、CPU 根据某种策略调整顺序（俗称，“打乱”）——虽然从单线程的角度看，乱序执行不影响执行结果。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;为什么需要乱序执行&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;主要原因是 CPU 内部采用&lt;span&gt;流水线技术&lt;/span&gt;&lt;sup&gt;[2]&lt;/sup&gt;。抽象且简化地看，一个 CPU 指令的执行过程可以分成 4 个阶段：取指、译码、执行、写回。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这 4 个阶段分别由 4 个独立物理执行单元来完成。这种情况下，如果指令之间没有依赖关系，后一条指令并不需要等到前一条指令完全执行完成再开始执行。而是前一条指令完成取指之后，后一条指令便可以开始执行取指操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比较理想的情况如下图所示：指令之间无依赖，可以使流水线的并行度最大化。&lt;img data-ratio=&quot;0.30192962542565266&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9637P74IBOHW1nlxA0eFXR2tDcdWManmEqLAKxwl4fibejHGTW1b2MvHCEe69xeToWWzgxGHicaNX44C15ntuiaXw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;881&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在&lt;strong&gt;按序执行&lt;/strong&gt;的情况下，一旦遇到指令依赖的情况，流水线就会停滞。比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;指令 &lt;span&gt;1&lt;/span&gt;: Load R3 &amp;lt;- R1(&lt;span&gt;0&lt;/span&gt;)    # 从内存中加载数据到 R3 寄存器&lt;br/&gt;指令 &lt;span&gt;2&lt;/span&gt;: Add  R3 &amp;lt;- R3, R1   # 加法，依赖指令 &lt;span&gt;1&lt;/span&gt; 的执行结果&lt;br/&gt;指令 &lt;span&gt;3&lt;/span&gt;: Sub  R1 &amp;lt;- R6, R7   # 减法&lt;br/&gt;指令 &lt;span&gt;4&lt;/span&gt;: Add  R4 &amp;lt;- R6, R8   # 加法&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的伪代码中，指令 2 依赖指令 1 的执行结果。在指令 1 执行完成之前，指令 2 无法执行，这会让流水线的执行效率大大降低。&lt;img data-ratio=&quot;0.2252328535139712&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9637P74IBOHW1nlxA0eFXR2tDcdWManmFYqB5UHTIcPSF4VNx0rZvTzzs4TFjtwhbkShR7jA2qLpicDMy1uPBVQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1181&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;观察到，指令 3 和指令 4 对其它指令没有依赖，可以考虑将这两条指令”乱序“到指令 2 之前。&lt;img data-ratio=&quot;0.2711518858307849&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9637P74IBOHW1nlxA0eFXR2tDcdWManm0CWWUOcjYxeadgb0T0MSh8rQH9xnmTiaSiahJa7jXQWH848gNODjECfw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;981&quot;/&gt;这样，流水线执行单元就可以尽可能处于工作状态。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总的来说，通过乱序执行，合理调整指令的执行顺序，可以提高流水线的运行效率，让指令的执行能够尽可能地并行起来。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;Compiler Fence&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在多线程的环境下，乱序执行的存在，很容易打破一些预期，造成一些意想不到的问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;乱序执行有两种情况：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;在编译期，编译器进行指令重排。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在运行期，CPU 进行指令乱序执行。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们先来看一个编译器指令重排的例子：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;atomic&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 按序递增发号器&lt;/span&gt;&lt;br/&gt;&lt;span&gt;std&lt;/span&gt;::atomic&amp;lt;&lt;span&gt;int&lt;/span&gt;&amp;gt; timestamp_oracle{&lt;span&gt;0&lt;/span&gt;};&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 当前处理的号码&lt;/span&gt;&lt;br/&gt;&lt;span&gt;int&lt;/span&gt; now_serving_ts{&lt;span&gt;0&lt;/span&gt;};&lt;br/&gt;&lt;br/&gt;&lt;span&gt;int&lt;/span&gt; shared_value;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;compute&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;memory_reorder&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;// 原子地获取一个号码&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;int&lt;/span&gt; ts = timestamp_oracle.fetch_add(&lt;span&gt;1&lt;/span&gt;);&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// 加锁：判断当前是否轮到这个号码，否则就循环等&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt; (now_serving_ts != ts);&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// 临界区：开始处理请求&lt;/span&gt;&lt;br/&gt;    shared_value = compute();&lt;br/&gt;    &lt;br/&gt;    &lt;span&gt;// 编译器 memory barrier&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;asm&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt;&lt;span&gt;(&lt;span&gt;&quot;&quot;&lt;/span&gt; : : : &lt;span&gt;&quot;memory&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// 解锁：下一个要处理的号码&lt;/span&gt;&lt;br/&gt;    now_serving_ts = ts + &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单解释一下这段代码：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;这个程序通过维护一个“发号器 timestamp_oracle”，来实现按顺序处理每个线程的请求。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;每个线程先从“发号器”取一个号，然后不停判断当前是否轮到自己执行，类似自旋锁的逻辑。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;每个线程执行完，将“号码”切换到下一个。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 O1 的编译优化选项下，编译出来的汇编指令没有被重排（通过左右两边的代码行背景色就可以看出来）。&lt;img data-ratio=&quot;0.44094955489614246&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9637P74IBOHW1nlxA0eFXR2tDcdWManmRfz8j3EibXK9eEYduBJwjZAUE4XsHRfClKq3XicBspAqYxyAYCtoEZXw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1685&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在 O2 的编译优化选项下，出现了指令被重排了，并且这里的指令重排打破了程序的预期，先切换了 now_serving_ts，再更新 shared_value，导致 shared_value 可能被并发修改。&lt;img data-ratio=&quot;0.47041420118343197&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9637P74IBOHW1nlxA0eFXR2tDcdWManmWRdaz3eFXaaTibibHoHibmk8kRmCmmhoMgRXicibTuggxX2rVd8mbB3R0qg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1690&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了阻止编译器重排这两句代码的指令，需要在它们之间插入一个 compiler fence。&lt;img data-ratio=&quot;0.5121517486662714&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9637P74IBOHW1nlxA0eFXR2tDcdWManmPwYZd252Tg5xciawkmhmd7Y1fz5ibnzg7VzUjjdEpcSic6O26ZdxQ65vA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1687&quot;/&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;asm&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt;&lt;span&gt;(&lt;span&gt;&quot;&quot;&lt;/span&gt;: : :&lt;span&gt;&quot;memory&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个是 GCC 扩展的 compiler fence 的写法。这条指令告诉编译器（&lt;span&gt;GCC 官方文档&lt;/span&gt;&lt;sup&gt;[3]&lt;/sup&gt;）：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;防止这条 fence 指令上方的内存访问操作被移到下方，同时防止下方的内存访问操作移到上面，也就是防止了乱序。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;让编译器把所有缓存在寄存器中的内存变量 flush 到内存中，然后重新从内存中读取这些值。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于第 2 点，有时候我们只需要刷新部分变量。刷新所有寄存器并不一定完全符合我们的预期，并且会引入不必要的开销。GCC 支持指定变量的 compiler fence。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;write(x)&lt;br/&gt;asm volatile(&lt;span&gt;&quot;&quot;&lt;/span&gt;: &lt;span&gt;&quot;=m&quot;&lt;/span&gt;(y) : &lt;span&gt;&quot;m&quot;&lt;/span&gt;(x):)&lt;br/&gt;read(y)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;中间的内联汇编指令告诉编译器不要把 write(x) 和 read(y) 这两个操作乱序。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;CPU Fence&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;先来看一个例子：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;int x = 0;&lt;br/&gt;int y = 0;&lt;br/&gt;&lt;br/&gt;int r0, r1;&lt;br/&gt;&lt;br/&gt;// CPU1&lt;br/&gt;void &lt;span&gt;&lt;span&gt;f1&lt;/span&gt;&lt;/span&gt;()&lt;br/&gt;{&lt;br/&gt;    x = 1;&lt;br/&gt;    asm volatile(&lt;span&gt;&quot;&quot;&lt;/span&gt;: : :&lt;span&gt;&quot;memory&quot;&lt;/span&gt;);&lt;br/&gt;    r0 = y; &lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// CPU2&lt;br/&gt;void &lt;span&gt;&lt;span&gt;f2&lt;/span&gt;&lt;/span&gt;()&lt;br/&gt;{&lt;br/&gt;    y = 1;&lt;br/&gt;    asm volatile(&lt;span&gt;&quot;&quot;&lt;/span&gt;: : :&lt;span&gt;&quot;memory&quot;&lt;/span&gt;);&lt;br/&gt;    r1 = x;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4311377245508982&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/9637P74IBOHW1nlxA0eFXR2tDcdWManmxJPzKzetWxV5tEOmYQQTJ2y3AYQD12FR1MopLX0UfdrAibKhIb4M2rg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1002&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的例子中，由于 compiler fence 的存在，编译器不会对函数 f1 和函数 f2 内部的指令进行重排。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此时，如果 CPU 执行时也没有乱序，是不可能出现 &lt;code&gt;r0 == 0 &amp;amp;&amp;amp; r1 == 0&lt;/code&gt; 的情况的。不幸的是，由于 CPU 乱序执行的存在，这种情况是可能发生的。看下面这个例子：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;#&lt;span&gt;include&lt;/span&gt; &lt;span&gt;&amp;lt;thread&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;int&lt;/span&gt; x = &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;&lt;span&gt;int&lt;/span&gt; y = &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;int&lt;/span&gt; r0 = &lt;span&gt;100&lt;/span&gt;;&lt;br/&gt;&lt;span&gt;int&lt;/span&gt; r1 = &lt;span&gt;100&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;f1&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    x = &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;asm&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt;&lt;span&gt;(&lt;span&gt;&quot;&quot;&lt;/span&gt;: : :&lt;span&gt;&quot;memory&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;    r0 = y;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;f2&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    y = &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;asm&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt;&lt;span&gt;(&lt;span&gt;&quot;&quot;&lt;/span&gt;: : :&lt;span&gt;&quot;memory&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;    r1 = x;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;init&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    x = &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;    y = &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;    r0 = &lt;span&gt;100&lt;/span&gt;;&lt;br/&gt;    r1 = &lt;span&gt;100&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;bool&lt;/span&gt; &lt;span&gt;check&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; r0 == &lt;span&gt;0&lt;/span&gt; &amp;amp;&amp;amp; r1 == &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;std&lt;/span&gt;::atomic&amp;lt;&lt;span&gt;bool&lt;/span&gt;&amp;gt; wait1{&lt;span&gt;true&lt;/span&gt;};&lt;br/&gt;&lt;span&gt;std&lt;/span&gt;::atomic&amp;lt;&lt;span&gt;bool&lt;/span&gt;&amp;gt; wait2{&lt;span&gt;true&lt;/span&gt;};&lt;br/&gt;&lt;span&gt;std&lt;/span&gt;::atomic&amp;lt;&lt;span&gt;bool&lt;/span&gt;&amp;gt; stop{&lt;span&gt;false&lt;/span&gt;};&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;loop1&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt;(!stop.load(&lt;span&gt;std&lt;/span&gt;::memory_order_relaxed)) {&lt;br/&gt;        &lt;span&gt;while&lt;/span&gt; (wait1.load(&lt;span&gt;std&lt;/span&gt;::memory_order_relaxed));&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;asm&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt;&lt;span&gt;(&lt;span&gt;&quot;&quot;&lt;/span&gt; ::: &lt;span&gt;&quot;memory&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;        f1();&lt;br/&gt;        &lt;span&gt;&lt;span&gt;asm&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt;&lt;span&gt;(&lt;span&gt;&quot;&quot;&lt;/span&gt; ::: &lt;span&gt;&quot;memory&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;        wait1.store(&lt;span&gt;true&lt;/span&gt;, &lt;span&gt;std&lt;/span&gt;::memory_order_relaxed);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;loop2&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt; (!stop.load(&lt;span&gt;std&lt;/span&gt;::memory_order_relaxed)) {&lt;br/&gt;        &lt;span&gt;while&lt;/span&gt; (wait2.load(&lt;span&gt;std&lt;/span&gt;::memory_order_relaxed));&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;&lt;span&gt;asm&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt;&lt;span&gt;(&lt;span&gt;&quot;&quot;&lt;/span&gt; ::: &lt;span&gt;&quot;memory&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;        f2();&lt;br/&gt;        &lt;span&gt;&lt;span&gt;asm&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt;&lt;span&gt;(&lt;span&gt;&quot;&quot;&lt;/span&gt; ::: &lt;span&gt;&quot;memory&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;        wait2.store(&lt;span&gt;true&lt;/span&gt;, &lt;span&gt;std&lt;/span&gt;::memory_order_relaxed);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;int&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;&lt;span&gt;std&lt;/span&gt;::thread &lt;span&gt;thread1&lt;/span&gt;&lt;span&gt;(loop1)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;std&lt;/span&gt;::thread &lt;span&gt;thread2&lt;/span&gt;&lt;span&gt;(loop2)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;long&lt;/span&gt; count = &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt;(&lt;span&gt;true&lt;/span&gt;) {&lt;br/&gt;        count++;&lt;br/&gt;        init();&lt;br/&gt;        &lt;span&gt;&lt;span&gt;asm&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt;&lt;span&gt;(&lt;span&gt;&quot;&quot;&lt;/span&gt; ::: &lt;span&gt;&quot;memory&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;        wait1.store(&lt;span&gt;false&lt;/span&gt;, &lt;span&gt;std&lt;/span&gt;::memory_order_relaxed);&lt;br/&gt;        wait2.store(&lt;span&gt;false&lt;/span&gt;, &lt;span&gt;std&lt;/span&gt;::memory_order_relaxed);&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;while&lt;/span&gt; (!wait1.load(&lt;span&gt;std&lt;/span&gt;::memory_order_relaxed));&lt;br/&gt;        &lt;span&gt;while&lt;/span&gt; (!wait2.load(&lt;span&gt;std&lt;/span&gt;::memory_order_relaxed));&lt;br/&gt;        &lt;span&gt;&lt;span&gt;asm&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt;&lt;span&gt;(&lt;span&gt;&quot;&quot;&lt;/span&gt; ::: &lt;span&gt;&quot;memory&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (check()) {&lt;br/&gt;            &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;&quot;test count &quot;&lt;/span&gt; &amp;lt;&amp;lt; count &amp;lt;&amp;lt; &lt;span&gt;&quot;: r0 == &quot;&lt;/span&gt; &amp;lt;&amp;lt; r0 &amp;lt;&amp;lt; &lt;span&gt;&quot; &amp;amp;&amp;amp; r1 == &quot;&lt;/span&gt; &amp;lt;&amp;lt; r1 &amp;lt;&amp;lt; &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;endl&lt;/span&gt;;&lt;br/&gt;            &lt;span&gt;break&lt;/span&gt;;&lt;br/&gt;        } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; (count % &lt;span&gt;10000&lt;/span&gt; == &lt;span&gt;0&lt;/span&gt;) {&lt;br/&gt;                &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;&quot;test count &quot;&lt;/span&gt; &amp;lt;&amp;lt; count &amp;lt;&amp;lt; &lt;span&gt;&quot;: OK&quot;&lt;/span&gt; &amp;lt;&amp;lt; &lt;span&gt;std&lt;/span&gt;::&lt;span&gt;endl&lt;/span&gt;;&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    stop.store(&lt;span&gt;true&lt;/span&gt;);&lt;br/&gt;    wait1.store(&lt;span&gt;false&lt;/span&gt;);&lt;br/&gt;    wait2.store(&lt;span&gt;false&lt;/span&gt;);&lt;br/&gt;    thread1.join();&lt;br/&gt;    thread2.join();&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的程序可以很轻易就运行出 r0 == 0 &amp;amp;&amp;amp; r1 == 0 的结果，比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;test count &lt;span&gt;56&lt;/span&gt;: r0 == &lt;span&gt;0&lt;/span&gt; &amp;amp;&amp;amp; r1 == &lt;span&gt;0&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了防止 CPU 乱序执行，需要使用 CPU fence。我们可以将函数 f1 和 f2 中的 compiler fence 修改为 CPU fence：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;f1&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    x = &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;asm&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt;&lt;span&gt;(&lt;span&gt;&quot;mfence&quot;&lt;/span&gt;: : :&lt;span&gt;&quot;memory&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;    r0 = y;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;void&lt;/span&gt; &lt;span&gt;f2&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    y = &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;asm&lt;/span&gt; &lt;span&gt;volatile&lt;/span&gt;&lt;span&gt;(&lt;span&gt;&quot;mfence&quot;&lt;/span&gt;: : :&lt;span&gt;&quot;memory&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;;&lt;br/&gt;    r1 = x;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如此，便不会出现 &lt;code&gt;r0 == 0 &amp;amp;&amp;amp; r1 == 0&lt;/code&gt; 的情况了。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;总结&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;指令乱序执行主要由两种因素导致：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;编译期指令重排。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;运行期 CPU 乱序执行。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;无论是编译期的指令重排还是 CPU 的乱序执行，主要都是为了让 CPU 内部的指令流水线可以“充满”，提高指令执行的并行度。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面举的插入 fence 的例子都是使用了 GCC 的扩展语法，实际上 C++ 标准库已经提供了类似的封装：&lt;span&gt;std::atomic_thread_fence&lt;/span&gt;&lt;sup&gt;[4]&lt;/sup&gt;，跨平台且可读性更好。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一些无锁编程、追求极致性能的场景可能会需要手动在合适的地方插入合适 fence，这里涉及的细节太多，非常容易出错。原子变量操作根据不同的 memory order 会自动插入合适的 fence，建议优先考虑使用原子变量。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;乱序执行: &lt;em&gt;https://en.wikipedia.org/wiki/Out-of-order_execution&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;p&gt;流水线技术: &lt;em&gt;https://en.wikipedia.org/wiki/Instruction_pipelining&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[3]&lt;/span&gt;&lt;p&gt;GCC 官方文档: &lt;em&gt;https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html#Clobbers-and-Scratch-Registers&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[4]&lt;/span&gt;&lt;p&gt;std::atomic_thread_fence: &lt;em&gt;https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a331fe91cfc6ec7bf0ca37730296c87d</guid>
<title>面试官：说下你对方法区演变过程和内部结构的理解</title>
<link>https://toutiao.io/k/rctfy0i</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前我们已经了解过“运行时数据区”的程序计数器、虚拟机栈、本地方法栈和堆空间，今天我们就来了解一下最后一个模块——方法区。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.42424242424242425&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/55HPQyguvpNO0mrHPOTbFIkP3fI9IOhKKBDCsAdicb3BM5SiaPbpjVh7oQicicNKOPc5jFpEl7qOCc6zh9auKTXGog/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;924&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;简介&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;创建对象时内存分配简图&lt;img data-ratio=&quot;0.35294117647058826&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/55HPQyguvpNO0mrHPOTbFIkP3fI9IOhKuLqlgiaNgZMicSoaE3x714vMPNvFMjqiaZaibSJp1o2Hr9EQIWQd551cpQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;561&quot;/&gt;&lt;img data-ratio=&quot;0.5610425240054869&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/55HPQyguvpNO0mrHPOTbFIkP3fI9IOhKMwKhm9RjkMSJwMib5iaQqicx93pDeqibNHGp3iaNFod4rLPllF13ib2ckezw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;729&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;《Java虚拟机规范》中明确说明：“尽管所有的方法区在逻辑上属于堆的一部分，但一些简单的实现可能不会选择去进行垃圾收集或者进行压缩。”&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。所以，方法区可以看作是一块&lt;strong&gt;独立&lt;/strong&gt;于 Java 堆的内存空间。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;方法区与 Java 堆一样，是各个线程共享的内存区域。方法区在 JVM 启动时就会被创建，并且它的实际的物理内存空间是可以&lt;strong&gt;不连续&lt;/strong&gt;的，关闭 JVM 就会释放这个区域的内存。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;永久代、元空间&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;《java虚拟机规范》对如何实现方法区，不做统一要求。例如：BEA JRockit/IBM J9 中不存在永久代的概念。而对于 HotSpot 来说，在 jdk7 及以前，习惯上把方法区的实现称为&lt;strong&gt;永久代&lt;/strong&gt;，而从 jdk8 开始，使用&lt;strong&gt;元空间&lt;/strong&gt;取代了永久代。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;方法区是 Java 虚拟机规范中的概念，而永久代和元空间是 HotSpot 虚拟机对方法区的一种实现。通俗点讲：如果把方法区比作接口的话，那永久代和元空间可以比作实现该接口的实现类。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;直接内存&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;永久代、元空间并不只是名字变了，内部结构也进行了调整。永久代使用的是 JVM 的内存，而元空间使用的是本地的直接内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;直接内存并不是 JVM 运行时数据区的一部分，因此不会受到 Java 堆的限制。但是它会受到本机总内存大小以及处理器寻址空间的限制，所以如果这部分内存也被频繁的使用，依然会导致 OOM 错误的出现。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;方法区的大小&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;方法区的大小是可以进行设置的，可以选择固定大小也可以进行扩展。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;jdk7 及以前&lt;span/&gt;&lt;/h4&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;-XX:PermSize=N //方法区 (永久代) 初始分配空间，默认值为 20.75M&lt;br/&gt;-XX:MaxPermSize=N //方法区 (永久代) 最大可分配空间。32位机器默认是64M，64位机器默认是82M&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;jdk8及以后&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;默认值依赖于平台，windows下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;-XX:MetaspaceSize=N //方法区 (元空间) 初始分配空间，如果未指定此标志，则元空间将根据运行时的应用程序需求动态地重新调整大小。&lt;br/&gt;-XX:MaxMetaspaceSize=N //方法区 (元空间) 最大可分配空间，默认值为 -1，即没有限制&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;与永久代很大的不同就是，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，比如：加载大量的第三方 jar 包、Tomcat 部署的工程过多、大量动态生成反射类等都会导致方法区溢出，抛出内存溢出错误。&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;永久代：OutOfMemoryError:PermGen space&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;元空间：OutOfMemoryError:Metaspace&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;至于如何解决 OOM 异常，将在以后的文章中讲解！&lt;/strong&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;jvisualvm&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以通过 JDK 自带的 &lt;strong&gt;jvisualvm&lt;/strong&gt; 工具来查看程序加载的类文件：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;例&lt;/strong&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;MethodAreaDemo1&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;start...&quot;&lt;/span&gt;);&lt;br/&gt;        &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;            Thread.sleep(&lt;span&gt;1000000&lt;/span&gt;);&lt;br/&gt;        } &lt;span&gt;catch&lt;/span&gt; (InterruptedException e) {&lt;br/&gt;            e.printStackTrace();&lt;br/&gt;        }&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;end...&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行程序，可以看到一个简单的程序就需要加载这么多的类文件。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5154255319148936&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/55HPQyguvpNO0mrHPOTbFIkP3fI9IOhKGjoTpgCcUAKuicRId78MPldw9u7kAicoQ9KRz7kVr0EGnfBvq2FA6MtQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1880&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;高水位线&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于一个64位的服务器端 JVM 来说，&lt;code&gt;XX：MetaspaceSize=21&lt;/code&gt; 就是初始的高水位线，一旦触及这个水位线，Full GC 将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;新的高水位线的值取决于 GC 后释放了多少元空间：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;如果释放的空间不足，那么在不超过 MaxMetaspaceSize 时，适当提高该值；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果释放空间过多，则适当降低该值。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如果初始化的高水位线设置过低，高水位线调整情况会发生很多次。通过垃圾回收器的日志可以观察到 Full GC 多次调用。为了避免频繁地GC，建议将 &lt;code&gt;-XX ：MetaspaceSize&lt;/code&gt; 设置为一个相对较高的值。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;内部结构&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;《深入理解Java虚拟机》书中对方法区存储内容描述如下：它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。接下来我们就一起来看一下它的内部结构。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.16718266253869968&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/55HPQyguvpNO0mrHPOTbFIkP3fI9IOhKzMleiaFRv2bjqBeSBxRaWG9c7ibUIO7CLTDzWgEMriaQFthFWhw5hvAAw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;969&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;类型信息&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对每个加载的类型（ 类 class、接口 interface、枚举 enum、注解 annotation），JVM 必须在方法区中存储以下类型信息：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;这个类型的完整有效名称（全名=包名.类名）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;这个类型直接父类的完整有效名（对于 interface 或是 java. lang.Object ，都没有父类）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;这个类型的修饰符（ public ， abstract， final 的某个子集）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;这个类型直接接口的一个有序列表&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;域（Field）信息&lt;span/&gt;&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;JVM必须在方法区中保存类型的所有域（field，也称为属性）的相关信息以及域的声明顺序；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;域的相关信息包括：域名称、 域类型、域修饰符（public， private，protected， static， final， volatile， transient 的某个子集）&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;方法（Method）信息&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;JVM 必须保存所有方法的以下信息，同域信息一样包括声明顺序：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;方法名称&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;方法的返回类型（或void）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;方法参数的数量和类型（按顺序）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;方法的修饰符（public， private， protected， static， final，synchronized， native ， abstract 的一个子集）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;方法的字节码（bytecodes）、操作数栈、局部变量表及大小（ abstract 和 native 方法除外）&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;异常表（ abstract 和 native 方法除外）每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;non-final 的类变量&lt;span/&gt;&lt;/h3&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;静态变量和类关联在一起，随着类的加载而加载，他们成为类数据在逻辑上的一部分&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;类变量被类的所有实例所共享，即使没有类实例你也可以访问它。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以通过例子来查看：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;MethodAreaDemo2&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        Order order = &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;        order.hello();&lt;br/&gt;        System.out.println(order.count);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;Order&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; count = &lt;span&gt;1&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; number = &lt;span&gt;2&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;hello&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;hello!&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行结果为：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;hello!&lt;br/&gt;&lt;span&gt;1&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以打开 IDEA 的 Terminal 窗口，在 MethodAreaDemo2.class 所在的路径下，输入 &lt;code&gt;javap -v -p MethodAreaDemo2.class&lt;/code&gt; 命令&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3969359331476323&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/55HPQyguvpNO0mrHPOTbFIkP3fI9IOhKkHrIicXFB5ibT5ZAtsPTOkBQhbxh2sLAg3dScoD7fwXyylYnQeib618aw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;718&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过图片我们可以看出被声明为 final 的类变量的处理方法是不一样的，全局常量在编译的时候就被分配了。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;运行时常量池&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说到运行时常量池，我们先来了解一下什么是常量池表。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;常量池表&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述信息外，还包含一项信息那就是常量池表（Constant Pool Table），里边存储着&lt;strong&gt;数量值&lt;/strong&gt;、&lt;strong&gt;字符串值&lt;/strong&gt;、&lt;strong&gt;类引用&lt;/strong&gt;、&lt;strong&gt;字段引用&lt;/strong&gt;和&lt;strong&gt;方法引用&lt;/strong&gt;。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5986238532110092&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/55HPQyguvpNO0mrHPOTbFIkP3fI9IOhKbnibMl97oKg3Oib7wZygNpM8VOKDNeNDVq7dDGAGaOtLzBicK3oiaBonng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1308&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;为什么字节码文件需要常量池？&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;java 源文件中的类、接口，编译后会产生一个字节码文件。而字节码文件需要数据支持，通常这种数据会很大，以至于不能直接存放到字节码中。换一种方式，可以将指向这些数据的&lt;strong&gt;符号引用&lt;/strong&gt;存到字节码文件的常量池中，这样字节码只需使用常量池就可以在运行时通过&lt;strong&gt;动态链接&lt;/strong&gt;找到相应的数据并使用。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;运行时常量池&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行时常量池（ &lt;code&gt;Runtime Constant Pool&lt;/code&gt;）是方法区的一部分，类加载器加载字节码文件时，将常量池表加载进方法区的运行时常量池。运行时常量池中包含多种不同的常量，包括编译期就已经明确的数值字面量，也包括到运行期解析后才能够获得的方法或者字段引用。此时不再是常量池中的符号地址了，这里换为&lt;strong&gt;真实&lt;/strong&gt;地址。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;运行时常量池，相对于 Class 文件常量池的另一重要特征是：具备动态性，比如 &lt;code&gt;String.intern()&lt;/code&gt;。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;演进细节&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;针对的是 &lt;strong&gt;Hotspot&lt;/strong&gt; 的虚拟机：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;jdk1.6 及之前：有&lt;strong&gt;永久代&lt;/strong&gt; ，静态变量存放在永久代上；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;jdk1.7：有&lt;strong&gt;永久代&lt;/strong&gt;，但已经逐步“去永久代”，字符串常量池、静态变量移除，保存在堆中；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;jdk1.8及之后：无永久代，类型信息、字段、方法、常量保存在本地内存的&lt;strong&gt;元空间&lt;/strong&gt;，但字符串常量池、静态变量仍在堆中；&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;演变示例图&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5350404312668463&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/55HPQyguvpNO0mrHPOTbFIkP3fI9IOhKadYK1fdKFJwTGN0yUkBJQDdzgDouLlJBcYvh69ibGafy3pEeLh6jiaVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;742&quot;/&gt;&lt;img data-ratio=&quot;0.5197183098591549&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/55HPQyguvpNO0mrHPOTbFIkP3fI9IOhKzKCDtice7jMa3ra13n69gqdo7KZxVicqIJOr0v0n7gttFswznu8tHq0w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;710&quot;/&gt;&lt;img data-ratio=&quot;0.43800904977375565&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/55HPQyguvpNO0mrHPOTbFIkP3fI9IOhKybrNQDch78E1IAWbqiaic6wKYZC1kF1bDO9D5nNibUvNoPeH92JcsNnMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1105&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;为什么要将永久代替换为元空间呢?&lt;span/&gt;&lt;/h3&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;永久代使用的是 JVM 的内存，受 JVM 设置的内存大小限制；元空间使用的是本地直接内存，它的最大可分配空间是系统可用内存的空间。因为元空间里存放的是类的&lt;strong&gt;元数据&lt;/strong&gt;，所以随着内存空间的增大，能加载的类就更多了，相应的溢出的机率会大大减小。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;在 JDK8，合并 HotSpot 和 JRockit 的代码时，JRockit 从来没有一个叫永久代的东西，合并之后就没有必要额外的设置这么一个永久代的地方了。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;对永久代进行调优是很困难的。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;StringTable 为什么要调整&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为永久代的回收效率很低，在 full gc 的时候才会触发。而 full GC 是老年代的空间不足、永久代不足时才会触发。这就导致了&lt;code&gt;StringTable&lt;/code&gt; 回收效率不高。而我们开发中会有大量的字符串被创建，回收效率低，导致永久代内存不足。放到堆里，能及时回收内存。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;垃圾回收&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入方法区后就“永久存在”了。方法区的垃圾收集主要回收两部分内容：常量池中废奔的&lt;strong&gt;常量&lt;/strong&gt;和不再使用的&lt;strong&gt;类型&lt;/strong&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;方法区内常量池中主要存放字面量和符号引用两大类常量：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;字面量比较接近 Java 语言层次的常量概念，如文本字符串、被声明为 final 的常量值等。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;符号引用则属于编译原理方面的概念，包括类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;HotSpot 虚拟机对常量池的回收策略是很明确的，只要常量池中的常量没有被任何地方引用，就可以被回收。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;类型判定&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;判定一个常量是否“废弃”还是相对简单，而要判定一个类型是否属于“不再被使用的类”的条件就比较苛刻了。需要同时满足下面三个条件：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;该类所有的&lt;strong&gt;实例&lt;/strong&gt;都已经被回收，也就是 Java 堆中不存在该类及其任何派生子类的实例；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;加载该类的&lt;strong&gt;类加载器&lt;/strong&gt;已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如OSGi、JSP的重加载等，否则通常是很难达成的；&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Java 虛拟机被允许对满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，没有引用了就必然会回收。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上就是今天的全部内容了，如果你有不同的意见或者更好的&lt;code&gt;idea&lt;/code&gt;，欢迎联系阿Q，添加阿Q可以加入&lt;strong&gt;技术交流群&lt;/strong&gt;参与讨论呦！&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzI5MDg2NjEzNA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/55HPQyguvpMAn4Ha81WVBfsKnC9ficVemZff27LiaSoKX83JqwnNmrNhb4D4oAjW7wiaDwtkLTTCRs1A1hanfNu9g/0?wx_fmt=png&quot; data-nickname=&quot;阿Q说代码&quot; data-alias=&quot;AQ_Shuo&quot; data-signature=&quot;专注于后端技术栈分享：文章风格多变、配图通俗易懂、故事生动有趣&quot; data-from=&quot;1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>34d64247764aef0d5709782679fa9487</guid>
<title>Apache Flink 在汽车之家的应用与实践</title>
<link>https://toutiao.io/k/s9l41rn</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p id=&quot;js_tags&quot; class=&quot;article-tag__list single-tag__wrp js_single&quot; data-len=&quot;1&quot; role=&quot;link&quot; aria-labelledby=&quot;js_article-tag-card__left&quot; aria-describedby=&quot;js_article-tag-card__right&quot;&gt;
                                            
                                                                                    &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__left&quot; class=&quot;article-tag-card__left&quot;&gt;
                                    &lt;span class=&quot;article-tag-card__title&quot;&gt;收录于话题&lt;/span&gt;
                                    &lt;span class=&quot;article-tag__item-wrp no-active js_tag&quot; data-url=&quot;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU3Mzg4OTMyNQ==&amp;amp;action=getalbum&amp;amp;album_id=1929702550740484100#wechat_redirect&quot; data-tag_id=&quot;&quot; data-album_id=&quot;1929702550740484100&quot; data-tag_source=&quot;4&quot;&gt;
                                        &lt;span class=&quot;article-tag__item&quot;&gt;#行业案例&lt;/span&gt;
                                    &lt;/span&gt;
                                &lt;/span&gt;
                                &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__right&quot; class=&quot;article-tag-card__right&quot;&gt;49个&lt;span class=&quot;weui-hidden_abs&quot;&gt;内容&lt;/span&gt;&lt;/span&gt;
                                                                                        &lt;/p&gt;

                
                                
                
                

                
                                                                

                
                                


                
                
                
                
                                                
                                                                
                                
                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section&gt;&lt;span&gt;▼ 关注「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Flink 中文社区&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，获取更多技术干货 &lt;span&gt;▼&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU3Mzg4OTMyNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6FJHxaI14AsXuzeg4SybT0hiaCSohrIY75oiaOMzhQU7RouiafjNa76k2CtD6xxB2JqnawqFqV3zg3A/0?wx_fmt=png&quot; data-nickname=&quot;Flink 中文社区&quot; data-alias=&quot;&quot; data-signature=&quot;Apache Flink 官微，Flink PMC 维护&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;span&gt;本&lt;/span&gt;&lt;/span&gt;&lt;span&gt;文整理自汽车之家实时计算平台负责人邸星星在 Flink Forward Asia 2020 分享的议题《Apache Flink 在汽车之家的应用及实践》。主要内容包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;背景及现状&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;AutoStream 平台&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;基于 Flink 的实时生态建设&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;后续规划&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Tips：&lt;/strong&gt;&lt;span&gt;点&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;击&lt;/span&gt;&lt;span&gt;&lt;strong&gt;「阅读原&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;文」&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;即可查看作者分享原版视频～ &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img data-ratio=&quot;1&quot; data-type=&quot;png&quot; data-w=&quot;20&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu78FqIxdIQicVe5cg78bpax1XDKxMS06V8h6bib5fhicN8n5zK7Z4oDWWgzgbAeCibuKRnD5eibTcg73mg/640?wx_fmt=png&quot;/&gt; GitHub 地址 &lt;img data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu78FqIxdIQicVe5cg78bpax1XDKxMS06V8h6bib5fhicN8n5zK7Z4oDWWgzgbAeCibuKRnD5eibTcg73mg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;20&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;欢迎大家给 Flink 点赞送 star~&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.024390243902439&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu58p6JubKoFyrKVibtOyk1CTpJialGPpBBg6uRknWESa1xwDsR8yeKiah9z0lnproCED8dp6l4bmfgQQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;492&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;一、背景及现状&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1. 第一阶段&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;在 2019 年之前，汽车之家的大部分实时业务都是运行在 Storm 之上的。Storm 作为早期主流的实时计算引擎，凭借简单的 Spout 和 Bolt 编程模型以及集群本身的稳定性，俘获了大批用户，我们在 2016 年搭建了 Storm 平台。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n6&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSibnLibfH2tiaeibO6y9nE7LJqM0s6CPjTLcLLu5iaAEd1d8YlRSr6lIbRCw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;随着实时计算的需求日渐增多，数据规模逐步增大，Storm 在开发及维护成本上都凸显了不足，这里列举几个痛点:&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;开发成本高&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们一直是用的 Lambda 架构，会用 T+1 的离线数据修正实时数据，即最终以离线数据为准，所以计算口径实时要和离线完全保持一致，实时数据开发的需求文档就是离线的 SQL，实时开发人员的核心工作就是把离线的 SQL 翻译成 Storm 代码，期间虽然封装了一些通用的 Bolt 来简化开发，但把离线动辄几百行的 SQL 精准地翻译成代码还是很有挑战的，并且每次运行都要经过打包、上传、重启的一系列的繁琐操作，调试成本很高。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;计算低效&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Storm 对状态支持的不好，通常需要借助 Redis、HBase 这类 kv 存储维护中间状态，我们之前是强依赖 Redis。&lt;span&gt;比如常见的计算 UV 的场景，最简单的办法是使用 Redis 的 sadd 命令判断 uid 是否为已经存在，但这种方法会带来很高的网络 IO，同时如果没有提前报备的大促或搞活动导致流量翻倍的情况，很容易把 Redis 内存搞满，运维同学也会被杀个措手不及。同时 Redis 的吞吐能力也限制了整个作业的吞吐量。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;难以维护、管理&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;由于采用编写 Storm 代码方式开发，难以分析元数据及血缘关系，同时可读性差，计算口径不透明，业务交接成本很高。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;对数仓不友好&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;数据仓库团队是直接对接业务需求的团队，他们更熟悉基于 Hive 的 SQL 开发模式，通常都不擅长 Storm 作业的开发，这导致一些原本是实时的需求，只能退而求其次选择 T+1 的方式给出数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在这个阶段，我们支持了最基本的实时计算需求，因为开发门&lt;/span&gt;&lt;span&gt;槛比较高，很多实时业务都是由我们平台开发来完成，既做平台，又做数据开发，精力分散很严重。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;2. 第二阶段&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n32&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSnSFoNia6kk23F8a3WSeWZdWoLLbyoMiazehzZUL0QQ8K7nrLVU7qd3uQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们从 2018 年开始调研 Flink 引擎，其相对完备的 SQL 支持，天生对状态的支持吸引了我们，在经过学习调研后，2019 年初开始设计开发 Flink SQL 平台，并于 2019 年中上线了 AutoStream 1.0 平台。平台上线之初就在仓库团队、监控团队和运维团&lt;/span&gt;&lt;span&gt;队&lt;/span&gt;&lt;span&gt;得以应用，能够快速被用户主要得益于以下几点:&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;开发、维护成本低：&lt;/strong&gt;汽车之家大部分的实时任务可以用 Flink SQL + UDF 实现。平台提供常用的 Source 和 Sink，以及业务开发常用的 UDF，同时用户可以自己编写 UDF。基于  &quot;SQL + 配置&quot; 的方式完成开发，可以满足大部分需求。对于自定义任务，我们提供方便开发使用的 SDK，助力用户快速开发自定义 Flink 任务。平台面向的用户已经不只是专业的数据开发人员了，普通开发、 测试、运维人员经过基本的学习都可以在平台上完成日常的实时数据开发工作，实现平台赋能化。数据资产可管理，SQL 语句本身是结构化的，我们通过解析一个作业的 SQL，结合 source、 sink 的 DDL，可以很容易的知道这个作业的上下游，天然保留血缘关系。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;高性能：&lt;/strong&gt;&lt;span&gt;Flink 可以完全基于状态 (内存，磁盘) 做计算，对比之前依赖外部存储做计算的场景，性能提升巨大。在 818 活动压测期间，改造后的程序可以轻松支持原来几十倍流量的实时计算，且横向扩展性能十分良好。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;全面的监控报警：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;用户将任务托管在平台上，任务的存续由平台负责，用户专注于任务本身的逻辑开发本身即可。对于 SQL 任务，SQL 的可读性极高，便于维护；对于自定义任务，基于我们 SDK 开发，用户可以更专注于梳理业务逻辑上。不论是 SQL 任务还是 SDK，我们都内嵌了大量监控，并与报警平台关联，方便用户快速发现分析定位并修复任务，提高稳定性。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;赋能业务：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;支持数仓分层模型，平台提供了良好的 SQL 支持，数仓人员可以借助 SQL，将离线数仓的建设经验应用于实时数仓的建设上，自平台上线后，数仓逐步开始对接实时计算需求。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n52&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSOOgR7UhdeU5HC28jYs1sKpoWOGfeo9O0yqpaVT1jKrb3UA4VDV3Cjg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;痛点：&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;易用性有待提高，比如用户无法自助管理 UDF，只能使用平台内置的 UDF 或者把打好的 jar 包发给平台管理员，通过人工的方式处理上传问题。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;随着平台作业量的高速增长，平台 on-call 成本非常高。&lt;span&gt;首先我们经常面对一些新用户的基础问题：&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;平台的使用问题；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;开发过程中遇到的问题，比如为什么打包报错；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Flink UI 的使用问题；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;监控图形的含义，如何配置报警。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;还有一些不太容易快速给出答案的问题：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Jar 包冲突；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;为什么消费 Kafka 延迟；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;任务为什么报错。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;尤其是延迟问题，我们常见的数据倾斜，GC，反压问题可以直接引导用户去 Flink UI 和监控图表上去查看，但有时候还是需要手动去服务器上查看 jmap、jstack 等信息，有时候还需要生成火焰图来帮助用户定位性能问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;初期我们没有和运营团队合作，完全是我们开发人员直接对接处理这些问题，虽然期间补充了大量的文档，但是整体上 on-call 成本还是很高。&lt;/span&gt;&lt;/section&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在 Kafka 或 Yarn 出现故障时，没有快速恢复的方案，当面对一些重保业务时，有些捉襟见肘。众所周知，没有永远稳定，不出故障的环境或组件，当有重大故障出现时，需要有快速恢复业务的应对方案。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;资源没有合理管控，存在比较严重的资源浪费的情况。随着使用平台开发任务的用户不断增加，平台的作业数也不断增加。有些用户不能很好的把控集群资源的使用，经常出现过多申请资源的问题，导致作业运行效率低下甚至空闲，造成了资源的浪费。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在 AutoStream1.0 平台这个阶段，基于 SQL 开发的方式极大地降低了实时开发的门槛，各业务方可以自己实现实时业务的开发，同时数仓同学经过简单的学习后，就开始对接实时业务，将我们平台方从大量的业务需求中释放出来，让我们可以专心做平台方面的工作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n95&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;3. 当前阶段&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n96&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSBonaic8JxaxcGyRGdV1OKUoHCuPjpkRZeqVjF5WDbcHYdmkvqWvrUjQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;针对上面的几个方面，我们有针对性行的做了以下几点升级：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;引入 Jar Service：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;支持用户自助上传 UDF jar 包，并在 SQL 片段中自助引用，实现自助管理 UDF。同时自定义作业也可以配置 Jar Service 中的 Jar，面对多个作业共用同一个 Jar 的场景，用户只需要在作业中配置 Jar Service 中的 jar 包路径就可以，避免每次上线都重复上传 Jar 的繁琐操作；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;自助诊断：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们开发了动态调整日志级别、自助查看火焰图等功能，方便用户自己定位问题，减轻我们日常 on-call 成本；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;作业健康检查功能：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;从多个维度分析，为每个 Flink 作业打分，每个低分项都相应的给出建议；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Flink 作业级别的快速容灾恢复：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们建设了两套 YARN 环境，每一个 YARN 对应一个单独的 HDFS，两个 HDFS 之前通过 SNAPSHOT 方式进行 Checkpoint 数据的双向复制，同时在平台上增加了切换集群的功能，在一个 YARN 集群不可用的情况下，用户可以自助在平台上，选择备用集群的 Checkpoint；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Kafka 多集群架构支持：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;使用我们自研的 Kafka SDK，支持快速切换 Kafka 集群；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;对接预算系统：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;每个作业占用的资源都直接对应到预算团队，这样一定程度上保证资源不会被其他团队占用，同时每个团队的预算管理员可以查看预算使用明细，了解自己的预算支持了团队内的哪些业务。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;目前用户对平台的使用已经趋于熟悉，同时自助健康检查和自助诊断等功能的上线，我们平台方的日常 on-call 频率在逐步降低，开始逐渐进入平台建设的良性循环阶段。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n116&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;4. 应用场景&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n117&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSoNIgLxiaYh9qpGY7j3L3bcK2gv2jmOS7aVac6z3rz1iawbzVXnLQQ15w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;汽车之家用于做实时计算的数据主要分为三类：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;客户端日志，也就是我们内部说的点击流日志，包括用户端上报的启动日志、时长日志、PV 日志、点击日志以及各类事件日志，这类主要是用户行为日志，是我们建设实时数仓中流量宽表、UAS 系统、实时画像的基础，在这之上还支持了智能搜索、智能推荐等在线业务；同时基础的流量数据也用于支持各业务线的流量分析、实时效果统计，支持日常运营决策。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;服务端日志，包括 nginx 日志、各类后端应用产生的日志、各种中间件的日志。&lt;span&gt;这些日志数据主要用于后端服务的健康监测、性能监控等场景。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;业务库的实时变更记录，主要有三种：MySQL 的 binlog，SQLServer 的 CDC，TiDB 的 TiCDC 数据，基于这些实时的数据变更记录，我们通过对各种内容数据的抽象与规范，建设了内容中台、资源池等基础服务；也有一些做简单逻辑的业务数据实时统计场景，结果数据用于实时大屏、罗盘等，做数据展现。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以上这三类数据都会实时写&lt;/span&gt;&lt;span&gt;入 Kafka 集群，在 Flink 集群中针对不同场景进行计算，结果数据写入到 Redis、MySQL、Elasticsearch、HBase、Kafka、Kylin 等引擎中，用于支持上层应用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面列举了一些应用场景：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n131&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprS6pl1sM1jgdm3CD2123uBW9pBx1XGGEy5JhwSkjcIGYgReO8WbbTAYA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n134&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;5. 集群规模&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;目前 Flink 集群服务器 400+，部署模式为 YARN (80%) 和 Kubernetes，运行作业数 800+，日计算量 1 万亿，峰值每秒处理数据 2000 万条。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n137&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSx4tcdK7YSKjK9yf1yO9xKm4M5WJDctkbVpsLUe1xcrM5kYhAJz81hg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;二、AutoStream 平台&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h3 cid=&quot;n141&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h3 cid=&quot;n141&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;1. 平台架构&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n142&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.562535158447403&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprS3gMNNIdMZMRUglvNr3ibvIg5M5PuYxcVpF0ozxuFdgWIcz86Jy4I98g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;5333&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上面是 AutoStream 平台目前的整体架构，主要是以下几部分内容：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;AutoStream core System&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这是我们平台的核心服务，负责对元数据服务、Flink 客户端服务、Jar 管理服务及交互结&lt;span&gt;果查询服务进行整合，通过前端页面把平台功能暴露给用户。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;主要包括 SQL 和 Jar 作业的管理、库表信息的管理、UDF 管理、操作记录及历史版本的管理、健康检查、自助诊断、报警管理等模块，同时提供对接外部系统的能力，支持其他系统通过接口方式管理库表信息、SQL 作业信息及作业启停操作等。基于 Akka 任务的生命周期管理和调度系统提供了高效，简单，低延迟的操作保障，提升了用户使用的效率和易用性。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;元数据服务 (Catalog-like Unified Metastore)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;主要对应 Flink Catalog 的后端实现，除了支持基本的库表信息管理外，还支持库表粒度的权限控制&lt;span&gt;，结合我们自身的特点，支持用户组级别的授权。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;底层我们提供了 Plugin Catalog 机制，既可以用于和 Flink 已有的 Catalog 实现做集成，也可以方便我们嵌入自定义的 Catalogs，通过 Plugin 机制可以很容易的重用 HiveCatalog，JdbcCatalog 等，从而保证了库表的周期的一致性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;同时元数据服务还负责对用户提交的 DML 语句进行解析，识别当前作业的依赖的表信息，用于作业的分析及提交过程，同时可以记录血缘关系。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Jar Service&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;平台提供的各类 SDK 在 Jar Service 上进行统一管理，同时用户也可以在平台上把自定义 Jar、UDF jar 等提交到 Jar Service 上统一管理，然后在作业中通过配置或 DDL 引用。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Flink 客户端服务 (Customed Flink Job Client)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;负责把平台上的作业转化成 Flink Job 提交到 Yarn 或 Kubernetes 上，我们在这一层针对 Yarn 和 Kubernetes 做了抽象，统一两种调度框架的行为，对外暴露统一接口及规范化的参数，弱化 Yarn 和 Kubernetes 的差异，为 Flink 作业在两种框架上无缝切换打&lt;span&gt;下了良好的基础。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;每个作业的依赖不尽相同，我们除了对基础依赖的管理以外，还需要支持个性化的依赖。比如不同版本的 SQL SDK，用户自助上传的 Jar、UDF 等，所以不同作业的提交阶段需要做隔离。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;我们采用的是 Jar service + 进程隔离的方式，通过和 Jar Service 对接，根据作业的类型和配置，选用相应的 Jar，并且提交单独的进程中执行，实现物理隔离。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;结果缓存服务 (Result Cache Serivce)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;是一个简易的缓存服务，用于 SQL 作业开发阶段的在线调试场景。&lt;span&gt;当我们分析出用户的 SQL 语句，将 Select 语句的结果集存入缓存服务中；然后用户可以在平台上通过选择 SQL 序号 (每个完整的 SELECT 语句对应一个序号)，实时查看 SQL 对应的结果数据，方便用户开发与分析问题。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;内置Connectors (Source &amp;amp; Sink)&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;最右侧的部分主要是各种 &lt;span&gt;Source、Sink 的实现，有一些是重用 Flink 提供的 connector，有一些是我们自己开发的 connector。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;针对每一种 connector 我们都添加了必要 Metric，并配置成单独的监控图表，方便用户了解作业运行情况，同时也为定位问题提供数据依据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n188&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;2. 基于 SQL 的开发流程&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在平台提供以上功能的基础上，用户可以快速的实现 SQL 作业的开发：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;创建一个 SQL 任务；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;编写 DDL 声明 Source 和 Sink；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;编写 DML，完成主要业务逻辑的实现；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在线查看结果，若数据符合预期，添加 INSERT INTO 语句，写入到指定 Sink 中即可。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n200&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSwKFymbBVia3PDOSlsQcfJpluxGVN8icia02A6rD8w0NcVq32tYTxKlGvA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;平台默认会保存 SQL 每一次的变更记录，用户可以在线查看历史版本，同时我们会记录针对作业的各种操作，在作业维护阶段可以帮助用户追溯变更历史，定位问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面是一个 Demo，用于统计当天的 PV、UV 数据：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n206&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSS42lR2RjVd1G16QltdIesN4MlciciaW2BiaRd0rSPO5kQxf8Xia8xgvjxQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n208&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;3. 基于 Catalog 的元数据管理&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n209&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSuP6SsiaQ8QDBl6EpuOE3Vj7EBKFZiaqnzZqwicK8icUqX6ofxZ9QP5JouQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;元数据管理的主要内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;支持权限控制：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;除了支持基本的库表信息管理外，还支持表粒度的权限控制，结合我们自身的&lt;span&gt;特点，支持用户组级别的授权；&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Plugin Catalog 机制：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;可以组合多种其他 Catalog 实现，复用已有的 Catalog；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;库表生命周期行为统一：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;用户可以选择平台上的表和底层存储的生命周期统一，避免两边分别维护，重复建表；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;新老版本完全兼容：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;由于在 AutoStream 1.0 的时候，我们没有单独引入 Metastore 服务，此外 1.0 时期的 DDL SQL 解析模块是自研的组件。所以在建设 MetaStore 服务时，需要考虑历史作业和历史库表信息兼容的问题。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;对于库表信息，新的 MetaStore 在底层将新版和旧版的库表信息转换成统一的存储格式，从而保证了库表信息的兼容性。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;对于作业，这里我们通过抽象接口，并分别提供 V1Service 和 V2Service 两种实现路径，保证了新老作业在用户层面的兼容。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面是几个模块和 Metastore 交互的示意图：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n225&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSIlagdMbuGgtWVa1O46f26yic4XrfVtp7SEyfydBTpEiaED5UxjtjWtVw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n228&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;4. UDXF 管理&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;我们引入了 Jar Service 服务用来管理各种 Jar，包括用户自定义作业、平台内部 SDK 组件、UDXF 等，在 Jar Service 基础上我们可以很容易的实现 UDXF 的自助管理，在 On k8s 的场景下，我们提供了统一的镜像，Pod 启动后会从 Jar Service 下载对应的 Jar 到容器内部，用于支持作业的启动。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;用户提交的 SQL 中如果包含 Function DDL，我们会在 Job Client Service 中会解析 DDL，下载对应的 Jar 到本地。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为了避免和其他作业有依赖冲突，我们每次都会单独启动一个子进程来完成作业提交的操作。UDXF Jar 会被并加入到 classpath 中，我们对 Flink 做了一些修改，作业提交时会把这个 Jar 一并上传到 HDFS 中；同时 AutoSQL SDK 会根据函数名称和类名为当前作业注册 UDF。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n233&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSltJb2iaMhm5q4HkqicAfVoc2K9CpgbpiatDVhqgk8m4XeCQERMWnYt80g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n237&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;5. 监控报警及日志收集&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;得益于 Flink 完善的 Metric 机制，我们可以方便的添加 Metric，针对 Connector，我们内嵌了丰富的 Metric，并配置了默认的监控看板，通过看板可以查看 CPU、内存、JVM、网络传输、Checkpoint、各种 Connector 的监控图表。同时平台和公司的云监控系统对接，自动生成默认的报警策略，监控存活状态、消费延迟等关键指标。同时用户可以在云监控系统修改默认的报警策略，添加新的报警项实现个性化监控报警。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;日志通过云 Filebeat 组件写入到 Elasticsearch 集群，同时开放 Kibana 供用户查询。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n242&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprS4v1fObibtaCDQT7dcRlKB38Y9ic7af1x3ficVodhx3W8QO8Ba36ULiaEgQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;整体的监控报警及日志收集架构如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n246&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSb9Rk3GzYbgIdxJcAxqVMc1ib05jWjuC675j6W2OIriaaD1EF8QuYoxicw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n248&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;6. 健康检查机制&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;随着作业数的高速增长，出现了很多资源使用不合理的情况，比如前面提到的资源浪费的情况。用户大多时候都是在对接新需求，支持新业务，很少回过头来评估作业的资源配置是否合理，优化资源使用。所以平台规划了一版成本评估的模型，也就是现在说的健康检查机制，平台每天会针对作业做多维度的健康评分，用户可以随时在平台上查看单个作业的得分情况及最近 30 天的得分变化曲线。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;低分作业会在用户登录平台时进行提示，并且定期发邮件提醒用户进行优化、整改，在优化作业后用户可以主动触发重新评分，查看优化效果。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n252&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSJ6YrACRl0No3HibwZMTjzBZ7mfCrd7vtM1Ply4n6OTHQAQsH4QVCDxg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们引入了多维度，基于权重的评分策略，针对 CPU、内存使用率、是否存在空闲 Slot、GC 情况、Kafka 消费延迟、单核每秒处理数据量等多个维度的指标结合计算拓补图进行分析评估，最终产生一个综合分。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;每个低分项都会显示低分的原因及参考范围，并显示一些指导建议，辅助用户进行优化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们新增了一个 Metric，用一个 0%~100% 的数字体现 TaskManagner CPU 利用率。这样用户可以直观的评估 CPU 是否存在浪费的情况。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n258&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSCbCicCNgtWVH7Gxs90nhFAIeRScHwb2WjE1l4I2VEktmqW359p0lKxg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面是作业评分的大致流程：首先我们会收集和整理运行作业的基本信息和 Metrics 信息。然后应用我们设定好的规则，得到基本评分和基础建议信息。最后将得分信息和建议整合，综合评判，得出综合得分和最终的报告。用户可以通过平台查看报告。对于得分较低的作业，我们会发送报警给作业的归属用户。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n262&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSkSvn4zngo1cXkPRZrgTYwmdGq0ZTIibAOVHbzW8nBEvcXvWWFB3CKeg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n264&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;7. 自助诊断&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如之前提到的痛点，用户定位线上问题时，只能求助于我们平台方，造成我们 on-&lt;/span&gt;&lt;span&gt;call 工作量很大，同时用户体验也不好，鉴于此，所以我们上线了以下功能：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;动态修改日志级别：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们借鉴了 Storm 的修改日志级别的方式，在 Flink 上实现了类似功能，通过扩展 REST API 和 RPC 接口的方法，支持修改指定 Logger 的到某一日志级别，并支持设置一个过期时间，当过期后，改 Logger 的日志会重新恢复为 INFO 级别；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;支持自助查看线程栈和堆内存信息：&lt;/strong&gt;Flink UI 中已经支持在线查看线程栈 (jstack)，我们直接复用了这个接口；&lt;span&gt;还额外增加了查看堆内存 (jmap) 的接口，方便用户在线查看；&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;支持在线生成、查看火焰图：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;火焰图是定位程序性能问题的一大利器，我们利用了阿里的 arthas 组件，为 Flink 增加了在线查看火焰图的能力，用户遇到性能问题时，可以快速评估性能瓶颈。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n274&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSAhfAfBBibHoktpzeIySlyWdkK8sgiau9cdorFaibH7umkKiajohA9yWKibw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n277&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;8. 基于 Checkpoint 复制的快速容灾&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n278&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprS7nuC13lggfCT2BUicialBqDV89mibeqyKOv16n7KmDUG14TsX8SX1zY6Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当实时计算应用在重要业务场景时，单个 Yarn 集群一旦出现故障且短期内不可恢复，那么可能会对业务造成较大影响。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在此背景下，我们建设了 Yarn 多集群架构，两个独立的 Yarn 各自对应一套独立的 HDFS 环境，checkpoint 数据定期在两个 HDFS 间相互复制。目前 checkpoint 复制的延迟稳定在 20 分钟内。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;同时，在平台层面，我们把切换集群的功能直接开放给用户，用户可以在线查看 checkpoint 的复制情况，选择合适的 checkpoint 后 (当然也可以选择不从 checkpoint 恢复) 进行集群切换，然后重启作业，实现作业在集群间的相对平滑的迁移。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;三、基于 Flink 的实时生态建设&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;AutoStream 平台的核心场景是支持实时计算开发人员的使用，使实时计算开发变得简单高效、可监控、易运维。同时随着平台的逐步完善，我们开始摸索如何对 &lt;/span&gt;&lt;span&gt;AutoStream 平台进行重用，如何让 Flink 应用在更多场景下。重用 AutoStream 有以下几点优势：&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Flink 本身是优秀的分布式计算框架，有着较高的计算性能，良好的容错能力和成熟的状态管理机制，社区蓬勃发展，功能及稳定性有保障；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;AutoStream 有着完善的监控和报警机制，作业运行在平台上，无需单独对接监控系统，同时 Flink 对 Metric 支持很友好，可以方便的添加新的 Metric；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;大量的技术沉淀和运营经验，通过两年多的平台建设，我们在 AutoStream 上已经实现了较为完善的 Flink 作业全生命周期的管理，并建设了 Jar Service 等基础组件，通过简单的上层接口包装，就可以对接其他系统，让其他系统具备实时计算的能力；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;支持 Yarn 和 Kubernetes 部署。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n298&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSNgf2c4TmLEJib9RmwYspDga4zDGaib1DJl8FsHt5tV8Owf4ZicZNSbibTQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;基于以上几点，我们在建设其他系统时，优先重用 AutoStream 平台，以接口调用的方式进行对接，将 Flink 作业全流程的生命周期，完全托管给 AutoStream 平台，各系统优先考虑实现自身的业务逻辑即可。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我们团队内的 AutoDTS (接入及分发任务) 和 AutoKafka (Kafka 集群复制) 系统目前就是依托于 AutoStream 建设的。简单介绍一下集成的方式，以 AutoDTS 为例：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;把任务 Flink 化，AutoDTS 上的接入、分发任务，都是以 Flink 作业的形式存在；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;和 AutoStream 平台对接，调用接口实现 Flink 作业的创建、修改、启动、停止等操作。&lt;span&gt;这里 Flink 作业既可以是 Jar，也可以是 SQL 作业；&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;AutoDTS 平台根据业务场景，建设个性化的前端页面，个性化的表单数据，表单提交后，可以将表单数据存储到 MySQL 中；同时需要把作业信息以及 Jar 包地址等信息组装成 AutoStream 接口定义的格式，通过接口调用在 AutoStream 平台自动生成一个 Flink 任务，同时保存这个 Flink 任务的 ID；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;启动 AutoDTS 的一个接入任务，直接调用 AutoStream 接口就实现了作业的启动。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n313&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;1. AutoDTS 数据接入分发平台&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Auto&lt;/span&gt;&lt;span&gt;DTS 系统主要包含两部分功能：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;数据接入：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;将数据库中的变更数据 (Change log) 实时写入到 Kafka；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;数据分发：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;将接入到 Kafka 的数据，实时写入到其他存储引擎。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;■ &lt;/span&gt;1.1 AutoDTS 数据接入&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;&lt;h4 cid=&quot;n321&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;下面是数据接入的架构图：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n323&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSYMupLyN3ficmdaw9QZWabmiaFENFIO4ZS0g0SJ4BgNib90ykvAia7K2xxA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们维护了基于 Flink 的数据接入 SDK 并定义了统一的 JSON 数据格式，也就是说 MySQL Binlog，SQL Server、 TiDB 的变更数据接入到 Kafka 后，数据格式是一致的，下游业务使用时，基于统一格式做开发，无需关注原始业务库的类型。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;数据接入到 Kafka Topic 的同时，Topic 会自动注册为一张 AutoStream 平台上的流表，方便用户使用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;数据接入基于 Flink 建设还有一个额外的好处，就是可以基于 Flink 的精确一次语义，低成本的实现精确一次数据接入，这对支持数据准确性要求很高的业务来说，是一个必要条件。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;目前我们在做把业务表中的全量数据接入 Kafka Topic 中，基于 Kafka 的 compact 模式，可以实现 Topic 中同时包含存量数据和增量数据。这对于数据分发场景来说是十分友好的，目前如果想把数据实时同步到其他存储引擎中，需要先基于调度系统，接入一次全量数据，然后再开启实时分发任务，进行变更数据的实时分发。有了 Compact Topic 后，可以省去全量接入的操作。Flink1.12 版本已经对 Compact Topic 做支持，引入 upsert-kafka Connector [1]&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;102&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;span&gt;[1] https://cwiki.apache.org/confluence/display/Flink/FLIP-149%3A+Introduce+the+upsert-kafka+Connector&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;下面是一条样例数据：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n334&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprS8c4UYmM075icTABBjbBdKnibbymKuMKpfYnOia8ibI1qj2J4NTzbiaFRJaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;默认注册到平台上的流表是 Schemaless 的，用户可以用 JSON 相关的 UDF 获取其中的字段数据。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n337&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSu5pntNaY31nyhv3TibU8OYRezQBMD6ZQC3qqZhFkbNyzdib7zEE267jw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面是使用流表的示例：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n340&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSXUiaeyStN8hp9BepdK9zPXWuMYiblEicJhb1N71opfNmTYUqpyvNNJL3w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;■ &lt;/span&gt;1.2 AutoDTS 数据分发&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n343&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSm8fic0Da8XXshokBwwIsVDib9M5E9SktwToumlCB08WBe0A1V4ibA6ttg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们已经知道，接入到 Kafka 中的数据是可以当做一张流表来使用的，而数据分发任务本质上是把这个流表的数据写入到其他存储引擎，鉴于 AutoStream 平台已经支持多种 Table Sink (Connector)，我们只需要根据用户填写的下游存储的类型和地址等信息，就可以通过拼装 SQL 来实现数据的分发。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;通过直接重用 Connector 的方式，最大化的避免了重复开发的工作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面是一个分发任务对应的 SQL 示例：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n349&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.562535158447403&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSelwbuWeyZkHib1ia3Dmm6ypFdgeLsiabeosEFvtriaYrkbCgmPXTPFJYYw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;5333&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n351&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;&lt;span&gt;2. Kaka 多集群架构&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kafka 在实际应用中，有些场景是需要做 Kafka 多集群架构支持的，下面列举几个常见的场景：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据冗余灾备，实时复制数据到另一个备用集群，当一个 Kafka 集群不可用时，可以让应用切换到备用集群，快速恢复业务；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;集群迁移，当机房合同到期，或者上云时，都需要做集群的迁移，此时需要把集群数&lt;span&gt;据整体复制到新机房的集群，让业务相对平滑迁移；&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;读写分离场景，使用 Kafka 时，大多数情况都是读多写少，为保证数据写入的稳定性，可以选择建设 Kafka 读写分离集群。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我们目前建设了 Kafka 多集群架构，和 Flink 相关的主要有两块内容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Kafka 集群间数据复制的程序运行在 Flink 集群中；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;改造了 Flink Kafka Connector，支持快速切换 Kafka 集群。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;■ &lt;/span&gt;2.1 整体架构&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n369&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSPg7oN0SHklMzCibUFNUaaFKChdM0ian14Zm3EWPiarakicfbbzADKzibS7w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;先来看一下 Kafka 集群间的数据复制，这是建设多集群架构的基础。我们是使用 MirrorMaker2 来实现数据复制的，我们把 MirrorMaker2 改造成普通的 Flink 作业，运行在 Flink 集群中。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们引入了 Route Service 和 Kafka SDK，实现客户端快速切换访问的 Kafka 集群。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;客户端需要依赖我们自己发布的 Kafka SDK，并且配置中不再指定 bootstrap.servers 参数，而是通过设置 cluster.code 参数来声明自己要访问的集群。SDK 会根据 cluster.code 参数，访问 Route Service 获取集群真正的地址，然后创建 Producer/Consumer 开始生产/消费数据。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;SDK 会监听路由规则的变化，当需要切换集群时，只需要在 Route Service 后台切换路由规则，SDK 发现路由集群发生变化时，会重启 Producer/Consumer 实例，切换到新集群。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果是消费者发生了集群切换，由于 Cluster1 和 Cluster2 中 Topic 的 offset 是不同的，需要通过 Offset Mapping Service 来获取当前 Consumer Group 在 Cluster2 中的 offset，然后从这些 Offset 开始消费，实现相对平滑的集群切换。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;■ &lt;/span&gt;2.2 Kafka 集群间的数据复制&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用 MirrorMaker2 来实现集群间的数据复制，MirrorMaker2 是 Kafka 2.4 版本引入的，具体以下特性：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;自动识别新的 Topic 和 Partition；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;自动同步 Topic 配置：&lt;span&gt;Topic 的配置会自动同步到目标集群；&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;自动同步 ACL；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;提供 Offset 的转换工具：支持根据源集群、目标集群及 Group 信息，获取到该 Group 在目标集群的中对应的 Offset 信息；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;支持扩展黑白名单策略：可以灵活定制，动态生效。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;shell&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;clusters = primary, backup&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;primary.bootstrap.servers = vip1:9091&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;backup.bootstrap.servers = vip2:9092&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;primary-&amp;gt;backup.enabled = true&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;backup-&amp;gt;primary.enabled = true&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这段配置完成了 primary 到 backup 集群的双向数据复制，primary 集群中的 topic1 中的数据会复制到 backup 集群中的 primary.topic1 这个 Topic 中，目标集群的Topic 命名规则是 sourceCluster.sourceTopicName，可以通过实现 ReplicationPolicy 接口来自定义命名策略。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n402&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSEk0bFYX51dzr53Zm7faS6ic74xD2AAX9KprllnEwgpFvlmmhZwbNznw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 2.3 MirrorMaker2 相关的 Topic 介绍&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;源集群中的 Topic&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;heartbeats：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;存储心跳数据；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;mm2-offset-syncs.targetCluster.internal：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;存储源集群 (upstreamOffset) 和目标集群的 offset(downstreamOffset) 对应关系。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;目标集群中的 Topic  &lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;mm2-configs.sourceCluster.internal：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;connect 框架自带，用来存储配置；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;mm2-offsets.sourceCluster.internal：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;connect 框架自带，用来存储 WorkerSourceTask 当前处理的 offset，mm2 场景下是为了当前数据同步到源集群 topic partition 的哪一个 offset，这个更像是 Flink 的 checkpoint 概念；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;mm2-status.sourceCluster.internal：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;connect 框架自带，用来存储 connector 状态。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上面三个用的都是 connect runtime 模块中的 KafkaBasedLog 工具类，这个工具类可以读写一个 compact 模式的 topic 数据，此时 MirrorMaker2 把 topic 当作 KV 存储使用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;sourceCluster.checkpoints.internal：记录 sourceCluster consumer group 在当前集群对应的 offset，mm2 会定期从源 kafka 集群读取 topic 对应的 consumer group 提交的 offset， 并写到目标集群的 sourceCluster.checkpoints.internal topic 中。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n422&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSvV6vWPSZw85Szd9lCQ0lCic9ezz4Ee4qsLlUbEZWMl8S69ISWia33lyw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;■ &lt;/span&gt;2.4 MirrorMaker2 的部署&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;下面是 MirrorMaker2 作业运行的流程，在 AutoKafka 平台上创建一个数据复制作业，会调用 AutoStream 平台接口，相应的创建一个 MM2 类型的作业。启动作业时，会调用 AutoStream 平台的接口把 MM2 作业提交到 Flink 集群中运行。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n426&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSib4P0I1e8ljQS3rS4gbaorHUe1nubFpNnUtoeq1KBicDFEUCBkvhWKrQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 2.5 路由服务&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;Route Service 负责处理客户端的路由请求，根据客户端的信息匹配合适的路由规则，将最终路由结果，也就是集群信息返回给客户端。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;支持基于集群名称、Topic、Group、ClientID 以及客户端自定义的参数灵活配置路由规则。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面的例子就是将 Flink 作业 ID 为 1234 的消费者，路由到 cluster_a1 集群。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n432&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSONg0fpFBiaPvOmfbuicXFn6dj6ICIvRIib3kyAxNe3zqeYfcoO50SKqwA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 2.6 Kafka SDK&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;使用原生的 kafka-clients 是无法和 Route Service 进行通信的，客户端需要依赖我们提供的 Kafka SDK (汽车之家内部开发的 SDK) 能和 Route Service 通信，实现动态路由的效果。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Kafka SDK 实现了 Producer、Consumer 接口，本质是 kafka-clients 的代理，业务做较少的改动就可以引入 Kafka SDK。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;业务依赖 Kafka SDK 后，Kafka SDK 会负责和 Route Service 通信，监听路由变化，当发现路由的集群发生变化时，会 close 当前的 Producer/Consumer，创建新的 Producer/Consumer，访问新的集群。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;此外 Kafka SDK 还负责将 Producer、Consumer 的 metric 统一上报到云监控系统的 prometheus，通过查看平台预先配置好的仪表盘，可以清晰的看到业务的生产、消费情况。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;同时 SDK 会收集一些信息，比如应用名称、IP 端口、进程号等，这些信息可以在 AutoKafka 平台上查到，方便我们和用户共同定位问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n440&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSNurfEmvfOPDnGWetRpibkLYWaVaFeia5NJLw05iaxeS0xWhoGwEbMDYFg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 2.7 Offset Mapping Service&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;当 Consumer 的路由发生变化并切换集群时，情况有一些复杂，因为目前 MirrorMaker2 是先把数据从源集群消费出来，再写入到目标集群的，同一条数据可以确保写入到目标 topic 的相同分区，但是 offset 和源集群是不同的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;针对这种 offset 不一致的情况，MirrorMaker2 会消费源集群的 __consumer_offsets 数据，加上目标集群对应的 offset，写入到目标集群的 sourceCluster.checkpoints.internal topic 中。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;同时，源集群的 mm2-offset-syncs.targetCluster.internal topic 记录了源集群和目标集群 offset 的映射关系，结合这两个 topic，我们建设了 Offset Mapping Service 来完成目标集群的 offset 的转换工作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;所以当 Consumer 需要切换集群时，会调用 Offset Mapping Service 的接口，获取到目标集群的 offsets，然后主动 seek 到这些位置开始消费，这样实现相对平滑的集群切换工作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n448&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSud60IMLO0qOU8NsTPmuNvbedamciciaMXT2XqzEzGAfUepHdhNrepUBA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 2.8 Flink 与 Kafka 多集群架构的集成&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;由于 Kafka SDK 兼容 kafka-clients 的用法，用户只需要更换依赖，然后设置 cluster.code、Flink.id 等参数即可。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当 Producer/Consumer 发生集群切换后，由于创建了新的 Producer/Consumer 实例，Kafka 的 metric 数据没有重新注册，导致 metric 数据无法正常上报。我们在 AbstractMetricGroup 类中增加了 unregister 方法，在监听 Producer/Consumer 的切换事件时，重新注册 kafka metrics 就可以了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;至此我们完成了 Flink 对 Kafka 多集群架构的支持。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n457&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSZl1ibXiau8lPfnXIrwSWEl8icicR4icsNamozSryicKAnCakZ69TPXHrricXg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;四、后续规划&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p cid=&quot;n460&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HZ3kWoZPQjWibonwErWprSYuiac0wJmmWzGNIf6QibhBojE0ypQzUFusL1l9OMdcuHSWKKmvm7hPdA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;目前我们支持的数据统计类场景大多是基于流量数据或用户行为数据的，这些场景对精确一次的语义要求不高，随着目前社区对 Change Log 支持的逐步完善，同时我们的数据接入体系是支持精确一次语义的，并且正在做业务表全量接入到 Kafka 的功能，所以后续可以实现精确一次的数据统计，支持交易、线索、金融类的统计需求。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;一些公司已经提出湖仓一体的理念，数据湖技术确实可以解决一些原有数仓架构的痛&lt;span&gt;点，比如数据不支持更新操作，无法做到准实时的数据查询。目前我们在做一些 Flink 和 Iceberg、Hudi 集成的一些尝试，后续会在公司寻找场景并落地。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;hr/&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;热点推荐&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;hr/&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;更多 Flink 相关技术问题，可扫码加入社区钉钉交流群～&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;1.2078189300411524&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6PUTQaA1BP3Fb8uViccQpspmTibIYEfM7Wv6VACia9CDQfcN8huMVCafZ5s36wThUmbYRTOzMu4hd8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;972&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt; &lt;img class=&quot;__bg_gif&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/Z6bicxIx5naLWBBEcl44aIic1Mthe1nZiaramW5s4e8WwyCYYbTzu6uPBpgI6sxNXNymEnOYKpJpcrItUia7lS64mA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot;/&gt;  &lt;/span&gt;&lt;span&gt;戳我，回顾作者原版分享视频！&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>