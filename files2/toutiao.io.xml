<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>dc05c13cb0614d6cdcae7b43cb9c5e2c</guid>
<title>文末送福利｜十一长假干嘛呢？快来吧！</title>
<link>https://toutiao.io/k/8pbs9cx</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;码农周刊是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;码农周刊是一份专为广大程序员、编程爱好者们打造的 IT 技术周刊。每周发送。&lt;br/&gt;2013 年 9 月 12 日创刊至今，已发送 300 多期，订阅用户超 20 万。&lt;br/&gt;&lt;/span&gt;&lt;span&gt;专业、简单、有用&lt;/span&gt;&lt;span&gt;，是我们一直坚持的办刊宗旨。一路走来，我们见证了不少订阅用户从编程新手进阶成了高级程序员、架构师、CTO……&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;2020 年 4 月，为了给用户提供更优质的服务，我们推出了「&lt;/span&gt;&lt;span&gt;码农周刊VIP会员&lt;/span&gt;&lt;span&gt;」服务。&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;你与 BAT 技术大牛，只差一份「码农周刊VIP会员」的距离！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;VIP会员特权&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1. 52 期码农周刊VIP会员&lt;span&gt;专属邮件周报&lt;/span&gt;，让你及时掌握技术动向；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 只限VIP会员加入的&lt;span&gt;交流圈子&lt;/span&gt;，让你与技术大牛切磋学习；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. VIP会员独享的&lt;span&gt;工作机会&lt;/span&gt;，为你介绍好公司的好机会；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 更多会员特权，持续更新……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;如何加入「码农周刊VIP会员」？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1. 微信扫描下方二维码，加入码农周刊VIP会员知识星球。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;促销期间，一年仅需 108 元！平均一天花费不到 3 毛！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-cropselx1=&quot;34&quot; data-cropselx2=&quot;356&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;425&quot; data-ratio=&quot;1.0857487922705313&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/t8lpVibticjQ6h6x4EnYInRLic6PibFNWw4zSv28rAxcJu9dumVJF03PwHGOWxOzeJKIsydVa7UJuTo4jOjrct9NZw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;828&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 加入码农周刊VIP会员知识星球后，客服会联系您，请留意知识星球内的私信。&lt;br/&gt;3. 客服向您发送码农周刊VIP会员欢迎邮件，开启您的码农周刊VIP会员之旅。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;心动不如心动，赶快订阅吧！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>5d14adaa0bd7211e64919b5763d676fc</guid>
<title>腾讯看点基于 Flink 构建万亿数据量下的实时数仓及实时查询系统</title>
<link>https://toutiao.io/k/rl31vbv</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p id=&quot;js_tags&quot; class=&quot;article-tag__list single-tag__wrp js_single&quot; data-len=&quot;1&quot; role=&quot;link&quot; aria-labelledby=&quot;js_article-tag-card__left&quot; aria-describedby=&quot;js_article-tag-card__right&quot;&gt;
                                            
                                                                                    &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__left&quot; class=&quot;article-tag-card__left&quot;&gt;
                                    &lt;span class=&quot;article-tag-card__title&quot;&gt;收录于话题&lt;/span&gt;
                                    &lt;span class=&quot;article-tag__item-wrp no-active js_tag&quot; data-url=&quot;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU3Mzg4OTMyNQ==&amp;amp;action=getalbum&amp;amp;album_id=1929702550740484100#wechat_redirect&quot; data-tag_id=&quot;&quot; data-album_id=&quot;1929702550740484100&quot; data-tag_source=&quot;4&quot;&gt;
                                        &lt;span class=&quot;article-tag__item&quot;&gt;#行业案例&lt;/span&gt;
                                    &lt;/span&gt;
                                &lt;/span&gt;
                                &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__right&quot; class=&quot;article-tag-card__right&quot;&gt;51个&lt;span class=&quot;weui-hidden_abs&quot;&gt;内容&lt;/span&gt;&lt;/span&gt;
                                                                                        &lt;/p&gt;

                
                                
                
                

                
                                                                

                
                                


                
                
                
                
                                                
                                                                
                                
                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section&gt;&lt;span&gt;▼ 关注「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Flink 中文社区&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，获取更多技术干货 &lt;span&gt;▼&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU3Mzg4OTMyNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6FJHxaI14AsXuzeg4SybT0hiaCSohrIY75oiaOMzhQU7RouiafjNa76k2CtD6xxB2JqnawqFqV3zg3A/0?wx_fmt=png&quot; data-nickname=&quot;Flink 中文社区&quot; data-alias=&quot;&quot; data-signature=&quot;Apache Flink 官微，Flink PMC 维护&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;span&gt;本&lt;span&gt;文由社区志愿者路培杰整理，腾讯看点数据团队高级工程师王展雄在 Flink Forward Asia 2020 分享的议题《腾讯看点基于 Flink 构建万亿数据量下的实时数仓及实时查询系统》。内容包括：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;背景介绍&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;架构设计&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;实时数仓&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;实时数据查询系统&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;实时系统应用成果总结&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Tips：&lt;/strong&gt;&lt;span&gt;点&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;击&lt;/span&gt;&lt;span&gt;&lt;strong&gt;「阅读原&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;文」&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;即可查看作者分享原版视频～&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu78FqIxdIQicVe5cg78bpax1XDKxMS06V8h6bib5fhicN8n5zK7Z4oDWWgzgbAeCibuKRnD5eibTcg73mg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;20&quot;/&gt; GitHub 地址 &lt;img data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu78FqIxdIQicVe5cg78bpax1XDKxMS06V8h6bib5fhicN8n5zK7Z4oDWWgzgbAeCibuKRnD5eibTcg73mg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;20&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;欢迎大家给 Flink 点赞送 star~&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.024390243902439&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu58p6JubKoFyrKVibtOyk1CTpJialGPpBBg6uRknWESa1xwDsR8yeKiah9z0lnproCED8dp6l4bmfgQQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;492&quot;/&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;一、背景介绍&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 需要解决的业务痛点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;推荐系统&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于推荐同学来说，想知道一个推荐策略在不同人群中的推荐效果是怎么样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;运营&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于运营的同学来说，想知道在广东省的用户中，最火的广东地域内容是哪些？方便做地域 push。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;审核&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于审核的同学，想知道过去 5 分钟游戏类被举报最多的内容和账号是哪些，方便能够及时处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;内容创作&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于内容的作者，想知道今天到目前为止，内容被多少个用户观看，收到了多少个点赞和转发，方便能够及时调整他的策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;老板决策&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于老板来说，想知道过去 10 分钟有多少用户消费了内容，对消费人群有一个宏观的了解。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n214&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2fpwdPsRskWMxl0ZxflQrxLic2sDXrXDT1oM4dj3FWArLzyjia6ticdVhg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以上这几点都是我们日常工作中经常遇到的业务场景，后面的篇幅中会给出对应的解决方案。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n218&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 开发前调研&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;在进行开发之前我们做了如下这些调研。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n221&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2ZPxUG2ic5AP9CntTdj21f9e0QkMJaAwfcho23icRXlBADzS0QxvNk3ag/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;■ &lt;/span&gt;2.1 离线数据分析平台能否满足这些需求&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;h4 cid=&quot;n223&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;调研的结论是不能满足离线数据分析平台，不行的原因如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;首先用户的消费行为数据上报需要经过 Spark 的多层离线计算，最终结果出库到 MySQL 或者 ES 提供给离线分析平台查询。这个过程的延时至少是 3-6 个小时，目前比较常见的都是提供隔天的查询，所以很多实时性要求高的业务场景都不能满足。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;另一个问题是腾讯看点的数据量太大，带来的不稳定性也比较大，经常会有预料不到的延迟，所以离线分析平台是无法满足这些需求的。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 2.2 准实时数据分析平台&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;h4 cid=&quot;n232&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;在腾讯内部提供了准实时数据查询的功能，底层技术用的是 Kudu + Impala，Impala 虽然是 MPP 架构的大数据计算引擎，并且访问以列式存储数据的 Kudu。但是对于实时数据的分析场景来说，它的查询响应速度和数据的延迟都还是比较高的。比如说查询一次实时的 DAU 返回结果的耗时至少是几分钟，无法提供良好的交互式的用户体验。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;所以 Kudu+Impala 这种通用的大数据处理框架的速度优势，更多的是相比 Spark 加 HDFS 这种离线分析框架来说的，对于我们实时性要求更高的场景是无法满足的。因此需要进行开发，这就涉及到了方案选型和架构设计。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n236&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. 腾讯看点信息流的业务流程&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在大家介绍一下腾讯看点信息流的业务流程，了解了业务的流程，就能够更好的理解技术架构的方案。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第 3 步，启用的内容给到推荐系统和运营系统，分发给 C 侧用户；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第 4 步，内容分发给 C 侧用户之后，用户会产生各种行为，比如说曝光、点击举报等，这些行为数据通过埋点上报，实时接入到消息队列中；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n252&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2sjpnjYaWrSqcgkziaXc3QplzHtXdNUon0XJmgCiakD402Jopx2zstWeg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们做的工作主要就在第 5 步和第 6 步，可以看一下我们的业务流程图来进一步的了解。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n254&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2Fia4gWiaib1Fhym8foqbc455oZOrV2CfHH6oibZOfRickMtUD7CUZGu2UlA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;在业务流程图中，我们主要做的两部分工作，就是图中有颜色的这两部分：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;绿色部分，我们基于了 OLAP 的存储计算引擎，开发了实时数据分析系统。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为什么要构建实时数据仓库？因为原始的数据上报数据量非常大，一天上报的峰值就有上万亿条，而且上报的格式非常混乱，缺乏了内容的维度、信息用户的画像信息，下游就根本没有办法直接使用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;而我们提供的实时数据仓库，是根据腾讯看点信息流的业务场景，进行了内容维度的关联，用户画像的关联和各种粒度的聚合，下游可以非常方便的使用实时数据，而且实时数据仓库可以提供给下游的用户反复的消费使用，可以大量的减少重复的工作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;绿色部分的多维实时数据分析系统，消费了我们提供的实时数据仓库，利用了 OLAP 存储计算引擎，将海量的数据进行高效的存储，再提供高性能的多维实时分析功能。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;二、架构设计&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 设计的目标与难点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先来看一下数据分析系统的设计目标与难点。我们的实时数据分析系统分为四大模块：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n260&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2p16XNM9pFKM2NET60JjZukLuwdAAUUJBGbQ2YfZtth3icTgVclvLEzw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;难点主要在于前两个模块，实时计算引擎和实时存储引擎。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;千万级每秒的海量数据如何实时的接入，并且进行极低延迟的维表关联是有难度的；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;实时存储引擎如何支持高并发的写入。高可用分布式和高性能的索引查询是比较难的，可以看一下我们的系统架构设计来了解这几个模块的具体实现。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n263&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 系统架构设计&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;关于系统架构的设计，主要从以下几方面来讲。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;■ &lt;/span&gt;2.1 实时计算&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;h4 cid=&quot;n492&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h4&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;接入层主要是从千万级每秒的原始消息队列中拆分出不同业务不同行为数据的微队列。拿 QQ 看点的视频内容来说，拆分过后的数据就只有百万级每秒了。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;实时计算层主要是负责多行行为流水数据进行 &quot;行转列&quot; 的操作，实时关联用户画像数据和内容维度数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;实时数仓存储层主要就是设计出符合看点的业务，下游好用的实时消息队列。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n265&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2Jwh6L5XAwjPUPQibdiaQJ0szoV0Ic59ygicujicQH9dEN4XeYia9ia9AcCdw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我们暂时提供了两个消息队列，作为实时数仓的两层：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第一层是 DWM 层，它是内容 ID 和用户 ID 粒度聚合的，就是说一条数据包含了内容 ID 和用户 ID，然后还有 B 侧的内容维度数据，C 侧的用户行为数据，还有用户画像数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二层是 DWS 层，这一层是内容 ID 粒度聚合的，就是一条数据包含了内容 ID、B 侧数据和 C 侧数据。可以看到内容 ID 和用户 ID 粒度的消息，队列流量进一步减小到了 10 万级每秒，内容 ID 粒度更是减小到了万级每秒，并且格式更加清晰，维度信息更加丰富。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n267&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2DfQjx4nvk4zm66HcyFSLxXhInVloepgMXH9D4EW52NzesHrYtywofw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 2.2 实时存储&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;实时写入层主要是负责 Hash 路由，将数据写入；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;OLAP 存储层是利用 MPP 的存储引擎，设计出符合业务的索引和物化视图，高效存储海量数据；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n269&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2IsVMqQYM7bOCNgOB9v3AmeKswSkf8Wn4N1VUSQnjicWvS7XWOYZz2zA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 2.3 后台服务&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;后台服务是基于腾讯自研的 RPC 后台服务框架写的，并且会进行一些二级缓存。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 2.4 前端服务&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;前端采用的是开源组件 Ant Design，利用了 Nginx，反向代理了浏览器的请求到后台服务器上。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n272&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. 方案选型&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;关于架构设计的方案选型，我们对比了业内的领先方案，最终选择了最符合我们业务场景的方案。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n274&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2aQEibKUew6OKexEk2chELlboe2SzIMTLKZdkibDhsFmQChGqrrISt6ZA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 3.1 实时数仓的选型&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们选择的是业内比较成熟的 Lambda 架构，它的优点是成熟度高，灵活性高，迁移成本低等等。但是它有一个缺点，实时和离线用了两套代码，可能会存在一个口径修改了数据，但另一个没有修改从而造成数据不一致的问题。我们的解决方案每天都有做数据对账的工作，如果有异常会进行告警。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 3.2 实&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;时计算引擎的&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;选型&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们选择了 Flink 作为实时计算引擎，是因为 Flink 在设计之初就是为了流处理来设计的，Sparks Streaming 严格来说还是微批处理，storm 现在用的已经不是很多了。并且， Flink 还有 exactly-once 的准确性，轻量级的容错机制，低延迟高吞吐，应用性高的特点，所以我们选择了 Flink 作为实时计算引擎。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 3.3 实时存储引擎&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们的要求是需要有维度索引，支持高并发的写入和高性能的多维实时 OLAP 查询。可以看到 HBase，TiDB 和 ES 都不能满足要求。Druid 有一个缺陷，它是按照时序划分 Segment，也就说明无法将同一个内容全部存放在同一个 Segment 上，所以在计算全局的 Top N 的时候就只能够计算近似值。于是我们选择了最近两年大火的 MPP 数据库引擎 Clickhouse，后面我会结合我们的具体使用场景和 Clickhouse 的内核原理，介绍一下 Clickhouse 的优势。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;三、实时数仓&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;实时数仓也分为三块来介绍：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第三是基于实时数仓，利用 Flink 开发实时应用时候遇到的一些问题。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;实时数仓这一部分的难度在于它处于一个比较新的领域，并且各个公司各个业务的差距都比较大，怎么样能够设计出方便好用，符合看点信息流业务场景的实时数仓是有难度的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3 cid=&quot;n282&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 如何构建实时数仓&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;先看一下实时数仓要做什么。实时数仓对外来说就是几个消息队列，不同的消息队列里面存放的是不同聚合粒度的实时数据，包括了内容 ID、用户 ID、C 侧用户行为数据，B 侧内容维度数据和用户画像数据等。搭建实时数仓可以分为三步。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n285&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2GXNH7MfpXf1jYmlSrfg7wnAqNUa1IYdy6xsjZkoXyMon86bten2Ggg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 1.1数据清洗&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;首先从海量的原始消息队列中进行复杂的数据清洗操作，可以获得格式清晰的实时数据。它的具体操作其实就是在 Flink 的实时计算环节，先按照一分钟的粒度进行了窗口的聚合，在窗口内原本多行的行为数据被转成了一行多列的数据格式。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 1.2 高性能维表关联&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;第二步是进行高性能的实时维表关联，补充用户画像数据和内容维度数据等。但是海量的用户画像数据是存在于 HDFS 上的，内容维度数据又是存在于 HBase 上的，所以想要极低延迟的维表关联是有技术挑战的。这一块在后文会单独介绍。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 1.3&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; 不同粒度聚&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;合&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;第三步是将算好的实时数据按照不同的粒度进行聚合，然后放到对应的消息队列中进行保存，可以提供给下游多用户复用，到这里实时数仓就搭建完成了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n294&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2gSwicxDdMtnBic6LSemQRuccsED3xAtYyA1qqk1JZiccGqTNGpGicdakUg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;接下来详细介绍一下第二步中高性能实时维表关联是怎么处理的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;几十亿的用户画像数据存放在 HDFS 上，肯定是无法进行高性能的维表关联的，所以需要进行缓存。由于数据量太大，本地缓存的代价不合理，我们采用的是 Redis 进行缓存，具体实现是通过 Spark 批量读取 HDFS 上的画像数据，每天更新 Redis 缓存，内容维度数据存放在 HBase 中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了不影响线上的业务，我们访问的是 HBase 的备库，而且由于内容维度变化的频率远高于用户画像，所以维度关联的时候，我们需要尽量的关联到实时的 HBase 数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一分钟窗口的数据，如果直接关联 HBase 的话，耗时是十几分钟，这样会导致任务延迟。我们发现 1000 条数据访问 HBase 是秒级的，而访问 Redis 的话只是毫秒级的，访问 Redis 的速度基本上是访问 HBase 的 1000 倍，所以我们在访问 HBase 的内容之前设置了一层 Redis 缓存，然后通过了监听 HBase-proxy 写流水，通过这样来保证缓存的一致性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样一分钟的窗口数据，原本关联内容维度数据耗时需要十几分钟，现在就变成了秒级。我们为了防止过期的数据浪费缓存，缓存的过期时间我们设置成了 24 个小时。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后还有一些小的优化，比如说内容数据上报过程中会上报不少非常规的内容 ID，这些内容 ID 在 HBase 中是不存储的，会造成缓存穿透的问题。所以在实时计算的时候，我们直接过滤掉这些内容 ID，防止缓存穿透，又减少了一些时间。另外，因为设置了定时缓存，会引入一个缓存雪崩的问题，所以我们在实时计算的过程中进行了削峰填谷的操作，错开了设置缓存的时间，来缓解缓存雪崩的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3 cid=&quot;n297&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 实时数仓的优点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n298&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2TVicN6fGg1rgNTUAoEm5DicvGjYEmV9b3iaCXd81tmfS3D5LZIUiaxNpxQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我们可以看一下，在我们建设实时数仓的前后，开发一个实时应用的区别。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没有数仓的时候，我们需要消费千万级每秒的原始队列，进行复杂的数据清洗，然后再进行用户画像关联、内容维度关联，才能够拿到符合要求格式的实时数据。开发和扩展的成本都会比较高。如果想开发一个新的应用，又要走一遍流程。现在有了实时数仓之后，如果再想开发一个内容 ID 粒度的实时应用，就直接申请 TPS 万级每秒的 DWS 层消息对列即可，开发成本变低很多，资源消耗小了很多，可扩展性也强了很多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们看一个实际的例子，开发我们系统的实时数据大屏，原本需要进行如上的所有操作才能够拿到数据，现在只需要消费 DWS 层消息队列写一条 Flink SQL 即可，仅仅会消耗 2 个 CPU 核心和 1GB 的内存。以 50 个消费者为例，建立实时数仓的前后，下游开发一个实时应用，可以减少 98% 的资源消耗，包括了计算资源、存储资源、人力成本和开发人员的学习接入成本等等，并且随着消费者越多节省的就越多，就拿 Redis 存储这一部分来说，一个月就能够省下上百万的人民币。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3 cid=&quot;n301&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. Flink 开发过程中遇到的问题总结&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在利用 Flink 开发实时应用的过程中遇到过不少问题，这里选择几个比较有代表性的给大家分享一下。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 3.1 实时数据大屏&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;第一个是开发实时数据大屏的时候，开始是通过 Flink SQL 来实现的，功能非常简单，就是计算当天截止到当前累计的点击数，实现的方式也非常简单，输入的 source table 是实时数据仓库的消息队列。输出的 sink table 就是 Redis。SQL 就是：select sum(click) from sourceTable Group by day time。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这个任务看起来是没有问题的，但是实际跑起来数据却无法实时更新，是因为 source table 每到达一条点击数据，累计值都会加一，然后就会往 Redis 中写一条最新的数据。所以当数据量太大的时候，它就会频繁的写 Redis，所以这样就会导致写 Redis 的网络延迟会显得非常高，从而会导致背压数据无法实时更新。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们做了一个简单的优化，用 table API 执行完 SQL 之后，转化成 DataStream，然后通过一个一秒钟的数据窗口，每秒钟仅仅会输出最新的累计值到 Redis 中，这样的数据就可以实时更新了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n306&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2BvbSuD1mRQjUxNP6HssINTYkU2GvskCv2TDT5gafhUTkkGn0sfDrEQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 3.2 Flink state 的 TTL&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink 的 1.6 版本开始引入了 state TTL，开启了 state TTL 之后，Flink 就会为每一个 keyed state 增加一个时间戳字段，通过时间戳字段就可以判断 state 是不是过期，是否需要进行清理。但是如果仅仅从字面意思上理解就会遇到一些问题，在 1.10 版本之前，虽然开启了 state TTL，但是 Flink 默认是不会自动清理过期的 state 的。所以如果是 heap memory backend，就会导致 OOM 的问题；如果是 rocksDB backend，就会导致 state 的状态越来越大，最终会导致重启的时候耗费的时间过长。后面经过调研，我们发现有两种方式可以清理 Flink 的过期的 state。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;第一种是手动清理，第二种的话是自动清理。我们最终选择的是以手动触发的方式来清理过期的 state。每天在深夜，也就是业务低谷期的时候，我们会对 state 中的数据进行遍历的访问，访问到过期的数据，就会进行清理。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;为什么我们没有选择 Flink 的自动清理策略，是因为 Flink 在 1.8 版本之前，只有一种自动清理策略，clean up in full snapshot。这种清理策略从名字上来看就知道他是在做全量 snapshot 的时候会进行清理，但是有一个致命的缺陷，它并不会减少本身 state 的大小，而是仅仅把清理过后的 state 做到 snapshot 里面，最终还是会 OOM。并且，它重启之后才能够加载到之前清理过的 state，会导致它频繁的重启。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;虽然在 1.8 版本之后，增加了两种自动清理的策略，但是因为它是异步清理，所以他的清理时机和使用方式都不如手动清理那么灵活，所以最终我们还是选择了手动触发的方式进行清理。在 1.10 版本之后，默认是选择了自动清理的策略，但是这就要求用户对自动清理策略的时机和策略 有比较好的了解，这样才能够更好的满足业务的需求。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n310&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2IdRIsdT2icnTFbNCIbiaDnHrWWbQlBTvdfBTSox7OTHHWNRZbDaJibwJQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 3.3 使用 Flink valueState 和 mapState 经验总结&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;h4 cid=&quot;n312&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;虽然通过 valueState 也可以存储 map 结构的数据，但是能够使用 mapState 的地方尽量使用 mapState，最好不要通过 valueState 来存储 map 结构的数据，因为 Flink 对 mapState 是进行了优化的，效率会比 valuState 中存储 map 结构的数据更加高效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如我们遇到过的一个问题就是使用 valueState 存储了 map 结构的数据，选择的是 rocksDB backend。我们发现磁盘的 IO 变得越来越高，延迟也相应的增加。后面发现是因为 valueState 中修改 map 中的任意一个 key 都会把整个 map 的数据给读出来，然后再写回去，这样会导致 IO 过高。但是 mapState，它每一个 key 在 rocksDB 中都是一条单独的 key，磁盘 IO 的代价就会小很多。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n314&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn26UJk5QMtmtzlyGl1l8Jf6sUguZbiab6a3FGhmSCE4eFL8C9FnYJ9jyA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 3.4 Checkpoint 超时问题&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;h4 cid=&quot;n316&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h4&gt;&lt;p&gt;&lt;span&gt;我们还遇到过一些问题，比如说 Checkpoint 超时了，当时我们第一个想法就是计算资源不足，并行度不够导致的超时，所以我们直接增加了计算资源，增大了并行度，但是超时的情况并没有得到缓解。后面经过研究才发现是数据倾斜，导致某个节点的 barrier 下发不及时导致的，通过 rebalance 之后才能够解决。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总的来说 Flink 功能还是很强的，它文档比较完善，网上资料非常丰富，社区也很活跃，一般遇到问题都能够比较快的找到解决方案。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;四、实时数据查询系统&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我们的实时查询系统，多维实时查询系统用的是 Clickhouse 来实现的，这块分为三个部分来介绍。第一是分布式高可用，第二是海量数据的写入，第三是高性能的查询。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Click house 有很多表引擎，表引擎决定了数据以什么方式存储，以什么方式加载，以及数据表拥有什么样的特性？目前 Clickhouse 拥有 merge tree、replaceingMerge Tree、AggregatingMergeTree、外存、内存、IO 等 20 多种表引擎，其中最体现 Clickhouse 性能特点的是 merge tree 及其家族表引擎，并且当前 Clickhouse 也只有 merge 及其家族表引擎支持了主键索引、数据分区、数据副本等优秀的特性。我们当前使用的也是 Clickhouse 的 merge tree 及其家族表引擎，接下来的介绍都是基于引擎展开的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4 cid=&quot;n323&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 分布式高可用&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;先看分布式高可用，不管单节点的性能多强，随着业务的增长，早晚都会有遇到瓶颈的一天，而且意外的宕机在计算机的运行中是无法避免的。Clickhouse 通过分片来水平扩展集群，将总的数据水平分成 m 分，然后每个分片中保存一份数据，避开了单节点的性能瓶颈，然后通过副本即每个分片拥有若干个数据一样的副本来保障集群的高可用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;再看看 Clickhouse 默认的高可用方案，数据写入是通过分布式表写入，然后分布式表会将数据同时写入到同一个分片的所有副本里面。这里会有一个问题，如果副本 0 写入成功，副本 1 写入失败，那么就会造成同一个分片的不同副本数据不一致的问题，所以默认的高可用方案是不能够用于生产环境的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们这里听取的是 Clickhouse 官方的建议，借助了 Zookeeper 实现高可用的方案，数据写入一个分片的时候，仅仅写入一个副本，然后再写 Zookeeper，通过 Zookeeper 告诉同一个分片的其他副本，再过来拉取数据，保证数据的一致性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接下来看一下 Clickhouse 实现这种高可用方案的底层原理，这种高可用的方案需要通过 Clickhouse 的 replicated merge tree 表引擎来实现，其中在 replicated merge tree 表引擎的核心代码中，有大量跟 Zookeeper 进行交互的逻辑，从而实现了多个副本的协同，包括主副本的选举写入任务队列的变更和副本状态的变化等等。可以看到外部数据写入 Clickhouse 的一个分片，会先写入一个副本的内存中，在内存中按照指定的条件排好序，再写入磁盘的一个临时目录。最后将临时目录重命名为最终目录的名字，写完之后通过 Zookeeper 进行一系列的交互，实现数据的复制。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这里没有选用消息队列进行数据的同步，是因为 Zookeeper 更加轻量级，而且写的时候任意写一个副本，其他的副本都能够通过读 Zookeeper 获得一致性的数据，而且就算其他节点第一次来获取数据失败了，后面只要发现它跟 Zookeeper 上的数据记录不一致，就会再次尝试获取数据，保证数据的一致性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n325&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2BabR8yYEX2hY3zRyOyF4JekXicPxkVNqPUWgTsTtytjV2pMkaibnXw6w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n327&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2. 海量数据的写入&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 2.1 Append + Merge&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;h5 cid=&quot;n731&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h5&gt;&lt;section&gt;&lt;span&gt;数据写入遇到的第一个问题是海量数据直接写 Clickhouse 是会失败的。Clickhouse 的 merge tree 家族表引擎的底层原理类似于 LSM tree，数据是通过 append 的方式写入，后续再启动 merge 线程，将小的数据文件进行合并。了解了 Clickhouse merge tree 家族表引擎的写入过程，我们就会发现以下两个问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果一次写入的数据太少，比如一条数据只写一次，就会产生大量的文件目录。当后台合并线程来不及合并的时候，文件目录的数量就会越来越多，这会导致 Clickhouse 抛出 too many parts 的异常，写入失败。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;另外，之前介绍的每一次写入除了数据本身，Clickhouse 还会需要跟 Zookeeper 进行 10 来次的数据交互，而我们知道 Zookeeper 本身是不能够承受很高的并发的，所以可以看到写入 Clickhouse QPS 过高，导致 zookeeper 的崩溃。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n329&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2aaQIBw8epdiaYR9qicDfaHzfteGhluiaDynvpSuq3gbtFzA8E7orRpFBA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我们采用的解决方案是改用 batch 的方式写入，写入 zookeeper 一个 batch 的数据，产生一个数据目录，然后再与 Zookeeper 进行一次数据交互。那么 batch 设置多大？如果 batch 太小的话，就缓解不了 Zookeeper 的压力；但是 batch 也不能设置的太大，要不然上游的内存压力以及数据的延迟都会比较大。所以通过实验，最终我们选择了大小几十万的 batch，这样可以避免了 QPS 太高带来的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实当前的方案还是有优化空间的，比如说 Zookeeper 无法线性扩展，我有了解到业内有些团队就把 Mark 和 date part 相关的信息不写入 Zookeeper。这样能够减少 Zookeeper 的压力。不过这样涉及到了对源代码的修改，对于一般的业务团队来说，实现的成本就会比较高。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n331&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn26GPqG41q8b4pXibRmEiabvCWp0zcjQSyWQJbzS3L0yIXQJDsqaPRLJpA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 2.2 分布式表写入&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果数据写入通过分布式表写入会遇到单点的磁盘问题，先介绍一下分布式表，分布式表实际上是一张逻辑表，它本身并不存储真实的数据，可以理解为一张代理表，比如用户查询分布式表，分布式表会将查询请求下发到每一个分片的本地表上进行查询，然后再收集每一个本地表的查询结果，汇总之后再返回给用户。那么用户写入分布式表的场景，是用户将一个大的 batch 的数据写入分布式表，然后分布式表示按照一定的规则，将大的 batch 的数据划分为若干个 mini batch 的数据，存储到不同的分片上。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n676&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2O4FWvqDv99A66tCnBDgtOuO9ial0kqT4c7QpC9JJ4caEyR1VecRxJ4A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;这里有一个很容易误解的地方，我们最开始也是以为分布式表只是按照一定的规则做一个网络的转发，以为万兆网卡的带宽就足够，不会出现单点的性能瓶颈。但是实际上 Clickhouse 是这样做的，我们看一个例子，有三个分片 shard1，shard2 和 shard3，其中分布式表建立在 shard2 的节点上。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n656&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2Ec1SMkEvEiblXPBCuW9y8OBzBPSoIgkUqXmms6w5cMVmNh2HibGsj0Gw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第一步，我们给分布式表写入 300 条数据，分布式表会根据路由规则把数据进行分组，假设 shard1 分到 50 条，shard2 分到 150 条，shard3 分到 100 条。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二步，因为分布式表跟 shard2 是在同一台机器上，所以 shard2 的 150 条就直接写入磁盘了。然后 shard1 的 50 条和 shard3 的 100 条，并不是直接转发给他们的，而是也会在分布式表的机器上先写入磁盘的临时目录。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第三步，分布式表节点 shard2 会向 shard1 节点和 shard3 节点分别发起远程连接的请求，将对应临时目录的数据发送给 shard1 和 shard3。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这里可以看到分布式表所在的节点 shard2 全量数据都会先落在磁盘上，我们知道磁盘的读写速度都是不够快的，很容易就会出现单点的磁盘性能瓶颈。比如单 QQ 看点的视频内容，每天可能写入百亿级的数据，如果写一张分布式表，很容易就会造成单台机器出现磁盘的瓶颈，尤其是 Clickhouse 的底层运用的是 merge tree，它在合并的过程中会存在写放大的问题，这样会加重磁盘的压力。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们做的两个优化方案:&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第一个就是对磁盘做了 RAID 提升了磁盘的 IO；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二就是在写入之前，上游进行了数据的划分分表操作，直接分开写入到不同的分片上，磁盘的压力直接变为了原来的 n 分之一，这样就很好的避免了磁盘的单点的瓶颈。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n654&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2QBPeWhibLKShibjk8TIdE8hYS1eicYiayDG3kX89uIRoMapWzwppQLRkpA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n31&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;■ 2.3 局部 Top 并非全局 Top&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;虽然我们的写入是按照分片进行了划分，但是这里引入了一个分布式系统常见的问题，就是局部的 Top 并非全局 Top。比如说同一个内容 x 的数据落在了不同的分片上，计算全局 Top100 点击内容的时候，之前说到分布式表会将查询请求下发到各个分片上，计算局部的 Top100 点击的内容，然后将结果进行汇总。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;举个例子，内容 x 在分片一和分片二上不是 Top100，所以在汇总数据的时候就会丢失掉分片一和分片二上的内容 x 的点击数据。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n729&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2TOgjIrv9Cfc0mzibCDzFwnCUrpMKOPkibWViahw0NFCoDXoDibvZTMXh4g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;第二是会造成数据错误，我们做的优化就是在写入之前加上了一层路由，我们将同一个内容 ID 的数据全部路由到了同一个分片上，解决了该问题。这里需要多说一下，现在最新版的 Clickhouse 都是不存在这样这个问题的，对于有 group by 和 limit 的 SQL 命令，只把 group by 语句下发到本地表进行执行，然后各个本地表执行完的全量结果都会传到分布式表，在分布式表再进行一次全局的 group by，最后再做 limit 的操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样虽然能够保证全局 top N 的正确性，但代价就是牺牲了一部分的执行性能。如果想要恢复到更高的执行性能，我们可以通过 Clickhouse 提供的 distributed_group_by_no_merge 参数来选择执行的方式。然后再将同一个内容 ID 的记录全部路由到同一个分片上，这样在本地表也能够执行 limit 操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4 cid=&quot;n337&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3. 高性能的存储和查询&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Clickhouse 高性能查询的一个关键点，就是稀疏索引。稀疏索引这个设计很有讲究，设计的好可以加速查询，设计的不好反而会影响查询效率。因为我们的查询大部分都是时间和内容 ID 相关的，比如说某个内容过去 n 分钟在各个人群的表现如何，我按照日期分钟粒度时间和内容 ID 建立了稀疏索引，针对某个内容的查询，建立稀疏索引之后，可以减少 99% 的文件扫描。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Clickhouse 高性能查询的第二点，就是我们现在的数据量太大，维度太多，拿 QQ 看点的视频内容来说，一天入库的流水就有上百亿条，有些维度有几百个类别，如果一次性把所有的维度进行预聚合查询反而会变慢，并且索引会占用大量的存储空间。我们的优化就是针对不同的维度建立对应的预聚合和物化视图，用空间换时间，这样可以缩短查询的时间。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n761&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn26yH5RzEw8v2syYicXTsdAe2jXE6skMmgrYyAicnx7suiaJ5IB4BJxK6pA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;举个例子，通过 summary merge tree 建立一个内容 ID 粒度聚合的累积，累加 pv 的物化视图，这样相当于提前进行了 group by 的计算，等真正需要查询聚合结果的时候，就直接查询物化视图，数据都是已经聚合计算过的，且数据的扫描量只是原始流水的千分之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分布式表查询还会有一个问题，就是查询单个内容 ID 的时候，分布式表会将查询请求下发到所有的分片上，然后再返回给查询结果进行汇总。实际上因为做过路由，一个内容 ID 只存在于一个分片上，剩下的分片其实都是在空跑。针对这类的查询，我们的优化就是后台按照同样的规则先进行路由，然后再查询目标分片，这样减少了 n 分之 n -1 的负载，可以大量的缩短查询时间。而且由于我们提供的是 OLAP 的查询，数据满足最终的一致性即可。所以通过主从副本的读写分离，也可以进一步的提升性能。我们在后台还做了一个一分钟的数据缓存，这样针对相同条件的查询，后台就可以直接返回。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n767&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2QCZic5WbLG9w38Dk7BuZjeiagOnyoic5VqN6LjzgUOOrscsjH1HiaRtK1w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4 cid=&quot;n340&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4. Clickhouse 扩容方案&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们调研了业内一些常见的方案：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;比如说 HBase 原始数据是存放在 HDFS 上的，扩容只是 region server 的扩容，并不涉及到原始数据的迁移。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;但是 Clickhouse 的每个分片数据都是在本地，更像是 RocksDB 的底层存储引擎，不能像 HBase 那样方便的扩容。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;然后是 Redis，Redis 是 Hash 槽这一种，类似于一致性 Hash 的方式，是比较经典的分布式缓存方案。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Redis slot 在 Hash 的过程中，虽然会存在短暂的 ASK 不可用，但是总体上来说迁移还是比较方便的。就从原来的 h0 迁移迁移到 h1，最后再删除 h0，但是 Clickhouse 大部分都是 OLAP 的批量查询，而且由于列式存储不支持删除的特性，一致性 hash 的方案也不是很合适。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们目前的扩容方案就是从实时数仓另外消费一份数据写入新的 Clickhouse 集群，两个集群一起跑一段时间，因为实时数据我们现在就保存了三天，等三天之后，后台服务就直接访问新的 Clickhouse 集群。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;五、实时系统应用成果总结&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我们输出了腾讯看点的实时数据仓库，DWM 层和 DWS 层两个消息队列，上线了腾讯看点的实时数据分析系统，该系统能够亚秒级的响应多维条件查询请求。在未命中缓存的情况下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;过去 30 分钟的内容查询，99% 的请求耗时在一秒内；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;过去 24 小时的内容查询 90% 的请求耗时在 5 秒内，99% 的请求耗时在 10 秒内。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n345&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu727uN8AYknCD5hAIEr0dn2rdq1yUzZDuBrZFOABUOvCDfNS6GzJzIaZLYDwxMtQbiaAyaJE6oyqhA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;hr/&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;热点推荐&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;hr/&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;更多 Flink 相关技术问题，可扫码加入社区钉钉交流群～&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;1.2078189300411524&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6PUTQaA1BP3Fb8uViccQpspmTibIYEfM7Wv6VACia9CDQfcN8huMVCafZ5s36wThUmbYRTOzMu4hd8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;972&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt; &lt;img class=&quot;__bg_gif&quot; data-ratio=&quot;1&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/Z6bicxIx5naLWBBEcl44aIic1Mthe1nZiaramW5s4e8WwyCYYbTzu6uPBpgI6sxNXNymEnOYKpJpcrItUia7lS64mA/640?wx_fmt=gif&quot;/&gt;  &lt;/span&gt;&lt;span&gt;戳我，查看作者分享原版视频！&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e411ee24ac72af6cb4801734e1f19ec7</guid>
<title>全链路压测（一）：认识全链路压测</title>
<link>https://toutiao.io/k/yts8rpc</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;h2&gt;&lt;span&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;之前断断续续写过一些全链路压测相关的技术文章，很多同学评价还不错。朋友建议我写个系列，基于自己的落地实践经验，对全链路压测做个系统性的梳理总结。今年跳槽后我的工作重心也偏向了全链路压测和稳定性保障方面的研究，这个时间点写这个系列，也算是对自己过去工作的最好总结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整体写作规划里，这个系列大概有14篇内容，不排除后期有新的理解和沉淀，会加更。目前草稿写差不多了，大体的更新节奏，应该是一周2篇左右的样子，静等更新吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;目录大纲&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.5816993464052288&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ftksfIbzTWgvgMUfOnyCv9daMFfaTBia70ndxicRBxLA4ibQOgm6o5NxOicWy2owKc8YyMahuxhRiaax51m2snZYS8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;918&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;背景：天猫2012双11的痛&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;全链路压测这个Topic，最初是阿里提出的，背景缘由也很简单，双十一大促嘛。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;13年之前，阿里每次为了准备双十一大促系统能平稳支撑，都要花4-6个月准备，然后大促结束后花2个月时间打扫战场。整个过程，参与的各个团队的同学加起来有将近200人，其中最耗时的点主要集中在机器容量评估和预案梳理以及压测优化方面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果2012年双11零点时刻，由于访问量过高，还是出了问题：商品超卖无法发货。这个问题当时还上了央视新闻，可见其影响力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来他们内部复盘，一番讨论后，为了避免后续的大促再次出现类似的问题，决定在生产搞压测，这就是现在被很多测试同学所熟知的生产全链路压测的背景由来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;定义：如何理解全链路压测&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;PS：这里的定义是我基于自己对生产全链路压测的了解和实践总结得来的，仅代表个人观点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1、什么是全链路压测？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于实际的生产业务场景和系统环境，模拟海量的用户请求和数据，对整个业务链路进行各种场景的测试验证，持续发现并进行瓶颈调优，保障系统稳定性的一个技术工程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2、全链路压测解决了什么问题？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对业务场景越发复杂化、海量数据冲击，发现并解决整个业务系统的可用性、扩展性以及容错性的过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3、全链路压测创造了什么价值？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;差异：传统压测和全链路压测&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;记得刚开始学习性能测试相关知识的时候，我一直有个疑问：性能测试可以对测试工程师本人和企业带来什么价值？随着不断学习成和工作中的实践以及和很多测试同学交流，我总结出了如下几点优点和潜在价值：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提升测试工程师的技术能力；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提升对系统架构和业务逻辑的了解；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol start=&quot;3&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提升测试工程师在职场和求职市场的竞争力；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;提前发现系统潜在的不稳定因素，提高线上系统稳定性；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;ol start=&quot;5&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;更精准的容量评估和容量规划，降低系统的硬件成本和维护成本；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;保障系统在大促秒杀等场景和峰值流量冲击下的稳定性，助力业务目标达成；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;hr/&gt;&lt;p&gt;&lt;span&gt;随着互联网行业不断发展，系统架构越发复杂，业务场景越发多样化，对性能测试的要求也越来越高，传统压测方式已经无法满足业务和技术的发展需要。相比于传统的压测方式，全链路压测作为性能测试领域新阶段的最佳实践，它们的差异如下：&lt;/span&gt;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;压测类型&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;传统压测&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;全链路压测&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;压测方式&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;Jmeter、Locust、Loadrunner&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;压测集群、流量引擎、录制回放&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;承接方式&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;需求响应式，被动&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;发现系统所有链路存在的瓶颈点，主动&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;压测环境&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;测试环境/性能环境&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;生产环境&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;环境特点&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;环境不稳定/配置低/压测结果参考性不高&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;环境稳定/完全真实环境/压测结果真实可靠&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;压测场景&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;单机单接口、单机单链路、单机混合链路&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;包含覆盖范围内的所有核心链路及场景&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;压测过程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;可观测性较低，延时较高&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;实时可视化观测&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;测试结果&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;数据维度小，无法提供太多数据便于分析&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;提供多维度细粒度的数据，便于快速定位问题优化&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;投入成本&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;需要搭建单独的压测环境&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;span&gt;完全线上生产环境进行，无须单独搭建环境&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.3627450980392157&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ftksfIbzTWgvgMUfOnyCv9daMFfaTBia7qq7icWz38ccniaDSIMUh7DaBGkibh09KIxeeHGNKiak75474hukeog3ACg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1224&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;思考：解决差异带来的不稳定&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;传统压测和生产全链路压测的主要区别，概括来说可以分为如下四个点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.4472934472934473&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ftksfIbzTWgvgMUfOnyCv9daMFfaTBia7Dgf6fg5U0KVyArU8Wxv1qvBicaZcQ4zA6KvUibIRD8cSKho8ib123Z3mw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1053&quot;/&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;span&gt;那么，要解决差异带来的不稳定因素，最终的选择就是生产全链路压测：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.43422263109475623&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ftksfIbzTWgvgMUfOnyCv9daMFfaTBia7JRYnxaMB7L9BG8PXu8GyiaPvPiciblXrhHrb7HjeEVKMiaiaKMgXJjCXIPA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1087&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;挑战：如何落地生产全链路压测&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;虽然全链路压测解决了传统压测过程中的种种痛点，可以为线上性能评估提供更多详实的参考建议。但在落地过程中，全链路压测依然要解决很多问题，主要有如下几点挑战：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.42778541953232463&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ftksfIbzTWgvgMUfOnyCv9daMFfaTBia73ibrHcdTicEKWibT8oibJc7UW0bmVTmWtrBKrnmgIgc6YNjTbDqVcqE2bw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;727&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1、链路梳理&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在大多数企业都是采用微服务架构来设计系统，且业务场景多样化，导致了系统架构异常复杂。要覆盖所有压测范围内的场景，就需要对涉及的所有应用及其调用关系进行梳理。目前业内还没有较好的链路梳理工具，导致这个过程需要人肉来梳理，耗时且费力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2、数据隔离&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;生产全链路压测最重要的一点是避免对生产数据造成污染。业内常见的做法有如下两点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3、避免业务侵入&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在全链路压测落地过程中，有一点必须考虑到的是业务部门的接受能力。如果要通过技术框架改造或者采用数据标记的方式来实现，势必会对生产业务造成一定影响（要改造是需要大量资源和时间的）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4、性能定位分析&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全链路压测是在生产环境进行，压测过程中，除了要防止数据污染，完善的监控体系和实时的可视化链路追踪也是很重要的一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同企业在监控体系方面的建设都不一样，要进行全面详细的流量评估，需要有完善的监控平台来进行各维度的数据采集和展示。在整个压测链路中，实时的可视化链路追踪能实时的观察到每个调用链路的具体信息，对问题的快速发现和定位有重大的帮助。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还要考虑到不把生产服务压挂。因此需要一套完整的机制来保证，压测在正常实施的同时，不对生产服务应用造成影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5、更多挑战&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全链路压测是在生产环境进行，压测过程中，要考虑不对生产服务造成影响。因此需要一套完整的机制来保证，压测在正常实施的同时，不对生产服务应用造成影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;流程：生产全链路压测落地实践&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;生产全链路压测的整个流程，大致可分为三个环节，每个环节的主要事项如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.3445867287543655&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ftksfIbzTWgvgMUfOnyCv9daMFfaTBia7jM97KenibunD1pjs6zLUpYFHutMpAWiaAWUUc5qibgE5ic6ib1IFEPrG0Hg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;859&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;能力建设：生产压测能力演变历程&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;生产全链路压测的本质是能力建设的技术工程，不是一蹴而就。整体的演变历程大致如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.43769716088328076&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ftksfIbzTWgvgMUfOnyCv9daMFfaTBia7hJ7RpPuHE1M5cvDREERPwib7EwZglAb4Vx6SkQiaEcFejvoz99kniamDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1268&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1、需求驱动压测&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个阶段的主要特点是被动式响应压测需求，效率低，无法快速定位性能问题，结果对线上没太多参考价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2、性能体系建设&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个阶段主要是性能测试体系的建设过程，比如日常版本压测和性能基线性能回归等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3、线上风险识别与熔断&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;到了这个阶段，就需要线上有一定的监控报警体系和风险熔断能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4、生产只读业务链路压测&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只读场景相对来说技术难度没那么大，可以通过这个阶段来做到技术练兵。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;5、生产流量数据隔离能力&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面提到了数据安全隔离，这也是生产全链路压测最大的一个技术挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;6、生产部分业务链路压测&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全链路的覆盖场景根据业务不同要覆盖的范围和难度也不一样，建议先从非核心业务开始落地做试点验证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;7、生产全链路压测&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过上面几个步骤，从基础的能力建设、体系建设，到线上的监控能力、只读场景练兵以及数据隔离到试点验证，最终才能达到生产核心链路全链路压测的过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;最后&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上内容主要是对全链路压测的背景及落地实践和演变过程做个介绍，后续的系列文章会针对每个环节进行讨论和说明，敬请期待。建个沟通群，关注回复全链路压测进群。&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>fe552937d399a553a18720ced2a4ea19</guid>
<title>一个 95 分位延迟要求 5ms 的场景，如何做性能优化</title>
<link>https://toutiao.io/k/a2z12ud</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;组内的数据系统在承接一个业务需求时无法满足性能需求，于是针对这个场景做了一些优化，在此写篇文章做记录。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;业务场景是这样：调用方一次获取某个用户的几百个特征（可以把特征理解为属性），特征以 redis hash 的形式存储在持久化 KV 数据库中，特征数据以天级别为更新粒度。要求 95 分位的延迟在 5ms 左右。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个数据系统属于无状态的服务，为了增大吞吐量和降低延迟，从存储和代码两方面进行优化。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;存储层面&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;存储层面，一次调用一个用户的三百个特征原方案是用 redis hash 做表，每个 field 为用户的一个特征。由于用户单个请求会获取几百个特征，即使用&lt;code&gt;hmget&lt;/code&gt;做合并，存储也需要去多个 slot 中获取数据，效率较低，于是对数据进行归一化，即：把 hash 表的所有 filed 打包成一个 json 格式的 string，举个例子：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;// 优化前的特征为 hash 格式&lt;/span&gt;&lt;br/&gt;hash key : user_2837947&lt;br/&gt;&lt;span&gt;127.0&lt;/span&gt;&lt;span&gt;.0&lt;/span&gt;&lt;span&gt;.1&lt;/span&gt;:&lt;span&gt;6379&lt;/span&gt;&amp;gt; hgetall user_2837947&lt;br/&gt;&lt;span&gt;1&lt;/span&gt;) &lt;span&gt;&quot;name&quot;&lt;/span&gt;    &lt;span&gt;// 特征1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;2&lt;/span&gt;) &lt;span&gt;&quot;薯条&quot;&lt;/span&gt;     &lt;span&gt;// 特征1的值&lt;/span&gt;&lt;br/&gt;&lt;span&gt;3&lt;/span&gt;) &lt;span&gt;&quot;age&quot;&lt;/span&gt;    &lt;span&gt;// 特征2&lt;/span&gt;&lt;br/&gt;&lt;span&gt;4&lt;/span&gt;) &lt;span&gt;&quot;18&quot;&lt;/span&gt;     &lt;span&gt;// 特征2的值&lt;/span&gt;&lt;br/&gt;&lt;span&gt;5&lt;/span&gt;) &lt;span&gt;&quot;address&quot;&lt;/span&gt; &lt;span&gt;// 特征3&lt;/span&gt;&lt;br/&gt;&lt;span&gt;6&lt;/span&gt;) &lt;span&gt;&quot;China&quot;&lt;/span&gt;   &lt;span&gt;// 特征3的值&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// 优化后的特征为 string json格式&lt;/span&gt;&lt;br/&gt;string key: user_2837947&lt;br/&gt;val:&lt;br/&gt;{&lt;br/&gt;  &lt;span&gt;&quot;name&quot;&lt;/span&gt;:&lt;span&gt;&quot;薯条&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;age&quot;&lt;/span&gt;:&lt;span&gt;18&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;address&quot;&lt;/span&gt;:&lt;span&gt;&quot;China&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;特征进行打包后解决了一次请求去多个 slot 获取数据时延较大的问题。但是这样做可能带来新的问题：若 hash filed 过多，string 的 value 值会很大。目前想到的解法有两种，一种是按照类型将特征做细分，比如原来一个 string 里面有 300 的字段，拆分成 3 个有 100 个值的 string 类型。第二种是对 string val 进行压缩，在数据存储时压缩存储，读取数据时在程序中解压缩。这两种方法也可以结合使用。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果这样仍不能满足需求，可以在持久化 KV 存储前再加一层缓存，缓存失效时间根据业务特点设置，这样程序交互的流程会变成这样：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.37570394207562346&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwfcU0Y45mM0yjiaKjvU37u3IhSBibXpRlOA8pdc5tMf9hMJibGyqy1dJAPA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1243&quot;/&gt;&lt;/p&gt;&lt;br/&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;代码层面&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接着来优化一下代码。首先需要几个工具去协助我们做性能优化。首先是压测工具，压测工具可以模拟真实流量，在预估的 QPS 下观察系统的表现情况。发压时注意渐进式加压，不要一下次压得太死。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后还需要 profiler 工具。Golang 的生态中相关工具我们能用到的有 pprof 和 trace。pprof 可以看 CPU、内存、协程等信息在压测流量进来时系统调用的各部分耗时情况。而 trace 可以查看 runtime 的情况，比如可以查看协程调度信息等。本次优化使用 压测工具+pprof 的 CPU profiler。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面来看一下 CPU 运行耗时情况：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;右侧主要是 runtime 部分，先忽略&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5274079874706343&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwfLAtG4JVfzic6godD8SZJVyb1sI5885JtddKMuvqqicJt9063GWgeWdibg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2554&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;火焰图中圈出来的大平顶山都是可以优化的地方，&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.46933229813664595&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwfhdQpmQXx5Nhzn6MsTpib0ESq87j28JZeqxibKWCFRrXhAcDrbRiaCgicgg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2576&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里的三座平顶山的主要都是&lt;code&gt;json.Marshal&lt;/code&gt;和&lt;code&gt;json.Unmarshal&lt;/code&gt;操作引起的，对于 json 的优化，有两种思路，一种是换个高性能的 json 解析包 ，另一种是根据业务需求看能否绕过解析。下面分别来介绍：&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;高性能解析包+一点黑科技&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里使用了陶师傅的包&lt;code&gt;github.com/json-iterator/go&lt;/code&gt;。看了他的 benchmark 结果，比 golang 原生库还是要快很多的。自己再写个比较符合我们场景的Benchmark看陶师傅有没有骗我们：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br/&gt; &lt;span&gt;&quot;encoding/json&quot;&lt;/span&gt;&lt;br/&gt; jsoniter &lt;span&gt;&quot;github.com/json-iterator/go&quot;&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&quot;testing&quot;&lt;/span&gt;&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;var&lt;/span&gt; s = &lt;span&gt;`{....300多个filed..}`&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;BenchmarkDefaultJSON&lt;/span&gt;&lt;span&gt;(b *testing.B)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; b.N; i++ {&lt;br/&gt;  param := &lt;span&gt;make&lt;/span&gt;(&lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;interface&lt;/span&gt;{})&lt;br/&gt;  _ = json.Unmarshal([]&lt;span&gt;byte&lt;/span&gt;(s), &amp;amp;param)&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;BenchmarkIteratorJSON&lt;/span&gt;&lt;span&gt;(b *testing.B)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; b.N; i++ {&lt;br/&gt;  param := &lt;span&gt;make&lt;/span&gt;(&lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;interface&lt;/span&gt;{})&lt;br/&gt;  &lt;span&gt;var&lt;/span&gt; json = jsoniter.ConfigCompatibleWithStandardLibrary&lt;br/&gt;  _ = json.Unmarshal([]&lt;span&gt;byte&lt;/span&gt;(s), &amp;amp;param)&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行结果：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.2251270878721859&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwfVY2GfBamwKicibAXD49icn4SJQwH7A52sJN4Q7xqjdaiao6rsXMiaVga6Gw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1377&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个包易用性也很强，在原来 json 代码解析的上面加一行代码就可以了：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;var&lt;/span&gt; json = jsoniter.ConfigCompatibleWithStandardLibrary&lt;br/&gt;err = json.Unmarshal(datautil.String2bytes(originData), &amp;amp;fieldMap&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还有一个可以优化的地方是&lt;code&gt;string&lt;/code&gt;和&lt;code&gt;[]byte&lt;/code&gt;之间的转化，我们在代码里用的参数类型是&lt;code&gt;string&lt;/code&gt;，而 json 解析接受的参数是&lt;code&gt;[]byte&lt;/code&gt;，所以一般在json解析时需要进行转化：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;err = json.Unmarshal([]&lt;span&gt;byte&lt;/span&gt;(originData), &amp;amp;fieldMap)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么&lt;code&gt;string&lt;/code&gt;转化为&lt;code&gt;[]byte&lt;/code&gt;发生了什么呢。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt;{&lt;br/&gt;  a := &lt;span&gt;&quot;string&quot;&lt;/span&gt;&lt;br/&gt;  b := []&lt;span&gt;byte&lt;/span&gt;(a)&lt;br/&gt;  &lt;span&gt;println&lt;/span&gt;(b)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们用汇编把编译器悄悄做的事抓出来：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6128826530612245&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwf977IWSmTt9BwG5bAt5lT1MSmn8fg6yC51ejbgtsGiaVVnOHPq41WNMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1568&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;来看一下这个函数做了啥：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3694646397884997&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwfKticwJ64bC4gOqG4vUxInexVG4ablwjKduwiaiakmHekDtQK6LCKnqUBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1513&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里底层会发生拷贝现象，我们可以拿到&lt;code&gt;[]byte&lt;/code&gt;和&lt;code&gt;string&lt;/code&gt;的底层结构后，用黑科技去掉拷贝过程：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;String2bytes&lt;/span&gt;&lt;span&gt;(s &lt;span&gt;string&lt;/span&gt;)&lt;/span&gt; []&lt;span&gt;byte&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; x := (*[&lt;span&gt;2&lt;/span&gt;]&lt;span&gt;uintptr&lt;/span&gt;)(unsafe.Pointer(&amp;amp;s))&lt;br/&gt; h := [&lt;span&gt;3&lt;/span&gt;]&lt;span&gt;uintptr&lt;/span&gt;{x[&lt;span&gt;0&lt;/span&gt;], x[&lt;span&gt;1&lt;/span&gt;], x[&lt;span&gt;1&lt;/span&gt;]}&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; *(*[]&lt;span&gt;byte&lt;/span&gt;)(unsafe.Pointer(&amp;amp;h))&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;Bytes2String&lt;/span&gt;&lt;span&gt;(b []&lt;span&gt;byte&lt;/span&gt;)&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;return&lt;/span&gt; *(*&lt;span&gt;string&lt;/span&gt;)(unsafe.Pointer(&amp;amp;b))&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面写 benchmark 看一下黑科技好不好用：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; (&lt;br/&gt; &lt;span&gt;&quot;strings&quot;&lt;/span&gt;&lt;br/&gt; &lt;span&gt;&quot;testing&quot;&lt;/span&gt;&lt;br/&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;var&lt;/span&gt; s = strings.Repeat(&lt;span&gt;&quot;hello&quot;&lt;/span&gt;, &lt;span&gt;1024&lt;/span&gt;)&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;testDefault&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; a := []&lt;span&gt;byte&lt;/span&gt;(s)&lt;br/&gt; _ = &lt;span&gt;string&lt;/span&gt;(a)&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;testUnsafe&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; a := String2bytes(s)&lt;br/&gt; _ = Bytes2String(a)&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;BenchmarkTestDefault&lt;/span&gt;&lt;span&gt;(b *testing.B)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; b.N; i++ {&lt;br/&gt;  testDefault()&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;BenchmarkTestUnsafe&lt;/span&gt;&lt;span&gt;(b *testing.B)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; b.N; i++ {&lt;br/&gt;  testUnsafe()&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行速度，内存分配上效果都很明显，黑科技果然黑：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.14258434118395927&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwfkjvyefiaocibVEDp0lKlndNbRoGrkedn6FH1ib7CXxP8xNnFV6BlttRcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1571&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;加 cache，空间换时间&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;项目中有一块代码负责处理 N 个请求中的参数。代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;for&lt;/span&gt; _, item := &lt;span&gt;range&lt;/span&gt; items {&lt;br/&gt;  &lt;span&gt;var&lt;/span&gt; params &lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;string&lt;/span&gt;&lt;br/&gt;  err := json.Unmarshal([]&lt;span&gt;byte&lt;/span&gt;(items[&lt;span&gt;1&lt;/span&gt;]), &amp;amp;params)&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;    ...&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这个需要优化的场景中，上游在单次请求获取某个用户300多个特征，如果用上面的代码我们需要&lt;code&gt;json.Unmarshal&lt;/code&gt;300多次，这是个无用且非常耗时的操作，可以加 cache 优化一下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;paramCache := &lt;span&gt;make&lt;/span&gt;(&lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;string&lt;/span&gt;)&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; _, item := &lt;span&gt;range&lt;/span&gt; items {&lt;br/&gt;  &lt;span&gt;var&lt;/span&gt; params &lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;string&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;  tmpParams, ok := cacheDict[items[&lt;span&gt;1&lt;/span&gt;]]&lt;br/&gt;  &lt;span&gt;// 没有解析过，进行解析&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;if&lt;/span&gt; ok == &lt;span&gt;false&lt;/span&gt; {&lt;br/&gt;   err := json.Unmarshal([]&lt;span&gt;byte&lt;/span&gt;(items[&lt;span&gt;1&lt;/span&gt;]), &amp;amp;params)&lt;br/&gt;   &lt;span&gt;if&lt;/span&gt; err != &lt;span&gt;nil&lt;/span&gt; {&lt;br/&gt;    ...&lt;br/&gt;   }&lt;br/&gt;   cacheDict[items[&lt;span&gt;1&lt;/span&gt;]] = params&lt;br/&gt;  } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;      &lt;span&gt;// 解析过，copy出一份&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;// 这里的copy是为了预防并发问题&lt;/span&gt;&lt;br/&gt;   params = DeepCopyMap(tmpParams)&lt;br/&gt;  }&lt;br/&gt; }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样理论上不会存在任何的放大现象，读者朋友如果有批处理的接口，代码中又有类似这样的操作，可以看下这里是否有优化的可能性。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;for&lt;/span&gt; {&lt;br/&gt;  dosomething()&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;替换耗时逻辑&lt;span/&gt;&lt;/h3&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4274300932090546&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwfvH5ab3WoOiaNXOAw0Zm5PxW6v6jxjbbXiacHUo3vyCp4AGibHichNyib0Ew/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2253&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;火焰图中的 &lt;code&gt;TplToStr&lt;/code&gt; 模板函数同样占到了比较大的 CPU 耗时，此函数的功能是把用户传来的参数和预制的模板拼出一个新的 string 字符串，比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;入参：Tpl: shutiao_test_{{user_id}} user_id: 123478&lt;br/&gt;返回：shutiao_test_123478&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我们的系统中，这个函数根据模板和用户参数拼出一个 flag，根据这个 flag 是否相同作为某个操作的标记。这个拼模板是一个非常耗时的操作，这块可以直接用字符串拼接去代替模板功能，比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;入参：Tpl: shutiao_test_{{user_id}} user_id: 123478&lt;br/&gt;返回：shutiao_test_user_id_123478&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;优化完之后，火焰图中已经看不到这个函数的平顶山了，直接节省了 5%的 CPU 的调用百分比。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.31543921916592726&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwfqjB4cQzBveVGOwXUuoPVhInBbBQq8AmVKsgbpjB4uWNbdnKlq7fjJA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2254&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;prealloc&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还发现一些 growslice 占得微量 cpu 耗时，本以为预分配可以解决问题，但做 benchmark 测试发现 slice 容量较小时是否做预分配在性能上差异不大：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.39883876730683343&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwficKGOIHFkrfSKKOMOib8AIy6rPpN4eI0I72zkggt0jRC0BByiboEolWtQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2239&quot;/&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;&quot;testing&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;test&lt;/span&gt;&lt;span&gt;(m *[]&lt;span&gt;string&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;300&lt;/span&gt;; i++ {&lt;br/&gt;  *m = &lt;span&gt;append&lt;/span&gt;(*m, &lt;span&gt;string&lt;/span&gt;(i))&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;BenchmarkSlice&lt;/span&gt;&lt;span&gt;(b *testing.B)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; b.N; i++ {&lt;br/&gt;  b.StopTimer()&lt;br/&gt;  m := &lt;span&gt;make&lt;/span&gt;([]&lt;span&gt;string&lt;/span&gt;, &lt;span&gt;0&lt;/span&gt;)&lt;br/&gt;  b.StartTimer()&lt;br/&gt;&lt;br/&gt;  test(&amp;amp;m)&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;BenchmarkCapSlice&lt;/span&gt;&lt;span&gt;(b *testing.B)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; b.N; i++ {&lt;br/&gt;  b.StopTimer()&lt;br/&gt;  m := &lt;span&gt;make&lt;/span&gt;([]&lt;span&gt;string&lt;/span&gt;, &lt;span&gt;300&lt;/span&gt;)&lt;br/&gt;  b.StartTimer()&lt;br/&gt;&lt;br/&gt;  test(&amp;amp;m)&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.11581793600721045&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwfrzgrnOW9YDxGtzxF5xjfOQDZ5kfWUh3qCYgeEUYiaicyicJm2kAj4KPDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2219&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于代码中用到的 map 也可以做一些预分配，写 map 时如果能确认容量尽量用 make 函数对容量进行初始化。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.18545127974854064&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwfHjc3LhL0iboNWYWniaQBztytxBETyQfKNIXVOIOGBpZRGb5MNGbLqHZg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2227&quot;/&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;package&lt;/span&gt; main&lt;br/&gt;&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;&quot;testing&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;test&lt;/span&gt;&lt;span&gt;(m &lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;string&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;300&lt;/span&gt;; i++ {&lt;br/&gt;  m[&lt;span&gt;string&lt;/span&gt;(i)] = &lt;span&gt;string&lt;/span&gt;(i)&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;BenchmarkMap&lt;/span&gt;&lt;span&gt;(b *testing.B)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; b.N; i++ {&lt;br/&gt;  b.StopTimer()&lt;br/&gt;  m := &lt;span&gt;make&lt;/span&gt;(&lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;string&lt;/span&gt;)&lt;br/&gt;  b.StartTimer()&lt;br/&gt;&lt;br/&gt;  test(m)&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;BenchmarkCapMap&lt;/span&gt;&lt;span&gt;(b *testing.B)&lt;/span&gt;&lt;/span&gt; {&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := &lt;span&gt;0&lt;/span&gt;; i &amp;lt; b.N; i++ {&lt;br/&gt;  b.StopTimer()&lt;br/&gt;  m := &lt;span&gt;make&lt;/span&gt;(&lt;span&gt;map&lt;/span&gt;[&lt;span&gt;string&lt;/span&gt;]&lt;span&gt;string&lt;/span&gt;, &lt;span&gt;300&lt;/span&gt;)&lt;br/&gt;  b.StartTimer()&lt;br/&gt;&lt;br/&gt;  test(m)&lt;br/&gt; }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个优化还是比较有效的：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.16832579185520363&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/YdZzofiato9LnAibWgptaLDu4h7B5lDvwfplSfosOUb8N3sYKUf0sicib0UcY3TjJjFFAUVSRuqpxjX2dwYERb46cg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2210&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;异步化&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接口流程中有一些不影响主流程的操作完全可以异步化，比如：往外发送的统计工作。在 golang 中异步化就是起个协程。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;总结一下套路：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;代码层面的优化，是 us 级别的，而针对业务对存储进行优化，可以做到 ms 级别的，所以优化越靠近应用层效果越好。对于代码层面，优化的步骤是：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;压测工具模拟场景所需的真实流量&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;pprof 等工具查看服务的 CPU、mem 耗时&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;锁定平顶山逻辑，看优化可能性：异步化，改逻辑，加 cache 等&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;局部优化完写 benchmark 工具查看优化效果&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;整体优化完回到步骤一，重新进行 压测+pprof 看效果，看 95 分位耗时能否满足要求(如果无法满足需求，那就换存储吧~。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外推荐一个不错的库，这是 Golang 布道师 Dave Cheney 搞的用来做性能调优的库，使用起来非常方便：&lt;code&gt;https://github.com/pkg/profile&lt;/code&gt;，可以看 pprof和 trace 信息。有兴趣读者可以了解一下。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>563277c93f3553d97bcacf169659a801</guid>
<title>发现机器学习中的未知未知数</title>
<link>https://toutiao.io/k/dod38k9</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;机器学习 (ML) 模型的性能取决于学习算法以及用于训练和评估的数据。算法的作用得到了很好的研究，并且是众多挑战的焦点，例如SQuAD、GLUE、ImageNet等。此外，还努力改进数据，包括一系列解决 ML 评估问题的研讨会。相比之下，专注于 用于评估 ML 模型的数据并不常见。此外，许多评估数据集包含易于评估的项目，例如具有易于识别的主题的照片，因此它们错过了现实世界上下文的自然模糊性。评估中缺乏模棱两可的真实世界示例削弱了可靠地测试机器学习性能的能力，这使得 ML 模型容易出现“弱点”，即模型难以或不可能准确评估的示例类别，因为评估集中缺少那类示例。&lt;/p&gt;&lt;p&gt;为了解决识别 ML 模型中的这些弱点的问题，我们最近在HCOMP 2020（对全球研究人员和开发人员开放至 2021 年 4 月 30 日）发起了机器学习众包不利测试集(CATS4ML) 数据挑战赛。挑战的目标是提高 ML 评估集的标准，并找到尽可能多的示例，这些示例使算法处理起来令人困惑或有其他问题。CATS4ML 依靠人们的能力和直觉来发现机器学习确信但实际上错误分类的新数据示例。&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;em&gt;什么是机器学习“弱点”？&lt;/em&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;有两类弱点：已知的未知数和未知的未知数。已知未知数是模型不确定正确分类的示例。研究界继续在称为主动学习的领域中研究这一点，并找到了解决方案，概括地说，就是在不确定的例子上以交互方式从人们那里获取新标签。例如，如果模特不确定照片的主题是否是猫，则要求一个人进行验证；但如果系统是确定的，就不会问一个人。虽然这方面还有改进的余地，但令人欣慰的是模型的置信度与其性能相关，即可以看到模型不知道的东西。&lt;/p&gt;&lt;p&gt;另一方面，未知的未知数是模型对其答案充满信心但实际上是错误的示例。主动发现未知未知数的努力（例如Attenberg 2015和Crawford 2019）帮助发现了许多意外的机器行为。与这种发现未知未知的方法相比，生成对抗网络(GAN)生成未知的未知用于计算机视觉错觉形式的图像识别模型，这些模型会导致深度学习模型犯超出人类感知的错误。虽然 GAN 会在有意操纵的情况下发现模型漏洞，但现实世界的示例可以更好地突出模型在日常性能中的失败。这些真实世界的例子是 CATS4ML 感兴趣的未知未知数——挑战旨在收集人类可以可靠解释但许多 ML 模型肯定不同意的未经处理的例子。&lt;/p&gt;&lt;p&gt;&lt;img data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eG1jA7faiceHGJOmJicwQXV0dgcXSF1PU2nIbI5vSYicuYg2ibxiaZXq6v4hDvaxvOT59Fg2rYQlGdO8b4PHWATZdWw/640?wx_fmt=png&quot; data-type=&quot;png&quot;/&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;em&gt;CATS4ML数据挑战的第一版：打开图像数据集&lt;/em&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;的CATS4ML数据的挑战集中在视觉识别，使用图像和标签从打开图像数据集。挑战的目标图像是从开放图像数据集中选择的，以及来自同一数据集的一组 24 个目标标签。挑战参与者被邀请发明新的和创造性的方法来探索这个现有的公开可用的数据集，并专注于预先选择的目标标签列表，发现 ML 模型未知未知数的例子。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eG1jA7faiceHGJOmJicwQXV0dgcXSF1PU2BC3JhjSanFkhvQr9KG0UxXPAS7yuoZSh5nUztjTGn6CQjYicWmVpa4g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;&lt;p&gt;CATS4ML是FAIR最近推出的用于动态数据收集的DynaBench研究平台的补充。DynaBench 使用 ML 模型在循环中解决静态基准测试问题，CATS4ML 通过鼓励探索现有的 ML 基准测试可能是未知的不利示例，专注于改进 ML 的评估数据集。结果将有助于检测和避免未来的错误，还将为模型可解释性提供见解。&lt;/p&gt;&lt;p&gt;通过这种方式，CATS4ML 旨在通过提供数据集资源来提高对问题的认识，开发人员可以使用这些资源来发现其算法的弱点。这也将为研究人员提供有关如何为机器学习创建更加平衡、多样化和具有社会意识的基准数据集的信息。&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;&lt;em&gt;参与&lt;/em&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;我们邀请全球 ML 研究人员和从业者社区与我们一起努力从开放图像数据集中发现有趣、困难的例子。在挑战网站上注册，下载目标图像和标记数据，贡献您发现的图像并参加获胜者的比赛！&lt;/p&gt;&lt;p&gt;为了在本次比赛中得分，参赛者应提交一组图像-标签对，由人工在环评分者确认，其投票应与多个机器上标签的平均机器得分不一致学习模型。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/eG1jA7faiceHGJOmJicwQXV0dgcXSF1PU2B18FM0ueEJmSdiak3IAAHWUaZTbJQvice5MWvlUgvAE0QQOGSSzt41kA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>