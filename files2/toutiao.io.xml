<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>0eac70291b356c94de28d2bbceef8664</guid>
<title>B站取数服务演进之路</title>
<link>https://toutiao.io/k/yx71pwe</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;section mpa-from-tpl=&quot;t&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;上一篇我们介绍了B站基于Iceberg的湖仓一体架构实践，本篇我们将继续介绍B站在取数服务方向的演进之路，这也是湖仓一体架构的实践的重要表现方式。&lt;/p&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;01&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;引言&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;2.909090909090909&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VKL4sQiapMh3aMfiaIsOd0xCAAcnrFtpKzEK9BM7mfIMJDTzDVA3EDjm1sYdKRTysAibprJlUkJvy9tyXJtjXRBSA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;22&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;数据平台部作为B站的基础部门，为B站各业务方提供多种数据服务，如BI分析平台，ABTest平台，画像服务，流量分析平台等等，这些服务、平台背后都有海量数据的取数查询需求。伴随着业务的发展，取数服务也面临越来越多的挑战：&lt;span&gt;  &lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;需求多、人力紧张，越来越多业务基于数据驱动来做运营，相关的取数需求如：指标查询、UP主、稿件等明细数据的个性化查询需求越来越多，导致在需求响应上，有限的人力跟不上业务发展。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;系统架构重复建设：&lt;/span&gt;&lt;span&gt;基于Lambda，Kappa的大数据应用架构在B站有一些应用积累，但非平台化，导致在新场景支持上，出现重复建设，增加了维护成本。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;性能优化成本高：&lt;/span&gt;&lt;span&gt;在满足多种取数场景需求上，数据服务引入多种引擎，比如Elasticsearch、ClickHouse、HBase、MongoDB，这些引擎都需要查询定制优化，增加了研发成本。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;基于这些问题的思考，我们在取数服务上经过了2次大的架构升级，不断探索服务化，平台化之路，下面介绍我们在这方面的工作，欢迎大家一起学习交流。&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;02&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;演进之路&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img data-ratio=&quot;2.909090909090909&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VKL4sQiapMh3aMfiaIsOd0xCAAcnrFtpKzEK9BM7mfIMJDTzDVA3EDjm1sYdKRTysAibprJlUkJvy9tyXJtjXRBSA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;22&quot; class=&quot;rich_pages wxw-img&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;我们在取数服务的升级道路上，大概分为三个时期：最开始是&lt;strong&gt;石器时代&lt;/strong&gt;，这个时期主要以响应业务需求，技术可复用为主；第二时期是&lt;strong&gt;铁器时代&lt;/strong&gt;，我们开始尝试做一些通用服务来支持基础需求，比如统一出仓，统一查询，降低研发成本；第三时期是&lt;strong&gt;工业时代&lt;/strong&gt;，为了更快的响应业务需求，我们尝试引入湖仓技术来进一步提升取数研发的效率。下面分别介绍。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2.1 石器时代 - 烟囱式开发&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;取数服务在早期建设时，按照常规方式，我们将过程分为4个阶段：数据模型（数仓建模）、数据存储，查询接口（取数接口），数据产品（业务定制），如下图所示：&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.1408730158730158&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Zp5qolPqxIwgVgu7icE4bm1h174IOxqvUcwwRIwApc6d5rCpzIgTP6vTKjIln9M3x4fopAFKoibvJ7SX9uMxR7JA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1008&quot;/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;数据模型：&lt;span&gt;数仓建模阶段，按照标准方式，ODS层，DWD层，DWA层来对数据进行分层，分主题建模，通过Hive，Spark对离线数据进行建模，通过Flink进行实时数据建模。&lt;/span&gt;&lt;span&gt;最终对业务上透出的以DWD、DWA层数据。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据存储：&lt;/span&gt;&lt;span&gt;根据不同业务场景的数据查询需求，选型不同引擎来支持业务取数，比如指标数据查询，我们会将数据存储到TiDB中；&lt;/span&gt;&lt;span&gt;对于明细数据的批量查询，我们会将数据存储到ClickHouse，对于点查数据我们会将数据存储到TaiShan DB（内部的 KV 存储）等等。&lt;/span&gt;&lt;span&gt;这些个性化使用，早期基于工程师设计方案选型判断做出决策。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;查询接口：&lt;/span&gt;&lt;span&gt;基于业务产品的取数需求，定制化研发各种取数HTTP接口。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据产品：&lt;/span&gt;&lt;span&gt;主要支持2大类产品，一类是通用类平台产品，如BI平台，DMP用户画像，ABTest平台，另一类是业务垂类产品，比如B站UP主洞察分析，用户增长指标查询等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;2.1.1 早期面临的挑战&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;这个模式我们有2个角色来支持业务需求，一个是数仓同学，另一个是应用开发同学，整体研发流程如下&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3125904486251809&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Zp5qolPqxIyz7LwbZ6iaEicqvUAqS1o4aSzSLwiaXJYS6x84icyUqZNwsxy7eHq6I3YWyHOaEbSsegs3zgk9krVpAw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1382&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在早期业务量不大的情况下，上述架构和流程能支持业务需求，分工较为明确，但随着业务规模增大，取数需求增多，其带来的问题也逐渐凸显：&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;重数据模型，数据工作量大，研发周期长，出现人力短板，研发跟不上需求。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;技术架构重复建设，比如相同数据不同业务需求会出现重复出仓，相同取数逻辑分业务重复开发，导致维护成本上升。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;重复建设也带来了数据口径一致性的问题，排查成本高。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;基于上述问题的思考，我们开始将一些标准化的能力升级为统一服务。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2.2 铁器时代 - 统一化服务&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;这个时期我们重点考虑存储和计算统一。通过将数据的出仓过程标准化，引入数据构建流程，将数据进行统一存储。然后在上面搭建了一个基于SQL DSL的取数引擎，内部代号叫Akuya SQL Engine（ASE）。整体架构如下图所示：&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.427536231884058&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Zp5qolPqxIyz7LwbZ6iaEicqvUAqS1o4aSlOf5Qlnp41aCWWqfwYGYXTkDmhSvefHphh3otcb2a5QCQ6Xuaiaczbg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1380&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2.2.1 数据构建&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;数据构建任务是基于Flink实现的流批一体作业，内部代号为Ark。Source对接了kafka和hive hcatalog，分别支持实时数据和离线数据，Sink主要兼容4种引擎来做统一存储：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;Elasticsearch：存储指标数据，利用动态列来存储维度信息，支持预计算指标查询。查询响应在毫秒级。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;ClickHouse：存储大宽表明细数据，利用ClickHouse的列式存储特性，支持百亿级明细数据查询，查询响应在秒级。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;TiDB：存储明细数据，支持亿级数据点查，查询响应在毫秒级。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;InfluxDB：存储实时指标数据，查询响应在毫秒级。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4043478260869565&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Zp5qolPqxIyz7LwbZ6iaEicqvUAqS1o4aSs5psMOpqr7N8JfDdJ3icZia7ibzsY7wJ8bVbHaiaNpfgCp6liciaJXcurL6w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1380&quot;/&gt;&lt;/section&gt;&lt;section&gt;上图为数据构建系统的架构，用户通过数据构建平台可视化配置数据出仓任务，平台会根据不同离线、实时数据类型触发相应的Ark任务，并托管在内部的AiFlow（内部自研的机器学习平台）调度平台上。&lt;/section&gt;&lt;section&gt;&lt;span&gt;2.2.2 数据查询&lt;/span&gt;&lt;/section&gt;&lt;section&gt;ASE为了兼容不同存储引擎的标准化数据查询，我们引入了SQL语法，参考了Apache Calcite，Tidb Parser项目，考虑到内部服务Go语言为主，我们最终基于TiDB Parser扩展实现了SQL DSL解析，并独立成Service，同时基于Calcite实现自定义JDBC Driver，兼容其他大数据平台。下面以指标数据查询为例，介绍下主要实现思路：&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;通过Parser解析SQL为AST语法树后，首先会对接AMS（内部元数据服务）进行元数据校验，以及元信息查询；然后进行优化策略，如多指标同时查询，会自动并行化；最后结合元数据信息转化为物理计划查询底层引擎，如存储在ES中预计算指标，会转化为ES DSL API查询，存储在TiDB中指标查询会转化为JDBC协议访问数据。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4312590448625181&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Zp5qolPqxIyz7LwbZ6iaEicqvUAqS1o4aSo1sicWCg9Y1cefaxsiasLR3wYmAVdCYn6I2ibfxhC4N9UgzoADKsMKt2A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1382&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6213872832369942&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Zp5qolPqxIyz7LwbZ6iaEicqvUAqS1o4aSH096m9SuVHnM6Gtfx6B1CiaVRBwvdhWkDlTOPEZjv1mvJFlmvwqWYhg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1384&quot;/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;通过上述SQL DSL，我们可以支持如下一些场景查询&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;根据维度查询多指标&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;select&lt;/span&gt; dim1, dim2, pv, uv &lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; business.metric &lt;span class=&quot;code-snippet__keyword&quot;&gt;where&lt;/span&gt; log_date = &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;20210310&#x27;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;根据维度分组统计&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;select&lt;/span&gt; dim1, &lt;span class=&quot;code-snippet__keyword&quot;&gt;sum&lt;/span&gt;(pv) &lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; business.metric &lt;span class=&quot;code-snippet__keyword&quot;&gt;where&lt;/span&gt; dim1 &lt;span class=&quot;code-snippet__keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; dim2 &lt;span class=&quot;code-snippet__keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; log_date=&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;20210310&#x27;&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;by&lt;/span&gt; dim1&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;根据年月汇总指标&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;month&lt;/span&gt;(), &lt;span class=&quot;code-snippet__keyword&quot;&gt;sum&lt;/span&gt;(pv) &lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; business.metric &lt;span class=&quot;code-snippet__keyword&quot;&gt;where&lt;/span&gt; dim1 &lt;span class=&quot;code-snippet__keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; log_date&amp;gt;&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;20200101&#x27;&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; log_date&amp;lt;=&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;20201231&#x27;&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;month&lt;/span&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;单指标年月环比计算&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;select&lt;/span&gt; log_date, pv, year_to_year(pv) &lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; business.metric &lt;span class=&quot;code-snippet__keyword&quot;&gt;where&lt;/span&gt; dim1 &lt;span class=&quot;code-snippet__keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; dim2 &lt;span class=&quot;code-snippet__keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; log_date &amp;gt;= &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;20210301&quot;&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; log_date &amp;lt;= &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;20210310&quot;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;select&lt;/span&gt; log_date, uv, month_to_month(uv) &lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; business.metric &lt;span class=&quot;code-snippet__keyword&quot;&gt;where&lt;/span&gt; dim1 &lt;span class=&quot;code-snippet__keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; dim2 &lt;span class=&quot;code-snippet__keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; log_date &amp;gt;= &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;20210301&quot;&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; log_date &amp;lt;= &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;20210310&quot;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;month(), year\_to\_year(), month\_to\_month() 为系统UDF，标准函数&lt;/span&gt;&lt;/section&gt;&lt;section&gt;派生指标计算&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;select&lt;/span&gt; CTR(点击pv, 展现pv) &lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; business.metric &lt;span class=&quot;code-snippet__keyword&quot;&gt;where&lt;/span&gt; dim1 &lt;span class=&quot;code-snippet__keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; dim2 &lt;span class=&quot;code-snippet__keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; log_date&amp;gt;&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;20200101&#x27;&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;and&lt;/span&gt; log_date&amp;lt;=&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;20201231&#x27;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;CTR是UDF，支持业务自定义实现&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2.2.3 中期面临的挑战&lt;/span&gt;&lt;/section&gt;&lt;section&gt;有了数据统一存储和查询之后，我们对应的研发模式上也随之改变如下：&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.26406926406926406&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Zp5qolPqxIyz7LwbZ6iaEicqvUAqS1o4aSniaSOXBl4Vx2icibc1cBBTqrWLSKymicictesyTV1oltg4Wibb3SRBZtengA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1386&quot;/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;数据同学：聚焦数据模型建设，引入统一数据构建能力后，这部分工作可以由应用开发同学方便的自助操作。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;应用开发同学：不用再重复开发取数接口，通过统一取数接口可以直查数据，更聚焦产品功能建设。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;进一步的实践发现，我们依然面临几个突出问题：&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据重复建设：&lt;/span&gt;&lt;span&gt;由于存在数据出仓过程，那么离线数据和存储引擎上必然存在重复数据，导致数据管理成本上升。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;性能优化成本高：需要考虑为不同的存储引擎做查询优化，定制优化成本高。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;开放的工具、服务较少：随着数据应用场景增多，对取数流程引入的功能需求越来越多，如数据安全，数据DQC，数据抽样等等，业务方（需求方）希望能更多的参与其中，但在这方面平台能力建设不足。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;为了能更好的解决这些问题，我们在21年开始尝试引入湖仓一体架构来优化。&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2.3 工业时代 - 湖仓一体架构&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;目前我们在B站探索搭建湖仓架构上的取数服务，主要思路是降低数据出仓成本，在低成本存储架构上，完善数据处理和管理功能。并形成PaaS能力。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6933570581257414&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Zp5qolPqxIwgVgu7icE4bm1h174IOxqvUFiaFRriaekhialEGFibhJuqkpa3zHyXe7D5OveA5XaWxMhcFDkMqZmQeicw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1686&quot;/&gt;&lt;/p&gt;&lt;section&gt;我们兼容历史架构，新的湖仓一体平台有几个核心能力：&lt;br/&gt;&lt;/section&gt;&lt;section&gt;（1）基于HDFS的数据湖仓，数据无需出仓：&lt;/section&gt;&lt;section&gt;我们为DB，服务器，消息队列等数据源提供统一的数据接入层，可以快捷将生产环境中的结构化离线数据，实时数据抽取到数据仓库中。实现标准存储。&lt;span&gt; &lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;（2）打通元数据，湖仓元数据共享：&lt;/section&gt;&lt;section&gt;湖仓基于Iceberg统一建设，通过HCatalog实现湖仓元数据的统一化管理，Hive表和Iceberg表可以无缝切换。&lt;/section&gt;&lt;section&gt;（3）支持数据索引，提升查询性能，支持数据事务，保障一致性：&lt;/section&gt;&lt;section&gt;直接基于Hive表查询数据较慢，无法直接对接业务取数，但在Iceberg中引入数据索引机制，能大幅度提升取数性能，平均在秒级响应，经过定制调优甚至能到毫秒级，可以满足大部分的取数需求。同时有了大数据上的事务ACID能力，对于一些敏感型业务，可确保并发访问的一致性。感兴趣的同学，可以参考另外一篇文章《B站基于Iceberg的湖仓一体架构实践》。&lt;/section&gt;&lt;section&gt;&lt;span&gt;（4）开放更多数据处理服务能力，加速数据应用：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;有了Iceberg强大的数据查询性能作为后盾，同时数据无须出仓，我们在湖仓上逐步完善数据服务能力，并使之平台化，直接开放给用户使用。比如：&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据索引：&lt;/span&gt;&lt;span&gt;我们支持先建表后加索引，所以在取数使用时，可以按需来性能调优，我们将能力平台化，方便用户根据自己需求来优化索引，提升取数体验。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Ad-Hoc：数据探查分析是很高频的一个需求，我们通过对接Trino服务（自研的Iceberg查询服务），可以支持交互式分析。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据ETL：并支持SQL语法读写Hive表和Iceberg表，如：&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;section&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;insert&lt;/span&gt; overwrite &lt;span class=&quot;code-snippet__keyword&quot;&gt;table&lt;/span&gt; iceberg_rta.dm_growth_dwd_rta_action_search_click_deeplink_l_1d_d&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;select&lt;/span&gt; &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  search_time&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    , click_time&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    , request_id&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    , click_id&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    , remote_ip&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    , platform&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    , app_id&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    , account_id&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    , rta_device&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    , click_device&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    , start_device&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    , source_id&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; b_dwm.dm_growth_dwd_rta_action_search_click_deeplink_l_1d_d&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;where&lt;/span&gt; log_date=&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;20220210&#x27;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;distribute&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;by&lt;/span&gt; source_id &lt;span class=&quot;code-snippet__keyword&quot;&gt;sort&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;by&lt;/span&gt; source_id&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;数据元信息：整合了湖仓元数据信息管理，可以统一查询。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;数据API：通过Akuya SQL Engine（ASE），对接Trino服务，可以指定Iceberg表自动生成数据API。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;2.3.1&lt;/span&gt;&lt;span&gt; 现阶段&lt;/span&gt;&lt;span&gt;的挑战&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在湖仓一体架构上，我们通过完善平台能力，支持多人协同参与研发，提升效率，变成如下：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.315028901734104&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Zp5qolPqxIyz7LwbZ6iaEicqvUAqS1o4aSXD9Qjwu56O0YO7E0SnoEsjaT0sAwRaffuiaCWx4j8DXDl4K0xLAC36w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1384&quot;/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;数仓同学：负责数据接入湖仓，轻度模型建设，降低数据复杂度。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;BI同学：通过更多的平台化功能，BI同学也可以介入，根据数据产品需求进行数据探查，并能直接作用在数据产品上。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;应用开发同学：通过索引、事务能力，更灵活的实现取数需求，支持更多的应用场景开发。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span/&gt;当前我们在湖仓架构上的应用工具还在完善中，后续会开放更多的数据处理服务方便用户取数。&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;03&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;总结展望&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;2.909090909090909&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VKL4sQiapMh3aMfiaIsOd0xCAAcnrFtpKzEK9BM7mfIMJDTzDVA3EDjm1sYdKRTysAibprJlUkJvy9tyXJtjXRBSA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;22&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;湖仓一体架构的引入，让数据处理变的更加高效。我们围绕湖仓架构大胆探索，小心求证。在新老架构上做了较多的融合工作，比如元信息管理，查询服务等工作。通过实践经验来看，湖仓一体能促进更多研发协同，降低用户生成数据、使用数据的门槛。未来，我们将继续提升平台化能力，进一步提升取数体验。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;关联阅读&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzkzNzMxOTI1NQ==&amp;amp;mid=2247483734&amp;amp;idx=1&amp;amp;sn=d97d71939e488d8fe637247b2c81446c&amp;amp;chksm=c2900f6ef5e786783e6b93f8d5c67e59a42626f82fa7f059d2bfe0f2cdbb67f13af6ae92478e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;B站基于Iceberg的湖仓一体架构实践&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;B站基于Iceberg的湖仓一体架构实践&lt;/a&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzkzNzMxOTI1NQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/Zp5qolPqxIw0oWTJn2gOIPqxXPLTrg9aTmqRRpaG6F1VSejQkTVcrzX3tvibgwZ6dEqgwjS3ia9tOribshUxtIKsA/0?wx_fmt=png&quot; data-nickname=&quot;哔哩哔哩技术&quot; data-alias=&quot;bilibili-SYS&quot; data-signature=&quot;哔哩哔哩技术分享&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzUxNTE4OTc0Mg==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/EVKwaZXNTl9OCCo7pxLHz2e2I3kV3rTPao5LlIickfJS79DNd2yjqjfYEtwtMOyVuKhJoDIq6UU4U9TQbjvOLaQ/0?wx_fmt=png&quot; data-nickname=&quot;哔哩哔哩招聘&quot; data-alias=&quot;&quot; data-signature=&quot;生产快乐的地方&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>9546cedde377c95b088208ff8da90ac2</guid>
<title>他，45岁，“华人首富”，无房无车——深度起底赵长鹏和他的数字货币</title>
<link>https://toutiao.io/k/qaeetcv</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;p&gt;&lt;span&gt;本文内容节选自&lt;strong&gt;「码农周刊VIP会员专属邮件周报 Vol.088」&lt;/strong&gt;，感谢阅读。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MzA0ODkyMA==&amp;amp;mid=2655078432&amp;amp;idx=2&amp;amp;sn=f1ba1fa5fbfbcf98a3e6f610b258cf05&amp;amp;chksm=bd2918178a5e9101b993d9e84d783562c995577cec855adf32ccb5946ff4da21fd6e89ba078e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;想邮件订阅周报？点此即刻订阅！&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;想邮件订阅周报？点此即刻订阅！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MzA0ODkyMA==&amp;amp;mid=2655078432&amp;amp;idx=2&amp;amp;sn=f1ba1fa5fbfbcf98a3e6f610b258cf05&amp;amp;chksm=bd2918178a5e9101b993d9e84d783562c995577cec855adf32ccb5946ff4da21fd6e89ba078e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;‍‍&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;325&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AjN1jquNavibxN2ZVP72EwkSLibibWpkyHxCahAbvgsJEUBDOucdoMibBUer6RNpTOWYvricOllyKzjFTsBF7SnqK1A/640?wx_fmt=png&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本期，首先分享的是&lt;strong&gt;如何记住所学的东西？&lt;/strong&gt;，摘录几条，供参考。&lt;br/&gt;1）学习要以时间为基础，定期休息，了解你好奇的是什么；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 2）学习的时候要清理工作记忆，应用元认知，用问题去“围攻”学习对象，改善理解； &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）课后要写高度概括的总结，细化，交叉学习，转化，并选出永远不能忘记的东西；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 4）课余跟朋友讨论自己学了什么，应用间隔重复来防止遗忘，并养成每天回忆的习惯；&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; 5）应用综合练习，通过对复杂环境的模式匹配来掌握知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;……&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;中国云市场的新逻辑&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://mp.weixin.qq.com/s/qSNURmWMfep20o-AwOoEFg&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;市场环境和政策环境都在变化，云公司的商业模型、技术模型、政策法规模型，以及自身定位均需重构。&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;深度起底赵长鹏和他的数字货币&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://mp.weixin.qq.com/s/m71kjgIy3m4hKTgRXqzOqQ&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;全球流浪的“华人首富”无房无车&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;从 VSCode 看大型 IDE 技术架构&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://toutiao.io/k/acuovgh&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;VSCode 开发团队从 10 来个人开始，早期成员大多有 Eclipse 开发团队的背景。&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;知乎的用户画像与实时数据的架构与实践&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://toutiao.io/k/0up430p&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;实践经验和心得体会&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;阿里巴巴开源的，帮助你快速搭建本地和云端 IDE 的框架&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://github.com/opensumi/core/blob/main/README-zh_CN.md&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旨在解决阿里经济体内部 IDE 产品研发的重复建设问题，满足 IDE 在更多垂直场景的定制能力。&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;一个开箱即用的，全周期的数据环境解决方案&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://github.com/macacajs/macaca-datahub/blob/master/README.zh.md&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;支持从本地开发阶段，到集成测试阶段，以及上线前验证阶段的一系列数据环境需求。&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;成为一名优秀Java开发人员的7个步骤&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://toutiao.io/k/6kwaapq&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;供参考&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;万字长文教你用Go开发区块链应用&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://toutiao.io/k/3f3i7ey&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一步步教你&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;《非常时期囤货手册》&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://github.com/toutiaoio/A-Guide-To-Stockpiling&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个可供选择的居家封闭情况下的商品列表&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;《区块链黑暗森林自救手册》&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;https://github.com/slowmist/Blockchain-dark-forest-selfguard-handbook&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;供参考&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MzA0ODkyMA==&amp;amp;mid=2655078432&amp;amp;idx=2&amp;amp;sn=f1ba1fa5fbfbcf98a3e6f610b258cf05&amp;amp;chksm=bd2918178a5e9101b993d9e84d783562c995577cec855adf32ccb5946ff4da21fd6e89ba078e&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;想邮件订阅周报？点此即刻订阅！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MzA0ODkyMA==&amp;amp;mid=2655078432&amp;amp;idx=2&amp;amp;sn=f1ba1fa5fbfbcf98a3e6f610b258cf05&amp;amp;chksm=bd2918178a5e9101b993d9e84d783562c995577cec855adf32ccb5946ff4da21fd6e89ba078e&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;1&quot;&gt;&lt;span&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;325&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AjN1jquNavibxN2ZVP72EwkSLibibWpkyHxyJ9h3jlN45cDia9gELfqK5QibDhPb4YXaryX2SQkhlwnwKlyHTuEc6Ag/640?wx_fmt=png&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8f32fca3b337745bcf9471266273bfed</guid>
<title>如果老板要求你的系统接入春晚大流量活动，你会心慌慌吗？</title>
<link>https://toutiao.io/k/0ps3624</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;article tabindex=&quot;0&quot;&gt;&lt;p&gt;&lt;span&gt;今天给大家分享一个话题，就是如果要是你老板突然要求你把你负责的系统，要接入到春晚中去抗下春晚带来的超大流量，你会感到心里特别慌，然后特别没底吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我估计大部分兄弟应该都会感到很慌很没底，不过没事，今天我们就来给大家讲讲，如果咱们系统要接入春晚活动抗下超大并发流量，应该怎么来优化设计。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;回头看看：原始系统技术架构&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然说到系统接入春晚大并发流量，那么就得先谈谈没接入之前，你的系统大概长什么样子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实也挺简单，大家一般日常负责开发的系统，通常都是用 SpringBoot+SSM 框架技术栈来写代码，对外基于 SpringBoot 的内嵌 Tomcat 提供 Http 接口，然后用 Nacos+Dubbo 来 RPC 调用别的系统，接着就是连接 MySQL 数据库执行 CRUD 操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图：&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5671957671957671&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1J6IbIcPCLZnABF2GlsRMKWxibKQG4RiaCOBicU66icZOpgFM9Jkia7zQZo3Q2fQp97viaAqAZDE58KUYsJhk4k00jHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1890&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;基于 CDN 的活动静态页面缓存方案&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;好，那么接着我们来分析一下，一旦要是这个系统接入了春晚大流量活动以后，超高的流量，可能在平时百倍以上要打到我们的系统来，此时应该如何来优化这个系统架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先第一个问题，就是对于一些静态化的资源，比如说图片/视频一类的资源，要是用户手里拿个 APP 看我们提供的图片和视频的时候，这些东西要是都走到我们后台系统来获取，大家觉得靠谱吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那明显不靠谱啊，因为这种图片和视频一般都比较大，如果大量的人同时请求我们写的 Java 系统来请求下载获取图片和视频，那绝对会把系统搞崩溃的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以一般来说，这个时候都应该上一个东西，叫做 CDN。这个 CDN 呢，大概意思就是说，在全国各地都搞一批服务器，然后呢，让 CDN 提前请求我们的后端系统，把一些图片、视频一类的静态资源都加载到 全国各地的 CDN 服务器上去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接着呢，全国各地的用户打卡手机 APP，想要加载图片和视频的时候，就近找一个距离自己最近的 CDN 服务器加载图片和视频就可以了，这样就可以让超高流量分散到全国各地的很多 CDN 服务器上去了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;大家看下图：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5781683626271971&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1J6IbIcPCLZnABF2GlsRMKWxibKQG4RiaCQMUkOQDLiaaNU7xp2hjUo9rmicWiammlBhXAC1qVazeehBsa6gy4FMxnA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2162&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;好，那么现在咱们全国各地用户打开手机 APP 查看我们的各种活动的时候，活动的图片和视频是可以从全国各地就近找一个 CDN 服务器获取了，等于这块大流量是分散到全国各地 CDN 服务器去了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么但是活动页面里可能除了图片和视频以外，还有很多别的数据是得动态查询获取的呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;基于 Nginx+Tomcat+Redis 的多级缓存方案&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就是说全国各地用户还是得发送大量的请求到我们后台系统来加载一些数据，那么对于这种高并发的数据读取该怎么来抗呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;简单，上一套多级缓存架构，我们可以在 Tomcat 前面加一层 Nginx 反向代理服务器，在 Nginx 里可以基于 Lua 脚本自己写代码，然后在 Nginx 的内存里可以基于 LRU 策略缓存一些热门数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后如果是 Nginx 里没有缓存到的数据，可以在我们的业务系统 Tomcat 里用本地 Cache，比如说 Guava 就可以提供本地缓存 Ccache，同样基于 LRU 策略缓存一些数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后就是如果 Tomcat 本地缓存里也没有，就可以去 Redis 分布式缓存集群里加载缓存数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基本上通过 Ngxin+Tomcat+Redis 三级缓存架构，就可以把高并发读取的流量全部抗下来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;如下图：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5406162464985994&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1J6IbIcPCLZnABF2GlsRMKWxibKQG4RiaCnkyR0FKiazW3LMNmRic7K4RxKX3TIY24GYmMM6JXAHdbLIE8tGcxLLAw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2142&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;超高并发写请求 RocketMQ 削峰填谷方案&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下一个问题来了，那么参与春晚活动的时候，除了这种超高并发的大流量读取以外，还可能会因为参与活动发起超高流量的数据写入请求呢？此时应该怎么抗下来呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为这个时候，妥妥的是不可能靠什么 CDN 全国各地服务器、Nginx 本地缓存给你抗了，那必须你自己扛下来啊。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个时候往往是这样，首先第一个是机器扩容，因为如果有大流量的数据写入，那确实咱们平时的业务系统部署的机器数量可能是不够多的，所以往往再抗这种大活动的时候，得临时扩容一批机器出来，这是第一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，一般来说这种大流量数据写入，往往会采取让我们业务系统收到请求后，先写入到 Redis 缓存里去，然后写一个消息到 RocketMQ 里去，接着再从 RocketMQ 里消费消息后异步落入 DB 里去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为数据库能抗的写入压力是有限的，大并发流量写入是不适合他的，所以往往会用这种方式来做一个处理，同样的机器配置，Redis 和 RocketMQ 可以抗几万并发，MySQL 只能抗几千并发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;所以此时，架构如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5434198746642793&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1J6IbIcPCLZnABF2GlsRMKWxibKQG4RiaCVef3QooArHjzKal6uray0IIzGu98icJwCSmkKFGOxT7z2zGcmYcfqBw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2234&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;系统限流防雪崩体系架构方案&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后呢，其实还应该再加一个机制，那就是限流，因为在上述这套架构上线以前，应该对这套架构通过三级缓存可以抗多大读流量压力，以及基于写入 Redis+RocketMQ 异步写 DB，可以抗多大写流量压力，包括临时扩容一批机器后，整体全链路大致可以抗多大的读写 TPS，这些都得通过全链路压测去测试出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然后应该根据这个系统能整体抗的最大读写压力，在 Nginx 那一层加入限流机制，一旦要是每秒流量超过了最大值，此时直接限流，不允许继续放行，避免系统被压垮。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5498652291105122&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1J6IbIcPCLZnABF2GlsRMKWxibKQG4RiaCQMjumGaYwJw5HD61QdxgxNTmWricic1Aayfnb5IlIyu0VY5cpkIOxpxw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2226&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;好了，今天的分享就到这里了，希望大家对于这种普通系统接入大活动超高流量下的架构设计能有一定的了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;若有收获，就点个赞吧！！&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_iframe&quot; data-pluginname=&quot;videosnap&quot; data-id=&quot;export/UzFfAgtgekIEAQAAAAAAYU4EDiCi8QAAAAstQy6ubaLX4KHWvLEZgBPE86IoQgVLPeiDzNPgMIsyk32aWkO7IMzOclqOsU-2&quot; data-url=&quot;https://findermp.video.qq.com/251/20304/stodownload?encfilekey=rjD5jyTuFrIpZ2ibE8T7YmwgiahniaXswqzvoa3ZwBjuRS9LDWurYNnvkMTdJQtxV1sZVfZGXtWlRHK9q5NWbF0CYFtLu4kpy8MB0sfFkBWrOGV5b2SycguPA&amp;amp;adaptivelytrans=0&amp;amp;bizid=1023&amp;amp;dotrans=0&amp;amp;hy=SH&amp;amp;idx=1&amp;amp;m=&amp;amp;scene=0&amp;amp;token=AxricY7RBHdXDtln0TeKQPsFtAvj5nxwfXwmv5z9PBVJia3aDgEL70PPFaZAhkpMLFibzeH7E3ASxU&quot; data-headimgurl=&quot;http://wx.qlogo.cn/finderhead/Q3auHgzwzM5nv7YHhmhvPsGGX04JCIgibK2x2Ru0TOY9HeZTGSIL1KQ/0&quot; data-username=&quot;v2_060000231003b20faec8c5e08a1fc3d5c807ec30b07756771265bc6b6234fb9e05062ae69ab4@finder&quot; data-nickname=&quot;儒猿IT&quot; data-desc=&quot;很多兄弟可能平时经常搞的都是一些CRUD的业务系统开发，从来没接触过API网关。那么API网关是啥，到底能对我们起到什么作用呢？#API #API网关 #CRUD @微信时刻 &amp;#10;&amp;#10;&quot; data-nonceid=&quot;2527740014003838467&quot; data-type=&quot;video&quot;/&gt;&lt;/section&gt;&lt;/article&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4eadcfa9c8cc6af3ff0f2049f7ecd524</guid>
<title>重写Babel：分词器</title>
<link>https://toutiao.io/k/5gtmxcm</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;blockquote&gt;&lt;p&gt;本文翻译自：&lt;span&gt;Rebuilding Babel: The Tokenizer&lt;sup&gt;[1]&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;我们思考一个问题：分词器「a tokenizer」是如何将代码字符串「a code string」转换为token标记列表的「a list of tokens」？&lt;/p&gt;&lt;p&gt;几周前，我花了一些时间从头开始重建Babel编译器，以进一步了解它的内部工作机制。所以你看，我对编译器了解的是做够多的，知道如何深度的使用它们（就像在我的&lt;span&gt;debugger&lt;sup&gt;[2]&lt;/sup&gt;&lt;/span&gt;文章中介绍的那样），但我并不知道如何从头开始去实现一个。&lt;/p&gt;&lt;p&gt;在这篇文章中，我们将介绍如何构建分词器（tokenizer），这正是编译器的第一个组成部分。具体来说，我们将构建一个分词器，该分词器可以理解以下的代码片段，仅此而已：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;function&lt;/span&gt; &lt;span&gt;hello&lt;/span&gt;() {&lt;br/&gt;  &lt;span&gt;console&lt;/span&gt;.&lt;span&gt;log&lt;/span&gt;(&lt;span&gt;&#x27;hello, world!&#x27;&lt;/span&gt;)&lt;br/&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;为此，我们将深入研究：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;1. 什么是token标识，以及为什么需要分词器（tokenizer）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2. 如何通过三个具体步骤实现分词器：&lt;/p&gt;&lt;/li&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;1. 标记单字符tokens&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2. 标记标识符和关键字，以及：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;3. 标记字符串字面量&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/ol&gt;&lt;p&gt;往我们开始吧！&lt;/p&gt;&lt;h1&gt;编译入门&lt;/h1&gt;&lt;p&gt;&lt;span&gt;让我们先整体来讨论一下编译器是如何工作的。我认为编译器是一个管道，有四个具体步骤：&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.11742892459826947&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qnAibK5Aia2dWF5FPUdyT48mu71KSRqSf0ickmh2FF6biaVRMn81m7NRo2U8DOxggIFpB13glMyibc5Kamtg7ZfgeYA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1618&quot; title=&quot;null&quot;/&gt;&lt;figcaption&gt;www.nan.fyi_tokenizer.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;每一步的输出会作为下一步的输入，并会将其转换为其他内容。第一步是做标记的操作，将源代码作为输入，而最后一步是代码生成操作，吐出修改后的代码。&lt;/p&gt;&lt;p&gt;让我们回到分词器（tokenizer）！&lt;/p&gt;&lt;h1&gt;Token是语言词汇&lt;/h1&gt;&lt;blockquote&gt;&lt;p&gt;问题：什么是标记（Token），以及分词器究竟是做什么的？&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;本质上，分词器将源代码分解为称为标记（Token）的小对象（因此得名）。在编程语言中，我喜欢把一个标记看作一个“单词”，即使是最小的字符序列也是有意义的。&lt;/p&gt;&lt;p&gt;例如，如果将以下的JavaScript代码做分词：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;function&lt;/span&gt; &lt;span&gt;hello&lt;/span&gt;() {&lt;br/&gt;  &lt;span&gt;console&lt;/span&gt;.&lt;span&gt;log&lt;/span&gt;(&lt;span&gt;&#x27;hello, world!&#x27;&lt;/span&gt;)&lt;br/&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;你将获得如下的标记模块：&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3889789303079417&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qnAibK5Aia2dWF5FPUdyT48mu71KSRqSf0TPdm4NKKWoBgTK1bXoVAWcX9NSpFExuW5KoH3xMaLzNVfdVyA6fInQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1234&quot; title=&quot;null&quot;/&gt;&lt;figcaption&gt;www.nan.fyi_tokenizer (2).png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;就像英语中的单词可以是名词、动词、形容词等一样，每个标记都有一个表示该标记含义的类型。在我们前面的示例中，这些类型可能类似于下图👇🏻：&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4554294975688817&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qnAibK5Aia2dWF5FPUdyT48mu71KSRqSf0ic4sDic7OK6ZU5EbbRu0lU3Ukqb5GFJwDFYbdd9aDHvp7lkj5OTUnqCQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1234&quot; title=&quot;null&quot;/&gt;&lt;figcaption&gt;www.nan.fyi_tokenizer.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;h1&gt;为什么要这样处理？&lt;/h1&gt;&lt;p&gt;在我们继续之前，我想先岔开话题，谈谈为什么我们首先需要有分词器。在这里我们找不到一个能够讲的非常清楚的资源，但据我所知，有两个原因：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;1. 将数据组织成对机器更友好的格式；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2. 将处理语言微语法的逻辑与处理常规语法的逻辑分开。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;对机器友好的数据格式&lt;/h2&gt;&lt;p&gt;当你以一种一致的方式对你在处理的数据进行结构化时，编写程序往往会容易得多。将字符串分组为标记（tokens）意味着编译器管道的其余部分不需要单独解析源代码——它们的优点是可以处理整洁的对象数组。&lt;/p&gt;&lt;h2&gt;微语法与常规语法&lt;/h2&gt;&lt;blockquote/&gt;&lt;p&gt;另一个原因则是要将处理语言微语法的逻辑与处理常规语法的逻辑分开。当我在这里说“语法”时，我指的是控制编程语言“正确”结构的规则。&lt;/p&gt;&lt;p&gt;例如，在JavaScript中定义常量的正确方法是使用const关键字，如下所示：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;const&lt;/span&gt; hello = &lt;span&gt;&#x27;world&#x27;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这是一个常规语法的例子，因为规则就是关于如何将不同单词排列在一起的正确方式，然后可以形成一行正确的代码。&lt;/p&gt;&lt;p&gt;另一方面，微语法（microsyntax）是一种将不同字符排列在一起组成一个单词的正确方法。一个例子是如何在JavaScript中定义字符串，即它们是被单引号或双引号包围的单词：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;// valid strings&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&#x27;hello&#x27;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&quot;world&quot;&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// invalid strings&lt;/span&gt;&lt;br/&gt;&amp;lt;-hello-&amp;gt;&lt;br/&gt;&amp;amp;world&amp;amp;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;区分处理这两种不同语法类型的代码是很重要的，因为它们涉及两种不同的东西。试图把它们混在一起的话只会导致更复杂的难以阅读和理解的代码。&lt;/p&gt;&lt;h2&gt;简单总结&lt;/h2&gt;&lt;p&gt;重申一下，标记器的工作是将源代码（作为字符串接收）分解为一个标记列表。这样分解代码可以让其他阶段的工作变得更加轻松：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;1. 将输入内容（源代码）整理成更结构化的格式，以及&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2. 通过将常规语法和微语法的逻辑分离，使代码变得更简单&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h1&gt;开始实施&lt;/h1&gt;&lt;p&gt;不管怎么样，我们回到分词器。&lt;/p&gt;&lt;p&gt;现在我们知道了什么是标记（tokens），以及为什么需要分词器，我们终于准备好开始实现它了！同样，我们希望重点关注以下代码片段的标记化，仅此而已：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;function&lt;/span&gt; &lt;span&gt;hello&lt;/span&gt;() {&lt;br/&gt;  &lt;span&gt;console&lt;/span&gt;.&lt;span&gt;log&lt;/span&gt;(&lt;span&gt;&#x27;hello, world!&#x27;&lt;/span&gt;)&lt;br/&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;下面是我们正在实现的标记器的预览，通过代码片段进行介绍：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;备注：作者在原文中实现了一个可视化的「挨个单词解析」的动作分解，这里近展现了最终的实现结果。实际效果可回到原文查看。&lt;/p&gt;&lt;/blockquote&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.3014705882352942&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qnAibK5Aia2dWF5FPUdyT48mu71KSRqSf0fic8ChvjXQkltXUOzlez9YaYdsp3llCkJAiaE2976VzvwFsrpAERiaOCw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1360&quot; title=&quot;null&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;我们将实现分为3个部分：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;1. 解析单字符标记；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2. 解析标识符和关键字；以及&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;3. 解析字符串字面量。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;让我们开始吧！&lt;/p&gt;&lt;h1&gt;单字符标记「Single Character Tokens」&lt;/h1&gt;&lt;p&gt;&lt;span&gt;让我们首先尝试解析出最简单的标记——只有一个字符长度的标记（即单字符标记）。在我们正在分析的代码片段中，这将是以下的所有标记（包括：左右括号、点、左右大括号等）：&lt;/span&gt;&lt;/p&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4566813509544787&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qnAibK5Aia2dWF5FPUdyT48mu71KSRqSf0IjH5PHDIygTB4kic9qUIx7uViaVKaJgNwHTSCqrofj9oykicD5yLqx50g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1362&quot; title=&quot;null&quot;/&gt;&lt;figcaption&gt;www.nan.fyi_tokenizer (1).png&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;我们将从迭代输入的每个字符开始：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;function&lt;/span&gt; &lt;span&gt;hello&lt;/span&gt;() {\n &lt;span&gt;console&lt;/span&gt;.&lt;span&gt;log&lt;/span&gt;(&lt;span&gt;&#x27;hello, world!&#x27;&lt;/span&gt;)\n}&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;&lt;p&gt;什么是\n? \n字符是代表新的一行的特殊字符。当我们编辑代码或文本时，它通常是不可见的，但我选择在这里显式的展展示来，以表达计算机所看到的内容。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;在遍历代码字符串时，我们检查当前字符是否是这些单字符标记中的一个。如果是，我们将该字符添加到最终的标记列表中。&lt;/p&gt;&lt;p&gt;检查一个字符是否为单字符标记的一种方法是：实现一个我们支持的所有单字符标记的列表，并检查该字符是否在该列表中：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;备注：作者在原文中实现了一个可视化的「挨个单词解析」的动作分解，这里近展现了最终的实现结果。实际效果可回到原文查看。&lt;/p&gt;&lt;/blockquote&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9662261380323054&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qnAibK5Aia2dWF5FPUdyT48mu71KSRqSf0m3Ia1w0YwGOicHlf7fz8fBluC4CFRCx4VSFbm6DvAicdTDVvNWOUvcyA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1362&quot; title=&quot;null&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;h1&gt;标识符和关键字&lt;/h1&gt;&lt;p&gt;有了单字符标记，接下来我们要做的就是解析标识符和关键字标记。但请稍等，标识符到底是什么？&lt;/p&gt;&lt;h2&gt;什么是标识符？&lt;/h2&gt;&lt;p&gt;在JavaScript中，标识符是用于引用某个数据段（原文：some piece of data）的字符序列。例如，在我们的输入代码片段中，单词hello、console和log都是标识符，因为它们分别指函数定义、对象和方法（这段程序可用的所有数据）。&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据MDN上的解说&lt;sup&gt;[3]&lt;/sup&gt;&lt;/span&gt;，JavaScript中的有效标识符是字母数字组成的字符序列，但第一个字符不能是数字。这意味着以下字符串是有效标识符：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;hello&lt;br/&gt;&lt;span&gt;_&lt;/span&gt;abc&lt;br/&gt;abc123&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但下面的是非法的：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;2cool&lt;br/&gt;8ball&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我最初是希望能够完全支持MDN的标识符规则的，但（出于实现成本考虑）现在我选择将标识符限制为仅按字母顺序排列的字符，以便将其范围限定为输入代码片段。这意味着，在上面的所有示例中，我的标记器只会将单词hello识别为标识符。&lt;/p&gt;&lt;h2&gt;实现&lt;/h2&gt;&lt;p&gt;总而言之，标识符（出于我们的目的）是任何字母顺序的字符序列。为了分析它，我采用了以下方法：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;1. 如果当前字符按字母顺序排列，则开始解析标识符；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2. 继续向当前标识符标记添加字符，直到当前字符不按字母顺序排列。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6740088105726872&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qnAibK5Aia2dWF5FPUdyT48mu71KSRqSf0Dp8jtV1bo4obbl16uguQRicTLojHDwficWjPd6kZ2kDS38icicUwk3qcvw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1362&quot; title=&quot;null&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;关键词&lt;/h2&gt;&lt;p&gt;有些词，如function、while和switch，在JavaScript中有特殊含义，因此不能用作常规标识符。这组标识符称为&lt;strong&gt;关键字&lt;/strong&gt;，通常有各自的标记类型。&lt;/p&gt;&lt;p&gt;因此，就有如下的问题：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;分词器如何区分标识符和关键字呢？&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;一种方法是执行与单字符标记相同的操作：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;1. 维护一个已知的关键字的集合；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2. 当我们解析完一个标识符时，检查解析的名称是否在这个集合中；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;3. 如果是，请将token的类型更改为关键字的类型。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1.0778267254038179&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qnAibK5Aia2dWF5FPUdyT48mu71KSRqSf0rnKPtctYUDOXVLVzRblIV6yKCOQRD96ib3tkCLSuboYO4J0CBOlGicRQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1362&quot; title=&quot;null&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;h1&gt;字符串字面量&lt;/h1&gt;&lt;p&gt;接下来是标记代码片段中的 &#x27;hello, world!&#x27; 部分，也被称为字符串字面量。在JavaScript中，字符串字面量遵循以下规则：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;1. 以单引号（&#x27;）或双引号（“）对开始和结束，以及&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2. 不能跨越多行&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了简单起见，我选择了只支持单引号和多行字符串（事实证明，如果我们支持多行，实现会更简单）。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;啊哈，这是microsyntax！&lt;br/&gt;&lt;br/&gt;这就是我们早些时候关于微语法的小讨论！通过在这里处理字符串规则，编译器的其他部分不必担心这个字符串是否“正确”。&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;为了标记一个字符串字面量，我们将做一些类似于标记标识符的事情，除了我们只在到达另一个单引号时停止。具体操作如下：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;1. 如果当前字符是单引号，则开始分析字符串文字；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2. 继续收集字符，直到当前字符中有一个是另一个撇号，表示字符串的结尾；或者&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;3. 您已到达文件的结尾，但字符串未终止 - 这是一个错误的代码！&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6740088105726872&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/qnAibK5Aia2dWF5FPUdyT48mu71KSRqSf0ptM1YpHTvmrxMicwhLdPWOPDXJwsJ5HRl6fPh5vD52UrWUygZUeueLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1362&quot; title=&quot;null&quot;/&gt;&lt;figcaption&gt;image.png&lt;/figcaption&gt;&lt;/figure&gt;&lt;h1&gt;总结&lt;/h1&gt;&lt;p&gt;这就是我们的分词！目前它做不了太多，但它能够标记我们开头使用的代码片段：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;function&lt;/span&gt; &lt;span&gt;hello&lt;/span&gt;(message) {&lt;br/&gt;  &lt;span&gt;console&lt;/span&gt;.&lt;span&gt;log&lt;/span&gt;(message)&lt;br/&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我故意省略了代码实现，因为我想巩固分词器背后的概念，而不是将其绑定到任何直接实现。毕竟，实现同一件事有很多不同的方法！但是，如果您想阅读一些代码，请查看&lt;span&gt;我对这个分词器的实现&lt;sup&gt;[4]&lt;/sup&gt;&lt;/span&gt;（用TypeScript编写）。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;export&lt;/span&gt; &lt;span&gt;function&lt;/span&gt; &lt;span&gt;tokenize&lt;/span&gt;(input: &lt;span&gt;string&lt;/span&gt;): &lt;span&gt;Token&lt;/span&gt;[] {&lt;br/&gt;  &lt;span&gt;let&lt;/span&gt; current = &lt;span&gt;0&lt;/span&gt;;&lt;br/&gt;  &lt;span&gt;const&lt;/span&gt; tokens = [];&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;function&lt;/span&gt; &lt;span&gt;finishIdentifier&lt;/span&gt;() {&lt;br/&gt;    &lt;span&gt;let&lt;/span&gt; name = &lt;span&gt;&quot;&quot;&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;isAlpha&lt;/span&gt;(input[current])) {&lt;br/&gt;      name += input[current];&lt;br/&gt;      current++;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;const&lt;/span&gt; builder = keywords.&lt;span&gt;get&lt;/span&gt;(name);&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (builder) {&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; &lt;span&gt;builder&lt;/span&gt;();&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; token.&lt;span&gt;identifier&lt;/span&gt;(name);&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;function&lt;/span&gt; &lt;span&gt;finishStringLiteral&lt;/span&gt;() {&lt;br/&gt;    &lt;span&gt;let&lt;/span&gt; value = &lt;span&gt;&quot;&quot;&lt;/span&gt;;&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt; (input[current] &amp;amp;&amp;amp; input[current] !== &lt;span&gt;&quot;&#x27;&quot;&lt;/span&gt;) {&lt;br/&gt;      value += input[current];&lt;br/&gt;      current++;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (input[current] === &lt;span&gt;&quot;&#x27;&quot;&lt;/span&gt;) {&lt;br/&gt;      &lt;span&gt;// consume the closing tick&lt;/span&gt;&lt;br/&gt;      current++;&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; token.&lt;span&gt;stringLiteral&lt;/span&gt;(value);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Error&lt;/span&gt;(&lt;span&gt;`Unterminated string, expected a closing &#x27;`&lt;/span&gt;);&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;while&lt;/span&gt; (current &amp;lt; input.length) {&lt;br/&gt;    &lt;span&gt;const&lt;/span&gt; currentChar = input[current];&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;isWhitespace&lt;/span&gt;(currentChar)) {&lt;br/&gt;      current++;&lt;br/&gt;      &lt;span&gt;continue&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;isAlpha&lt;/span&gt;(currentChar)) {&lt;br/&gt;      tokens.&lt;span&gt;push&lt;/span&gt;(&lt;span&gt;finishIdentifier&lt;/span&gt;());&lt;br/&gt;    } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (&lt;span&gt;isSingleCharacter&lt;/span&gt;(currentChar)) {&lt;br/&gt;      tokens.&lt;span&gt;push&lt;/span&gt;(&lt;span&gt;getCharToken&lt;/span&gt;(currentChar));&lt;br/&gt;      current++;&lt;br/&gt;    } &lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (currentChar === &lt;span&gt;&quot;&#x27;&quot;&lt;/span&gt;) {&lt;br/&gt;      &lt;span&gt;// consume the first tick&lt;/span&gt;&lt;br/&gt;      current++;&lt;br/&gt;      tokens.&lt;span&gt;push&lt;/span&gt;(&lt;span&gt;finishStringLiteral&lt;/span&gt;());&lt;br/&gt;    } &lt;span&gt;else&lt;/span&gt; {&lt;br/&gt;      &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Error&lt;/span&gt;(&lt;span&gt;`Unknown character: &lt;span&gt;${currentChar}&lt;/span&gt;`&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; tokens;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// --&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;export&lt;/span&gt; &lt;span&gt;enum&lt;/span&gt; &lt;span&gt;TokenType&lt;/span&gt; {&lt;br/&gt;  &lt;span&gt;Function&lt;/span&gt; = &lt;span&gt;&quot;Function&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;Identifier&lt;/span&gt; = &lt;span&gt;&quot;Identifier&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;LeftParen&lt;/span&gt; = &lt;span&gt;&quot;LeftParen&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;RightParen&lt;/span&gt; = &lt;span&gt;&quot;RightParen&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;LeftCurly&lt;/span&gt; = &lt;span&gt;&quot;LeftCurly&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;RightCurly&lt;/span&gt; = &lt;span&gt;&quot;RightCurly&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;Dot&lt;/span&gt; = &lt;span&gt;&quot;Dot&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;Semicolon&lt;/span&gt; = &lt;span&gt;&quot;Semicolon&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;StringLiteral&lt;/span&gt; = &lt;span&gt;&quot;StringLiteral&quot;&lt;/span&gt;,&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;export&lt;/span&gt; &lt;span&gt;type&lt;/span&gt; &lt;span&gt;Token&lt;/span&gt; =&lt;br/&gt;  | {&lt;br/&gt;      &lt;span&gt;type&lt;/span&gt;: &lt;span&gt;TokenType&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;  | {&lt;br/&gt;      &lt;span&gt;type&lt;/span&gt;: &lt;span&gt;TokenType&lt;/span&gt;.Identifier;&lt;br/&gt;      &lt;span&gt;name&lt;/span&gt;: &lt;span&gt;string&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;  | {&lt;br/&gt;      &lt;span&gt;type&lt;/span&gt;: &lt;span&gt;TokenType&lt;/span&gt;.StringLiteral;&lt;br/&gt;      &lt;span&gt;value&lt;/span&gt;: &lt;span&gt;string&lt;/span&gt;;&lt;br/&gt;    };&lt;br/&gt;&lt;br/&gt;&lt;span&gt;export&lt;/span&gt; &lt;span&gt;const&lt;/span&gt; token = {&lt;br/&gt;  &lt;span&gt;function&lt;/span&gt;() {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; {&lt;br/&gt;      &lt;span&gt;type&lt;/span&gt;: &lt;span&gt;TokenType&lt;/span&gt;.Function,&lt;br/&gt;    };&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;identifier&lt;/span&gt;(name: &lt;span&gt;string&lt;/span&gt;) {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; {&lt;br/&gt;      &lt;span&gt;type&lt;/span&gt;: &lt;span&gt;TokenType&lt;/span&gt;.Identifier,&lt;br/&gt;      name,&lt;br/&gt;    };&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;leftParen&lt;/span&gt;() {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; { &lt;span&gt;type&lt;/span&gt;: &lt;span&gt;TokenType&lt;/span&gt;.LeftParen };&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;rightParen&lt;/span&gt;() {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; { &lt;span&gt;type&lt;/span&gt;: &lt;span&gt;TokenType&lt;/span&gt;.RightParen };&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;leftCurly&lt;/span&gt;() {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; { &lt;span&gt;type&lt;/span&gt;: &lt;span&gt;TokenType&lt;/span&gt;.LeftCurly };&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;rightCurly&lt;/span&gt;() {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; { &lt;span&gt;type&lt;/span&gt;: &lt;span&gt;TokenType&lt;/span&gt;.RightCurly };&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;dot&lt;/span&gt;() {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; { &lt;span&gt;type&lt;/span&gt;: &lt;span&gt;TokenType&lt;/span&gt;.Dot };&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;semicolon&lt;/span&gt;() {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; { &lt;span&gt;type&lt;/span&gt;: &lt;span&gt;TokenType&lt;/span&gt;.Semicolon };&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;stringLiteral&lt;/span&gt;(value: &lt;span&gt;string&lt;/span&gt;) {&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; {&lt;br/&gt;      &lt;span&gt;type&lt;/span&gt;: &lt;span&gt;TokenType&lt;/span&gt;.StringLiteral,&lt;br/&gt;      value,&lt;br/&gt;    };&lt;br/&gt;  },&lt;br/&gt;};&lt;br/&gt;&lt;br/&gt;&lt;span&gt;const&lt;/span&gt; keywords = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Map&lt;/span&gt;([[&lt;span&gt;&quot;function&quot;&lt;/span&gt;, token.function]]);&lt;br/&gt;&lt;br/&gt;&lt;span&gt;// --&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;function&lt;/span&gt; &lt;span&gt;isAlpha&lt;/span&gt;(char: &lt;span&gt;string&lt;/span&gt;) {&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;/[a-zA-Z]/&lt;/span&gt;.&lt;span&gt;test&lt;/span&gt;(char);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;function&lt;/span&gt; &lt;span&gt;isWhitespace&lt;/span&gt;(char: &lt;span&gt;string&lt;/span&gt;) {&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;/\s/&lt;/span&gt;.&lt;span&gt;test&lt;/span&gt;(char);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;type&lt;/span&gt; &lt;span&gt;SingleCharacterToken&lt;/span&gt; = &lt;span&gt;&quot;(&quot;&lt;/span&gt; | &lt;span&gt;&quot;)&quot;&lt;/span&gt; | &lt;span&gt;&quot;{&quot;&lt;/span&gt; | &lt;span&gt;&quot;}&quot;&lt;/span&gt; | &lt;span&gt;&quot;.&quot;&lt;/span&gt; | &lt;span&gt;&quot;;&quot;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;const&lt;/span&gt; knownSingleCharacters = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Map&lt;/span&gt;&amp;lt;&lt;span&gt;SingleCharacterToken&lt;/span&gt;, () =&amp;gt; &lt;span&gt;Token&lt;/span&gt;&amp;gt;([&lt;br/&gt;  [&lt;span&gt;&quot;(&quot;&lt;/span&gt;, token.leftParen],&lt;br/&gt;  [&lt;span&gt;&quot;)&quot;&lt;/span&gt;, token.rightParen],&lt;br/&gt;  [&lt;span&gt;&quot;{&quot;&lt;/span&gt;, token.leftCurly],&lt;br/&gt;  [&lt;span&gt;&quot;}&quot;&lt;/span&gt;, token.rightCurly],&lt;br/&gt;  [&lt;span&gt;&quot;.&quot;&lt;/span&gt;, token.dot],&lt;br/&gt;  [&lt;span&gt;&quot;;&quot;&lt;/span&gt;, token.semicolon],&lt;br/&gt;]);&lt;br/&gt;&lt;br/&gt;&lt;span&gt;function&lt;/span&gt; &lt;span&gt;isSingleCharacter&lt;/span&gt;(char: &lt;span&gt;string&lt;/span&gt;): char is &lt;span&gt;SingleCharacterToken&lt;/span&gt; {&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; knownSingleCharacters.&lt;span&gt;has&lt;/span&gt;(char &lt;span&gt;as&lt;/span&gt; &lt;span&gt;SingleCharacterToken&lt;/span&gt;);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;function&lt;/span&gt; &lt;span&gt;getCharToken&lt;/span&gt;(char: SingleCharacterToken) {&lt;br/&gt;  &lt;span&gt;const&lt;/span&gt; builder = knownSingleCharacters.&lt;span&gt;get&lt;/span&gt;(char);&lt;br/&gt;  &lt;span&gt;return&lt;/span&gt; builder!();&lt;br/&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;最后，如果您想了解更多信息，有几个练习供您尝试：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;1. 用你选择的语言实现这个标记器；使用文章中的可视化作为参考。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;2. 完成后，可以继续扩展分词器以支持你选择的JS语法——可能是async await之类的东西。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;就到这里，感谢你的阅读！&lt;/p&gt;&lt;h4&gt;引用链接&lt;/h4&gt;&lt;p&gt;&lt;code&gt;[1]&lt;/code&gt; Rebuilding Babel: The Tokenizer: &lt;em&gt;https://www.nan.fyi/tokenizer&lt;/em&gt;&lt;br/&gt;&lt;code&gt;[2]&lt;/code&gt; debugger: &lt;em&gt;https://www.nan.fyi/debugger&lt;/em&gt;&lt;br/&gt;&lt;code&gt;[3]&lt;/code&gt; 根据MDN上的解说: &lt;em&gt;https://developer.mozilla.org/en-US/docs/Glossary/Identifier&lt;/em&gt;&lt;br/&gt;&lt;code&gt;[4]&lt;/code&gt; 我对这个分词器的实现: &lt;em&gt;https://github.com/narendrasss/compiler/blob/main/src/tokenizer.ts&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d154897851ff237a1d6cef93058146ec</guid>
<title>强大的 Gensim 库用于 NLP 文本分析</title>
<link>https://toutiao.io/k/d55ikid</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                                                     &quot; id=&quot;js_content&quot;&gt;
            &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img __bg_gif&quot; data-ratio=&quot;0.17647058823529413&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/VeJKXItpwPVibOSMQeyaGwgUuVlcQvxkGXXWJd5ibVobOMbl2fuGGsbm5Ric4aJjgUiahJfqib9xbibDticDldfIziaT8g/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;680&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;作者 | 云朵君&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;来源 | 数据STUDIO&lt;/span&gt;&lt;/section&gt;&lt;h5&gt;&lt;span&gt;自然语言处理，简称 NLP，是人工智能的一个分支，它允许机器理解、处理和操纵人类语言。Gensim是在做自然语言处理时较为经常用到的一个工具库，主要用来以无监督的方式从原始的非结构化文本当中来学习到文本隐藏层的主题向量表达。将和大家一起学习&lt;span&gt;几个关键的 NLP 主题，帮助我们更加熟悉使用 Gensim 进行文本数据操作。&lt;/span&gt;&lt;/span&gt;&lt;/h5&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;NLP基础&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;NLP就是处理自然语言，可以是文本、音频和视频。本文将重点了解如何使用文本数据并讨论文本数据的构建块。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;基本概念&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;code&gt;标记(Token)&lt;/code&gt;：&lt;/strong&gt; 是具有已知含义的字符串，标记可以是单词、数字或只是像标点符号的字符。&lt;/span&gt;&lt;code&gt;&lt;span&gt;“你好”&lt;/span&gt;&lt;/code&gt;&lt;span&gt;、&lt;/span&gt;&lt;code&gt;&lt;span&gt;“123”&lt;/span&gt;&lt;/code&gt;&lt;span&gt;和&lt;/span&gt;&lt;code&gt;&lt;span&gt;“-”&lt;/span&gt;&lt;/code&gt;&lt;span&gt;是标记的一些示例。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;code&gt;句子(Sentence)&lt;/code&gt;：&lt;/strong&gt; 是一组意义完整的记号。&lt;strong&gt;“天气看起来不错”&lt;/strong&gt; 是一个句子的例子，句子的标记是&lt;strong&gt;【“天气”, “看起来”, “不错“】&lt;/strong&gt;。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;code&gt;段落(Paragraph)&lt;/code&gt;：&lt;/strong&gt; 是句子或短语的集合，也可以将句子视为段落的标记。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;code&gt;文档(Documents)&lt;/code&gt;：&lt;/strong&gt; 可能是一个句子、一个段落或一组段落。发送给个人的文本消息是文档的一个示例。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;code&gt;语料(Corpus)&lt;/code&gt;：&lt;/strong&gt; 通常是作为词袋的原始文档集合。语料库包括每个记录中每个单词的 id 和频率计数。语料库的一个例子是发送给特定人的电子邮件或文本消息的集合。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4541108986615679&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7ic0xaWbfkWClibe90xgLfwoanZzs5TwRbtzaWnKZRZvJPu2icibWxUNasfIRibAichG9oNrRfeTG9VSwGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1046&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;code&gt;稀疏向量(SparseVector)&lt;/code&gt;：&lt;/strong&gt; 通常，我们可以略去向量中多余的0元素。此时，向量中的每一个元素是一个(key, value)的元组&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;code&gt;模型(Model)&lt;/code&gt;：&lt;/strong&gt; 是一个抽象的术语。定义了两个向量空间的变换（即从文本的一种向量表达变换为另一种向量表达）。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;Gensim简介&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;大名鼎鼎的 Gensim 是一款具备多种功能的神器。它是一个著名的开源 Python 库，&lt;strong&gt;用于从原始的非结构化的文本中，无监督地学习到文本隐层的主题向量表达&lt;/strong&gt;。它处理大量文本数据的能力和训练向量embedding的速度使其有别于其他 NLP 库。此外，Gensim 支持包括&lt;/span&gt;&lt;code&gt;&lt;span&gt;TF-IDF，LSA，LDA，和 word2vec&lt;/span&gt;&lt;/code&gt;&lt;span&gt;在内的多种主题模型算法，用此很多算法工程师会将其作为主题建模的首选库。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Gensim支持流式训练，并提供了诸如相似度计算，信息检索等一些常用任务的API接口。&lt;/span&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;安装和使用&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;可直接使用 pip 安装或 conda 环境安装 Gensim。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;#Using Pip installer:&lt;/span&gt;&lt;br/&gt;pip install --upgrade gensim&lt;br/&gt;&lt;br/&gt;&lt;span&gt;#Using Conda environment:&lt;/span&gt;&lt;br/&gt;conda install -c conda-forge gensim&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.33210332103321033&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7ic0xaWbfkWClibe90xgLfwoaEJTibpYPCt8qMX0ydg15283ywWePPLuXibHy3oDZY1U8GpEyPwt5RVqA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1626&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;训练语料的预处理&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;训练语料的预处理指的是将文档中原始的字符文本转换成Gensim模型所能理解的稀疏向量的过程。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;通常，我们要处理的原生语料是一堆文档的集合，每一篇文档又是一些原生字符的集合。在交给Gensim的模型训练之前，我们需要将这些原生字符解析成Gensim能处理的稀疏向量的格式。由于语言和应用的多样性，我们需要先对原始的文本进行分词、去除停用词等操作，得到每一篇文档的特征列表。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;创建字典&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;首先，从句子列表中制作字典。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;调用Gensim提供的API建立语料特征（word）的索引字典，并将文本特征的原始表达转化成词袋模型对应的稀疏向量的表达。可以使用 Gensim 从句子列表和文本文件中生成字典。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;import&lt;/span&gt; gensim&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; gensim &lt;span&gt;import&lt;/span&gt; corpora&lt;br/&gt;&lt;br/&gt;text1 = [&lt;span&gt;&quot;&quot;&quot;Gensim is a free open-source Python library for representing documents as semantic vectors,&lt;br/&gt;           as efficiently and painlessly as possible. Gensim is designed &lt;br/&gt;           to process raw, unstructured digital texts using unsupervised machine learning algorithms.&quot;&quot;&quot;&lt;/span&gt;]&lt;br/&gt;&lt;br/&gt;tokens1 = [[item &lt;span&gt;for&lt;/span&gt; item &lt;span&gt;in&lt;/span&gt; line.split()] &lt;span&gt;for&lt;/span&gt; line &lt;span&gt;in&lt;/span&gt; text1]&lt;br/&gt;g_dict1 = corpora.Dictionary(tokens1)&lt;br/&gt;&lt;br/&gt;print(&lt;span&gt;&quot;The dictionary has: &quot;&lt;/span&gt; +str(len(g_dict1)) + &lt;span&gt;&quot; tokens\n&quot;&lt;/span&gt;)&lt;br/&gt;print(g_dict1.token2id)&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;The dictionary has: 29 tokens&lt;br/&gt;&lt;br/&gt;{&#x27;Gensim&#x27;: 0, &#x27;Python&#x27;: 1, &#x27;a&#x27;: 2, &#x27;algorithms.&#x27;: 3, &lt;br/&gt;&#x27;and&#x27;: 4, &#x27;as&#x27;: 5, &#x27;designed&#x27;: 6, &#x27;digital&#x27;: 7, &lt;br/&gt;&#x27;documents&#x27;: 8, &#x27;efficiently&#x27;: 9, &#x27;for&#x27;: 10, &#x27;free&#x27;: 11, &lt;br/&gt;&#x27;is&#x27;: 12, &#x27;learning&#x27;: 13, &#x27;library&#x27;: 14, &#x27;machine&#x27;: 15, &lt;br/&gt;&#x27;open-source&#x27;: 16, &#x27;painlessly&#x27;: 17, &#x27;possible.&#x27;: 18, &lt;br/&gt;&#x27;process&#x27;: 19, &#x27;raw,&#x27;: 20, &#x27;representing&#x27;: 21, &lt;br/&gt;&#x27;semantic&#x27;: 22, &#x27;texts&#x27;: 23, &#x27;to&#x27;: 24, &#x27;unstructured&#x27;: 25, &lt;br/&gt;&#x27;unsupervised&#x27;: 26, &#x27;using&#x27;: 27, &#x27;vectors,&#x27;: 28}&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;可以从输出中看到字典中的每个标记都分配了一个唯一的 &lt;/span&gt;&lt;code&gt;&lt;span&gt;id&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;现在，用文本文件中的tokens创建一个字典。开始时使用 Gensim 的 &lt;/span&gt;&lt;code&gt;&lt;span&gt;simple_preprocess()&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 函数对文件进行预处理，从文件中检索tokens列表。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;from&lt;/span&gt; gensim.utils &lt;span&gt;import&lt;/span&gt; simple_preprocess&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; gensim &lt;span&gt;import&lt;/span&gt; corpora&lt;br/&gt;&lt;span&gt;# text2 = open(&#x27;sample_text.txt&#x27;, encoding =&#x27;utf-8&#x27;).read()&lt;/span&gt;&lt;br/&gt;text2 = &lt;span&gt;&quot;&quot;&quot;&lt;br/&gt;NLP is a branch of data science that consists of systematic processes for analyzing,&lt;br/&gt;understanding, and deriving information from the text data in a smart and efficient manner. &lt;br/&gt;By utilizing NLP and its components, one can organize the massive chunks of text data, &lt;br/&gt;perform numerous automated tasks and solve a wide range of problems such as – &lt;br/&gt;automatic summarization, machine translation, named entity recognition, &lt;br/&gt;relationship extraction, sentiment analysis, speech recognition, and topic segmentation etc.&lt;br/&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;br/&gt; &lt;br/&gt;tokens2 =[]&lt;br/&gt;&lt;span&gt;for&lt;/span&gt; line &lt;span&gt;in&lt;/span&gt; text2.split(&lt;span&gt;&#x27;.&#x27;&lt;/span&gt;):&lt;br/&gt;    tokens2.append(simple_preprocess(line, deacc = &lt;span&gt;True&lt;/span&gt;))&lt;br/&gt;g_dict2 = corpora.Dictionary(tokens2)&lt;br/&gt;print(&lt;span&gt;&quot;The dictionary has: &quot;&lt;/span&gt; +str(len(g_dict2)) + &lt;span&gt;&quot; tokens\n&quot;&lt;/span&gt;)&lt;br/&gt;print(g_dict2.token2id)&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.24030037546933666&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7ic0xaWbfkWClibe90xgLfwoaKuzencQscXvksR5icks4GzmrHoBX9IkmiaWfAuH34QMBu8wjOt1lTzZA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1598&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;现在已经成功地从文本文件中创建了一个字典。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;还可以使用新文档中的标记更新现有字典。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;g_dict1.add_documents(tokens2)&lt;br/&gt;print(&lt;span&gt;&quot;The dictionary has: &quot;&lt;/span&gt; +str(len(g_dict1)) + &lt;span&gt;&quot; tokens\n&quot;&lt;/span&gt;)&lt;br/&gt;print(g_dict1.token2id)&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2222222222222222&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7ic0xaWbfkWClibe90xgLfwoaicsDIqicVuGorwNj7denROC8SMqX8lES5xWrTuOicOaL3B7Xd9Ft4YbQg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1998&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;创建一个词袋&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;使用 Gensim 的 &lt;/span&gt;&lt;code&gt;&lt;span&gt;doc2bow&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 函数从创建的字典中生成 &lt;strong&gt;Bag of Words&lt;/strong&gt; (词袋)。词袋返回一个元组向量，其中包含每个标记的唯一 &lt;strong&gt;id&lt;/strong&gt; 和文档中出现的次数。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;g_bow =[g_dict1.doc2bow(token, allow_update = &lt;span&gt;True&lt;/span&gt;)&lt;br/&gt;        &lt;span&gt;for&lt;/span&gt; token &lt;span&gt;in&lt;/span&gt; tokens1]&lt;br/&gt;print(&lt;span&gt;&quot;Bag of Words : &quot;&lt;/span&gt;, g_bow)&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.07673267326732673&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7ic0xaWbfkWClibe90xgLfwoaysxxZSXNiaMHz3iauWt8GIHsx5kiasBArE8bIPvsIOW3twicsEWD3pI1Kw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1616&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;保存和加载语料库&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;可以保存 Gensim 字典和 BOW语料库，并在需要时加载它们。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;# Save the Dictionary and BOW&lt;/span&gt;&lt;br/&gt;g_dict1.save(&lt;span&gt;&#x27;./g_dict1.dict&#x27;&lt;/span&gt;) &lt;br/&gt;corpora.MmCorpus.serialize(&lt;span&gt;&#x27;./g_bow1.mm&#x27;&lt;/span&gt;, g_bow)  &lt;br/&gt;&lt;br/&gt;&lt;span&gt;# Load the Dictionary and BOW&lt;/span&gt;&lt;br/&gt;g_dict_load = corpora.Dictionary.load(&lt;span&gt;&#x27;./g_dict1.dict&#x27;&lt;/span&gt;)&lt;br/&gt;g_bow_load = corpora.MmCorpus(&lt;span&gt;&#x27;./g_bow1.mm&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;到这里，训练语料的预处理工作就完成了。我们得到了语料中每一篇文档对应的稀疏向量（这里是bow向量）；向量的每一个元素代表了一个 word在这篇文档中出现的次数。值得注意的是，虽然词袋模型是很多主题模型的基本假设，这里介绍的 &lt;/span&gt;&lt;code&gt;&lt;span&gt;doc2bow&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 函数并不是将文本转化成稀疏向量的唯一途径。后面我们将介绍更多的向量变换函数。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;其次，出于内存优化的考虑，Gensim 支持文档的流式处理。我们需要做的，只是将上面的列表封装成一个Python迭代器；每一次迭代都返回一个稀疏向量即可。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;MyCorpus(object)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;__iter__(self)&lt;/span&gt;:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;for&lt;/span&gt; line &lt;span&gt;in&lt;/span&gt; open(&lt;span&gt;&#x27;mycorpus.txt&#x27;&lt;/span&gt;):&lt;br/&gt;        &lt;span&gt;# 假设每行有一个文档，标记用空格分隔&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;yield&lt;/span&gt; dictionary.doc2bow(line.lower().split())&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;主题向量的变换&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;对文本向量的变换是 Gensim 的核心。通过挖掘语料中隐藏的语义结构特征，我们最终可以变换出一个简洁高效的文本向量。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在 Gensim 中，每一个向量变换的操作都对应着一个主题模型，例如上一小节提到的对应着词袋模型的 &lt;/span&gt;&lt;code&gt;&lt;span&gt;doc2bow&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 变换。每一个模型又都是一个标准的Python对象。下面以TF-IDF模型为例，介绍 Gensim 模型的一般使用方法。&lt;/span&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;创建 TF-IDF&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;词频—逆文档频率（TF-IDF）&lt;/strong&gt; 是一种通过计算词的权重来衡量文档中每个词的重要性的技术。在 TF-IDF 向量中，每个词的权重与该词在该文档中的出现频率成反比。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;首先是模型对象的初始化。通常，Gensim模型都接受一段训练语料（注意在Gensim中，语料对应着一个稀疏向量的迭代器）作为初始化的参数。显然，越复杂的模型需要配置的参数越多。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;from&lt;/span&gt; gensim &lt;span&gt;import&lt;/span&gt; models&lt;br/&gt;&lt;span&gt;import&lt;/span&gt; numpy &lt;span&gt;as&lt;/span&gt; np&lt;br/&gt;&lt;br/&gt;text = [&lt;span&gt;&quot;The food is excellent but the service can be better&quot;&lt;/span&gt;,&lt;br/&gt;        &lt;span&gt;&quot;The food is always delicious and loved the service&quot;&lt;/span&gt;,&lt;br/&gt;        &lt;span&gt;&quot;The food was mediocre and the service was terrible&quot;&lt;/span&gt;]&lt;br/&gt;g_dict = corpora.Dictionary([simple_preprocess(line) &lt;span&gt;for&lt;/span&gt; line &lt;span&gt;in&lt;/span&gt; text])&lt;br/&gt;g_bow = [g_dict.doc2bow(simple_preprocess(line)) &lt;span&gt;for&lt;/span&gt; line &lt;span&gt;in&lt;/span&gt; text]&lt;br/&gt;&lt;br/&gt;print(&lt;span&gt;&quot;Dictionary : &quot;&lt;/span&gt;)&lt;br/&gt;&lt;span&gt;for&lt;/span&gt; item &lt;span&gt;in&lt;/span&gt; g_bow:&lt;br/&gt;    print([[g_dict[id], freq] &lt;span&gt;for&lt;/span&gt; id, freq &lt;span&gt;in&lt;/span&gt; item])&lt;br/&gt;&lt;br/&gt;g_tfidf = models.TfidfModel(g_bow, smartirs=&lt;span&gt;&#x27;ntc&#x27;&lt;/span&gt;)&lt;br/&gt;print(&lt;span&gt;&quot;TF-IDF Vector:&quot;&lt;/span&gt;)&lt;br/&gt;&lt;span&gt;for&lt;/span&gt; item &lt;span&gt;in&lt;/span&gt; g_tfidf[g_bow]:&lt;br/&gt;    print([[g_dict[id], np.around(freq, decimals=&lt;span&gt;2&lt;/span&gt;)] &lt;span&gt;for&lt;/span&gt; id, freq &lt;span&gt;in&lt;/span&gt; item])&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.16738197424892703&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7ic0xaWbfkWClibe90xgLfwoawD4ic6FsxEdR8VKUrA3xJ3xjVPteEkLov7oibMxiaxKLhuVSpgyyewibqQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1165&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;代码&lt;/span&gt;&lt;code&gt;&lt;span&gt;tfidf = models.TfidfModel(corpus)&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，完成对语料库corpus中出现的每一个特征的IDF值的统计工作。其中，corpus是一个返回bow向量的迭代器。需要注意的是，&lt;strong&gt;这里的bow向量必须与训练语料的bow向量共享同一个特征字典（即共享同一个向量空间&lt;/strong&gt;）。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;注意，同样是出于内存的考虑，&lt;/span&gt;&lt;code&gt;&lt;span&gt;model[corpus]&lt;/span&gt;&lt;/code&gt;&lt;span&gt;方法返回的是一个迭代器。如果要多次访问&lt;/span&gt;&lt;code&gt;&lt;span&gt;model[corpus]&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的返回结果，可以先将结果向量序列化到磁盘上。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;将训练好的模型保存到磁盘上，以便下一次使用：&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;tfidf.save(&lt;span&gt;&quot;./model.tfidf&quot;&lt;/span&gt;)&lt;br/&gt;tfidf = models.TfidfModel.load(&lt;span&gt;&quot;./model.tfidf&quot;&lt;/span&gt;)&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;创建Bigrams和Trigrams&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;一些单词通常出现在一个大文档的文本中。当这些词同时出现时，它们可能作为一个实体出现，与单独出现时的意思完全不同。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以&lt;/span&gt;&lt;code&gt;&lt;span&gt;“世界之窗”&lt;/span&gt;&lt;/code&gt;&lt;span&gt;为例，当它们同时出现（世界之窗）的时候和单独出现（世界，窗）的时候有完全不同的意思，这些词组被称为&lt;/span&gt;&lt;code&gt;&lt;span&gt;“N-gram”&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;code&gt;&lt;span&gt;Bigrams&lt;/span&gt;&lt;/code&gt;&lt;span&gt;二元组是由2个单词组成的&lt;/span&gt;&lt;code&gt;&lt;span&gt;N-gram&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，&lt;/span&gt;&lt;code&gt;&lt;span&gt;Trigrams&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 三元组是由3个单词组成的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接下来将为&lt;/span&gt;&lt;code&gt;&lt;span&gt;“text8”&lt;/span&gt;&lt;/code&gt;&lt;span&gt;数据集创建二元组和三元组，可通过 &lt;strong&gt;Gensim Downloader API&lt;/strong&gt; 下载。并使用 &lt;strong&gt;Gensim&lt;/strong&gt; 的 &lt;/span&gt;&lt;code&gt;&lt;span&gt;Phrases&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 功能。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;code&gt;&lt;span&gt;Trigram&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 模型是通过将之前获得的 &lt;/span&gt;&lt;code&gt;&lt;span&gt;bigram&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 模型传递给 &lt;/span&gt;&lt;code&gt;&lt;span&gt;Phrases&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 函数来生成的。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;import&lt;/span&gt; gensim.downloader &lt;span&gt;as&lt;/span&gt; api&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; gensim.models.phrases &lt;span&gt;import&lt;/span&gt; Phrases&lt;br/&gt; &lt;br/&gt;dataset = api.load(&lt;span&gt;&quot;text8&quot;&lt;/span&gt;)&lt;br/&gt;tokens = [word &lt;span&gt;for&lt;/span&gt; word &lt;span&gt;in&lt;/span&gt; dataset]&lt;br/&gt;            &lt;br/&gt;bigram_model = Phrases(tokens, min_count = &lt;span&gt;3&lt;/span&gt;, threshold = &lt;span&gt;10&lt;/span&gt;)&lt;br/&gt;print(bigram_model[tokens[&lt;span&gt;0&lt;/span&gt;]]) &lt;br/&gt;&lt;br/&gt;trigram_model = Phrases(bigram_model[data], threshold = &lt;span&gt;10&lt;/span&gt;)&lt;br/&gt;print(trigram_model[bigram_model[data[&lt;span&gt;0&lt;/span&gt;]]])&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;第一次运行时会下载数据集：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.07142857142857142&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7ic0xaWbfkWClibe90xgLfwoau6t2CMI6bicnDbNiaQDksBpMx3ibmZ7JzgtdoDESxviamfnf5g3wTNLaoA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1288&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;运行结束后，输出结果。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3109700815956482&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7ic0xaWbfkWClibe90xgLfwoaY1DhuJQEatqbglLRQZR9aXmNCSLsyibicx4yicvyHqekzrCUXOic2FIWNw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2206&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;创建 Word2Vec 模型&lt;/span&gt;&lt;/h3&gt;&lt;section&gt;&lt;span&gt;Word Embedding 模型是将文本表示为数字向量的模型。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;code&gt;&lt;span&gt;Word2Vec&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 是 Gensim 的一个预先构建的词嵌入模型，它使用外部神经网络将词嵌入到低维向量空间中。Gensim 的 &lt;/span&gt;&lt;code&gt;&lt;span&gt;Word2Vec&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 模型可以实现 &lt;/span&gt;&lt;code&gt;&lt;span&gt;Skip-grams&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 模型和 &lt;/span&gt;&lt;code&gt;&lt;span&gt;Continuous Bag of Words&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 模型。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接下来为&lt;/span&gt;&lt;code&gt;&lt;span&gt;“text8”&lt;/span&gt;&lt;/code&gt;&lt;span&gt;数据集的前 1000 个单词训练 &lt;/span&gt;&lt;code&gt;&lt;span&gt;Word2Vec&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 模型。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;from&lt;/span&gt; gensim.models.word2vec &lt;span&gt;import&lt;/span&gt; Word2Vec&lt;br/&gt;&lt;span&gt;from&lt;/span&gt; multiprocessing &lt;span&gt;import&lt;/span&gt; cpu_count&lt;br/&gt;&lt;br/&gt;&lt;span&gt;# import gensim.downloader as api&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# dataset = api.load(&quot;text8&quot;)&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;words = [d &lt;span&gt;for&lt;/span&gt; d &lt;span&gt;in&lt;/span&gt; dataset]&lt;br/&gt;data1 = words[:&lt;span&gt;1000&lt;/span&gt;]&lt;br/&gt;w2v_model = Word2Vec(data1, min_count = &lt;span&gt;0&lt;/span&gt;,&lt;br/&gt;                     workers=cpu_count())&lt;br/&gt;print(w2v_model.wv[&lt;span&gt;&#x27;social&#x27;&lt;/span&gt;])&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5710491367861886&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7ic0xaWbfkWClibe90xgLfwoa4GfqJULfxsnP3j3XVV8qPwXJkg3x8YshjddriaUPyC3F8Ujliaf0yPHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1506&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上面的输出是通过这个模型找到的&lt;/span&gt;&lt;code&gt;&lt;span&gt;“Social”&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的词向量。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;使用 &lt;/span&gt;&lt;code&gt;&lt;span&gt;most_similar&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 函数，可以得到所有与该&lt;span&gt;“Social”&lt;/span&gt;词相似的词。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;print(w2v_model.wv.most_similar(&lt;span&gt;&#x27;social&#x27;&lt;/span&gt;))&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;[(&#x27;political&#x27;, 0.7943845987319946),&lt;br/&gt; (&#x27;cultural&#x27;, 0.7576460838317871),&lt;br/&gt; (&#x27;ideology&#x27;, 0.7451750040054321),&lt;br/&gt; (&#x27;progressive&#x27;, 0.725498378276825),&lt;br/&gt; (&#x27;intellectual&#x27;, 0.7218820452690125),&lt;br/&gt; (&#x27;discipline&#x27;, 0.7171103954315186),&lt;br/&gt; (&#x27;religious&#x27;, 0.7035976052284241),&lt;br/&gt; (&#x27;radical&#x27;, 0.7034412026405334),&lt;br/&gt; (&#x27;socio&#x27;, 0.700967013835907),&lt;br/&gt; (&#x27;promoting&#x27;, 0.6993831396102905)]&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;同样，还可以保存 &lt;/span&gt;&lt;code&gt;&lt;span&gt;Word2Vec&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 模型并在需要的时候将其加载回来。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;w2v_model.save(&lt;span&gt;&#x27;./w2v_model1&#x27;&lt;/span&gt;)&lt;br/&gt;w2v_model = Word2Vec.load(&lt;span&gt;&#x27;./w2v_model1&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;Gensim 还具有一项功能，可更新现有的 &lt;/span&gt;&lt;code&gt;&lt;span&gt;Word2Vec&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 模型。可以通过调用 &lt;/span&gt;&lt;code&gt;&lt;span&gt;build_vocab&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 函数和 &lt;/span&gt;&lt;code&gt;&lt;span&gt;train&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 函数来更新模型。&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;data2 = words[&lt;span&gt;1000&lt;/span&gt;:]&lt;br/&gt;w2v_model.build_vocab(data2, update=&lt;span&gt;True&lt;/span&gt;)&lt;br/&gt;w2v_model.train(data2, total_examples=w2v_model.corpus_count, &lt;br/&gt;                epochs=w2v_model.epochs)&lt;br/&gt;print(w2v_model.wv[&lt;span&gt;&#x27;social&#x27;&lt;/span&gt;]) &lt;span&gt;# numpy.array()&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.38992042440318303&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7ic0xaWbfkWClibe90xgLfwoad3TKPeicOhdtm6x8JdcCGibJ6ibqt6011RH2agvhdDnvVPGTuKicITbZ8w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1508&quot;/&gt;&lt;/figure&gt;&lt;/section&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;文档相似度的计算&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;在得到每一篇文档对应的主题向量后，我们就可以计算文档之间的相似度，进而完成如文本聚类、信息检索之类的任务。在Gensim中，也提供了这一类任务的API接口。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以信息检索为例。对于一篇待检索的query，我们的目标是从文本集合中检索出主题相似度最高的文档。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;首先，我们需要将待检索的query和文本放在同一个向量空间里进行表达（以LSI向量空间为例）&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;# 构造LSI模型并将待检索的query和文本转化为LSI主题向量&lt;/span&gt;&lt;br/&gt;&lt;span&gt;# 转换之前的corpus和query均是BOW向量&lt;/span&gt;&lt;br/&gt;lsi_model = models.LsiModel(corpus, id2word=dictionary,&lt;br/&gt;                            num_topics=&lt;span&gt;2&lt;/span&gt;)&lt;br/&gt;documents = lsi_model[corpus]&lt;br/&gt;query_vec = lsi_model[query]&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;接下来，我们用待检索的文档向量&lt;strong&gt;初始化一个相似度计算的对象&lt;/strong&gt;：&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;index = similarities.MatrixSimilarity(documents)&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;我们也可以通过&lt;/span&gt;&lt;code&gt;&lt;span&gt;save()&lt;/span&gt;&lt;/code&gt;&lt;span&gt;和&lt;/span&gt;&lt;code&gt;&lt;span&gt;load()&lt;/span&gt;&lt;/code&gt;&lt;span&gt;方法持久化保存这个相似度矩阵：&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;index.save(&lt;span&gt;&#x27;/tmp/test.index&#x27;&lt;/span&gt;)&lt;br/&gt;index = similarities.MatrixSimilarity.load(&lt;span&gt;&#x27;/tmp/test.index&#x27;&lt;/span&gt;)&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;span&gt;注意，如果待检索的目标文档过多，使用&lt;/span&gt;&lt;code&gt;&lt;span&gt;similarities.MatrixSimilarity&lt;/span&gt;&lt;/code&gt;&lt;span&gt;类往往会带来内存不够用的问题。此时，可以改用&lt;/span&gt;&lt;code&gt;&lt;span&gt;similarities.Similarity&lt;/span&gt;&lt;/code&gt;&lt;span&gt;类。二者的接口基本保持一致。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;最后，我们借助&lt;/span&gt;&lt;code&gt;&lt;span&gt;index&lt;/span&gt;&lt;/code&gt;&lt;span&gt;对象计算任意一段&lt;/span&gt;&lt;code&gt;&lt;span&gt;query&lt;/span&gt;&lt;/code&gt;&lt;span&gt;和所有文档的（余弦）相似度：&lt;/span&gt;&lt;/section&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;span&gt;sims = index[query_vec]&lt;br/&gt;&lt;span&gt;# 返回一个元组类型的迭代器：(idx, sim)&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;写在最后&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/h2&gt;&lt;section&gt;&lt;span&gt;本文已经讨论了几个关键的 NLP 主题，帮助我们更加熟悉使用 Gensim 进行文本数据操作。Gensim作为一款强大且开源的工具包非常值得我们花时间学习，如果对搜索引擎和自然语言处理感兴趣，更需要深入学习。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span mstvisible=&quot;8&quot;&gt;&lt;img class=&quot;__bg_gif rich_pages wxw-img&quot; data-backh=&quot;112&quot; data-backw=&quot;562&quot; data-fileid=&quot;100066738&quot; data-ratio=&quot;0.2&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/VeJKXItpwPVibOSMQeyaGwgUuVlcQvxkGpJiaozYcoDqdicBtIND9d4IpGGEDk1TYx9khYV1lE1EZMEXiaGxnr1Gkw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;750&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzg4NDQwNTI0OQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/VeJKXItpwPU2rprYJh2tFmCOVoNcwicACppRbhiczdnAbdSCgjmEKxK9lib4wXkAUvicQZPLrpY5HdVLUb10T5oprQ/0?wx_fmt=png&quot; data-nickname=&quot;AI科技大本营&quot; data-alias=&quot;rgznai100&quot; data-signature=&quot;为AI领域从业者提供人工智能领域热点报道和海量重磅访谈；面向技术人员，提供AI技术领域前沿研究进展和技术成长路线；面向垂直企业，实现行业应用与技术创新的对接。全方位触及人工智能时代，连接AI技术的创造者和使用者。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section data-tools=&quot;135编辑器&quot; data-id=&quot;105185&quot; mstvisible=&quot;7&quot;&gt;&lt;section mstvisible=&quot;8&quot;&gt;&lt;section mstvisible=&quot;9&quot;&gt;&lt;section mstvisible=&quot;10&quot;&gt;&lt;section mstvisible=&quot;11&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mstvisible=&quot;12&quot;&gt;&lt;span msthash=&quot;3662581&quot; msttexthash=&quot;2224768&quot; mstvisible=&quot;17&quot;&gt;往&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mstvisible=&quot;10&quot;&gt;&lt;section mstvisible=&quot;11&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mstvisible=&quot;12&quot;&gt;&lt;span msthash=&quot;3662582&quot; msttexthash=&quot;2402309&quot; mstvisible=&quot;17&quot;&gt;期&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mstvisible=&quot;10&quot;&gt;&lt;section mstvisible=&quot;11&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mstvisible=&quot;12&quot;&gt;&lt;span msthash=&quot;3662583&quot; msttexthash=&quot;2023658&quot; mstvisible=&quot;17&quot;&gt;回&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mstvisible=&quot;10&quot;&gt;&lt;section mstvisible=&quot;11&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mstvisible=&quot;12&quot;&gt;&lt;span msthash=&quot;3662584&quot; msttexthash=&quot;3552458&quot; mstvisible=&quot;17&quot;&gt;顾&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mstvisible=&quot;8&quot;&gt;&lt;section mstvisible=&quot;9&quot;&gt;&lt;section mstvisible=&quot;10&quot;&gt;&lt;section mstvisible=&quot;11&quot;&gt;&lt;section mstvisible=&quot;12&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mstvisible=&quot;13&quot;&gt;&lt;span msthash=&quot;4675944&quot; msttexthash=&quot;7009860&quot; mstvisible=&quot;18&quot;&gt;技术&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-autoskip=&quot;1&quot; mstvisible=&quot;11&quot;&gt;&lt;p hm_fix=&quot;367:547&quot; mstvisible=&quot;12&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg4NDQwNTI0OQ==&amp;amp;mid=2247558656&amp;amp;idx=2&amp;amp;sn=fe88af86dfb2f3954d5f55df5da061fc&amp;amp;chksm=cfbb036ef8cc8a782e96d954f729ae0a730185f476a3f6d3ee450442f1afad04e1944ebd3ad4&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;YYDS！Python实现自动驾驶&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;YYDS！Python实现自动驾驶&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mstvisible=&quot;9&quot;&gt;&lt;section mstvisible=&quot;10&quot;&gt;&lt;section mstvisible=&quot;11&quot;&gt;&lt;section mstvisible=&quot;12&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mstvisible=&quot;13&quot;&gt;&lt;span msthash=&quot;4675945&quot; msttexthash=&quot;5041816&quot; mstvisible=&quot;18&quot;&gt;资讯&lt;br mstvisible=&quot;15&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-autoskip=&quot;1&quot; mstvisible=&quot;11&quot;&gt;&lt;p mstvisible=&quot;12&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg4NDQwNTI0OQ==&amp;amp;mid=2247558949&amp;amp;idx=2&amp;amp;sn=f4192d10906f4162e704bd27ca40d3ba&amp;amp;chksm=cfbb024bf8cc8b5d5d2a22434a1b0f1b55e2bae90d227f80eb2bb66f007fd6f9ec28ecf4d296&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;何同学又上热搜了，这次为什么？&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;何同学又上热搜了，这次为什么？&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mstvisible=&quot;9&quot;&gt;&lt;section mstvisible=&quot;10&quot;&gt;&lt;section mstvisible=&quot;11&quot;&gt;&lt;section mstvisible=&quot;12&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mstvisible=&quot;13&quot;&gt;&lt;span msthash=&quot;4675946&quot; msttexthash=&quot;5041816&quot; mstvisible=&quot;18&quot;&gt;技术&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-autoskip=&quot;1&quot; mstvisible=&quot;11&quot;&gt;&lt;p mstvisible=&quot;12&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg4NDQwNTI0OQ==&amp;amp;mid=2247558772&amp;amp;idx=2&amp;amp;sn=6c88e394df011202f1e35657c5cfdd74&amp;amp;chksm=cfbb031af8cc8a0cb75be22579b260c4e74aa8b9bb9e048b043794f13d3105ad55aa7cb9b636&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;一起用Python做个AI出牌神器！&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;一起用Python做个AI出牌神器！&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mstvisible=&quot;9&quot;&gt;&lt;section mstvisible=&quot;10&quot;&gt;&lt;section mstvisible=&quot;11&quot;&gt;&lt;section mstvisible=&quot;12&quot;&gt;&lt;section data-brushtype=&quot;text&quot; mstvisible=&quot;13&quot;&gt;&lt;span msthash=&quot;5812160&quot; msttexthash=&quot;7009860&quot; mstvisible=&quot;18&quot;&gt;技术&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-autoskip=&quot;1&quot; mstvisible=&quot;11&quot;&gt;&lt;p mstvisible=&quot;12&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg4NDQwNTI0OQ==&amp;amp;mid=2247558399&amp;amp;idx=1&amp;amp;sn=f7591eaea3f790e6fe7e06e5675f847f&amp;amp;chksm=cfbb0191f8cc88873e2ecdec59b33deb52555e4538fdea7be61ed3cac7c612ac5122428c3c74&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;利用Python打造一个语音合成系统&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;用Python打造一个语音合成系统&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot; mstvisible=&quot;7&quot;&gt;&lt;section mstvisible=&quot;8&quot;&gt;&lt;br mstvisible=&quot;9&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mstvisible=&quot;7&quot;&gt;&lt;section hm_fix=&quot;256:729&quot; mstvisible=&quot;8&quot;&gt;&lt;section mstvisible=&quot;9&quot;&gt;&lt;section mstvisible=&quot;10&quot;&gt;&lt;section mstvisible=&quot;11&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100066736&quot; data-ratio=&quot;0.9302325581395349&quot; data-type=&quot;png&quot; data-w=&quot;86&quot; data-width=&quot;100%&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VeJKXItpwPX2FZVxJbbER98riaKxfbdicAoaWibibhVHicMhT0lJR8XvXs6U1fqAnmhH2q1ooImrAgSIVfNicjNLMzZQ/640?wx_fmt=png&quot;/&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; mstvisible=&quot;11&quot;&gt;&lt;p mstvisible=&quot;12&quot;&gt;&lt;span mstvisible=&quot;17&quot;&gt;&lt;strong msthash=&quot;3106770&quot; msttexthash=&quot;4005274&quot; mstvisible=&quot;13&quot;&gt;分享&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mstvisible=&quot;10&quot;&gt;&lt;section mstvisible=&quot;11&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100066735&quot; data-ratio=&quot;0.9294117647058824&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VeJKXItpwPX2FZVxJbbER98riaKxfbdicAL8bkIiaLIqnn0OY6W10TRgtSMWLMOxicm3q2ibbJ8Y9ybJBsiaqeTqBpqQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;85&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; mstvisible=&quot;11&quot;&gt;&lt;p mstvisible=&quot;12&quot;&gt;&lt;span mstvisible=&quot;17&quot;&gt;&lt;strong msthash=&quot;3106771&quot; msttexthash=&quot;9328462&quot; mstvisible=&quot;13&quot;&gt;点收藏&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mstvisible=&quot;9&quot;&gt;&lt;section mstvisible=&quot;10&quot;&gt;&lt;section mstvisible=&quot;11&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100066737&quot; data-ratio=&quot;0.9294117647058824&quot; data-type=&quot;png&quot; data-w=&quot;85&quot; data-width=&quot;100%&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VeJKXItpwPX2FZVxJbbER98riaKxfbdicACtBqqOgf8qDicxXJYAynmgBjgqaFYZcH5PwYjibIceYLvXC66FAfxTOQ/640?wx_fmt=png&quot;/&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; mstvisible=&quot;11&quot;&gt;&lt;p mstvisible=&quot;12&quot;&gt;&lt;span mstvisible=&quot;17&quot;&gt;&lt;strong msthash=&quot;3106772&quot; msttexthash=&quot;9861345&quot; mstvisible=&quot;13&quot;&gt;点点赞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mstvisible=&quot;10&quot;&gt;&lt;section mstvisible=&quot;11&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100066740&quot; data-ratio=&quot;0.9294117647058824&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VeJKXItpwPX2FZVxJbbER98riaKxfbdicA2N4IEaJic9hzA5VlkZ7zyD8Eibe5gRX5iae5ZH6bRf72qDz6v1nnBEpxw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;85&quot; data-width=&quot;100%&quot;/&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot; mstvisible=&quot;11&quot;&gt;&lt;p mstvisible=&quot;12&quot;&gt;&lt;span mstvisible=&quot;17&quot;&gt;&lt;strong msthash=&quot;3106773&quot; msttexthash=&quot;8512010&quot; mstvisible=&quot;13&quot;&gt;点在看&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>