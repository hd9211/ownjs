<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>ca4d3568f2c4898293875aadc2f6b8a7</guid>
<title>深度解析 Raft 分布式一致性协议</title>
<link>https://toutiao.io/k/am8mql2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9517241379310345&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6rxOmdqsWFX4xjLOnOqvByPwoIk8q8ypLYj9HScINibBWT3VEmaFwTAVCAiccGz3TGxsuKXK8eaIhSA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2465&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;笔者期望通过一篇权威靠谱、清晰易懂的系统性文章，帮助读者深入理解 Raft 算法，并能付诸于工程实践中，同时解读不易理解或容易误解的关键点。&lt;/strong&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文是 Raft 实战系列理论内容的整合篇，我们结合 Raft 论文讲解 Raft 算法思路，并遵循 Raft 的模块化思想对难理解及容易误解的内容抽丝剥茧。算法方面讲解：选主机制、基于日志实现状态机机制、安全正确维护状态机机制；工程实现方面讲解：集群成员变更防脑裂策略、解决数据膨胀及快速恢复状态机策略、线性一致读性能优化策略等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;注：本篇内容较多，建议在大屏 PC 或平板阅读，效果更佳。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;1. 概述&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.1 Raft 是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;Raft is a consensus algorithm for managing a replicated log. It produces a result equivalent to (multi-)Paxos, and it is as efficient as Paxos, but its structure is different from Paxos; this makes Raft more understandable than Paxos and also provides a better foundation for building practical systems.&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;--《In Search of an Understandable Consensus Algorithm》&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在分布式系统中，为了消除单点提高系统可用性，通常会使用副本来进行容错，但这会带来另一个问题，即如何保证多个副本之间的一致性？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;这里我们只讨论强一致性，即线性一致性。弱一致性涵盖的范围较广，涉及根据实际场景进行诸多取舍，不在 Raft 系列的讨论目标范围内。&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;所谓的强一致性（线性一致性）并不是指集群中所有节点在任一时刻的状态必须完全一致，而是指一个目标，即让一个分布式系统看起来只有一个数据副本，并且读写操作都是原子的，这样应用层就可以忽略系统底层多个数据副本间的同步问题。也就是说，我们可以将一个强一致性分布式系统当成一个整体，一旦某个客户端成功的执行了写操作，那么所有客户端都一定能读出刚刚写入的值。即使发生网络分区故障，或者少部分节点发生异常，整个集群依然能够像单机一样提供服务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;共识算法（Consensus Algorithm）就是用来做这个事情的，它保证即使在小部分（≤ (N-1)/2）节点故障的情况下，系统仍然能正常对外提供服务。共识算法通常基于状态复制机（Replicated State Machine）模型，也就是所有节点从同一个 state 出发，经过同样的操作 log，最终达到一致的 state。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.6139288417865254&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6rxOmdqsWFX4xjLOnOqvByPcnSpqicVPNjmOW0icVDAOTvZ8QklZ5j8GicYK1iawOu0zickAu1vxCmqicVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1321&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：Replicated State Machine&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;共识算法是构建强一致性分布式系统的基石，Paxos 是共识算法的代表，而 Raft 则是其作者在博士期间研究 Paxos 时提出的一个变种，主要优点是容易理解、易于实现，甚至关键的部分都在论文中给出了伪代码实现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.2 谁在使用 Raft&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;采用 Raft 的系统最著名的当属 etcd 了，可以认为 etcd 的核心就是 Raft 算法的实现。作为一个分布式 kv 系统，etcd 使用 Raft 在多节点间进行数据同步，每个节点都拥有全量的状态机数据。我们在学习了 Raft 以后将会深刻理解为什么 etcd 不适合大数据量的存储（for the most critical data）、为什么集群节点数不是越多越好、为什么集群适合部署奇数个节点等问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;作为一个微服务基础设施，consul 底层使用 Raft 来保证 consul server 之间的数据一致性。在阅读完第六章后，我们会理解为什么 consul 提供了 default、consistent、stale 三种一致性模式（Consistency Modes）、它们各自适用的场景，以及 consul 底层是如何通过改变 Raft 读模型来支撑这些不同的一致性模式的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;TiKV 同样在底层使用了 Raft 算法。虽然都自称是“分布式 kv 存储”，但 TiKV 的使用场景与 etcd 存在区别。其目标是支持 100TB+ 的数据，类似 etcd 的单 Raft 集群肯定无法支撑这个数据量。因此 TiKV 底层使用 Multi Raft，将数据划分为多个 region，每个 region 其实还是一个标准的 Raft 集群，对每个分区的数据实现了多副本高可用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前 Raft 在工业界已经开始大放异彩，对于其各类应用场景这里不再赘述，感兴趣的读者可以参考 https://raft.github.io/，下方有列出各种语言的大量 Raft 实现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.3 Raft 基本概念&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Raft 使用 Quorum 机制来实现共识和容错，我们将对 Raft 集群的操作称为提案，每当发起一个提案，必须得到大多数（&amp;gt; N/2）节点的同意才能提交。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;这里的“提案”我们可以先狭义地理解为对集群的读写操作，“提交”理解为操作成功。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;那么当我们向 Raft 集群发起一系列读写操作时，集群内部究竟发生了什么呢？我们先来概览式地做一个整体了解，接下来再分章节详细介绍每个部分。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;首先，Raft 集群必须存在一个主节点（leader），我们作为客户端向集群发起的所有操作都必须经由主节点处理。所以 Raft 核心算法中的第一部分就是&lt;strong&gt;选主（Leader election）&lt;/strong&gt;——没有主节点集群就无法工作，先票选出一个主节点，再考虑其它事情。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其次，主节点需要承载什么工作呢？它会负责接收客户端发过来的操作请求，将操作包装为日志同步给其它节点，在保证大部分节点都同步了本次操作后，就可以安全地给客户端回应响应了。这一部分工作在 Raft 核心算法中叫&lt;strong&gt;日志复制（Log replication）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;然后，因为主节点的责任是如此之大，所以节点们在选主的时候一定要谨慎，只有符合条件的节点才可以当选主节点。此外主节点在处理操作日志的时候也一定要谨慎，为了保证集群对外展现的一致性，不可以&lt;strong&gt;覆盖或删除&lt;/strong&gt;前任主节点已经处理成功的操作日志。所谓的“谨慎处理”，其实就是在选主和提交日志的时候进行一些限制，这一部分在 Raft 核心算法中叫&lt;strong&gt;安全性（Safety）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Raft 核心算法其实就是由这三个子问题组成的：选主（Leader election）、日志复制（Log replication）、安全性（Safety）。这三部分共同实现了 Raft 核心的共识和容错机制。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;除了核心算法外，Raft 也提供了几个工程实践中必须面对问题的解决方案。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第一个是关于日志无限增长的问题。Raft 将操作包装成为了日志，集群每个节点都维护了一个不断增长的日志序列，状态机只有通过重放日志序列来得到。但由于这个日志序列可能会随着时间流逝不断增长，因此我们必须有一些办法来避免无休止的磁盘占用和过久的日志重放。这一部分叫&lt;strong&gt;日志压缩（Log compaction）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第二个是关于集群成员变更的问题。一个 Raft 集群不太可能永远是固定几个节点，总有扩缩容的需求，或是节点宕机需要替换的时候。直接更换集群成员可能会导致严重的&lt;strong&gt;脑裂&lt;/strong&gt;问题。Raft 给出了一种安全变更集群成员的方式。这一部分叫&lt;strong&gt;集群成员变更（Cluster membership change）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此外，我们还会额外讨论&lt;strong&gt;线性一致性&lt;/strong&gt;的定义、为什么 &lt;strong&gt;Raft 不能与线性一致划等号&lt;/strong&gt;、&lt;strong&gt;如何基于 Raft 实现线性一致&lt;/strong&gt;，以及在如何&lt;strong&gt;保证线性一致的前提下进行读性能优化&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上便是理论篇内将会讨论到的大部分内容的概要介绍，这里我们对 Raft 已经有了一个宏观上的认识，知道了各个部分大概是什么内容，以及它们之间的关系。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来我们将会详细讨论 Raft 算法的每个部分。让我们先从第一部分&lt;strong&gt;选主&lt;/strong&gt;开始。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. 选主&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.1 什么是选主&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;选主（Leader election）就是在分布式系统内抉择出一个主节点来负责一些特定的工作。在执行了选主过程后，集群中每个节点都会识别出一个特定的、唯一的节点作为 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们开发的系统如果遇到选主的需求，通常会直接基于 zookeeper 或 etcd 来做，把这部分的复杂性收敛到第三方系统。然而作为 etcd 基础的 Raft 自身也存在“选主”的概念，这是两个层面的事情：基于 etcd 的选主指的是利用第三方 etcd 让集群对谁做主节点的决策达成一致，技术上来说利用的是 etcd 的一致性状态机、lease 以及 watch 机制，这个事情也可以改用单节点的 MySQL/Redis 来做，只是无法获得高可用性；而 Raft 本身的选主则指的是在 Raft 集群自身内部通过票选、心跳等机制来协调出一个大多数节点认可的主节点作为集群的 leader 去协调所有决策。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;当你的系统利用 etcd 来写入谁是主节点的时候，这个决策也在 etcd 内部被它自己集群选出的主节点处理并同步给其它节点。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2.2 Raft 为什么要进行选主？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;按照论文所述，原生的 Paxos 算法使用了一种点对点（peer-to-peer）的方式，所有节点地位是平等的。在理想情况下，算法的目的是制定&lt;strong&gt;一个决策&lt;/strong&gt;，这对于简化的模型比较有意义。但在工业界很少会有系统会使用这种方式，当有一系列的决策需要被制定的时候，先选出一个 leader 节点然后让它去协调所有的决策，这样算法会更加简单快速。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此外，和其它一致性算法相比，Raft 赋予了 leader 节点更强的领导力，称之为 &lt;strong&gt;Strong Leader&lt;/strong&gt;。比如说日志条目只能从 leader 节点发送给其它节点而不能反着来，这种方式简化了日志复制的逻辑，使 Raft 变得更加简单易懂。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.3 Raft 选主过程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.3.1 节点角色&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raft 集群中每个节点都处于以下三种角色之一：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Leader&lt;/strong&gt;: 所有请求的处理者，接收客户端发起的操作请求，写入本地日志后同步至集群其它节点。 &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Follower&lt;/strong&gt;: 请求的被动更新者，从 leader 接收更新请求，写入本地文件。如果客户端的操作请求发送给了 follower，会首先由 follower 重定向给 leader。 &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Candidate&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;: 如果 follower 在一定时间内没有收到 leader 的心跳，则判断 leader 可能已经故障，此时启动 leader election 过程，本节点切换为 candidate 直到选主结束。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.3.2 任期&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;每开始一次新的选举，称为一个&lt;strong&gt;任期（term）&lt;/strong&gt;，每个 term 都有一个严格递增的整数与之关联。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;每当 candidate 触发 leader election 时都会增加 term，如果一个 candidate 赢得选举，他将在本 term 中担任 leader 的角色。但并不是每个 term 都一定对应一个 leader，有时候某个 term 内会由于选举超时导致选不出 leader，这时 candicate 会递增 term 号并开始新一轮选举。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.40350877192982454&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6rxOmdqsWFX4xjLOnOqvByPYKbo5lQ6GVGWdxA6VYrbO4DZTlZUZZbRIl8gnp9a1iaQmibc6Y0CSKBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1824&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Term 更像是一个&lt;strong&gt;逻辑时钟（logic clock）&lt;/strong&gt;的作用，有了它，就可以发现哪些节点的状态已经过期。每一个节点都保存一个 current term，在通信时带上这个 term 号。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;节点间通过 RPC 来通信，主要有两类 RPC 请求：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.3.3 节点状态转换&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们知道集群每个节点的状态都只能是 leader、follower 或 candidate，那么节点什么时候会处于哪种状态呢？下图展示了一个节点可能发生的状态转换：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.4429868819374369&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6rxOmdqsWFX4xjLOnOqvByP8WLyTK7wohqV434Gb7bx0k24GSn4m26ATu6NPWJ8ZhOzXPkicythfww/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1982&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来我们详细讨论下每个转换所发生的场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.3.3.1 Follower 状态转换过程&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raft 的选主基于一种心跳机制，集群中每个节点刚启动时都是 follower 身份（&lt;strong&gt;Step: starts up&lt;/strong&gt;），leader 会周期性的向所有节点发送心跳包来维持自己的权威，那么首个 leader 是如何被选举出来的呢？方法是如果一个 follower 在一段时间内没有收到任何心跳，也就是选举超时，那么它就会主观认为系统中没有可用的 leader，并发起新的选举（&lt;strong&gt;Step: times out, starts election&lt;/strong&gt;）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里有一个问题，即这个“选举超时时间”该如何制定？如果所有节点在同一时刻启动，经过同样的超时时间后同时发起选举，整个集群会变得低效不堪，极端情况下甚至会一直选不出一个主节点。Raft 巧妙的使用了一个随机化的定时器，让每个节点的“超时时间”在一定范围内随机生成，这样就大大的降低了多个节点同时发起选举的可能性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9453883495145631&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IibQudy5jM3BSsoCVdBmAuBF5GicxWzoHDIm7rPDNgk7pgKhNBrPmkohQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：一个五节点 Raft 集群的初始状态，所有节点都是 follower 身份，term 为 1，且每个节点的选举超时定时器不同&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;若 follower 想发起一次选举，follower 需要先增加自己的当前 term，并将身份切换为 candidate。然后它会向集群其它节点发送“请给自己投票”的消息（RequestVote RPC）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9493365500603136&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IZ5wBibSsQqrmnQNRctqJ7JYq4iazvKkyz7fkib443cpGTQqG2oxcsZWng/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;829&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S1 率先超时，变为 candidate，term + 1，并向其它节点发出拉票请求&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.3.3.2 Candicate 状态转换过程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Follower 切换为 candidate 并向集群其他节点发送“请给自己投票”的消息后，接下来会有三种可能的结果，也即上面&lt;strong&gt;节点状态图中 candidate 状态向外伸出的三条线&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1. 选举成功（Step: receives votes from majority of servers）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当candicate从整个集群的&lt;strong&gt;大多数&lt;/strong&gt;（N/2+1）节点获得了针对同一 term 的选票时，它就赢得了这次选举，立刻将自己的身份转变为 leader 并开始向其它节点发送心跳来维持自己的权威。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9538834951456311&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IicoZwfdqrciaaDqQnQ88Hd9lyJkuiaRBypgD50rlXd6fHN7ibCG51rjQYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：“大部分”节点都给了 S1 选票&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9503030303030303&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36I07e2icJdKHTxHxKeXx9prMgKehj9DsRSFnDupl3UKEeIHdVtiaq1TgZw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S1 变为 leader，开始发送心跳维持权威&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;每个节点针对每个 term 只能投出一张票，并且按照先到先得的原则。这个规则确保只有一个 candidate 会成为 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2. 选举失败（Step: discovers current leader or new term）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Candidate 在等待投票回复的时候，可能会突然收到其它自称是 leader 的节点发送的心跳包，如果这个心跳包里携带的 term &lt;strong&gt;不小于&lt;/strong&gt; candidate 当前的 term，那么 candidate 会承认这个 leader，并将身份切回 follower。这说明其它节点已经成功赢得了选举，我们只需立刻跟随即可。但如果心跳包中的 term 比自己小，candidate 会拒绝这次请求并保持选举状态。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9423769507803121&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IFe5HlnlBicWBbZMWqNlZqjwhBbfEld9dsh6ibBrCKWV6ZUT0g5dVFxBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;833&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S4、S2 依次开始选举&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9466019417475728&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IbaVAOgRjSvib9QGJw8KqBecDV0NnTdGgwia88cvHKqAvcadf5lbTRlPQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S4 成为 leader，S2 在收到 S4 的心跳包后，由于 term 不小于自己当前的 term，因此会立刻切为 follower 跟随 S4&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3. 选举超时（Step: times out, new election）&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第三种可能的结果是 candidate 既没有赢也没有输。如果有多个 follower 同时成为 candidate，选票是可能被瓜分的，如果没有任何一个 candidate 能得到大多数节点的支持，那么每一个 candidate 都会超时。此时 candidate 需要增加自己的 term，然后发起新一轮选举。如果这里不做一些特殊处理，选票可能会一直被瓜分，导致选不出 leader 来。这里的“特殊处理”指的就是前文所述的&lt;strong&gt;随机化选举超时时间&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9498164014687882&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IqrGEBica93t0aq0s1SR3BWU8Tx8RLYW6g5DfZ6priaibxxSk1ib3uBuj9A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;817&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S1 ~ S5 都在参与选举&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9503030303030303&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IDWx8pyu0Oickqc3v8CnkV55pKovmUGd9kYrPw1aRRWG9PTMOspJ7r6w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：没有任何节点愿意给他人投票&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9444444444444444&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36I8LZ2W7GSZslzK0XW5M3sIAJLRg7lGJxPSicO7Lv5QCAMUvJTc2AZkHg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;828&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：如果没有随机化超时时间，所有节点将会继续同时发起选举……&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上便是 candidate 三种可能的选举结果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2.3.3.3 Leader 状态转换过程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;节点状态图中的最后一条线是：&lt;strong&gt;discovers server with higher term&lt;/strong&gt;。想象一个场景：当 leader 节点发生了宕机或网络断连，此时其它 follower 会收不到 leader 心跳，首个触发超时的节点会变为 candidate 并开始拉票（由于随机化各个 follower 超时时间不同），由于该 candidate 的 term 大于原 leader 的 term，因此所有 follower 都会投票给它，这名 candidate 会变为新的 leader。一段时间后原 leader 恢复了，收到了来自新leader 的心跳包，发现心跳中的 term 大于自己的 term，此时该节点会立刻切换为 follower 并跟随的新 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上述流程的动画模拟如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9514563106796117&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IS8uluhyInDbaH7fMV3gxfINQX9aXiaiagw2q9pYCM2b0YSbGcknnHo8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;824&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S4 作为 term2 的 leader&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9418181818181818&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IAL1iasZypk4ia200LC86GLKYyY9Mm2N6TlBczEe4XdnWC6aibicy5gQfHg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;图：S4 宕机，S5 即将率先超时&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9406060606060606&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IdpiajFEyIdfSFDejic9kznSH2DDH5XmyKPduPt59kv1v5m2Dickia7XNIg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;825&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S5 当选 term3 的 leader&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.9387019230769231&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36Ig7mGNMj5cFic2Q7XvubZPibnHh1iaUpQPLSNoXoX81RtSjQbwTTuT3aXg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;832&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S4 宕机恢复后收到了来自 S5 的 term3 心跳&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.935251798561151&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pc32tWo6Y0axUrXLsZw36IddsvkChAaN32ib3ibib6XP3eTBwGZSs97LM1U1z0picxJ8nwjoFBxP7Wog/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;834&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图：S4 立刻变为 S5 的 follower&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上就是 Raft 的选主逻辑，但还有一些细节（譬如是否给该 candidate 投票还有一些其它条件）依赖算法的其它部分基础，我们会在后续“安全性”一章描述。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当票选出 leader 后，leader 也该承担起相应的责任了，这个责任是什么？就是下一章将介绍的“日志复制”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3. 日志复制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.1 什么是日志复制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在前文中我们讲过：共识算法通常基于&lt;strong&gt;状态复制机（Replicated State Machine）&lt;/strong&gt;模型，所有节点从&lt;strong&gt;同一个 state&lt;/strong&gt; 出发，经过一系列&lt;strong&gt;同样操作 log&lt;/strong&gt; 的步骤，最终也必将达到&lt;strong&gt;一致的 state&lt;/strong&gt;。也就是说，只要我们保证集群中所有节点的 log 一致，那么经过一系列应用（apply）后最终得到的状态机也就是一致的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raft 负责保证集群中所有节点 &lt;strong&gt;log 的一致性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外我们还提到过：Raft 赋予了 leader 节点更强的领导力（&lt;strong&gt;Strong Leader&lt;/strong&gt;）。那么 Raft 保证 log 一致的方式就很容易理解了，即所有 log 都必须交给 leader 节点处理，并由 leader 节点复制给其它节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个过程，就叫做&lt;strong&gt;日志复制（Log replication）&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.2 Raft 日志复制机制解析&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.2.1 整体流程解析&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;一旦 leader 被票选出来，它就承担起领导整个集群的责任了，开始接收客户端请求，并将操作包装成日志，并复制到其它节点上去。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;整体流程如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Leader 为客户端提供服务，客户端的每个请求都包含一条即将被状态复制机执行的指令。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Leader 把该指令作为一条新的日志附加到自身的日志集合，然后向其它节点发起&lt;strong&gt;附加条目请求（AppendEntries RPC）&lt;/strong&gt;，来要求它们将这条日志附加到各自本地的日志集合。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当这条日志已经确保被&lt;strong&gt;安全的复制&lt;/strong&gt;，即大多数（N/2+1）节点都已经复制后，leader 会将该日志 &lt;strong&gt;apply&lt;/strong&gt; 到它本地的状态机中，然后把操作成功的结果返回给客户端。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;整个集群的日志模型可以宏观表示为下图（x ← 3 代表 x 赋值为 3）：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.7560283687943262&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17Jl4utBzmsa1XUIa0h9lwXkibms0XWfibNcpzrZ9EDgUHHib8kVI5P37mw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1410&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;每条日志除了存储状态机的操作指令外，还会拥有一个&lt;strong&gt;唯一的整数索引值（log index）&lt;/strong&gt;来表明它在日志集合中的位置。此外，每条日志还会存储一个 &lt;strong&gt;term&lt;/strong&gt; 号（日志条目方块最上方的数字，相同颜色 term 号相同），该 term 表示 leader 收到这条指令时的当前任期，term 相同的 log 是由同一个 leader 在其任期内发送的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当一条日志被 leader 节点认为可以安全的 apply 到状态机时，称这条日志是 &lt;strong&gt;committed&lt;/strong&gt;（上图中的 &lt;strong&gt;committed entries&lt;/strong&gt;）。那么什么样的日志可以被 commit 呢？答案是：&lt;strong&gt;当 leader 得知这条日志被集群过半的节点复制成功时&lt;/strong&gt;。因此在上图中我们可以看到 (term3, index7) 这条日志以及之前的日志都是 committed，尽管有两个节点拥有的日志并不完整。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raft 保证所有 committed 日志都已经被&lt;strong&gt;持久化&lt;/strong&gt;，且“&lt;strong&gt;最终&lt;/strong&gt;”一定会被状态机apply。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;注：这里的“最终”用词很微妙，它表明了一个特点：Raft 保证的只是集群内日志的一致性，而我们真正期望的集群对外的状态机一致性需要我们做一些额外工作，这一点在《线性一致性与读性能优化》一章会着重介绍。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;3.2.2 日志复制流程图解&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们通过 Raft 动画来模拟常规日志复制这一过程：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5317460317460317&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17iaVIy9WiaGOQqcwc34YIARSREnF1rIc4boJic1tfic2b9Evcag4zZZZvTw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1512&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;如上图，S1 当选 leader，此时还没有任何日志。我们模拟客户端向 S1 发起一个请求。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5253333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17a7A9ad4okMRRzZpD1Dy7nlJRox4m2mlibBpS3PU2J4mEx4njYXvpwFw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1500&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;S1 收到客户端请求后新增了一条日志 (term2, index1)，然后并行地向其它节点发起 AppendEntries RPC。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5266666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17bndJsTOj2C5gDDwcKTYaaa7EiarMic1w2lhbZ2hOmUpSz0t6c1XZyI1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1500&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;S2、S4 率先收到了请求，各自附加了该日志，并向 S1 回应响应。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.523936170212766&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17AkE76iauFHz9eBJlNQiczkVnmU3Dpk4w8pd8XFC5pL5XafQQrDx8IUjg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1504&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所有节点都附加了该日志，但由于 leader 尚未收到任何响应，因此暂时还不清楚该日志到底是否被成功复制。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.521970705725699&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17ico1kLywianZrG4a22Nup6lWQzEZDAfWjV5C84zULAD3iayBfLTqMCZiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1502&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 S1 收到&lt;strong&gt;2个节点&lt;/strong&gt;的响应时，该日志条目的边框就已经变为实线，表示该日志已经&lt;strong&gt;安全的复制&lt;/strong&gt;，因为在5节点集群中，2个 follower 节点加上 leader 节点自身，副本数已经确保过半，此时 &lt;strong&gt;S1 将响应客户端的请求&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5206391478029294&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17G64Ev75FZafF5YasPYI68Yvy2fOOZJbd1ibAuEayJGQaZxfkiazBCNicQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1502&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;leader 后续会持续发送心跳包给 followers，心跳包中会携带当前&lt;strong&gt;已经安全复制（我们称之为 committed）的日志索引&lt;/strong&gt;，此处为 (term2, index1)。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5202388852023888&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6r7LqPnp2KFbHcfQvfgBb17I3wiaoTMKupYyJQZVxGpiceMPYu6DPamprcHQMm65jETq7kLjPxNReuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1507&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所有 follower 都通过心跳包得知 (term2, index1) 的 log 已经成功复制 （committed），因此所有节点中该日志条目的边框均变为实线。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.2.3 对日志一致性的保证&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;前边我们使用了 (term2, index1) 这种方式来表示一条日志条目，这里为什么要带上 term，而不仅仅是使用 index？原因是 term 可以用来检查不同节点间日志是否存在不一致的情况，阅读下一节后会更容易理解这句话。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raft 保证：&lt;strong&gt;如果不同的节点日志集合中的两个日志条目拥有相同的 term 和 index，那么它们一定存储了相同的指令&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为什么可以作出这种保证？因为 Raft 要求 leader 在一个 term 内针对同一个 index 只能创建一条日志，并且永远不会修改它。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同时 Raft 也保证：&lt;strong&gt;如果不同的节点日志集合中的两个日志条目拥有相同的 term 和 index，那么它们之前的所有日志条目也全部相同&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这是因为 leader 发出的 AppendEntries RPC 中会额外携带&lt;strong&gt;上一条&lt;/strong&gt;日志的 (term, index)，如果 follower 在本地找不到相同的 (term, index) 日志，则&lt;strong&gt;拒绝接收这次新的日志&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以，只要 follower 持续正常地接收来自 leader 的日志，那么就可以通过归纳法验证上述结论。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.2.4 可能出现的日志不一致场景&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在所有节点正常工作的时候，leader 和 follower的日志总是保持一致，AppendEntries RPC 也永远不会失败。然而我们总要面对任意节点随时可能宕机的风险，如何在这种情况下继续保持集群日志的一致性才是我们真正要解决的问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.6763848396501457&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6qAPI6WrC0YUAjNfyQ0CjuDbPnDO9kSV3pgFlE23IT4BPFDbqhWVVFqPcwsQJmMWQeU2cNeyJhYMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1372&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上图展示了一个 term8 的 leader 刚上任时，集群中日志可能存在的混乱情况。例如 follower 可能缺少一些日志（a ~ b），可能多了一些未提交的日志（c ~ d），也可能既缺少日志又多了一些未提交日志（e ~ f）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;注：Follower 不可能比 leader 多出一些已提交（committed）日志，这一点是通过选举上的限制来达成的，会在下一章《安全性》介绍。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们先来尝试复现上述 a ~ f 场景，最后再讲 Raft 如何解决这种不一致问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;场景a~b. Follower 日志落后于 leader&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种场景其实很简单，即 &lt;strong&gt;follower 宕机了一段时间&lt;/strong&gt;，follower-a 从收到 (term6, index9) 后开始宕机，follower-b 从收到 (term4, index4) 后开始宕机。这里不再赘述。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;场景c. Follower 日志比 leader 多 term6&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 term6 的 leader 正在将 (term6, index11) 向 follower 同步时，该 leader 发生了宕机，且此时只有 follower-c 收到了这条日志的 AppendEntries RPC。然后经过一系列的选举，term7 可能是选举超时，也可能是 leader 刚上任就宕机了，最终 term8 的 leader 上任了，成就了我们看到的场景 c。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;场景d. Follower 日志比 leader 多 term7&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 term6 的 leader 将 (term6, index10) 成功 commit 后，发生了宕机。此时 term7 的 leader 走马上任，连续同步了两条日志给 follower，然而还没来得及 commit 就宕机了，随后集群选出了 term8 的 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;场景e. Follower 日志比 leader 少 term5 ~ 6，多 term4&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 term4 的 leader 将 (term4, index7) 同步给 follower，且将 (term4, index5) 及之前的日志成功 commit 后，发生了宕机，紧接着 follower-e 也发生了宕机。这样在 term5~7 内发生的日志同步全都被 follower-e 错过了。当 follower-e 恢复后，term8 的 leader 也刚好上任了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;场景f. Follower 日志比 leader 少 term4 ~ 6，多 term2 ~ 3&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 term2 的 leader 同步了一些日志（index4 ~ 6）给 follower 后，尚未来得及 commit 时发生了宕机，但它很快恢复过来了，又被选为了 term3 的 leader，它继续同步了一些日志（index7~11）给 follower，但同样未来得及 commit 就又发生了宕机，紧接着 follower-f 也发生了宕机，当 follower-f 醒来时，集群已经前进到 term8 了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.2.5 如何处理日志不一致&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过上述场景我们可以看到，真实世界的集群情况很复杂，那么 Raft 是如何应对这么多不一致场景的呢？其实方式很简单暴力，想想 &lt;strong&gt;Strong Leader&lt;/strong&gt; 这个词。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Raft 强制要求 follower 必须复制 leader 的日志集合来解决不一致问题。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;也就是说，follower 节点上任何与 leader 不一致的日志，都会被 leader 节点上的日志所覆盖。这并不会产生什么问题，因为某些选举上的限制，如果 follower 上的日志与 leader 不一致，那么该日志在 follower 上&lt;strong&gt;一定是未提交的&lt;/strong&gt;。未提交的日志并不会应用到状态机，也不会被外部的客户端感知到。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;要使得 follower 的日志集合跟自己保持完全一致，leader 必须先找到二者间&lt;strong&gt;最后一次&lt;/strong&gt;达成一致的地方。因为一旦这条日志达成一致，在这之前的日志一定也都一致（回忆下前文）。这个确认操作是在 AppendEntries RPC 的一致性检查步骤完成的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Leader 针对每个 follower 都维护一个 &lt;strong&gt;next index&lt;/strong&gt;，表示下一条需要发送给该follower 的日志索引。当一个 leader 刚刚上任时，它初始化所有 next index 值为自己最后一条日志的 index+1。但凡某个 follower 的日志跟 leader 不一致，那么下次 AppendEntries RPC 的一致性检查就会失败。在被 follower 拒绝这次 Append Entries RPC 后，leader 会减少 next index 的值并进行重试。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最终一定会存在一个 next index 使得 leader 和 follower 在这之前的日志都保持一致。极端情况下 next index 为1，表示 follower 没有任何日志与 leader 一致，leader 必须从第一条日志开始同步。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;针对每个 follower，一旦确定了 next index 的值，leader 便开始从该 index 同步日志，follower 会删除掉现存的不一致的日志，保留 leader 最新同步过来的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;整个集群的日志会在这个简单的机制下自动趋于一致。此外要注意，&lt;strong&gt;leader 从来不会覆盖或者删除自己的日志&lt;/strong&gt;，而是强制 follower 与它保持一致。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这就要求集群票选出的 leader 一定要具备“日志的正确性”，这也就关联到了前文提到的：选举上的限制。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;下一章我们将对此详细讨论。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4. 安全性及正确性&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;前面的章节我们讲述了 Raft 算法是如何选主和复制日志的，然而到目前为止我们描述的&lt;strong&gt;这套机制还不能保证每个节点的状态机会严格按照相同的顺序 apply 日志&lt;/strong&gt;。想象以下场景：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Leader 将一些日志复制到了大多数节点上，进行 commit 后发生了宕机。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;某个 follower 并没有被复制到这些日志，但它参与选举并当选了下一任 leader。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;新的 leader 又同步并 commit 了一些日志，这些日志覆盖掉了其它节点上的上一任 committed 日志。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;各个节点的状态机可能 apply 了不同的日志序列，出现了不一致的情况。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此我们需要对“选主+日志复制”这套机制加上一些额外的限制，来保证&lt;strong&gt;状态机的安全性&lt;/strong&gt;，也就是 Raft 算法的正确性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4.1 对选举的限制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们再来分析下前文所述的 committed 日志被覆盖的场景，根本问题其实发生在第2步。Candidate 必须有足够的资格才能当选集群 leader，否则它就会给集群带来不可预料的错误。Candidate 是否具备这个资格可以在选举时添加一个小小的条件来判断，即：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;每个 candidate 必须在 RequestVote RPC 中携带自己本地日志的最新 (term, index)，如果 follower 发现这个 candidate 的日志还没有自己的新，则拒绝投票给该 candidate。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Candidate 想要赢得选举成为 leader，必须得到集群大多数节点的投票，那么&lt;strong&gt;它的日志就一定至少不落后于大多数节点&lt;/strong&gt;。又因为一条日志只有复制到了大多数节点才能被 commit，因此&lt;strong&gt;能赢得选举的 candidate 一定拥有所有 committed 日志&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此前一篇文章我们才会断定地说：Follower 不可能比 leader 多出一些 committed 日志。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;比较两个 (term, index) 的逻辑非常简单：如果 term 不同 term 更大的日志更新，否则 index 大的日志更新。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4.2 对提交的限制&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;除了对选举增加一点限制外，我们还需对 commit 行为增加一点限制，来完成我们 Raft 算法核心部分的最后一块拼图。&lt;/p&gt;&lt;p&gt;回忆下什么是 commit：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;当 leader 得知某条日志被集群过半的节点复制成功时，就可以进行 commit，committed 日志一定最终会被状态机 apply。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所谓 commit 其实就是对日志简单进行一个标记，表明其可以被 apply 到状态机，并针对相应的客户端请求进行响应。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;然而 leader 并不能在任何时候都随意 commit 旧任期留下的日志，即使它已经被复制到了大多数节点。Raft 论文给出了一个经典场景：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.4641269841269841&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6ojLgVaS2nEfNX5CEmHIym1KPOOaOaaPA6NIoicMfOJGG2GdkE6TqJXWG9iaEY1D16vuPjMRBpxPjTg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1575&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上图从左到右按时间顺序模拟了问题场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段a&lt;/strong&gt;：S1 是 leader，收到请求后将 (term2, index2) 只复制给了 S2，尚未复制给 S3 ~ S5。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段b&lt;/strong&gt;：S1 宕机，S5 当选 term3 的 leader（S3、S4、S5 三票），收到请求后保存了 (term3, index2)，尚未复制给任何节点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段c&lt;/strong&gt;：S5 宕机，S1 恢复，S1 重新当选 term4 的 leader，继续将 (term2, index2) 复制给了 S3，已经满足大多数节点，我们将其 commit。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段d&lt;/strong&gt;：S1 又宕机，S5 恢复，S5 重新当选 leader（S2、S3、S4 三票），将 (term3, inde2) 复制给了所有节点并 commit。注意，此时发生了致命错误，已经 committed 的 (term2, index2) 被 (term3, index2) 覆盖了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了避免这种错误，我们需要添加一个额外的限制：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Leader 只允许 commit 包含当前 term 的日志。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;针对上述场景，问题发生在阶段c，即使作为 term4 leader 的 S1 将 (term2, index2) 复制给了大多数节点，它也不能直接将其 commit，而是必须等待 term4 的日志到来并成功复制后，一并进行 commit。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段e&lt;/strong&gt;：在添加了这个限制后，要么 (term2, index2) 始终没有被 commit，这样 S5 在阶段d将其覆盖就是安全的；要么 (term2, index2) 同 (term4, index3) 一起被 commit，这样 S5 根本就无法当选 leader，因为大多数节点的日志都比它新，也就不存在前边的问题了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上便是对算法增加的两个小限制，它们对确保状态机的安全性起到了至关重要的作用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;至此我们对 Raft 算法的核心部分，已经介绍完毕。下一章我们会介绍两个同样描述于论文内的辅助技术：集群成员变更和日志压缩，它们都是在 Raft 工程实践中必不可少的部分。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;5. 集群成员变更与日志压缩&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;尽管我们已经通过前几章了解了 Raft 算法的核心部分，但相较于算法理论来说，在工程实践中仍有一些现实问题需要我们去面对。Raft 非常贴心的在论文中给出了两个常见问题的解决方案，它们分别是：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;集群成员变更&lt;/strong&gt;：如何安全地改变集群的节点成员。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;日志压缩&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：如何解决日志集合无限制增长带来的问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;本文我们将分别讲解这两种技术。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2 data-id=&quot;heading-26&quot;&gt;&lt;strong&gt;&lt;span&gt;5.1 集群成员变更&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在前文的理论描述中我们都假设了集群成员是不变的，然而在实践中有时会需要替换宕机机器或者改变复制级别（即增减节点）。一种最简单暴力达成目的的方式就是：停止集群、改变成员、启动集群。这种方式在执行时会导致集群整体不可用，此外还存在手工操作带来的风险。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了避免这样的问题，Raft 论文中给出了一种无需停机的、自动化的改变集群成员的方式，其实本质上还是利用了 Raft 的核心算法，将集群成员配置作为一个特殊日志从 leader 节点同步到其它节点去。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;5.1.1 直接切换集群成员配置&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;先说结论：&lt;strong&gt;所有将集群从旧配置直接完全切换到新配置的方案都是不安全的&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此我们不能想当然的将新配置直接作为日志同步给集群并 apply。因为我们不可能让集群中的全部节点在“&lt;strong&gt;同一时刻&lt;/strong&gt;”&lt;strong&gt;原子地&lt;/strong&gt;切换其集群成员配置，所以在切换期间不同的节点看到的集群视图可能存在不同，最终可能导致集群存在多个 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了理解上述结论，我们来看一个实际出现问题的场景，下图对其进行了展现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.34332425068119893&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6q0eyr7icJ0wbzhpZoWsZcE8eL3z8cz8ibTEk83PFjd0C2RePlowLnE457H6e6KjqdfwdPicwILR5Spw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1835&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图5-1&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段a&lt;/strong&gt;. 集群存在 S1 ~ S3 三个节点，我们将该成员配置表示为 C-old，绿色表示该节点当前视图（成员配置）为 C-old，其中红边的 S3 为 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段b&lt;/strong&gt;. 集群新增了 S4、S5 两个节点，该变更从 leader 写入，我们将 S1 ~ S5 的五节点新成员配置表示为 C-new，蓝色表示该节点当前视图为 C-new。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段c&lt;/strong&gt;. 假设 S3 短暂宕机触发了 S1 与 S5 的超时选主。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段d&lt;/strong&gt;. S1 向 S2、S3 拉票，S5 向其它全部四个节点拉票。由于 S2 的日志并没有比 S1 更新，因此 S2 可能会将选票投给 S1，S1 两票当选（因为 S1 认为集群只有三个节点）。而 S5 肯定会得到 S3、S4 的选票，因为 S1 感知不到 S4，没有向它发送 RequestVote RPC，并且 S1 的日志落后于 S3，S3 也一定不会投给 S1，结果 S5 三票当选。最终集群出现了多个主节点的致命错误，也就是所谓的脑裂。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.7048799380325329&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6q0eyr7icJ0wbzhpZoWsZcE8ibLCMiaRKKiaFMrDZibSWvqhCE8opGjZf5wClWF0xXuib2kicQEmFGibnyWJg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1291&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图5-2&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上图来自论文，用不同的形式展现了和图5-1相同的问题。颜色代表的含义与图5-1是一致的，在 &lt;strong&gt;problem: two disjoint majorities&lt;/strong&gt; 所指的时间点，集群可能会出现两个 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但是，多主问题并不是在任何新老节点同时选举时都一定可能出现的，社区一些文章在举多主的例子时可能存在错误，下面是一个案例（笔者学习 Raft 协议也从这篇文章中受益匪浅，应该是作者行文时忽略了。文章很赞，建议大家参考学习）：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5916955017301038&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/JfuVbKibIl6qkfsd3Z6Z3PRtzXfEMFJOukfQyWCGjz8YOM5xC06JFewssTFzkUBqMfshYhNma148NrLicf9RzibWQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1156&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;图5-3 &lt;em&gt;来源：https://zhuanlan.zhihu.com/p/27207160&lt;/em&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该假想场景类似图5-1的阶段d，模拟过程如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;S1 为集群原 leader，集群新增 S4、S5，该配置被推给了 S3，S2 尚未收到。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;此时 S1 发生短暂宕机，S2、S3 分别触发选主。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;最终 S2 获得了 S1 和自己的选票，S3 获得了 S4、S5 和自己的选票，集群出现两个 leader。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;图5-3过程看起来好像和图5-1没有什么大的不同，只是参与选主的节点存在区别，然而事实是&lt;strong&gt;图5-3的情况是不可能出现的&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;注意：Raft 论文中传递集群变更信息也是通过日志追加实现的，所以也受到选主的限制。很多读者对选主限制中比较的日志是否必须是 committed 产生疑惑，回看下在《安全性》一文中的描述：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;每个 candidate 必须在 RequestVote RPC 中携带自己本地日志的最新 (term, index)，如果 follower 发现这个 candidate 的日志还没有自己的新，则拒绝投票给该 candidate。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里再帮大家明确下，论文里确实间接表明了，&lt;strong&gt;选主时比较的日志是不要求 committed 的，只需比较本地的最新日志就行&lt;/strong&gt;！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;回到图5-3，不可能出现的原因在于，S1 作为原 leader 已经第一个保存了新配置的日志，而 S2 尚未被同步这条日志，根据上一章《安全性》我们讲到的&lt;strong&gt;选主限制&lt;/strong&gt;，&lt;strong&gt;S1 不可能将选票投给 S2&lt;/strong&gt;，因此 S2 不可能成为 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;5.1.2 两阶段切换集群成员配置&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raft 使用一种两阶段方法平滑切换集群成员配置来避免遇到前一节描述的问题，具体流程如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段一&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;客户端将 C-new 发送给 leader，leader 将 C-old 与 C-new 取&lt;strong&gt;并集&lt;/strong&gt;并立即 apply，我们表示为 &lt;strong&gt;C-old,new&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Leader 将 C-old,new 包装为日志同步给其它节点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Follower 收到 C-old,new 后立即 apply，当 **C-old,new 的大多数节点（即 C-old 的大多数节点和 C-new 的大多数节点）**都切换后，leader 将该日志 commit。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段二&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Leader 接着将 C-new 包装为日志同步给其它节点。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Follower 收到 C-new 后立即 apply，如果此时发现自己不在 C-new 列表，则主动退出集群。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Leader 确认 &lt;strong&gt;C-new 的大多数节点&lt;/strong&gt;都切换成功后，给客户端发送执行成功的响应。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5042125729099157&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6q0eyr7icJ0wbzhpZoWsZcE8V1icvK2N7ImVSjVqJEicaicJOsTe8ibmsk4NJudvicNMDd03ZriciayNBRMTQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1543&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上图展示了该流程的时间线。虚线表示已经创建但尚未 commit 的成员配置日志，实线表示 committed 的成员配置日志。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为什么该方案可以保证不会出现多个 leader？我们来按流程逐阶段分析。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段1. C-old,new 尚未 commit&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该阶段所有节点的配置要么是 C-old，要么是 C-old,new，但无论是二者哪种，只要原 leader 发生宕机，新 leader 都&lt;strong&gt;必须得到大多数 C-old 集合内节点的投票&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以图5-1场景为例，S5 在阶段d根本没有机会成为 leader，因为 C-old 中只有 S3 给它投票了，不满足大多数。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段2. C-old,new 已经 commit，C-new 尚未下发&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该阶段 C-old,new 已经 commit，可以确保已经被 C-old,new 的大多数节点（&lt;strong&gt;再次强调：C-old 的大多数节点和 C-new 的大多数节点&lt;/strong&gt;）复制。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此当 leader 宕机时，新选出的 leader 一定是已经拥有 C-old,new 的节点，不可能出现两个 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段3. C-new 已经下发但尚未 commit&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该阶段集群中可能有三种节点 C-old、C-old,new、C-new，但由于已经经历了阶段2，因此 C-old 节点不可能再成为 leader。而无论是 C-old,new 还是 C-new 节点发起选举，都需要经过大多数 C-new 节点的同意，因此也不可能出现两个 leader。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;阶段4. C-new 已经 commit&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该阶段 C-new 已经被 commit，因此只有 C-new 节点可以得到大多数选票成为 leader。此时集群已经安全地完成了这轮变更，可以继续开启下一轮变更了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上便是对该两阶段方法可行性的分步验证，Raft 论文将该方法称之为&lt;strong&gt;共同一致（Joint Consensus）&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;关于集群成员变更另一篇更详细的论文还给出了其它方法，简单来说就是论证&lt;strong&gt;一次只变更一个节点的的正确性&lt;/strong&gt;，并给出解决可用性问题的优化方案。感兴趣的同学可以参考《Consensus: Bridging Theory and Practice》：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;Consensus: Bridging Theory and Practice&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://github.com/ongardie/dissertation&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;5.2 日志压缩&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们知道 Raft 核心算法维护了日志的一致性，通过 apply 日志我们也就得到了一致的状态机，客户端的操作命令会被包装成日志交给 Raft 处理。然而在实际系统中，客户端操作是连绵不断的，但日志却不能无限增长，首先它会占用很高的存储空间，其次每次系统重启时都需要完整回放一遍所有日志才能得到最新的状态机。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此 Raft 提供了一种机制去清除日志里积累的陈旧信息，叫做&lt;strong&gt;日志压缩&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;快照（Snapshot）&lt;/strong&gt;是一种常用的、简单的日志压缩方式，ZooKeeper、Chubby 等系统都在用。简单来说，就是将某一时刻系统的状态 dump 下来并落地存储，这样该时刻之前的所有日志就都可以丢弃了。所以大家对“压缩”一词不要产生错误理解，我们并没有办法将状态机快照“解压缩”回日志序列。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;注意，&lt;strong&gt;在 Raft 中我们只能为 committed 日志做 snapshot&lt;/strong&gt;，因为只有 committed 日志才是确保最终会应用到状态机的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.662777129521587&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6qkfsd3Z6Z3PRtzXfEMFJOue9Fdv8yyjUvrKUbBLI5ibnfpjgQB4ib6OHR1FicvECQmQ9Xy5HftIZOcQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1714&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上图展示了一个节点用快照替换了 (term1, index1) ~ (term3, index5) 的日志。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;快照一般包含以下内容：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 leader 需要给某个 follower 同步一些旧日志，但这些日志已经被 leader 做了快照并删除掉了时，leader 就需要把该快照发送给 follower。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同样，当集群中有新节点加入，或者某个节点宕机太久落后了太多日志时，leader 也可以直接发送快照，大量节约日志传输和回放时间。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同步快照使用一个新的 RPC 方法，叫做 &lt;strong&gt;InstallSnapshot RPC&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;至此我们已经将 Raft 论文中的内容基本讲解完毕了。《In Search of an Understandable Consensus Algorithm (Extended Version)》 毕竟只有18页，更加侧重于理论描述而非工程实践。如果你想深入学习 Raft，或自己动手写一个靠谱的 Raft 实现，《Consensus: Bridging Theory and Practice》 是你参考的不二之选。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;In Search of an Understandable Consensus Algorithm (Extended Version)&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://raft.github.io/raft.pdf&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;Consensus: Bridging Theory and Practice&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;https://github.com/ongardie/dissertation&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来我们将额外讨论一下关于线性一致性和 Raft 读性能优化的内容。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6. 线性一致性与读性能优化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.1 什么是线性一致性？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在该系列首篇《基本概念》中我们提到过：在分布式系统中，为了消除单点提高系统可用性，通常会使用副本来进行容错，但这会带来另一个问题，即如何保证多个副本之间的&lt;strong&gt;一致性&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;什么是一致性？所谓一致性有很多种模型，不同的模型都是用来评判一个并发系统正确与否的不同程度的标准。而我们今天要讨论的是&lt;strong&gt;强一致性（Strong Consistency）&lt;/strong&gt;模型，也就是&lt;strong&gt;线性一致性（Linearizability）&lt;/strong&gt;，我们经常听到的 CAP 理论中的 C 指的就是它。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其实我们在第一篇就已经简要描述过何为线性一致性：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;所谓的强一致性（线性一致性）并不是指集群中所有节点在任一时刻的状态必须完全一致，而是指一个目标，即让一个分布式系统看起来只有一个数据副本，并且读写操作都是原子的，这样应用层就可以忽略系统底层多个数据副本间的同步问题。也就是说，我们可以将一个强一致性分布式系统当成一个整体，一旦某个客户端成功的执行了写操作，那么所有客户端都一定能读出刚刚写入的值。即使发生网络分区故障，或者少部分节点发生异常，整个集群依然能够像单机一样提供服务。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“&lt;strong&gt;像单机一样提供服务&lt;/strong&gt;”从感官上描述了一个线性一致性系统应该具备的特性，那么我们该如何判断一个系统是否具备线性一致性呢？通俗来说就是不能读到旧（stale）数据，但具体分为两种情况：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;只要根据上述两条规则即可判断一个系统是否具备线性一致性。下面我们来看一个非线性一致性系统的例子。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.7196428571428571&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pUUFc3dfInRmvjJzEuuJE6fCyvPMHzgy9kFW1Vw4a4WKWqA80uCCjLyJjibFMrfREnEHc6HicfEENw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1120&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;本节例图均来自《Designing Data-Intensive Application》，作者 Martin Kleppmann&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如上图所示，裁判将世界杯的比赛结果写入了主库，Alice 和 Bob 所浏览的页面分别从两个不同的从库读取，但由于存在主从同步延迟，Follower 2 的本次同步延迟高于 Follower 1，最终导致 Bob 听到了 Alice 的惊呼后刷新页面看到的仍然是比赛进行中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;虽然线性一致性的基本思想很简单，只是要求&lt;strong&gt;分布式系统看起来只有一个数据副本&lt;/strong&gt;，但在实际中还是有很多需要关注的点，我们继续看几个例子。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.31261101243339257&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pUUFc3dfInRmvjJzEuuJE6ugz40Pdue0wfWibK6oEh101IjIosPLzDQHsNKib9iabtM6bAx2hKyWrpQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1126&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上图从客户端的&lt;strong&gt;外部视角&lt;/strong&gt;展示了多个用户同时请求读写一个系统的场景，每条柱形都是用户发起的一个请求，左端是请求发起的时刻，右端是收到响应的时刻。由于网络延迟和系统处理时间并不固定，所以柱形长度并不相同。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;x 最初的值为 0，Client C 在某个时间段将 x 写为 1。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Client A 第一个读操作位于 Client C 的写操作之前，因此必须读到原始值 0。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Client A 最后一个读操作位于 Client C 的写操作之后，如果系统是线性一致的，那么必须读到新值 1。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;其它与写操作重叠的所有读操作，既可能返回 0，也可能返回 1，因为我们并不清楚写操作在哪个时间段内哪个精确的点生效，这种情况下读写是并发的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;仅仅是这样的话，仍然不能说这个系统满足线性一致。假设 Client B 的第一次读取返回了 1，如果 Client A 的第二次读取返回了 0，那么这种场景并不破坏上述规则，但这个系统仍不满足线性一致，因为客户端在写操作执行期间看到 x 的值在新旧之间来回翻转，这并不符合我们期望的“看起来只有一个数据副本”的要求。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以我们需要额外添加一个约束，如下图所示。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.30905861456483125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pUUFc3dfInRmvjJzEuuJE6GmH2gCuIGCQoxPEG5DTll5bhDfFibStI3a7MCEkZTWlBQQbfHSNCfpw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1126&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在任何一个客户端的读取返回新值后，所有客户端的后续读取也必须返回新值，这样系统便满足线性一致了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们最后来看一个更复杂的例子，继续细化这个时序图。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.49644128113879005&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/JfuVbKibIl6pUUFc3dfInRmvjJzEuuJE6ITUeicICQRqYdkW2ppNyHyz8uP9xaZROVHDIQ1qE9K6rLF1Sklv8D9Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1124&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如上图所示，每个读写操作在某个特定的时间点都是&lt;strong&gt;原子性的生效&lt;/strong&gt;，我们在柱形中用竖线标记出生效的时间点，将这些标记按时间顺序连接起来。那么线性一致的要求就是：&lt;strong&gt;连线总是按照时间顺序向右移动，而不会向左回退&lt;/strong&gt;。所以这个连线结果必定是一个&lt;strong&gt;有效的寄存器读写序列&lt;/strong&gt;：任何客户端的每次读取都必须返回该条目最近一次写入的值。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;线性一致性并非限定在分布式环境下，在单机单核系统中可以简单理解为“寄存器”的特性。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Client B 的最后一次读操作并不满足线性一致，因为在连线向右移动的前提下，它读到的值是错误的（因为Client A 已经读到了由 Client C 写入的 4）。此外这张图里还有一些值得指出的细节点，可以解开很多我们在使用线性一致系统时容易产生的误解：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上述现象在线性一致的语义下都是合理的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以&lt;strong&gt;线性一致性（Linearizability）&lt;/strong&gt;除了叫&lt;strong&gt;强一致性（Strong Consistency）&lt;/strong&gt;外，还叫做&lt;strong&gt;原子一致性（Atomic Consistency）&lt;/strong&gt;、&lt;strong&gt;立即一致性（Immediate Consistency）&lt;/strong&gt;或&lt;strong&gt;外部一致性（External Consistency）&lt;/strong&gt;，这些名字看起来都是比较贴切的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.2 Raft 线性一致性读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在了解了什么是线性一致性之后，我们将其与 Raft 结合来探讨。首先需要明确一个问题，使用了 Raft 的系统都是线性一致的吗？不是的，Raft 只是提供了一个基础，要实现整个系统的线性一致还需要做一些额外的工作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;假设我们期望基于 Raft 实现一个线性一致的分布式 kv 系统，让我们从最朴素的方案开始，指出每种方案存在的问题，最终使整个系统满足线性一致性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.2.1 写主读从缺陷分析&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;写操作并不是我们关注的重点，如果你稍微看了一些理论部分就应该知道，所有写操作都要作为提案从 leader 节点发起，当然所有的写命令都应该简单交给 leader 处理。真正关键的点在于&lt;strong&gt;读操作的处理方式，这涉及到整个系统关于一致性方面的取舍&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在该方案中我们假设读操作直接简单地向 follower 发起，那么由于 Raft 的 Quorum 机制（大部分节点成功即可），针对某个提案在某一时间段内，集群可能会有以下两种状态：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上每个场景客户端都可能读到&lt;strong&gt;过时的数据&lt;/strong&gt;，整个系统显然是不满足线性一致的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.2.2 写主读主缺陷分析&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在该方案中我们限定，所有的读操作也必须经由 leader 节点处理，读写都经过 leader 难道还不能满足线性一致？是的！！并且该方案存在不止一个问题！！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问题一：状态机落后于 committed log 导致脏读&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;回想一下前文讲过的，我们在解释什么是 commit 时提到了写操作什么时候可以响应客户端：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;em&gt;所谓 commit 其实就是对日志简单进行一个标记，表明其可以被 apply 到状态机，并针对相应的客户端请求进行响应。&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;也就是说一个提案只要被 leader commit 就可以响应客户端了，Raft 并没有限定提案结果在返回给客户端前必须先应用到状态机。所以从客户端视角当我们的某个写操作执行成功后，下一次读操作可能还是会读到旧值。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这个问题的解决方式很简单，在 leader 收到读命令时我们只需记录下当前的 commit index，当 apply index 追上该 commit index 时，即可将状态机中的内容响应给客户端。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;问题二：网络分区导致脏读&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;假设集群发生网络分区，旧 leader 位于少数派分区中，而且此刻旧 leader 刚好还未发现自己已经失去了领导权，当多数派分区选出了新的 leader 并开始进行后续写操作时，连接到旧 leader 的客户端可能就会读到旧值了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此，仅仅是直接读 leader 状态机的话，系统仍然不满足线性一致性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.2.3 Raft Log Read&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了确保 leader 处理读操作时仍拥有领导权，我们可以将读请求同样作为一个提案走一遍 Raft 流程，当这次读请求对应的日志可以被应用到状态机时，leader 就可以读状态机并返回给用户了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种读方案称为 &lt;strong&gt;Raft Log Read&lt;/strong&gt;，也可以直观叫做 &lt;strong&gt;Read as Proposal&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为什么这种方案满足线性一致？因为该方案根据 commit index 对所有读写请求都一起做了线性化，这样每个读请求都能感知到状态机在执行完前一写请求后的最新状态，将读写日志一条一条的应用到状态机，整个系统当然满足线性一致。但该方案的缺点也非常明显，那就是&lt;strong&gt;性能差&lt;/strong&gt;，读操作的开销与写操作几乎完全一致。而且由于所有操作都线性化了，我们无法并发读状态机。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;6.3 Raft 读性能优化&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来我们将介绍几种优化方案，它们在不违背系统线性一致性的前提下，大幅提升了读性能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.3.1 Read Index&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与 Raft Log Read 相比，Read Index 省掉了同步 log 的开销，&lt;strong&gt;能够大幅提升读的吞吐，一定程度上降低读的时延&lt;/strong&gt;。其大致流程为：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;Leader 在收到客户端读请求时，记录下当前的 commit index，称之为 read index。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Leader 向 followers 发起一次心跳包，这一步是为了确保领导权，避免网络分区时少数派 leader 仍处理请求。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;等待状态机&lt;strong&gt;至少&lt;/strong&gt;应用到 read index（即 apply index &lt;strong&gt;大于等于&lt;/strong&gt; read index）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;执行读请求，将状态机中的结果返回给客户端。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里第三步的 apply index &lt;strong&gt;大于等于&lt;/strong&gt; read index 是一个关键点。因为在该读请求发起时，我们将当时的 commit index 记录了下来，只要使客户端读到的内容在该 commit index 之后，那么结果&lt;strong&gt;一定都满足线性一致&lt;/strong&gt;（如不理解可以再次回顾下前文线性一致性的例子以及2.2中的问题一）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.3.2 Lease Read&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与 Read Index 相比，Lease Read 进一步省去了网络交互开销，因此更能&lt;strong&gt;显著降低读的时延&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;基本思路是 leader 设置一个&lt;strong&gt;比选举超时（Election Timeout）更短的时间作为租期&lt;/strong&gt;，在租期内我们可以相信其它节点一定没有发起选举，集群也就一定不会存在脑裂，所以在这个时间段内我们直接读主即可，而非该时间段内可以继续走 Read Index 流程，Read Index 的心跳包也可以为租期带来更新。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Lease Read 可以认为是 Read Index 的时间戳版本，额外依赖时间戳会为算法带来一些不确定性，如果时钟发生漂移会引发一系列问题，因此需要谨慎的进行配置。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;6.3.3 Follower Read&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在前边两种优化方案中，无论我们怎么折腾，核心思想其实只有两点：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这两个保证分别对应2.2节所描述的两个问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其实无论是 Read Index 还是 Lease Read，最终目的都是为了解决第二个问题。换句话说，读请求最终一定都是由 leader 来承载的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那么读 follower 真的就不能满足线性一致吗？其实不然，这里我们给出一个可行的读 follower 方案：&lt;strong&gt;Follower 在收到客户端的读请求时，向 leader 询问当前最新的 commit index，反正所有日志条目最终一定会被同步到自己身上，follower 只需等待该日志被自己 commit 并 apply 到状态机后，返回给客户端本地状态机的结果即可&lt;/strong&gt;。这个方案叫做 &lt;strong&gt;Follower Read&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;注意：Follower Read 并不意味着我们在读过程中完全不依赖 leader 了，在保证线性一致性的前提下完全不依赖 leader 理论上是不可能做到的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以上就是 Raft 算法的核心内容及工程实践最需要考虑的内容。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果你坚持看了下来，相信已经对 Raft 算法的理论有了深刻的理解。当然，理论和工程实践之间存在的鸿沟可能比想象的还要大，实践中有众多的细节问题需要去面对。在后续的源码分析及实践篇中，我们会结合代码讲解到许多理论部分没有提到的这些细节点，并介绍基础架构设计的诸多经验，敬请期待！&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>5b7bb79998a1eb5f890eb03e3e2dd71c</guid>
<title>WebRTC + NDI——广播业的福音？</title>
<link>https://toutiao.io/k/pf98b5z</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;elementor-widget-container&quot;&gt;

&lt;p&gt;在疫情蔓延的这几个月里，许多人的日常生活、公司的运作模式发生了巨大变化。我们大多数人被迫呆在家里工作有很长一段时间了，很多行业，特别是整个广播电视行业深受其害。比如由于嘉宾（甚至主持人）无法来到演播室现场，新闻节目、脱口秀中的采访或任何形式的现场互动只能作罢，制作团队只好寻找其他能让节目正常运行的解决方案。&lt;/p&gt;



&lt;p&gt;对于我们这些从事实时业务的人来说，答案好像很简单——利用实时技术即可。但说起来容易做起来难，问题的关键在于制作团队如何使用他们需要编辑和播出的媒体流以及所采用的工具。一如既往，我又受到那些在Twitter上与我们频繁互动的用户的启发，尤其是来自&lt;a href=&quot;https://nimblea.pe/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;Nimble Ape&lt;/a&gt;的Dan Jenkins（同时他也是绝妙的&lt;a href=&quot;https://commcon.xyz/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;CommCon&lt;/a&gt;活动的策划人，推荐大家去看看其中刚刚结束的那场线上会议）提出了一个与BBC新闻有关的新奇发现。另外，Sam Machin的回答也很有启发性，他向我介绍了一种新“玩法”。&lt;/p&gt;



&lt;p&gt;“Skype很受欢迎，因为它配备了NDI插件，可以让它在视觉混合器中作为摄像机源出现，我还没找到其他能提供这个功能的应用。&lt;/p&gt;



&lt;p&gt;——Sam Machin (@sammachin) &lt;a href=&quot;https://twitter.com/sammachin/status/1253578518241345537?ref_src=twsrc%5Etfw&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;2020年4月24日&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;这是我第一次听说NDI，却有醍醐灌顶的感觉。它提醒我用户是否选择你的服务，往往基于其是否能帮助用户更顺畅地工作。我觉得这很有趣并参与到讨论中来，因为我想知道执行RTP到NDI的翻译有多容易（或多难）。&lt;/p&gt;



&lt;p&gt;“我没想过用NDI实现。我需要确定生成这样的流/设备要花多大功夫。在Janus中，我们有办法把WebRTC流转为普通的RTP流，以便在其他地方使用，所以或许也有办法实现RTP到NDI。&lt;/p&gt;



&lt;p&gt;——Lorenzo Miniero (@elminiero)&lt;a href=&quot;https://twitter.com/elminiero/status/1253641526485360640?ref_src=twsrc%5Etfw&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt; 2020年4月24日&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;提起OBS，&lt;a href=&quot;https://cosmosoftware.io/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;CoSMo软件公司&lt;/a&gt;确实实现了一个能够与WebRTC对话的OBS版本。但之后被证实是个虚假消息。正如Alex博士澄清的那样，OBS-WebRTC不支持WebRTC输入，若该项支持成立，OBS是可以实现将输入流翻译成NDI的操作的。&lt;/p&gt;



&lt;p&gt;“OBS的NDI插件既可入也可出。在OBS-Studio-Webrtc中，我们只负责原生的webrtc OUT。webrtc IN由browser source来处理（其内部使用CEF）。&lt;/p&gt;



&lt;p&gt;——Alex.Gouaillard博士 (@ag. Gouaillard )&lt;a href=&quot;https://twitter.com/agouaillard/status/1258682645933969414?ref_src=twsrc%5Etfw&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;2020年5月8日&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;在交流之后，我迫不及待地想研究NDI相关技术（尤其是我现在对它一无所知），但后来由于琐事繁多，我就把它抛之脑后了。&lt;/p&gt;



&lt;p&gt;但几周前和Dan的一次闲聊又激发了我的斗志。他提到他认识的一家视频制作公司正苦恼如何能从网上获取适当的实时推送用于其日常制作中。他也再一次提到，现在NDI几乎是该行业的事实标准了。另外他也提及引入WebRTC流的适当方法少之又少，这迫使编辑们只能像黑客一样去盗取源材料了。&lt;/p&gt;



&lt;p&gt;因此我决定开始研究NDI。我想弄清楚RTP到NDI翻译是否真的可行。&lt;/p&gt;



&lt;p&gt;WebRTC + NDI——广播业的福音？2&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;首先，&lt;/strong&gt;&lt;strong&gt;NDI&lt;/strong&gt;&lt;strong&gt;是什么？&lt;/strong&gt;&lt;strong/&gt;&lt;/p&gt;



&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Network_Device_Interface&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;维基百科&lt;/a&gt;上写道：&lt;/p&gt;



&lt;p&gt;“&lt;a href=&quot;https://www.ndi.tv/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;网络设备接口(NDI)&lt;/a&gt;是NewTek开发的一种免费软件标准，它能使支持视频的产品以高质量、低延迟的方式通信、传输和接收高质量的视频，该方式可精确到帧，适合在直播环境中进行切换。&lt;/p&gt;



&lt;p&gt;简而言之，NDI允许在同一局域网内进行多通道和非压缩媒体流的实时交换，它利用mDNS进行服务发现。这使得节目制作人可以在同一局域网内利用不同来源的媒体，也就是说制作人可以不受限于实际连接到其设置的设备去制作节目。例如下图（来自他们的宣传资料），可以从视觉上让整个过程更加清晰。&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://www.meetecho.com/blog/wp-content/uploads/2020/07/ndi.jpg&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;显然，这项技术背后真正的优势是他们提供的免费SDK，以及可以与NDI媒体实际交互的一套工具。一旦产生了流媒体，无论其来源如何，我们都可以很容易地对其进行切割、操作或处理，以便将其嵌入到更复杂的制作环境中。正因为如此，很多媒体制作公司都在使用NDI。&lt;/p&gt;



&lt;p&gt;这就引出了一个关键问题：如果远程采访也采取这样的制作方式，那制作者很可能无所不用其极获取可以直接使用的NDI源。显然，WebRTC对他们来说还是很难用的。如果没有办法直接拉来WebRTC源，他们只能用些备选方案，比如捕捉渲染远程视频的浏览器窗口，然后用NDI录音机裁剪出他们需要的东西，最终产出成品。而对于音频制作来说，这可能意味着制作人员会录制系统音频输出或者采用类似的操作。&lt;/p&gt;



&lt;p&gt;当然，这是一个次优的解决方案，需要制作人员花费更多心血。此外，如果渲染流媒体的网页有动态接口，它可能会擅自移动你感兴趣的部分，甚至限制页面功能（比如不支持屏幕共享），这就更令人头痛了。这正是我开始研究如何让RTP或多或少地直接翻译成NDI的原因，希望能让整个过程更容易操作。&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;RTP/NDI&lt;/strong&gt;&lt;strong&gt;网关&lt;/strong&gt;&lt;strong/&gt;&lt;/p&gt;



&lt;p&gt;我首先去查找了市面上是否已经有一些RTP/NDI的实现，结果模棱两可。我找到的第一个项目是一个开源插件，叫&lt;a href=&quot;https://github.com/teltek/gst-plugin-ndi&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;gst-plugin-ndi&lt;/a&gt;。这个插件值得研究，但它只涵盖了NDI的接收，没有交付。稍后我会详细解释，该插件对证实我的成果相当有帮助，但并不是我想要的项目。之后我快速研究了FFmpeg的集成，找到了这篇&lt;a href=&quot;https://trac.ffmpeg.org/ticket/7589&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;文章&lt;/a&gt;，作者在文中解释了FFmpeg之前是如何支持NDI的，但后来由于Newtek主张其存在版权侵权问题，就放弃了对其支持。因此，FFmpeg也不是我的选择。&lt;/p&gt;



&lt;p&gt;下一步，我开始寻找自己生成NDI内容的方法，这很简单。因为事实上&lt;a href=&quot;https://www.ndi.tv/sdk/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;NDI SDK&lt;/a&gt;是免费的，可以在官网上免费下载（下载链接会发送到你提供的邮件地址里）。下载好SDK后，你就可以访问一个很强大的文档，包含大量例子。我浏览了一些展示了如何发送音频和视频的例子，看起来很简单。事实上，对于视频，NDI支持以几种不同的支持格式发送未压缩的帧；对于音频，未压缩的帧可以是16pp或FLTP的（浮点会更好）。&lt;/p&gt;



&lt;p&gt;考虑到WebRTC媒体的性质，我决定写一个小型的RTP接收器应用程序（我更喜欢称其为rtp2ndi），该程序可以将音频和视频数据包解包或解码成NDI支持的格式。具体来说，我使用&lt;a href=&quot;https://opus-codec.org/downloads/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;libopus&lt;/a&gt;来解码音频数据包，以及&lt;a href=&quot;https://ffmpeg.org/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;libavcodec&lt;/a&gt;来解码视频（为了操作简单只支持VP8格式）。至于NDI格式，我选择UYVY视频帧，48khz 16pp音频（虽然FLTP是首选，但NDI SDK还是支持上述格式的）。&lt;/p&gt;



&lt;p&gt;WebRTC + NDI——广播业的福音？3+4&lt;/p&gt;



&lt;p&gt;测试该应用需要两种不同工具：&lt;/p&gt;



&lt;p&gt;1. 能通过RTP把音视频帧传送到我应用上的工具;&lt;/p&gt;



&lt;p&gt;2. 能通过NDI接收翻译过的流媒体的工具。&lt;/p&gt;



&lt;p&gt;对于第一种工具，我选择了自己经常在测试中会用到的一个流媒体脚本——一个简单的gstreamer管道。该管道会接收一个预先录制的文件，再通过RTP发送该文件。对于第二种工具，我选择了上面提到的gst-plugin-ndi项目，它提供了一种在窗口中渲染输入feed的简单方法。&lt;/p&gt;



&lt;p&gt;准备就绪后，我先启动了rtp2ndi工具，将其绑定到几个端口来接收RTP数据包，同时给NDI流指定一个名称。&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://www.meetecho.com/blog/wp-content/uploads/2020/07/rtp2ndi-1.png&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;RTP接收器就位后，我就开始把数据包输入到脚本里。&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://www.meetecho.com/blog/wp-content/uploads/2020/07/rtp2ndi-2.png&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;这样我的RTP接收器就开始照我的预想来接收和解码数据包了，同时在这个过程中把数据包翻译成NDI。&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://www.meetecho.com/blog/wp-content/uploads/2020/07/rtp2ndi-3-1.png&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;之后我要做的就是启动gstreamer管道来接收并显示NDI数据流。&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://www.meetecho.com/blog/wp-content/uploads/2020/07/rtp2ndi-4.png&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;当当！这时我们就能看到下图了，这是我最喜欢的一个SNL片段!&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://www.meetecho.com/blog/wp-content/uploads/2020/07/rtp2ndi-5.png&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;现在我们有了一个好的开端，下一步就是尝试用WebRTC进行画面操作。我一如既往选择了Janus来完成这项工作。&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;用&lt;/strong&gt;&lt;strong&gt;WebRTC&lt;/strong&gt;&lt;strong&gt;（和&lt;/strong&gt;&lt;strong&gt;Janus&lt;/strong&gt;&lt;strong&gt;）进行画面操作&lt;/strong&gt;&lt;strong/&gt;&lt;/p&gt;



&lt;p&gt;除发送SNL片段的脚本外，另一个测试WebRTC源的方法可以是常用的&lt;a href=&quot;https://fosdem.org/2020/schedule/event/janus/&quot;&gt;RTP转发器&lt;/a&gt;，之前在很多场合（包括几天前我在&lt;a href=&quot;https://www.youtube.com/watch?v=oSZw90guaUw&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;CommCon&lt;/a&gt;的演讲）我都推荐过这个方法，也亲自用过很多次了。该方法用在这里也不会出错。步骤很简单：创建一个VideoRoom发布者，RTP把源转发到rtp2ndi工具就好了。但出于其他考虑（下文会详述），我想要开发更集成、能独立运行的工具。&lt;/p&gt;



&lt;p&gt;所以我写了一个新的Janus插件，允许WebRTC用户进行以下操作：&lt;/p&gt;



&lt;p&gt;1. 用Janus通过WebRTC发布音频或视频：&lt;/p&gt;



&lt;p&gt;2. 解码发布的流；&lt;/p&gt;



&lt;p&gt;3. 将它们翻译成NDI。&lt;/p&gt;



&lt;p&gt;简而言之，我想结合gstreamer管道提供的注入部分，利用Janus核心中集成的RTP服务器功能来接收数据包，并在新插件中嵌入rtp2ndi的RTP到NDI过程。这是一个相当简单的操作。我设计了一个简单的演示页面，允许网络用户给NDI发送者取一个名字，然后像其他几个插件所做的的那样，与Janus建立一个只进行发送的PeerConnection。&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://www.meetecho.com/blog/wp-content/uploads/2020/07/janus-ndi-1.png&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;我们需要协商一个新的PeerConnection来指示插件创建相关资源，即一个Opus解码器、一个VP8解码器，以及一个使用提供名称的NDI发送器。建立PeerConnection后，演示界面会变成下图这个样子：&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://www.meetecho.com/blog/wp-content/uploads/2020/07/janus-ndi-2.png&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;显而易见，这个操作没什么特别的地方。我们只是简单展示了浏览器捕捉到的本地流并将其发送给Janus。然后一如往常，Janus核心会将未加密的音视频数据包传递给插件。我们配置Janus NDI插件对数据包进行解码，并通过NDI转发未压缩的帧（和之前rtp2ndi做的完全一样）。这意味着通过WebRTC发源的流现在也可以被NDI接收者使用，我们可以通过gstreamer NDI插件再次确认其可行性。&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://www.meetecho.com/blog/wp-content/uploads/2020/07/janus-ndi-3.png&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;到这里基本算大功告成了，但这仍然不是我真正想达到的目的。事实上，如果你仔细想想，该操作确实允许Janus作为WebRTC/NDI网关来运行。但如果处理你感兴趣对话的Janus服务器实际是在互联网，而不是在你的局域网里（几乎总是这样）的话，这个操作意义不大。具体一点，如果Janus处于互联网中的某个位置，比如在AWS，你就无法对创建于此的NDI流做什么。因为只有当所有的流都在你的LAN网络范围内交换时，NDI才能发挥作用。&lt;/p&gt;



&lt;p&gt;因此，我决定再进一步。具体来说就是我决定尝试让两个Janus实例互相对话，即：&lt;/p&gt;



&lt;p&gt;1. 一个在互联网上的Janus（比如上文在线演示的那个Janus）。&lt;/p&gt;



&lt;p&gt;2. 一个在我局域网里的Janus。&lt;/p&gt;



&lt;p&gt;目的很简单——通过WebRTC，使用我局域网中的Janus接收一个实际由公共互联网上的Janus提供服务的流，这样本地的Janus实例就可以将远程流翻译成我可以在本地访问的NDI流。具体来说就是用我的本地Janus实例作为WebRTC 的”客户端”接收来自远程Janus实例的媒体，并将其网关到NDI，如下图所示。&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://www.meetecho.com/blog/wp-content/uploads/2020/07/janus-to-janus.png&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;虽然这听起来很费解而且确实有点不合常规，但其实让Janus实例之间这样对话并不稀奇。之前有人使用这个技巧通过WebRTC把一个插件的媒体加载到另一个插件中。要让这一招奏效，通常只需在双方协调Janus API调用，使其中一个（泄露时可能还有其他候选）的SDP提议传递给另一个，相应的SDP应答也会发送回来，让两个Janus实例相互协商PeerConnection。这就是使用WebRTC这种标准的好处!&lt;/p&gt;



&lt;p&gt;我决定进行实操。具体来说，我订阅了Janus在线demo上默认的Streaming挂载点(&lt;a href=&quot;https://www.meetecho.com/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;Meetecho&lt;/a&gt;点)，并利用相关产品与我的Janus NDI插件协商，形成一个新的PeerConnection。事实上，流媒体插件订阅在功能上等同于Janus中的VideoRoom（SFU）订阅。它们都属于简单而又有效的验证部署方式。&lt;/p&gt;



&lt;p&gt;之后，再加上编排代码就大功告成了。&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://www.meetecho.com/blog/wp-content/uploads/2020/07/janus-ndi-4.png&quot; alt=&quot;&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;当当！该在线演示中远程流媒体挂载点的视频被作为订阅者的本地Janus实例通过WebRTC成功拉取，经过gstreamer NDI接收者再次确认，该媒体流也被正确翻译成NDI了。&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;大功告成&lt;/strong&gt;&lt;strong/&gt;&lt;/p&gt;



&lt;p&gt;希望大家喜欢这篇我对于该新机遇的简短介绍。当然，这篇文章中我主要分享了朝这个方向努力的初步进展，考虑到该操作还没有在实际生产环境中测试过，也没有用gstreamer NDI插件以外的任何其他NDI工具测试过，实际上我们还有很多工作要做。我做的一些假设可能需要调整。如果将来该操作需求较大，我也会考虑开源代码。&lt;/p&gt;



&lt;p&gt;更重要的是，虽然我概念验证的方法有用，但这并不是最理想的验证方式。事实上正如我们在上文所看到的那样，假设处理你感兴趣的对话/流的Janus实例和负责NDI翻译的Janus实例是不同的（这种情况很常见），也就是你要让两个Janus实例在协调器的帮助下建立一个或多个PeerConnections。这个操作是可行的，但仅仅是为了NDI翻译过程就在生产局域网中多一个Janus实例，可能会被视为一种矫枉过正了。&lt;/p&gt;



&lt;p&gt;可能更好的替代方案是创建一个新的临时客户应用程序，其能够执行几乎相同的操作，即：&lt;/p&gt;



&lt;p&gt;1. 建立一个PeerConnection，以便通过WebRTC接收音频和/或视频；&lt;/p&gt;



&lt;p&gt;2. 解包和解码传入流；&lt;/p&gt;



&lt;p&gt;3. 将解码后的数据流翻译成NDI。&lt;/p&gt;



&lt;p&gt;这样操作的复杂性在于WebRTC堆栈，这就是为什么在我的概念验证中我坚持使用Janus，因为它能提供很多免费工具。也就是说在开源世界中，我能找到很多工具完成这个目的。此外，我们自己的&lt;a href=&quot;https://janus.conf.meetecho.com/citeus#jattack&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;Jattack&lt;/a&gt;测试应用程序基本上就是这样的。通过一些更改，它也可以用来支持额外的NDI翻译过程。&lt;/p&gt;



&lt;p&gt;不管采用什么方法，对该机遇感兴趣的人只需开发一个客户端应用程序，将其指向需要媒体的服务器，基本上就可以让他们对整个过程拥有更高控制权。例如该应用可以被配置成只连接一个房间，并自动订阅所有发现；或者指示它挑选来自不同来源的流；总之就是以一种更集成的方式获取我们之前设想的通用外部协商机制所提供的东西。开发一项这样专门的应用程序也将为客户端的额外定制打开大门。例如与其在服务器上运行一个CLI应用程序，这个应用程序可以设定自己的用户界面，并在客户的桌面上运行。&lt;/p&gt;



&lt;p&gt;如果上述这方面的需求大，我下一步打算重点关注该领域。虽然不一定不是UI的部分（我真的不太擅长这一块！），但打造一个专用的客户端还是大有可为的。&lt;/p&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;&lt;p&gt;文章地址：&lt;a href=&quot;https://www.meetecho.com/blog/webrtc-ndi/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;https://www.meetecho.com/blog/webrtc-ndi/&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;



&lt;blockquote class=&quot;wp-block-quote&quot;&gt;&lt;p&gt;原文作者：&lt;a href=&quot;https://www.meetecho.com/blog/author/lminiero/&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot;&gt;Lorenzo Miniero&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;



&lt;p/&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>3fbb3dae8cdd93347c2283e1af8b50c0</guid>
<title>如果全身心投入 1 年，但是收入是 0，你还愿意做独立开发者吗？</title>
<link>https://toutiao.io/k/ucwtqdo</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;article class=&quot;article fmt article-content&quot; data-id=&quot;1190000038515517&quot; data-license=&quot;cc&quot;&gt;
                                &lt;p&gt;&lt;span class=&quot;img-wrap&quot;&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; data-src=&quot;/img/bVcLLMm&quot; src=&quot;https://cdn.segmentfault.com/v-5fd9cb14/global/img/squares.svg&quot; alt=&quot;image&quot; title=&quot;image&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;独立项目名称：&lt;strong&gt;主线程&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;月收入（选答）：&lt;strong&gt;暂时0&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;思否社区ID：&lt;a href=&quot;https://segmentfault.com/u/dreamapplehappy&quot;&gt;&lt;strong&gt;dreamapplehappy&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;今天我们采访到的独立开发者是dreamapplehappy，在杭州读完大学之后，他选择留在杭州这个美丽的城市。&lt;/p&gt;&lt;p&gt;他先后在三家创业公司工作过，并且都是负责前端。现在在一家比较稳定的独角兽公司工作。&lt;/p&gt;&lt;p&gt;最近他在忙两个事情：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一个方向是关于产品，学习如何从零到一开发一款产品，然后慢慢优化，发展壮大&lt;/li&gt;&lt;li&gt;另一个方向是关于技术，想深入的把通用的知识如设计模式，数据结构与算法，以及正则表达式相关的知识在深入的学习整理一下，然后看看能不能写一些文章或者教程帮助大家更好的学习。最近在写的一个系列是设计模式大冒险系列&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;想让这个世界因为自己的存在而变得有一点点不一样，他选择成为一名独立开发者。&lt;/p&gt;&lt;p&gt;他认为独立开发者有足够的自由，不受约束，可以自己把握产品的方向，开发的节奏；更加的灵活，小巧，有更多的成就感和满足感。&lt;/p&gt;&lt;p&gt;最主要的是你是在创造，是内在驱动的，是充满热情的，富有活力的，包容的，不放弃的。这些都是你在为他人工作的时候很难感受到的。&lt;/p&gt;&lt;p&gt;作为一个独立开发者，更接近创业，可以跳出自己的舒适圈，与不同的人沟通协作和交流，拓宽自己的思维，让自己站得更高，看得更远。&lt;/p&gt;&lt;h2&gt;主线程&lt;/h2&gt;&lt;blockquote&gt;&lt;strong&gt;立项日期：19年4月份&lt;/strong&gt;&lt;p&gt;&lt;strong&gt; 项目背景&lt;/strong&gt;：dreamapplehappy所在的创业公司因为产品失败，团队就解散了。然后自己暂时也不想马上就找下一份工作，觉得是不是可以做点什么事情，折腾一下。当时我女朋友也离职在家，她在离职的这段时间还是保持着自律，然后为了督促自己学习，她还建了一个学习打卡的微信群。然后每天监督大家学习，完成计划。然后统计群里每一位成员是否打卡，以及打卡的天数。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;当时她开始时用的是Excel，我知道后便问她为什么不选择市面上已经有的一些解决方案。她说那些都不太满足她的需求；然后我就提议说要不我们来开发一个吧，反正我们现在有很多时间，暂时也不用考虑生活的问题。于是主线程这个项目就诞生了。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;面向群体：&lt;/strong&gt;&lt;strong&gt;前期针对18-30岁考生，如考研、考证、考公、考编、考四六级等人群（这类用户目标明确，使用产品粘性大，付费意愿相对较强），后期扩展至职场和K12人群&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;愿景：&lt;strong&gt;让成为理想的自己变得简单易行&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;产品：&lt;strong&gt;目前是一款学习打卡类小程序，后续结合服务号&amp;amp;微信群运营，之后会考虑开发APP以及Web端的应用&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;核心价值：&lt;strong&gt;帮助用户形成“设定目标-计划任务-坚持打卡-达成目标-经验变现”的学习成长闭环&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;小程序功能：&lt;strong&gt;主线任务、番茄专注、打卡圈子、想法广场、数据分析&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;未来构想：&lt;strong&gt;搭建成长平台，建立内容互动社区（UGC+PGC），解决学习成长过程中的各类问题，打造学习界的Keep！&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;1、如何做的第一版产品？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;列出功能点：&lt;strong&gt;因为这个产品也是我自己使用的工具，所以我即是用户，也是开发者；所以我们第一步是先把需求整理了一下，把关键的需求记录下来。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;市面上产品的分析：&lt;strong&gt;我们也下载了一些市面上大家用的比较多的，关于组队学习打卡、监督学习、任务管理和学习时间记录分析的产品。看看对于上面我们列出的功能，市面上的通用解决方案是怎样的，是不是比较好？没有没有可以优化的地方》总之把这些产品的优缺点都做一个记录。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;画原型图：&lt;strong&gt;我们使用最原始的方案，把产品的原型画在纸上。相比于电子版纸质版感觉更灵活方便。现在记录这个产品的原型图的纸质笔记本还在我的书桌旁边，每逢看到这个本子，都会想起来当时开发主线程的种种美好。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;img-wrap&quot;&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; data-src=&quot;/img/bVcLLM2&quot; src=&quot;https://cdn.segmentfault.com/v-5fd9cb14/global/img/squares.svg&quot; alt=&quot;image&quot; title=&quot;image&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;开发：&lt;strong&gt;我负责前端的开发，我女朋友负责后端开发。我们选择的开发平台是微信小程序。因为微信小程序开发比较方便，而且基于微信，比较容易分享和传播。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我记得第一个版本我们两周就开发完了。把我们想要的最最基本的功能做了出来。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、独立开发过程中遇到过哪些困难？最难搞定的是什么？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;缺少设计，需要自己花费大量的时间去看一些设计师设计的类似产品，设计产品的交互方式以及交互的动效。**&lt;/li&gt;&lt;li&gt;缺少运营，需要自己在开发之外抽出一定的时间去相关的平台运营，宣传。&lt;/li&gt;&lt;li&gt;由于小程序平台的限制，有些功能我们想做但是因为受限于小程序提供的有限功能，所以不得不换种方式。但是替代的方案效果一般来说不是很好。&lt;/li&gt;&lt;li&gt;一些其它的比如小程序审核，公司注册，域名备案，等等。**&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最难搞定的其实是自己对自己产品的信心，我们在开发的过程中有时也会突然感觉自己的产品好像不是很好，觉得它没有竞争力，开发出来不会有人用。在这种情绪下我们的士气会比较低落，我们的开发进度就会比较慢。好在我们后来慢慢的找回了开发产品的自信，进度也就慢慢变正常了。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3、项目目前取得了哪些成就？项目为你带来了什么？&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;注册使用的用户已经一万多了&lt;/li&gt;&lt;li&gt;日活最多的时候能够达到600+&lt;/li&gt;&lt;li&gt;得到了一些投资人的肯定&lt;/li&gt;&lt;li&gt;收到了很多用户的夸奖与认可&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;项目虽然没有给我们带来金钱上的回报，但是带给我们精神和思想上的收益却是金钱买不来的，同时也增加了我的技能树。通过从0到1完成这个项目，我自己对待自己的生活和工作都有了新的认识。我的思维变得开阔，不再是以前那个只知道开发，学习技术的工程师。遇到问题思考的方式也会有一些变化，会站在更高一层去看待技术，产品之间的关系。也为我下一次创业积累了很多宝贵的财富，我相信如果我下次创业会比这次更成功一些的。&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;img-wrap&quot;&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; data-src=&quot;/img/remote/1460000038515520&quot; src=&quot;https://cdn.segmentfault.com/v-5fd9cb14/global/img/squares.svg&quot; alt=&quot;&quot; title=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4、你的商业模式是什么？是如何增长的？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;商业模式：搭建成长平台，建立内容互动社区（UGC+PGC），解决学习成长过程中的各类问题，打造学习界的 Keep！盈利方式依赖会员，付费的内容以及广告。&lt;/p&gt;&lt;p&gt;增长：一方面来自我们在相关平台的推广，一方面来自用户自己的打卡分享，以及圈子的邀请等&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5、近阶段项目有哪些更新，未来会做什么变动？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;近阶段项目一直在维护中，功能上暂时没有进行迭代更新。未来应该会继续维护下去，如果时间允许，我们会继续迭代新的功能。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6、如果项目重来一次你会做哪些改变？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;先注册一个公司，把产品上线需要的一些条件都准备好。&lt;/p&gt;&lt;p&gt;尽快开发出一个最小可行性版本，然后尽早跟用户见面，多收集用户的反馈。保持快速的迭代，不断地优化产品的体验。跟主流程不相关的功能都不要添加，要持续打磨产品的核心功能。&lt;/p&gt;&lt;h2&gt;个人相关问题&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1、推荐你最喜欢的一款产品 / 游戏 / App？并说明原因&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;珍新闻（原锤子阅读）&lt;/p&gt;&lt;p&gt;正如APP的slogan那样，看少一点，看好一点。现在我发觉身边的人对于碎片化的内容兴趣比较高，比较喜欢看短视频，短的资讯。这会让我们感觉自己好像知道很多，但是这些都是不太成体系的东西，我们自己没有把这些知识归纳到自己的体系中。也就不能够很好的消化这些零碎的知识。&lt;/p&gt;&lt;p&gt;珍新闻里面的内容相对不是那么碎片化，相对比较完整。文章的内容质量一般也不错。重要的是这里面的大多数文章都能够将一个事情的来龙去脉讲解清楚，有深度，不是泛泛而谈。我也很喜欢那种花费十几二十分钟，甚至半个小时读完一篇文章的快感。&lt;/p&gt;&lt;p&gt;推荐给大家，希望对大家有所帮助&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2、分享一下你的技术栈和你日常的工作流？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;技术栈：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;JavaScript&lt;/li&gt;&lt;li&gt;Node.js&lt;/li&gt;&lt;li&gt;Vue.js&lt;/li&gt;&lt;li&gt;小程序&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;工作流：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;资讯：Hacker News&lt;/li&gt;&lt;li&gt;阅读：珍新闻&lt;/li&gt;&lt;li&gt;产品：PMCAFF&lt;/li&gt;&lt;li&gt;开发工具：Webstrom&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;3、对独立开发者或编程初学者有什么建议？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;对独立开发者：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;开始之前先确保自己能够在开发产品的过程中维持生活&lt;/li&gt;&lt;li&gt;对自己的产品保持热爱，充满信心。&lt;/li&gt;&lt;li&gt;快速迭代，多获取用户的意见和建议，持续改进产品&lt;/li&gt;&lt;li&gt;如果可以的话，寻找合伙人，让专业的人干专业的事情&lt;/li&gt;&lt;li&gt;保持一个好心情，和一个正常的工作习惯&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对编程初学者：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;编程语言，开发工具选择一个合适的就好，不要陷入对语言和开发工具的争执中。&lt;/li&gt;&lt;li&gt;要多实践，要多写博客整理回顾自己学习的知识&lt;/li&gt;&lt;li&gt;基础知识一定要掌握好，深厚的基础知识会给你的学习带来很多便利&lt;/li&gt;&lt;li&gt;身体很重要，学会劳逸结合，学会好好对待自己的身体健康&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;4、生活中有什么爱好？有什么个人的特别的工作习惯吗？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;爱好：看电影，学习，弹吉他&lt;/p&gt;&lt;p&gt;特别的工作习惯：先把问题想清楚，考虑好然后在动手开发&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5、你对国内的独立开发者环境（云厂商、数字化营销服务商 ）有什么意见和建议？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;希望能给独立开发者一个好的平台支持，提供相关的工具或者资源帮助开发者快速完善自己的产品。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6、聊聊你的思否的看法或对国内技术社区的看法&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;我在上大学的时候就注册了思否账号，感觉这是一个不错的平台。确实帮助了很多开发者解决自己遇到的一些开发的问题。思否的文章质量也都挺不错的，也能让一些开发者学习到很多知识，希望思否越来越好。&lt;/p&gt;&lt;h2&gt;独立开发者寄语&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;如果想跟我讨论产品或者交流技术可以关注我的公众号「关山不难越」或者关注我的思否账号dreamapplehappy，期待与大家的交流。&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;也欢迎你来使用主线程&lt;/p&gt;&lt;blockquote&gt;&lt;span class=&quot;img-wrap&quot;&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; data-src=&quot;/img/bVcLLNS&quot; src=&quot;https://cdn.segmentfault.com/v-5fd9cb14/global/img/squares.svg&quot; alt=&quot;image&quot; title=&quot;image&quot;/&gt;&lt;/span&gt;&lt;/blockquote&gt;&lt;hr/&gt;&lt;p&gt;&lt;span class=&quot;img-wrap&quot;&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; data-src=&quot;https://segmentfault.com/img/bVbI0cI&quot; src=&quot;https://cdn.segmentfault.com/v-5fd9cb14/global/img/squares.svg&quot; alt=&quot;独立开发者支持计划-1.png&quot; title=&quot;独立开发者支持计划-1.png&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;该内容栏目为「SFIDSP - 思否独立开发者支持计划」。为助力独立开发者营造更好的行业环境， SegmentFault 思否社区作为服务于开发者的技术社区，正式推出「思否独立开发者支持计划」，我们希望借助社区的资源为独立开发者提供相应的个人品牌、独立项目的曝光推介。&lt;/p&gt;&lt;p&gt;有意向的独立开发者或者独立项目负责人，可通过邮箱提供相应的信息（个人简介、独立项目简介、联系方式等），以便提升交流的效率。&lt;/p&gt;&lt;p&gt;联系邮箱：pr@segmentfault.com&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;span class=&quot;img-wrap&quot;&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; data-src=&quot;https://segmentfault.com/img/bVcHo5B&quot; src=&quot;https://cdn.segmentfault.com/v-5fd9cb14/global/img/squares.svg&quot; alt=&quot;image&quot; title=&quot;image&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;二维码过期添加思否小姐姐拉你入群&lt;br/&gt;&lt;span class=&quot;img-wrap&quot;&gt;&lt;img referrerpolicy=&quot;no-referrer&quot; data-src=&quot;https://segmentfault.com/img/bVcHEJ9&quot; src=&quot;https://cdn.segmentfault.com/v-5fd9cb14/global/img/squares.svg&quot; alt=&quot;image.png&quot; title=&quot;image.png&quot;/&gt;&lt;/span&gt;&lt;/blockquote&gt;
                            &lt;/article&gt;

                            
                            

                            &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b2653ba887af1e6490e0f2992f2fb074</guid>
<title>Netflix 是怎样做系统监控的？</title>
<link>https://toutiao.io/k/n38vxll</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    

                    
                    
                    &lt;section&gt;&lt;span&gt;作为知名的流媒体巨头，Netflix 在全球拥有近 2 亿订阅用户，服务遍及多个国家。本文阐述了 Netflix 的系统监控实践：自研 Telltale，成功运行并监控着 Netflix 100 多个生产应用程序的运行状况。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;1 难忘的经历&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;相信很多运维人都有过这样的经历：&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;监控系统某个指标超过阈值，触发告警。大半夜里，你被紧急召唤。半睁着眼，你满脸疑惑：“系统真出问题了吗，还是仅仅需要调整下告警？上一次有人调整我们的告警阈值是在什么时候？有没有可能是上游或者下游的服务出现了问题？”&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;鉴于这是一次非常重要的应用告警，因此你不得不从床上爬起来，迅速打开电脑，然后浏览监控仪表盘来追踪问题源头。忙了半天，你还没确认这个告警是来自于系统的问题，但也意识到，从海量数据中寻找线索时，时间正在流逝。你必须尽快定位告警的原因，并祈祷系统稳定运行。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;对我们的用户来讲，稳健的 Netflix 服务至关重要。当你坐下来看《养虎为患》时，你肯定希望它能顺利播放。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;多年来，我们从经常在深夜被召唤的工程师那里了解到应用程序监控的痛点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;过多的告警&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;太多滚动浏览的仪表盘&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;太多的配置&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;过多的维护&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://netflixtechblog.com/full-cycle-developers-at-netflix-a08c31f83249&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2 Telltale&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;我们的流媒体团队需要一个全新的监控系统，可以让团队成员快速地诊断和修复问题；因为在系统告警的紧急情况下，每一秒都至关重要！我们的 Node 团队 需要一个仅需一小撮人就能运维大型集群的系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，我们构建了 Telltale。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.392&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJFFcu949wWgyibjHWbObeib9Ar0hiac5ibW8EGT6ayJYiauoJljCpE6qI5vaQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 监控时间轴&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt; Telltale 的特性&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;1. 汇集监控数据源，创建整体监控视图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 汇集了各种监控数据源，从而能创建关于应用程序运行状况的整体监控视图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2. 多维度判断应用程序的健康状况&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 可以通过多个维度判断一个应用程序的健康情况，而无需根据单一指标频繁调整告警阈值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3. 及时告警&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为我们知道应用程序在什么情况下是正常的，所以能在应用程序有异常趋势时及时通知应用程序的所有者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4. 显示关键数据&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;指标是了解应用程序运行状态的关键。但很多时候，你拥有太多的指标、太多的图表以及太多的监控仪表盘。而 Telltale 仅显示应用程序中有用的相关数据及其上游和下游服务的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5. 用颜色区分问题的严重程度&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们使用不同的颜色来表示问题的严重程度（除选择颜色之外，还可以让 Telltale 显示不同的数字），以便运维人员一眼就能判断出应用程序的运行状况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6. 高亮提示&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还会对一些监控事件进行高亮提示，比如局部区域的网络流量疏散及就近的 服务部署，这些信息对于全面了解服务的健康情况至关重要，尤其是在真正发生系统故障的情况下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就是我们的 Telltale 监控。它现已成功运行并提供监控服务，监控着 Netflix 100 多个生产应用程序的运行状况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.8022857142857143&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJF7jMpgsRQZn473Pa3G9CZvyaiaNxHByfVDCbdy9s54rBAuTPicKeicibxiag/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;3应用程序健康评估模型&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;微服务并非是孤立存在和运行的。它需要特定的依赖，与其他服务进行数据交互，甚至位于不同的AWS区域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面的调用图是一个相对简单的图，其中涉及许多服务，实际的调用链可能会更深更复杂。一个应用程序是系统生态的一部分，它的运行状态可能会受到相关属性变化的微弱影响，也有可能会受到区域范围内某些事件的影响从而发生根本性改变。canary的启动可能会对应用程序产生一定影响。在一定程度上，上游或下游服务的部署同样也可以带来一定的影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://netflixtechblog.com/automated-canary-analysis-at-netflix-with-kayenta-3260bc7acc69&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 通过使用多个维度的数据源构建一个不断自我优化的模型来监控应用程序的健康度：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Atlas 时序指标&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;区域网络流量疏散&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Mantis 实时流数据&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;基础架构变更事件&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Canary 部署及使用&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;上、下游服务的运行状况&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;表征 QoE 的相关指标&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;告警平台发出的报警&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同的数据源对应用程序健康度的影响权重不同。例如，与错误率增加相比，响应时间的增加对应用程序的影响要小很多；错误代码有很多，但是某些特定的错误代码的影响要比其他错误代码的影响大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在服务下游部署 canary 可能不如在上游部署带来的效果明显&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;区域网络流量转移意味着某个区域的网络流量降为零而另一个区域的网络流量会加倍。你可以感受下不同的指标对于监控的影响。监控指标的具体含义决定了我们应该如何科学有效地使用它来进行监控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;https://netflixtechblog.com/project-nimble-region-evacuation-reimagined-d0d0568254d4&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在构建应用程序健康状况视图时，Telltale 考虑了所有这些因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;应用程序健康评估模型是 Telltale 的核心。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;4智能监控&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;每个服务运维人员都知道告警阈值调整的难度。将阈值设置得太低，你会收到大量虚假告警。如果过度补偿并放宽告警阈值，就会错过重要的异常警告。这样导致的最终结果是对告警缺乏信任。Telltale 可以帮助你免除不断调整相关配置的繁琐工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过提供准确的和严格管理的数据源，我们能让应用程序所有者的设置和配置过程变得更加容易。这些数据源通过按照一定的组合应用到程序的配置中，以实现最常见的服务类型配置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 可以自动追踪服务之间的依赖关系，以构建应用程序健康评估模型中的拓扑。通过数据源管理以及拓扑监测，在不用付出很大的努力情况下就能使配置保持最新状态。那些需要手动实践的一些场景仍然支持手动配置和调整。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;没有任何一个独立的算法可以适用我们所有的监控场景。因此，我们采用了混合算法，包括统计算法、基于规则的算法和机器学习算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不久后，我们将在 Netflix Tech Blog 上发表一篇针对我们监控算法的文章。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 还具有分析器，可用于趋势探测或内存泄漏监测。智能监控意味着我们的用户可以信赖我们的监控结果。这表明故障发生时，用户能更快地定位和解决系统异常问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;5智能告警&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;智能监控必然会促进智能告警。当 Telltale 检测到应用程序中的运行异常时，就会产生异常事件。团队可以选择通过 Slack、电子邮件或 PagerDuty（均由我们的内部告警系统提供支持）进行告警。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果该异常问题是由上游或下游系统引起的，则 Telltale 的上下文感知路由会提醒服务对应的维护团队。智能告警还意味着运维团队针对特定异常只会收到一个通知，也就是说，告警风暴已经成为过去式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.4940828402366864&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;676&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJFpv5YEJvVDfp4piaZ7L3RxGTbDAYDV152iacDMwiciaibAv593LWibibNAdpCg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Slack 中的 Telltale 通知示例&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在系统出现问题时，掌握准确的信息至关重要。我们的 Slack 告警程序还会启动一个包含有关事件上下文信息的线程，提供 Telltale 识别到的异常问题信息及问题产生的原因。正确的上下文可以方便我们了解应用程序的当前状态，以便值班运维的工程师能有针对性的定位和修复问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;异常告警事件会不断发展而且拥有自己的生命周期，因此及时更新事件状态至关重要。告警异常是好转了还是恶化了？是否要考虑新的监控信息或事件？Telltale 在当前事件发生改变时会更新 Slack 线程。系统返回正常状态后，该线程将被标记为“已解决”，因此用户一眼就能知道哪些异常事件正在处理中，哪些异常事件已成功修复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些 Slack 线程不仅仅适用于 Telltale。团队还可以用它们来共享有关事件的其他数据，方便进一步观察、理论分析和讨论。异常信息数据和讨论全部集中在一个线程中，方便达成针对当前异常的共识，有利于更快提出问题的解决方案以及异常事件的事后分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们致力于提高 Telltale 告警的质量。一种方法是向我们的用户学习。因此，我们在 Slack 消息中提供了反馈按钮。用户可以告诉我们以后某些情况不需要再发生告警，或提供某些告警不合理的原因。智能告警意味着用户可以信赖我们的告警。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5233968804159446&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;577&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJFQknyUSYJImrDt3RVA5pWGKticNCGLYFMOAJFH6jxyJGz1oSGVRxCiamw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Slack 的 Telltale 通知中描述异常详细信息的一个示例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt; 为什么我的应用服务运行状态欠佳？&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;各种类型的监控数据、应用程序相关知识以及跨多种服务数据的相关性，有助于 Telltale 检测分析应用程序运行健康度降低的原因。这些原因包括实例异常、相关依赖的监测和部署异常、数据库异常或者网络流量高峰等。突出高亮显示这些可能的原因可以帮助运维人员节省大量宝贵的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;6异常事件管理&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.6765714285714286&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJFxVtwF0IgQv8O409rMAiavflDHtNyz2hzVib129Mln6RbbtKZ7tDKQDGw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 异常事件摘要的一个示例&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当 Telltale 发送告警时，它还会创建一个快照，其中引用了不正常的监控信号数据。随着新监控信息的到来，会将其添加到此快照中。这简化了团队的很多事后审查流程。当需要复查过去的异常问题时，“应用程序事件摘要”功能可以从各个方面显示当前的问题，包括一些关键指标，比如总停机时间和 MTTR（平均解决时间）。我们希望帮助我们的团队了解更多的异常事件的模式，以便提高我们服务的整体可用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.8294701986754967&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;604&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJFUaxfpiaGyLGVERw3nV6FYSrzKWRqyBKpiaqUaqNxI0GlQHf0Dg1VTeIQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;集群视图下将相似异常事件分组&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;7部署监控&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;可以看出，Telltale 的应用程序健康评估模型及其智能监控功能非常强大，所以我们也会将其应用于安全部署方面。我们从开放源码交付平台 Spinnaker 开始测试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;https://spinnaker.io/&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;随着 Spinnaker 逐渐推出新版本，我们使用 Telltale 连续监监控运行新版本实例的运行状态。持续监控意味着新部署在问题出现时能自行停止并进行回滚操作。这意味着部署存在问题时的影响半径较小，持续时间更短。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.8361111111111111&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FE4VibF0SjfMHV4KtpyDEbKwrlyPHFqJFyhvxeQj5F99suvQBZ0anw0iaCiaHeHJhfzQjFwmVpVsk5hSibUk4h0czQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;8 持续优化&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;在复杂的系统中，运行微服务非常具有挑战性。Telltale 的智能监控和告警功能可以帮助我们运维人员提高系统可用性、降低运维人员的劳动强度并减少工作人员大半夜被叫醒的频率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们为 Telltale 做到的这些功能提升感到高兴。但是远没有结束，我们仍在不断探索新算法，以提高告警的准确性。我们将在以后的 Netflix Tech Blog 文章中详细介绍我们的工作进展&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们仍然在对应用程序健康评估模型进行进一步评估和改进。我们相信服务运行日志和跟踪数据中会包含更多有价值的信息，这样我们就能采集到更有用的指标数据。我们很期待与平台其他团队进行合作，共同开发这些新功能。将新应用监控引入 Telltale 可以享受到很好的服务体验，但是无法很好的进行扩展，所以我们绝对可以优化和提高自服务的用户界面。我们确信，有更好的启发式方法能帮助用户找出影响服务健康度的一些因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Telltale 简化了应用程序的监控。&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>c193198bb5a187e5f0146e32766bc3e9</guid>
<title>[译] Kubernetes 调度详解</title>
<link>https://toutiao.io/k/w17gmb0</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section&gt;&lt;span&gt;Kubernetes Scheduler 是 Kubernetes 控制平面的核心组件之一。它在控制平面上运行，将 Pod 分配给节点，同时平衡节点之间的资源利用率。将 Pod 分配给新节点后，在该节点上运行的 kubelet 会在 Kubernetes API 中检索 Pod 定义，根据节点上的 Pod 规范创建资源和容器。换句话说，&lt;strong&gt;Scheduler 在控制平面内运行，并将工作负载分配给 Kubernetes 集群&lt;/strong&gt;。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;本文将对 Kubernetes Scheduler 进行深入研究，首先概述一般的调度以及具有亲和力（affinity）和 taint 的驱逐调度，然后讨论调度程序的瓶颈以及生产中可能遇到的问题，最后研究如何微调调度程序的参数以适合集群。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;调度简介&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Kubernetes 调度是将 Pod 分配给集群中匹配节点的过程。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;Scheduler 监控新创建的 Pod，并为其分配最佳节点。它会根据 Kubernetes 的调度原则和我们的配置选项选择最佳节点。&lt;/span&gt;&lt;span&gt;最简单的配置选项是直接在 &lt;/span&gt;&lt;code&gt;&lt;span&gt;PodSpec&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 设置 nodeName：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;496&quot; data-backw=&quot;486&quot; data-ratio=&quot;1.0205761316872428&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGvQ5fCgEdeE2YHzQrXVE78lsCNeYkyZ0UrBMia6qvBTBvZbXe7Ssg8cA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;486&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;上面的 nginx pod 默认情况下将在 node-01 上运行，但是 nodeName 有许多限制导致无法正常运行 Pod，例如云中节点名称未知、资源节点不足以及节点网络间歇性问题等。因此，除了测试或开发期间，我们最好不使用 nodeName。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果要在一组特定的节点上运行 Pod，可以使用 nodeSelector。我们在 &lt;/span&gt;&lt;code&gt;&lt;span&gt;PodSpec&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 中将 nodeSelector 定义为一组键值对：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;542&quot; data-backw=&quot;444&quot; data-ratio=&quot;1.2207207207207207&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGlCNuib1s4oCJYXJuhD9laj0sDBytoCHg7UUVwDsxGibPhCWmcBDHfh8g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;444&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;对于上面的 nginx pod，Kubernetes Scheduler 将找到一个磁盘类型为 ssd 的节点。当然，该节点可以具有其他标签。我们可以在 Kubernetes 参考文档中查看标签的完整列表。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;地址：&lt;/span&gt;&lt;span&gt;https://kubernetes.io/docs/reference/kubernetes-api/labels-annotations-taints/&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;使用 &lt;/span&gt;&lt;code&gt;&lt;span&gt;nodeSelector&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 有约束 Pod 可以在有特定标签的节点上运行。但它的使用仅受标签及其值限制。Kubernetes 中有两个更全面的功能来表达更复杂的调度需求：节点亲和力（node affinity），标记容器以将其吸引到一组节点上；taint 和 toleration，标记节点以排斥 Pod。这些功能将在下面讨论。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;节点亲和力&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;节点亲和力&lt;span&gt;（Node Affinity）&lt;/span&gt;是在 Pod 上定义的一组约束，用于确定哪些节点适合进行调度，即使用亲和性规则为 Pod 的节点分配定义硬性要求和软性要求。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;例如可以将 Pod 配置为仅运行带有 GPU 的节点，并且最好使用 NVIDIA_TESLA_V100 运行深度学习工作负载。Scheduler 会评估规则，并在定义的约束内找到合适的节点。与 &lt;/span&gt;&lt;code&gt;&lt;span&gt;nodeSelectors&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 相似，节点亲和性规则可与节点标签一起使用，但它比 &lt;/span&gt;&lt;code&gt;&lt;span&gt;nodeSelectors&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 更强大。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;我们可以为 podspec 添加四个相似性规则：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;requiredDuringSchedulingIgnoredDuringExecution&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;requiredDuringSchedulingRequiredDuringExecution&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;preferredDuringSchedulingIgnoredDuringExecution&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;preferredDuringSchedulingRequiredDuringExecution&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;这四个规则由两个条件组成：必需或首选条件，以及两个阶段：计划和执行。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;以 required 开头的规则描述了必须满足的严格要求。以 preferred 开头的规则是软性要求，将强制执行但不能保证。调度阶段是指将 Pod 首次分配给节点。执行阶段适用于在调度分配后节点标签发生更改的情况。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果规则声明为 IgnoredDuringExecution，Scheduler 在第一次分配后不会检查其有效性。但如果使用 RequiredDuringExecution 指定了规则，Scheduler 会通过将容器移至合适的节点来确保规则的有效性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以下是示例：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;589&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;674&quot; data-ratio=&quot;1.0193236714975846&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGofCRibndVXu77KHaoictKkeDibhgmuywiblyjw26V5jr2h6wzeWWz6Qliag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1242&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;上面的 Nginx Pod 具有节点亲和性规则，该规则让 Kubernetes Scheduler 将 Pod 放置在 us-east 的节点上。第二条规则指示优先使用 us-east-1 或 us-east-2。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;使用亲和性规则，我们可以让 Kubernetes 调度决策适用于自定义需求。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Taint 与 Toleration&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;集群中并非所有 Kubernetes 节点都相同。某些节点可能具有特殊的硬件，例如 GPU、磁盘或网络功能。同样，我们可能需要将一些节点专用于测试、数据保护或用户组。我们可以将 Taint 添加到节点以排斥 Pod，如以下示例所示：&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;code&gt;&lt;span&gt;kubectl taint nodes node1 test-environment=true:NoSchedule&lt;/span&gt;&lt;/code&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;使用 &lt;/span&gt;&lt;code&gt;&lt;span&gt;test-environment=true:NoScheduletaint&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 时，除非在 podspec 具有匹配的 toleration，否则 Kubernetes Scheduler 将不会分配任何 pod ：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;553&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;673&quot; data-ratio=&quot;0.9575757575757575&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGicbLayoIBkdqkfx5eVguIcJLiaLtZgWTicGTicAGoW1kqKurth41yIzWog/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;660&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;taint 和 tolerations 共同发挥作用，让 Kubernetes Scheduler 专用于某些节点并分配特定 Pod。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;调度瓶颈&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;尽管 Kubernetes Scheduler 能选择最佳节点，但是在 Pod 开始运行之后，“最佳节点”可能会改变。所以从长远来看，Pod 的资源使用及其节点分配可能存在问题。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;资源请求（Request）和限制（Limit）：“Noisy Neighbor”&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;“Noisy Neighbor”并不特定于 Kubernetes。任何多租户系统都是它们的潜在地。假设有两个容器 A 和 B，它们在同一节点上运行。如果 Pod B 试图通过消耗所有 CPU 或内存来创造 noise，Pod A 将出现问题。如果我们为容器设置了资源请求和限制就能控制住 neighbor。Kubernetes 将确保为容器安排其请求的资源，并且不会消耗超出其资源限制的资源。如果在生产中运行 Kubernetes，最好设置资源请求和限制以确保系统可靠。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;系统进程资源不足&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Kubernetes 节点主要是连接到 Kubernetes 控制平面的虚拟机。因此，节点上也有自己的操作系统和相关进程。如果 Kubernetes 工作负载消耗了所有资源，则这些节点将无法运行，并会发生各种问题问题。我们需要在 kubelet 中使用 –system -reserved 设置保留资源，以防止发生这种情况。&lt;/span&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;抢占或调度 Pod&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果 Kubernetes Scheduler 无法将 Pod 调度到可用节点，则可以从节点抢占（preempt）或驱逐（evict）一些 Pod 以分配资源。如果看到 Pod 在集群中移动而没有发现特定原因，可以使用优先级类对其进行定义。同样，如果没有调度好 Pod，并且正在等待其他 Pod，也需要检查其优先级。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以下是示例：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;181&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;235&quot; data-ratio=&quot;0.31337047353760444&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGCOy36sR7upNEKu71SbXfnVgEzSzEb31LmQKnlgcV8dKCs0jzHicGLVQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1436&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;可以通过以下方式在 podspec 中为分配优先级：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;257&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;328&quot; data-ratio=&quot;0.4452423698384201&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGtdyKGib5R2OxMm4npCcnbN8rDfZNd3ib0HeD32sYdHX88Md2XIJDJmDg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1114&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;调度框架&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;Kubernetes Scheduler 具有可插拔的调度框架架构，可向框架添加一组新的插件。插件实现 Plugin API，并被编译到调度程序中。下面我们将讨论调度框架的工作流、扩展点和 Plugin API。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;工作流和扩展点&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;调度 Pod 包括两个阶段：调度周期（scheduling cycle）和绑定周期（binding cycle）。在调度周期中，Scheduler 会找到一个可用节点，然后在绑定过程中，将决策应用于集群。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下图说明了阶段和扩展点的流程：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;305&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5283203125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGcmsVyMOa9e4SQnkCaokDFCdJtUQkDTx1oApezIm6hKq2IRbQicic4O0A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;调度工作流（来源：Kubernetes 文档）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;工作流中的以下几点对插件扩展开放：&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;QueueSort：对队列中的 Pod 进行排序&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;PreFilter：检查预处理 Pod 的相关信息以安排调度周期&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Filter：过滤不适合该 Pod 的节点&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;PostFilter：如果找不到可用于 Pod 的可行节点，调用该插件&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;PreScore：运行 PreScore 任务以生成一个可共享状态供 Score 插件使用&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Score：通过调用每个 Score 插件对过滤的节点进行排名&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;NormalizeScore：合并分数并计算节点的最终排名&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Reserve：在绑定周期之前选择保留的节点&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Permit：批准或拒绝调度周期结果&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;PreBind：执行任何先决条件工作，例如配置网络卷&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Bind：将 Pod 分配给 Kubernetes API 中的节点&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;PostBind：通知绑定周期的结果&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;插件扩展实现了 Plugin API，是 Kubernetes Scheduler 的一部分。我们可以在 Kubernetes 存储库中检查。插件应使用以下名称进行注册：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;98&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;148&quot; data-ratio=&quot;0.17002518891687657&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGP6uWJQmoHvPNW2bS3cN6wewfpTmLnPJyjTYLACyQVYeA3wiaJL9IMlQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1588&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;插件还实现了相关的扩展点，如下所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;127&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;191&quot; data-ratio=&quot;0.2197265625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcGDkicliaRR19tIpibpSTiaibMpFqiaIO5icN3DbHQmllCFnCjGzNfErozonYuQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2048&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;Scheduler 性能调整&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;Kubernetes Scheduler 有一个工作流来查找和绑定 Pod 的可行节点。当集群中的节点数量非常多时，Scheduler 的工作量将成倍增加。在大型集群中，可能需要很长时间才能找到最佳节点，因此要微调调度程序的性能，以在延迟和准确性之间找到折中方案。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;percentageOfNodesToScore 将限制节点的数量来计算自己的分数。默认情况下，Kubernetes 在 100 节点集群的 50％ 和 5000 节点集群的 10％ 之间设置线性阈值。默认最小值为 5％，它要确保至少考虑集群中 5％ 节点的调度。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面的示例展示了如何通过性能调整 kube-scheduler 来手动设置阈值：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-backh=&quot;163&quot; data-backw=&quot;578&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;257&quot; data-ratio=&quot;0.28186714542190305&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/1e9ia4YcKpMPIbNibX8zIXMicNiaH2O1FFcG4glTLP1jy7so5frMxNRlibgevFPXHcibcpg8C3QlapxEmtDnl1f1XjQw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1114&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果有一个庞大的集群并且 Kubernetes 工作负载不能承受 Kubernetes Scheduler 引起的延迟，那么更改百分比是个好主意。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;K8sMeetup&lt;/strong&gt;&lt;strong/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section data-brushtype=&quot;text&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;本文涵盖了 Kubernetes 调度的大多方面，从 Pod 和节点的配置开始，包括 nodeSelector、亲和性规则、taint 和 toleration，然后介绍了 Kubernetes Scheduler 框架、扩展点、API 以及可能发生的与资源相关的瓶颈，最后展示了性能调整设置。尽管 Kubernetes Scheduler 能简单地将 Pod 分配给节点，但是了解其动态性并对其进行配置以实现可靠的生产级 Kubernetes 设置至关重要。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;原文链接：&lt;/span&gt;&lt;span&gt;https://thenewstack.io/a-deep-dive-into-kubernetes-scheduling/&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>