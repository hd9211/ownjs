<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>bc8cc5e07aeb5c4be54119245e8dbe79</guid>
<title>ThreadLocal&amp;MDC内存泄漏问题</title>
<link>https://toutiao.io/k/k98aint</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p id=&quot;js_tags&quot; class=&quot;article-tag__list single-tag__wrp js_single js_wx_tap_highlight wx_tap_card&quot; data-len=&quot;1&quot; role=&quot;link&quot; aria-labelledby=&quot;js_article-tag-card__left js_a11y_comma js_article-tag-card__right&quot;&gt;
                                            
                                                                                    &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__left&quot; class=&quot;article-tag-card__left&quot;&gt;
                                    &lt;span class=&quot;article-tag-card__title&quot;&gt;收录于话题&lt;/span&gt;
                                    &lt;span class=&quot;article-tag__item-wrp no-active js_tag&quot; data-url=&quot;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzUzNjAxODg4MQ==&amp;amp;action=getalbum&amp;amp;album_id=2176378785174994948#wechat_redirect&quot; data-tag_id=&quot;&quot; data-album_id=&quot;2176378785174994948&quot; data-tag_source=&quot;4&quot;&gt;
                                        &lt;span class=&quot;article-tag__item&quot;&gt;#java&lt;/span&gt;
                                    &lt;/span&gt;
                                &lt;/span&gt;
                                &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__right&quot; class=&quot;article-tag-card__right&quot;&gt;3个&lt;/span&gt;
                                                                                        &lt;/p&gt;

                
                                
                
                

                
                                                                

                
                                


                
                
                
                
                                                
                                                                
                                
                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;在&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzNjAxODg4MQ==&amp;amp;mid=2247483678&amp;amp;idx=1&amp;amp;sn=2091e0f6b52cd859284fb14baec7565c&amp;amp;chksm=fafdebb0cd8a62a632c71b43bfd92c387520ca9a4c2a7038fab5c667efa935352e7793a6fe5d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;《大话高可用》&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;《大话高可用》&lt;/a&gt;里，之前的老大有过总结，高可用就是：&lt;span&gt;别人死我们不死，自己不作死，不被别人搞死。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这段时间，网上都在传Log4j2的lookup远程执行代码漏洞。这个漏洞要想造成危害，基本都是被别人搞死的。因为只有url链接或者页面输入了可执行脚本才会触发。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最近在重构&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzNjAxODg4MQ==&amp;amp;mid=2247484045&amp;amp;idx=2&amp;amp;sn=25cf3c0399cf92edbd57e207f18afea3&amp;amp;chksm=fafde823cd8a61354d12e2355829b78b0a84b422ec4d3569bbbff711cb9b1cb3315eafaef9ac&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;《简明日志规范》&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;《简明日志规范》&lt;/a&gt;，就是重构我自己之前开源的一个统一日志的组件。对org.slf4j.MDC不放心，怕引发内存泄露等线上长时间运行才产生的问题。要是有这个问题，比Log4j2的漏洞更不可原谅。因为这纯属自己作死。所以做了一个小研究。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;MDC（Mapped Diagnostic Context，映射调试上下文）是日志系统提供的一种方便在多线程条件下记录日志的功能。可以理解为一个存储容器，原理是将信息存储在了ThreadLocal里。ThreadLocal和线程绑定。程序里用的都是线程池，理论上应该不会出现无限膨胀的情况。总归还是不放心。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;利用周末时间进行了源码研究和测试，终于放心了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;验证&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;首先读了源码，从MDC跟到ThreadLocal，反复的找，没有找到存储ThreadLocal相关信息的容器。因为要是有，且释放做的不好的话是会无限膨胀的。先进行了粗浅的理论研究之后。测试验证一下。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;验证代码如下，实际上MDC.put的内容我放了1万字，便于确认效果。&lt;/p&gt;&lt;pre&gt;&lt;span&gt;public static void &lt;/span&gt;&lt;span&gt;main&lt;/span&gt;(String[] args) {&lt;br/&gt;    ThreadPoolExecutor threadPoolExecutor = &lt;span&gt;new &lt;/span&gt;ThreadPoolExecutor(&lt;span&gt;2&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;200&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;TimeUnit.&lt;span&gt;DAYS&lt;/span&gt;&lt;span&gt;, new &lt;/span&gt;LinkedTransferQueue&amp;lt;&amp;gt;())&lt;span&gt;;&lt;br/&gt;    for &lt;/span&gt;(&lt;span&gt;long &lt;/span&gt;i = &lt;span&gt;0&lt;/span&gt;&lt;span&gt;; &lt;/span&gt;i &amp;lt; Long.&lt;span&gt;MAX_VALUE&lt;/span&gt;&lt;span&gt;; &lt;/span&gt;i++) {&lt;br/&gt;        threadPoolExecutor.submit(&lt;span&gt;new &lt;/span&gt;Runnable() {&lt;br/&gt;            &lt;span&gt;@Override&lt;br/&gt;            &lt;/span&gt;&lt;span&gt;public void &lt;/span&gt;&lt;span&gt;run&lt;/span&gt;() {&lt;br/&gt;                &lt;span&gt;try &lt;/span&gt;{&lt;br/&gt;                   MDC.&lt;span&gt;put&lt;/span&gt;(&lt;span&gt;&quot;k&quot;&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;Thread.&lt;span&gt;currentThread&lt;/span&gt;().getName())&lt;span&gt;;&lt;br/&gt;                    &lt;/span&gt;Thread.&lt;span&gt;sleep&lt;/span&gt;(&lt;span&gt;100&lt;/span&gt;)&lt;span&gt;;&lt;br/&gt;                &lt;/span&gt;} &lt;span&gt;catch &lt;/span&gt;(Exception e) {&lt;br/&gt;                    e.printStackTrace()&lt;span&gt;;&lt;br/&gt;                &lt;/span&gt;}&lt;br/&gt;&lt;br/&gt;            }&lt;br/&gt;        })&lt;span&gt;;&lt;br/&gt;    &lt;/span&gt;}&lt;br/&gt;}&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;场景1&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;将最大线程数调到1W，内存增长根本停不下来，我的电脑明显心有余力不足，没有达到效果。&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzNjAxODg4MQ==&amp;amp;mid=2247485666&amp;amp;idx=1&amp;amp;sn=281374a2c8b286fe9c993e2f4698a261&amp;amp;chksm=fafde24ccd8a6b5ad998f2e893045bb387b3e26b9c7e20802b12b8a2fb2f32dca3db1c2fcf51&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;《Java线程池总结》&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;《Java线程池总结》&lt;/a&gt;有对线程池参数的讲解，这里不赘述。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;场景2&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;核心线程池数10，最大线程数20，在线程执行代码的结尾增加MDC.clear()。因为大多数的最佳实践是结束时都要加，避免线程复用造成的取出数据不准确。日志不准确是个问题，但是没有内存泄露这么可怕。这里加和不加做对比，验证如果忘记加会不会对内存造成压力。&lt;/p&gt;&lt;p&gt;结果运行的进程占2095.1M时达到稳定。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8259109311740891&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRliccfY8uUicHoibfkj1TpT97GxLrW69RpydnOyjuKibiclQEQPLheLjzCPeRVolMsDRUIMRggy8FNAQGjw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;988&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;场景3&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;上面场景中去掉MDC.clear()。&lt;/p&gt;&lt;p&gt;结果运行的进程占2045.8M时达到稳定。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6504320502749411&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz/2tk5ianItRliccfY8uUicHoibfkj1TpT97GxpicVP0aBqmtE4mibCJYMdiauia0L3SINVcq41RHmHYaxsTJsGaA9icPOY2w/640?wx_fmt=bmp&quot; data-type=&quot;bmp&quot; data-w=&quot;1273&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;场景4&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;核心线程池数1，最大线程数2，在线程执行代码的结尾增加MDC.clear()。&lt;/p&gt;&lt;p&gt;结果运行的进程占2116.7M时达到稳定。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7638888888888888&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRliccfY8uUicHoibfkj1TpT97GxcTDMibzYlU90Ss4UXpjw8FYnH54XS0zjvgQejXXLicicJJiamDZ3tp89Bw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1152&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;场景5&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;上面场景中去掉MDC.clear()。&lt;/p&gt;&lt;p&gt;结果运行的进程占2109.3M时达到稳定。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7054195804195804&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRliccfY8uUicHoibfkj1TpT97GxILsl5qz9faRtgTgrowrjxj18iaFB8lEdV3B4QoibcmbSiaBSX4iac0gxTw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1144&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;场景6&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;上面场景中修改核心线程池数2，最大线程数4。&lt;/p&gt;&lt;p&gt;结果运行的进程占2120.7M时达到稳定。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7051170858629662&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRliccfY8uUicHoibfkj1TpT97GxhesCeZFmlibdoiar79ZsnteOmxrMjp3x2qdE1rHvLTp4Y00HS8GPJQDA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1153&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;试验结论&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;无论是否执行MDC.clear()。最终内存占用都会趋于稳定，无内存泄露。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;理论分析&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;虽然验证了，还是不放心。为什么呢？做了这么久的面试官，我深知ThreadLocal内存漏洞问题是一道经典面试题啊。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.08095952023988&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRl9s4DWWQHr4AsiasnOOFwuEwQ74jgXqTTCohictCAgFWBnia7QicicNJhkuB8HYAqyLe1OCU0JqTvas5HA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;667&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;MDC是基于ThreadLocal做的，ThreadLocal泄露了，MDC可以幸免吗？测试没有泄露是不是测试姿势不对？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了知其然而知其所以然，从ThreadLocal内存泄露的具体案例出发，更加仔细的研究了源码。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;ThreadLocal内存泄露问题&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;下面这段测试代码在循环中会出现膨胀，循环过多会导致内存泄露。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;public void &lt;/span&gt;test() &lt;span&gt;throws &lt;/span&gt;Exception {&lt;/span&gt;&lt;/p&gt;&lt;span&gt;&lt;span&gt;for &lt;/span&gt;(&lt;span&gt;int &lt;/span&gt;i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;100&lt;/span&gt;; i++) {&lt;br/&gt;        ThreadLocal threadLocal = &lt;span&gt;new &lt;/span&gt;ThreadLocal();&lt;br/&gt;        threadLocal.set(&lt;span&gt;&quot;t1&quot;&lt;/span&gt;+i);&lt;br/&gt;        Thread t = Thread.&lt;span&gt;currentThread&lt;/span&gt;();&lt;br/&gt;        &lt;span&gt;log&lt;/span&gt;.info(t);&lt;br/&gt;    }&lt;br/&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原因从debug现象来看，随着循环数i的增长，t也就是当前线程的threadLocals数随之增长。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7197149643705463&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRl9s4DWWQHr4AsiasnOOFwuEwR2MmFlKIJ31v3HT36UCZufUsJBtV2CB56veOB0r3gYvDwACAdYAUiag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;842&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;跟踪threadLocal.set(&quot;t1&quot;+i)代码到set方法的源码：&lt;/p&gt;&lt;pre&gt;&lt;span&gt;&lt;span&gt;public void &lt;/span&gt;set(&lt;span&gt;T &lt;/span&gt;value) {&lt;br/&gt;    Thread t = Thread.&lt;span&gt;currentThread&lt;/span&gt;();&lt;br/&gt;    ThreadLocalMap map = getMap(t);&lt;br/&gt;    &lt;span&gt;if &lt;/span&gt;(map != &lt;span&gt;null&lt;/span&gt;)&lt;br/&gt;        map.set(&lt;span&gt;this&lt;/span&gt;, value);&lt;br/&gt;    &lt;span&gt;else&lt;br/&gt;        &lt;/span&gt;createMap(t, value);&lt;br/&gt;&lt;/span&gt;&lt;p&gt;&lt;span&gt;}&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;解释一下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1&amp;gt;threadLocal获取到当前线程，获取当前线程的ThreadLoca&lt;/span&gt;lMap对象。&lt;/p&gt;&lt;p&gt;2&amp;gt;如果map存在，则将当前&lt;span&gt;threadLocal&lt;/span&gt;对象作为key设置value=&quot;t1&quot;+i&lt;/p&gt;&lt;p&gt;3&amp;gt;如果map不存在，则新建一个map，并&lt;span&gt;将当前&lt;/span&gt;&lt;span&gt;threadLocal&lt;/span&gt;&lt;span&gt;对象作为key设置value=&quot;t1&quot;+i&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;就是说一个线程唯一对应一个&lt;span&gt;ThreadLocalMap&lt;/span&gt;对象。&lt;span&gt;threadLocal对象&lt;/span&gt;是&lt;span&gt;ThreadLocalMap这个map中的一个key。将上面的test测试类用伪代码调整成正常的顺序大家应该就能理解了：&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;span&gt;&lt;span&gt;public void &lt;/span&gt;test() &lt;span&gt;throws &lt;/span&gt;Exception {&lt;br/&gt;    Thread t = Thread.&lt;span&gt;currentThread&lt;/span&gt;();&lt;br/&gt;    ThreadLocalMap map = getMap(t);&lt;br/&gt;    &lt;span&gt;for &lt;/span&gt;(&lt;span&gt;int &lt;/span&gt;i = &lt;span&gt;0&lt;/span&gt;; i &amp;lt; &lt;span&gt;100&lt;/span&gt;; i++) {&lt;br/&gt;        ThreadLocal threadLocal = &lt;span&gt;new &lt;/span&gt;ThreadLocal();&lt;br/&gt;        map.set(threadLocal,&lt;span&gt;&quot;t1&quot;&lt;/span&gt;+i);&lt;br/&gt;        &lt;span&gt;log&lt;/span&gt;.info(t);&lt;br/&gt;    }&lt;br/&gt;}&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;所以threadLocal 的引用一直在当前线程的ThreadLocalMap手里，并不是循环下一个这个引用就不可达了。所以会一直创建新的保存老的，直到内存溢出，如下面运行截图：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.0647709320695102&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRl9s4DWWQHr4AsiasnOOFwuEwA35oPJLJ2PPbr0JQwyWPBM18WWLialRcyHyJdYNqFAJL17uAurw3KUg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;633&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;简而言之: threadLocal使用不当，可能会内存泄露。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;MDC为什么无内存泄露问题&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;跟MDC.put(&quot;k&quot;, Thread.currentThread().getName())到源码发现其实put的真正承载容器是static MDCAdapter mdcAdapter。这是一个静态类，在MDC类源码的底部有mdcAdapter的初始化过程static静态块，表明了整个JVM只有一份。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;MDCAdapter 是一个接口，具体的实现因为这是slf4j门面中的。实现会有所不同，但logback等主流日志实现都是new一个ThreadLocal，将Map容器绑定到ThreadLocal中。代码片段感受一下：&lt;/p&gt;&lt;pre&gt;&lt;span&gt;public class LogbackMDCAdapter implements MDCAdapter {&lt;br/&gt;    final ThreadLocal&amp;lt;Map&amp;lt;String, String&amp;gt;&amp;gt; copyOnThreadLocal = new ThreadLocal();&lt;/span&gt;&lt;/pre&gt;&lt;pre&gt;&lt;span&gt;public void put(String key, String val) throws IllegalArgumentException {&lt;br/&gt;    if (key == null) {&lt;br/&gt;        throw new IllegalArgumentException(&quot;key cannot be null&quot;);&lt;br/&gt;    } else {&lt;br/&gt;        Map&amp;lt;String, String&amp;gt; oldMap = (Map)this.copyOnThreadLocal.get();&lt;br/&gt;        Integer lastOp = this.getAndSetLastOperation(1);&lt;br/&gt;        if (!this.wasLastOpReadOrNull(lastOp) &amp;amp;&amp;amp; oldMap != null) {&lt;br/&gt;            oldMap.put(key, val);&lt;br/&gt;        } else {&lt;br/&gt;            Map&amp;lt;String, String&amp;gt; newMap = this.duplicateAndInsertNewMap(oldMap);&lt;br/&gt;            newMap.put(key, val);&lt;br/&gt;        }&lt;br/&gt;&lt;br/&gt;    }&lt;br/&gt;&lt;/span&gt;&lt;p&gt;&lt;span&gt;}&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/pre&gt;&lt;p&gt;简而言之：一个线程顶多会创建一个ThreadLocal，所以不会内存泄露。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、不要假定，要证明。证明之后要理解，逻辑自洽。&lt;/p&gt;&lt;p&gt;2、&lt;span&gt;别人死我们不死，自己不作死，不被别人搞死。&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>baaf901d617cb9d028fdf52f30613716</guid>
<title>为什么GOLANG的TIMER实现使用四叉堆而不是二叉堆</title>
<link>https://toutiao.io/k/i3e1v7i</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;article id=&quot;post-39627&quot; class=&quot;post-content post-39627 post type-post status-publish format-standard hentry category-16 tag-heap tag-timer tag-498 tag-500 tag-497 h-entry h-as-article&quot; itemref=&quot;site-publisher&quot;&gt;
&lt;header class=&quot;entry-header&quot;&gt;
 &lt;/header&gt;

&lt;div class=&quot;entry-content e-content&quot; itemprop=&quot;description articleBody&quot;&gt;
&lt;pre&gt;&lt;code class=&quot;&quot;&gt;版权声明 本站原创文章 由 萌叔 发表
转载请注明 萌叔 | http://vearne.cc
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;1.引言&lt;/h3&gt;
&lt;p&gt;Golang在Timer(计时器)的实现中使用了四叉堆，而不是常见的二叉堆，这个问题引起了我的兴趣。&lt;/p&gt;
&lt;p&gt;对于这个问题，网上的解释是这样的&lt;br/&gt;
&lt;img src=&quot;http://ut-bucket01.sh1a.qingstor.com/woshiaotian/20211228/59f1eb2e-67a4-11ec-b5b4-1e00da114f95.jpeg&quot; alt=&quot;&quot; data-pagespeed-url-hash=&quot;967164888&quot;/&gt;&lt;/p&gt;
&lt;p&gt;但是我仔细查阅了资料以后，有了点有趣的发现。&lt;/p&gt;
&lt;h3&gt;2.说明&lt;/h3&gt;
&lt;p&gt;假设: 堆为&lt;code&gt;d&lt;/code&gt;叉堆，堆中共有&lt;code&gt;n&lt;/code&gt;个节点&lt;br/&gt;
备注: 时间复杂度的证明见&lt;a href=&quot;https://en.wikipedia.org/wiki/D-ary_heap&quot;&gt;d-ary heap&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Timer最常见的2个操作&lt;/p&gt;

&lt;p&gt;添加一个计时器。涉及 &lt;em&gt;sift-up&lt;/em&gt;（上推）操作，时间复杂度为O(log n / log d)&lt;/p&gt;
&lt;p&gt;Python代码&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python &quot;&gt;import math
result = math.log(n, d)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;时间消耗（需要交换或者比较的次数）&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;left&quot;&gt;n(数量)&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;二叉堆&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;四叉堆&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;八叉堆&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;1w&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;13.3&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;6.64&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;4.43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;10w&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;16.61&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;8.30&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;5.54&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;100w&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;19.93&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;9.97&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;6.64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;1000w&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;23.25&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;11.63&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;7.75&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;指定时间到达后，清除计时器。涉及 &lt;em&gt;sift-down&lt;/em&gt;（下推）操作，时间复杂度为O(d * log n / log d)&lt;/p&gt;
&lt;p&gt;Python代码&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python &quot;&gt;import math
result = d * math.log(n, d)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;时间消耗（需要交换或者比较的次数）&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;left&quot;&gt;n(数量)&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;二叉堆&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;四叉堆&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;八叉堆&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;1w&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;26.58&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;26.58&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;35.43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;10w&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;33.33&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;33.33&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;44.29&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;100w&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;39.86&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;39.86&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;53.15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;1000w&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;46.51&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;46.51&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;62.01&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;3. 结论&lt;/h3&gt;
&lt;p&gt;正常情况下，插入操作：多叉堆执行性能优于二叉堆; 删除操作：多叉堆执行性能弱于二叉堆。&lt;br/&gt;
但是细心的朋友应该已经发现，&lt;strong&gt;四叉堆插入操作的耗时只有二叉堆的一半，而删除操作的耗时与四叉堆完全相同。&lt;/strong&gt; 这么一对比，优势确实显著。&lt;/p&gt;
&lt;h3&gt;参考资料&lt;/h3&gt;
&lt;p&gt;1.&lt;a href=&quot;https://en.wikipedia.org/wiki/Heap_(data_structure)&quot;&gt;Heap (data structure)&lt;/a&gt;&lt;br/&gt;
2.&lt;a href=&quot;https://en.wikipedia.org/wiki/Binary_heap&quot;&gt;Binary heap&lt;/a&gt;&lt;br/&gt;
3.&lt;a href=&quot;https://en.wikipedia.org/wiki/D-ary_heap&quot;&gt;d-ary heap&lt;/a&gt;&lt;br/&gt;
4.&lt;a href=&quot;https://www.cyhone.com/articles/analysis-of-golang-timer/&quot;&gt;Golang 定时器底层实现深度剖析&lt;/a&gt;&lt;br/&gt;
5.&lt;a href=&quot;https://www.jianshu.com/p/6b526aa481b1&quot;&gt;数据结构：堆（Heap）&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h4&gt;请我喝瓶饮料&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;http://static.zybuluo.com/woshiaotian/ohw8kvpn5k7hthgbuol4e4aq/WechatIMG29.jpg&quot; alt=&quot;微信支付码&quot; data-pagespeed-url-hash=&quot;2495828515&quot;/&gt;&lt;/p&gt;

&lt;p class=&quot;clear&quot;/&gt;
&lt;/div&gt;
&lt;nav class=&quot;navigation post-navigation&quot; role=&quot;navigation&quot; aria-label=&quot;文章&quot;&gt;
&lt;h2 class=&quot;screen-reader-text&quot;&gt;文章导航&lt;/h2&gt;

&lt;/nav&gt; &lt;p class=&quot;clear&quot;/&gt;

&lt;/article&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>0d787e8687548ebeced32906e325ecac</guid>
<title>聊聊spring事务失效的12种场景，太坑了</title>
<link>https://toutiao.io/k/uf6yk96</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong data-darkmode-bgcolor-16346154121535=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16346154121535=&quot;#fff|rgb(255, 255, 255)|rgb(255, 255, 255)&quot; data-darkmode-color-16346154121535=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16346154121535=&quot;#fff|rgb(62, 62, 62)|rgb(0, 0, 0)&quot; data-style=&quot;outline: 0px; letter-spacing: 0.544px; text-align: left; white-space: normal; color: rgb(0, 0, 0); font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif; font-size: 16px; background-color: rgb(255, 255, 255);&quot; class=&quot;js_darkmode__2&quot;&gt;点击关注公众号，Java干货&lt;/strong&gt;&lt;span data-darkmode-bgcolor-16346154121535=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16346154121535=&quot;#fff|rgb(255, 255, 255)|rgb(255, 255, 255)&quot; data-darkmode-color-16346154121535=&quot;rgb(255, 76, 65)&quot; data-darkmode-original-color-16346154121535=&quot;#fff|rgb(62, 62, 62)|rgb(255, 76, 65)&quot; data-style=&quot;outline: 0px; letter-spacing: 0.544px; text-align: left; font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif; font-size: 16px; background-color: rgb(255, 255, 255); color: rgb(255, 76, 65);&quot; class=&quot;js_darkmode__3&quot;&gt;&lt;strong data-darkmode-bgcolor-16346154121535=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16346154121535=&quot;#fff|rgb(255, 255, 255)|rgb(255, 255, 255)&quot; data-darkmode-color-16346154121535=&quot;rgb(255, 76, 65)&quot; data-darkmode-original-color-16346154121535=&quot;#fff|rgb(62, 62, 62)|rgb(255, 76, 65)&quot;&gt;及时送达👇&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU4MDUyMDQyNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/knmrNHnmCLEX3M6DvCn5gKuBOaMMVu9lUJAvwH2k66nV9VgGG0cyczd1ryib06P1z5pF72Le3HUr5loicnQx36lg/0?wx_fmt=png&quot; data-nickname=&quot;小哈学Java&quot; data-alias=&quot;xiaoha_java&quot; data-signature=&quot;专注于Java领域干货分享，不限于BAT面试, 算法，数据库，Spring Boot, 微服务,高并发, JVM, Docker容器，ELK相关知识，期待与您一同进步。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5645161290322581&quot; data-src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/knmrNHnmCLHoM2ib2hgLaZr0ruTQZDRYZlAFxVibcicZ18G3Llxx1ibOBNRVRWeex0qMOndOBUfLgh1K72Nm1G31zg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;496&quot;/&gt;&lt;span data-darkmode-bgcolor-16346154121535=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16346154121535=&quot;#fff|rgb(255, 255, 255)|rgb(255, 255, 255)&quot; data-darkmode-color-16346154121535=&quot;rgb(255, 76, 65)&quot; data-darkmode-original-color-16346154121535=&quot;#fff|rgb(62, 62, 62)|rgb(255, 76, 65)&quot; data-style=&quot;outline: 0px; letter-spacing: 0.544px; text-align: left; font-family: Optima-Regular, Optima, PingFangSC-light, PingFangTC-light, &amp;quot;PingFang SC&amp;quot;, Cambria, Cochin, Georgia, Times, &amp;quot;Times New Roman&amp;quot;, serif; font-size: 16px; background-color: rgb(255, 255, 255); color: rgb(255, 76, 65);&quot; class=&quot;js_darkmode__3&quot;&gt;&lt;strong data-darkmode-bgcolor-16346154121535=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16346154121535=&quot;#fff|rgb(255, 255, 255)|rgb(255, 255, 255)&quot; data-darkmode-color-16346154121535=&quot;rgb(255, 76, 65)&quot; data-darkmode-original-color-16346154121535=&quot;#fff|rgb(62, 62, 62)|rgb(255, 76, 65)&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;前言&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;对于从事java开发工作的同学来说，spring的事务肯定再熟悉不过了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在某些业务场景下，如果一个请求中，需要同时&lt;span&gt;写入&lt;/span&gt;多张表的数据。为了保证操作的原子性（要么同时成功，要么同时失败），避免数据不一致的情况，我们一般都会用到spring事务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;确实，spring事务用起来贼爽，就用一个简单的注解：&lt;code&gt;@Transactional&lt;/code&gt;，就能轻松搞定事务。我猜大部分小伙伴也是这样用的，而且一直用一直爽。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但如果你使用不当，它也会坑你于无形。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;今天我们就一起聊聊，事务失效的一些场景，说不定你已经中招了。不信，让我们一起看看。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9913419913419913&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/uL371281oDFI5ibhP1TXOMnqQtJhfb3XCnTbgmpiab2LDA8VVCmg2jMUoeJd70gAJsj7vL2IB0icYxsbsvnKIu9LQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1386&quot;/&gt;&lt;/figure&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;一 事务不生效&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;1.访问权限问题&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;众所周知，java的访问权限主要有四种：private、default、protected、public，它们的权限从左到右，依次变大。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但如果我们在开发过程中，把有某些事务方法，定义了错误的访问权限，就会导致事务功能出问题，例如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;UserService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;add&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;         saveData(userModel);&lt;br/&gt;         updateData(userModel);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以看到add方法的访问权限被定义成了&lt;code&gt;private&lt;/code&gt;，这样会导致事务失效，spring要求被代理方法必须是&lt;code&gt;public&lt;/code&gt;的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说白了，在&lt;code&gt;AbstractFallbackTransactionAttributeSource&lt;/code&gt;类的&lt;code&gt;computeTransactionAttribute&lt;/code&gt;方法中有个判断，如果目标方法不是public，则&lt;code&gt;TransactionAttribute&lt;/code&gt;返回null，即不支持事务。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;protected&lt;/span&gt; TransactionAttribute &lt;span&gt;computeTransactionAttribute&lt;/span&gt;&lt;span&gt;(Method method, @Nullable Class&amp;lt;?&amp;gt; targetClass)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;// Don&#x27;t allow no-public methods as required.&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (allowPublicMethodsOnly() &amp;amp;&amp;amp; !Modifier.isPublic(method.getModifiers())) {&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// The method may be on an interface, but we need attributes from the target class.&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;// If the target class is null, the method will be unchanged.&lt;/span&gt;&lt;br/&gt;    Method specificMethod = AopUtils.getMostSpecificMethod(method, targetClass);&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// First try is the method in the target class.&lt;/span&gt;&lt;br/&gt;    TransactionAttribute txAttr = findTransactionAttribute(specificMethod);&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (txAttr != &lt;span&gt;null&lt;/span&gt;) {&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; txAttr;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// Second try is the transaction attribute on the target class.&lt;/span&gt;&lt;br/&gt;    txAttr = findTransactionAttribute(specificMethod.getDeclaringClass());&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (txAttr != &lt;span&gt;null&lt;/span&gt; &amp;amp;&amp;amp; ClassUtils.isUserLevelMethod(method)) {&lt;br/&gt;      &lt;span&gt;return&lt;/span&gt; txAttr;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (specificMethod != method) {&lt;br/&gt;      &lt;span&gt;// Fallback is to look at the original method.&lt;/span&gt;&lt;br/&gt;      txAttr = findTransactionAttribute(method);&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; (txAttr != &lt;span&gt;null&lt;/span&gt;) {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; txAttr;&lt;br/&gt;      }&lt;br/&gt;      &lt;span&gt;// Last fallback is the class of the original method.&lt;/span&gt;&lt;br/&gt;      txAttr = findTransactionAttribute(method.getDeclaringClass());&lt;br/&gt;      &lt;span&gt;if&lt;/span&gt; (txAttr != &lt;span&gt;null&lt;/span&gt; &amp;amp;&amp;amp; ClassUtils.isUserLevelMethod(method)) {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; txAttr;&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;  }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;也就是说，如果我们自定义的事务方法（即目标方法），它的访问权限不是&lt;code&gt;public&lt;/code&gt;，而是private、default或protected的话，spring则不会提供事务功能。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;2. 方法用final修饰&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有时候，某个方法不想被子类重新，这时可以将该方法定义成final的。普通方法这样定义是没问题的，但如果将事务方法定义成final，例如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;UserService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;add&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt;&lt;/span&gt;{&lt;br/&gt;        saveData(userModel);&lt;br/&gt;        updateData(userModel);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以看到add方法被定义成了&lt;code&gt;final&lt;/code&gt;的，这样会导致事务失效。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你看过spring事务的源码，可能会知道spring事务底层使用了aop，也就是通过jdk动态代理或者cglib，帮我们生成了代理类，在代理类中实现的事务功能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但如果某个方法用final修饰了，那么在它的代理类中，就无法重写该方法，而添加事务功能。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;注意：如果某个方法是static的，同样无法通过动态代理，变成事务方法。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;3.方法内部调用&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有时候我们需要在某个Service类的某个方法中，调用另外一个事务方法，比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;UserService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; UserMapper userMapper;&lt;br/&gt;&lt;br/&gt;  &lt;span/&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;add&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        userMapper.insertUser(userModel);&lt;br/&gt;        updateStatus(userModel);&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;updateStatus&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        doSameThing();&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们看到在事务方法add中，直接调用事务方法updateStatus。从前面介绍的内容可以知道，updateStatus方法拥有事务的能力是因为spring aop生成代理了对象，但是这种方法直接调用了this对象的方法，所以updateStatus方法不会生成事务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由此可见，在同一个类中的方法直接内部调用，会导致事务失效。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;那么问题来了，如果有些场景，确实想在同一个类的某个方法中，调用它自己的另外一个方法，该怎么办呢？&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.1 新加一个Service方法&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这个方法非常简单，只需要新加一个Service方法，把@Transactional注解加到新Service方法上，把需要事务执行的代码移到新方法中。具体代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Servcie&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ServiceA&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;   &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;   prvate ServiceB serviceB;&lt;br/&gt;&lt;br/&gt;   &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;save&lt;/span&gt;&lt;span&gt;(User user)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;         queryData1();&lt;br/&gt;         queryData2();&lt;br/&gt;         serviceB.doSave(user);&lt;br/&gt;   }&lt;br/&gt; }&lt;br/&gt;&lt;br/&gt; &lt;span&gt;@Servcie&lt;/span&gt;&lt;br/&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ServiceB&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;(rollbackFor=Exception&lt;span&gt;.&lt;span&gt;class&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;doSave&lt;/span&gt;(&lt;span&gt;User&lt;/span&gt; &lt;span&gt;user&lt;/span&gt;) &lt;/span&gt;{&lt;br/&gt;       addData1();&lt;br/&gt;       updateData2();&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt; }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.2 在该Service类中注入自己&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果不想再新加一个Service类，在该Service类中注入自己也是一种选择。具体代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Servcie&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ServiceA&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;   &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;   prvate ServiceA serviceA;&lt;br/&gt;&lt;br/&gt;   &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;save&lt;/span&gt;&lt;span&gt;(User user)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;         queryData1();&lt;br/&gt;         queryData2();&lt;br/&gt;         serviceA.doSave(user);&lt;br/&gt;   }&lt;br/&gt;&lt;br/&gt;   &lt;span&gt;@Transactional&lt;/span&gt;(rollbackFor=Exception&lt;span&gt;.&lt;span&gt;class&lt;/span&gt;)&lt;br/&gt;   &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;doSave&lt;/span&gt;(&lt;span&gt;User&lt;/span&gt; &lt;span&gt;user&lt;/span&gt;) &lt;/span&gt;{&lt;br/&gt;       addData1();&lt;br/&gt;       updateData2();&lt;br/&gt;    }&lt;br/&gt; }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可能有些人可能会有这样的疑问：这种做法会不会出现循环依赖问题？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;答案：不会。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实spring ioc内部的三级缓存保证了它，不会出现循环依赖问题。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;3.3 通过AopContent类&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在该Service类中使用AopContext.currentProxy()获取代理对象&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的方法2确实可以解决问题，但是代码看起来并不直观，还可以通过在该Service类中使用AOPProxy获取代理对象，实现相同的功能。具体代码如下：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Servcie&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ServiceA&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;   &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;save&lt;/span&gt;&lt;span&gt;(User user)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;         queryData1();&lt;br/&gt;         queryData2();&lt;br/&gt;         ((ServiceA)AopContext.currentProxy()).doSave(user);&lt;br/&gt;   }&lt;br/&gt;&lt;br/&gt;   &lt;span&gt;@Transactional&lt;/span&gt;(rollbackFor=Exception&lt;span&gt;.&lt;span&gt;class&lt;/span&gt;)&lt;br/&gt;   &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;doSave&lt;/span&gt;(&lt;span&gt;User&lt;/span&gt; &lt;span&gt;user&lt;/span&gt;) &lt;/span&gt;{&lt;br/&gt;       addData1();&lt;br/&gt;       updateData2();&lt;br/&gt;    }&lt;br/&gt; }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;4.未被spring管理&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我们平时开发过程中，有个细节很容易被忽略。即使用spring事务的前提是：对象要被spring管理，需要创建bean实例。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通常情况下，我们通过@Controller、@Service、@Component、@Repository等注解，可以自动实现bean实例化和依赖注入的功能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果有一天，你匆匆忙忙的开发了一个Service类，但忘了加@Service注解，比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;//@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;UserService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;add&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;         saveData(userModel);&lt;br/&gt;         updateData(userModel);&lt;br/&gt;    }    &lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从上面的例子，我们可以看到UserService类没有加&lt;code&gt;@Service&lt;/code&gt;注解，那么该类不会交给spring管理，所以它的add方法也不会生成事务。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;5.多线程调用&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在实际项目开发中，多线程的使用场景还是挺多的。如果spring事务用在多线程场景中，会有问题吗？&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Slf&lt;/span&gt;4j&lt;br/&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;UserService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; UserMapper userMapper;&lt;br/&gt;    &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; RoleService roleService;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;add&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;        userMapper.insertUser(userModel);&lt;br/&gt;        &lt;span&gt;new&lt;/span&gt; Thread(() -&amp;gt; {&lt;br/&gt;            roleService.doOtherThing();&lt;br/&gt;        }).start();&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;RoleService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;doOtherThing&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;保存role表数据&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;从上面的例子中，我们可以看到事务方法add中，调用了事务方法doOtherThing，但是事务方法doOtherThing是在另外一个线程中调用的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这样会导致两个方法不在同一个线程中，获取到的数据库连接不一样，从而是两个不同的事务。如果想doOtherThing方法中抛了异常，add方法也回滚是不可能的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果看过spring事务源码的朋友，可能会知道spring的事务是通过数据库连接来实现的。当前线程中保存了一个map，key是数据源，value是数据库连接。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; ThreadLocal&amp;lt;Map&amp;lt;Object, Object&amp;gt;&amp;gt; resources =&lt;br/&gt;&lt;br/&gt;  &lt;span&gt;new&lt;/span&gt; NamedThreadLocal&amp;lt;&amp;gt;(&lt;span&gt;&quot;Transactional resources&quot;&lt;/span&gt;);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们说的同一个事务，其实是指同一个数据库连接，只有拥有同一个数据库连接才能同时提交和回滚。如果在不同的线程，拿到的数据库连接肯定是不一样的，所以是不同的事务。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;6.表不支持事务&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;周所周知，在mysql5之前，默认的数据库引擎是&lt;code&gt;myisam&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;它的好处就不用多说了：索引文件和数据文件是分开存储的，对于查多写少的单表操作，性能比innodb更好。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有些老项目中，可能还在用它。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在创建表的时候，只需要把&lt;code&gt;ENGINE&lt;/code&gt;参数设置成&lt;code&gt;MyISAM&lt;/code&gt;即可：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;CREATE TABLE `category` (&lt;br/&gt;  `id` bigint NOT NULL AUTO_INCREMENT,&lt;br/&gt;  `one_category` varchar(&lt;span&gt;20&lt;/span&gt;) COLLATE utf8mb4_bin DEFAULT NULL,&lt;br/&gt;  `two_category` varchar(&lt;span&gt;20&lt;/span&gt;) COLLATE utf8mb4_bin DEFAULT NULL,&lt;br/&gt;  `three_category` varchar(&lt;span&gt;20&lt;/span&gt;) COLLATE utf8mb4_bin DEFAULT NULL,&lt;br/&gt;  `four_category` varchar(&lt;span&gt;20&lt;/span&gt;) COLLATE utf8mb4_bin DEFAULT NULL,&lt;br/&gt;  &lt;span&gt;PRIMARY &lt;span&gt;KEY&lt;/span&gt; &lt;span&gt;(`id`)&lt;/span&gt;&lt;br/&gt;) ENGINE&lt;/span&gt;=MyISAM AUTO_INCREMENT=&lt;span&gt;4&lt;/span&gt; DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;myisam好用，但有个很致命的问题是：&lt;code&gt;不支持事务&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果只是单表操作还好，不会出现太大的问题。但如果需要跨多张表操作，由于其不支持事务，数据极有可能会出现不完整的情况。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此外，myisam还不支持行锁和外键。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以在实际业务场景中，myisam使用的并不多。在mysql5以后，myisam已经逐渐退出了历史的舞台，取而代之的是innodb。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;有时候我们在开发的过程中，发现某张表的事务一直都没有生效，那不一定是spring事务的锅，最好确认一下你使用的那张表，是否支持事务。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;7.未开启事务&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有时候，事务没有生效的根本原因是没有开启事务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你看到这句话可能会觉得好笑。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;开启事务不是一个项目中，最最最基本的功能吗？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么还会没有开启事务？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;没错，如果项目已经搭建好了，事务功能肯定是有的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但如果你是在搭建项目demo的时候，只有一张表，而这张表的事务没有生效。那么会是什么原因造成的呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当然原因有很多，但没有开启事务，这个原因极其容易被忽略。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果你使用的是springboot项目，那么你很幸运。因为springboot通过&lt;code&gt;DataSourceTransactionManagerAutoConfiguration&lt;/code&gt;类，已经默默的帮你开启了事务。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;你所要做的事情很简单，只需要配置&lt;code&gt;spring.datasource&lt;/code&gt;相关参数即可。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但如果你使用的还是传统的spring项目，则需要在applicationContext.xml文件中，手动配置事务相关参数。如果忘了配置，事务肯定是不会生效的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;具体配置如下信息：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;   &lt;br/&gt;&amp;lt;!-- 配置事务管理器 --&amp;gt; &lt;br/&gt;&amp;lt;bean &lt;span&gt;&lt;span&gt;class&lt;/span&gt;&lt;/span&gt;=&lt;span&gt;&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&lt;/span&gt; id=&lt;span&gt;&quot;transactionManager&quot;&lt;/span&gt;&amp;gt; &lt;br/&gt;    &amp;lt;property name=&lt;span&gt;&quot;dataSource&quot;&lt;/span&gt; ref=&lt;span&gt;&quot;dataSource&quot;&lt;/span&gt;&amp;gt;&amp;lt;/property&amp;gt; &lt;br/&gt;&amp;lt;/bean&amp;gt; &lt;br/&gt;&amp;lt;tx:advice id=&lt;span&gt;&quot;advice&quot;&lt;/span&gt; transaction-manager=&lt;span&gt;&quot;transactionManager&quot;&lt;/span&gt;&amp;gt; &lt;br/&gt;    &amp;lt;tx:attributes&amp;gt; &lt;br/&gt;        &amp;lt;tx:method name=&lt;span&gt;&quot;*&quot;&lt;/span&gt; propagation=&lt;span&gt;&quot;REQUIRED&quot;&lt;/span&gt;/&amp;gt;&lt;br/&gt;    &amp;lt;/tx:attributes&amp;gt; &lt;br/&gt;&amp;lt;/tx:advice&amp;gt; &lt;br/&gt;&amp;lt;!-- 用切点把事务切进去 --&amp;gt; &lt;br/&gt;&amp;lt;aop:config&amp;gt; &lt;br/&gt;    &amp;lt;aop:pointcut expression=&lt;span&gt;&quot;execution(* com.susan.*.*(..))&quot;&lt;/span&gt; id=&lt;span&gt;&quot;pointcut&quot;&lt;/span&gt;/&amp;gt; &lt;br/&gt;    &amp;lt;aop:advisor advice-ref=&lt;span&gt;&quot;advice&quot;&lt;/span&gt; pointcut-ref=&lt;span&gt;&quot;pointcut&quot;&lt;/span&gt;/&amp;gt; &lt;br/&gt;&amp;lt;/aop:config&amp;gt; &lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;默默的说一句，如果在pointcut标签中的切入点匹配规则，配错了的话，有些类的事务也不会生效。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;二 事务不回滚&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;1.错误的传播特性&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实，我们在使用&lt;code&gt;@Transactional&lt;/code&gt;注解时，是可以指定&lt;code&gt;propagation&lt;/code&gt;参数的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;该参数的作用是指定事务的传播特性，spring目前支持7种传播特性：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;REQUIRED&lt;/code&gt; 如果当前上下文中存在事务，那么加入该事务，如果不存在事务，创建一个事务，这是默认的传播属性值。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;SUPPORTS&lt;/code&gt; 如果当前上下文存在事务，则支持事务加入事务，如果不存在事务，则使用非事务的方式执行。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;MANDATORY&lt;/code&gt; 如果当前上下文中存在事务，否则抛出异常。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;REQUIRES_NEW&lt;/code&gt; 每次都会新建一个事务，并且同时将上下文中的事务挂起，执行当前新建事务完成以后，上下文事务恢复再执行。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;NOT_SUPPORTED&lt;/code&gt; 如果当前上下文中存在事务，则挂起当前事务，然后新的方法在没有事务的环境中执行。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;NEVER&lt;/code&gt; 如果当前上下文中存在事务，则抛出异常，否则在无事务环境上执行代码。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;code&gt;NESTED&lt;/code&gt; 如果当前上下文中存在事务，则嵌套事务执行，如果不存在事务，则新建事务。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果我们在手动设置propagation参数的时候，把传播特性设置错了，比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;UserService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;(propagation = Propagation.NEVER)&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;add&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        saveData(userModel);&lt;br/&gt;        updateData(userModel);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们可以看到add方法的事务传播特性定义成了Propagation.NEVER，这种类型的传播特性不支持事务，如果有事务则会抛异常。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;目前只有这三种传播特性才会创建新事务：REQUIRED，REQUIRES_NEW，NESTED。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;2.自己吞了异常&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事务不会回滚，最常见的问题是：开发者在代码中手动try...catch了异常。比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Slf&lt;/span&gt;4j&lt;br/&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;UserService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;add&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;            saveData(userModel);&lt;br/&gt;            updateData(userModel);&lt;br/&gt;        } &lt;span&gt;catch&lt;/span&gt; (Exception e) {&lt;br/&gt;            log.error(e.getMessage(), e);&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种情况下spring事务当然不会回滚，因为开发者自己捕获了异常，又没有手动抛出，换句话说就是把异常吞掉了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果想要spring事务能够正常回滚，必须抛出它能够处理的异常。如果没有抛异常，则spring认为程序是正常的。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;3.手动抛了别的异常&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;即使开发者没有手动捕获异常，但如果抛的异常不正确，spring事务也不会回滚。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Slf&lt;/span&gt;4j&lt;br/&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;UserService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;add&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;        &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;             saveData(userModel);&lt;br/&gt;             updateData(userModel);&lt;br/&gt;        } &lt;span&gt;catch&lt;/span&gt; (Exception e) {&lt;br/&gt;            log.error(e.getMessage(), e);&lt;br/&gt;            &lt;span&gt;throw&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; Exception(e);&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的这种情况，开发人员自己捕获了异常，又手动抛出了异常：Exception，事务同样不会回滚。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为spring事务，默认情况下只会回滚&lt;code&gt;RuntimeException&lt;/code&gt;（运行时异常）和&lt;code&gt;Error&lt;/code&gt;（错误），对于普通的Exception（非运行时异常），它不会回滚。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;4.自定义了回滚异常&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在使用@Transactional注解声明事务时，有时我们想自定义回滚的异常，spring也是支持的。可以通过设置&lt;code&gt;rollbackFor&lt;/code&gt;参数，来完成这个功能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但如果这个参数的值设置错了，就会引出一些莫名其妙的问题，例如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Slf&lt;/span&gt;4j&lt;br/&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;UserService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;(rollbackFor = BusinessException&lt;span&gt;.&lt;span&gt;class&lt;/span&gt;)&lt;br/&gt;    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;add&lt;/span&gt;(&lt;span&gt;UserModel&lt;/span&gt; &lt;span&gt;userModel&lt;/span&gt;) &lt;span&gt;throws&lt;/span&gt; &lt;span&gt;Exception&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;       saveData(userModel);&lt;br/&gt;       updateData(userModel);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果在执行上面这段代码，保存和更新数据时，程序报错了，抛了SqlException、DuplicateKeyException等异常。而BusinessException是我们自定义的异常，报错的异常不属于BusinessException，所以事务也不会回滚。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;即使rollbackFor有默认值，但阿里巴巴开发者规范中，还是要求开发者重新指定该参数。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这是为什么呢？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为如果使用默认值，一旦程序抛出了Exception，事务不会回滚，这会出现很大的bug。所以，建议一般情况下，将该参数设置成：Exception或Throwable。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;5.嵌套事务回滚多了&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;UserService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; UserMapper userMapper;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; RoleService roleService;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;add&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;        userMapper.insertUser(userModel);&lt;br/&gt;        roleService.doOtherThing();&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;RoleService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;(propagation = Propagation.NESTED)&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;doOtherThing&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;保存role表数据&quot;&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这种情况使用了嵌套的内部事务，原本是希望调用roleService.doOtherThing方法时，如果出现了异常，只回滚doOtherThing方法里的内容，不回滚 userMapper.insertUser里的内容，即回滚保存点。。但事实是，insertUser也回滚了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;why?&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因为doOtherThing方法出现了异常，没有手动捕获，会继续往上抛，到外层add方法的代理方法中捕获了异常。所以，这种情况是直接回滚了整个事务，不只回滚单个保存点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;怎么样才能只回滚保存点呢？&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Slf&lt;/span&gt;4j&lt;br/&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;UserService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; UserMapper userMapper;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; RoleService roleService;&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;add&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;&lt;br/&gt;        userMapper.insertUser(userModel);&lt;br/&gt;        &lt;span&gt;try&lt;/span&gt; {&lt;br/&gt;            roleService.doOtherThing();&lt;br/&gt;        } &lt;span&gt;catch&lt;/span&gt; (Exception e) {&lt;br/&gt;            log.error(e.getMessage(), e);&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可以将内部嵌套事务放在try/catch中，并且不继续往上抛异常。这样就能保证，如果内部嵌套事务中出现异常，只回滚内部事务，而不影响外部事务。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;三 其他&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;1 大事务问题&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在使用spring事务时，有个让人非常头疼的问题，就是大事务问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通常情况下，我们会在方法上&lt;code&gt;@Transactional&lt;/code&gt;注解，填加事务功能，比如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;UserService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;br/&gt;    &lt;span&gt;@Autowired&lt;/span&gt; &lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; RoleService roleService;&lt;br/&gt;    &lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;add&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;       query1();&lt;br/&gt;       query2();&lt;br/&gt;       query3();&lt;br/&gt;       roleService.save(userModel);&lt;br/&gt;       update(userModel);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;span&gt;@Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;&lt;span&gt;class&lt;/span&gt; &lt;span&gt;RoleService&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;br/&gt;    &lt;span&gt;@Autowired&lt;/span&gt; &lt;br/&gt;    &lt;span&gt;private&lt;/span&gt; RoleService roleService;&lt;br/&gt;    &lt;br/&gt;    &lt;span&gt;@Transactional&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;save&lt;/span&gt;&lt;span&gt;(UserModel userModel)&lt;/span&gt; &lt;span&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{&lt;br/&gt;       query4();&lt;br/&gt;       query5();&lt;br/&gt;       query6();&lt;br/&gt;       saveData(userModel);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;但&lt;code&gt;@Transactional&lt;/code&gt;注解，如果被加到方法上，有个缺点就是整个方法都包含在事务当中了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面的这个例子中，在UserService类中，其实只有这两行才需要事务：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;roleService.save(userModel);&lt;br/&gt;update(userModel);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在RoleService类中，只有这一行需要事务：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;saveData(userModel);&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;现在的这种写法，会导致所有的query方法也被包含在同一个事务当中。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果query方法非常多，调用层级很深，而且有部分查询方法比较耗时的话，会造成整个事务非常耗时，而从造成大事务问题。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2759259259259259&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/uL371281oDEBCPPbyDJ73OtgGneSbqS4EPv3uEv9HEcX4hevWFJGDG8gPspHNL0abAiaEvxZoGZbBIkTbBQGfHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;2.编程式事务&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面聊的这些内容都是基于&lt;code&gt;@Transactional&lt;/code&gt;注解的，主要说的是它的事务问题，我们把这种事务叫做：&lt;code&gt;声明式事务&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其实，spring还提供了另外一种创建事务的方式，即通过手动编写代码实现的事务，&lt;span&gt;我们把这种事务叫做&lt;/span&gt;：&lt;code&gt;编程式事务&lt;/code&gt;。例如：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;br/&gt;   &lt;span&gt;@Autowired&lt;/span&gt;&lt;br/&gt;   &lt;span&gt;private&lt;/span&gt; TransactionTemplate transactionTemplate;&lt;br/&gt;   &lt;br/&gt;   ...&lt;br/&gt;   &lt;br/&gt;   &lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;save&lt;/span&gt;&lt;span&gt;(&lt;span&gt;final&lt;/span&gt; User user)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;         queryData1();&lt;br/&gt;         queryData2();&lt;br/&gt;         transactionTemplate.execute((status) =&amp;gt; {&lt;br/&gt;            addData1();&lt;br/&gt;            updateData2();&lt;br/&gt;            &lt;span&gt;return&lt;/span&gt; Boolean.TRUE;&lt;br/&gt;         })&lt;br/&gt;   }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在spring中为了支持编程式事务，专门提供了一个类：TransactionTemplate，在它的execute方法中，就实现了事务的功能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;相较于&lt;code&gt;@Transactional&lt;/code&gt;注解声明式事务，我更建议大家使用，基于&lt;code&gt;TransactionTemplate&lt;/code&gt;的编程式事务。主要原因如下：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;避免由于spring aop问题，导致事务失效的问题。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;能够更小粒度的控制事务的范围，更直观。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;建议在项目中少使用@Transactional注解开启事务。但并不是说一定不能用它，如果项目中有些业务逻辑比较简单，而且不经常变动，使用@Transactional注解开启事务开启事务也无妨，因为它更简单，开发效率更高，但是千万要小心事务失效的问题。&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a9646836ccb4bfcc7eaed8d59362ee2a</guid>
<title>ApacheCN Python 译文集</title>
<link>https://toutiao.io/k/4c56kbq</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;snippet-clipboard-content position-relative overflow-auto&quot; data-snippet-clipboard-copy-content=&quot;docker pull apachecn0/apachecn-python-zh&amp;#10;docker run -tid -p &amp;lt;port&amp;gt;:80 apachecn0/apachecn-python-zh&amp;#10;# 访问 http://localhost:{port} 查看文档&quot;&gt;&lt;pre&gt;&lt;code&gt;docker pull apachecn0/apachecn-python-zh
docker run -tid -p &amp;lt;port&amp;gt;:80 apachecn0/apachecn-python-zh
# 访问 http://localhost:{port} 查看文档
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;snippet-clipboard-content position-relative overflow-auto&quot; data-snippet-clipboard-copy-content=&quot;pip install apachecn-python-zh&amp;#10;apachecn-python-zh &amp;lt;port&amp;gt;&amp;#10;# 访问 http://localhost:{port} 查看文档&quot;&gt;&lt;pre&gt;&lt;code&gt;pip install apachecn-python-zh
apachecn-python-zh &amp;lt;port&amp;gt;
# 访问 http://localhost:{port} 查看文档
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;snippet-clipboard-content position-relative overflow-auto&quot; data-snippet-clipboard-copy-content=&quot;npm install -g apachecn-python-zh&amp;#10;apachecn-python-zh &amp;lt;port&amp;gt;&amp;#10;# 访问 http://localhost:{port} 查看文档&quot;&gt;&lt;pre&gt;&lt;code&gt;npm install -g apachecn-python-zh
apachecn-python-zh &amp;lt;port&amp;gt;
# 访问 http://localhost:{port} 查看文档
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>39d3293365a212b4901a5c2a5a036f86</guid>
<title>Flink Kafka Connector 与 Exactly Once 剖析</title>
<link>https://toutiao.io/k/qjedev9</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p class=&quot;original_area_primary&quot;&gt;
                                                                                                &lt;/p&gt;

                    
                                            &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section&gt;&lt;span&gt;Flink Kafka Connector 是 Flink 内置的 Kafka 连接器，它包含了从 Kafka Topic 读入数据的 Flink Kafka Consumer 以及向 Kafka Topic 写出数据的 Flink Kafka Producer，除此之外 Flink Kafa Connector 基于 Flink Checkpoint 机制提供了完善的容错能力。本文从 Flink Kafka Connector 的基本使用到 Kafka 在 Flink 中端到端的容错原理展开讨论。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135编辑器&quot; data-id=&quot;94679&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section class=&quot;horizontal-tb&quot;&gt;&lt;p&gt;&lt;strong&gt;1.Flink Kafka 的使用&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在 Flink 中使用 Kafka Connector 时需要依赖 Kafka 的版本，Flink 针对不同的 Kafka 版本提供了对应的 Connector 实现。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135编辑器&quot; data-id=&quot;92984&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;1.1 &lt;/span&gt;&lt;span&gt;版本依赖&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;既然 Flink 对不同版本的 Kafka 有不同实现，在使用时需要注意区分，根据使用环境引入正确的依赖关系。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;output_wrapper&quot;&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;xml&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.apache.flink&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;${flink_kafka_connector_version}&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;${flink_version}&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在上面的依赖配置中 ${flink_version} 指使用 Flink 的版本，${flink_connector_kafka_version} 指依赖的 Kafka connector 版本对应的 artifactId。下表描述了截止目前为止 Kafka 服务版本与 Flink Connector 之间的对应关系。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;Flink 官网内容 Apache Kafka &lt;/span&gt;&lt;span&gt;Connector 中也有详细的说明。&lt;br/&gt;&lt;br/&gt;&lt;span/&gt;&lt;/span&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;89&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;span&gt;链接：&lt;br/&gt;&lt;/span&gt;&lt;span&gt;https://ci.apache.org/projects/flink/flink-docs-release-1.7/dev/connectors/kafka.html&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3408333333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXANBq0r47afhfsmxsOmtxZUw0NCibuiaUSK4NV1J212lvC37Crb0Wzqm5g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1200&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;从 Flink 1.7 版本开始为 Kafka 1.0.0 及以上版本提供了全新的 Kafka Connector 支持，如果使用的 Kafka 版本在 1.0.0 及以上可以忽略因 Kafka 版本差异带来的依赖变化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;1.2 &lt;/span&gt;&lt;span&gt;基本使用&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;明确了使用的 Kafka 版本后就可以编写一个基于 Flink Kafka 读/写的应用程序「本文讨论内容全部基于 Flink 1.7 版本和 Kafka 1.1.0 版本」。根据上面描述的对应关系在工程中添加 Kafka Connector 依赖。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;output_wrapper&quot;&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;xml&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.apache.flink&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;flink-connector-kafka_2.11&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;&lt;span class=&quot;code-snippet__name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.7.0&lt;span class=&quot;code-snippet__tag&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&amp;lt;/&lt;span class=&quot;code-snippet__name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面的代码片段是从 Kafka Topic「flink_kafka_poc_input」中消费数据，再写入 Kafka Topic「flink_kafka_poc_output」的简单示例。示例中除了读/写 Kafka Topic 外，没有做其他的逻辑处理。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;output_wrapper&quot;&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;typescript&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-snippet__built_in&quot;&gt;void&lt;/span&gt; main(&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt;[] args) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  Properties consumerConfig = &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; Properties();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  consumerConfig.setProperty(&lt;span class=&quot;code-snippet__string&quot;&gt;&quot;bootstrap.servers&quot;&lt;/span&gt;, &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;127.0.0.1:9091&quot;&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  consumerConfig.setProperty(&lt;span class=&quot;code-snippet__string&quot;&gt;&quot;group.id&quot;&lt;/span&gt;, &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;flink_poc_k110_consumer&quot;&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  FlinkKafkaConsumer&amp;lt;&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt;&amp;gt; flinkKafkaConsumer = &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; FlinkKafkaConsumer&amp;lt;&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt;&amp;gt;(&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;flink_kafka_poc_input&quot;&lt;/span&gt;, &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; SimpleStringSchema(), &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      consumerConfig&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    );&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  DataStream&amp;lt;&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt;&amp;gt; stream = env.addSource(flinkKafkaConsumer);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  Properties producerConfig = &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; Properties();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  producerConfig.setProperty(&lt;span class=&quot;code-snippet__string&quot;&gt;&quot;bootstrap.servers&quot;&lt;/span&gt;, &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;127.0.0.1:9091&quot;&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  FlinkKafkaProducer&amp;lt;&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt;&amp;gt; myProducer = &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; FlinkKafkaProducer&amp;lt;&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt;&amp;gt;(&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;flink_kafka_poc_output&quot;&lt;/span&gt;, &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      &lt;span class=&quot;code-snippet__keyword&quot;&gt;new&lt;/span&gt; MapSerialization(), &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;      producerConfig&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    );&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  stream.addSink(myProducer);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  env.execute();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;class&lt;/span&gt; MapSerialization &lt;span class=&quot;code-snippet__keyword&quot;&gt;implements&lt;/span&gt; SerializationSchema&amp;lt;&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt;&amp;gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; byte[] serialize(&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt; element) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; element.getBytes();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink API 使用起来确实非常简单，调用 addSource 方法和 addSink 方法就可以将初始化好的 FlinkKafkaConsumer 和 FlinkKafkaProducer 加入到流处理中。execute 执行后，KafkaConsumer 和 KafkaProducer 就可以开始正常工作了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135编辑器&quot; data-id=&quot;94679&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section class=&quot;horizontal-tb&quot;&gt;&lt;p&gt;&lt;strong&gt;2.Flink Kafka 的容错&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;众所周知，Flink 支持 Exactly-once semantics。什么意思呢？翻译过来就是「恰好一次语义」。流处理系统中，数据源源不断的流入到系统、被处理、最后输出结果。我们都不希望系统因人为或外部因素产生任何意想不到的结果。对于 Exactly-once 语义达到的目的是指即使系统被人为停止、因故障 shutdown、无故关机等任何因素停止运行状态时，对于系统中的每条数据不会被重复处理也不会少处理。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135编辑器&quot; data-id=&quot;92984&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2.1 Flink Exactly-once&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink 宣称支持 Exactly-once 其针对的是 Flink 应用内部的数据流处理。但 Flink 应用内部要想处理数据首先要有数据流入到 Flink 应用，其次 Flink 应用对数据处理完毕后也理应对数据做后续的输出。在 Flink 中数据的流入称为 Source，数据的后续输出称为 Sink，对于 Source 和 Sink 完全依靠外部系统支撑（比如 Kafka）。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink 自身是无法保证外部系统的 Exactly-once 语义。但这样一来其实并不能称为完整的 Exactly-once，或者说 Flink 并不能保证端到端 Exactly-once。而对于数据精准性要求极高的系统必须要保证端到端的 Exactly-once，所谓端到端是指 Flink 应用从 Source 一端开始到 Sink 一端结束，数据必经的起始和结束两个端点。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;那么如何实现端到端的 Exactly-once 呢？Flink 应用所依赖的外部系统需要提供 Exactly-once 支撑，并结合 Flink 提供的 Checkpoint 机制和 Two Phase Commit 才能实现 Flink 端到端的 Exactly-once。对于 Source 和 Sink 的容错保障，Flink 官方给出了具体说明：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Fault Tolerance Guarantees of Data Sources and Sinks：&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;90&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;https://ci.apache.org/projects/flink/flink-docs-release-1.7/dev/connectors/guarantees.html&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135编辑器&quot; data-id=&quot;92984&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;2.2 &lt;/span&gt;&lt;span&gt;Flink Checkpoint&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在讨论基于 Kafka 端到端的 Exactly-once 之前先简单了解一下 Flink Checkpoint。Flink Checkpoint 是 Flink 用来实现应用一致性快照的核心机制，当 Flink 因故障或其他原因重启后可以通过最后一次成功的 Checkpoint 将应用恢复到当时的状态。如果在应用中启用了 Checkpoint，会由 JobManager 按指定时间间隔触发 Checkpoint，Flink 应用内所有带状态的 Operator 会处理每一轮 Checkpoint 生命周期内的几个状态。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;由 CheckpointedFunction 接口定义。Task 启动时获取应用中所有实现了CheckpointedFunction 的 Operator，并触发执行 initializeState 方法。在方法的实现中一般都是从状态后端将快照状态恢复。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section/&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;由 CheckpointedFunction 接口定义。JobManager 会定期发起 Checkpoint，Task 接收到 Checkpoint 后获取应用中所有实现了 CheckpointedFunction 的 Operator 并触发执行对应的 snapshotState 方法。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;JobManager 每发起一轮 Checkpoint 都会携带一个自增的 checkpointId，这个 checkpointId 代表了快照的轮次。&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;output_wrapper&quot;&gt;&lt;pre&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;java&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__class&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;CheckpointedFunction&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;snapshotState(FunctionSnapshotContext context)&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;throws&lt;/span&gt; Exception&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;initializeState(FunctionInitializationContext context)&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;throws&lt;/span&gt; Exception&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;由 CheckpointListener 接口定义。当基于同一个轮次(checkpointId 相同)的Checkpoint 快照全部处理成功后获取应用中所有实现了 CheckpointListener 的 Operator 并触发执行 notifyCheckpointComplete 方法。触发 notifyCheckpointComplete 方法时携带的 checkpointId 参数用来告诉 Operator 哪一轮 Checkpoint 已经完成。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;output_wrapper&quot;&gt;&lt;pre&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;java&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-snippet__class&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;CheckpointListener&lt;/span&gt; &lt;/span&gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;  &lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;code-snippet__title&quot;&gt;notifyCheckpointComplete(&lt;span class=&quot;code-snippet__keyword&quot;&gt;long&lt;/span&gt; checkpointId)&lt;/span&gt; &lt;span class=&quot;code-snippet__keyword&quot;&gt;throws&lt;/span&gt; Exception&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135编辑器&quot; data-id=&quot;92984&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section class=&quot;horizontal-tb&quot;&gt;&lt;p&gt;&lt;strong&gt;3. Flink Kafka 端到端 Exactly-once&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Kafka 是非常受欢迎的分布式消息系统，在 Flink 中它可以作为 Source，同时也可以作为 Sink。Kafka 0.11.0 及以上版本提供了对事务的支持，这让 Flink 应用搭载 Kafka 实现端到端的 exactly-once 成为了可能。下面我们就来深入了解提供了事务支持的 Kafka 是如何与 Flink 结合实现端到端 exactly-once 的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;本文忽略了 Barrier 机制，所以示例和图中都以单线程为例。Barrier 在《Flink Checkpoint 原理》有较多讨论。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;3.1 Flink Kafka Consumer&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Kafka 自身提供了可重复消费消息的能力，Flink 结合 Kafka 的这个特性以及自身 Checkpoint 机制，得以实现 Flink Kafka Consumer 的容错。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;Flink Kafka Consumer 是 Flink 应用从 Kafka 获取数据流消息的一个实现。除了数据流获取、数据发送下游算子这些基本功能外它还提供了完善的容错机制。这些特性依赖了其内部的一些组件以及内置的数据结构协同处理完成。这里，我们先简单了解这些组件和内置数据结构的职责，再结合 &lt;strong&gt;Flink 运行时&lt;/strong&gt; 和 &lt;strong&gt;故障恢复时&lt;/strong&gt; 两个不同的处理时机来看一看它们之间是如何协同工作的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;从 Kafka 消费数据的前提是需要知道消费哪个 topic，这个 topic 有多少个 partition。组件 AbstractPartitionDiscoverer 负责获得指定 topic 的元数据信息，并将获取到的 topic 元数据信息封装成 KafkaTopicPartition 集合。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;KafkaTopicPartition 结构用于记录 topic 与 partition 的对应关系，内部定义了 String topic 和 int partition 两个主要属性。假设 topic A 有 2 个分区，通过组件 AbstractPartitionDiscoverer 处理后将得到由两个 KafkaTopicPartition 对象组成的集合：KafkaTopicPartition(topic:A, partition:0) 和 KafkaTopicPartition(topic:A, partition:1)&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;作为 Flink Source，Flink Kafka Consumer 最主要的职责就是能从 Kafka 中获取数据，交给下游处理。在 Kafka Consumer 中 AbstractFetcher 组件负责完成这部分功能。除此之外 Fetcher 还负责 offset 的提交、KafkaTopicPartitionState 结构的数据维护。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;KafkaTopicPartitionState 是一个非常核心的数据结构，基于内部的 4 个基本属性，Flink Kafka Consumer 维护了 topic、partition、已消费 offset、待提交 offset 的关联关系。Flink Kafka Consumer 的容错机制依赖了这些数据。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;除了这 4 个基本属性外 KafkaTopicPartitionState 还有两个子类，一个是支持 PunctuatedWatermark 的实现，另一个是支持 PeriodicWatermark 的实现，这两个子类在原有基础上扩展了对水印的支持，我们这里不做过多讨论。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.28833333333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXAicWqAYCqPZF4ibKlam5AOZDPHZuFlVWSD2CibxlzbjLqKBDVYwNcvgDPg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1200&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink Kafka Consumer 的容错性依靠的是状态持久化，也可以称为状态快照。对于Flink Kafka Consumer 来说，这个状态持久化具体是对 topic、partition、已消费 offset 的对应关系做持久化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;在实现中，使用 ListState&amp;lt;Tuple2&amp;lt;KafkaTopicPartition, Long &amp;gt;&amp;gt; 定义了状态存储结构，在这里 Long 表示的是 offset 类型，所以实际上就是使用 KafkaTopicPartition 和 offset 组成了一个对儿，再添加到状态后端集合。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当状态成功持久化后，一旦应用出现故障，就可以用最近持久化成功的快照恢复应用状态。在实现中，状态恢复时会将快照恢复到一个 TreeMap 结构中，其中 key 是 KafkaTopicPartition，value 是对应已消费的 offset。恢复成功后，应用恢复到故障前 Flink Kafka Consumer 消费的 offset，并继续执行任务，就好像什么都没发生一样。&lt;/span&gt;&lt;/section&gt;&lt;h5&gt;&lt;br/&gt;&lt;/h5&gt;&lt;h5&gt;&lt;strong&gt;&lt;span&gt;3.1.1 运行时&lt;/span&gt;&lt;/strong&gt;&lt;/h5&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;我们假设 Flink 应用正常运行，Flink Kafka Consumer 消费 topic 为 Topic-A，Topic-A 只有一个 partition。在运行期间，主要做了这么几件事:&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;KafkaFetcher 不断的从 Kafka 消费数据，消费的数据会发送到下游算子并在内部记录已消费过的 offset。下图描述的是 Flink Kafka Consumer 从消费 Kafka 消息到将消息发送到下游算子的一个处理过程。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.24833333333333332&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXAOHHhYBGENpPj1RMm5c9XKjtjpuI2PhH5iaItjHmpDuibqTINugr6NYAw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1200&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接下来我们再结合消息真正开始处理后，KafkaTopicPartitionState 结构中的数据变化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.24833333333333332&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXAYubKhF3g1EdzvoUiaq9X6fqzTpGfKk0TWaHjJoAOCSjFlZBAVlAqGsw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1200&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;可以看到，随着应用的运行，KafkaTopicPartitionState 中的 offset 属性值发生了变化，它记录了已经发送到下游算子消息在 Kafka 中的 offset。在这里由于消息 P0-C 已经发送到下游算子，所以 KafkaTopicPartitionState.offset 变更为 2。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果 Flink 应用开启了 Checkpoint，JobManager 会定期触发 Checkpoint。FlinkKafkaConsumer 实现了 CheckpointedFunction，所以它具备快照状态(snapshotState)的能力。在实现中，snapshotState 具体干了这么两件事。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下图描述当一轮 Checkpoint 开始时 FlinkKafkaConsumer 的处理过程。在例子中，FlinkKafkaConsumer 已经将 offset=3 的 P0-D 消息发送到下游，当checkpoint 触发时将 topic=Topic-A；partition=0；offset=3 作为最后的状态持久化到外部存储。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ol class=&quot; list-paddingleft-2&quot;/&gt;&lt;ul class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;将当前快照轮次(CheckpointId)与 topic、partition、offset 写入到一个待提交 offset 的 Map 集合，其中 key 是 CheckpointId。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;将 FlinkKafkaConsumer 当前运行状态持久化，即将 topic、partition、offset 持久化。一旦出现故障，就可以根据最新持久化的快照进行恢复。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下图描述当一轮 Checkpoint 开始时 FlinkKafkaConsumer 的处理过程。在例子中，FlinkKafkaConsumer 已经将 offset=3 的 P0-D 消息发送到下游，当 checkpoint 触发时将 topic=Topic-A；partition=0；offset=3 作为最后的状态持久化到外部存储。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4008333333333333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXAV1tDaXdMiaMibZm4jQfbRyW8hGROIzeFJyPWJ2RVSDfibibuZicCGLIoIzw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1200&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当所有算子基于同一轮次快照处理结束后，会调用 CheckpointListener.notifyCheckpointComplete(checkpointId) 通知算子 Checkpoint 完成，参数 checkpointId 指明了本次通知是基于哪一轮 Checkpoint。在 FlinkKafkaConsumer 的实现中，接到 Checkpoint 完成通知后会变更 KafkaTopicPartitionState.commitedOffset 属性值。最后再将变更后的 commitedOffset 提交到 Kafka brokers 或 Zookeeper。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在这个例子中，commitedOffset 变更为 4，因为在快照阶段，将 topic=Topic-A;partition=0;offset=3 的状态做了快照，在真正提交 offset 时是将快照的 offset + 1 作为结果提交的。「源代码 KafkaFetcher.java 207 行 doCommitInternalOffsetsToKafka 方法」。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.37416666666666665&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXAw7h911TeG7FXLA79lb3FicYIliaez3a5Tziad4TwWBmGbp4LLibuCSzEdA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1200&quot;/&gt;&lt;/section&gt;&lt;h5&gt;&lt;br/&gt;&lt;/h5&gt;&lt;h5&gt;&lt;strong&gt;&lt;span&gt;3.1.2 故障恢复&lt;/span&gt;&lt;/strong&gt;&lt;/h5&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;Flink 应用崩溃后，开始进入恢复模式。假设 Flink Kafka Consumer 最后一次成功的快照状态是 topic=Topic-A；partition=0；offset=3，在恢复期间按照下面的先后顺序执行处理。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;状态初始化阶段尝试从状态后端加载出可以用来恢复的状态。它由 CheckpointedFunction.initializeState 接口定义。在 FlinkKafkaConsumer 的实现中，从状态后端获得快照并写入到内部存储结构 TreeMap，其中 key 是由 KafkaTopicPartition 表示的 topic 与 partition，value 为 offset。下图描述的是故障恢复的第一个阶段，从状态后端获得快照，并恢复到内部存储。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2318668252080856&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXAv37VaVXibnuYuSpicRrEKmTWGpVtRwqxmAicIIIRicx96mxtlwNHJSmeqg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;841&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;function 初始化阶段除了初始化 OffsetCommitMode 和 partitionDiscoverer 外，还会初始化一个 Map 结构，该结构用来存储应用待消费信息。如果应用需要从快照恢复状态，则从待恢复状态中初始化这个 Map 结构。下图是该阶段从快照恢复的处理过程。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.43844856661045534&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXA2ypBdCN5194icJ0WcLc0D6LaaSxaDnibWqB1PCHKQtDpibCcYOaecJibRw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;593&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;function 初始化阶段兼容了正常启动和状态恢复时 offset 的初始化。对于正常启动过程，StartupMode 的设置决定待消费信息中的结果。该模式共有 5 种，默认为 StartupMode.GROUP_OFFSETS。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.37583333333333335&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXABicLJt1pZCiak7HWFIatVPbGB2rql9OfnSF4VROBn4PasXsrzvKESPAQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1200&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section/&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在该阶段中，将 KafkaFetcher 初始化、初始化内部消费状态、启动消费线程等等，其目的是为了将 FlinkKafkaConsumer 运行起来，下图描述了这个阶段的处理流程。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3441666666666667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXApzCNRvW9333ugHKI5qcaV0icAbmibibpsvO7QjRPr3gKia2JDaeQLwT0GA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1200&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这里对图中两个步骤做个描述：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;步骤 3，使用状态后端的快照结果 topic=Topic-A；partition=0；offset=3 初始化 Flink Kafka Consumer 内部维护的 Kafka 处理状态。因为是恢复流程，所以这个内部维护的处理状态也应该随着快照恢复。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;步骤 4，在真正消费 Kafka 数据前(指调用 KafkaConsumer.poll 方法)，使用Kafka 提供的 seek 方法将 offset 重置到指定位置，而这个 offset 具体算法就是状态后端 offset + 1。在例子中，消费 Kafka 数据前将 offset 重置为 4，所以状态恢复后 KafkaConsumer 是从 offset=4 位置开始消费。「源代码 KafkaConsumerThread.java 428 行」&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;3.1.3 总结&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上述的 3 个步骤是恢复期间主要的处理流程，一旦恢复逻辑执行成功，后续处理流程与正常运行期间一致。最后对 FlinkKafkaConsumer 用一句话做个总结。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;「将 offset 提交权交给 FlinkKafkaConsumer，其内部维护 Kafka 消费及提交的状态。基于 Kafka 可重复消费能力并配合 Checkpoint 机制和状态后端存储能力，就能实现 FlinkKafkaConsumer 容错性，即 Source 端的 Exactly-once 语义」。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;3.2 Flink Kafka Producer&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink Kafka Producer 是 Flink 应用向 Kafka 写出数据的一个实现。在 Kafka 0.11.0 及以上版本中提供了事务支持，这让 Flink 搭载 Kafka 的事务特性可以轻松实现 Sink 端的 Exactly-once 语义。关于 Kafka 事务特性在《Kafka 幂等与事务》中做了详细讨论。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在 Flink Kafka Producer 中，有一个非常重要的组件 FlinkKafkaInternalProducer，这个组件代理了 Kafka 客户端 org.apache.kafka.clients.producer.KafkaProducer，它为 Flink Kafka Producer 操作 Kafka 提供了强有力的支撑。在这个组件内部，除了代理方法外，还提供了一些关键操作。个人认为，Flink Kafka Sink 能够实现 Exactly-once 语义除了需要 Kafka 支持事务特性外，同时也离不开&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;FlinkKafkaInternalProducer 组件提供的支持，尤其是下面这些关键操作：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;事务重置 FlinkKafkaInternalProducer 组件中最关键的处理当属事务重置，事务重置由 resumeTransaction 方法实现「源代码 FlinkKafkaInternalProducer.java 144 行」。由于 Kafka 客户端未暴露针对事务操作的 API，所以在这个方法内部，大量的使用了反射。方法中使用反射获得 KafkaProducer 依赖的 transactionManager 对象，并将状态后端快照的属性值恢复到 transactionManager 对象中，这样以达到让 Flink Kafka Producer 应用恢复到重启前的状态。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面我们结合 &lt;strong&gt;Flink 运行时&lt;/strong&gt; 和 &lt;strong&gt;故障恢复&lt;/strong&gt; 两个不同的处理时机来了解 Flink Kafka Producer 内部如何工作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;3.2.1 运行时&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们假设 Flink 应用正常运行，Flink Kafka Producer 正常接收上游数据并写到 Topic-B 的 Topic 中，Topic-B 只有一个 partition。在运行期间，主要做以下几件事：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上游算子不断的将数据 Sink 到 FlinkKafkaProducer，FlinkKafkaProducer 接到数据后封装 ProducerRecord 对象并调用 Kafka 客户端 KafkaProducer.send 方法将 ProducerRecord 对象写入缓冲「源代码 FlinkKafkaProducer.java 616 行」。下图是该阶段的描述：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.25690276110444177&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXAFSOUNXibCibWNafFTCjagNkvcz20tr8B9Yx91xkicQG3Ohongn125SWoQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;833&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink 1.7 及以上版本使用 FlinkKafkaProducer 作为 Kafka Sink，它继承抽象类 TwoPhaseCommitSinkFunction，根据名字就能知道，这个抽象类主要实现两阶段提交。为了集成 Flink Checkpoint 机制，抽象类实现了 CheckpointedFunction 和 CheckpointListener，因此它具备快照状态(snapshotState)能力。状态快照处理具体做了下面三件事：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;调用 KafkaProducer 客户端 flush 方法，将缓冲区内全部记录发送到 Kafka，但不提交。这些记录写入到 Topic-B，此时这些数据的事务隔离级别为 UNCOMMITTED，也就是说如果有个服务消费 Topic-B，并且设置的 isolation.level=read_committed，那么此时这个消费端还无法 poll 到 flush 的数据，因为这些数据尚未 commit。什么时候 commit 呢？在快照结束处理阶段进行 commit，后面会提到。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;将快照轮次与当前事务记录到一个 Map 表示的待提交事务集合中，key 是当前快照轮次的 CheckpointId，value 是由 TransactionHolder 表示的事务对象。TransactionHolder 对象内部记录了 transactionalId、producerId、epoch 以及 Kafka 客户端 kafkaProducer 的引用。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;持久化当前事务处理状态，也就是将当前处理的事务详情存入状态后端，供应用恢复时使用。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下图是状态快照处理阶段处理过程。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.44333333333333336&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXADoFbfAcbXeESNrfB1IXicYHxeUTFibBt0gYS6hWxgwqs1fTDvgwH2RHg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1200&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;TwoPhaseCommitSinkFunction 实现了 CheckpointListener，应用中所有算子的快照处理成功后会收到基于某轮 Checkpoint 完成的通知。当 FlinkKafkaProducer 收到通知后，主要任务就是提交上一阶段产生的事务，而具体要提交哪些事务是从上一阶段生成的待提交事务集合中获取的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.31583333333333335&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXAiacQ2ufdS360EdyMbDkRyxLftUMvIY6kDdq3F3zvbDCOBoeV7Dn8qgA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1200&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;图中第 4 步执行成功后，flush 到 Kafka 的数据从 UNCOMMITTED 变更为 COMMITTED，这意味着此时消费端可以 poll 到这批数据了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2PC(两阶段提交)理论的两个阶段分别对应了 FlinkKafkaProducer 的状态快照处理阶段和快照结束处理阶段，前者是通过 Kafka 的事务初始化、事务开启、flush 等操作预提交事务，后者是通过 Kafka 的 commit 操作真正执行事务提交。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;h5&gt;&lt;strong&gt;&lt;span&gt;3.2.2 故障恢复&lt;/span&gt;&lt;/strong&gt;&lt;/h5&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;Flink 应用崩溃后，FlinkKafkaProducer 开始进入恢复模式。下图为应用崩溃前的状态描述：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4525&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXAEyQyOchnibxiawUSdMw6SjV1Tj1SDIpM2MicqWxiahBnZwmSjFwQQQTnvQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1200&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在恢复期间主要的处理在状态初始化阶段。当 Flink 任务重启时会触发状态初始化，此时应用与 Kafka 已经断开了连接。但在运行期间可能存在数据 flush 尚未提交的情况。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果想重新提交这些数据需要从状态后端恢复当时 KafkaProducer 持有的事务对象，具体一点就是恢复当时事务的 transactionalId、producerId、epoch。这个时候就用到了 FlinkKafkaInternalProducer 组件中的事务重置，在状态初始化时从状态后端获得这些事务信息，并重置到当前 KafkaProducer 中，再执行 commit 操作。这样就可以恢复任务重启前的状态，Topic-B 的消费端依然可以 poll 到应用恢复后提交的数据。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;需要注意的是：如果这个重置并提交的动作失败了，可能会造成数据丢失。下图描述的是状态初始化阶段的处理流程：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.32713347921225383&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8biaFoWLFLS3ic1JlYyUpibRk5eCqknsVXAx78dJg85GImUCQTfSyMFrAS0tIwMQwAdnAHIzRDTXWOvib5QL0ZWh9g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;914&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;3.2.3 总结&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;FlinkKafkaProducer 故障恢复期间，状态初始化是比较重要的处理阶段。这个阶段在 Kafka 事务特性的强有力支撑下，实现了事务状态的恢复，并且使得状态存储占用空间最小。依赖 Flink 提供的 TwoPhaseCommitSinkFunction 实现类，我们自己也可以对 Sink 做更多的扩展。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;# 直击 Flink Forward Europe #&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;柏林时间 10 月 8 日，Flink Forward 欧洲站盛大开启，Flink China 社区特邀 Apache Flink PMC 杨克特（鲁尼）与 Apache Kafka PMC 秦江杰（Becket）带你直击 Flink Forward 柏林站最新消息，他们将：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;第一时间跟你分享大会精彩内容&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;帮你总结大会独家干货&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;带你一起感受 Flink 发源地的开发者氛围&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section/&gt;&lt;section/&gt;&lt;section/&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;锁定今晚 19:00-20:00 ，搬好小板凳，钉钉扫码加群，&lt;span&gt;前排看直&lt;/span&gt;&lt;span&gt;播！&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;1.3193548387096774&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu48oSP5m5GR0zZWlCvNR8Or4PBEV6LGUWmQicDnSPQMQJibXDIicVVEalrTQrxMCKUMdjuC7XjVibFVPA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;620&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;hr/&gt;&lt;p&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;▼ Flink 社区推荐 &lt;span&gt;▼ &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Apache Flink 及大数据领域盛会 &lt;span&gt;Flink Forward Asia 2019 &lt;/span&gt;将于 11月28-30日在北京国家会议中心举办，&lt;strong&gt;大会议程已上线，复制下方&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;链接&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;至浏览器&lt;/strong&gt;可了解大会议程详情。&lt;br/&gt;&lt;/span&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;大会议程：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;https://developer.aliyun.com/special/ffa2019-conference&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;▼ &lt;/span&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247484366&amp;amp;idx=1&amp;amp;sn=b0ef7cb8b88f7643547e1226873d3b9d&amp;amp;chksm=fd3b8d8cca4c049a615e01d39a52057359e2de413edfcd9bb5babb99eff32acee72309099e84&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;不容错过！&lt;/a&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247484366&amp;amp;idx=1&amp;amp;sn=b0ef7cb8b88f7643547e1226873d3b9d&amp;amp;chksm=fd3b8d8cca4c049a615e01d39a52057359e2de413edfcd9bb5babb99eff32acee72309099e84&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;史上超强阵容，Flink Forward Asia &lt;span&gt;2019&lt;/span&gt; 你报名了吗？&lt;/a&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;▼ &lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247484585&amp;amp;idx=1&amp;amp;sn=8e844d2eaa8ff8ca5d08121c2f98a506&amp;amp;chksm=fd3b8aebca4c03fd9b6eb87f5466ff847a5b22efbe209afd7fa8ac430536cf0a65107468d451&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;开源、开放！大数据领域顶级盛会议题征集 ing ！&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247484585&amp;amp;idx=1&amp;amp;sn=8e844d2eaa8ff8ca5d08121c2f98a506&amp;amp;chksm=fd3b8aebca4c03fd9b6eb87f5466ff847a5b22efbe209afd7fa8ac430536cf0a65107468d451&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;▼ &lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247484459&amp;amp;idx=1&amp;amp;sn=f7bbedda08e1a2edba1f5d8a5eb1efdf&amp;amp;chksm=fd3b8a69ca4c037f2f2c1f74fae931f3d134ea3c98883c46a07d9df25244f8f1054f5e8bc05d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;经典回顾！&lt;/span&gt;&lt;/a&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247484459&amp;amp;idx=1&amp;amp;sn=f7bbedda08e1a2edba1f5d8a5eb1efdf&amp;amp;chksm=fd3b8a69ca4c037f2f2c1f74fae931f3d134ea3c98883c46a07d9df25244f8f1054f5e8bc05d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;FlinkForward China 2018 全场 PPT 大合集&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247484366&amp;amp;idx=1&amp;amp;sn=b0ef7cb8b88f7643547e1226873d3b9d&amp;amp;chksm=fd3b8d8cca4c049a615e01d39a52057359e2de413edfcd9bb5babb99eff32acee72309099e84&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-itemshowtype=&quot;0&quot; data-linktype=&quot;1&quot; hasload=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages &quot; data-ratio=&quot;0.425&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6VV9aykcW992MyapNQKf9PCONfAPI0BpN8ARPOSCqfcZDMHhOwWPrDL0yX7KGIM2SP6o0zWicYO1Q/640?wx_fmt=jpeg&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;（&lt;strong&gt;点击图片可查看 Flink Forward Asia 2019 详情&lt;/strong&gt;）&lt;/span&gt;&lt;/section&gt;&lt;section/&gt;&lt;section&gt;&lt;span&gt;你也「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;在看&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」吗？&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>