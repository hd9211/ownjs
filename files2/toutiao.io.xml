<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>48dcfbb91c22e0a952ebe9fd2660ff13</guid>
<title>看过这篇剖析，你还不懂 Go sync.Map 吗？</title>
<link>https://toutiao.io/k/x1rnpcx</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;p&gt;hi, 大家好，我是 haohongfan。&lt;/p&gt;

&lt;p&gt;本篇文章会从使用方式和源码角度剖析 sync.Map。不过不管是日常开发还是开源项目中，好像 sync.Map 并没有得到很好的利用，大家还是习惯使用 Mutex + Map  来使用。&lt;/p&gt;

&lt;p&gt;下面这段代码，看起来很有道理，其实是用错了（背景：并发场景中获取注册信息）。&lt;/p&gt;

&lt;pre lang=&quot;go&quot;&gt;&lt;code&gt;instance, ok := instanceMap[name]
if ok {
    return instance, nil
}

initLock.Lock()
defer initLock.Unlock()

// double check
instance, ok = instanceMap[name]
if ok {
    return instance, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里使用使用 sync.Map 会更合理些，因为 sync.Map 底层完全包含了这个逻辑。可能写 Java 的同学看着上面这段代码很眼熟，但确实是用错了，关于为什么用错了以及会造成什么影响，请大家关注后续的文章。&lt;/p&gt;

&lt;p&gt;我大概分析了下大家宁愿使用 Mutex + Map，也不愿使用 sync.Map 的原因：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;sync.Map 本身就很难用，使用起来并不像一个 Map。失去了 map 应有的特权语法，如：make,  map[1] 等&lt;/li&gt;
&lt;li&gt;sync.Map 方法较多。让一个简单的 Map 使用起来有了较高的学习成本。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;不管什么样的原因吧，当你读过这篇文章后，在某些特定的并发场景下，建议使用 sync.Map 代替 Map + Mutex 的。&lt;/p&gt;

&lt;h2&gt;用法全解&lt;/h2&gt;

&lt;pre lang=&quot;go&quot;&gt;&lt;code&gt;package main

import (
    &quot;fmt&quot;
    &quot;sync&quot;
)

func main() {
    var syncMap sync.Map
    syncMap.Store(&quot;11&quot;, 11)
    syncMap.Store(&quot;22&quot;, 22)

    fmt.Println(syncMap.Load(&quot;11&quot;)) // 11
    fmt.Println(syncMap.Load(&quot;33&quot;)) // 空

    fmt.Println(syncMap.LoadOrStore(&quot;33&quot;, 33)) // 33
    fmt.Println(syncMap.Load(&quot;33&quot;)) // 33
    fmt.Println(syncMap.LoadAndDelete(&quot;33&quot;)) // 33
    fmt.Println(syncMap.Load(&quot;33&quot;)) // 空

    syncMap.Range(func(key, value interface{}) bool {
        fmt.Printf(&quot;key:%v value:%v\n&quot;, key, value)
        return true
    })
    // key:22 value:22
    // key:11 value:11
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其实 sync.Map 并不复杂，只是将普通 map 的相关操作转成对应函数而已。&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th/&gt;
&lt;th&gt;普通 map&lt;/th&gt;
&lt;th&gt;sync.Map&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;map 获取某个 key&lt;/td&gt;
&lt;td&gt;map[1]&lt;/td&gt;
&lt;td&gt;sync.Load(1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;map 添加元素&lt;/td&gt;
&lt;td&gt;map[1] = 10&lt;/td&gt;
&lt;td&gt;sync.Store(1, 10)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;map 删除一个 key&lt;/td&gt;
&lt;td&gt;delete(map, 1)&lt;/td&gt;
&lt;td&gt;sync.Delete(1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;遍历 map&lt;/td&gt;
&lt;td&gt;for...range&lt;/td&gt;
&lt;td&gt;sync.Range()&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;sync.Map 两个特有的函数，不过从字面就能理解是什么意思了。
LoadOrStore：sync.Map 存在就返回，不存在就插入
LoadAndDelete：sync.Map 获取某个 key，如果存在的话，同时删除这个 key&lt;/p&gt;

&lt;h2&gt;源码解析&lt;/h2&gt;

&lt;pre lang=&quot;go&quot;&gt;&lt;code&gt;type Map struct {
    mu Mutex
    read atomic.Value // readOnly  read map
    dirty map[interface{}]*entry  // dirty map
    misses int
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e43e8e6d4d5c45e4bd583828ebe90c9a%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;sync map 全景图&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d0b2ce0bc920486684e9c8be65bd046c%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;Load&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/372873ca13694fa88db13b17f01f05e3%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;Store&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2eb152ca82e3448ba00dde977fab7ca4%7Etplv-k3u1fbpfcp-zoom-1.image&quot; alt=&quot;Delete&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;read map 的值是什么时间更新的 ？&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Load/LoadOrStore/LoadAndDelete 时，当 misses 数量大于等于 dirty map 的元素个数时，会整体复制 dirty map 到 read map&lt;/li&gt;
&lt;li&gt;Store/LoadOrStore 时，当 read map 中存在这个key，则更新&lt;/li&gt;
&lt;li&gt;Delete/LoadAndDelete 时，如果 read map 中存在这个key，则设置这个值为 nil&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;dirty map 的值是什么时间更新的 ？&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;完全是一个新 key， 第一次插入 sync.Map，必先插入 dirty map&lt;/li&gt;
&lt;li&gt;Store/LoadOrStore 时，当 read map 中不存在这个key，在 dirty map 存在这个key，则更新&lt;/li&gt;
&lt;li&gt;Delete/LoadAndDelete 时，如果 read map 中不存在这个key，在 dirty map 存在这个key，则从 dirty map 中删除这个key&lt;/li&gt;
&lt;li&gt;当 misses 数量大于等于 dirty map 的元素个数时，会整体复制 dirty map 到 read map，同时设置 dirty map 为 nil&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;疑问：当 dirty map 复制到 read map 后，将 dirty map 设置为 nil，也就是 dirty map 中就不存在这个 key 了。如果又新插入某个 key，多次访问后达到了 dirty map 往 read map 复制的条件，如果直接用 read map 覆盖 dirty map，那岂不是就丢了之前在 read map 但不在 dirty map 的 key ?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;答：其实并不会。当 dirty map 向 read map 复制后，readOnly.amended 等于了 false。当新插入了一个值时，会将 read map 中的值，重新给 dirty map 赋值一遍，也就是 read map 也会向 dirty map 中复制。&lt;/p&gt;

&lt;pre lang=&quot;go&quot;&gt;&lt;code&gt;func (m *Map) dirtyLocked() {
    if m.dirty != nil {
        return
    }

    read, _ := m.read.Load().(readOnly)
    m.dirty = make(map[interface{}]*entry, len(read.m))
    for k, e := range read.m {
        if !e.tryExpungeLocked() {
            m.dirty[k] = e
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;read map 和 dirty map 是什么时间删除的？&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;当 read map 中存在某个 key 的时候，这个时候只会删除 read map， 并不会删除 dirty map（因为 dirty map 不存在这个值）&lt;/li&gt;
&lt;li&gt;当 read map 中不存在时，才会去删除 dirty map 里面的值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;疑问：如果按照这个删除方式，那岂不是 dirty map 中会有残余的 key，导致没删除掉？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;答：其实并不会。当 misses 数量大于等于 dirty map 的元素个数时，会整体复制 dirty map 到 read map。这个过程中还附带了另外一个操作：将 dirty map 置为 nil。&lt;/p&gt;

&lt;pre lang=&quot;go&quot;&gt;&lt;code&gt;func (m *Map) missLocked() {
    m.misses++
    if m.misses &amp;lt; len(m.dirty) {
        return
    }
    m.read.Store(readOnly{m: m.dirty})
    m.dirty = nil
    m.misses = 0
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;read map 与 dirty map 的关系 ？&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;在 read map 中存在的值，在 dirty map 中可能不存在。&lt;/li&gt;
&lt;li&gt;在 dirty map 中存在的值，在 read map 中也可能存在。&lt;/li&gt;
&lt;li&gt;当访问多次，发现 dirty map 中存在，read map  中不存在，导致 misses 数量大于等于 dirty map 的元素个数时，会整体复制 dirty map 到 read map。&lt;/li&gt;
&lt;li&gt;当出现 dirty map 向 read map 复制后，dirty map 会被置成 nil。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;当出现 dirty map 向 read map 复制后，readOnly.amended 等于了 false。当新插入了一个值时，会将 read map 中的值，重新给 dirty map 赋值一遍&lt;/p&gt;

&lt;h3&gt;read/dirty map 中的值一定是有效的吗？&lt;/h3&gt;

&lt;p&gt;并不一定。放入到 read/dirty map 中的值总共有 3 种类型：&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;nil：如果获取到的 value 是 nil，那说明这个 key 是已经删除过的。既不在 read map，也不在 dirty map &lt;/li&gt;
&lt;li&gt;expunged：这个 key 在 dirty map 中是不存在的&lt;/li&gt;
&lt;li&gt;valid：其实就正常的情况，要么这个值存在在 read map 中，要么存在在 dirty map 中
## sync.Map 是如何提高性能的？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通过源码解析，我们知道 sync.Map 里面有两个普通 map，read map主要是负责读，dirty map 是负责读和写（加锁）。在读多写少的场景下，read map 的值基本不发生变化，可以让 read map 做到无锁操作，就减少了使用 Mutex + Map 必须的加锁/解锁环节，因此也就提高了性能。&lt;/p&gt;

&lt;p&gt;不过也能够看出来，read map 也是会发生变化的，如果某些 key 写操作特别频繁的话，sync.Map 基本也就退化成了 Mutex + Map（有可能性能还不如 Mutex + Map）。&lt;/p&gt;

&lt;p&gt;所以，不是说使用了 sync.Map 就一定能提高程序性能，我们日常使用中尽量注意拆分粒度来使用 sync.Map。&lt;/p&gt;

&lt;p&gt;关于如何分析 sync.Map 是否优化了程序性能，同样可以使用 pprof。具体过程可以参考 《这可能是最容易理解的 Go Mutex 源码剖析》&lt;/p&gt;

&lt;h2&gt;sync.Map 应用场景&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;读多写少&lt;/li&gt;
&lt;li&gt;写操作也多，但是修改的 key 和读取的 key 特别不重合。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;关于第二点我觉得挺扯的，毕竟我们很难把控这一点，不过由于是官方的注释还是放在这里。&lt;/p&gt;

&lt;p&gt;实际开发中我们要注意使用场景和擅用 pprof 来分析程序性能。 &lt;/p&gt;

&lt;h2&gt;sync.Map 使用注意点&lt;/h2&gt;

&lt;p&gt;和 Mutex 一样， sync.Map 也同样不能被复制，因为 atomic.Value 是不能被复制的。&lt;/p&gt;

&lt;h2&gt;参考链接&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://golang.design/under-the-hood/zh-cn/part1basic/ch05sync/map/&quot;&gt;https://golang.design/under-the-hood/zh-cn/part1basic/ch05sync/map/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://draveness.me/golang-sync-primitives/&quot;&gt;https://draveness.me/golang-sync-primitives/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/golang/go/blob/master/src/sync/map.go&quot;&gt;https://github.com/golang/go/blob/master/src/sync/map.go&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;sync.Map 完整流程图获取链接：链接:  &lt;a href=&quot;https://pan.baidu.com/s/1RIX6NKj8UhWkdFyFHptWwg&quot;&gt;https://pan.baidu.com/s/1RIX6NKj8UhWkdFyFHptWwg&lt;/a&gt;  密码: rsg9。&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>70580e71755732f09d58988d3fd7fb3c</guid>
<title>聊聊 Raft 协议</title>
<link>https://toutiao.io/k/zb7loam</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;entry-content e-content&quot; itemprop=&quot;description articleBody&quot;&gt;
&lt;pre&gt;&lt;code class=&quot;&quot;&gt;版权声明 本站原创文章 由 萌叔 发表
转载请注明 萌叔 | http://vearne.cc
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;1. 参考资料&lt;/h3&gt;

&lt;blockquote&gt;&lt;p&gt;
The original project authors have created new raft implementations now used in etcd and InfluxDB.
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;goraft/raftd&lt;/code&gt;的作者参与了&lt;code&gt;etcd&lt;/code&gt;项目的实现，所以&lt;code&gt;goraft/raftd&lt;/code&gt;是有参考价值的 。另外&lt;code&gt;goraft/raftd&lt;/code&gt;的实现不完整，没有实现&lt;code&gt;Log&lt;/code&gt;擦除等功能，因此不能用于生产环境。&lt;/p&gt;
&lt;h3&gt;2. Node的简单介绍&lt;/h3&gt;
&lt;h4&gt;2.1 node的三种状态(state)&lt;/h4&gt;
&lt;p&gt;图1 有限状态自动机&lt;br/&gt;
&lt;img src=&quot;http://ut-bucket01.sh1a.qingstor.com/woshiaotian/20210412/49c9686a-9b41-11eb-bbaa-784f43a6cab8.png&quot; alt=&quot;&quot; data-pagespeed-url-hash=&quot;4137029170&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Leader&lt;/li&gt;
&lt;li&gt;Candidate&lt;/li&gt;
&lt;li&gt;Follower&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2.2 各种存储&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;http://ut-bucket01.sh1a.qingstor.com/woshiaotian/20210412/f786b7ea-9b42-11eb-a3e6-784f43a6cab8.jpeg&quot; alt=&quot;&quot; data-pagespeed-url-hash=&quot;2223510391&quot;/&gt;&lt;br/&gt;
&lt;img src=&quot;http://ut-bucket01.sh1a.qingstor.com/woshiaotian/20210413/b49a8c16-9c0c-11eb-8f31-784f43a6cab8.jpeg&quot; alt=&quot;&quot; data-pagespeed-url-hash=&quot;640913661&quot;/&gt;&lt;/p&gt;
&lt;h5&gt;2.2.1 Write-Ahead Log（WAL）&lt;/h5&gt;
&lt;p&gt;存储:文件&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;&quot;&gt;      4f
    raft:join&quot;&amp;gt;{&quot;name&quot;:&quot;2832bfa&quot;,&quot;connectionString&quot;:&quot;http://localhost:4001&quot;}
       e
raft:nop      4f
    raft:join&quot;&amp;gt;{&quot;name&quot;:&quot;3320b68&quot;,&quot;connectionString&quot;:&quot;http://localhost:4002&quot;}
      4f
    raft:join&quot;&amp;gt;{&quot;name&quot;:&quot;7bd5bdc&quot;,&quot;connectionString&quot;:&quot;http://localhost:4003&quot;}
       e
raft:nop      29
write&quot;{&quot;key&quot;:&quot;foo&quot;,&quot;value&quot;:&quot;bar&quot;}
      29
write&quot;{&quot;key&quot;:&quot;aaa&quot;,&quot;value&quot;:&quot;bbb&quot;}
      29
write&quot;{&quot;key&quot;:&quot;bbb&quot;,&quot;value&quot;:&quot;ccc&quot;}
      29
    write&quot;{&quot;key&quot;:&quot;ddd&quot;,&quot;value&quot;:&quot;eee&quot;}
       e

raft:nop       e

       raft:nop      29

    write&quot;{&quot;key&quot;:&quot;foo&quot;,&quot;value&quot;:&quot;bar&quot;}
      29
    write&quot;{&quot;key&quot;:&quot;foo&quot;,&quot;value&quot;:&quot;bar&quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;h5&gt;2.2.2 状态信息(状态信息)&lt;/h5&gt;
&lt;p&gt;commitIndex、peer等&lt;/p&gt;
&lt;p&gt;存储:内存&amp;amp;文件&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;&quot;&gt;type server struct {
    *eventDispatcher

    name        string
    path        string
    // Leader、Follower 或者 Candidate
    state       string
    transporter Transporter
    context     interface{}
    // 代表它所感知的全局的Term情况
    currentTerm uint64

    votedFor   string
    log        *Log
    // 代表它所感知的全局的leader情况
    leader     string
    peers      map[string]*Peer
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;&quot;&gt;type Log struct {
    ApplyFunc   func(*LogEntry, Command) (interface{}, error)
    file        *os.File
    path        string
    entries     []*LogEntry
    commitIndex uint64
    mutex       sync.RWMutex
    startIndex  uint64 // the index before the first entry in the Log entries
    startTerm   uint64
    initialized bool
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;goraft&lt;/code&gt;的实现是写完Log.entries, 接着就写WAL&lt;/p&gt;
&lt;h5&gt;2.2.3 内存数据库&lt;/h5&gt;
&lt;p&gt;存储:内存&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;&quot;&gt;// The key-value database.
type DB struct {
    data  map[string]string
    mutex sync.RWMutex
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;2.3 节点之间的通讯&amp;amp;重要的名词解释&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;http://ut-bucket01.sh1a.qingstor.com/woshiaotian/20210412/e9e592e6-9b47-11eb-9d60-784f43a6cab8.png&quot; alt=&quot;&quot; data-pagespeed-url-hash=&quot;583801909&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Leader –&amp;gt; Follower&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;&quot;&gt;{
    &quot;Term&quot;: 17,
    &quot;PrevLogIndex&quot;: 26, 
    &quot;PrevLogTerm&quot;: 17,
    &quot;CommitIndex&quot;: 26,
    &quot;LeaderName&quot;: &quot;2832bfa&quot;,
    &quot;Entries&quot;: [{
        &quot;Index&quot;: 27,
        &quot;Term&quot;: 17,
        &quot;CommandName&quot;: &quot;write&quot;,
        &quot;Command&quot;: &quot;eyJrZXkiOiJhYWEiLCJ2YWx1ZSI6ImJiYiJ9Cg==&quot;
    }]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;名词解释&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Term&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CommitIndex&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LogEntry&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;3. Leader Election(选举过程)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;:不需要集群中节点的数量是奇数&lt;br/&gt;
可以是4、8个，都没关系&lt;/p&gt;
&lt;h4&gt;3.1 什么时候开始选举？&lt;/h4&gt;
&lt;h4&gt;3.2 投票相关–如何处理VoteRequest&lt;/h4&gt;
&lt;p&gt;看参考资料1.4 的演示动画&lt;br/&gt;
&lt;img src=&quot;http://ut-bucket01.sh1a.qingstor.com/woshiaotian/20210412/dcd25458-9b48-11eb-8c3e-784f43a6cab8.png&quot; alt=&quot;&quot; data-pagespeed-url-hash=&quot;1115556425&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;3.2.1 一个Term期间，最多只能投出1票&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;&quot;&gt;// VoteRequest中的Term，必须大于本地的currentTerm
    if req.Term &amp;lt; s.Term() {
        s.debugln(&quot;server.rv.deny.vote: cause stale term&quot;)
        return newRequestVoteResponse(s.currentTerm, false), false
    }

    // If the term of the request peer is larger than this node, update the term
    // If the term is equal and we&#x27;ve already voted for a different candidate then
    // don&#x27;t vote for this candidate.
// VoteRequest中的Term，如果大于本地的currentTerm，则更新本地的currentTerm
    if req.Term &amp;gt; s.Term() {
        s.updateCurrentTerm(req.Term, &quot;&quot;)
    } else if s.votedFor != &quot;&quot; &amp;amp;&amp;amp; s.votedFor != req.CandidateName {
        s.debugln(&quot;server.deny.vote: cause duplicate vote: &quot;, req.CandidateName,
            &quot; already vote for &quot;, s.votedFor)
        return newRequestVoteResponse(s.currentTerm, false), false
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;3.2.2 获得投票需要满足的条件&lt;/h4&gt;
&lt;p&gt;raft协议中这样的要求&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;
candidate’s log is at least as up-to-date as receiver’s log then vote
&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;解释起来，就是必须同时满足以下2个条件，才会给candidate投票&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;candidate.LastLogTerm &amp;gt;= receiver.LastLogTerm&lt;/li&gt;
&lt;li&gt;candidate.LastLogIndex &amp;gt;= receiver.LastLogIndex&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;: Log中有擦除情况出现，所以条件1是必须的&lt;/p&gt;
&lt;h4&gt;3.3 当选&amp;amp;当选后的一系列动作&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;获得&lt;code&gt;majority&lt;/code&gt;投票的候选人当选为&lt;code&gt;Leader&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;通过心跳压制其它&lt;code&gt;Candidate&lt;/code&gt;, 迫使其它&lt;code&gt;Candidate&lt;/code&gt;转变为&lt;code&gt;Follower&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;写入&lt;code&gt;NOPCommand&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;http://vearne.cc/archives/1851&quot;&gt;聊聊RAFT的一个实现(4)–NOPCOMMAND&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;3.4 一种极端场景&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;http://ut-bucket01.sh1a.qingstor.com/woshiaotian/20210413/b6749fc6-9bfe-11eb-8307-784f43a6cab8.jpeg&quot; alt=&quot;&quot; data-pagespeed-url-hash=&quot;3790889467&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;注意1&lt;/strong&gt;: &lt;code&gt;Node B&lt;/code&gt;和&lt;code&gt;Node D&lt;/code&gt;每个节点收到2张选票，&lt;br/&gt;
所以这一轮投票没有选出&lt;code&gt;Leader&lt;/code&gt;。 &lt;code&gt;Node B&lt;/code&gt;和 &lt;code&gt;Node D&lt;/code&gt;的状态仍为&lt;code&gt;candidate&lt;/code&gt;。一段时间后(&lt;code&gt;goraft/raftd&lt;/code&gt;的实现为electionTimeout至2倍electionTimeout之间的随机值)，他们会发起下一轮投票。详情见图1&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;注意2&lt;/strong&gt; 每轮投票&lt;code&gt;Term&lt;/code&gt;均需要加1&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;4. Log Replication(数据写入)&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://vearne.cc/archives/1510&quot;&gt;聊聊RAFT的一个实现(3)–commit&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://ut-bucket01.sh1a.qingstor.com/woshiaotian/20210412/f786b7ea-9b42-11eb-a3e6-784f43a6cab8.jpeg&quot; alt=&quot;&quot; data-pagespeed-url-hash=&quot;2223510391&quot;/&gt;&lt;br/&gt;
Step0. &lt;code&gt;Client&lt;/code&gt;发出&lt;code&gt;WriteCommand&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Step1. 先写&lt;code&gt;Leader&lt;/code&gt;的Log&lt;/p&gt;
&lt;p&gt;Step2. 在通过AppendRequest，写&lt;code&gt;Follower&lt;/code&gt;的Log&lt;/p&gt;
&lt;p&gt;Step3. 执行&lt;code&gt;Leader&lt;/code&gt;的Commit(写内存数据库)&lt;/p&gt;
&lt;p&gt;Step4. 执行&lt;code&gt;Follower&lt;/code&gt;的Commit&lt;/p&gt;
&lt;p&gt;Step5. 给&lt;code&gt;Client&lt;/code&gt;返回结果&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;注意1:&lt;/strong&gt; 写入动作，只能由&lt;code&gt;Leader&lt;/code&gt;来发起, 在&lt;code&gt;goraft/raftd&lt;/code&gt;的实现里，&lt;code&gt;Follower&lt;/code&gt;会直接拒绝执行&lt;code&gt;WriteCommand&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;注意2&lt;/strong&gt;: Step5 不需要等到Step4完全完成(收到Follower的response) 就可以开始执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;
只要client等到leader完成Commit动作。即使后续leader发生变更或部分节点崩溃，raft协议可以保证，client所提交的改动依然有效。
&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3&gt;5. 数据读取&amp;amp;watch&lt;/h3&gt;
&lt;h4&gt;5.1 默认consul有3种一致性模型&lt;/h4&gt;

&lt;p&gt;默认情况下，consul server(follower）不提供数据查询，仅转发请求给consul server(leader）&lt;br/&gt;
&lt;a href=&quot;https://www.consul.io/api/features/consistency&quot;&gt;consistency&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;其中consistent模式是强一致性的，其它两种模式都不能保证强一致性。用stale模式可以提高吞吐能力，当然数据短时间内可能会有不一致问题&lt;/p&gt;
&lt;h4&gt;5.2 &lt;code&gt;default&lt;/code&gt;和&lt;code&gt;consistent&lt;/code&gt;模式的区别&lt;/h4&gt;
&lt;h4&gt;5.3 如何使用stale模型&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;&quot;&gt;curl -v &#x27;http://dev1:8500/v1/health/service/es?dc=dc1&amp;amp;passing=1&amp;amp;stale
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;http://ut-bucket01.sh1a.qingstor.com/woshiaotian/20210412/e97f1c6a-9b64-11eb-a499-784f43a6cab8.jpeg&quot; alt=&quot;&quot; data-pagespeed-url-hash=&quot;2025687919&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;5.4 watch是怎么回事？&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;http://vearne.cc/archives/13983&quot;&gt;玩转CONSUL(1)–WATCH机制探究&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h4&gt;打赏我&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;http://static.zybuluo.com/woshiaotian/ohw8kvpn5k7hthgbuol4e4aq/WechatIMG29.jpg&quot; alt=&quot;微信支付码&quot; data-pagespeed-url-hash=&quot;2495828515&quot;/&gt;&lt;/p&gt;

&lt;p class=&quot;clear&quot;/&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4cdf12d7c48c9457ff46d94507e1f798</guid>
<title>MySQL 提升笔记（二）：存储引擎盘点</title>
<link>https://toutiao.io/k/m3yyxtk</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzkwODE5ODM0Ng==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/PMZOEonJxWeFt08hV3N1706WTzfhoTNoXm5LXRV0XibppmeNR4zSNMa3QOJJ7ib4O21P5yohibwuD26Tp9ETWZAqA/0?wx_fmt=png&quot; data-nickname=&quot;三分恶&quot; data-alias=&quot;Fighter3FullStack&quot; data-signature=&quot;一个全栈开发。分享Java后端、Web前端、计算机基础知识。&quot;/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在前面我们了解了server层调用存储引擎层接口来完成sql的执行，使用存储引擎的好处是：每个存储引擎都有各自的特点，能够根据具体的应用建立不同存储引擎表。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;需要注意的是，存储引擎是基于表的，而不是数据库&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MySQL 5.7 支持的存储引擎有 InnoDB、MyISAM、Memory、Merge、Archive、Federated、CSV、BLACKHOLE 等。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;其中最常用的3种，InnoDB、MyISAM、Memory，MySQL5.5.8以后，默认存储引擎为InnoDB。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1、常用存储引擎&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.1、InnoDB存储引擎&lt;/span&gt;&lt;span/&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;InnoDB是MySQL的默认事务型引擎，也是最重要、使用最广泛的存储引擎。特点是行锁设计，支持外键，5.6之后支持全文索引。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;InnoDB的数据存储在一个逻辑表空间（tablespace）中，表空间是由InnoDB管理的一个黑盒，由一系列的数据文件组成。在MySQL 4.1以后的版本中，InnoDB可以将每个表的数据和索引存放在单独的文件中。InnoDB也可以使用裸设备作为表空间的存储介质。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;InnoDB采用MVCC来支持高并发，并且实现了四个标准的隔离级别。其默认级别是REPEATABLE READ（可重复读），并且通过间隙锁（next-key locking）策略防止幻读的出现。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;除此之外，InnoDB存储引擎还提供了插入缓冲（insert buffer）、二次写（double write）、自适应哈希索引（adaptive hash index）、预读（read ahead）等高性能和高可用的功能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;InnoDB表是基于聚簇索引建立的，InnoDB的索引结构和MySQL的其他存储引擎有很大的不同，聚簇索引对主键查询有很高的性能。&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5051282051282051&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PMZOEonJxWdJhaVazLGBgWIqDE2z0iakrI5MkE0e0D4FQTJOnJr5HgfTrbCxWjLzHYRPLYmLiauGwHxzibmjK674A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1170&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;figcaption&gt;主键索引&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;InnoDB内部做了很多优化，包括从磁盘读取数据时采用的可预测性预读，能够自动在内存中创建hash索引以加速读操作的自适应哈希索引（adaptive hash index），以及能够加速插入操作的插入缓冲区（insert buffer）等。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.2、MyISAM存储引擎&lt;/span&gt;&lt;span/&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MyISAM存储引擎不支持事务、只支持表锁、支持全文索引。在MySQL5.5之前是MySQl默认的存储引擎。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MyISAM对整张表加锁，而不是针对行。读取时会对需要读到的所有表加共享锁，写入时则对表加排他锁。但是在表有读取查询的同时，也可以往表中插入新的记录（这被称为并发插入，CONCURRENT INSERT）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MyISAM存储引擎表是由MYD和MYI组成，MYD用来存放数据文件，MYI用来存放索引文件。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.17937219730941703&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PMZOEonJxWdJhaVazLGBgWIqDE2z0iakrOuugmaEMdTxugr9BRqtbAO4WeYXPQ2v5aNVs6EJwlw36qwAiaVLIuSA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;446&quot;/&gt;&lt;figcaption&gt;MyISAM表文件&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;MyISAM引擎设计简单，数据以紧密格式存储，所以在某些场景下的性能很好。MyISAM有一些服务器级别的性能扩展限制，比如对索引键缓冲区（key cache）的Mutex锁，MariaDB基于段（segment）的索引键缓冲区机制来避免该问题。但MyISAM最典型的性能问题还是表锁的问题，很容易导致所有的查询都长期处于“Locked”状态。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;1.3、Memory存储引擎&lt;/span&gt;&lt;span/&gt;&lt;span&gt; &lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Memory可以理解为临时表——当然二者不是一个东西。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Memory存储引擎将表中的数据存放在内存中，不需要进行磁盘I/O，速度非常快。但是如果数据库重启或者崩溃，Memory表的结构会保留，但表里的数据都会丢失。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Memroy表在很多场景可以发挥好的作用：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;用于查找（lookup）或者映射（mapping）表，例如将邮编和地名映射的表。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;用于缓存周期性聚合数据（periodically aggregated data）的结果。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;用于保存数据分析中产生的中间数据。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Memory表默认使用Hash索引，因此查找操作非常快。虽然Memory表的速度非常快，但还是无法取代传统的基于磁盘的表。Memroy表是表级锁，因此并发写入的性能较低。它不支持BLOB或TEXT类型的列，并且每行的长度是固定的，所以即使指定了VARCHAR列，实际存储时也会转换成CHAR，这可能导致部分内存的浪费（其中一些限制在Percona版本已经解决）。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果MySQL在执行查询的过程中需要使用临时表来保存中间结果，内部使用的临时表就是Memory表。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果中间结果太大超出了Memory表的限制，或者含有BLOB或TEXT字段，则临时表会转换成MyISAM表。&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;2、存储引擎对比&lt;/span&gt;&lt;span/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不同的存储引擎都有各自的特点，以适应不同的需求，如表所示。为了做出选择，首先要考虑每一个存储引擎提供了哪些不同的功能。&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;功能&lt;/th&gt;&lt;th&gt;MylSAM&lt;/th&gt;&lt;th&gt;MEMORY&lt;/th&gt;&lt;th&gt;InnoDB&lt;/th&gt;&lt;th&gt;Archive&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;存储限制&lt;/td&gt;&lt;td&gt;256TB&lt;/td&gt;&lt;td&gt;RAM&lt;/td&gt;&lt;td&gt;64TB&lt;/td&gt;&lt;td&gt;None&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;支持事务&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;支持全文索引&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;支持树索引&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;支持哈希索引&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;支持数据缓存&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;支持外键&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/section&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;InnoDB支持的哈希索引是自适应的，InnoDB会根据表的使用情况自动为表生成哈希索引，不能人为干预是否在一张表中生成哈希索引。&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;MySQL 5.6开始InnoDB支持全文索引。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;以根据以下的原则来选择 MySQL 存储引擎：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;如果要提供提交、回滚和恢复的事务安全（ACID 兼容）能力，并要求实现并发控制，InnoDB 是一个很好的选择。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果数据表主要用来插入和查询记录，则 MyISAM 引擎提供较高的处理效率。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存的 MEMORY 引擎中，MySQL 中使用该引擎作为临时表，存放查询的中间结果。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;如果只有 INSERT 和 SELECT 操作，可以选择Archive 引擎，Archive 存储引擎支持高并发的插入操作，但是本身并不是事务安全的。Archive 存储引擎非常适合存储归档数据，如记录日志信息可以使用 Archive 引擎。&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;提示&lt;/code&gt;：使用哪一种引擎要根据需要灵活选择，因为存储引擎是基于表的，所以一个数据库中多个表可以使用不同的引擎以满足各种性能和实际需求。使用合适的存储引擎将会提高整个数据库的性能。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一般MySQL的深入都是围绕InnoDB展开。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;hr data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;big&gt;&lt;strong&gt;参考：&lt;/strong&gt;&lt;/big&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;【1】：《高性能MySQL》&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;【2】：极客时间 《MySQL实战45讲》&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;【3】：《MySQL技术内幕 InnoDB存储引擎》&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;【4】：MySQL存储引擎精讲（附带各种存储引擎的对比）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;【5】：MySQL - 常用存储引擎区别总结（2020最新版）&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;系列目录：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzkwODE5ODM0Ng==&amp;amp;mid=2247485701&amp;amp;idx=1&amp;amp;sn=bb66ed8733dac01eed2585a5b88ac1ca&amp;amp;chksm=c0cce1a0f7bb68b61cdd51fe4f388ce4e3a3cb48d95e22eea75c80c366cffe3c5ef9756c0c8d&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;MYSQL提升笔记（1）：MySQL逻辑架构&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzkwODE5ODM0Ng==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/PMZOEonJxWeFt08hV3N1706WTzfhoTNoXm5LXRV0XibppmeNR4zSNMa3QOJJ7ib4O21P5yohibwuD26Tp9ETWZAqA/0?wx_fmt=png&quot; data-nickname=&quot;三分恶&quot; data-alias=&quot;Fighter3FullStack&quot; data-signature=&quot;一个全栈开发。分享Java后端、Web前端、计算机基础知识。&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;204&quot; data-backw=&quot;558&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.36484375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PMZOEonJxWdBLml8yqRnW8SzBIzu9h5RZaLdMfqqUt3mXMbX3bO0nu0FyfqotEfYm56F1xTqoqsmrQn3icGJ6Dw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;br/&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4bf0454a2462ac10a92ed701321d29c4</guid>
<title>美团酒旅数据治理实践</title>
<link>https://toutiao.io/k/6cg7b61</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一、背景&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1. 为什么要做数据治理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2. 需要治理哪些问题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3. 美团酒旅数据现状&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4. 治理目标&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;二、数据治理实践&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;1. 数据治理策略&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;2. 标准化和组织保障&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;3. 技术系统&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;4. 衡量指标&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;5. 治理效果总结&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;三、未来规划&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;四、作者简介&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;一、背景&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1. 为什么要做数据治理&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;随着移动互联网的兴起，线下商业活动逐渐开始向线上化发展，数据的产生速度有了极大的提升。越来越多的公司开始认识到数据的重要性，并将其打造成为公司的核心资产，从而驱动业务的发展。在数据相关的领域中，“数据治理”这个话题近两年尤为火热，很多公司特别是大型互联网公司都在做一些数据治理的规划和动作。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;为什么要做数据治理？因为在数据产生、采集、加工、存储、应用到销毁的全过程中，每个环节都可能会引入各种质量、效率或安全相关的问题。在公司早期的发展阶段，这些数据问题对公司发展的影响并不是很大，公司对问题的容忍度相对也比较高。但是，随着业务的发展，公司在利用数据资产创造价值的同时，对数据质量和稳定性要求也有所提升。此外，当数据积累得越来越多，公司对数据精细化运营程度的要求也随之提高，会逐渐发现有很多问题需要治理。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5526315789473685&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJa1G5ib6fbNPFmEr1Ujdhr26XAYvwkhBTv4C5FSbsjtOwic9cRjcCCOQYw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;874&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2. 需要治理哪些问题&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据治理是一项需要长期被关注的复杂工程，这项工程通过建立一个满足企业需求的数据决策体系，在数据资产管理过程中行使权力、管控和决策等活动，并涉及到组织、流程、管理制度和技术体系等多个方面。一般而言，数据治理的治理内容主要包括下面几个部分：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;质量问题&lt;/strong&gt;：这是最重要的问题，很多公司的数据部门启动数据治理的大背景就是数据质量存在问题，比如数仓的及时性、准确性、规范性，以及数据应用指标的逻辑一致性问题等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;成本问题&lt;/strong&gt;：互联网行业数据膨胀速度非常快，大型互联网公司在大数据基础设施上的成本投入占比非常高，而且随着数据量的增加，成本也将继续攀升。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;效率问题&lt;/strong&gt;：在数据开发和数据管理过程中都会遇到一些影响效率的问题，很多时候是靠“盲目”地堆人力在做。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;安全问题&lt;/strong&gt;：业务部门特别关注用户数据，一旦泄露，对业务的影响非常之大，甚至能左右整个业务的生死。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;标准问题&lt;/strong&gt;：当公司业务部门比较多的时候，各业务部门、开发团队的数据标准不一致，数据打通和整合过程中都会出现很多问题。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5405982905982906&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaawgskq8iaujiaXYhjtc8edWdXYPfldoiaOuDnqP8DKCyD1VDlgjoD5TDw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;936&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3. 美团酒旅数据现状&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2014年，美团酒旅业务成为独立的业务部门，到2018年，酒旅平台已经成为国内酒旅业务重要的在线预订平台之一。业务发展速度较快，数据增长速度也很快。在2017到2018两年里，生产任务数以每年超过一倍的速度在增长，数据量以每年两倍多的速度在增长。如果不做治理的话，根据这种接近指数级的数据增长趋势来预测，未来数据生产任务的复杂性及成本负担都会变得非常之高。在2019年初，我们面临着下面五种问题：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据质量问题严重&lt;/strong&gt;：一是数据冗余严重，从数据任务增长的速度来看，新上线任务多，下线任务少，对数据表生命周期的控制较少；二是在数据建设过程中，很多应用层数据都属于“烟囱式”建设，很多指标口径没有统一的管理规范，数据一致性无法进行保证，同名不同义、同义不同名的现象频发。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据成本增长过快&lt;/strong&gt;：某些业务线大数据存储和计算资源的机器费用占比已经超过了35%，如果不加以控制，大数据成本费用只会变得越来越高。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据运营效率低下&lt;/strong&gt;：数据使用和咨询多，数据开发工程师需要花费大量时间一对一解答业务用户的各种问题。但是这种方式对于用户来说，并没有提升数据的易用性，无法有效地积累和沉淀数据知识，还降低了研发人员的工作效率。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据安全缺乏控制&lt;/strong&gt;：各业务线之间可以共用的数据比较多，而且每个业务线没有统一的数据权限管控标准。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;开发标准规范缺失&lt;/strong&gt;：早期为快速响应业务需求，研发人员通常采用“烟囱式”的开发模式，由于缺乏相应的开发规范约束，且数据工程师的工作思路和方式差异性都非常大，导致数据仓库内的重复数据多，规范性较差。当发生数据问题时，问题的排查难度也非常大，且耗时较长。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4. 治理目标&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2019年，美团酒旅数据团队开始主动启动数据治理工作，对数据生命周期全链路进行体系化数据治理，期望保障数据的长期向好，解决数据各个链路的问题，并保持数据体系的长期稳定。具体的目标包含以下几个方面：&lt;/span&gt;&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;建立数据开发全链路的标准规范，提高数据质量，通过系统化手段管理指标口径，保障数据一致性。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;控制大数据成本，避免大数据机器成本膨胀对业务营收带来的影响，合理控制数据的生命周期，避免数据重复建设，减少数据冗余，及时归档和清理冷数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;管理数据的使用安全，建立完善的数据安全审批流程和使用规范，确保数据被合理地使用，避免因用户数据泄露带来的安全风险和商业损失。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;提高数据工程师的开发和运维效率，减少他们数据运营时间的投入，提高数据运营的自动化和系统化程度。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;二、数据治理实践&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;其实早在2018年以前，酒旅数据组就做过数据治理，当时只是从数仓建模、指标管理和应用上单点做了优化和流程规范。之后，基于上面提到的五个问题，我们又做了一个体系化的数据治理工作。下面将介绍一下美团酒旅数据团队在数据治理各个方向上的具体实践。&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1. 数据治理策略&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据治理方案需要覆盖数据生命周期的全链路，我们把数据治理的内容划分为几大部分：组织、标准规范、技术、衡量指标。整体数据治理的实现路径是以标准化的规范和组织保障为前提，通过做技术体系整体保证数据治理策略的实现。同时，搭建数据治理的衡量体系，随时观测和监控数据治理的效果，保障数据治理长期向好的方向发展。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4643196955280685&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaqbm3zibkbrrsriakHZCqDbEBiaENyvwV6fg8MjeMZqAve5kWvHNcLh5kQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1051&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2. 标准化和组织保障&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们制定了一个全链路的数据标准，从数据采集、数仓开发、指标管理到数据生命周期管理，全链路建立标准，在标准化建立过程中联合组建了业务部门的数据管理委员会。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4912109375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJarKSAVJsNXoqXAW4oamuv7hkQS024b8WV1iaSZnibniaB6DeOAO9DVVKBA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1024&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;2.1 标准化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据标准化包括三个方面：一是标准制定；二是标准执行；三是在标准制定和执行过程中的组织保障，比如怎么让标准能在数据技术部门、业务部门和相关商业分析部门达成统一。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;从标准制定上，我们制定了一套覆盖数据生产到使用全链路的数据标准方法，从数据采集、数仓开发、指标管理到数据生命周期管理都建立了相应环节的标准化的研发规范，数据从接入到消亡整个生命周期全部实现了标准化。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;2.2 组织保障&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;根据美团数据管理分散的现状，专门建立一个职能全面的治理组织去监督执行数据治理工作的成本有点太高，在推动和执行上，阻力也会比较大。所以，在组织保障上，我们建立了委员会机制，通过联合业务部门和技术部门中与数据最相关的团队成立了数据管理委员会，再通过委员会去推动相关各方去协同数据治理的相关工作。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;业务部门的数据接口团队是数据产品组，数据技术体系是由数据开发组负责建设，所以我们以这两个团队作为核心建立了业务数据管理委员会，并由这两个团队负责联合业务部门和技术部门的相关团队，一起完成数据治理各个环节工作和流程的保障。组织中各个团队的职责分工如下：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;数据管理委员会&lt;/strong&gt;：负责数据治理策略、目标、流程和标准的制定，并推动所有相关团队达成认知一致。&lt;strong&gt;业务数据产品组&lt;/strong&gt;：负责数据标准、需求对接流程、指标统一管理、数据安全控制以及业务方各部门的协调推动工作。&lt;strong&gt;技术数据开发组&lt;/strong&gt;：负责数据仓库、数据产品、数据质量、数据安全和数据工具的技术实现，以及技术团队各个部门的协调推动工作。&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3. 技术系统&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据治理涉及的范围非常广，需要协作的团队也很多，除了需要通过组织和流程来保障治理行动正常开展，我们也考虑通过技术系统化和自动化的方式进一步提效，让系统代替人工。下面我们将从数据质量、数据成本、数据安全和运营效率等几个方向，来逐一介绍技术实现方案。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1 数据质量&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据质量是影响数据价值最重要的因素，高质量的数据给带来准确的数据分析，错误的数据会把业务引导到错误的方向。数据质量涉及范围较广，在数据链路的每一个环节都有可能出现数据质量问题，酒旅业务现阶段的主要质量问题包括：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数仓规范性差，数仓架构无统一的强制规范执行约束，数仓历史冗余数据严重。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;应用层数据属于“烟囱式”建设，指标在多个任务中生产，无法保证数据的一致性。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据下游应用的数据使用无法把控，数据准确较差，接口稳定性无法得到保障。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;业务方对多个数据产品的指标逻辑无统一的定义，各个产品中数据不能直接对标。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据组的治理数据质量方案覆盖了数据生命周期的各个环节，下面将介绍一下整体的技术架构。&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;统一数仓规范建模（One Model）&lt;/strong&gt;：通过统一数仓规范建模系统化保障数仓规范执行，做到业务数仓规范标准化，并及时监控和删除重复和过期的数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;统一指标逻辑管理（One Logic）&lt;/strong&gt;：通过业务内统一的指标定义和使用，并系统化管理指标逻辑，数据应用层的数据指标逻辑都从指标管理系统中获取，保障所有产品中的指标逻辑一致。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;统一数据服务（One Service）&lt;/strong&gt;：通过建设统一的数据服务接口层，解耦数据逻辑和接口服务，当数据逻辑发生变化后不影响接口数据准确性，同时监控接口的调用，掌握数据的使用情况。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;统一用户产品入口（One Portal）&lt;/strong&gt;：分用户整合数据产品入口，使同一场景下数据逻辑和使用方式相同，用户没有数据不一致的困惑。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6632947976878613&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaIicWNbq3jQszGYIQswnibZm4Qiapw4VOxID6WKPmuCcXBB3lSDtVYtW6A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;692&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1.1 统一数仓规范建模（One Model）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在业务发展初期，数据团队集中精力在快速建设数仓来支持业务，数仓建模规范疏于管理。随着业务的发展，数仓中的数据急剧增多，数据产品和下游应用快速增加，数据工程师和数据使用方也变得越来越多，数仓的问题日益突显。业务数据仓库从初期发展到现在主要暴露了3方面的问题：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据规范性较差，不同时间的数仓规范不同，数仓规范的执行审核需要较多的人力。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据不一致问题多，同一指标在多个ETL中生产，数据更新同步也不及时。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;历史数据冗余严重，数据存储方式较多，业务方查询不知道该用哪个数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据团队主要通过数仓规范化制定、数仓分层架构和数仓规范化系统来解决上述问题，下面是我们的具体解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;制定标准-数仓规范&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;做好数仓规范化最基本的前提是要制定一系列标准化的规范，并推动组内同学执行。标准化的适用性、全面性和可执行性直接影响到规范的执行效果。数仓规范主要从3个方面制定数据标准化：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数仓建模规范，数仓建设最基础的规范，包括分层、命名、码值、指标定义、分层依赖等维度。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;主数据管理规范，数仓各个主题的数据只有一份，团队共建复用，不能重复开发。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据使用规范，在查询数据时优先查询主题层，不再提供明细层和ODS层的查询访问入口。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;工具保障-数仓规范化开发系统-Dataman&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在执行数据规范化的过程中，我们发现团队中每个人对规范的理解不一致，很可能造成数据规范不统一，审核人在审核上线任务时需要考虑规范的全部规则，审批需要投入的人力较多。在这样的流程下，数据规范性无法从根源上进行控制，因此需要建设数据规范化的工具，通过系统保障规范的一致性。数据组使用的数据层规范化工具-Dataman，主要包括3个功能模块：标准化规范、配置化开发和规则化验证。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5255102040816326&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJawbMGdoqZAMuhE47fy7QsicfcuicZqSG4MglE4miawDFShjdW8oe2FG0ZQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;980&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;标准化规范&lt;/strong&gt;：制定业务数据仓库的标准规范并配置在系统中，包括架构分层、字段管理、词根管理、公共维度和码值管理等，在ETL开发时通过统一的数仓规范开发，通过配置化实现数仓的命名、分层和码值，保障数仓长期的规范性。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.32575757575757575&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaV1U9eB8hf3GOJCZzibZicKeytBhjTbwm2AL4K94s3b6ep9oq2icdteSlQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;924&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;配置化开发&lt;/strong&gt;：系统化保障工程师在开发ETL过程中遵守数仓规范，Dataman可以用配置化的方式生成XT任务模板，模板中包含数据模型的基础信息，研发同学只需要在任务模板中开发数据生产逻辑。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.36804308797127466&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaCovGoD8smEcxeliaHXBJVZBq3fS03uBzffwDQqXnhBibIbNgYPibtECVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1114&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;规则化验证&lt;/strong&gt;：跟进数据仓库底层元数据和标准化配置信息，定期扫描数仓的规范性情况，判断出不符合数仓规范的任务和高相似度的数据表。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1.2 统一指标逻辑管理（One Logic）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;业务使用数据的第一步是搭建业务指标体系，业务的目标和策略的执行情况需要通过指标来分析，指标体系的合理性和指标数据的质量直接影响到业务决策，指标的重要性不言而喻。我们通过系统化地管理数据指标，从根源上解决指标口径一致性问题，主要从以下3个方向入手：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;指标定义规范化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;此处主要从指标的生成和管理上做好规范，确保业务同学和研发人员对指标体系管理的认知一致，确保指标的新建、更改和使用都按照规范执行。我们通过下面2个方向来实现指标定义的规范统一。&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;业务指标体系的规范化&lt;/strong&gt;：我们在业务线内统一了指标体系规范，指标分为原子指标、计算指标和复合指标，通过使用这3类指标支持业务的数据分析需求，业务未来新增指标也要按照这个标准分类。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;指标的管理规范化&lt;/strong&gt;：我们与商业分析团队一起梳理业务指标逻辑标准和录入流程，通过制定指标的新增和变更规范SOP，解决由指标管理流程引起的质量问题，使得指标定义、系统录入、指标认证和使用各个环节都有严格的流程管控，经由业务侧数据产品经理、业务侧数据治理数据管理员和数据工程师共同审批，确保标准规范的落地执行。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;指标管理系统化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;物理数据表管理&lt;/strong&gt;：数据表管理的信息主要包括表的基础元数据信息、表类型（&lt;/span&gt;&lt;span&gt;维表或事实表&lt;/span&gt;&lt;span&gt;）、表的推荐度、描述信息和样例数据等。数据表管理主要是面向数据开发同学，通过维护数据表信息，为数据模型和指标管理提供数据基础支持。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;数据模型管理&lt;/strong&gt;：是对物理数据表的模型构建，通过一个物理模型可以查询到指标和相关的维度数据。数据模型可以是星型模型或宽表，星型模型中维护多个数据表的关联方式、关联字段、维度表包含字段和模型的ER图等信息。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;指标管理&lt;/strong&gt;：主要包括2部分的内容，指标的业务信息和技术信息。&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;业务信息&lt;/strong&gt;：为了保障业务的指标信息准确且统一，指标的业务信息需要数据产品经理与商业分析团队讨论确定后录入，录入后需要指标所属数据主题的负责人审批后才能上线。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;技术信息&lt;/strong&gt;：技术信息主要包括指标对应的物理模型以及指标的计算逻辑，技术信息的填写需要数据工程师配置。技术信息配置后会在系统里生成技术元数据，指标管理系统通过技术元数据生成数据查询语句，提供给下游应用。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.7037552155771906&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJanOqxoEzkuDYb9IAdXLvEhEU54M1oBXdOQb9CRUpeq6hJKLMm9vs68g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;719&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;指标查询智能化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在指标管理系统中创建指标时，我们系统化管理了指标与数仓物理模型的关联关系和取数逻辑，通过数据物理模型获得指标对应的字段和可以关联的维度，以此把指标解析为数据查询SQL语句，通过数据查询引擎执行生产的SQL，智能化获得指标数据。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.6252390057361377&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJayItIGUtIIjGaPZzGF7RSwfzGvJ4x3O5mSSB71L1K4gmMIQxugN8mGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2092&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在查询解析过程中，经常出现指标绑定了多个底层数据表的情况，此时需要我们手动的选一个物理模型作为指标生产的底层数据。但问题是，如果一个指标对应的模型太多，每次解析都需要手动指定，研发人员不确定选择哪个模型的性能最好。另外，随着物理模型的增多，大量旧的指标配置的关联模型不是最优解，就需要手动优化更改。为了解决这个问题，指标管理系统增加了智能解析模块，在选择智能模式查询时，系统会根据指标管理模型的数据量、存储性能和查询次数等信息自动选取最优的物理模型。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1.3 统一数据服务（One Service）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据仓库对外提供数据的需求越来越多，除了管理层、分析师和产品运营同学使用数据产品和报表外，数据还需要提供到各个业务系统中使用。常用的提供数据的方式主要包括同步数据表、提供SQL和为下游服务开发定制化API接口等方式，但存在以下几个方面的问题：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据一致性无法保障，当数据指标逻辑更改时，业务系统不能及时调整，导致不同业务系统的数据不一致。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据同步到业务系统后，我们就无法管控数据的使用方式，也不能监控到数据是否被其他下游使用的情况。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据开发效率比较低，数据服务稳定性比较差，数据工程师开发一个定制化API接口需要几天时间，各个接口服务单独维护，服务稳定性也比较差。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;从2018年开始，数据BP中心与分析系统中心合作建设了统一数据API服务平台（&lt;/span&gt;&lt;span&gt;Buffalo&lt;/span&gt;&lt;span&gt;），通过开发可配置的数据接口服务平台实现数据对外的灵活提供，并实现对数据服务的下游使用及性能的可监控。统一的数据服务平台解决了几个比较关键的问题：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据逻辑统一收口&lt;/strong&gt;：数据服务接口和数据逻辑解耦，当数仓更改和数据指标逻辑变更后下游无感知。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据服务的更好管控&lt;/strong&gt;：研发同学能够了解到数据被哪些下游使用、调用了多少次和数据服务是否稳定等信息。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;开发效率大幅提升，服务稳定性大幅提高&lt;/strong&gt;：通过统一服务平台可以在1小时内完成一个接口的配置化开发，与此同时，接口稳定性统一运维，服务稳定性有了很好的保障。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4895155459146782&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJalicKP1xhnian28d93KM9lh4ywYia3gJNVXlDbamz1pWy9F9rZ4tlwAibmg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2766&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1.4 统一用户产品入口（One Portal）&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果不加控制，数据产品就会建设得越来越多。酒旅业务在2018年有超过10个数据相关产品的入口，用户很难快速地找到自己想要查的数据产品和报表。不同产品面对的用户不一样，数据的使用场景和展示方式也各不相同，业务方在使用数据时不知道从哪里能看到最全面的数据产品。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;此外，也存在因为适用场景不一样，导致面向不同用户的数据逻辑不同的情况，比如某些业务同学查看的GMV不包含民宿数据，但是商业分析团队要看的GMV是包含民宿数据的。为了能够让业务方能够在一个数据产品门户中找到更全面的数据，且这个产品门户中多个产品的数据逻辑是一致的，我们将数据门户按照使用用户和应用场景划分为3类：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;决策分析使用“大圣”（&lt;/span&gt;&lt;span&gt;美团内部的数据平台&lt;/span&gt;&lt;span&gt;），面向管理者和商业分析团队，所有业务管理者和商业分析团队成员需要的数据都可以从大圣数据产品里查看。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;业务数据查询使用“天狼” （&lt;/span&gt;&lt;span&gt;美团内部的数据平台&lt;/span&gt;&lt;span&gt;），用户主要是销售，在天狼里能查看销售所需的各种数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据资产信息查询使用“大禹”（&lt;/span&gt;&lt;span&gt;美团内部的数据平台&lt;/span&gt;&lt;span&gt;），用户是研发人员和检索数据信息的业务方，在大禹数据门户里可以找到数据资产的信息，能更快地找到想要的数据，更全面地了解相关的元数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.3431558935361217&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaKQgwsvniciaicia9F7yZwG19yIwlDpzvdibAiccApOV254rqQmTghF0s7Qug/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1052&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1.5 整体系统架构&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;整体的技术架构分为三层，从统一数据建模到统一指标逻辑、统一数据服务和统一产品入口，整体保障了数据的质量，同时配合数据管理的组织保障体系和流程规范，将整体数据质量相关的架构搭建起来。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5331632653061225&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaA9xInHW3Wx508TglNOxnzqHh7korjibNfogMse25agdibMoyBHC0E1Dg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2352&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3.2 数据运营效率&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据工程师在日常工作中的主要工作包括两大部分：数据开发和数据运营。我们在前面介绍了通过数据开发和指标管理相关的工具系统建设，开发效率得到了大幅提升。而数据运营是另一大类工作，他们的主要时间投入在数据使用咨询和数据问题答疑，大概占数据工程师日常工作5%～10%的时间。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据工程师日常投入到运营的人力多的主要原因是信息不对称和信息检索能力弱，数据团队建设了很多数据模型和数据产品，但是用户不知道怎么快速地找到和使用这些数据，问题主要体现在下面3个方面：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;找数难&lt;/strong&gt;：所需要的数据有没有？在哪里能找到？&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;看不懂&lt;/strong&gt;：数据仓库是以数据表和报表等方式提供，数据的逻辑和含义不够清晰易懂。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;不会用&lt;/strong&gt;：数据指标的查询逻辑是什么？多个表怎么关联使用？&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3.2.1 方案思路&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据团队通过数据资产信息的系统化的方式建设易用的数据检索产品，帮助用户更快捷、更方便地找到数据，并指导用户正确地使用数据，提高数据信息的易用性，以此减少数据工程师的数据答疑和运维时间。实现策略是通过用户的问题分类，通过数据信息系统化的方式分类解答80%的问题，最后少量的问题透传到研发人员再进行人工答疑。系统化方式主要分两层，数据使用智能和数据答疑机器人。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.42527472527472526&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJarH12tffHJaeSNDccUq1AUERV60oagrqSicAZhlt3HCRDrgKkFCdgjicA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;910&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3.2.2 数据使用指南系统&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据使用指南的定位是业务数据信息的知识白皮书，提供最新、最全、最准确的指标口径、项目指标体系、数据表用法等信息，以简洁、流畅的操作支持数据指南中的内容及时更新，降低业务方的数据答疑和数据使用成本。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据使用指南通过把业务场景和数据使用场景打通，从业务场景分析到使用到的数据表、指标和数据产品打通，在系统中能够快速找到数据表、指标定义、数据查询SQL、指标所在数据产品等信息，一站式解决数据查找、使用和分析的全部场景。主要功能包括指标信息和数据表信息及使用。&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;指标信息&lt;/strong&gt;：包括业务分类指标和指标的详细信息，在指标详细信息页面可以查看指标定义、指标使用场景、指标统计维度、指标对应数据表、指标所在数据产品和指标的SQL查询示例等信息，把指标信息与数据表和数据产品关联，方便用户快速根据指标信息查找到数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据表信息及使用方式&lt;/strong&gt;：包括数据表的基础信息、表的使用推荐度、SQL查询样例、数据更新时间和数据就绪时间等信息，帮助使用者快速定位需要的数据表和数据SQL的查询使用。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4792079207920792&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaQHxrdKAia0rhTbo9p7sWt5XicJQtfTjJ2qNpenRk1Yg9YblIlVIkbQfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1010&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3.2.3 数据答疑机器人&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;用户在使用数据时，经常咨询数据工程师一些问题，比如想找的数据在哪个表？指标怎么取？业务系统的一个字段怎么在数仓里面取到？很多问题会被重复问到，每次解答都需要研发人员花费一定的时间，而通过Wiki的方式维护效果较差，于是我们考虑用自动化答疑的方式，把数据工程师在日常答疑过程中积累问题和答案，通过一定的规则匹配，当再次被问到时系统可以自动地给出解答。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;使用日常答疑中积累的咨询问题和答案作为基础答疑知识库，数据答疑机器人使用美团AI平台的摩西机器人搭建，配合问题答疑的策略，实现对历史已有问题和答案通过搜索匹配后发送给用户，具体实现方式如下：&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.45569620253164556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaVqVlpiap9icLMngyuQ4xcibGFClCqnQz9Qdre4BJgCbOzdAicmTGDSg5eA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;948&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3.3 数据成本&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;大数据的主要成本构成有3大部分，计算资源、存储资源和日志采集资源，其中计算资源和存储占总成本超过90%，我们的数据成本治理主要是针对大数据计算和存储这两个部分。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-cropselx1=&quot;0&quot; data-cropselx2=&quot;521&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;254&quot; data-ratio=&quot;0.4822076978939724&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaqlPWic7mticAWbPF1LFgdHhjawn4h1n53UzSvichRdibgoJKIOicaia6EZMw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2754&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;大数据成本优化方案&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;计算资源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;无效任务清理，通过任务生产出来数据的使用情况判断是否为无效任务，通过下线无效任务，减少任务执行使用的计算资源。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;超长任务优化，经过任务的计算资源使用数据可以发现，某几个大任务在执行时会占用大部分的计算资源，导致其他任务执行时间变长，或者占用配置外的弹性计算资源，导致计算成本增加。数据组会统计和监控每天任务的执行情况，发现执行时间长（&lt;/span&gt;&lt;span&gt;超过2个小时&lt;/span&gt;&lt;span&gt;）或者占用资源多的任务会及时进行优化。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;分散利用计算资源，数仓的夜间批处理任务使用计算资源的实际一般都集中在早晨2点到上午10点前，这就导致在一天中只有三分之一的资源被充分利用，而且这段时间内通常资源都是不够用的，需要使用平台提供的配置外弹性资源。而其他时间段的计算资源闲置，对资源有较大的浪费。为了把全天的资源都有效地利用起来，我们会把一些对就绪时间不敏感的任务（&lt;/span&gt;&lt;span&gt;比如算法挖掘、用户标签、数据回刷等&lt;/span&gt;&lt;span&gt;）放到10点之后，把配置的计算资源充分利用起来。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;租户拆分和整合统一管理，提高资源池总量和资源总体的使用率。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;存储资源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数仓架构优化和重构：通过统一数仓建模规范，把相似或相同模型进行整合和去重，确保每个主题数据只保留一份。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据存储压缩：在数据仓库建设初期，很多Hive表的存储格式是txt，通过压缩为ORC格式可以减少大量的存储空间。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;冷数据处理：把数据分为冷、热两大类数据，通过每天对全部数仓表扫描识别出冷数据，发给数据负责人及时处理。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据生命周期控制：按照数仓分层的应用场景配置数据的生命周期，明细数仓层保留的全部历史数据，主题层保留5年数据，应用层保留1～3年数据。通过数据生命周期控制，极大地减少了数据存储成本。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;日志采集资源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;下线冷数据的上游日志数据收集任务，数据收集费用主要来自两类数据，业务系统数据库的Log同步和后台日志数据收集，通过对收集数据的使用情况监控，及时下线下游无应用的数据收集任务。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;3.4 数据安全&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据资产对业务来说既是价值，也是风险。数据安全作为业务部门“事关生死”的核心工作，在技术架构上会从数据产生到数据应用各个环节进行控制，保障数据应用事前有控制、事中有监控和事后有审计。数据安全控制从业务系统开始对用户高敏感数据加密，在数仓进行分级和脱敏，在应用层做密文数据权限和密钥权限的双重保障，管控用户相关的高敏感数据，按照三层系统控制加五个使用原则实现如下：&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.48810656517602286&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaPnhbV5IPEboOmRrJMx0HfQSWQFwmKTPBIiavyib37It2oHEic6kicib7p3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1051&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;4. 衡量指标&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;业务部门在业务发展初级就会建立指标体系，并使用数据指标对各个业务过程做精细化的分析，衡量业务目标的达成情况和行动的执行程度。数据治理也需要一套成熟稳定的衡量指标体系，对数据体系做到长期、稳定和可量化的衡量。我们通过制定体系化的数据衡量指标体系，来及时监测数据治理过程中哪些部分做的好，哪些部分还有问题。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;4.1 衡量指标建设&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;为了能够不重不漏地把指标都建立起来，我们从2个方面进行考虑：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;技术分类，按照数据团队关注的问题和目标，把数据治理的指标体系分成质量、成本、安全、易用性和效率这5大类。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据流环节，分别从数据的采集、生产、存储、指标管理、应用和销毁等环节监控关注的指标。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5178217821782178&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaxkut0f2ww4BhejLqf8F45xdices6xtoibt1ROU5PryFWP9h98tp6GpzQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1010&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;4.2 衡量指标保障数据治理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;根据PDCA原则，将数据治理作为日常的运营项目做起来，底层依赖数据指标体系进行监控，之上从发现问题到提出优化方案，然后跟进处理，再到日常监控，构成一个完整的循环。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5309734513274337&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJaibMoqur8ItxRWQ3AdL0OHPm7oEdJaqDAiaBibQkdCQ2QmicgUJyZv4yWMA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;904&quot;/&gt;&lt;/figure&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;5. 治理效果总结&lt;/span&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据治理覆盖了数据生命周期全链路，通过围绕数据从产生到价值消亡全部生命周期，建立数据治理组织、制定治理衡量体系和建设治理技术系统来达到数据治理目标。经过体系化的数据治理，数据系统的治理、成本、安全和运营效率都有了比较大的改善。&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据质量&lt;/strong&gt;：技术架构优化后，通过标准化规范和系统保障数据的准确性，并在治理过程中清除和整合了历史冗余数据，数据质量问题有很大的改善。2019年数据生产任务的增长率比2018年减少了60%左右。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据成本&lt;/strong&gt;：经过数据成本优化后，在支持2019年酒旅业务高速增长的同时，大数据的单均成本费用降低了40%左右。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;数据安全&lt;/strong&gt;：通过业务系统数据加密和数据仓库数据脱敏，双重保障高敏感数据安全，避免数据泄露。通过数据安全规范和数据敏感性的宣导，加强业务同学的数据安全意识，业务没有严重数据安全问题的发生。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;运营效率&lt;/strong&gt;：运营工具化减少了研发同学超过60%的日常答疑时间，极大地减少了研发同学工作被打扰的次数，提高了开发效率。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;三、未来规划&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;数据治理分为三个大阶段：被动治理、主动治理、自动治理。&lt;/span&gt;&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4414945919370698&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsUK4CicDkapoJgwhBsBgQFJa5UyM1lt2hnuFAO2VjlCxy0BjY5s5q8AdYqbIqTIQofA2Olpciccic0og/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1017&quot;/&gt;&lt;/figure&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第一阶段我们做的是&lt;strong&gt;被动治理&lt;/strong&gt;，也就是阶段性治理，确少统筹考虑，主要是基于单个问题的治理，而且治理之后过一段时间可能还要做重复治理。这个阶段更多是人治，一个项目成立，协调几个人按照项目制完成，没有体系规划，也没有组织保障。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二阶段是&lt;strong&gt;主动治理&lt;/strong&gt;，有长期的统筹规划，能覆盖到数据生命周期的各个链路，在治理过程中把一些手段和经验流程化、标准化、系统化，长期解决一些数据问题，让数据治理长期可控。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第三阶段是&lt;strong&gt;自动治理&lt;/strong&gt;，也是智能治理，在长期规划和数据生命周期各环节链路确定好之后，把已经有的经验、流程和标准做成策略。一旦出现问题，自动监控，通过一些系统化的方式解决。自动治理的第一步还是治理方案的落地和策略化，这非常依赖于元数据，把数据治理各个过程中的一些经验技术都沉淀起来。做完策略沉淀之后做自动化，把策略用工具的方式实现，当系统发现数据有问题时，自动就去处理。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;目前，美团酒旅业务数据治理处在第二阶段和第三阶段之间，虽然有整体治理计划、技术架构和组织保障，但仍需要投入一定的人力去做。未来，数据治理会继续朝着智能化的方向进行探索，真正把自动化治理工作做得更好。&lt;/span&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;四、作者简介&lt;/span&gt;&lt;/h2&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;建舒，2015年加入美团，数据科学与平台部数据工程师。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;王磊，2017年加入美团，数据科学与平台部数据工程师。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;罗茜，2017年加入美团，数据科学与平台部数据产品经理。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>ae8f81c3b1d6e7802de92cc9493e238c</guid>
<title>好代码实践：基于 Redis 的轻量级分布式均衡消费队列</title>
<link>https://toutiao.io/k/mg4sote</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/Z6bicxIx5naKCBHZSLXXMiaicElAGWfOX2G4hiasoMhOpicpX3nKQm41pfJXKicZ3wNpFh7coG67qv1Niajh9yTdvlOmg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1000&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;一  我对好代码的看法&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1  什么是好代码&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果你读过《设计模式之美》，你可能会觉得玩转各种设计模式，符合设计模式的6大基本原则的代码就是好代码；如果读过《clean code》，你可能会觉得好代码的一个标准是——整洁；如果你经常研读Spring源码，你可能会觉得精妙的设计、高度的抽象、灵活的配置才是好代码，就像是一本书，一千个读者眼中有一千个哈姆雷特，每个人按照自己的认知都会有自己的判断。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2  我认为的好代码&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如前文所述，不同的人对好代码的认知标准是不同的，我认为的好代码，也局限于我的认知水平，也许今天我觉得是好代码，随着认知的提升，改天也会有不同的想法；就目前的认知而言，我认为的好代码的一些特点：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;可用性&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;对，你没看错，好代码，一定是可用的，可以work的，如果一段代码只是看着好看，用了各种花里胡哨的编码技巧、手法，但是不能work，那就失去了它存在的意义了。所以，好代码，最最最重要的一个特点就是可用性。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;可读性&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我认为好代码的第二个特点就是可读性，我们的写代码的目标用户有两类，第一类是给编译器看的；第二类是给维护它的程序员看的。针对第一类用户，只要你符合它的语法规范，它就认识，它就可以执行；而第二类用户，就是后期不断的维护它、升级它的程序员同学，如果这段代码，维护它的人都读不懂，那他的长期存在的意义也就不大了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;其他优秀的特点&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;可维护性、可扩展性、可复用性、强鲁棒性、可测试性等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;好代码的其他优秀特点太多了，不一一列举了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3  让code在计算机上起舞&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;回到根源，我们写代码的目的是干嘛？为的是把我们的所思所想通过计算机认识的指令告诉它，让它来替我们做我们想做的事情。好代码，不仅可以简单地完成我们的所思所想，更能够快速、高效、完备地执行。让我们的code一起在计算机上起舞吧。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;二  我们为什么要做&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2020年五一期间，当大家都在享受五一假期的快乐时光时，我们突然收到hbase报警，整个hbase的IO压力已经接近瓶颈，直接影响数据读写，临时扩容hbase才勉强支撑过去。按照这个发展趋势，一旦遇到业务高峰时，hbase的读写直接会给整个业务链路带来瓶颈问题。为了能够解决海量巴枪数据实时写入hbase+solr时产生的高IO压力，我们设计出一款基于redis实现的轻量级分布式均衡消费队列，实现巴枪数据按照一定规则进行sharding到不同的队列中，实现批量数据攒批去重，然后按批写入hbase+solr，从而降低hbase+solr的IO压力。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;三  我们怎么做的&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;组件整体设计思路：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img data-ratio=&quot;0.5888268156424581&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naKCBHZSLXXMiaicElAGWfOX2GvNKRnh0tYx38ppcFZCoDX54DM7Yr0cQZ35xf1MxWzwVERsxibiask9yQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;895&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;整个组件主要分为三大核心模块，master（主节点）、writer（数据写入节点）、worker（工作节点）。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;设计机制：&lt;/span&gt;&lt;span&gt;弱中心机制，任何一个配置好的节点都可能成为master（主节点）、writer（数据写入节点）、worker（工作节点），具备高可用能力，不存在单机单点瓶颈问题。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;master（主节点）职责：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;writer（数据写入节点）职责：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;worker（工作节点）职责：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote&gt;&lt;p&gt;伟大的linux大神曾说过，&quot;Talk is cheap，让我看看代码&quot;。&lt;/p&gt;&lt;/blockquote&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;四  我们做了什么&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1  整个组件的包结构图&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img data-ratio=&quot;0.5683576956147893&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naKCBHZSLXXMiaicElAGWfOX2Gu3ZHqbux1x67ic9WYTqh93ZONk9wE6yFGUyul2v2PwBSIx8nbGs10dg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2326&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2  简洁的代码结构&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.68828125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naKCBHZSLXXMiaicElAGWfOX2G4qrpQgGtYLibL671ibNccBtFicJgCaskgDqM5BXtp7FlOkPN5hjKDkHyg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;整个工程一共60个类，核心代码共1623行， 平均每个类的代码行数为27.05行，最大的一个类代码行数不超过200行。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3  强大的扩展性&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.52109375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naKib8LgguCoe5AXMNDYPvZ2Nd8qR4alWoKllFdjfpDlgvYDLBtCnkX5nEYChATCIVwpAsaJUrhMxxQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;通过钩子回调方式的设计，方便接入的用户能够快速的注入自己的回调实现方法，进行快速扩展业务能力。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;4  线上日志展示截图&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;日志文件&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img data-ratio=&quot;0.1388888888888889&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naKCBHZSLXXMiaicElAGWfOX2G9VP0oTRn8DnsNiaF2VibMorJcX7jcO7HGOqHlmv6XMaALnTUluniaex2Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1224&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img data-ratio=&quot;0.27521008403361347&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naKCBHZSLXXMiaicElAGWfOX2Gwf6t96vv1icBAn9CBNniak0lXRZfUYiaibIWhbiaOYhIH04c55ibkAU6f1bQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1904&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;master队列分配日志&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.30859375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naKCBHZSLXXMiaicElAGWfOX2GuZQoPR8f7w4f0Ribce4b6cyeicoo4rryJss4kaf8RCZVia32eJrVF8YicQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;worker数据消费日志&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.2515625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naKCBHZSLXXMiaicElAGWfOX2GIE3sDpYccb3eFYhUmCZcSVAPsQaYMNMYUvb20P1RuXVRldQFYicgr9w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;writer队列负载检测日志&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.190625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naKCBHZSLXXMiaicElAGWfOX2GxWSIKSYPJ43LJaVx0GH2nAa3c0q71hbO1gvibDFBhlubtV6PtFuYnOw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;re&lt;/span&gt;&lt;span&gt;dis消费队列监控大盘&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.496875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naKCBHZSLXXMiaicElAGWfOX2GzX8RXw3ib6cxQhhSrwUPKVibVMwAF3LL3uicr4EEzZy24zH5WZFQcPH2w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;五  我们的收益&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;组件部署上线之时，hbase服务端监控指标变化，实现hbase整体使用水位接近50%的优化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;hbase IOPS使用监控&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.48046875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naKCBHZSLXXMiaicElAGWfOX2GtJcTzN0x5PtZaTfYlYsXJicMqtAMmQTH4T2ib2Aicz8zqoeGMW9eQRic6Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;hbase CPU使用监控&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4984375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Z6bicxIx5naKCBHZSLXXMiaicElAGWfOX2GibeCSKXethzq28Vwa0vOiaLF2FapoGicNIdXHuvEhojpo5U5OEiaWbqibOw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;六  我们的展望&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;七  我的一些理解&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;好代码，给人第一个印象的感觉，就像一篇好文章一样，读起来朗朗上口。不同的文章有不同的风格体裁，不同的代码也有不同的编程风格要求。Python有严格的缩进，像诗歌一样工整对仗；C语言面向过程像散文一样形散神聚，意境深邃；Java语言面向对象又像是写小说一样，能勾勒出一个一个人物形象。但是无论哪一种文章体裁，他的可读性和可理解性都非常重要，只有文章是可读的可理解的，才会吸引更多的读者去读它，让他流传下去，代码也一样，它的可维护性和可读性也非常重要，保证代码可用性，提高代码的简洁程度和可维护程度，才能让我们的代码在计算机上跑的更远，更久。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;技术公开课&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《使用Redis消息队列完成秒杀过期订单处理》&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本课程共15课时，通过一个Redis的实战案例，介绍Redis消息队列，以及如何在Java程序中监听Redis队列消息，最后结合Redis的key失效机制和消息队列完成对过期订单的处理。&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;点击“阅读原文”开始学习&lt;/span&gt;&lt;span&gt;吧~&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>