<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>2ee9f6222fa110d9e3f034bd3e6ee7c0</guid>
<title>云计算的全球变局与中国故事</title>
<link>https://toutiao.io/k/9z6dese</link>
<content:encoded>&lt;div&gt;&lt;body id=&quot;readabilityBody&quot;&gt;
&lt;p id=&quot;app&quot;/&gt;
&lt;img src=&quot;https://static001.infoq.cn/static/infoq/img/logo-121-75.yuij86g.png&quot; alt=&quot;云计算的全球变局与中国故事_云原生_刘燕_InfoQ精选文章&quot;/&gt;





    

&lt;/body&gt;
&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8b16dc0d9fec58f267ee028d502dfd85</guid>
<title>刨根问底: Kafka 到底会不会丢数据？</title>
<link>https://toutiao.io/k/909ukbu</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content                                       &quot; id=&quot;js_content&quot;&gt;
            &lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;em&gt;&lt;span&gt;&lt;em&gt;&lt;span/&gt;&lt;/em&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;阅读本文大约需要 30 分钟。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;那么 Kafka 到底会不会丢数据呢？如果丢数据，究竟该怎么解决呢？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;只有掌握了这些， 我们才能处理好 Kafka 生产级的一些故障，从而更稳定地服务业务。&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;认真读完这篇文章，我相信你会对Kafka 如何解决丢数据问题，有更加深刻的理解。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;这篇文章干货很多，希望你可以耐心读完。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.599290780141844&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgDMV2ZHaB5kf106rAXEfTHvztibRqyYzYzTAaQYxlxRk7aNbGzsA0ZDEw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1410&quot;/&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;01 总体概述&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;越来越多的互联网公司使用消息队列来支撑自己的核心业务。由于是核心业务，一般都会要求消息传递过程中最大限度的做到不丢失，如果中间环节出现数据丢失，就会引来用户的投诉，年底绩效就要背锅了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么使用 Kafka 到底会不会丢数据呢？如果丢数据了该怎么解决呢？为了避免类似情况发生，除了要做好补偿措施，我们更应该在系统设计的时候充分考虑系统中的各种异常情况，从而设计出一个稳定可靠的消息系统。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家都知道 Kafka 的整个架构非常简洁，是分布式的架构，主要由 Producer、Broker、Consumer 三部分组成，后面剖析丢失场景会从这三部分入手来剖析。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4658730158730159&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoy608FibvOZ3G3oUeCm1weLtKg0t7fed0PZGTjX3rAkv0rjeyPnNs5FCoiakrj3dObYvwGU1FAmib8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1260&quot;/&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;02 消息传递语义剖析&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在深度剖析消息丢失场景之前，我们先来聊聊&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;消息传递语义&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;&lt;span&gt;到底是个什么玩意？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所谓的消息传递语义是 Kafka 提供的 Producer 和 Consumer 之间的消息传递过程中消息传递的保证性。主要分为三种， 如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.30466666666666664&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgD5VoCylicDO5Jhy4CTTL9RM4MgVrDXOic1FXWgibOVcxUGsFTC2tjyJBnA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1500&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）首先当 Producer 向 Broker 发送数据后，会进行 commit，&lt;span&gt;如果 commit 成功，&lt;/span&gt;由于 Replica 副本机制的存在，则意味着消息不会丢失，但是 Producer 发送数据给 Broker 后，遇到网络问题而造成通信中断，那么 Producer 就无法准确判断该消息是否已经被提交（commit），这就可能造成 at least once 语义&lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）在 Kafka 0.11.0.0 之前， 如果 Producer 没有收到消息 commit 的响应结果，它只能重新发送消息，确保消息已经被正确的传输到 Broker，重新发送的时候会将消息再次写入日志中；而在 0.11.0.0 版本之后， Producer 支持幂等传递选项，保证重新发送不会导致消息在日志出现重复&lt;/span&gt;。&lt;span&gt;为了实现这个, Broker 为 Producer 分配了一个ID，并通过每条消息的序列号进行去重。也支持了类似事务语义来保证将消息发送到多个 Topic 分区中，保证所有消息要么都写入成功，要么都失败，这个主要用在 Topic 之间的 exactly once 语义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;其中启用幂等传递的方法配置&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：enable.idempotence = true。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;启用事务支持的方法配置&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：设置属性 transcational.id = &quot;指定值&quot;。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）从 Consumer 角度来剖析, 我们知道 Offset 是由 Consumer 自己来维护的, 如果 Consumer 收到消息后更新 Offset， 这时 Consumer 异常 crash 掉， 那么新的 Consumer 接管后再次重启消费，就会造成 at most once 语义（消息会丢，但不重复）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4) 如果 Consumer 消费消息完成后, 再更新 Offset， 如果这时 Consumer crash 掉，那么新的 Consumer 接管后重新用这个 Offset 拉取消息， 这时就会造成 at least once 语义（消息不丢，但被多次重复处理）。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;总结：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;默认 Kafka 提供 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;at least once&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;span&gt;语义的消息传递&lt;/span&gt;&lt;span&gt;，&lt;/span&gt;&lt;span&gt;&lt;span&gt;允许用户通过在处理消息之前保存 Offset 的方式提供 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;at most once&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt; 语义。如果我们可以自己实现消费幂等，&lt;/span&gt;&lt;/span&gt;&lt;span&gt;理想情况下这个系统的消息传递就是严格的&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;exactly once&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」, &lt;/span&gt;&lt;span&gt;也就是保证不丢失、且只会被精确的处理一次，但是这样是很难做到的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从 Kafka 整体架构图我们可以得出有三次消息传递的过程：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1）Producer 端发送消息给 Kafka Broker 端。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）Kafka Broker 将消息进行同步并持久化数据。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3）&lt;strong&gt;&lt;span&gt;Consumer 端从 &lt;/span&gt;&lt;/strong&gt;Kafka Broker 将消息拉取并进行消费。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在以上这三步中每一步都可能会出现丢失数据的情况， 那么 Kafka 到底在什么情况下才能保证消息不丢失呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;通过上面三步，我们可以得出：Kafka 只对 &lt;/span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」的消息做&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;最大限度的持久化保证不丢失&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;怎么理解上面这句话呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1）首先是 &lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」的消息：当 Kafka 中 &lt;span&gt;N&lt;/span&gt; 个 Broker 成功的收到一条消息并写入到日志文件后，它们会告诉 Producer 端这条消息已成功提交了，那么这时该消息在 Kafka 中就变成 &lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;已提交消息&quot;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;N &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;个 Broker &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们怎么理解呢？这主要取决于对 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;已提交&quot;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 的定义， 这里可以选择只要一个 Broker 成功保存该消息就算已提交，也可以是所有 Broker 都成功保存该消息才算是已提交&lt;span/&gt;&lt;/span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;span&gt;&lt;span/&gt;。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）其次是 &lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;最大限度的持久化保证不丢失&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，也就是说 Kafka 并不能保证在任何情况下都能做到数据不丢失。即 Kafka 不丢失数据是有前提条件的。假如这时你的消息保存在 N 个 Broker 上，那么前提条件就是这 N 个 Broker 中至少有1个是存活的，就可以保证你的消息不丢失。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说 Kafka 是能做到不丢失数据的， 只不过这些消息必须是 &lt;span&gt;「&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;的消息，且还要满足一定的条件才可以。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;了解了 Kafka 消息传递语义以及什么情况下可以保证不丢失数据，下面我们来详细剖析每个环节为什么会丢数据，以及如何最大限度的避免丢失数据。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;03 消息丢失场景剖析&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Producer 端丢失场景剖析&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在剖析 Producer 端数据丢失之前，我们先来了解下 Producer 端发送消息的流程，对于不了解 Producer 的读者们，可以查看 &lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTcxMDgxNA==&amp;amp;mid=2247488849&amp;amp;idx=1&amp;amp;sn=febda095589f02553d9191528f271c07&amp;amp;chksm=cefb3c60f98cb576fd9c58d760b9a5e4ae32a0c001e2049b591297d904a0401646448999c78a&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;聊聊 Kafka Producer 那‍点事&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;聊聊 Kafka Producer 那点事&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5580969807868252&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j83KibYlWcyceJicnUBWdByYTAibzaQsQ90c1IKpZhfXTVOJ1Mj4ErYMPzLg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1093&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;消息发送流程如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）首先我们要知道一点就是 Producer 端是直接与 Broker 中的 Leader Partition 交互的，所以在 Producer 端初始化中就需要通过 Partitioner 分区器从 Kafka 集群中获取到相关 Topic 对应的 Leader Partition 的元数据 &lt;/span&gt;。&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）待获取到 Leader Partition 的元数据后直接将消息发送过去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）Kafka Broker 对应的 Leader Partition 收到消息会先写入 Page Cache，定时刷盘进行持久化（顺序写入磁盘）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4) Follower Partition 拉取 Leader Partition 的消息并保持同 Leader Partition 数据一致，待消息拉取完毕后需要给 Leader Partition 回复 ACK 确认消息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5）待 Kafka Leader 与 Follower Partition 同步完数据并收到所有 ISR 中的 Replica 副本的 ACK 后，Leader Partition 会给 Producer 回复 ACK 确认消息。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;根据上图以及消息发送流程可以得出：Producer 端为了提升发送效率，减少IO操作，发送数据的时候是将多个请求合并成一个个 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;RecordBatch&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，并将其封装转换成 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;Request&lt;/strong&gt;&lt;/span&gt;&lt;span&gt; 请求&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;异步&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;将数据发送出去（也可以按时间间隔方式，达到时间间隔自动发送），&lt;/span&gt;&lt;span&gt;&lt;strong&gt;所以 Producer 端消息丢失更多是因为消息根本就没有发送到 Kafka Broker 端&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;导致 Producer 端消息没有发送成功有以下原因：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外 Kafka Producer 端也可以通过配置来确认消息是否生产成功：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4184818481848185&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j83ibHEc1zjbRF13jNcgcN8j7ichWjVY4lXXQOPDw6Uvy4GA9PIebBUfhVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1515&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;在 Kafka Producer 端的 acks 默认配置为1， 默认级别是 at least once 语义, 并不能保证 exactly once 语义。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5719360568383659&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgDWN00EfxZVYY8KN1XElAQibuzibDZibZiaicCJY8L7NOwBhkJC9icavRGt0SA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;563&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然 Producer 端发送数据有 ACK 机制, 那么这里就可能会丢数据的&lt;strong&gt;!!!&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;acks = 0：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;由于发送后就自认为发送成功，&lt;/span&gt;&lt;span&gt;这时如果发生网络抖动， Producer 端并不会校验 ACK 自然也就丢了，且无法重试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;acks = 1：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;消息发送 Leader Parition 接收成功就表示发送成功，这时&lt;/span&gt;&lt;span&gt;只要 Leader Partition 不 Crash 掉，就可以保证 Leader Partition 不丢数据，但是如果 Leader Partition 异常 Crash 掉了， Follower Partition 还未同步完数据且没有 ACK，这时就会丢数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;acks = -1 或者 all：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 消息发送需要等待 ISR 中 Leader Partition 和 所有的 Follower Partition 都确认收到消息才算发送成功, 可靠性最高, 但也不能保证不丢数据,比如当 ISR 中只剩下 Leader Partition 了, 这样就变成 acks = 1 的情况了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Broker 端丢失场景剖析&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;接下来我们来看看 Broker 端持久化存储丢失场景， 对于不了解 Broker 的读者们，可以先看看 &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTcxMDgxNA==&amp;amp;mid=2247488847&amp;amp;idx=1&amp;amp;sn=fe2dace4ebf39001062fa331711606ba&amp;amp;chksm=cefb3c7ef98cb5689c91b02edb345cc75751ae7e2daf27d8de9a47f9ecc3eedaf3551eead037&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;聊聊 Kafka Brok‍er 那点事&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;聊聊 Kafka Broker 那点事&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;，&lt;span&gt;数据存储过程如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8770614692653673&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/FrBePKkiazpohQngGEXiaejib1KGW2yCL7iarBhb6BMv1k68TN9yicVfl0VbPU2byKSIicoOkYIEawkKKbpJae7YDcKw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;667&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Kafka Broker 集群接收到数据后会将数据进行持久化存储到磁盘，为了提高吞吐量和性能，采用的是&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;异步批量刷盘的策略&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，也就是说按照一定的消息量和间隔时间进行刷盘。首先会将数据存储到 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;PageCache&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt; 中，至于什么时候将 Cache 中的数据刷盘是由&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;操作系统&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;根据自己的策略决定或者调用 fsync 命令进行强制刷盘，如果此时 Broker 宕机 Crash 掉，且选举了一个落后 Leader Partition 很多的 Follower Partition 成为新的 Leader Partition，那么落后的消息数据&lt;span&gt;就会丢失&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;                &lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5719360568383659&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgDWN00EfxZVYY8KN1XElAQibuzibDZibZiaicCJY8L7NOwBhkJC9icavRGt0SA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;563&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然 Broker 端消息存储是通过异步批量刷盘的，那么这&lt;span&gt;里就可能会丢数据的&lt;/span&gt;&lt;strong&gt;!!!&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Consumer 端丢失场景剖析&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;接下来我们来看看 Consumer 端消费数据丢失场景，对于不了解 Consumer 的读者们，可以先看看 &lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg3MTcxMDgxNA==&amp;amp;mid=2247488851&amp;amp;idx=1&amp;amp;sn=987824e5ba607e2e33ae0c64adb77d84&amp;amp;chksm=cefb3c62f98cb574d3932d5898dd1da3c20772e1d1885fc90d9b9f4bb5cdf8f34d4e0c7ff7ad&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;聊聊 Kafka‍ ‍Consumer 那点事&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;&lt;strong&gt;聊聊 Kafka Consumer 那点事&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt;, &lt;span&gt;我们先来看看消费流程：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5238095238095238&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j83viczAKDtc5fufr0K3ME0Oas26TkdMNG1fwib5ZGGnoa792cPVFFb52bw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1302&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4313304721030043&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoXQcfdmzJJvFpv2pQM5j8354hIicJUibMVspQ7pMLgmm4EEBFBqp4l1QeEyADkGUFIt1HthRSq45bg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1398&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1）Consumer 拉取数据之前跟 Producer 发送数据一样, 需要通过订阅关系获取到集群元数据, &lt;/span&gt;找到&lt;span&gt;相关 Topic 对应的 Leader Partition 的元数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2）然后 Consumer 通过 Pull 模式主动的去 Kafka 集群中拉取消息。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3）在这个过程中，有个消费者组的概念（&lt;/span&gt;&lt;strong&gt;&lt;span&gt;不了解的可以看上面链接文章&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;），多个 Consumer 可以组成一个消费者组即 Consumer Group，每个消费者组都有一个Group-Id。同一个 Consumer Group 中的 Consumer 可以消费同一个 Topic 下不同分区的数据，但是不会出现多个 Consumer 去消费同一个分区的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;4）拉取到消息后进行业务逻辑处理，待处理完成后，会进行 ACK 确认，即提交 Offset 消费位移进度记录。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;5）最后 Offset 会被保存到 Kafka Broker 集群中的 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;__consumer_offsets&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; 这个 Topic 中，且每个 Consumer 保存自己的 Offset 进度。 &lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;根据上图以及消息消费流程可以得出消费主要分为两个阶段：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;                       &lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5719360568383659&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyoSEibpop7mMXZKAsS0sRwgDWN00EfxZVYY8KN1XElAQibuzibDZibZiaicCJY8L7NOwBhkJC9icavRGt0SA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;563&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然 Consumer 拉取后消息最终是要提交 Offset， 那么这&lt;span&gt;里就可能会丢数据的&lt;/span&gt;&lt;strong&gt;!!!&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;拉取消息后&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;先提交 Offset，后处理消息&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;，如果此时处理消息的时候异常宕机，由于 Offset 已经提交了,  待 Consumer 重启后，会从之前已提交的 Offset 下一个位置重新开始消费， 之前未处理完成的消息不会被再次处理，对于该 Consumer 来说消息就丢失了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;拉取消息后&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;先处理消息，在进行提交 Offset&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;， 如果此时在提交之前发生异常宕机，由于没有提交成功 Offset， 待下次 Consumer 重启后还会从上次的 Offset 重新拉取消息，不会出现消息丢失的情况， 但是会出现重复消费的情况，这里只能业务自己保证幂等性。&lt;/span&gt;        &lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;04 消息丢失解决方案&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;上面带你从 Producer、Broker、Consumer 三端剖析了可能丢失数据的场景，下面我们就来看看如何解决才能最大限度的&lt;span&gt;保证消息不丢失。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Producer 端解决方案&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在剖析&lt;span&gt; Producer 端&lt;/span&gt;丢失场景的时候， 我们得出其是通过&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;异步&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」方式进行发送的，所以如果此时是使用&lt;/span&gt;&lt;span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;发后即焚&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;」的方式发送，即&lt;/span&gt;&lt;span&gt;调用 Producer.send(msg) 会立即返回，由于没有回调，可能因网络原因导致 Broker 并没有收到消息，此时就丢失了。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此我们可以从以下几方面进行解决 Producer 端消息丢失问题：&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.1.1 更换调用方式：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;弃用调用发后即焚的方式，使用带回调通知函数的方法进行发送消息，即 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;Producer.send(msg, callback)&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;, 这样一旦发现发送失败， 就可以做针对性处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;kotlin&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;Future&amp;lt;RecordMetadata&amp;gt; send(ProducerRecord&amp;lt;K, V&amp;gt; record, Callback callback);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;public&lt;/span&gt; Future&amp;lt;RecordMetadata&amp;gt; send(ProducerRecord&amp;lt;K, V&amp;gt; record, Callback callback) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        ProducerRecord&amp;lt;K, V&amp;gt; interceptedRecord = &lt;span class=&quot;code-snippet__keyword&quot;&gt;this&lt;/span&gt;.interceptors == &lt;span class=&quot;code-snippet__literal&quot;&gt;null&lt;/span&gt; ? record : &lt;span class=&quot;code-snippet__keyword&quot;&gt;this&lt;/span&gt;.interceptors.onSend(record);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;span class=&quot;code-snippet__keyword&quot;&gt;return&lt;/span&gt; doSend(interceptedRecord, callback);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;）网络抖动&lt;/span&gt;&lt;span&gt;导致消息丢失，Producer 端可以进行重试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;  &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）消息大小不合格，可以进行适当调整，符合 Broker 承受范围再发送。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过以上方式可以保证最大限度消息可以发送成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.1.2 ACK 确认机制：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;该参数代表了对&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;已提交&quot;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;消息的定义。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;需要将 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;request.required.acks 设置为 -1/ all&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，-1/all 表示有多少个副本 Broker 全部收到消息，才认为是消息提交成功的标识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;acks = -1/ all &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;, 这里有两种非常典型的情况：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;（1）数据发送到 Leader Partition， 且所有的 ISR 成员全部同步完数据， 此时，Leader Partition 异常 Crash 掉，那么会选举新的 Leader Partition，数据不会丢失， 如下图所示&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6088534107402032&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbypdvf0k7OrsblGBGmIXwIIedLVUEYL2aVWTplEiaKYB2SjSw0DCaEibXBOUCdWXdvAASqpbQkhrgwBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1378&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;（2）数据发送到&lt;strong&gt;&lt;span&gt; Leader Partition&lt;/span&gt;&lt;/strong&gt;，部分 ISR 成员同步完成，此时 Leader Partition 异常 Crash， 剩下的 Follower &lt;span&gt;Partition&lt;/span&gt; 都可能被选举成新的 Leader Partition，会给 Producer 端发送失败标识， 后续会重新发送数据，数据可能会重复， 如下图所示：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6083086053412463&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbypdvf0k7OrsblGBGmIXwIIe0n7XoQWXSxHU5q2zpFH9Ric5jFdKcSeaNMIojr9UurYicAspAQtKwR2g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1348&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此通过上面分析，我们还需要通过其他参数配置来进行保证：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;replication.factor &amp;gt;= 2&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;min.insync.replicas &amp;gt; 1&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是 Broker 端的配置，下面会详细介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.1.3 重试次数 retries：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示 Producer 端发送消息的重试次数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;需要将 retries 设置为大于0的数， 在 Kafka 2.4 版本中默认设置为&lt;/span&gt;&lt;span&gt;Integer.MAX_VALUE。另外如果需要保证发送消息的顺序性，配置如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;retries &lt;span&gt;=&lt;/span&gt; Integer&lt;span&gt;.&lt;/span&gt;&lt;span&gt;MAX_VALUE&lt;/span&gt;&lt;br/&gt;max&lt;span&gt;.&lt;/span&gt;in&lt;span&gt;.&lt;/span&gt;flight&lt;span&gt;.&lt;/span&gt;requests&lt;span&gt;.&lt;/span&gt;per&lt;span&gt;.&lt;/span&gt;connection &lt;span&gt;=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;/pre&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;这样 Producer 端就会一直进行重试直到 Broker 端返回 ACK 标识，同时只有一个连接向 Broker 发送数据保证了消息的顺序性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.1.4 重试时间 retry.backoff.ms：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示消息发送超时后&lt;/span&gt;&lt;strong&gt;&lt;span&gt;两次重试之间的间隔时间&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，避免无效的频繁重试，默认值为100ms,  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;推荐设置为300ms&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Broker 端解决方案&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在剖析 Broker 端丢失场景的时候， 我们得出其是通过&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;异步批量刷盘&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;」的策略，先将数据存储到 &lt;/span&gt;&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;PageCache&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;」，再进行异步刷盘， 由于没有提供 &lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;同&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;步刷盘&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」策略， 因此 Kafka 是通过&lt;span&gt;「&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;多分区多副本&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;」&lt;/span&gt;的方式来&lt;span&gt;最大限度的&lt;/span&gt;保证数据不丢失。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以通过以下参数配合来保证：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;4.2.1 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;unclean.leader.election.enable&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示&lt;/span&gt;&lt;strong&gt;&lt;span&gt;有哪些 Follower 可以有资格被选举为 Leader&lt;/span&gt;&lt;/strong&gt;&lt;span&gt; , 如果一个 Follower 的数据落后 Leader 太多，那么一旦它被选举为新的 Leader， 数据就会丢失，因此我们要将其设置为false，防止此类情况发生。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;4.2.2 &lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;replication.factor&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示分区副本的个数。建议设置 &lt;strong&gt;&lt;strong&gt;&lt;span&gt;replication.factor &amp;gt;=3&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;, 这样如果 Leader 副本异常 Crash 掉，Follower 副本会被选举为新的 Leader 副本继续提供服务。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;4.2.3 &lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;min.insync.replicas&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;该参数表示消息至少要被写入成功到 ISR 多少个副本才算&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&quot;已提交&quot;，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;建议&lt;/span&gt;&lt;span&gt;设置&lt;strong&gt;&lt;strong&gt;&lt;strong&gt;&lt;span&gt;min.insync.replicas &amp;gt; 1, &lt;/span&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;这样才可以提升消息持久性，保证数据不丢失。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外我们还需要确保一下 &lt;/span&gt;&lt;strong&gt;&lt;span&gt;replication.factor &amp;gt; min.insync.replicas&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;, 如果相等，只要有一个副本异常 Crash 掉，整个分区就无法正常工作了，因此推荐设置成： &lt;strong&gt;&lt;span&gt;replication.factor = min.insync.replicas +1&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;, 最大限度保证系统可用性。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt; Consumer 端解决方案&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;在剖析 Consumer 端丢失场景的时候，我们得出其拉取完消息后是需要提交 Offset 位移信息的，因此为了不丢数据，正确的做法是：&lt;/span&gt;&lt;strong&gt;&lt;span&gt;拉取数据、&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;业务逻辑处理、&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span&gt;提交消费 Offset 位移信息。&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;我们还需要设置参数 &lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;enable.auto.commit = false, 采用手动提交位移的方式。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外对于消费消息重复的情况，业务自己保证幂等性, &lt;/span&gt;&lt;strong&gt;&lt;span&gt;保证只成功消费一次即可&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;05 总结&lt;/span&gt;&lt;br/&gt;&lt;/h1&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这里，我们一起来总结一下这篇文章的重点。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;1、从 Kafka 整体架构上概述了可能发生数据丢失的环节。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;2、带你剖析了&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;消息传递语义&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;的概念， 确定了 Kafka 只对&lt;span&gt;「&lt;/span&gt;&lt;strong&gt;&lt;span&gt;已提交&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;」&lt;/span&gt;的消息做&lt;span&gt;「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;最大限度的持久化保证不丢失&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」&lt;/span&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;3、带你剖析了 Producer、Broker、Consumer 三端可能导致数据丢失的场景以及具体的高可靠解决方案。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果我的文章对你有所帮助，还请帮忙&lt;/span&gt;&lt;strong&gt;点赞、在看、转发&lt;/strong&gt;&lt;span&gt;一下，非常感谢！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;坚持总结, 持续输出高质量文章&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;  关注我: 华仔聊技&lt;span data-raw-text=&quot;术&quot; data-textnode-index=&quot;537&quot; data-index=&quot;7642&quot;&gt;术&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;br/&gt;&lt;/h1&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzg3MTcxMDgxNA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/ojWoacgRbyp4CYMexUiagvdYANIhY2ibiaibtqichibk92kiaMvHTJmavuepu4yZWC2OqwCVz834X916B5txFNYY7KgXw/0?wx_fmt=png&quot; data-nickname=&quot;华仔聊技术&quot; data-alias=&quot;&quot; data-signature=&quot;聊聊后端技术架构以及中间件源码&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;
          &lt;/div&gt;

          

          



           
                                
                    
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>6474ab1f71c41a73378a280bd38e08b6</guid>
<title>【合集】万字长文带你重温Elasticsearch ，这下完全懂了！</title>
<link>https://toutiao.io/k/etl9ji2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-paragraph-type=&quot;ignored&quot;&gt;&lt;p&gt;&lt;span&gt;由于近期在公司内部做了一次 Elasticsearch 的分享，所以本篇主要是做一个总结，希望通过这篇文章能让读者大致了解 Elasticsearch 是做什么的以及它的使用和基本原理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;生活中的数据&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;搜索引擎是对数据的检索，所以我们先从生活中的数据说起。&lt;/span&gt;&lt;span&gt;我们生活中的数据总体分为两种：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;结构化数据：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;也称作行数据，是由二维表结构来逻辑表达和实现的数据，严格地遵循数据格式与长度规范，主要通过关系型数据库进行存储和管理。指具有固定格式或有限长度的数据，如数据库，元数据等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;非结构化数据：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;又可称为全文数据，不定长或无固定格式，不适于由数据库二维表来表现，包括所有格式的办公文档、XML、HTML、Word 文档，邮件，各类报表、图片和咅频、视频信息等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;说明：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;如果要更细致的区分的话，XML、HTML 可划分为半结构化数据。因为它们也具有自己特定的标签格式，所以既可以根据需要按结构化数据来处理，也可抽取出纯文本按非结构化数据来处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;根据两种数据分类，搜索也相应的分为两种：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;对于结构化数据，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;因为它们具有特定的结构，所以我们一般都是可以通过关系型数据库（MySQL，Oracle 等）的二维表（Table）的方式存储和搜索，也可以建立索引。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于非结构化数据，也即对全文数据的搜索主要有两种方法：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;顺序扫描：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;通过文字名称也可了解到它的大概搜索方式，即按照顺序扫描的方式查询特定的关键字。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;例如给你一张报纸，让你找到该报纸中“平安”的文字在哪些地方出现过。你肯定需要从头到尾把报纸阅读扫描一遍然后标记出关键字在哪些版块出现过以及它的出现位置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种方式无疑是最耗时的最低效的，如果报纸排版字体小，而且版块较多甚至有多份报纸，等你扫描完你的眼睛也差不多了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;全文搜索：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对非结构化数据顺序扫描很慢，我们是否可以进行优化？把我们的非结构化数据想办法弄得有一定结构不就行了吗？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种方式就构成了全文检索的基本思路。这部分从非结构化数据中提取出的然后重新组织的信息，我们称之为索引。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种方式的主要工作量在前期索引的创建，但是对于后期搜索却是快速高效的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;先说说 Lucene&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过对生活中数据的类型作了一个简短了解之后，我们知道关系型数据库的 SQL 检索是处理不了这种非结构化数据的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种非结构化数据的处理需要依赖全文搜索，而目前市场上开放源代码的最好全文检索引擎工具包就属于 Apache 的 Lucene了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是 Lucene 只是一个工具包，它不是一个完整的全文检索引擎。Lucene 的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;目前以 Lucene 为基础建立的开源可用全文搜索引擎主要是 Solr 和 Elasticsearch。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Solr 和 Elasticsearch 都是比较成熟的全文搜索引擎，能完成的功能和性能也基本一样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但是 ES 本身就具有分布式的特性和易安装使用的特点，而 Solr 的分布式需要借助第三方来实现，例如通过使用 ZooKeeper 来达到分布式协调管理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不管是 Solr 还是 Elasticsearch 底层都是依赖于 Lucene，而 Lucene 能实现全文搜索主要是因为它实现了倒排索引的查询结构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如何理解倒排索引呢？假如现有三份数据文档，文档的内容如下分别是：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Java is the best programming language.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;PHP is the best programming language.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Javascript is the best programming language.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了创建倒排索引，我们通过分词器将每个文档的内容域拆分成单独的词（我们称它为词条或 Term），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;结果如下所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;pre&gt;&lt;code&gt;Term          Doc_1    Doc_2   Doc_3&lt;br/&gt;-------------------------------------&lt;br/&gt;Java        &lt;span&gt;|   X   |&lt;/span&gt;        &lt;span&gt;|&lt;br/&gt;is          |&lt;/span&gt;   X   &lt;span&gt;|   X    |&lt;/span&gt;   X&lt;br/&gt;the         &lt;span&gt;|   X   |&lt;/span&gt;   X    &lt;span&gt;|   X&lt;br/&gt;best        |&lt;/span&gt;   X   &lt;span&gt;|   X    |&lt;/span&gt;   X&lt;br/&gt;programming &lt;span&gt;|   x   |&lt;/span&gt;   X    &lt;span&gt;|   X&lt;br/&gt;language    |&lt;/span&gt;   X   &lt;span&gt;|   X    |&lt;/span&gt;   X&lt;br/&gt;PHP         &lt;span&gt;|       |&lt;/span&gt;   X    &lt;span&gt;|&lt;br/&gt;Javascript  |&lt;/span&gt;       &lt;span&gt;|        |&lt;/span&gt;   X&lt;br/&gt;-------------------------------------&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种结构由文档中所有不重复词的列表构成，对于其中每个词都有一个文档列表与之关联。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种由属性值来确定记录的位置的结构就是倒排索引。带有倒排索引的文件我们称为倒排文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们将上面的内容转换为图的形式来说明倒排索引的结构信息，如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6856316297010607&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1037&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/MOwlO0INfQoDj1VEyYPRBRYa6M2Vvshl1CbBxUSvUBabWVL1e0DVGWXvXicEgFVM90geOY2pS9fHuibwOWbibaV9w/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中主要有如下几个核心术语需要理解：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;词条（Term&lt;span&gt;）&lt;/span&gt;：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;索引里面最小的存储和查询单元，对于英文来说是一个单词，对于中文来说一般指分词后的一个词。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;词典（Term Dictionary&lt;span&gt;）：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;或字典，是词条 Term 的集合。搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;倒排表（Post list&lt;span&gt;）：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;一个文档通常由多个词组成，倒排表记录的是某个词在哪些文档里出现过以及出现的位置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每条记录称为一个倒排项（Posting&lt;span&gt;）&lt;/span&gt;。倒排表记录的不单是文档编号，还存储了词频等信息。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;倒排文件（Inverted File&lt;span&gt;）：&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件被称之为倒排文件，倒排文件是存储倒排索引的物理文件。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从上图我们可以了解到倒排索引主要由两个部分组成：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;词典和倒排表是 Lucene 中很重要的两种数据结构，是实现快速检索的重要基石。&lt;/span&gt;&lt;span&gt;词典和倒排文件是分两部分存储的，词典在内存中而倒排文件存储在磁盘上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;ES 核心概念&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一些基础知识的铺垫之后我们正式进入今天的主角 Elasticsearch 的介绍。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ES 是使用 Java 编写的一种开源搜索引擎，它在内部使用 Lucene 做索引与搜索，通过对 Lucene 的封装，隐藏了 Lucene 的复杂性，取而代之的提供一套简单一致的 RESTful API。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，Elasticsearch 不仅仅是 Lucene，并且也不仅仅只是一个全文搜索引擎。 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它可以被下面这样准确的形容：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;官网对 Elasticsearch 的介绍是 Elasticsearch 是一个分布式、可扩展、近实时的搜索与数据分析引擎。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们通过一些核心概念来看下 Elasticsearch 是如何做到分布式，可扩展和近实时搜索的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;span/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;集群（Cluster）&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ES 的集群搭建很简单，不需要依赖第三方协调管理组件，自身内部就实现了集群的管理功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ES 集群由一个或多个 Elasticsearch 节点组成，每个节点配置相同的 cluster.name 即可加入集群，默认值为 “elasticsearch”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;确保不同的环境中使用不同的集群名称，否则最终会导致节点加入错误的集群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个 Elasticsearch 服务启动实例就是一个节点（Node）。节点通过 node.name 来设置节点名称，如果不设置则在启动时给节点分配一个随机通用唯一标识符作为名称。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;①发现机制&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么有一个问题，ES 内部是如何通过一个相同的设置 cluster.name 就能将不同的节点连接到同一个集群的？答案是 Zen Discovery。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Zen Discovery 是 Elasticsearch 的内置默认发现模块（发现模块的职责是发现集群中的节点以及选举 Master 节点）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;它提供单播和基于文件的发现，并且可以扩展为通过插件支持云环境和其他形式的发现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Zen Discovery 与其他模块集成，例如，节点之间的所有通信都使用 Transport 模块完成。节点使用发现机制通过 Ping 的方式查找其他节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Elasticsearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果集群的节点运行在不同的机器上，使用单播，你可以为 Elasticsearch 提供一些它应该去尝试连接的节点列表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当一个节点联系到单播列表中的成员时，它就会得到整个集群所有节点的状态，然后它会联系 Master 节点，并加入集群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这意味着单播列表不需要包含集群中的所有节点， 它只是需要足够的节点，当一个新节点联系上其中一个并且说上话就可以了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;如果你使用 Master 候选节点作为单播列表，你只要列出三个就可以了。&lt;/span&gt;&lt;span&gt;这个配置在 elasticsearch.yml 文件中：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;discovery&lt;/span&gt;&lt;span&gt;.zen.ping.unicast.hosts&lt;/span&gt;: &lt;span&gt;[&quot;host1&quot;, &quot;host2:port&quot;]&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;节点启动后先 Ping ，如果 discovery.zen.ping.unicast.hosts 有设置，则 Ping 设置中的 Host ，否则尝试 ping localhost 的几个端口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Elasticsearch 支持同一个主机启动多个节点，Ping 的 Response 会包含该节点的基本信息以及该节点认为的 Master 节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;选举开始，先从各节点认为的 Master 中选，规则很简单，按照 ID 的字典序排序，取第一个。如果各节点都没有认为的 Master ，则从所有节点中选择，规则同上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里有个限制条件就是 discovery.zen.minimum_master_nodes ，如果节点数达不到最小值的限制，则循环上述过程，直到节点数足够可以开始选举。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后选举结果是肯定能选举出一个 Master ，如果只有一个 Local 节点那就选出的是自己。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果当前节点是 Master ，则开始等待节点数达到 discovery.zen.minimum_master_nodes，然后提供服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果当前节点不是 Master ，则尝试加入 Master 。Elasticsearch 将以上服务发现以及选主的流程叫做 Zen Discovery 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于它支持任意数目的集群（ 1- N ），所以不能像 Zookeeper 那样限制节点必须是奇数，也就无法用投票的机制来选主，而是通过一个规则。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只要所有的节点都遵循同样的规则，得到的信息都是对等的，选出来的主节点肯定是一致的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但分布式系统的问题就出在信息不对等的情况，这时候很容易出现脑裂（Split-Brain）的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大多数解决方案就是设置一个 Quorum 值，要求可用节点必须大于 Quorum（一般是超过半数节点），才能对外提供服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而 Elasticsearch 中，这个 Quorum 的配置就是 discovery.zen.minimum_master_nodes 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;②节点的角色&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每个节点既可以是候选主节点也可以是数据节点，通过在配置文件 ../config/elasticsearch.yml 中设置即可，默认都为 true。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;pre&gt;&lt;code&gt;node.master: &lt;span&gt;true&lt;/span&gt;  &lt;span&gt;//是否候选主节点&lt;/span&gt;&lt;br/&gt;node.&lt;span&gt;data&lt;/span&gt;: &lt;span&gt;true&lt;/span&gt;    &lt;span&gt;//是否数据节点&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据节点负责数据的存储和相关的操作，例如对数据进行增、删、改、查和聚合等操作，所以数据节点（Data 节点）对机器配置要求比较高，对 CPU、内存和 I/O 的消耗很大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常随着集群的扩大，需要增加更多的数据节点来提高性能和可用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;候选主节点可以被选举为主节点（Master 节点），集群中只有候选主节点才有选举权和被选举权，其他节点不参与选举的工作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主节点负责创建索引、删除索引、跟踪哪些节点是群集的一部分，并决定哪些分片分配给相关的节点、追踪集群中节点的状态等，稳定的主节点对集群的健康是非常重要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5540865384615384&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;832&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/MOwlO0INfQoDj1VEyYPRBRYa6M2VvshlkYpIdmUeYtcXbo1HyalkH9QQLeiaJ5ZIAykicTmkKr6x5o145I72uM7Q/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个节点既可以是候选主节点也可以是数据节点，但是由于数据节点对 CPU、内存核 I/O 消耗都很大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以如果某个节点既是数据节点又是主节点，那么可能会对主节点产生影响从而对整个集群的状态产生影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此为了提高集群的健康性，我们应该对 Elasticsearch 集群中的节点做好角色上的划分和隔离。可以使用几个配置较低的机器群作为候选主节点群。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主节点和其他节点之间通过 Ping 的方式互检查，主节点负责 Ping 所有其他节点，判断是否有节点已经挂掉。其他节点也通过 Ping 的方式判断主节点是否处于可用状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然对节点做了角色区分，但是用户的请求可以发往任何一个节点，并由该节点负责分发请求、收集结果等操作，而不需要主节点转发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这种节点可称之为协调节点，协调节点是不需要指定和配置的，集群中的任何节点都可以充当协调节点的角色。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;③脑裂现象&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时如果由于网络或其他原因导致集群中选举出多个 Master 节点，使得数据更新时出现不一致，这种现象称之为脑裂，即集群中不同的节点对于 Master 的选择出现了分歧，出现了多个 Master 竞争。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;“脑裂”问题可能有以下几个原因造成：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;网络问题：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;集群间的网络延迟导致一些节点访问不到 Master，认为 Master 挂掉了从而选举出新的 Master，并对 Master 上的分片和副本标红，分配新的主分片。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;节点负载：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;主节点的角色既为 Master 又为 Data，访问量较大时可能会导致 ES 停止响应（假死状态）造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;内存回收：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;主节点的角色既为 Master 又为 Data，当 Data 节点上的 ES 进程占用的内存较大，引发 JVM 的大规模内存回收，造成 ES 进程失去响应。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了避免脑裂现象的发生，我们可以从原因着手通过以下几个方面来做出优化措施：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;适当调大响应时间，减少误判。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;通过参数 discovery.zen.ping_timeout 设置节点状态的响应时间，默认为 3s，可以适当调大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果 Master 在该响应时间的范围内没有做出响应应答，判断该节点已经挂掉了。调大参数（如 6s，discovery.zen.ping_timeout:6），可适当减少误判。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;选举触发。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我们需要在候选集群中的节点的配置文件中设置参数 discovery.zen.munimum_master_nodes 的值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个参数表示在选举主节点时需要参与选举的候选主节点的节点数，默认值是 1，官方建议取值(master_eligibel_nodes/2)+1，其中 master_eligibel_nodes 为候选主节点的个数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这样做既能防止脑裂现象的发生，也能最大限度地提升集群的高可用性，因为只要不少于 discovery.zen.munimum_master_nodes 个候选节点存活，选举工作就能正常进行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当小于这个值的时候，无法触发选举行为，集群无法使用，不会造成分片混乱的情况。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;角色分离。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;即是上面我们提到的候选主节点和数据节点进行角色分离，这样可以减轻主节点的负担，防止主节点的假死状态发生，减少对主节点“已死”的误判。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;strong&gt;&lt;span/&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;分片（Shards）&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ES 支持 PB 级全文搜索，当索引上的数据量太大的时候，ES 通过水平拆分的方式将一个索引上的数据拆分出来分配到不同的数据块上，拆分出来的数据库块称之为一个分片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这类似于 MySQL 的分库分表，只不过 MySQL 分库分表需要借助第三方组件而 ES 内部自身实现了此功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个多分片的索引中写入数据时，通过路由来确定具体写入哪一个分片中，所以在创建索引的时候需要指定分片的数量，并且分片的数量一旦确定就不能修改。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分片的数量和下面介绍的副本数量都是可以通过创建索引时的 Settings 来配置，ES 默认为一个索引创建 5 个主分片, 并分别为每个分片创建一个副本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;pre&gt;&lt;code&gt;PUT /myIndex&lt;br/&gt;{&lt;br/&gt;   &lt;span&gt;&quot;settings&quot;&lt;/span&gt; : {&lt;br/&gt;      &lt;span&gt;&quot;number_of_shards&quot;&lt;/span&gt; : 5,&lt;br/&gt;      &lt;span&gt;&quot;number_of_replicas&quot;&lt;/span&gt; : 1&lt;br/&gt;   }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ES 通过分片的功能使得索引在规模上和性能上都得到提升，每个分片都是 Lucene 中的一个索引文件，每个分片必须有一个主分片和零到多个副本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;span/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;副本（Replicas）&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;副本就是对分片的 Copy，每个主分片都有一个或多个副本分片，当主分片异常时，副本可以提供数据的查询等操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;主分片和对应的副本分片是不会在同一个节点上的，所以副本分片数的最大值是 N-1（其中 N 为节点数）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对文档的新建、索引和删除请求都是写操作，必须在主分片上面完成之后才能被复制到相关的副本分片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ES 为了提高写入的能力这个过程是并发写的，同时为了解决并发写的过程中数据冲突的问题，ES 通过乐观锁的方式控制，每个文档都有一个 _version （版本）号，当文档被修改时版本号递增。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一旦所有的副本分片都报告写成功才会向协调节点报告成功，协调节点向客户端报告成功。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2644230769230769&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;832&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/MOwlO0INfQoDj1VEyYPRBRYa6M2VvshlmNWMheD3dmdPn4KYQdvqX1bjleqFTFjpBS86wf2pclds52vgVlCZEg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从上图可以看出为了达到高可用，Master 节点会避免将主分片和副本分片放在同一个节点上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假设这时节点 Node1 服务宕机了或者网络不可用了，那么主节点上主分片 S0 也就不可用了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;幸运的是还存在另外两个节点能正常工作，这时 ES 会重新选举新的主节点，而且这两个节点上存在我们所需要的 S0 的所有数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们会将 S0 的副本分片提升为主分片，这个提升主分片的过程是瞬间发生的。此时集群的状态将会为  Yellow。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为什么我们集群状态是 Yellow 而不是 Green 呢？虽然我们拥有所有的 2 个主分片，但是同时设置了每个主分片需要对应两份副本分片，而此时只存在一份副本分片。所以集群不能为 Green 的状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们同样关闭了 Node2 ，我们的程序依然可以保持在不丢失任何数据的情况下运行，因为 Node3 为每一个分片都保留着一份副本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果我们重新启动 Node1 ，集群可以将缺失的副本分片再次进行分配，那么集群的状态又将恢复到原来的正常状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果 Node1 依然拥有着之前的分片，它将尝试去重用它们，只不过这时 Node1 节点上的分片不再是主分片而是副本分片了，如果期间有更改的数据只需要从主分片上复制修改的数据文件即可。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;小结：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;将数据分片是为了提高可处理数据的容量和易于进行水平扩展，为分片做副本是为了提高集群的稳定性和提高并发量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;副本是乘法，越多消耗越大，但也越保险。分片是除法，分片越多，单分片数据就越少也越分散。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;副本越多，集群的可用性就越高，但是由于每个分片都相当于一个 Lucene 的索引文件，会占用一定的文件句柄、内存及 CPU。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并且分片间的数据同步也会占用一定的网络带宽，所以索引的分片数和副本数也不是越多越好。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;span/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;映射（Mapping）&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;映射是用于定义 ES 对索引中字段的存储类型、分词方式和是否存储等信息，就像数据库中的 Schema ，描述了文档可能具有的字段或属性、每个字段的数据类型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;只不过关系型数据库建表时必须指定字段类型，而 ES 对于字段类型可以不指定然后动态对字段类型猜测，也可以在创建索引时具体指定字段的类型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对字段类型根据数据格式自动识别的映射称之为动态映射（Dynamic Mapping），我们创建索引时具体定义字段类型的映射称之为静态映射或显示映射（Explicit Mapping）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在讲解动态映射和静态映射的使用前，我们先来了解下 ES 中的数据有哪些字段类型？&lt;/span&gt;&lt;span&gt;之后我们再讲解为什么我们创建索引时需要建立静态映射而不使用动态映射。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ES（v6.8）中字段数据类型主要有以下几类：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2869047619047619&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;840&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/MOwlO0INfQoDj1VEyYPRBRYa6M2VvshleDgZDrIHPedaVhpvCmNkiciaAh583jicMHMLcTxLYM5XNb4gDicibO84F7A/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Text 用于索引全文值的字段，例如电子邮件正文或产品说明。这些字段是被分词的，它们通过分词器传递 ，以在被索引之前将字符串转换为单个术语的列表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;分析过程允许 Elasticsearch 搜索单个单词中每个完整的文本字段。文本字段不用于排序，很少用于聚合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Keyword 用于索引结构化内容的字段，例如电子邮件地址，主机名，状态代码，邮政编码或标签。它们通常用于过滤，排序，和聚合。Keyword 字段只能按其确切值进行搜索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过对字段类型的了解我们知道有些字段需要明确定义的，例如某个字段是 Text 类型还是 Keyword 类型差别是很大的，时间字段也许我们需要指定它的时间格式，还有一些字段我们需要指定特定的分词器等等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果采用动态映射是不能精确做到这些的，自动识别常常会与我们期望的有些差异。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以创建索引的时候一个完整的格式应该是指定分片和副本数以及 Mapping 的定义，如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;pre&gt;&lt;code&gt;PUT my_index &lt;br/&gt;{&lt;br/&gt;   &lt;span&gt;&quot;settings&quot;&lt;/span&gt; : {&lt;br/&gt;      &lt;span&gt;&quot;number_of_shards&quot;&lt;/span&gt; : 5,&lt;br/&gt;      &lt;span&gt;&quot;number_of_replicas&quot;&lt;/span&gt; : 1&lt;br/&gt;   }&lt;br/&gt;  &lt;span&gt;&quot;mappings&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;_doc&quot;&lt;/span&gt;: { &lt;br/&gt;      &lt;span&gt;&quot;properties&quot;&lt;/span&gt;: { &lt;br/&gt;        &lt;span&gt;&quot;title&quot;&lt;/span&gt;:    { &lt;span&gt;&quot;type&quot;&lt;/span&gt;: &lt;span&gt;&quot;text&quot;&lt;/span&gt;  }, &lt;br/&gt;        &lt;span&gt;&quot;name&quot;&lt;/span&gt;:     { &lt;span&gt;&quot;type&quot;&lt;/span&gt;: &lt;span&gt;&quot;text&quot;&lt;/span&gt;  }, &lt;br/&gt;        &lt;span&gt;&quot;age&quot;&lt;/span&gt;:      { &lt;span&gt;&quot;type&quot;&lt;/span&gt;: &lt;span&gt;&quot;integer&quot;&lt;/span&gt; },  &lt;br/&gt;        &lt;span&gt;&quot;created&quot;&lt;/span&gt;:  {&lt;br/&gt;          &lt;span&gt;&quot;type&quot;&lt;/span&gt;:   &lt;span&gt;&quot;date&quot;&lt;/span&gt;, &lt;br/&gt;          &lt;span&gt;&quot;format&quot;&lt;/span&gt;: &lt;span&gt;&quot;strict_date_optional_time||epoch_millis&quot;&lt;/span&gt;&lt;br/&gt;        }&lt;br/&gt;      }&lt;br/&gt;    }&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;ES 的基本使用&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在决定使用 Elasticsearch 的时候首先要考虑的是版本问题，Elasticsearch （排除 0.x 和 1.x）目前有如下常用的稳定的主版本：2.x，5.x，6.x，7.x（current）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你可能会发现没有 3.x 和 4.x，ES 从 2.4.6 直接跳到了 5.0.0。&lt;/span&gt;&lt;span&gt;其实是为了 ELK（ElasticSearch，Logstash，Kibana）技术栈的版本统一，免的给用户带来混乱。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Elasticsearch 是 2.x （2.x 的最后一版 2.4.6 的发布时间是 July 25, 2017） 的情况下，Kibana 已经是 4.x（Kibana 4.6.5 的发布时间是 July 25, 2017）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么在 Kibana 的下一主版本肯定是 5.x 了，所以 Elasticsearch 直接将自己的主版本发布为 5.0.0 了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统一之后，我们选版本就不会犹豫困惑了，我们选定 Elasticsearch 的版本后再选择相同版本的 Kibana 就行了，不用担忧版本不兼容的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Elasticsearch 是使用 Java 构建，所以除了注意 ELK 技术的版本统一，我们在选择 Elasticsearch 的版本的时候还需要注意 JDK 的版本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为每个大版本所依赖的 JDK 版本也不同，目前 7.2 版本已经可以支持 JDK11。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;span/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;安装使用&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.2857142857142857&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;763&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/MOwlO0INfQoDj1VEyYPRBRYa6M2VvshlaiarCoiciapywSvvJG35LU2fMKGvTLt4wg739GJ28Bw7wF100AGcTZOLg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;①下载和解压 Elasticsearch，无需安装解压后即可用，解压后目录如上图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;②安装目录下运行 bin/elasticsearch 来启动 ES。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;③默认在 9200 端口运行，请求 curl http://localhost:9200/ 或者浏览器输入 http://localhost:9200，得到一个 JSON 对象，其中包含当前节点、集群、版本等信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;pre&gt;&lt;code&gt;{&lt;br/&gt;  &lt;span&gt;&quot;name&quot;&lt;/span&gt; : &lt;span&gt;&quot;U7fp3O9&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;cluster_name&quot;&lt;/span&gt; : &lt;span&gt;&quot;elasticsearch&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;cluster_uuid&quot;&lt;/span&gt; : &lt;span&gt;&quot;-Rj8jGQvRIelGd9ckicUOA&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;version&quot;&lt;/span&gt; : {&lt;br/&gt;    &lt;span&gt;&quot;number&quot;&lt;/span&gt; : &lt;span&gt;&quot;6.8.1&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;build_flavor&quot;&lt;/span&gt; : &lt;span&gt;&quot;default&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;build_type&quot;&lt;/span&gt; : &lt;span&gt;&quot;zip&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;build_hash&quot;&lt;/span&gt; : &lt;span&gt;&quot;1fad4e1&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;build_date&quot;&lt;/span&gt; : &lt;span&gt;&quot;2019-06-18T13:16:52.517138Z&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;build_snapshot&quot;&lt;/span&gt; : &lt;span&gt;false&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;lucene_version&quot;&lt;/span&gt; : &lt;span&gt;&quot;7.7.0&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;minimum_wire_compatibility_version&quot;&lt;/span&gt; : &lt;span&gt;&quot;5.6.0&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;minimum_index_compatibility_version&quot;&lt;/span&gt; : &lt;span&gt;&quot;5.0.0&quot;&lt;/span&gt;&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;&quot;tagline&quot;&lt;/span&gt; : &lt;span&gt;&quot;You Know, for Search&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;span/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;集群健康状态&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要检查群集运行状况，我们可以在 Kibana 控制台中运行以下命令 GET /_cluster/health，得到如下信息：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;pre&gt;&lt;code&gt;{&lt;br/&gt;  &lt;span&gt;&quot;cluster_name&quot;&lt;/span&gt; : &lt;span&gt;&quot;wujiajian&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;status&quot;&lt;/span&gt; : &lt;span&gt;&quot;yellow&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;timed_out&quot;&lt;/span&gt; : &lt;span&gt;false&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;number_of_nodes&quot;&lt;/span&gt; : &lt;span&gt;1&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;number_of_data_nodes&quot;&lt;/span&gt; : &lt;span&gt;1&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;active_primary_shards&quot;&lt;/span&gt; : &lt;span&gt;9&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;active_shards&quot;&lt;/span&gt; : &lt;span&gt;9&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;relocating_shards&quot;&lt;/span&gt; : &lt;span&gt;0&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;initializing_shards&quot;&lt;/span&gt; : &lt;span&gt;0&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;unassigned_shards&quot;&lt;/span&gt; : &lt;span&gt;5&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;delayed_unassigned_shards&quot;&lt;/span&gt; : &lt;span&gt;0&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;number_of_pending_tasks&quot;&lt;/span&gt; : &lt;span&gt;0&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;number_of_in_flight_fetch&quot;&lt;/span&gt; : &lt;span&gt;0&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;task_max_waiting_in_queue_millis&quot;&lt;/span&gt; : &lt;span&gt;0&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;active_shards_percent_as_number&quot;&lt;/span&gt; : &lt;span&gt;64.28571428571429&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;集群状态通过 绿，黄，红 来标识：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;绿色：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;集群健康完好，一切功能齐全正常，所有分片和副本都可以正常工作。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;黄色：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;预警状态，所有主分片功能正常，但至少有一个副本是不能正常工作的。此时集群是可以正常工作的，但是高可用性在某种程度上会受影响。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;红色：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;集群不可正常使用。某个或某些分片及其副本异常不可用，这时集群的查询操作还能执行，但是返回的结果会不准确。对于分配到这个分片的写入请求将会报错，最终会导致数据的丢失。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当集群状态为红色时，它将会继续从可用的分片提供搜索请求服务，但是你需要尽快修复那些未分配的分片。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;ES 机制原理&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;ES 的基本概念和基本操作介绍完了之后，我们可能还有很多疑惑：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它们内部是如何运行的？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;主分片和副本分片是如何同步的？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建索引的流程是什么样的？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ES 如何将索引数据分配到不同的分片上的？&lt;/span&gt;&lt;span&gt;以及这些索引数据是如何存储的？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;为什么说 ES 是近实时搜索引擎而文档的 CRUD (创建-读取-更新-删除) 操作是实时的？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;以及 Elasticsearch 是怎样保证更新被持久化在断电时也不丢失数据？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;还有为什么删除文档不会立刻释放空间？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;带着这些疑问我们进入接下来的内容。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;span/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;写索引原理&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图描述了 3 个节点的集群，共拥有 12 个分片，其中有 4 个主分片（S0、S1、S2、S3）和 8 个副本分片（R0、R1、R2、R3），每个主分片对应两个副本分片，节点 1 是主节点（Master 节点）负责整个集群的状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.4359903381642512&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;828&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/MOwlO0INfQoDj1VEyYPRBRYa6M2Vvshlqtyzt0VwASdRhOFUj8lxjzQLEPIuFur0hSyEib1hXUU8petsI85oENQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;写索引是只能写在主分片上，然后同步到副本分片。这里有四个主分片，一条数据 ES 是根据什么规则写到特定分片上的呢？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这条索引数据为什么被写到 S0 上而不写到 S1 或 S2 上？那条数据为什么又被写到 S3 上而不写到 S0 上了？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;实际上，这个过程是根据下面这个公式决定的：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;shard&lt;/span&gt; = hash(routing) % number_of_primary_shards&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Routing 通过 Hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这就解释了为什么我们要在创建索引的时候就确定好主分片的数量并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于在 ES 集群中每个节点通过上面的计算公式都知道集群中的文档的存放位置，所以每个节点都有处理读写请求的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在一个写请求被发送到某个节点后，该节点即为前面说过的协调节点，协调节点会根据路由公式计算出需要写到哪个分片上，再将请求转发到该分片的主分片节点上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.49095295536791317&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;829&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/MOwlO0INfQoDj1VEyYPRBRYa6M2VvshlCgEB39QgCHH1pouHSvVrxqULkuDjs0ClKKbxLtmYxv016b3mvZrLlw/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;假如此时数据通过路由计算公式取余后得到的值是 shard=hash(routing)%4=0。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;则具体流程如下：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;客户端向 ES1 节点（协调节点）发送写请求，通过路由计算公式得到值为 0，则当前数据应被写到主分片 S0 上。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ES1 节点将请求转发到 S0 主分片所在的节点 ES3，ES3 接受请求并写入到磁盘。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;并发将数据复制到两个副本分片 R0 上，其中通过乐观并发控制数据的冲突。一旦所有的副本分片都报告成功，则节点 ES3 将向协调节点报告成功，协调节点向客户端报告成功。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;span/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;存储原理&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上面介绍了在 ES 内部索引的写处理流程，这个流程是在 ES 的内存中执行的，数据被分配到特定的分片和副本上之后，最终是存储到磁盘上的，这样在断电的时候就不会丢失数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;具体的存储路径可在配置文件 ../config/elasticsearch.yml 中进行设置，默认存储在安装目录的 Data 文件夹下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;建议不要使用默认值，因为若 ES 进行了升级，则有可能导致数据全部丢失：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;pre&gt;&lt;code&gt;path.data: &lt;span&gt;/path/&lt;/span&gt;to/data  &lt;span&gt;//索引数据&lt;/span&gt;&lt;br/&gt;path.logs: &lt;span&gt;/path/&lt;/span&gt;to/logs  &lt;span&gt;//日志记录&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;①分段存储&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;索引文档以段的形式存储在磁盘上，何为段？索引文件被拆分为多个子文件，则每个子文件叫作段，每一个段本身都是一个倒排索引，并且段具有不变性，一旦索引的数据被写入硬盘，就不可再修改。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在底层采用了分段的存储模式，使它在读写时几乎完全避免了锁的出现，大大提升了读写性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;段被写入到磁盘后会生成一个提交点，提交点是一个用来记录所有提交后段信息的文件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;一个段一旦拥有了提交点，就说明这个段只有读的权限，失去了写的权限。相反，当段在内存中时，就只有写的权限，而不具备读数据的权限，意味着不能被检索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;段的概念提出主要是因为：在早期全文检索中为整个文档集合建立了一个很大的倒排索引，并将其写入磁盘中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果索引有更新，就需要重新全量创建一个索引来替换原来的索引。这种方式在数据量很大时效率很低，并且由于创建一次索引的成本很高，所以对数据的更新不能过于频繁，也就不能保证时效性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;索引文件分段存储并且不可修改，那么新增、更新和删除如何处理呢？&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;新增，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;新增很好处理，由于数据是新的，所以只需要对当前文档新增一个段就可以了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;删除，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;由于不可修改，所以对于删除操作，不会把文档从旧的段中移除而是通过新增一个 .del 文件，文件中会列出这些被删除文档的段信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;更新，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;不能修改旧的段来进行反映文档的更新，其实更新相当于是删除和新增这两个动作组成。会将旧的文档在 .del 文件中标记删除，然后文档的新版本被索引到一个新的段中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就会被移除。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;段被设定为不可修改具有一定的优势也有一定的缺点，优势主要表现在：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;其它缓存(像 Filter 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和需要被缓存到内存的索引的使用量。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;段的不变性的缺点如下：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;当对旧数据进行删除时，旧数据不会马上被删除，而是在 .del 文件中被标记为删除。而旧数据只能等到段更新时才能被移除，这样会造成大量的空间浪费。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;若有一条数据频繁的更新，每次更新都是新增新的标记旧的，则会有大量的空间浪费。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;每次新增数据时都需要新增一个段来存储数据。当段的数量太多时，对服务器的资源例如文件句柄的消耗会非常大。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;在查询的结果中包含所有的结果集，需要排除被标记删除的旧数据，这增加了查询的负担。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;②延迟写策略&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;介绍完了存储的形式，那么索引写入到磁盘的过程是怎样的？是否是直接调 Fsync 物理性地写入磁盘？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;答案是显而易见的，如果是直接写入到磁盘上，磁盘的 I/O 消耗上会严重影响性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么当写数据量大的时候会造成 ES 停顿卡死，查询也无法做到快速响应。如果真是这样 ES 也就不会称之为近实时全文搜索引擎了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了提升写的性能，ES 并没有每新增一条数据就增加一个段到磁盘上，而是采用延迟写的策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每当有新增的数据时，就将其先写入到内存中，在内存和磁盘之间是文件系统缓存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当达到默认的时间（1 秒钟）或者内存的数据达到一定量时，会触发一次刷新（Refresh），将内存中的数据生成到一个新的段上并缓存到文件缓存系统 上，稍后再被刷新到磁盘中并生成提交点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里的内存使用的是 ES 的 JVM 内存，而文件缓存系统使用的是操作系统的内存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;新的数据会继续的被写入内存，但内存中的数据并不是以段的形式存储的，因此不能提供检索功能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由内存刷新到文件缓存系统的时候会生成新的段，并将段打开以供搜索使用，而不需要等到被刷新到磁盘。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 Refresh （即内存刷新到文件缓存系统）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是近实时搜索，因为文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可以手动触发 Refresh，POST /_refresh 刷新所有索引，POST /nba/_refresh 刷新指定的索引。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Tips：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候， 手动刷新很有用，但是不要在生产&amp;gt;环境下每次索引一个文档都去手动刷新。而且并不是所有的情况都需要每秒刷新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可能你正在使用 Elasticsearch 索引大量的日志文件， 你可能想优化索引速度而不是&amp;gt;近实时搜索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这时可以在创建索引时在 Settings 中通过调大 refresh_interval = &quot;30s&quot; 的值 ， 降低每个索引的刷新频率，设值时需要注意后面带上时间单位，否则默认是毫秒。当 refresh_interval=-1 时表示关闭索引的自动刷新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;虽然通过延时写的策略可以减少数据往磁盘上写的次数提升了整体的写入能力，但是我们知道文件缓存系统也是内存空间，属于操作系统的内存，只要是内存都存在断电或异常情况下丢失数据的危险。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了避免丢失数据，Elasticsearch 添加了事务日志（Translog），事务日志记录了所有还没有持久化到磁盘的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9651442307692307&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;832&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/MOwlO0INfQoDj1VEyYPRBRYa6M2VvshlUnbKnn85jdtxAELjdvibrcsn2uW0b1sLdv4fjjEHvQgRFaY4Ht3IoQg/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;添加了事务日志后整个写索引的流程如上图所示：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;一个新文档被索引之后，先被写入到内存中，但是为了防止数据的丢失，会追加一份数据到事务日志中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不断有新的文档被写入到内存，同时也都会记录到事务日志中。这时新数据还不能被检索和查询。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;当达到默认的刷新时间或内存中的数据达到一定量后，会触发一次  Refresh，将内存中的数据以一个新段形式刷新到文件缓存系统中并清空内存。这时虽然新段未被提交到磁盘，但是可以提供文档的检索功能且不能被修改。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;随着新文档索引不断被写入，当日志数据大小超过 512M 或者时间超过 30 分钟时，会触发一次 Flush。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;内存中的数据被写入到一个新段同时被写入到文件缓存系统，文件系统缓存中数据通过 Fsync 刷新到磁盘中，生成提交点，日志文件被删除，创建一个空的新日志。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过这种方式当断电或需要重启时，ES 不仅要根据提交点去加载已经持久化过的段，还需要工具 Translog 里的记录，把未持久化的数据重新持久化到磁盘上，避免了数据丢失的可能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;③段合并&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于自动刷新流程每秒会创建一个新的段 ，这样会导致短时间内的段数量暴增。&lt;/span&gt;&lt;span&gt;而段数目太多会带来较大的麻烦。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;每一个段都会消耗文件句柄、内存和 CPU 运行周期。更重要的是，每个搜索请求都必须轮流检查每个段然后合并查询结果，所以段越多，搜索也就越慢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Elasticsearch 通过在后台定期进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档不会被拷贝到新的大段中。合并的过程中不会中断索引和搜索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.3786057692307692&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;832&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/MOwlO0INfQoDj1VEyYPRBRYa6M2VvshltXYcYKyEJnYfgsWaYAwHJPOQcWuYdAYAiaqCABhoH44h6TYlTTKX0mg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;段合并在进行索引和搜索时会自动进行，合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中，这些段既可以是未提交的也可以是已提交的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;合并结束后老的段会被删除，新的段被 Flush 到磁盘，同时写入一个包含新段且排除旧的和较小的段的新提交点，新的段被打开可以用来搜索。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;段合并的计算量庞大， 而且还要吃掉大量磁盘 I/O，段合并会拖累写入速率，如果任其发展会影响搜索性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Elasticsearch 在默认情况下会对合并流程进行资源限制，所以搜索仍然有足够的资源很好地执行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;性能优化&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;span/&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;存储设备&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;磁盘在现代服务器上通常都是瓶颈。Elasticsearch 重度使用磁盘，你的磁盘能处理的吞吐量越大，你的节点就越稳定。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里有一些优化磁盘 I/O 的技巧：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;使用 SSD。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;就像其他地方提过的， 他们比机械磁盘优秀多了。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;使用 RAID 0。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;条带化 RAID 会提高磁盘 I/O，代价显然就是当一块硬盘故障时整个就故障了。不要使用镜像或者奇偶校验 RAID 因为副本已经提供了这个功能。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;另外，使用多块硬盘，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;并允许 Elasticsearch 通过多个 path.data 目录配置把数据条带化分配到它们上面。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;不要使用远程挂载的存储，&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;比如 NFS 或者 SMB/CIFS。这个引入的延迟对性能来说完全是背道而驰的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;如果你用的是 EC2，当心 EBS。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;即便是基于 SSD 的 EBS，通常也比本地实例的存储要慢。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;span/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;内部索引优化&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5151148730350665&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;827&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/MOwlO0INfQoDj1VEyYPRBRYa6M2VvshloYpVtwUuiafCCNDUWoE2nhABwy7EM9icWGZSGX9wU6eUzvpCwq3wfbibA/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Elasticsearch 为了能快速找到某个 Term，先将所有的 Term 排个序，然后根据二分法查找 Term，时间复杂度为 logN，就像通过字典查找一样，这就是 Term Dictionary。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在再看起来，似乎和传统数据库通过 B-Tree 的方式类似。&lt;/span&gt;&lt;span&gt;但是如果 Term 太多，Term Dictionary 也会很大，放内存不现实，于是有了 Term Index。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;就像字典里的索引页一样，A 开头的有哪些 Term，分别在哪页，可以理解 Term Index是一棵树。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这棵树不会包含所有的 Term，它包含的是 Term 的一些前缀。通过 Term Index 可以快速地定位到 Term Dictionary 的某个 Offset，然后从这个位置再往后顺序查找。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在内存中用 FST 方式压缩 Term Index，FST 以字节的方式存储所有的 Term，这种压缩方式可以有效的缩减存储空间，使得 Term Index 足以放进内存，但这种方式也会导致查找时需要更多的 CPU 资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于存储在磁盘上的倒排表同样也采用了压缩技术减少存储所占用的空间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;span/&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;调整配置参数&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;调整配置参数建议如下：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;给每个文档指定有序的具有压缩良好的序列模式 ID，避免随机的 UUID-4 这样的 ID，这样的 ID 压缩比很低，会明显拖慢 Lucene。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;对于那些不需要聚合和排序的索引字段禁用 Doc values。Doc Values 是有序的基于 document=&amp;gt;field value 的映射列表。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;不需要做模糊检索的字段使用 Keyword 类型代替 Text 类型，这样可以避免在建立索引前对这些文本进行分词。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;如果你的搜索结果不需要近实时的准确度，考虑把每个索引的 index.refresh_interval 改到 30s 。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你是在做大批量导入，导入期间你可以通过设置这个值为 -1 关掉刷新，还可以通过设置 index.number_of_replicas: 0 关闭副本。别忘记在完工的时候重新开启它。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;避免深度分页查询建议使用 Scroll 进行分页查询。普通分页查询时，会创建一个 from+size 的空优先队列，每个分片会返回 from+size 条数据，默认只包含文档 ID 和得分 Score 给协调节点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果有 N 个分片，则协调节点再对（from+size）×n 条数据进行二次排序，然后选择需要被取回的文档。当 from 很大时，排序过程会变得很沉重，占用 CPU 资源严重。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;减少映射字段，只提供需要检索，聚合或排序的字段。其他字段可存在其他存储设备上，例如 Hbase，在 ES 中得到结果后再去 Hbase 查询这些字段。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建索引和查询时指定路由 Routing 值，这样可以精确到具体的分片查询，提升查询效率。路由的选择需要注意数据的分布均衡。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span/&gt;&lt;span/&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;JVM 调优&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;JVM 调优建议如下：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;确保堆内存最小值（ Xms ）与最大值（ Xmx ）的大小是相同的，防止程序在运行时改变堆内存大小。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Elasticsearch 默认安装后设置的堆内存是 1GB。可通过 ../config/jvm.option 文件进行配置，但是最好不要超过物理内存的50%和超过 32GB。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;GC 默认采用 CMS 的方式，并发但是有 STW 的问题，可以考虑使用 G1 收集器。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;ES 非常依赖文件系统缓存（Filesystem Cache），快速搜索。一般来说，应该至少确保物理上有一半的可用内存分配到文件系统缓存。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;来源 | r6a.cn/cmsA&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>636604cf3bafaa693fd8adda37eb2188</guid>
<title>Airbnb复盘微服务</title>
<link>https://toutiao.io/k/eqbc7zj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 面临着架构解决方案的挑战，不但要解决现在的问题，同时要支持未来的扩张；这就是质量工程要解决的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 采用了增量和迭代过程：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;定义问题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;找到改进的解决方案&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;使用解决方案&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;提高解决方案采用率&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;处理解决方案的扩展挑战&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;这种方法能够分离每个问题的关注点，找到结构化的解决方案并在以后扩展它们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.45714285714285713&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3YTuicoOpRUHyvgUzgPdT3L5PXRlZzm2iaURwOvIwpkgf4244IaAKsKrQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 在采用上述方法过程中实施了以下做法：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;提供基础设施即代码以提高开发人员的生产力&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;明确所有权并通过工具和可观察性进行改进&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;定义由组织和方法支持的新架构&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;引入一个弃用工作组以加速迁移&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;让我们看看前述问题是如何解决的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;提供基础设施即代码以提高开发人员的生产力&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;当业务变革能力依赖于软件时，缓慢和错误的软件开发直接影响公司的竞争力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;凭借在微服务架构方面的经验，Airbnb 投资了自动化和工具化。但在一系列不断发展的技术中需要更快的迭代周期。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5478571428571428&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3EEEgSROqOP0Du4MqY23A2ydksndKx0If4iaAoia2ynibdbHlG5kGGiaxicg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;务实的解决方案是在单个仓库中投资基础设施即代码，从而逐步并行提升各个服务的采用率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;当运行更多服务时，就会出现理解这种复杂性的扩展挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;明确所有权并通过工具和可观察性进行改进&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;有太多的微服务相互捆绑；即使很小的变化也会导致相互依赖的变化和影响，掌握起来很复杂。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5671875&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa34sVCEX6dU8dJEa4RHAf2RhZNJAzbbwygtSQN3F5svJ0PDDWKUc0oug/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 投资于提高生产力，重点支持三个领域的新架构：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;1、所有权&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 部署了“Scry Ownership”，它是技术组件所有权数据（如所有者、维护者、通信渠道）的应用管理者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.42686567164179107&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3TkJvohbbZ7OiatxRkLnE91Ax6e8fhQIwsg1bdCsibE5WHY8O5WV6mtGA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1340&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;2、可观察性&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 设置了一系列可观察性仪表板，以系统地审查实施过程。下面是一个仪表板示例，用于跟踪正在设置的所有权：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5859598853868195&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3ib5syrRVermdic2GZ3qia5cVusDxfgCGNWpiaFfKFuPl0Ftiaon5Lx55zXg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;698&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;3、工具&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;数据空间仍然存在挑战。定制的 Thrift[2] 模式是有用的序列化器和数据描述符，但它们需要其他组件来检索产品中的数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 利用 GraphQL 构建了统一的数据访问层，直接提供查询能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.42714285714285716&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3qY16HgaRVAXc1ZEQV8hJ8ICiaypevosNSKl5zgJLxuE8oJxKS3VGIWA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;代码生成是提高开发人员生产力的最后一步。随着技术的增加，Airbnb 为每一层的标准组件提供了模板。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;通过设计指明数据类型和访问类型的代码注释，数据的访问甚至直接就被嵌入在了代码中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3442857142857143&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3mia0iahrjma3HC0eqQ8YBxia3UpHQFF2IJOQ7OUBicFLrR3tk7icFZ0QDkQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;当星号看起来对齐时，就会出现另一个速度问题。这一次，中央数据聚合器组件成为了限制因素。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;定义由组织和方法支持的新架构&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;中央数据聚合器的构建和部署时间太慢，团队无法按时迭代。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;即使提高了生产力，累积的结构复杂性仍然太高而无法在中央组件中处理。需要一个新的组织。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;熵是系统随着时间的推移变得更加复杂的自然趋势，需要支持和反作用力来平衡生态系统。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;质量工程力量在架构、组织和方法领域发挥作用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;1、支持增长的架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;太复杂了，团队必须对不同领域执行缓慢且成本高昂的影响分析，协调多个团队并纠正副作用错误。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;让我们分析一下“纯微服务架构”级联问题树：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;复杂性过度分布在细粒度服务中&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;这些细粒度的微服务缺乏稳定的协作点&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;缺失的粘合剂最终分布在组件和团队之间&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;即使是很小的变化也往往会导致混合影响&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;核心问题是缺乏城市化，导致单体或微服务架构缺乏模块化和关注点分离。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 采用了一种新的架构风格 Micro macroservices：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.37714285714285717&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3ktNiaMudwSq9niaiatibFtOPj1L0piazq1SM253qqm4tiaceibG0MmicBw5cNQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;在这样的架构中，每种类型的复杂性分布是一个清晰的层：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;统一 API是支持产品快速迭代的微服务&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;中央数据聚合器是具有紧密耦合的稳定单体&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;服务块外观 API抽象了提供实体块的微服务。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;阅读本文[3]，了解有关速度和质量架构的价值的更多信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;2、组织一致性支持新架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;旨在支持业务目标的组织可以改变游戏规则。这种调整对于 Airbnb 的加速发展至关重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;该组织与不断发展的架构保持一致，产品团队在统一 API 之上工作，数据聚合团队在中央数据层（即“胶水”），以及每个数据方面的域平台团队（预留、用户）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.455&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa3Ks1zbsc9O1hgoU4fOcABdQO43YicA0enWDHTjuDouDSmy6B1ibDfCrjw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;3、方法强制通往新架构的铺平道路&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;架构审查、IT 委员会、工艺治理——这些都是用于根据当前环境和未来架构审查提出的解决方案的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;这种方法的价值在于作为一种反力量，在由其他目标驱动的项目环境之外，以平衡选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 使用这些方法为 Micro macroservices 架构铺平了道路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5157142857142857&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa34jnficibqeaem1SMlLMKibR99QYqHkUU3BEmlibVzua7q5ZsvVwK21IJ1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1400&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;即使不包括在内，Airbnb 的管理层肯定对领导转型和发展新模式的文化以及发展技能产生了巨大影响，从而完成了 MAMOS 的范围。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;有了这些变化，Airbnb 能够引领平行的迁移轨道。但是弃用 Monolith 仍然需要太多时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;引入弃用工作组加速迁移&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;单独更改我们的银行账户已经是一场噩梦。当需要数年时间与多个团队协调才能完成时，这项任务就更加复杂了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;Airbnb 就像许多其他拥有遗留系统和持续业务的组织一样：他们无法在建造新房子的同时炸毁他们居住的房子。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;一个特定的组织单位致力于加速从单体架构中迁移出来，领导以下工作：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;移动应用程序弃用达12个月以上&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;提升和跟踪整体债务以获得可见性&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;日落低使用率的终端以加速删除&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;迁移的长期所有权&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;认识到折旧对估值有影响&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;这个团体有游说的反击力量，但对于实现迁移目标至关重要。反对单体应用不能是“每个人的责任”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span mpa-is-content=&quot;t&quot;&gt;当这项任务完成时，将面临其他挑战。&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.541015625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/vHicVZXtcAzAsrofrEPS0Aibcyl4DpHSa34Rdh4jLrRfpH13uIeMNBiaVjbG9jicTialIOBowjlQPqqPaVYJ6bgDibwA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1024&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>eb316818b048377a71f5cf41df051011</guid>
<title>介绍一个数据血缘的项目 OpenLineage</title>
<link>https://toutiao.io/k/pb9ns85</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;h4&gt;&lt;span&gt;背景&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;“大数据”这个概念逐渐深入人心，很多公司都面临的着：&lt;/p&gt;&lt;p&gt;总的来说，就是“大数据”中的“大”不仅仅是数据量大，也指的是数据种类多、数据来源复杂，不同的数据被各式各样的人使用。如何发现数据，确定数据的来龙去脉就成了一个急迫的问题。&lt;/p&gt;&lt;p&gt;OpenLineage 应运而生。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;介绍 OpenLineage&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;OpenLineage 可以翻译成开源血缘。按照这个项目的发起者 Julien Le Dem 的说法，“数据血缘需要遵循开源社区贡献者商定的标准，以保证其各自解决方案生成的元数据的兼容性和一致性。”&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Data lineage needs to follow a standard agreed upon by contributors to the open source community to guarantee the compatibility and consistency of the metadata produced by their respective solutions.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;它回答的问题是：“谁生产数据？它是如何转变的？谁在使用它？数据血缘是 DataOps 的支柱，它提供了对组织内数据旅程中系统和数据集交互的可见性。”&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Data lineage is the backbone of DataOps, providing visibility into the interaction of systems and datasets across the journey of data within an organization.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;也给出了一个可用的数据血缘应该满足什么样的要求。&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;它不仅需要捕获正在生成的数据集之间的依赖关系，还需要捕获生成和转换它们的业务逻辑&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这些数据集和程序中的每一个都需要有一种统一命名的形式，以便可以轻松识别并跨不同域统一访问&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;这些数据集和程序中的所有变化都需要以细粒度和自动方式进行跟踪和版本控制，以更好地了解整个生态系统随时间的演变&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;考虑到它需要支持的各种用例，描述这些数据集和程序的元数据需要灵活且可扩展&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;现在的 OpenLineage 的参与者包括了下面的一些开源项目：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Airflow&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Amundsen&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Datahub&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;dbt&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Egeria&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Great Expectations&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Iceberg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Marquez&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Pandas&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Parquet&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Prefect&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Spark&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Superset&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;&lt;span&gt;OpenLineage 概览&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;正如上面列举的参与 OpenLineage 的项目，它们都有着独特的设计理念和实现思路，让数据发现平台去和这些计算引擎一对一对接的话，就会变成复杂的网状的的链路。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4766666666666667&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;300&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAiclJSTyNpeJk78iaJ0Rqq1dZCsGGIk8y4N8gcwlmdRK1HRaqDGW3p76Jg/640?wx_fmt=png&quot;/&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;而 OpenLineage 起到了中间件的作用，负责沟通上下游。&lt;br/&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5154639175257731&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;291&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAicWqJwbOOa81hSs1JwSicX0CvFEr1XyUCgw7yyGUkdjJ8bIP5kqH6MbqA/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;&lt;p&gt;作为一个中间件，就是抛去所有花里胡哨的特性，直击本质。也就是上面提到的三个问题：&lt;/p&gt;&lt;p&gt;OpenLineage 的回答就是它的核心数据模型&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6382978723404256&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;940&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAicY1o085MZ2RofngfeQXLOicKpYXlfC6GGlsMHo5RVF5WqfjCrg30WXdQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;Run 和 Job 回答的是“它是如何转变的？”，Inputs/Outputs 回答的是“谁生产数据”/“谁在使用它”。在  OpenLineage 的核心数据模型设计中，它没有选择实现更细节，也更麻烦的列级别血缘，而是只做到了表级别的血缘。在我看来，这个选择是非常棒的，因为要选择实现列级别的血缘，每一种特定类型的 SQL 势必要绑定对应的 SQL 解释器，这就让 OpenLineage 变得复杂，就谈不上通用的标准了。&lt;/p&gt;&lt;p&gt;OpenLineage 的表达方式选择了 Json 格式，具体细节可以参考：https://github.com/OpenLineage/OpenLineage/blob/main/spec/OpenLineage.md&lt;/p&gt;&lt;pre&gt;&lt;code&gt;{&lt;br/&gt;  &lt;span&gt;&quot;eventType&quot;&lt;/span&gt;: &lt;span&gt;&quot;START&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;eventTime&quot;&lt;/span&gt;: &lt;span&gt;&quot;2020-12-09T23:37:31.081Z&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;run&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;runId&quot;&lt;/span&gt;: &lt;span&gt;&quot;3b452093-782c-4ef2-9c0c-aafe2aa6f34d&quot;&lt;/span&gt;,&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;&quot;job&quot;&lt;/span&gt;: {&lt;br/&gt;    &lt;span&gt;&quot;namespace&quot;&lt;/span&gt;: &lt;span&gt;&quot;my-scheduler-namespace&quot;&lt;/span&gt;,&lt;br/&gt;    &lt;span&gt;&quot;name&quot;&lt;/span&gt;: &lt;span&gt;&quot;myjob.mytask&quot;&lt;/span&gt;,&lt;br/&gt;  },&lt;br/&gt;  &lt;span&gt;&quot;inputs&quot;&lt;/span&gt;: [&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;namespace&quot;&lt;/span&gt;: &lt;span&gt;&quot;my-datasource-namespace&quot;&lt;/span&gt;,&lt;br/&gt;      &lt;span&gt;&quot;name&quot;&lt;/span&gt;: &lt;span&gt;&quot;instance.schema.table&quot;&lt;/span&gt;,&lt;br/&gt;    }&lt;br/&gt;  ],&lt;br/&gt;  &lt;span&gt;&quot;outputs&quot;&lt;/span&gt;: [&lt;br/&gt;    {&lt;br/&gt;      &lt;span&gt;&quot;namespace&quot;&lt;/span&gt;: &lt;span&gt;&quot;my-datasource-namespace&quot;&lt;/span&gt;,&lt;br/&gt;      &lt;span&gt;&quot;name&quot;&lt;/span&gt;: &lt;span&gt;&quot;instance.schema.output_table&quot;&lt;/span&gt;,&lt;br/&gt;    }&lt;br/&gt;  ],&lt;br/&gt;  &lt;span&gt;&quot;producer&quot;&lt;/span&gt;: &lt;span&gt;&quot;https://github.com/OpenLineage/OpenLineage/blob/v1-0-0/client&quot;&lt;/span&gt;,&lt;br/&gt;  &lt;span&gt;&quot;schemaURL&quot;&lt;/span&gt;: &lt;span&gt;&quot;https://openlineage.io/spec/1-0-0/OpenLineage.json#/definitions/RunEvent&quot;&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;&lt;span&gt;介绍 Marquez&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;空有标准，没有实现是没有意义的，OpenLineage 官方推荐的实现是 Marquez。它和 Databub、Amundsen 类似，长得像下面这样。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6084745762711864&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1180&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAicsD7iaO8eAF0dVN3QQmQQqD6icezS7kWUc6EzkbPE3t5UCLL21zNJqJFA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.53&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;1800&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/CFQZvsFct4ZtKq3njEjdMOeh0WZhYibAicXicmVfHs4icSrsu3eAjQeCsOcY4EuEhFiaMp0JwcDUoLGRpuIONzPBYjg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;h4&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;OpenLineage 是一个有野心的项目，它想和 HDFS 变成了分布式文件系统通用标准一样，变成数据血缘的通用标准。但是 OpenLineage 从 2020 年发布到现在，Databub、Amundsen 并没有受到 OpenLineage 的影响，依旧在按照项目自身的发展路径前进。&lt;/p&gt;&lt;p&gt;从个人实践来看，我很喜欢这个项目。国内很多谈数据治理的文章，都是在讲规章制度和规范这些，至于具体的落实，基本上很少会涉及，特别是像把数据血缘做成标准，可以让各种各样的数据计算引擎以同一套标准接入，就几乎上没有了。毕竟光讲理念、规章和制度，不去谈实现，略有“好高骛远”的嫌疑。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;参考链接&lt;/span&gt;&lt;/h4&gt;&lt;ol class=&quot;list-paddingleft-1&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://datakin.com/introducing-openlineage/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://github.com/OpenLineage/OpenLineage&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;https://openlineage.io/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>