<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>812e47fdbac33faffa4f87f7ff4a6b58</guid>
<title>[译] 如何优化您的日常决策</title>
<link>https://toutiao.io/k/88ebc7h</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;Post-body&quot;&gt;
                    &lt;p&gt;当今的生活和工作都是&lt;strong&gt;快节奏&lt;/strong&gt;的，人们每天都会遇到各种各样的事情，并需要做出做相应的&lt;strong&gt;决策&lt;/strong&gt;：哪些事情先做，哪些事情后做，哪些事情应该做，哪些事情不应该做。前些天有读到一篇文章：&lt;a href=&quot;https://jamesclear.com/design-default&quot; rel=&quot; nofollow ugc&quot;&gt;How to Optimize Your Daily Decisions&lt;/a&gt;，作者所做的思考，以及给出的建议，不仅通俗易懂，而且也方便用于日常工作、生活。因此有翻译成中文，分享给有需要的朋友；以下是原文。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://lovejade.oss-cn-shenzhen.aliyuncs.com/decisions.png&quot; title=&quot;&quot; alt=&quot;如何优化您的日常决策&quot;/&gt;&lt;/p&gt;

&lt;p&gt;您可能会假设人们购买产品是因为它们是什么，但事实是，我们经常购买东西是因为它们的位置。例如，与视线齐平的商店货架上的商品往往比不太显眼的货架上的商品购买得更多。&lt;/p&gt;

&lt;p&gt;在畅销书 &lt;a href=&quot;https://jamesclear.com/book/nudge&quot; rel=&quot; nofollow ugc&quot; title=&quot;理查德·塞勒 (Richard Thaler) 和卡斯·桑斯坦 (Cass Sunstein) 的推动&quot;&gt;Nudge&lt;/a&gt; ( &lt;a href=&quot;https://jamesclear.com/ebook/nudge&quot; rel=&quot; nofollow ugc&quot; title=&quot;轻推电子书&quot;&gt;Kindle&lt;/a&gt; | &lt;a href=&quot;https://jamesclear.com/audiobook/nudge&quot; rel=&quot; nofollow ugc&quot; title=&quot;轻推有声读物&quot;&gt;Audiobook&lt;/a&gt; ) 中，作者 Richard Thaler 和 Cass Sunstein 解释了我们日常决策受周围世界影响的各种方式。视线水平的货架对我们购买习惯的影响只是一个例子。&lt;/p&gt;

&lt;p&gt;这是另一个：&lt;/p&gt;

&lt;p&gt;过道的尽头是零售商的赚钱机器。根据《纽约时报》引用的数据，可口可乐 45% 的销售额专门来自过道尽头的货架。&lt;/p&gt;

&lt;p&gt;这就是为什么这很重要：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一些东西&lt;/strong&gt;必须放在与视线齐平的架子上。必须在过道尽头的架子上放&lt;em&gt;一些东西&lt;/em&gt;。某些东西必须是默认选择。某些东西必须是最能见度和最突出的选项。这不仅适用于商店，而且适用于我们生活的几乎每个领域。您的办公室、汽车、厨房和客厅都有默认选择。&lt;/p&gt;

&lt;p&gt;我的论点是这样的：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如果你为生活中的默认而设计，而不是接受交给你的任何东西，那么过上更好的生活会更容易&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;现在让我们谈谈如何做到这一点。&lt;/p&gt;

&lt;h2&gt;默认设计&lt;/h2&gt;

&lt;p&gt;尽管我们中的大多数人在任何特定时刻都有做出广泛选择的自由，但我们经常根据所处的环境做出决定。&lt;/p&gt;

&lt;p&gt;例如，如果我想这样做，我可以在写这篇文章时喝一杯啤酒。但是，我目前坐在办公桌前，旁边放着一杯水。看不到啤酒。虽然我有能力起床、步行到我的车、开车去商店和买啤酒，但我可能不会，因为我周围有更简单的选择——即饮用水。在这种情况下，喝一口水是默认的决定，很容易的决定。&lt;/p&gt;

&lt;p&gt;考虑在您的个人和职业生涯中如何设计您的默认决定。例如：&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;如果您睡觉时将手机放在床边，那么醒来后立即查看社交媒体和电子邮件可能是默认决定。&lt;/li&gt;
&lt;li&gt;如果你走进你的客厅，你的沙发和椅子都面向电视机，那么看电视很可能是默认的决定。&lt;/li&gt;
&lt;li&gt;如果您在厨房里放酒，那么持续饮酒更有可能成为默认决定。&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;当然，默认值也可以是正数。&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;如果你在工作时在办公桌旁边放一个哑铃，那么做一些快速的弯举更有可能是默认的决定。&lt;/li&gt;
&lt;li&gt;如果你全天都带着水瓶，那么喝水而不是苏打水更有可能是默认的决定。&lt;/li&gt;
&lt;li&gt;如果您将牙线放在可见的位置（例如牙刷旁边），则使用牙线更可能是默认决定。&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;研究人员将环境违约对我们决策的影响称为&lt;a href=&quot;https://jamesclear.com/choice-architecture&quot; rel=&quot; nofollow ugc&quot; title=&quot;选择架构&quot;&gt;选择架构&lt;/a&gt;。重要的是要意识到您可以成为您选择的架构师。您可以设计为默认。&lt;/p&gt;

&lt;h2&gt;如何优化您的默认决策&lt;/h2&gt;

&lt;p&gt;以下是我在尝试为我的生活中的默认设计时发现的一些有用的策略：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;简单&lt;/strong&gt;。当您经常被噪音包围时，很难将注意力集中在信号上。当你的厨房里堆满垃圾食品时，要吃得健康就更难了。当您在浏览器中打开 10 个选项卡时，更难以专注于阅读博客文章。当您陷入&lt;a href=&quot;https://jamesclear.com/multitasking-myth&quot; rel=&quot; nofollow ugc&quot; title=&quot;多任务处理的神话：为什么更少的优先级会导致更好的工作&quot;&gt;一心多用的神话&lt;/a&gt;时，完成最重要的任务就更加困难了。如有疑问，消除选项。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;视觉提示&lt;/strong&gt;。在超市中，将商品放在与视线齐平的货架上会使它们更具视觉效果并且更有可能被购买。在超市之外，您可以使用诸如&lt;a href=&quot;https://jamesclear.com/paper-clips&quot; rel=&quot; nofollow ugc&quot; title=&quot;如何通过使用回形针策略坚持每天的好习惯&quot;&gt;回形针法&lt;/a&gt;或&lt;a href=&quot;https://jamesclear.com/stop-procrastinating-seinfeld-strategy&quot; rel=&quot; nofollow ugc&quot; title=&quot;如何使用宋飞正传策略停止拖延你的目标&quot;&gt;宋飞策略之&lt;/a&gt;类的视觉提示来创建一个环境，在视觉上将您的行为推向正确的方向。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;选择退出与选择加入&lt;/strong&gt;。有一项&lt;a href=&quot;https://jamesclear.com/environment-design-organ-donation&quot; rel=&quot; nofollow ugc&quot; title=&quot;器官捐献与环境设计&quot;&gt;著名的器官捐赠研究&lt;/a&gt;揭示了多个欧洲国家如何提高器官捐赠率：他们要求公民选择不捐赠而不是选择捐赠。通过提前让未来的自己养成更好的习惯，你可以在生活中做一些类似的事情。例如，您可以将瑜伽课程安排在下周，而您今天感到有动力。当您的锻炼开始时，您必须证明选择退出是合理的，而不是激励自己选择加入。&lt;/p&gt;

&lt;p&gt;默认设计归结为一个非常简单的前提：改变你的环境，让好的行为更容易，坏的行为更难。&lt;/p&gt;

&lt;h2&gt;为您设计与由您设计&lt;/h2&gt;

&lt;p&gt;默认选择本身并不坏，但整个世界的设计都没有考虑到您的目标。事实上，许多公司的目标与您的目标直接竞争（食品公司可能希望您购买他们的薯片袋，而您想减肥）。出于这个原因，您应该谨慎接受每一个默认值，就好像它应该是最佳选择一样。&lt;/p&gt;

&lt;p&gt;我通过过自己设计的生活而不是接受别人给我的标准生活，从而获得了更多的成功。质疑一切。你需要改变、调整和改变你的环境，直到它符合你想要的生活。&lt;/p&gt;

&lt;p&gt;是的，你周围的世界塑造了你的习惯和选择，但有一件重要的事情需要意识到：首先必须有人来塑造这个世界。现在，有人可以是你。&lt;/p&gt;

&lt;p&gt;如果你想要更多关于改掉坏习惯和养成好习惯的实用想法，请查看我的书&lt;a href=&quot;https://jamesclear.com/book/atomic-habits&quot; rel=&quot; nofollow ugc&quot;&gt;原子习惯&lt;/a&gt;，它会告诉你习惯的微小改变如何带来显着的结果。&lt;/p&gt;

&lt;hr/&gt;

&lt;p&gt;通过该文的阅读，可以给生活、工作带来哪些启示？下面跟大家分享一些（如您有更多建议，欢迎留言分享）：&lt;/p&gt;

&lt;ol&gt;&lt;li&gt;定时对浏览器所打开的页面，加以阅读、消化、整理，然后关闭；从而提升专注；&lt;/li&gt;
&lt;li&gt;不再将短视频、微信等浪费时间，却没有太大价值的应用，放置手机桌面显眼位置；&lt;/li&gt;
&lt;li&gt;如您也有游戏瘾，周末将至，列出读一本书，或看几部电影的计划，尽量不去想玩游戏这事儿；&lt;/li&gt;
&lt;li&gt;如一定要玩儿，那么再玩了几盘，尽兴之后，删除游戏，让下次打开游戏，变得困难......&lt;/li&gt;&lt;/ol&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>65c9716f5112485d2dbb749cbfed662e</guid>
<title>Ethers.js 非权威开发指南（下）</title>
<link>https://toutiao.io/k/jqofcc1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;container wrapper post&quot;&gt;&lt;div class=&quot;post-header&quot;&gt;&lt;h1 class=&quot;title&quot;&gt;Ethers.js 非权威开发指南（下）&lt;/h1&gt;&lt;p class=&quot;meta&quot;&gt;胡键 Posted at — Jun 20, 2021
&lt;span class=&quot;meta&quot; id=&quot;busuanzi_container_page_pv&quot;&gt;阅读 &lt;span id=&quot;busuanzi_value_page_pv&quot;/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/div&gt;&lt;p class=&quot;share-component&quot; data-sites=&quot;qq,weibo,wechat,douban,twitter,facebook&quot; data-description=&quot;Share.js - 一键分享到微博，QQ空间，腾讯微博，人人，豆瓣&quot;/&gt;&lt;div class=&quot;markdown&quot;&gt;&lt;p&gt;本系列的&lt;a href=&quot;./ethersjs-indefinitive-guide-part1.html&quot;&gt;上篇&lt;/a&gt;已经展示了连接钱包，调用合约和确定交易状态的全过程，对于一般的 dapp 开发已经完全足够。但对于有格调的开发者来讲，这些还不足以满足他们的胃口。那么，在下篇，你们将看到一些更加高级和特别的东西：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;如何处理以太坊的事件？&lt;/li&gt;&lt;li&gt;如何监听特定合约的特定事件？&lt;/li&gt;&lt;li&gt;如何查询以太坊的过往历史？&lt;/li&gt;&lt;li&gt;如何获取导致交易产生的合约函数的输入参数？&lt;/li&gt;&lt;li&gt;对于高阶合约函数（即，接受另一个合约的函数为输入值），该如何调用？&lt;/li&gt;&lt;li&gt;如何实现签名（含 EIP712）？&lt;/li&gt;&lt;li&gt;如何获得某个账户的公钥？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;相信以上这些重口味问题的答案应该不会让各位失望。&lt;/p&gt;&lt;h2 id=&quot;监听事件&quot;&gt;监听事件&lt;/h2&gt;&lt;p&gt;通常，事件监听的需求来自于朴素的诉求：及时得到状态更新的通知。这种需求不仅仅局限于异步方法的调用，对于稍微复杂的一些程序，事件机制的引入也会让整个应用的架构得到简化。&lt;/p&gt;&lt;p&gt;Ethers.js 在 Provider 和 Contract 层面都提供了事件的支持，并且方法名称也有重叠。其中用得较多的方法如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;on&lt;/code&gt;，对特定事件添加监听器。&lt;/li&gt;&lt;li&gt;&lt;code&gt;off&lt;/code&gt;，移除某事件全部监听器。&lt;/li&gt;&lt;li&gt;&lt;code&gt;once&lt;/code&gt;，添加事件监听器，并且在事件处理完成后自动移除。它和 &lt;code&gt;on&lt;/code&gt; 的区别在于：&lt;ul&gt;&lt;li&gt;&lt;code&gt;on&lt;/code&gt; 没有移除事件监听器这一步骤，会继续监听后续事件；&lt;/li&gt;&lt;li&gt;&lt;code&gt;once&lt;/code&gt; 处理完当前事件之后，不再监听，对后续到来的事件不再处理；&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;dapp-典型的监听事件架构&quot;&gt;dapp 典型的监听事件架构&lt;/h3&gt;&lt;p&gt;虽然 Provider 和 Contract 提供了监听以太坊事件的方法，但要是不加区分到处引用这两个对象来添加事件处理函数，整个应用的代码仍不可避免地会陷入混乱。通常的做法都会结合前端框架的状态管理来做，实现上层业务代码和底层合约代码的解耦，同时又能及时得到通知。&lt;/p&gt;&lt;p&gt;通常做法如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;定义状态管理涉及的业务对象，此过程类似 db 或者 domain 的设计。&lt;/li&gt;&lt;li&gt;在事件处理函数内，基于所监听的事件，更新对应的状态对象。&lt;/li&gt;&lt;li&gt;在业务代码部分订阅业务对象的更新事件，在该事件处理函数内完成页面状态更新。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;对于 Angular 来讲：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;状态更新部分涉及对象&lt;/li&gt;&lt;/ol&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-fallback&quot; data-lang=&quot;fallback&quot;&gt;Provider / Contract EventListners &amp;gt; Akita Service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&quot;2&quot;&gt;&lt;li&gt;订阅状态更新涉及对象&lt;/li&gt;&lt;/ol&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-fallback&quot; data-lang=&quot;fallback&quot;&gt;Akita Query &amp;gt; Subscribers
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对于 Svelte 来讲，更简单，整个过程简化为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-fallback&quot; data-lang=&quot;fallback&quot;&gt;Provider / Contract EventListners &amp;gt; Store  &amp;gt; Reactive 语句 / 变量
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因为对 React 和 Vue 不熟，这里就此略过，但机制应该都是一样的。&lt;/p&gt;&lt;h3 id=&quot;使用-provider-监听&quot;&gt;使用 Provider 监听&lt;/h3&gt;&lt;p&gt;Provider 适合粗放型事件监听，值得注意的几个事件：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;block&lt;/code&gt;，新区块生成&lt;/li&gt;&lt;li&gt;&lt;code&gt;error&lt;/code&gt;，错误发生&lt;/li&gt;&lt;li&gt;&lt;code&gt;txHash 值&lt;/code&gt;，tx 被确认&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其他事件请参见 Ethers.js 的文档。&lt;/p&gt;&lt;p&gt;一般来讲，你不会需要上面的第三个事件（即&lt;code&gt;txHash 值&lt;/code&gt;），采用&lt;a href=&quot;./ethersjs-indefinitive-guide-part1.html&quot;&gt;本系列上篇&lt;/a&gt;中介绍的方法要更简单一些。&lt;/p&gt;&lt;p&gt;&lt;code&gt;block&lt;/code&gt; 事件在你需要一口气跟踪多个状态时最为有效，比如一次交易的变化可能导致多个地方的状态发生变化：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;账户余额&lt;/li&gt;&lt;li&gt;交易对内部双边余额的变化&lt;/li&gt;&lt;li&gt;计价合约的参数变化&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;note&quot;&gt;&lt;p&gt;&lt;strong&gt;本文是付费文章，剩余内容请访问以下链接支付之后继续阅读：&lt;/strong&gt;&lt;/p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/vwhXB3ZmHQD5r_y-3BfRkg&quot;&gt;付费链接&lt;/a&gt;&lt;p&gt;
（已付费：1）&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e63eede9020243e8a06784ed26e9eccb</guid>
<title>近期做的稳定性建设总结</title>
<link>https://toutiao.io/k/ic0wg6u</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;背景&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;近期业界频繁出现较大的稳定性事故，引发社会舆情。湖北十堰也发生了安全的大事故。海因里希法则告诉我们：一件重大事故的背后总是有29件轻微事故+300件潜在隐患。我们要把这些事件当做镜子做好自身的稳定性建设。&lt;/section&gt;&lt;section&gt;我们的项目目前平稳运行，架构设计上也能满足现阶段的需求。所以近期做的稳定性建设并非轰轰烈烈的大事件，却对未来的长远稳定性至关重要。如果一个工程或者项目需要做大手术了，甚至派上了公司级的专家一起来建设，那直接说明之前做的太烂了，遇到了大问题，估计要走马换将了。&lt;br/&gt;&lt;/section&gt;&lt;section&gt;很多朋友听到这里就会很无奈，在上一篇&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzNjAxODg4MQ==&amp;amp;mid=2247485721&amp;amp;idx=1&amp;amp;sn=8cac3b1db8338b9f0ba4e50db65945ce&amp;amp;chksm=fafde3b7cd8a6aa1805193fc1b2115285ad1c5362dcaa4097fc11de4947e2e37d4449e2d9602&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;《社招面试的架构分析》&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;《社招面试的架构分析》&lt;/a&gt;里，我也提到社招面试中很大一部分比重是要介绍自己实际做的项目业绩。做这些小事能有业绩吗？以后有什么值得说的吗？我的回答是：太有了。&lt;/section&gt;&lt;section&gt;&lt;img data-backh=&quot;210&quot; data-backw=&quot;509&quot; data-ratio=&quot;0.4125560538116592&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRlicnnsx1NRszaH7tOYc9e8rLjmC7iccpGjLMvGQ14R30a2DWg1UbjdibWrviakwU0PjOBpNic6NHhRibyNg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;892&quot;/&gt;&lt;/section&gt;&lt;section&gt;一个好的项目从功能演进方面大体经历：支撑业务、快速支撑业务、引领业务三个阶段。从稳定性建设来说，大体经历从0-1的基本稳定阶段和1到无限的稳定性加固阶段。“稳定性是第一性”，一旦稳定性出现问题，我们的功能演进就会回退到疲于奔命的支撑业务阶段。由于本篇文章功能演进不是重心，所以只告诉大家可以在面试中这么跟面试官讲：&lt;br/&gt;&lt;/section&gt;&lt;section&gt;我们的项目稳定性不错，日交易量十几个亿的情况下，SLA5个9以上。假设我们的系统连续5分钟系统成功率低于50%，就需要上报科技司、国务院了，所以我们有严格的事故定级标准，从最高的s0到最低的s9。s9定级要求影响总交易在5笔以下。实际上我在任的三年没有出过s9及以上的事故。(这里只是举个例子，大家还是要照自己的实际情况描述，要点是我们的系统很重要，对稳定性要求很高，这个场景下还做的不错。做的都是交易量不大的项目也不用担心，面试官关心的是从表述中体现出来的：格局、站位、层面和视野)&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;总体思路&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;1、独立出运维工程，将保障逻辑和业务逻辑分离，保障逻辑频繁迭代更新不影响业务逻辑稳定性&lt;/p&gt;&lt;p&gt;2、制定日志规范，新增集中采集日志，并据此新增监控告警，比外部先发现问题，并可以方便的进行问题排查和统计&lt;/p&gt;&lt;p&gt;3、规范和梳理现有监控告警，查缺补漏，合理设定告警阈值和级别，提高告警敏感度&lt;/p&gt;&lt;p&gt;4、告警治理，现有隐患各个击破，将平时告警数降为0&lt;/p&gt;&lt;p&gt;5、合理根据业务增长情况进行扩容&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;细节FAQ&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section&gt;这里举几个在方案评审时被问到的问题和回复以及具体实施过程中遇到问题的排查的解决思路用问答的形式表述如下：&lt;br/&gt;&lt;/section&gt;&lt;p&gt;Q1：在日志规范中规定在请求的开始和结束都需要打印日志，结束日志的内容包含了开始日志的内容，打印开始日志的意义是什么？&lt;/p&gt;&lt;p&gt;A：快速排查定位问题的需要&lt;/p&gt;&lt;section&gt;在需要对问题进行排查定位的场景，可以快速清晰的看到整个请求的过程。包括什么时间点接收到请求、什么时间点处理请求。&lt;/section&gt;&lt;section&gt;针对这个问题同学发起了连环问，问我结束时间-cost不就是开始时间吗？&lt;br/&gt;&lt;/section&gt;&lt;section&gt;是的，但是在实际排查问题的场景，需要尽量减少人工转换，快速定位，牺牲一点存储降低排查难度是值得的。同时，针对处理中间出现了问题，没有达到请求结束的场景，也可以定位到出现问题的环节。&lt;/section&gt;&lt;section&gt;连环问继续：如果是请求没有达到结束，直接try catch finally来处理，或者是通过请求成功率就可以定位了呀？&lt;br/&gt;&lt;/section&gt;&lt;section&gt;我们的try catch建议是catch exception，但是实际情况中有可能发生error级别的异常，这时候未必可以走到finally。我们没有必要在所有的场景都加上try catch还是要根据实际需要。如果请求出现成功率下降，那么影响的不是一笔交易，在需要针对具体一笔进行排查的时候，我们怎么知道请求成功率影响的是哪一笔呢？当然，通过复杂的排查和计算是可以最终实现定位的，但是我们要快速定位，尽量减少对开发人员的技术要求。同时，从容灾容错上考虑，我们需要对监控机制进行容灾，万一一个监控机制发生了问题，也可以最终定位到问题。这就是为什么系统有zabbix监控、&lt;span&gt;Prometheus监控等多项监控共存，指标上和角度上有区别也有重复，区别是为了根据具体场景快速定位，重复是为了容灾一个监控组件出现了问题也能定位。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Q2：收到一个可用内存不足10%的告警，经过了两个小时才自动恢复到87%，所在的机器出现一笔请求超时&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;A：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;现象&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1&amp;gt;对业务进行了解发现开始出现问题的时间点，有收到外部MQ发过来的大报文，虽然报文做了分片但是每个分片还是有几M大并且下发条数多，集中下发。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2&amp;gt;分别在问题机器和其他相同应用的不同机器上执行top命令，观察到问题机器和其他机器上jvm内存占用差不多并且稳定。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3&amp;gt;执行free -h命令观察到cache/buffer下降到1G以下，内存使用率的计算规则是(1-available)/total。available虽然大家都说是大体上等于free+buffer/cache。因为buffe/cache可以快速被释放。但是实际上当cache/buffer下降到一定数值，available的值远远小于&lt;span&gt;free&lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;buffer&lt;/span&gt;&lt;span&gt;/cach&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;。本次问题发生的时间点，机器可用内存7.6G，&lt;span&gt;free&lt;/span&gt;&lt;span&gt;+&lt;/span&gt;&lt;span&gt;buffer&lt;/span&gt;&lt;span&gt;/cach&lt;/span&gt;&lt;span&gt;e&lt;/span&gt;下降了200M，但是available却下降了500M多。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;4&amp;gt;&lt;span&gt;收到外部MQ发过来的大报文&lt;/span&gt;时间段网卡占用情况从平时0.5M以下飙升到20M TPS&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;5&amp;gt;&lt;span&gt;出现一笔请求超&lt;/span&gt;&lt;span&gt;时正在下发大报文的高峰期，请求方发请求到机器接收到请求时间间隔是几毫秒。收到请求后机器会将请求转发给MQ，用了3秒多。而请求方设置了5秒超时。&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;6&amp;gt;所有环节cpu使用率都很低&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;7&amp;gt;20天前在另外一台机器上也发生了内存升高到90%以上的现象&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;分析&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;此问题的根本原因是外部短时间内下发大量大报文(受节假日影响当天的报文略高于其他天)，从根本上治理需要和外部(大佬级别，我们完全没有主动权)一起进行架构方面的调整，不现实也没有必要用此牛刀。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;表现为虚机层面内存资源不足，影响了IO速率。因为高峰IO TPS20M，针对现在的千兆网卡、万兆网卡来说，并不大。问题并不在网络通道上，而在机器本身。而IO需要大量内存：内核态和用户态之间数据传输等环节的数据拷贝。研究过NIO、netty、linux内核等技术的应该都知道：IO无非就是分配内存、操作fd文件描述符和调用中断等命令的过程。因为现象中可以看到&lt;span&gt;jvm&lt;/span&gt;&lt;span&gt;内存&lt;/span&gt;&lt;span&gt;是没有问题的&lt;/span&gt;，这里的瓶颈就在系统内存不足上。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;所以短期我们制定SOP/EOP，应对临时问题。中期提申请进行纵向扩容。纵向扩容说白了就是增加物理内存。有人就要问了是不是扩机器数量也能解决问题。这种处理方式大概是能治病但是不一定对症。意思可以理解为吃广谱抗菌药来治疗感冒，有一定帮助但不是针对性的处理。因为扩机器是减少了请求数从而减少了内存占用量。但是万一有个大请求就是把内存飚高了呢？linux的设计如果内存高到一定程度自身的很多功能会受到影响，导致不符合预期。需要从根本上升高内存。并且扩内存实施成本更低，不需要程序的发布。就是低峰期暂停程序，插个内存条。当然，长期上业务量在上涨，但是我们还没有进行水平扩容。需要我们计算业务增长量进行合理扩机器。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;有的朋友会觉得这个处理方式并不高大上。牛逼的处理方式是调整个linux参数啥的。现在也算比较流行的一个词叫做：不可变服务器。&lt;span&gt;“传统”的部署方式中，对系统的改动都会呈现在服务器上，从而增加了风险。&lt;/span&gt;&lt;span&gt;采用不可变部署方式，&lt;/span&gt;服务器都是公司统一标准化的，那么变更只要考虑应用程序的发布，而应用程序一旦发布也不允许改变，就成了不可变服务。不可变性可以增加系统的稳定性。在一个规模比较大的公司，就算可以通过技术解决资源的问题，从整体角度，还是通用方案更加可取。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Q3：有个MQ服务偶尔会在并发量高的情况下有响应耗时高的问题，这个MQ是闭源的收费服务。怀疑是内部实现用的是短连接造成的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;A：排查人员review代码发现每次发送消息都调用了close方法，怀疑是短连接造成的。首先来说close方法有没有直接把连接关闭不能从名称上来判断，还是需要看实现。比如连接池方式的close实现实际上是把连接归还了连接池。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;可以使用netstat命令观察连接的状态，如果状态一直是established，应该是长连接。具体建立了几个长连接就看对应的&lt;span&gt;establish&lt;/span&gt;&lt;span&gt;ed&lt;/span&gt;的数量。具体原理就是常见的一个面试考题了：TCP三次握手：&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6014418125643667&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRlicBQKq12r4ibHKbDaRFmvNFSAQuhJKibWW5XtIQuqECVa8ZOSGokiarl0e0LUXsbVb0BUm0HR4atE1nw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;971&quot;/&gt;&lt;/p&gt;&lt;p&gt;TCP四次挥手：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6495238095238095&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRlicBQKq12r4ibHKbDaRFmvNFSrwEuqibuaZJZmwx2Jcm4yia3mHHtuib3BEhKic4ZI5YFDibvzb0lyFOmMOQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;525&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;看netstat的状态就可以了解处于TCP的哪个阶段了。&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;相关阅读&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>77290d22c9ca90ece1309b39017f6af9</guid>
<title>在 Golang 中是锁或 Channel 还是 Atomic</title>
<link>https://toutiao.io/k/4ycv1d9</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;  与其他编程语言一样在并发环境下如不对多个&lt;strong&gt;goroutine&lt;/strong&gt;（线程）访问或修改的共享资源元素的进行控制，让进入&lt;strong&gt;临界区&lt;/strong&gt;的对象互斥。就可能会出现数据异常情况；&lt;br/&gt;  一个&lt;strong&gt;非线程安全&lt;/strong&gt;对象如下，如不对Id的访问进行控制，多个goroutine进行更新Id字段是就会出现数据不一致的情况，如下示例：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; Conf &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt;  Id &lt;span&gt;int32&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;span&gt;func&lt;/span&gt;(c *Conf)&lt;span&gt;update&lt;/span&gt;(n &lt;span&gt;int32&lt;/span&gt;){&lt;br/&gt;  c.Id +=n&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;  启动100个goroutine用于更新对象c中的Id字段值，此时由于出现&lt;strong&gt;多个协程同时进入临界区&lt;/strong&gt;同时对Id变量进行修改。导致对象c中的Id字段值出现了不可预知的情况。此时程序输出的结果可能是：98、93、95等；&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() {&lt;br/&gt; &lt;span&gt;var&lt;/span&gt; c=&amp;amp;Conf{}&lt;br/&gt; &lt;span&gt;for&lt;/span&gt; i := 0; i&amp;lt;100;i++  {&lt;br/&gt;&lt;span&gt;go&lt;/span&gt; &lt;span&gt;func&lt;/span&gt;(n &lt;span&gt;int&lt;/span&gt;) {&lt;br/&gt;&lt;span&gt;//模拟停顿&lt;/span&gt;&lt;br/&gt;time.Sleep(1*time.Millisecond)&lt;br/&gt;c.update(1)&lt;br/&gt;}(i)&lt;br/&gt; }&lt;br/&gt;time.Sleep(10*time.Second)&lt;br/&gt;fmt.Println(c.Id)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;  下面分别使用锁与channel对临界区进行并发控制，使得输出得到正常的结果，并简单对比两者的性能；&lt;/p&gt;&lt;h2&gt;使用锁&lt;/h2&gt;&lt;p&gt;  现在在结构体Conf中添加一个读写锁变量sync.RWMutex，此时Conf继承了RWMutex中所有的方法字段等。通过此对象就可以对Id变量的访问进行加锁， struct变为如下：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; &lt;span&gt;Conf&lt;/span&gt; struct {&lt;br/&gt;  &lt;span&gt;Id&lt;/span&gt; &lt;span&gt;int32&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;sync&lt;/span&gt;.&lt;span&gt;RWMutex&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;定义一个新方法，此方法使用了锁对临界区访问进行了并发控制：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;func&lt;/span&gt;(&lt;span&gt;c&lt;/span&gt; *Conf) updateOfLock(n int32){&lt;br/&gt;   &lt;span&gt;c&lt;/span&gt;.&lt;span&gt;Lock&lt;/span&gt;()&lt;br/&gt;   &lt;span&gt;defer&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;.&lt;span&gt;Unlock&lt;/span&gt;()&lt;br/&gt;   &lt;span&gt;c&lt;/span&gt;.&lt;span&gt;Id&lt;/span&gt; +=n&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;  此时程序总是能够输出正确的结果：100&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() {&lt;br/&gt;&lt;span&gt;var&lt;/span&gt; c=&amp;amp;Conf{}&lt;br/&gt;&lt;span&gt;for&lt;/span&gt; i := 0; i&amp;lt;100;i++  {&lt;br/&gt;&lt;span&gt;go&lt;/span&gt; &lt;span&gt;func&lt;/span&gt;(n &lt;span&gt;int&lt;/span&gt;) {&lt;br/&gt;&lt;span&gt;//模拟停顿&lt;/span&gt;&lt;br/&gt;time.Sleep(1*time.Millisecond)&lt;br/&gt;c.updateOfLock(1)&lt;br/&gt;}(i)&lt;br/&gt;}&lt;br/&gt;time.Sleep(10*time.Second)&lt;br/&gt;fmt.Println(c.Id)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;使用channel&lt;/h2&gt;&lt;p&gt;  用channel控制临界资源的访问，原理也非常简单，创建一个长度为1的channel变量，进去临界区前往channel中写入一个值，由于长度为1，此时别的协程将无法往channel中写入值堵塞在此处channel上，前一个协程访问完临界区后从channel读取值，此后别的协程可再此往channel中写入值，从而能够进入临界区，结构体修改如下；&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;type&lt;/span&gt; Conf &lt;span&gt;struct&lt;/span&gt; {&lt;br/&gt;   Id &lt;span&gt;int32&lt;/span&gt;&lt;br/&gt;   lockChan &lt;span&gt;chan&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt;&lt;br/&gt;}&lt;br/&gt;&lt;span&gt;func&lt;/span&gt; (c *Conf) &lt;span&gt;updateOfChannel&lt;/span&gt;(n &lt;span&gt;int32&lt;/span&gt;) {&lt;br/&gt;   c.lockChan&amp;lt;-&lt;span&gt;true&lt;/span&gt;&lt;br/&gt;   &lt;span&gt;defer&lt;/span&gt; &lt;span&gt;func&lt;/span&gt;() {&amp;lt;-c.lockChan}()&lt;br/&gt;   c.Id +=n&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;  使用channel进行并发控制，需要注意取出lockChan中的值，此处使用了defer用于控制channel值的释放。&lt;/p&gt;&lt;pre&gt;&lt;code&gt; &lt;span&gt;func&lt;/span&gt; &lt;span&gt;main&lt;/span&gt;() {&lt;br/&gt;    &lt;span&gt;var&lt;/span&gt; c=&amp;amp;Conf{lockChan: &lt;span&gt;make&lt;/span&gt;(&lt;span&gt;chan&lt;/span&gt; &lt;span&gt;bool&lt;/span&gt;,1)}&lt;br/&gt;     &lt;span&gt;for&lt;/span&gt; i := 0; i&amp;lt;100;i++  {&lt;br/&gt;&lt;span&gt;go&lt;/span&gt; &lt;span&gt;func&lt;/span&gt;(n &lt;span&gt;int&lt;/span&gt;) {&lt;br/&gt;&lt;span&gt;//模拟停顿&lt;/span&gt;&lt;br/&gt;time.Sleep(1*time.Millisecond)&lt;br/&gt;c.updateOfChannel(1)&lt;br/&gt;}(i)&lt;br/&gt;     }&lt;br/&gt;time.Sleep(10*time.Second)&lt;br/&gt;fmt.Println(c.Id)&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;原子变量&lt;/h2&gt;&lt;p&gt;  无需修改Conf结构体，直接调用atomic的相关方法即可，方法如下，此时也是能够得到正确的值；&lt;/p&gt;&lt;pre&gt;&lt;code&gt;  &lt;span&gt;func&lt;/span&gt; (c *Conf) &lt;span&gt;updateOfAtomic&lt;/span&gt;(n &lt;span&gt;int32&lt;/span&gt;) {&lt;br/&gt;    atomic.AddInt32(&amp;amp;c.Id,n)&lt;br/&gt;  }&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;性能简单对比&lt;/h3&gt;&lt;p&gt;  通过跑Golang基准测试看看锁、原子变量、channel三者的性能如何，毫无疑问原子变量肯定是性能最好的，这是对底层的CAS操作连临界区都没有产生；这里主要对比锁与channel性能，三个测试函数都和下函数类似；&lt;/p&gt;&lt;pre&gt;&lt;code&gt; &lt;span&gt;func&lt;/span&gt; &lt;span&gt;BenchmarkAtomicTest&lt;/span&gt;(b *testing.B) {&lt;br/&gt;    &lt;span&gt;var&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;=&amp;amp;&lt;span&gt;Conf&lt;/span&gt;{}&lt;br/&gt;     &lt;span&gt;for&lt;/span&gt; i := 0; i&amp;lt;b.&lt;span&gt;N&lt;/span&gt;;i++  {&lt;br/&gt;       &lt;span&gt;c&lt;/span&gt;.updateOfAtomic(1)&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;  此时可以看到毫无悬念的atomic原子操作的方式性能最高，比其他两种低一个数量级，锁的方式比channel时间快了一倍，每次平均执行时间只需44.45纳秒，而channel每次需要84.12ns纳秒；当然此处的只是简单对比；&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;img data-ratio=&quot;0.3783783783783784&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/mGZDOXnuCWze9Afwt0UUyXB5Tlu84eK2YDF0sOXBN1u80sxq7A02rrt3oQZStFu9Sxx24A7HE6kc4a5fb2VOPw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;666&quot;/&gt;&lt;/p&gt;&lt;p&gt;  能用atomic时肯定是用atomic，至于锁和channel选哪个，还是要看应用场景、业务逻辑、可维护性等，总体来说两者性能差别不算太大，如果不太熟悉channel在过于复杂的业务逻辑中channel或许可读性会降低；但golang中的两个核心就是goroutine和channel；&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>470d7a8debca5f36bc82fa071462d7c8</guid>
<title>一文带你深入理解 Serializable 隔离最新技术 SSI</title>
<link>https://toutiao.io/k/akx3jo7</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;entry-inner&quot;&gt;
                                                    
&lt;p&gt;我们已经在前文了解了数据库的弱隔离以及Serializable隔离的两种技术（串行执行和两阶段锁），每个人都想用Serializable隔离，毕竟它很好的处理了各种冲突。但很多时候又被逼无奈选择弱隔离，原因也很简单，Serializable隔离好虽然好，但是性能消耗太大了，选择它就意味着选择了低的性能。所以人们一直在感叹假如有一种方法能做到Serializable隔离，性能损耗又不大的话就好了。皇天终归不负有心人，一个新的算法横空出世，它就是Serializable Snapshot isolation，简称SSI，它的优点就是能够牺牲很小的性能达到Serializable隔离的效果，这个算法是2008才出现的，不过已经被运用在PostgreSQL的版本9.1和FoundationDB中了。本文就来详细介绍一下这一最新的技术。&lt;/p&gt;



&lt;h2&gt;悲观和乐观的同步控制&lt;/h2&gt;



&lt;p&gt;我们在《&lt;a href=&quot;https://donggeitnote.com/2021/06/15/transaction-serializable-2pl/&quot;&gt;Transaction Serializable隔离之两阶段锁&lt;/a&gt;》中提到的两阶段锁其实就是一个悲观的同步控制策略：任何有可能出现冲突的数据，我们都加锁（不管是不是真的会有冲突），就有点类似多线程的编程。而《&lt;a href=&quot;https://donggeitnote.com/2021/06/13/transaction-serializable/&quot;&gt;Transaction Serializable隔离之串行执行&lt;/a&gt;》中提到的串行执行，更是把悲观做到了极致，直接变成串行的单线程编程了。&lt;/p&gt;



&lt;p&gt;相比较上面两者来说，SSI则是一种乐观的同步控制：假设所有的同步都是不产生冲突的，每个Transaction都能够互不干扰地执行，只在提交之前进行检查，假如发现了冲突，阻止提交进行重试。只有符合serializable的transaction才能够提交。&lt;/p&gt;



&lt;p&gt;其实使用悲观还是乐观的同步控制大家争论了很久，他们在不同的场景下各有其优缺点，比如说乐观的同步控制在一个经常发生冲突的系统中就会带来很糟糕的体验，毕竟你的假设不符合系统的实际情况，这样一来就会有很多重试的处理，从而加大系统的资源消耗，在一些系统资源本就解决极限的情况下反而不如悲观的同步控制，反之亦然。&lt;/p&gt;



&lt;p&gt;既然乐观同步控制不是什么新鲜的概念，SSI又有什么优势呢，正如它名字所说的，它是基于Snapshot隔离的，也就是说所有的读是从一个一直的snapshot来获取的。这就和早期别的乐观控制不同，SSI正是基于此来开发了一个算法探测Serialization的冲突从而决定哪个Transaction去abort的。&lt;/p&gt;



&lt;h2&gt;基于过时假设的决定&lt;/h2&gt;



&lt;p&gt;我们在之前的《&lt;a href=&quot;https://donggeitnote.com/2021/06/10/transaction-write-skew/&quot;&gt;Transaction弱隔离之Write Skew和Phantoms&lt;/a&gt;》中讨论过Write Skew，它的流程是一个transaction从数据库中读一些数据，检测相关的结果，然后基于结果决定做一些操作。这里的问题就是在snapshot隔离中，我们读的结果可能已经过时了，也就是说被别的transaction更新了。所以我们之前的基于结果决定做的操作可能不是我们想要的。&lt;/p&gt;



&lt;p&gt;当我们读数据的时候，其实数据库并不知道应用程序怎么使用这些数据（你可能只是显示，也可能基于读的结果做某些操作），所以为了安全，数据库一般会说假如有任何transaction改变了你查询的结果就是不valid的。所以为了提供Serializable的隔离，数据库需要能够探测到这种情况，一般怎么做呢？有两种方法：&lt;/p&gt;



&lt;ul&gt;&lt;li&gt;探测所有基于Stale MVCC object 版本的读（没有提交的写发生在这个读之前）&lt;/li&gt;&lt;li&gt;探测所有影响之前读的写操作（写发生在读之后）&lt;/li&gt;&lt;/ul&gt;



&lt;h3&gt;探测Stale MVCC读&lt;/h3&gt;



&lt;p&gt;还记得我们在《&lt;a href=&quot;https://donggeitnote.com/2021/06/06/snapshot-isolation/&quot;&gt;Snapshot的隔离和Repeatable的读&lt;/a&gt;》中提到的多版本控制吗？也就是说当一个transaction读的时候，它会忽略也没有提交的写。依然来看我们之前提到的医生值班的例子，Transaction 43开始读的时候，Transaction 42还没有提交，所以它读的时候Alice的on_call还是为true。但是在43提交的时候，42已经提交了，这就意味着提交时候其实42的修改已经生效了，也就是说43看到的内容其实已经是不对的了，这个时候就需要abort 43的操作。&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://donggeitnote.com/wp-content/uploads/2021/06/image-15.png&quot; alt=&quot;&quot; class=&quot;wp-image-734&quot; srcset=&quot;https://donggeitnote.com/wp-content/uploads/2021/06/image-15.png 624w, https://donggeitnote.com/wp-content/uploads/2021/06/image-15-300x186.png 300w&quot; sizes=&quot;(max-width: 624px) 100vw, 624px&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;实现也就很简单了，就是在提交之前会检查一下是否有任何写操作提交了，假如有了就需要abort。为什么我们等到提交的时候才检查呢？原因也很简单，因为我们其实并不知道42会对查询到的数据做什么操作，假如只是简单地读，我们完全没有必要去abort 43。这样一来我们就不会出现没有必要的abort操作了。&lt;/p&gt;



&lt;h2&gt;探测所有影响之前读的写&lt;/h2&gt;



&lt;p&gt;另外一种情况就是一个transaction修改了之前读的数据。如下图所示：&lt;/p&gt;



&lt;figure class=&quot;wp-block-image size-large&quot;&gt;&lt;img src=&quot;https://donggeitnote.com/wp-content/uploads/2021/06/image-16.png&quot; alt=&quot;&quot; class=&quot;wp-image-735&quot; srcset=&quot;https://donggeitnote.com/wp-content/uploads/2021/06/image-16.png 624w, https://donggeitnote.com/wp-content/uploads/2021/06/image-16-300x190.png 300w&quot; sizes=&quot;(max-width: 624px) 100vw, 624px&quot;/&gt;&lt;/figure&gt;



&lt;p&gt;我们在之前《&lt;a href=&quot;https://donggeitnote.com/2021/06/15/transaction-serializable-2pl/&quot;&gt;Transaction Serializable隔离之两阶段锁&lt;/a&gt;》中有提到索引区间锁的概念，这里其实使用了类似的技术，如上图所示，Transaction 42和transaction 43同时查询了Shift1234的值班医生，假如我们对Shift_id加一个索引，数据库就可以使用entry1234来记录transaction 42和43正在读这个数据（这个数据只要保存一会，当transaction结束时就可以丢掉了）。这样一来当有transaction想要写这个数据的时候，它需要取index那边看看是否有transaction正在读这个数据，这和锁有点类似，但是不是block，而是说当有问题的时候，通知那些读你们之前读的内容被修改了。&lt;/p&gt;



&lt;p&gt;在上图中，42的更新就会去查看想要的索引表，然后知道42也同时读了相应的数据，这样就会通知42去abort。&lt;/p&gt;



&lt;h2&gt;SSI的性能&lt;/h2&gt;



&lt;p&gt;和两阶段锁相比，SSI最大的优点就是它不需要等待另外一个transaction的锁。就和snapshot隔离类似，写不会block读，读也不block写。尤其是只读的transaction不需要请求任何锁，性能得到了很大的提升。&lt;/p&gt;



&lt;p&gt;和串行执行相比，SSI的性能不再局限于单CPU，我们可以利用所有可以利用的资源来提升性能。&lt;/p&gt;



&lt;p&gt;当然SSI的性能很大程度收abort的概率的影响，比如一个长时间的读或者写就会有很大概率被abort，所以一般来说SSI还是希望读写的transaction比较短。&lt;/p&gt;



&lt;h2&gt;总结&lt;/h2&gt;



&lt;p&gt;到本文我们详细介绍了Serializable隔离的三种实现，他们各有其利弊，希望通过这些文章介绍，你能够对Serializable隔离的实现有个大概的了解。&lt;/p&gt;
                                                    &lt;nav class=&quot;pagination group&quot;&gt;
                      &lt;/nav&gt;
        &lt;/div&gt;

        
        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>