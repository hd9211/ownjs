<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>ff8c596ee779d910bb850b613bf71bee</guid>
<title>用 JuiceFS 备份 Nginx 日志可以这么简单</title>
<link>https://toutiao.io/k/mqopme2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;post_content markdown&quot;&gt;&lt;p&gt;前一段，我们写了一篇讲异地备份重要性的文章，一周之后北京真的地震了，当时的时间是傍晚 6 点多一点，大部分工程师写代码正嗨的时候，地震之后就看到朋友圈里有人说感觉到地震的第一反应就是 git push，多么冰雪聪明、尽职尽责，可是你的线上数据做好备份了么？&lt;/p&gt;&lt;p&gt;在我们线上的生产环境中要备份的东西很多，各种服务日志、数据库数据、用户上传数据、代码等等。用 JuiceFS 来备份可以节省你大量时间，我们会围绕这个主题写一系列的教程，整理出一套最佳实践，方便大家。&lt;/p&gt;&lt;p&gt;今天第一篇就写写最常用的 Nginx 日志备份。&lt;/p&gt;&lt;h1 id=&quot;如何用-juicefs-备份-nginx-日志&quot;&gt;如何用 JuiceFS 备份 Nginx 日志&lt;/h1&gt;&lt;p&gt;生产环境中的 Nginx 经常作为反向代理，配置多台，用来对接后面的各种应用服务。日志主要有两类，访问日志 (access.log) 和错误日志 (error.log)。&lt;/p&gt;&lt;p&gt;日志是分散在每个 Nginx 节点的磁盘上的，每台机器自己的磁盘并不安全，而且分散的日志也难以维护和使用。所以，我们都会将日志汇总在一个更靠谱的存储系统中，一方面长期存储安全可靠，一方面也方便做分析使用。&lt;/p&gt;&lt;p&gt;在日志的存储上需要里，容量扩展性强，稳定安全，方便运维操作，价格便宜，最好按使用量付费是重点，对于存储性能的要求会低一些。目前常用的有 NFS、HDFS、对象存储等，把这些存储与 JuiceFS 做个比较：&lt;/p&gt;&lt;p&gt;说到日志的收集方式，主要有两种：&lt;strong&gt;定时收集&lt;/strong&gt; 和 &lt;strong&gt;实时收集&lt;/strong&gt;，我们在下面分别说明。JuiceFS 使用客户自己的对象存储保存文件数据，所以也自然继承了对象存储的好处，在此之上，我们提供了高性能的元数据服务和完整的 POSIX 兼容，使用上又比对象存储便利的多。&lt;/p&gt;&lt;h2 id=&quot;定时收集&quot;&gt;定时收集&lt;/h2&gt;&lt;p&gt;通常按照 小时、天，把日志拷贝到一个统一的存储点。这方面的工具集很多，我们用 Linux 默认安装的 logrotate 举例说明。&lt;/p&gt;&lt;p&gt;首先，要在 &lt;a href=&quot;https://juicefs.com&quot;&gt;JuiceFS 网站&lt;/a&gt; 注册个账号，并创建了一个文件系统，假设叫 super-backup。&lt;/p&gt;&lt;p&gt;第一步，每台机器安装 JuiceFS 客户端，挂载到 &lt;code&gt;/jfs&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;下载 JuiceFS 客户端&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -L juicefs.io/static/juicefs -o juicefs &amp;amp;&amp;amp; chmod +x juicefs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;挂载文件系统&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sudo ./juicefs mount super-backup /jfs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在自动化配置管理中使用 JuiceFS 也同样方便，具体方法请在上手指南中查看 &lt;a href=&quot;https://juicefs.io/docs/zh/getting_started.html#remember-authentication&quot;&gt;如何通过命令行认证&lt;/a&gt; 和 &lt;a href=&quot;https://juicefs.io/docs/zh/getting_started.html#mount-on-boot&quot;&gt;开机自动挂载&lt;/a&gt;，我们支持 &lt;a href=&quot;https://juicefs.io/docs/zh/getting_started.html#docker&quot;&gt;Docker 中挂载&lt;/a&gt; 和 &lt;a href=&quot;https://juicefs.io/docs/zh/use_juicefs_in_kubernetes.html&quot;&gt;Kubernates&lt;/a&gt; 中挂载。&lt;/p&gt;&lt;p&gt;第二步，在每台机器上用 logrotate 配置日志的滚动策略，修改 &lt;code&gt;/etc/logrotate.d/nginx&lt;/code&gt;&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;/var/log/nginx/*.log {
    daily    # 每天滚动一次
    compress
    dateext # 把日期添加到文件名中
    sharedscripts
    postrotate
        [ -f /var/run/nginx.pid ] &amp;amp;&amp;amp; kill -USR1 `cat /var/run/nginx.pid` # 重新加载日志文件
    endscript
    lastaction
        rsync -au *.gz /jfs/nginx-logs/`hostname -s`/ # 把压缩好的日志同步到 JuiceFS
    endscript
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;到此，Nginx 日志就可以每天 rotate 并保存到 JuiceFS 中了。增加 Nginx 节点时，只需要在新增节点上做同样的配置即可。&lt;/p&gt;&lt;p&gt;如果使用 NFS，在 logrotate 中的配置是基本一样的。但是 NFS 有几个不足之处：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;大部分 NFS 存在单点故障，而 JuiceFS 是高可用的（专业版承诺 99.95% SLA）。&lt;/li&gt;&lt;li&gt;NFS 协议传输不加密，所以你需要保证 NFS 和 Nginx 在同一个 VPC 中，如果还有其他要备份的服务，部署上就很麻烦。JuiceFS 传输有 SSL 加密，不受 VPC 限制。&lt;/li&gt;&lt;li&gt;NFS 需要事先容量规划，JuiceFS 是弹性扩容，按容量付费的，更省心，更便宜。
如果使用 HDFS 或者 对象存储，日后访问备份数据时，就比较麻烦。JuiceFS 就简单很多，比如可以直接用 &lt;code&gt;zgrep&lt;/code&gt; 查询。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;再分享几个 Tips：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;执行 &lt;code&gt;logrotate -f /etc/logrotate.d/nginx&lt;/code&gt; 立即执行对 logrotate 配置做个验证。还可以用 -d 做调试。&lt;/li&gt;&lt;li&gt;Logrotate 基于 cron 运行，无论你设置 weekly、daily 还是 hourly，具体的执行时间可以在 &lt;code&gt;/etc/crontab&lt;/code&gt; 中修改。&lt;/li&gt;&lt;li&gt;如果你觉得日志文件太多，我们还提供了 &lt;code&gt;juicefs merge&lt;/code&gt; 命令可以快速合并 gzip 压缩过的日志文件。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;说完定时汇总，下一节我们再说说日志实时收集。&lt;/p&gt;&lt;h2 id=&quot;实时收集&quot;&gt;实时收集&lt;/h2&gt;&lt;p&gt;日志的实时收集已经有了很多开源工具，常用的有 &lt;a href=&quot;https://www.elastic.co/products/logstash&quot;&gt;Logstash&lt;/a&gt;、&lt;a href=&quot;https://flume.apache.org/&quot;&gt;Flume&lt;/a&gt;、&lt;a href=&quot;https://github.com/facebookarchive/scribe&quot;&gt;Scribe&lt;/a&gt;、&lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Kafka&lt;/a&gt; 等。&lt;/p&gt;&lt;p&gt;在集群不是很大的时候，日志收集、分析、索引、展示有个全家桶方案 ELK，其中用 &lt;a href=&quot;https://www.elastic.co/products/logstash&quot;&gt;Logstash&lt;/a&gt; 做日志收集和分析。&lt;/p&gt;&lt;p&gt;需要下面的部署方式：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在每台机器上部署一个 Logstash Agent（Flume 等其他工具同理）；&lt;/li&gt;&lt;li&gt;部署一个 Logstash Central 做日志汇总；&lt;/li&gt;&lt;li&gt;部署一个 Redis 做整个服务的 Broker，目的是在日志收集和写入中间做个缓冲，避免 Central 挂了导致日志丢失；&lt;/li&gt;&lt;li&gt;然后再配置 Central 的落盘方式，将日志存储到 JuiceFS / NFS / 对象存储 / HDFS 等。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;先看看架构图：&lt;/p&gt;&lt;p&gt;这里不讲 Logstash 在收集、分析、过滤环节的配置了，网络上有很多文章可查（比如：&lt;a href=&quot;https://doc.yonyoucloud.com/doc/logstash-best-practice-cn/index.html&quot;&gt;Logstash 最佳实践&lt;/a&gt;），说一下输出环节。&lt;/p&gt;&lt;p&gt;把 Logstash 收集处理好的日志保存到 JuiceFS 只要在配置的 output 部分设置一下：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;output {
   file {
       path =&amp;gt; &quot;/jfs/nginx-logs/%{host}-%{+yyyy/MM/dd/HH}.log.gz&quot;
       message_format =&amp;gt; &quot;%{message}&quot;
       gzip =&amp;gt; true
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;存储到 NFS 也可以用上面的配置，&lt;strong&gt;缺点和上文定时收集部分提到的相同&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;如果要保存到对象存储、HDFS，需要再配置 Logstash 的第三方插件，大部分是非官方的，随着 Logstash 版本的升级，使用时可能需要折腾一下。&lt;/p&gt;&lt;h2 id=&quot;最简单的实时收集方案&quot;&gt;最简单的实时收集方案&lt;/h2&gt;&lt;p&gt;其实还有更简单的实时日志收集方法，就是直接让 Nginx 把日志输出到 JuiceFS 中，省去了维护和部署日志收集系统的麻烦。使用这个方案可能会担心 JuiceFS 出问题时影响 Nginx 的正常运行，有两方面可以帮大家减少一些顾虑：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;JuiceFS 本身是一个高可用的服务，专业版承诺 99.95%的可用性，应该跟你的数据库等服务在一个可用性级别；&lt;/li&gt;&lt;li&gt;Nginx 的日志输出是使用异步IO来实现的，即使 JuiceFS 出现暂时性的抖动，也基本不影响 Nginx 的正常运行（restart 或者 reload 可能会受影响）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;如果不喜欢运维复杂的日志收集系统，这个方案值得一试。&lt;/p&gt;&lt;h1 id=&quot;给-nginx-日志加一份异地备份&quot;&gt;给 Nginx 日志加一份异地备份&lt;/h1&gt;&lt;p&gt;定时收集和实时收集都讲完了，在 super-backup 中存储的 Nginx 日志如何做个&lt;strong&gt;异地备份&lt;/strong&gt;呢？&lt;/p&gt;&lt;p&gt;只要两步：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;去 JuiceFS 网站控制台中，访问你文件系统的设置菜单，勾选 “启动复制”，然后选择你要复制到的对象存储，保存。&lt;/li&gt;&lt;li&gt;在所有挂载 super-backup 的机器上重新挂载 super-backup 即可。之后新写入的数据会很快同步到要复制的 Bucket 中，旧的数据也会在客户端定时扫描（默认每周一次）时同步。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这样可以全自动的在另外一个对象存储中同步一份数据，有效防止单一对象存储的故障或者所在区域的灾难。&lt;/p&gt;&lt;p&gt;你一定会问：JuiceFS 挂了怎么办？元数据访问不了，光有对象存储里的数据也没用啊。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们最近发布了一个重要功能 – 兼容模式的 JuiceFS&lt;/strong&gt;，所有的文件会按原样保存在对象存储中，脱离 JuiceFS 的元数据服务，也仍然可以访问里面的文件。对于备份这类一次写入不做修改的场景适合使用。&lt;/p&gt;&lt;h1 id=&quot;后记&quot;&gt;后记&lt;/h1&gt;&lt;p&gt;上面我们详细讲解了在 JuiceFS 备份 Nginx 日志的方法，后续还会介绍如何备份 Gitlab、MySQL、MongoDB、用户上传数据等等，欢迎大家踊跃&lt;a href=&quot;mailto:success@juicedata.io&quot;&gt;提需求和投稿&lt;/a&gt;。&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>7e713fec1368de203559b85cdfebc4c2</guid>
<title>快手实时数仓建设实践</title>
<link>https://toutiao.io/k/21bsuqp</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;a class=&quot;weui-flex original_primary_card appmsg_card_context wx_tap_card js_wx_tap_highlight&quot; href=&quot;#&quot; id=&quot;copyright_info&quot;&gt;
                                
                                &lt;div class=&quot;weui-flex__item&quot; role=&quot;option&quot;&gt;
                                    &lt;strong class=&quot;original_primary_nickname&quot;&gt;Apache Flink&lt;/strong&gt;
                                                                            &lt;span class=&quot;weui-hidden_abs&quot;&gt;.&lt;/span&gt;
                                        &lt;p class=&quot;original_primary_desc&quot;&gt;Flink 中文社区官微，Flink PMC 维护&lt;/p&gt;
                                                                    &lt;/div&gt;
                                &lt;p class=&quot;weui-flex__ft&quot;/&gt;
                            &lt;/a&gt;
                        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>71718c23052e15e48f95825864043e77</guid>
<title>基于 Kafka 的实时数仓在搜索的实践应用</title>
<link>https://toutiao.io/k/tynr8z3</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;24&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;作者：vivo互联网服务器团队-Deng jie&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;一、概述&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Apache Kafka 发展至今，已经是一个很成熟的消息队列组件了，也是大数据生态圈中不可或缺的一员。Apache Kafka 社区非常的活跃，通过社区成员不断的贡献代码和迭代项目，使得 Apache Kafka 功能越发丰富、性能越发稳定，成为企业大数据技术架构解决方案中重要的一环。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Apache Kafka 作为一个热门消息队列中间件，具备高效可靠的消息处理能力，且拥有非常广泛的应用领域。那么，今天就来聊一聊基于 Kafka 的实时数仓在搜索的实践应用。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;二、为什么需要 Kafka&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;在设计大数据技术架构之前，通常会做一些技术调研。我们会去思考一下为什么需要 Kafka？怎么判断选择的 Kafka 技术能否满足当前的技术要求？&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;2.1 早期的数据架构&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;早期的数据类型比较简单，业务架构也比较简单，就是将需要的数据存储下来。比如将游戏类的数据存储到数据库（MySQL、Oracle）。但是，随着业务的增量，存储的数据类型也随之增加了，然后我们需要使用的大数据集群，利用数据仓库来将这些数据进行分类存储，如下图所示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;236&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.4087301587301587&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHbOv5Z4kzKJ5SDEUUDn19fWLNAA10OJYLj32wTop6y31s1xhha8Q6Pg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;756&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;但是，数据仓库存储数据是有时延的，通常时延为T+1。而现在的数据服务对象对时延要求均有很高的要求，例如物联网、微服务、移动端APP等等，皆需要实时处理这些数据。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;2.2 Kafka 的出现&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Kafka 的出现，给日益增长的复杂业务，提供了新的存储方案。将各种复杂的业务数据统一存储到 Kafka 里面，然后在通过 Kafka 做数据分流。如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;268&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.46365914786967416&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHic6iaIbZg6bfmdoiap8VYiaM2WSqJK0y5y7icM2mqNIDXAFG3SkS8lLxVeg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1197&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;这里，可以将视频、游戏、音乐等不同类型的数据统一存储到 Kafka 里面，然后在通过流处理对 Kafka 里面的数据做分流操作。例如，将数据存储到数据仓库、将计算的结果存储到KV做实时分析等。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通常消息系统常见的有两种，它们分别是：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这两种方式都是有效和实用的，通过消息队列将工作内容分开，用于容错和扩展；生产和消费能够允许多租户，来使得系统解耦。而 Apache Kafka 的优点之一在于它将消息队列、生产和消费结合到了一个强大的消息系统当中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同时，Kafka 拥有正确的消息处理特性，主要体现在以下几个方面：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;：当 Kafka 的性能（如存储、吞吐等）达到瓶颈时，可以通过水平扩展来提升性能；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;真实存储&lt;/strong&gt;：Kafka 的数据是实时落地在磁盘上的，不会因为集群重启或故障而丢失数据；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;实时处理&lt;/strong&gt;：能够集成主流的计算引擎（如Flink、Spark等），对数据进行实时处理；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;顺序写入&lt;/strong&gt;：磁盘顺序 I/O 读写，跳过磁头“寻址”时间，提高读写速度；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;内存映射&lt;/strong&gt;：操作系统分页存储利用内存提升 I/O 性能，实现文件到内存的映射，通过同步或者异步来控制 Flush；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;零拷贝&lt;/strong&gt;：将磁盘文件的数据复制到“页面缓存”一次，然后将数据从“页面缓存”直接发送到网络；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;高效存储&lt;/strong&gt;：Topic 和 Partition 拆为多个文件片段（Segment），定期清理无效文件。采用稀疏存储，间隔若干字节建立一条索引，防止索引文件过大。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;2.3 简单的应用场景&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;这里，我们可以通过一个简单直观的应用场景，来了解 Kafka 的用途。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;场景：假如用户A正在玩一款游戏，某一天用户A喜欢上了游戏里面的一款道具，打算购买，于是在当天 14:00 时充值了 10 元，在逛游戏商店时又喜欢上了另一款道具，于是在 14:30 时又充值了 30 元，接着在 15:00 时开始下单购买，花费了 20 元，剩余金额为 20 元。那么，整个事件流，对应到库表里面的数据明细应该是如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;226&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.3911792905081496&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXH4nFeKsqKQiccyeQpkia4QPGDwKusmCtGyumzOzBsb9jRBVsbic4FmfW7w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1043&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;三、Kafka解决了什么问题&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;早期为响应项目快速上线，在服务器或者云服务器上部署一个 WebServer，为个人电脑或者移动用户提供访问体验，然后后台在对接一个数据库，为 Web 应用提供数据持久化以及数据查询，流程如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;397&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.6862275449101797&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHMenfH7gmQlsxqdBYEwPKDcNcYNBMX9cjicibAMV8mXYFkcu3p6SoCVibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;835&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;但是，随着用户的迅速增长，用户所有的访问都直接通过 SQL 数据库使得它不堪重负，数据库的压力也越来越大，不得不加上缓存服务以降低 SQL 数据库的荷载。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同时，为了理解用户行为，又开始收集日志并保存到 Hadoop 这样的大数据集群上做离线处理，并且把日志放在全文检索系统（比如 ElasticSearch）中以便快速定位问题。由于需要给投资方看业务状况，也需要把数据汇总到数据仓库（比如 Hive）中以便提供交互式报表。此时的系统架构已经具有一定的复杂性了，将来可能还会加入实时模块以及外部数据交互。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;本质上，这是一个数据集成问题。没有任何一个系统能够解决所有的事情，所以业务数据根据不同用途，存放在不同的系统，比如归档、分析、搜索、缓存等。数据冗余本身没有任何问题，但是不同系统之间太过复杂的数据同步却是一种挑战。如下图所示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7608142493638677&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHnIKbtOuMHcHSGMOQKpqDKGagQqPgXU7rlayMuTjT8zgO2NYBjyqAfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;786&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;而 Kafka 可以让合适的数据以合适的形式出现在合适的地方。Kafka 的做法是提供消息队列，让生产者向队列的末尾添加数据，让多个消费者从队列里面依次读取数据然后自行处理。如果说之前连接的复杂度是 O(N^2)，那么现在复杂度降低到了 O(N)，扩展起来也方便多了，流程如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.665083135391924&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHpLYwqQgw7XcJaCT2NRIpZp44aibJic25p7tsTQM3jgWzE3NCcpNxHH8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;842&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;四、Kafka的实践应用&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.1 为什么需要建设实时数仓&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;4.1.1 目的&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通常情况下，在大数据场景中，存储海量数据建设数据仓库一般都是离线数仓（时延T+1），通过定时任务每天拉取增量数据，然后创建各个业务不同维度的数据，对外提供 T+1 的数据服务。计算和数据的实时性均比较差，业务人员无法根据自己的即时性需求获取几分钟之前的实时数据。数据本身的价值随着时间的流逝会逐步减弱，因此数据产生后必须尽快的到达用户的手中，实时数仓的建设需求由此而来。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;4.1.2 目标&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了适应业务高速迭代的特点，分析用户行为，挖掘用户价值，提高用户留存，在实时数据可用性、可扩展性、易用性、以及准确性等方面提供更好的支持，因此需要建设实时数仓。主要目标包含如下所示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.2 如何构建实时数仓为搜索提供数据&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;当前实时数仓比较主流的架构一般来说包含三个大的模块，它们分别是消息队列、计算引擎、以及存储。结合上述对 Kafka 的综合分析，结合搜索的业务场景，引入 Kafka 作为消息队列，复用大数据平台（BDSP）的能力作为计算引擎和存储，具体架构如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6093591047812817&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHO9AIzIshksuN2x0BgtLibhZGbxn1PM4ut8GFJotl2BbeK8hGcGjwgSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;983&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.3 流处理引擎选择&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;目前业界比较通用的流处理引擎主要有两种，它们分别是Flink和Spark，那么如何选择流处理引擎呢？我们可以对比以下特征来决定选择哪一种流处理引擎？&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;254&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.43867243867243866&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHcK5QeNJ0xfHiagfMTCPCfYwzXZIpgDvFntRY1dOicfTpeaicAlOEjCl9Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;693&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Flink作为一款开源的大数据流式计算引擎，它同时支持流批一体，引入Flink作为实时数仓建设的流引擎的主要原因如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;高吞吐、低延时；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;灵活的流窗口；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;轻量级容错机制；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;流批一体&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.4 建设实时数仓遇到的问题&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;在建设初期，用于实时处理的 Kafka 集群规模较小，单个 Topic 的数据容量非常大，不同的实时任务都会消费同一个大数据量的 Topic，这样会导致 Kafka 集群的 I/O 压力非常的大。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此，在使用的过程中会发现 Kafka 的压力非常大，经常出现延时、I/O能性能告警。因此，我们采取了将大数据量的单 Topic 进行实时分发来解决这种问题，基于 Flink 设计了如下图所示的数据分发流程。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHIiaMdoXuGZDJicfvKernZ29sXNxggwCOX3cia7ukKUamUVcUnAJMWu2og/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;上述流程，随着业务类型和数据量的增加，又会面临新的问题：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.5 实时数仓方案进阶&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;目前，主流的实时数仓架构通常有2种，它们分别是Lambda、Kappa。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.5.1 Lambda&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着实时性需求的提出，为了快速计算一些实时指标（比如，实时点击、曝光等），会在离线数仓大数据架构的基础上增加一个实时计算的链路，并对消息队列实现数据来源的流失处理，通过消费消息队列中的数据 ，用流计算引擎来实现指标的增量计算，并推送到下游的数据服务中去，由下游数据服务层完成离线和实时结果的汇总。具体流程如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHx8YkTBU4u1OJF482vyfXbnob0c5rQ79cY6MDSq3P9GUVo80Hjtl2Pg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;4.5.2 Kappa&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Kappa架构只关心流式计算，数据以流的方式写入到 Kafka ，然后通过 Flink 这类实时计算引擎将计算结果存放到数据服务层以供查询。可以看作是在Lambda架构的基础上简化了离线数仓的部分。具体流程如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXH2f7SsJ4bCU8FULRMLkibn56SCHB4ue2ka4H5Br3GxIAO3HWKibgvBNNw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;在实际建设实时数仓的过程中，我们结合这2种架构的思想来使用。实时数仓引入了类似于离线数仓的分层理念，主要是为了提供模型的复用率，同时也要考虑易用性、一致性、以及计算的成本。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;4.5.3 实时数仓分层&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;在进阶建设实时数仓时，分层架构的设计并不会像离线数仓那边复杂，这是为了避免数据计算链路过长造成不必要的延时情况。具体流程图如下所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHtZDYvXiam5DkkyF8Ka5AYV5ILw3iaibDrOl3R78yxsRZMsPRLa0K3MopQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;ODS层&lt;/strong&gt;：以Kafka 作为消息队列，将所有需要实时计算处理的数据放到对应的 Topic 进行处理；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;DW层&lt;/strong&gt;：通过Flink实时消费Topic中的数据，然后通过数据清理、多维度关联（JOIN）等，将一些相同维度的业务系统、维表中的特征属性进行关联，提供数据易用性和复用性能力，最终得到实时明细数据；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;DIM层&lt;/strong&gt;：用来存储关联的查询的维度信息，存储介质可以按需选择，比如HBase、Redis、MySQL等；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;DA层&lt;/strong&gt;：针对实时数据场景需求，进行高度聚合汇总，服务于KV、BI等场景。OLAP分析可以使用ClickHouse，KV可以选择HBase（若数据量较小，可以采用Redis）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;通过上面的流程，建设实时数仓分层时，确保了对实时计算要求比较高的任务不会影响到BI报表、或者KV查询。但是，会有新的问题需要解决：&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;27&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;p&gt;Kafka 实时数据如何点查？&lt;/p&gt;&lt;p&gt;消费任务异常时如何分析？&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.5.4 Kafka监控&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;针对这些问题，我们调研和引入了Kafka 监控系统——Kafka Eagle（目前改名为EFAK）。复用该监控系统中比较重要的维度监控功能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Kafka Eagle处理能够满足上诉两个维度的监控需求之外，还提供了一些日常比较实用的功能，比如Topic记录查看、Topic容量查看、消费和生产任务的速率、消费积压等。我们采用了 Kafka-Eagle 来作为对实时数仓的任务监控。Kafka-Eagle 系统设计架构如下图所示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;371&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.6418242491657397&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHRvfaYYemEfaSVLc950FHtpdyCicoY3w3PyQXBcuj0XZHDPdnDt6yNbA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;899&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Kafka-Eagle 是一款完全开源的对 Kafka 集群及应用做全面监控的系统，其核心由以下几个部分组成：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据采集&lt;/strong&gt;：核心数据来源 JMX 和 API 获取；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据存储&lt;/strong&gt;：支持 MySQL 和 Sqlite 存储；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据展示&lt;/strong&gt;：消费者应用、图表趋势监控（包括集群状态、消费生产速率、消费积压等）、开发的分布式 KSQL 查询引擎，通过 KSQL 消息查询；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据告警&lt;/strong&gt;：支持常用的 IM 告警（微信，钉钉，WebHook等），同时邮件、短信、电话告警也一并支持。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;部分预览截图如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;1）Topic最近7天写入量分布&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;默认展示所有Topic的每天写入总量分布，可选择时间维度、Topic聚合维度，来查看写入量的分布情况，预览截图如下所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;180&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.3109375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHe04uicakXl7dMv5fhCria3r50nFGkyHwRDbSqYkTe3pPLfASRhddJHYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;2）KSQL查询Topic消息记录&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;可以通过编写SQL语句，来查询（支持过滤条件）Topic中的消息记录，预览截图如下所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;315&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5453125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHUib0icea9QCd0zvzGZBsO0hUv9Mo4UEGUslGOHwreNV8O3uBpPXL3CqA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;3）消费Topic积压详情&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;可以监控所有被消费的Topic的消费速率、消费积压等详情，预览截图如下所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;264&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.45703125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHeBicJxLicdUj8qeKSj9KJGN5gMGEBJSBMiaS5G1qOVN5S19e4WXCYanYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;五、参考资料&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://kafka.apache.org/documentation/&quot; textvalue=&quot;https://kafka.apache.org/documentation/&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;1.https://kafka.apache.org/documentation/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;2.&lt;a target=&quot;_blank&quot; href=&quot;http://www.kafka-eagle.org/&quot; textvalue=&quot;http://www.kafka-eagle.org/&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;http://www.kafka-eagle.org/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;3.&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/smartloli/EFAK&quot; textvalue=&quot;https://github.com/smartloli/kafka-eagle&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;https://github.com/smartloli/kafka-eagle&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;END&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span title=&quot;&quot; opera-tn-ra-cell=&quot;_$.pages:0.layers:0.comps:119.title1&quot;&gt;&lt;p&gt;猜你喜欢&lt;/p&gt;&lt;/span&gt; &lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>242c08229b14d10b5b8bca413c2f029a</guid>
<title>《Rust 编码规范》</title>
<link>https://toutiao.io/k/injccgg</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;weui-dialog&quot;&gt;
      &lt;p class=&quot;weui-dialog__hd&quot;&gt;&lt;strong class=&quot;weui-dialog__title&quot;&gt;&quot;Top Stories&quot; is disabled&lt;/strong&gt;&lt;/p&gt;
      &lt;p class=&quot;weui-dialog__bd&quot;&gt;
        Enable &quot;Top Stories&quot; in &quot;Settings&quot; &amp;gt; &quot;General&quot; &amp;gt; &quot;Manage Discover&quot;      &lt;/p&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4141754e0724c878fe1751a73617ed61</guid>
<title>GitHub 上只卖 5 美元的脚本，却给我带来了一年数十万元报酬</title>
<link>https://toutiao.io/k/l44ffjj</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;&lt;span&gt;“一年多之前我把工作‘自动化’了，没有告诉任何人。”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;日前 Reddit 一个关于“利用自动化程序完成工作”的帖子迅速走红，收获八万多个赞，以及超 5000 条评论。作者是一名服务于律所的程序员，他通过脚本程序将自己的工作变成自动化处理，于是每天只需工作 10 分钟，就能赚取“接近 9 万（美元）”的年薪，他在帖子中简要分享了自己的工作。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;每天只在办公桌前待 10 分钟&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;根据帖子，该程序员受雇于一家中等规模的律师事务所，职位是 IT 专家，主要处理所有用于审判的电子证据。目前律所正在将证据管理系统更改为基于云的系统，并希望这名程序员是唯一拥有云管理员访问权限的人，其他人只有查看权限并在本地网络驱动器上工作。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;问题是，律所给的这唯一任务并不需要 8 小时来完成，于是在新冠肺炎疫情之前，这位 IT 专家大部分时间都被“困”在办公室里假装工作，而疫情发生后，远程工作模式开启，“摸鱼”空间就大幅增加了。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;他花了约一周时间，编写、调试和完善一个简单的脚本去完成自己的工作。这个脚本扫描本地驱动器来查找新的文件，为它们生成哈希值，将它们传输到云上，然后再次生成哈希值以确保真实性（在法庭上，必须证明电子证据没有被篡改）。然后，他只需每天打卡上班，其他时间就玩玩游戏或想做什么就做什么，下班的时候检查日志以确保一切顺利，然后打卡下班。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如此一来，实际上他每天只在办公桌前待 10 分钟。“有一段时间我感到内疚，好像有种在敲诈律师事务所的感觉，但最终我说服自己，只要每个人都开心，就没有伤害。我正在做他们雇我做的事，所有的工作都按时完成，我开始享受我的生活。”&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;怎么做到的？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在贴子发出后的这十多天内，作者更新了 2 次帖子，以回复网友问得最多的问题，比如，报酬是多少？答案是近 9 万美元。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;还比如，为什么律所会认为这是一份需要每天用 8 小时处理的工作？他回答道：“在他们雇用我之前，他们一直在努力跟上事情的发展。员工在一天结束时提交他们放置在本地驱动器上的所有文件的电子表格。然后管理员将检查电子表格并手动将文件夹 / 文件拖放到云端。我仍然每天都会收到电子表格，用它来验证我的日志。”&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;虽然有人觉得作者这是懒惰、甚至在浪费生命，但他不觉得自己是这样的人，他说自己另外有做一个出于热情的项目，而不是说白天就只躺着玩游戏。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;那又为什么感到内疚呢，作者回答说也许是因为这些人都是律师。“我不讨厌我的老板。他实际上非常好，尽管根本不精通技术。我实际上并没有与律师一起工作或见律师，我属于行政管理，因为他们没有 IT 部门。”&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;至于使用什么代码语言，以及怎么能做到这一点？作者回复道，“部分批处理文件执行用的 PowerShell 脚本。基本代码非常简单，其中大部分来自谷歌搜索‘批处理文件传输’（.bat transfer files）之类的内容，例如‘如何批处理传输某些类型的文件’等等。诀窍在于让脚本能适用于我们办公室，知道在哪里扫描新的文件，知道哪里是因为滞后而不能扫描的位置（讲真，如果你有一个包含 200000 个 .txt 文件的文件夹，那么一些垃圾会大大降低扫描速度。这时候最好手动操作，然后更改脚本以在以后的搜索中忽略该文件夹。）”&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;有人问作者为什么不卖掉脚本然后大赚一笔，他坦言这不是价值数百万美元的高端程序。这是用记事本编写的几行代码。它目前在这所律所里发挥价值，是因为这里的人都没有技术技能，“这只能放在 GitHub 上然后卖个 5 美元。”&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;另外，有网友质疑其真实性，因为觉得“不可能这么简单”。对此，作者回应称确实没那么简单——“脚本中涉及更多步骤，它执行我没有在这里讨论的功能。讨论这些功能更有可能泄露我的坐标。但脚本的核心，传输和哈希等等都是真实的。而所采取的针对我所在办公室的额外步骤的内容，我都省略了。”&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;当你用程序代替自己工作，需要告诉老板吗？&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在律所程序员的帖子下面，有 Reddit 用户提到通过程序自动化工作是个趋势，并可能会影响他们的下一个就业决定。“我觉得所有这些类型的帖子教会我的是我需要 1)学习如何编码和 2) 找到一份悠闲的办公室工作。”&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;获得最多赞同的第一热评则说，“将你的工资看成是自动化程序的订阅服务，哈哈。大公司都喜欢订阅服务吧。”&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;但也正如帖子里提到的，近年来，类似的例子并不少见。2016 年 Reddit 上也有一个程序员分享说自己在过去 6 年内实际工作时间可能只有 50 个小时，因为入职 8 个月后就把全部工作自动化了。第六年老板意识到这个事情后，就把他解雇了。最终主角不仅删除了分享帖，也删除了整个账户。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;大概一年后，又一个名为 Etherable 的人在 Stack Exchange 上提了一个问题: “我不告诉我的雇主我的工作已经自动化了，这是不是不道德? ”——这位程序员接受了一份“美化数据录入”的工作，并且 6 个月前编写了脚本让工作可以自动化处理，原本 1 个人需要 1 个月完成的工作，最后变成只需 10 分钟。这份工作是全职且有福利，也允许 Etherable 在家办公。但 Etherable 隐约觉得自己做得不太对，他每隔一周就告诉公司自己完成部分工作，甚至会特意在里面加入少量错误，然后让同事测试，以让工作看起来更像是人工处理的。总的来说他每星期只需要工作一两个小时，但领的是全职薪酬。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;当时评论如潮，但呈现两极化，有认为 Etherable 出售的不是每星期 40 小时的数据输入工作，而是“处理 X 张试算表”的结果，因此以自动化程序处理并非不道德，但刻意加入错误去掩饰这是不诚实的行为，有可能会损害公司利益，因此可以不必告诉公司自动化程序的事情，但不能不诚实。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;而持相反意见的则认为 Etherable 只工作一两小时却收了 40 小时的薪水，每星期都谎报自己完成的工作，刻意加入错误欺骗公司并令同事还要花时间确认其工作等等，这已经是不道德的行为。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;相比之下，Etherable 的例子似乎会复杂些，因为他还有刻意犯错的行为。不过本质上，不管是 Etherable 还是其他人，这些将工作自动化的程序员或许更想知道的是：如何确保自己的饭碗安全？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;参考链接：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>