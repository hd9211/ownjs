<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>300d4735d3a0c4edeefa6fabbb91dfa3</guid>
<title>双非渣本后端三个月逆袭字节</title>
<link>https://toutiao.io/k/faz5prg</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;post-topic-des nc-post-content&quot;&gt;
&lt;h2 id=&quot;个人背景介绍&quot;&gt;个人背景介绍&lt;/h2&gt; 
&lt;p&gt;2017年毕业于一所不知名双非本科大学，毕业时就有着一颗想进大厂的心，但又想留在成都，不愿意去北上广，现在其实相当后悔。当年在成都的大厂少之又少，再加上校招时非常努力地玩耍，导致投的几个大厂面试都全部挂掉。也错失了进大厂最好的机会，所以我奉劝大三的同学如果对自己的职业有追求，有进大厂的梦想，在大三的时候一定要好好准备，在校招的时候拿offer。&lt;br/&gt;&lt;span&gt;最后我在成都一家本地科技公司做了Java开发，中间也跳过一次槽，也是做的Java。但这几年时间里总感觉公司能给的成长太慢，虽然自己也在学习，还是免不了焦虑，特别是像自己这种学历和公司背景都一般的程序员，要保证自己以后不被淘汰，必须得做点什么。所以在听到一个前同事被公司裁掉，最后进入大厂这个事情之后，彻底点燃了我心中想进大厂的那把火，我也准备内推试试&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8&quot; target=&quot;_blank&quot;&gt;字节跳动&lt;/a&gt;。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;因为疫情原因，很多企业生存困难。我也保持了理智，没有辞职进行面试。而是给自己制定了学习计划，不得不说，在职的情况下复习确实很难，因为可能加班打乱计划。于是我把所有能利用的个人时间全部利用了起来，比如早上十点上班，我六点钟就会起床，刷两个小时LeetCode，八点钟洗漱之后去上班。晚上如果有时间就会把早上刷过的题拿出来继续复习，花了两个月的时间，一边复习（预习）数据结构，一边做题，LeetCode上面的高频题基本都过了一遍。花了那么多时间&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%88%B7%E9%A2%98&quot; target=&quot;_blank&quot;&gt;刷题&lt;/a&gt;，都是因为自己&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;太菜，以前没有进行专门的练习。题做得差不多之后，就开始复习专业知识了，具体内容我都会总结出来。前前后后准备了三个月，我才敢进行内推，经历了八次面试之后，面试时间又持续三个月，皇天不负有心人，终于在这个月等到了oc。&lt;/span&gt;&lt;br/&gt;下面是面试内容，时间太久了，可能记得不太全，但基本上包含了所有问题，白天上班，我都是选择晚上进行面试，哈哈&lt;/p&gt; 
&lt;h2 id=&quot;一面a部门&quot;&gt;一面A部门&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;讲&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A1%B9%E7%9B%AE&quot; target=&quot;_blank&quot;&gt;项目&lt;/a&gt;，串起来讲，可能遇到的问题，怎么解决，怎么实现，讲了发送客服消息&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;Spring里面的bean怎么回事&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;HashMap和ConcurrentHashMap，HashMap中的&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%BA%A2%E9%BB%91%E6%A0%91&quot; target=&quot;_blank&quot;&gt;红黑树&lt;/a&gt;，两者rehash的区别&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;Mysql的一致性是什么，数据库redolog，undo log，MySQL的索引结构，为什么二级索引叶子节点不能直接存储行数据的指针，这样可以不回表，怎么考虑的？&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=redis&quot; target=&quot;_blank&quot;&gt;redis&lt;/a&gt;里面的zset，跳表怎么实现，怎么增删，&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=redis&quot; target=&quot;_blank&quot;&gt;redis&lt;/a&gt;是怎么rehash的&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;，&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E4%BA%8C%E5%8F%89%E6%A0%91&quot; target=&quot;_blank&quot;&gt;二叉树&lt;/a&gt;转双向&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%93%BE%E8%A1%A8&quot; target=&quot;_blank&quot;&gt;链表&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2 id=&quot;二面a部门&quot;&gt;二面A部门&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;自我介绍&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;再一次聊&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A1%B9%E7%9B%AE&quot; target=&quot;_blank&quot;&gt;项目&lt;/a&gt;，功能，架构，角色，量级&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;Spring里面有哪些设计模式&lt;/li&gt; 
 &lt;li&gt;SpringMVC和SpringBoot有什么区别&lt;/li&gt; 
 &lt;li&gt;SpringBoot的自动配置是怎么实现的&lt;/li&gt; 
 &lt;li&gt;刚刚你说了线程池，你线程池是用的什么，参数有哪些，为什么这么设置 &lt;/li&gt; 
 &lt;li&gt;线程池核心线程满了怎么办，里面的阻塞队列是干什么的&lt;/li&gt; 
 &lt;li&gt;说说ThreadLocal是什么&lt;/li&gt; 
 &lt;li&gt;CAP理论知道吗，为什么不能同时满足&lt;/li&gt; 
 &lt;li&gt;Redis里面的数据结构有什么场景&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;Redis怎么实现锁（&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=redis&quot; target=&quot;_blank&quot;&gt;redis&lt;/a&gt;锁的所有坑都说了一遍）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;分布式事务知道吗，有哪些方案（说了2PC，3PC，TCC，MQ）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95%E9%A2%98&quot; target=&quot;_blank&quot;&gt;算法题&lt;/a&gt;，&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%A0%91%E7%9A%84%E7%9B%B4%E5%BE%84&quot; target=&quot;_blank&quot;&gt;树的直径&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;有什么要问我的&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2 id=&quot;三面a部门&quot;&gt;三面A部门&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;介绍&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A1%B9%E7%9B%AE&quot; target=&quot;_blank&quot;&gt;项目&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;场景题，设计一个朋友圈，读QPS 1000w，写QPS 10w&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95%E9%A2%98&quot; target=&quot;_blank&quot;&gt;算法题&lt;/a&gt;LFU&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;你有什么问题&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;这个面试官是个leader，比较强势，很多细节回答的不是很好，所以脸色一直不好，给人压力较大，面完就觉得凉了。果然面完之后和前两次不一样，HR那里就没有任何通知了，到这里还是很失落，准备了那么久，因为最后一面没表现好导致挂掉。之后等了一个月，这一个月没有任何消息，一个月过后又接到字节HR的电话，说我之前两面面评都不错，让我试试他们部门，我就同意了。&lt;/p&gt; 
&lt;h2 id=&quot;一面b部门&quot;&gt;一面B部门&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;介绍&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A1%B9%E7%9B%AE&quot; target=&quot;_blank&quot;&gt;项目&lt;/a&gt;，细节&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;怎么做服务拆分，边界怎么划分的&lt;/li&gt; 
 &lt;li&gt;分布式之后会遇到什么问题，CAP的各个情况介绍一下&lt;/li&gt; 
 &lt;li&gt;dubbo调用过程是怎样的，PB知道吗&lt;/li&gt; 
 &lt;li&gt;thrift了解过吗&lt;/li&gt; 
 &lt;li&gt;zk介绍一下，有哪些节点类型，特点&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;怎么知道&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A1%B9%E7%9B%AE&quot; target=&quot;_blank&quot;&gt;项目&lt;/a&gt;中接口的重要性，怎么做监控，你说的自动化测试是怎么做到的（这个问题回答完，他笑了。。。）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;你所理解的SLA是什么，要达到什么等级&lt;/li&gt; 
 &lt;li&gt;说说你理解的k8s&lt;/li&gt; 
 &lt;li&gt;nginx的upstream是干什么的&lt;/li&gt; 
 &lt;li&gt;nginx有哪些负载均衡策略&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95%E9%A2%98&quot; target=&quot;_blank&quot;&gt;算法题&lt;/a&gt;：&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E5%B2%9B%E5%B1%BF%E6%95%B0%E9%87%8F&quot; target=&quot;_blank&quot;&gt;岛屿数量&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;你有什么问题要问我&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2 id=&quot;二面b部门&quot;&gt;二面B部门&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;介绍&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A1%B9%E7%9B%AE&quot; target=&quot;_blank&quot;&gt;项目&lt;/a&gt;，细节&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;锁有哪些实现方式&lt;/li&gt; 
 &lt;li&gt;分布式锁的实现方式&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;JVM的内存模型，垃圾回收&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;MySQL的事务介绍，ACID的实现原理是什么（想问MySQL的日志）&lt;/li&gt; 
 &lt;li&gt;HashMap的原理，其他线程安全的Map&lt;/li&gt; 
 &lt;li&gt;Redis的高可用，有哪些持久化方式&lt;/li&gt; 
 &lt;li&gt;Redis的数据结构，线程模型&lt;/li&gt; 
 &lt;li&gt;用过什么消息队列，有什么特点&lt;/li&gt; 
 &lt;li&gt;怎么保证消息幂等消费&lt;/li&gt; 
 &lt;li&gt;docker的网络模式&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95%E9%A2%98&quot; target=&quot;_blank&quot;&gt;算法题&lt;/a&gt;：&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%AF%94%E8%BE%83%E7%89%88%E6%9C%AC%E5%8F%B7&quot; target=&quot;_blank&quot;&gt;比较版本号&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;提问&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2 id=&quot;三面b部门（交叉面）&quot;&gt;三面B部门（交叉面）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;介绍&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A1%B9%E7%9B%AE&quot; target=&quot;_blank&quot;&gt;项目&lt;/a&gt;，细节&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;Linux的内存管理&lt;/li&gt; 
 &lt;li&gt;浏览器打开一个网站的过程中会经历哪些网络处理，DNS的具体过程是啥&lt;/li&gt; 
 &lt;li&gt;zk是什么分布式模型（想问的CAP定理），主从怎么做选举&lt;/li&gt; 
 &lt;li&gt;zk只有一个主节点，写性能不高，zk怎么解决的&lt;/li&gt; 
 &lt;li&gt;etcd或consul知道吗&lt;/li&gt; 
 &lt;li&gt;多个服务中如何快速排查问题&lt;/li&gt; 
 &lt;li&gt;Redis中的淘汰方式有哪些，Redis性能高的原因是啥&lt;/li&gt; 
 &lt;li&gt;docker的实现原理&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95%E9%A2%98&quot; target=&quot;_blank&quot;&gt;算法题&lt;/a&gt;：相交&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%93%BE%E8%A1%A8&quot; target=&quot;_blank&quot;&gt;链表&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2 id=&quot;四面b部门-（leader面）&quot;&gt;四面B部门 （leader面）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;span&gt;介绍&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A1%B9%E7%9B%AE&quot; target=&quot;_blank&quot;&gt;项目&lt;/a&gt;，细节&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%A1%B9%E7%9B%AE&quot; target=&quot;_blank&quot;&gt;项目&lt;/a&gt;量级多大，QPS最高的接口是怎么做的&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;rpc怎么实现服务发现&lt;/li&gt; 
 &lt;li&gt;zk中的watch机制是怎么实现的&lt;/li&gt; 
 &lt;li&gt;分布式锁有哪些实现，MySQL，zk，Redis都说了一遍，并且分析了各自的优缺点，这个问题问的频率太高了&lt;/li&gt; 
 &lt;li&gt;怎么提高数据库读写性能&lt;/li&gt; 
 &lt;li&gt;k8s了解吗&lt;/li&gt; 
 &lt;li&gt;servicemesh有做过吗&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2 id=&quot;五面b部门（hr面）&quot;&gt;五面B部门（HR面）&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;离职原因&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E8%81%8C%E4%B8%9A%E8%A7%84%E5%88%92&quot; target=&quot;_blank&quot;&gt;职业规划&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;期望薪资&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2 id=&quot;基础知识&quot;&gt;基础知识&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;常用集合、数据结构（数据增删改查操作的原理具体实现、各参数的含义，以及如何组合使用）&lt;/li&gt; 
 &lt;li&gt;Java的语法，OO的思想要熟悉，常用设计模式要知道场景&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;JVM内存模型，垃圾回收&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;，垃圾收集器的区别，GC调优&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;线程模型&lt;/li&gt; 
 &lt;li&gt;IO模型（包括操作系统底层IO模型和常见BIO、NIO、AIO、IO多路复用的原理）&lt;/li&gt; 
 &lt;li&gt;Redis（数据结构的内部实现、淘汰原理策略、持久化、集群、扩容、数据同步、以及一些常见缓存问题的解决方案）&lt;/li&gt; 
 &lt;li&gt;MySQL（索引原理，查询优化，三大日志）&lt;/li&gt; 
 &lt;li&gt;消息队列（内部原理，常见消息问题解决方案）&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;分布式原理、&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;、rpc原理（paxos、raft、zoo&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=keep&quot; target=&quot;_blank&quot;&gt;keep&lt;/a&gt;er的原理）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;分布式场景题（高可用，高性能相关）&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2 id=&quot;其他知识&quot;&gt;其他知识&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;位运算&lt;/li&gt; 
 &lt;li&gt;大数据量操作（在有限时间内完成、在有限空间内完成）&lt;/li&gt; 
 &lt;li&gt;设计题（看一些常见的分布式ID、分布式计数服务等等）&lt;/li&gt; 
&lt;/ol&gt; 
 
&lt;ol&gt; 
 &lt;li&gt;数组&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E9%93%BE%E8%A1%A8&quot; target=&quot;_blank&quot;&gt;链表&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;位运算&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E4%BA%8C%E5%8F%89%E6%A0%91&quot; target=&quot;_blank&quot;&gt;二叉树&lt;/a&gt;（dfs，bfs，相当重要，只要会了&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E4%BA%8C%E5%8F%89%E6%A0%91&quot; target=&quot;_blank&quot;&gt;二叉树&lt;/a&gt;，回溯那些&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot;&gt;算法&lt;/a&gt;也会了）&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;设计题&lt;/li&gt; 
 &lt;li&gt;LRU/LFU&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;&lt;a class=&quot;content-link  js-post-content-keyword&quot; href=&quot;/jump/super-jump/word?word=%E6%8E%92%E5%BA%8F&quot; target=&quot;_blank&quot;&gt;排序&lt;/a&gt;&lt;/span&gt;&lt;/li&gt; 
 &lt;li&gt;查找&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src=&quot;https://uploadfiles.nowcoder.com/files/20210311/1219786_1615453294383/008eGmZEgy1goeugqrbrrj31360u0451.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt; 
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt; 
&lt;p&gt;我给大家的建议就是慢慢来，不管是社招还是校招，制定自己的计划，一定要有自己的知识体系，针对自己薄弱的地方进行强化复习，不放过任何一个细节。&lt;br/&gt;简历上写的东西一定要会，一般都是针对简历来提问的。如果在预习的过程中感到困难或者吃力，那就对了，等你熬过去了，就是胜利。祝福大家都能拿到满意的offer。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>3f77bb78a8b5b41114a85492bb50f9c4</guid>
<title>[推荐] 一文理解 MySQL 的锁机制与死锁排查</title>
<link>https://toutiao.io/k/gnbgq3w</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-source-line=&quot;1&quot;&gt;MySQL的并发控制是在数据安全性和并发处理能力之间的权衡，通过不同的锁策略来决定对系统开销和性能的影响。&lt;/p&gt;&lt;h2 data-source-line=&quot;3&quot;&gt;基础知识&lt;/h2&gt;&lt;p data-source-line=&quot;5&quot;&gt;为了后续的解释更加容易理解，这里列举一些基本概念的解释。&lt;/p&gt;&lt;h3 data-source-line=&quot;7&quot;&gt;悲观锁&lt;/h3&gt;&lt;p data-source-line=&quot;9&quot;&gt;悲观锁指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。&lt;/p&gt;&lt;p data-source-line=&quot;11&quot;&gt;select...for update是MySQL提供的实现悲观锁的方式。在悲观锁的情况下，为了保证事务的隔离性，其它事务无法修改这些数据。&lt;/p&gt;&lt;blockquote data-source-line=&quot;13&quot;&gt;&lt;p&gt;现在互联网高并发的架构中，受到fail-fast思路的影响，悲观锁已经比较少见了。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-source-line=&quot;15&quot;&gt;乐观锁&lt;/h3&gt;&lt;p data-source-line=&quot;17&quot;&gt;相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。&lt;/p&gt;&lt;p data-source-line=&quot;19&quot;&gt;而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本（Version）记录机制实现：通过为数据库表增加一个数字类型的&lt;code&gt;version&lt;/code&gt;字段，当读取数据时，将&lt;code&gt;version&lt;/code&gt;字段的值一同读出，数据每更新一次，对此&lt;code&gt;version&lt;/code&gt;值+1。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的&lt;code&gt;version&lt;/code&gt;值进行比对，如果数据库表当前版本号与第一次取出来的&lt;code&gt;version&lt;/code&gt;值相等，则予以更新，否则认为是过期数据，返回更新失败。&lt;/p&gt;&lt;h2 data-source-line=&quot;21&quot;&gt;锁的粒度&lt;/h2&gt;&lt;p data-source-line=&quot;23&quot;&gt;MySQL定义了两种锁的粒度：表级、行级。&lt;/p&gt;&lt;h3 data-source-line=&quot;25&quot;&gt;表锁&lt;/h3&gt;&lt;p data-source-line=&quot;27&quot;&gt;由MySQL Server控制，分为读锁和写锁。优点是开销小，加锁快；不会出现死锁；缺点是锁定粒度大，发生锁冲突的概率最高，并发度最低。表锁适合查询多、更新少的场景。&lt;/p&gt;&lt;p data-source-line=&quot;29&quot;&gt;当对表加了读锁，则会话只能读取当前被加锁的表，其它会话仍然可以对表进行读取但不能写入。&lt;/p&gt;&lt;p data-source-line=&quot;31&quot;&gt;当对表加了写锁，则会话可以读取或写入被加锁的表，其它会话不能对加锁的表进行读取或写入。&lt;/p&gt;&lt;h3 data-source-line=&quot;33&quot;&gt;行锁&lt;/h3&gt;&lt;p data-source-line=&quot;35&quot;&gt;由存储引擎实现，InnoDB支持，而MyISAM不支持。优点是开销大，加锁慢；会出现死锁；缺点是锁定粒度最小，发生锁冲突的概率最低，并发度也最高。InnoDB引擎下默认使用行级锁。行级锁适合按索引更新频率高的场景。&lt;/p&gt;&lt;p data-source-line=&quot;37&quot;&gt;InnoDB是MySQL最常用的存储引擎，本文以此为角度讲解MySQL的锁机制。有关MySQL存储引擎和有关B-Tree的知识，可以查看博客《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247483969&amp;amp;idx=1&amp;amp;sn=03eef5982173baa0e8dba05c1549f401&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;彻底搞懂MySQL的索引&lt;/a&gt;》&lt;/p&gt;&lt;h2 data-source-line=&quot;40&quot;&gt;行锁的分类&lt;/h2&gt;&lt;h3 data-source-line=&quot;42&quot;&gt;1. 记录锁&lt;/h3&gt;&lt;p data-source-line=&quot;44&quot;&gt;记录锁（Record lock）在唯一索引列或主键列记录上加锁，且该值存在，否则加锁类型为间隙锁。例如&lt;code&gt;SELECT a FROM t WHERE a = 12 FOR UPDATE&lt;/code&gt;，对值为12的索引进行锁定，防止其它事务插入、删除、更新值为12的记录行。&lt;/p&gt;&lt;h3 data-source-line=&quot;46&quot;&gt;2. 间隙锁&lt;/h3&gt;&lt;p data-source-line=&quot;48&quot;&gt;间隙锁（Gap Lock），只有在可重复读、串行化隔离级别才有，在索引记录之间的间隙中加锁，或者是在某一条索引之前或者之后加锁，并不包括该索引本身。&lt;/p&gt;&lt;p data-source-line=&quot;50&quot;&gt;例如：&lt;code&gt;SELECT a FROM t WHERE a &amp;gt; 15 and a &amp;lt; 20 FOR UPDATE&lt;/code&gt;，且a存在的值为1、2、5、10、15、20，则将(15,20)的间隙锁住。&lt;/p&gt;&lt;p data-source-line=&quot;52&quot;&gt;间歇锁的范围：&lt;/p&gt;&lt;ol data-source-line=&quot;54&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;对主键或唯一索引当前读时，where条件全部精确命中(=或者in)，这种场景本身就不会出现幻读，所以只会加记录锁。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;没有索引的列当前读操作时，会加全表gap锁，生产环境要注意。（所有主键x锁，所有主键间隙gap锁）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;非唯一索引列，如果where条件部分命中(&amp;gt;、&amp;lt;、like等)或者全未命中，则会加附近Gap间隙锁。例如，某表数据如下，非唯一索引2,6,9,9,11,15。&lt;code&gt;delete from table where another_id = 9&lt;/code&gt;要操作非唯一索引列9的数据，gap锁将会锁定的列是(6,11)，该区间内无法插入数据。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;更多情况看文末的图片总结。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;59&quot;&gt;在使用范围条件检索并锁定记录时，间歇锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。&lt;/p&gt;&lt;p data-source-line=&quot;61&quot;&gt;间隙锁和间隙锁之间是互不冲突的，间隙锁唯一的作用就是为了防止其他事务的插入，在RR（可重复读）级别下解决了幻读的问题。&lt;/p&gt;&lt;p data-source-line=&quot;63&quot;&gt;例如id有3,4,5，间隙锁锁定id&amp;gt;3的数据，是指的4及后面的数字都会被锁定。这样的话加入新的数据id=6，就会被阻塞，从而避免了幻读。&lt;/p&gt;&lt;blockquote data-source-line=&quot;65&quot;&gt;&lt;p&gt;快照读与当前读将在下一篇博客《一文理解MySQL的事务原则与事务隔离》进行详解&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-source-line=&quot;67&quot;&gt;3. 临键锁&lt;/h3&gt;&lt;p data-source-line=&quot;69&quot;&gt;临键锁（Next-Key Lock）是记录锁和间隙锁的合集。只有在可重复读、串行化隔离级别才有。&lt;/p&gt;&lt;p data-source-line=&quot;71&quot;&gt;&lt;img data-ratio=&quot;0.4596774193548387&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/OqTAl3WTC7EbEQBRzIuuyOlamgzFW5ewDH52amtOsbdOhLjJuPhnDG3iaTdXNib4VjGGQ4GERjceTx6guwh3GTYA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;620&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;73&quot;&gt;例如一个索引有10,11,13,20这四个值。InnoDB可以根据需要使用记录锁将10，11，13，20四个索引锁住，也可以使用间隙锁将(-∞,10)，(10,11)，(11,13)，(13,20)，(20,+∞)五个范围区间锁住。而临键锁是记录锁和间隙锁的合集。&lt;/p&gt;&lt;h3 data-source-line=&quot;75&quot;&gt;4. 插入意向锁&lt;/h3&gt;&lt;p data-source-line=&quot;77&quot;&gt;插入意向锁（Insert Intention Locks），是一种特殊的间隙锁，只有在执行INSERT操作时才会加锁，插入意向锁之间不冲突，可以向一个间隙中同时插入多行数据，但插入意向锁与间隙锁是冲突的，当有间隙锁存在时，插入语句将被阻塞，正是这个特性解决了幻读的问题。&lt;/p&gt;&lt;blockquote data-source-line=&quot;80&quot;&gt;&lt;p&gt;假设有一个记录索引包含键值4和7，不同的事务分别插入5和6，每个事务都会产生一个加在4-7之间的插入意向锁，获取在插入行上的排它锁，但是不会被互相锁住，因为数据行并不冲突。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-source-line=&quot;82&quot;&gt;意向锁&lt;/h3&gt;&lt;p data-source-line=&quot;84&quot;&gt;innodb的意向锁主要用户多粒度的锁并存的情况。比如事务A要在一个表上加S锁，如果表中的一行已被事务B加了X锁，那么该锁的申请也应被阻塞。如果表中的数据很多，逐行检查锁标志的开销将很大，系统的性能将会受到影响。为了解决这个问题，可以在表级上引入新的锁类型来表示其所属行的加锁情况，这就引出了“意向锁”的概念。&lt;/p&gt;&lt;p data-source-line=&quot;86&quot;&gt;举个例子，如果表中记录1亿，事务A把其中有几条记录上了行锁了，这时事务B需要给这个表加表级锁，如果没有意向锁的话，那就要去表中查找这一亿条记录是否上锁了。如果存在意向锁，那么假如事务A在更新一条记录之前，先加意向锁，再加X锁，事务B先检查该表上是否存在意向锁，存在的意向锁是否与自己准备加的锁冲突，如果有冲突，则等待直到事务A释放，而无须逐条记录去检测。事务B更新表时，其实无须知道到底哪一行被锁了，它只要知道反正有一行被锁了就行了。&lt;/p&gt;&lt;p data-source-line=&quot;88&quot;&gt;意向锁的主要作用是处理行锁和表锁之间的矛盾，能够显示“某个事务正在某一行上持有了锁，或者准备去持有锁”。&lt;/p&gt;&lt;h2 data-source-line=&quot;90&quot;&gt;锁的模式&lt;/h2&gt;&lt;p data-source-line=&quot;92&quot;&gt;共享锁和排它锁都是行级锁。意向共享锁和意向排他锁是表级锁。意向共享锁和意向排他锁都是系统自动添加和自动释放的，整个过程无需人工干预。&lt;/p&gt;&lt;h3 data-source-line=&quot;94&quot;&gt;1. 共享锁&lt;/h3&gt;&lt;p data-source-line=&quot;96&quot;&gt;共享锁（S锁，Shared Lock）：又称读锁，允许一个事务去读数据集，阻止其他事务获得该数据集的排他锁。共享锁与共享锁可以同时使用。举例：若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。&lt;/p&gt;&lt;h3 data-source-line=&quot;98&quot;&gt;2. 排他锁&lt;/h3&gt;&lt;p data-source-line=&quot;100&quot;&gt;排他锁（X锁，Exclusive Lock）：又称写锁，允许获取排他锁的事务更新数据，阻止其他事务获得相同的数据集的共享锁和排他锁。排它锁与排它锁、共享锁都不兼容。举例：若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。&lt;/p&gt;&lt;h3 data-source-line=&quot;102&quot;&gt;3. 意向共享锁&lt;/h3&gt;&lt;p data-source-line=&quot;104&quot;&gt;意向共享锁（IS锁，Intention Shared Lock）：事务打算给数据行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。&lt;/p&gt;&lt;h3 data-source-line=&quot;106&quot;&gt;4. 意向排他锁&lt;/h3&gt;&lt;p data-source-line=&quot;108&quot;&gt;意向排他锁（IX锁，Intention Exclusive Lock）：事务打算给数据行加排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。&lt;/p&gt;&lt;p data-source-line=&quot;110&quot;&gt;IS锁和IX锁的提出仅仅为了在之后加表级别的S锁和X锁时可以快速判断表中的记录是否被上锁，以避免用遍历的方式来查看表中有没有上锁的记录，也就是说其实IS锁和IX锁是兼容的，IX锁和IX锁是兼容的。&lt;/p&gt;&lt;p data-source-line=&quot;112&quot;&gt;意向锁之间不会发生冲突，但共享锁、排它锁、意向锁之间会发生冲突，表级别各种锁的兼容性如下表所示。&lt;/p&gt;&lt;table data-source-line=&quot;113&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;兼容性&lt;/th&gt;&lt;th&gt;&lt;code&gt;X&lt;/code&gt;&lt;/th&gt;&lt;th&gt;&lt;code&gt;IX&lt;/code&gt;&lt;/th&gt;&lt;th&gt;&lt;code&gt;S&lt;/code&gt;&lt;/th&gt;&lt;th&gt;&lt;code&gt;IS&lt;/code&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;X&lt;/code&gt;&lt;/td&gt;&lt;td&gt;不兼容&lt;/td&gt;&lt;td&gt;不兼容&lt;/td&gt;&lt;td&gt;不兼容&lt;/td&gt;&lt;td&gt;不兼容&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;IX&lt;/code&gt;&lt;/td&gt;&lt;td&gt;不兼容&lt;/td&gt;&lt;td&gt;兼容&lt;/td&gt;&lt;td&gt;不兼容&lt;/td&gt;&lt;td&gt;兼容&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;S&lt;/code&gt;&lt;/td&gt;&lt;td&gt;不兼容&lt;/td&gt;&lt;td&gt;不兼容&lt;/td&gt;&lt;td&gt;兼容&lt;/td&gt;&lt;td&gt;兼容&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;IS&lt;/code&gt;&lt;/td&gt;&lt;td&gt;不兼容&lt;/td&gt;&lt;td&gt;兼容&lt;/td&gt;&lt;td&gt;兼容&lt;/td&gt;&lt;td&gt;兼容&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 data-source-line=&quot;120&quot;&gt;5. 自增锁&lt;/h3&gt;&lt;p data-source-line=&quot;122&quot;&gt;AUTO-INC Locks，自增锁，是一种特殊的表锁。当表有设置自增&lt;code&gt;auto_increment&lt;/code&gt;列，在插入数据时会先获取自增锁，其它事务将会被阻塞插入操作，自增列+1后释放锁，如果事务回滚，自增值也不会回退，所以自增列并不一定是连续自增的。（MySQL 从 5.1.22 版本开始，引入了一种可选的轻量级锁（mutex）机制来代替AUTOINC锁。见于参考文档3）&lt;/p&gt;&lt;h3 data-source-line=&quot;124&quot;&gt;6. 元数据锁&lt;/h3&gt;&lt;p data-source-line=&quot;126&quot;&gt;元数据锁（metadata lock），MySQL Server控制，表级锁，是维护表元数据的数据一致性，保证在表上有活动事务（显式或隐式）的时候，不可以对元数据进行写入操作。从MySQL5.5版本开始引入了MDL锁，来保护表的元数据信息，用于解决或者保证DDL操作与DML操作之间的一致性。&lt;/p&gt;&lt;p data-source-line=&quot;128&quot;&gt;对于引入MDL，其主要解决了2个问题：&lt;/p&gt;&lt;ol data-source-line=&quot;130&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;事务隔离问题，比如在可重复隔离级别下，会话A在2次查询期间，会话B对表结构做了修改，两次查询结果就会不一致，无法满足可重复读的要求。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;数据复制的问题，比如会话A执行了多条更新语句期间，另外一个会话B做了表结构变更并且先提交，就会导致slave在重做时，先重做alter，再重做update时就会出现复制错误的现象。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;133&quot;&gt;每执行一条DML、DDL语句时都会申请MDL锁，DML操作需要MDL读锁，DDL操作需要MDL写锁（MDL加锁过程是系统自动控制，无法直接干预，读读共享，读写互斥，写写互斥），申请MDL锁的操作会形成一个队列，队列中写锁获取优先级高于读锁。&lt;/p&gt;&lt;p data-source-line=&quot;135&quot;&gt;一旦出现MDL写锁等待，不但当前操作会被阻塞，同时还会阻塞后续该表的所有操作（不过在MySQL5.6的时候推出了online ddl机制，使得排队的MDL写锁进行降级，防止对MDL读锁的阻塞）。&lt;/p&gt;&lt;h3 data-source-line=&quot;137&quot;&gt;加锁时机&lt;/h3&gt;&lt;ul data-source-line=&quot;139&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;SELECT xxx 查询语句正常情况下为快照读，只加元数据读锁，直到事务结束。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SELECT xxx LOCK IN SHARE MODE 语句为当前读，加S锁和元数据读锁，直到事务结束。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SELECT xxx FOR UPDATE 语句为当前读，加X锁和元数据读锁，直到事务结束。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;DML语句（INSERT、DELETE、UPDATE）为当前读，加X锁和元数据读锁，直到事务结束。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;DDL语句（ALTER、CREATE等）加元数据写锁，且是隐式提交不能回滚，直到事务结束。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;blockquote data-source-line=&quot;145&quot;&gt;&lt;p&gt;为什么DDL语句会隐式提交？因为DDL是数据定义语言，在数据库中承担着创建、删除和修改的重要的职责。一旦发生问题，带来的后果很可能是不可估量的。于是在每执行完一次后就进行提交，可以保证流畅性，数据不会发生阻塞，同时也会提高数据库的整体性能。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-source-line=&quot;147&quot;&gt;线上踩坑举例：由于DDL语句存在隐式提交，所以如果会话A开始了事务，进行了DML操作，然后进行了DDL操作，然后会话A回滚事务。此时会话A回滚的事务是一个空事务，因为DDL操作执行的时候会进行一次隐式提交&lt;/p&gt;&lt;h3 data-source-line=&quot;149&quot;&gt;行锁锁住整表的场景&lt;/h3&gt;&lt;ol data-source-line=&quot;151&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;SQL语句没有使用索引会把整张表锁住。例如事务里进行整表update；用到前缀like；字段没有加索引；数据库优化将索引查询转全表扫描等等。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Mysql在5.6版本之前，直接修改表结构的过程中会锁表。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-source-line=&quot;154&quot;&gt;&lt;p&gt;“查询每个表索引，并使用最佳索引，除非优化程序认为使用表扫描更有效。一次使用扫描是基于最佳索引是否跨越了表的30％以上，但是固定百分比不再决定使用索引还是扫描。现在，优化器更加复杂，并且根据附加因素（如表大小，行数和I / O块大小）进行估计。”见于参考文档1。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-source-line=&quot;156&quot;&gt;实验操作下的加锁情况分析&lt;/h3&gt;&lt;p data-source-line=&quot;158&quot;&gt;以下结论基于MySQL5.6，以InnoDB默认的RR级别来实验，只用来方便理解本文提到的锁机制。恐有纰漏，敬请谅解。&lt;/p&gt;&lt;p data-source-line=&quot;160&quot;&gt;&lt;img data-ratio=&quot;0.8625254582484725&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7EbEQBRzIuuyOlamgzFW5ewNCBDeyhI7KgaXpDamDFb0m6aiaW9T7sc74ANWwUbaeVtZ5XQsvlicE7w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;982&quot;/&gt;&lt;/p&gt;&lt;h2 data-source-line=&quot;162&quot;&gt;死锁排查&lt;/h2&gt;&lt;p data-source-line=&quot;164&quot;&gt;INFORMATION_SCHEMA提供对数据库元数据的访问、关于MySQL服务器的信息，如数据库或表的名称、列的数据类型或访问权限。其中有一个关于InnoDB数据库引擎表的集合，里面有记录数据库事务和锁的相关表。&lt;/p&gt;&lt;p data-source-line=&quot;166&quot;&gt;MySQL有关事务和锁的四条命令：&lt;/p&gt;&lt;ol data-source-line=&quot;168&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;SELECT * FROM information_schema.INNODB_TRX;&lt;/code&gt;命令是用来查看当前运行的所有事务。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;SELECT * FROM information_schema.INNODB_LOCKs;&lt;/code&gt;命令是用来查看当前出现的锁。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;SELECT * FROM information_schema.INNODB_LOCK_waits;&lt;/code&gt;命令是用来查看锁等待的对应关系。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;show engine innodb status \G;&lt;/code&gt;命令是用来获取最近一次的死锁信息。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;blockquote data-source-line=&quot;173&quot;&gt;&lt;p&gt;在查询结果中可以看到是否有表锁等待或者死锁。如果有死锁发生，可以通过&lt;code&gt;KILL trx_mysql_thread_id&lt;/code&gt;来杀掉当前运行的事务。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-source-line=&quot;175&quot;&gt;查询事务与锁的命令行&lt;/h3&gt;&lt;p data-source-line=&quot;177&quot;&gt;死锁是并发系统中常见的问题，同样也会出现在数据库MySQL的并发读写请求场景中。当两个及以上的事务，双方都在等待对方释放已经持有的锁或因为加锁顺序不一致造成循环等待锁资源，就会出现“死锁”。常见的报错信息为&quot;Deadlock found when trying to get lock...&quot;&lt;/p&gt;&lt;p data-source-line=&quot;179&quot;&gt;MySQL死锁问题排查的常见思路：&lt;/p&gt;&lt;ol data-source-line=&quot;180&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;通过多终端模拟并发事务，复现死锁。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;通过上面四条命令，查看事务与锁的信息。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;通过explain可以查看执行计划。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;184&quot;&gt;发生死锁异常后，通过开启InnoDB的监控机制来获取实时的死锁信息，它会周期性（每隔 15 秒）打印 InnoDb 的运行状态到 mysqld服务的错误日志文件中。&lt;/p&gt;&lt;p data-source-line=&quot;186&quot;&gt;InnoDB的监控较为重要的有标准监控（Standard InnoDB Monitor）和锁监控（InnoDB Lock Monitor），通过对应的系统参数可以将其开启。&lt;/p&gt;&lt;pre data-source-line=&quot;187&quot;&gt;&lt;code&gt;&lt;span&gt;set&lt;/span&gt; &lt;span&gt;GLOBAL&lt;/span&gt; innodb_status_output=&lt;span&gt;ON&lt;/span&gt;;&lt;span&gt;开启标准监控&lt;/span&gt;&lt;br/&gt;&lt;span&gt;set&lt;/span&gt; &lt;span&gt;GLOBAL&lt;/span&gt; innodb_status_output_locks;&lt;span&gt;开启所监控&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-source-line=&quot;192&quot;&gt;另外，MySQL 提供了一个系统参数&lt;code&gt;innodb_print_all_deadlocks&lt;/code&gt;专门用于记录死锁日志，当发生死锁时，死锁日志会记录到 MySQL 的错误日志文件中。&lt;/p&gt;&lt;p data-source-line=&quot;194&quot;&gt;另外，MySQL 提供了一个系统参数&lt;code&gt;innodb_print_all_deadlocks&lt;/code&gt;专门用于记录死锁日志，当发生死锁时，死锁日志会记录到 MySQL 的错误日志文件中。&lt;/p&gt;&lt;h3 data-source-line=&quot;196&quot;&gt;如何尽可能避免死锁&lt;/h3&gt;&lt;ol data-source-line=&quot;198&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;合理的设计索引，区分度高的列放到组合索引前面，使业务SQL尽可能通过索引定位更少的行，减少锁竞争。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;尽量按主键/索引去查找记录，范围查找增加了锁冲突的可能性，也不要利用数据库做一些额外额度计算工作。比如有的程序会用到&lt;code&gt;select … where … order by rand();&lt;/code&gt;这样的语句，类似这样的语句用不到索引，因此将导致整个表的数据都被锁住。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;以固定的顺序访问表和行。比如两个更新数据的事务，事务A更新数据的顺序为1，2;事务B更新数据的顺序为2，1。这样更可能会造成死锁。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-source-line=&quot;205&quot;&gt;参考文档：&lt;/p&gt;&lt;ol data-source-line=&quot;206&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;http://www.searchdoc.cn/rdbms/mysql/dev.mysql.com/doc/refman/5.7/en/where-optimization.com.coder114.cn.html&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html#innodb-record-locks&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;https://dev.mysql.com/doc/refman/5.7/en/innodb-auto-increment-handling.html&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>22ed3766d45b09a255ec0717186c4442</guid>
<title>[推荐] Redis：我是如何与客户端进行通信的</title>
<link>https://toutiao.io/k/dr4u4yt</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;江湖上说，&lt;strong&gt;天下武功，无坚不摧，唯快不破&lt;/strong&gt;，这句话简直是为我量身定制。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我是一个Redis服务，最引以为傲的就是我的速度，我的 QPS 能达到10万级别。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在我的手下有数不清的小弟，他们会时不时到我这来存放或者取走一些数据，我管他们叫做客户端，还给他们起了英文名叫 Redis-client。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有时候一个小弟会来的非常频繁，有时候一堆小弟会同时过来，但是，即使再多的小弟我也能管理的井井有条。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有一天，小弟们问我。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.8333333333333334&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyfoy2icYqicT72JftlHDibibSES2rlIOOYyFGNpDvc9lEy5Je4pkIpwpYjdA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;552&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;想当年，为了不让小弟们拖垮我傲人的速度，在设计和他们的通信协议时，我绞尽脑汁，制定了下面的三条原则：&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;实现简单&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;针对计算机来说，解析速度快&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;针对人类来说，可读性强&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为什么这么设计呢？先来看看一条指令发出的过程，首先在客户端需要对指令操作进行封装，使用网络进行传输，最后在服务端进行相应的解析、执行。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.463768115942029&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicaLtJLCXG77p4PNzYoiaRAw5KYTmIWibRvsmxTp149neUMtI3gWFTiageu3ic5KFHm9HlmPkGxkCbZIMA/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;690&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一过程如果设计成一种非常复杂的协议，那么封装、解析、传输的过程都将非常耗时，无疑会降低我的速度。什么，你问我为什么要遵循最后一条规则？算是对于程序员们的馈赠吧，我真是太善良了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我把创造出来的这种协议称为 RESP (&lt;code&gt;REdis Serialization Protocol&lt;/code&gt;)协议，它工作在 TCP 协议的上层，作为我和客户端之间进行通讯的标准形式。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说到这，我已经有点迫不及待想让你们看看我设计出来的杰作了，但我好歹也是个大哥，得摆点架子，不能我主动拿来给你们看。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;所以我建议你直接使用客户端发出一条向服务器的命令，然后取出这条命令对应的报文来直观的看一下。话虽如此，不过我已经被封装的很严实了，正常情况下你是看不到我内部进行通讯的具体报文的，所以，你可以&lt;strong&gt;伪装&lt;/strong&gt;成一个Redis的服务端，来截获小弟们发给我的消息。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实现起来也很简单，我和小弟之间是基于 Socket 进行通讯，所以在本地先启动一个&lt;code&gt;ServerSocket&lt;/code&gt;，用来监听Redis服务的6379端口：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;server&lt;/span&gt;() &lt;span&gt;throws&lt;/span&gt; IOException &lt;/span&gt;{&lt;br/&gt;    ServerSocket serverSocket = &lt;span&gt;new&lt;/span&gt; ServerSocket(&lt;span&gt;6379&lt;/span&gt;);&lt;br/&gt;    Socket socket = serverSocket.accept();&lt;br/&gt;    &lt;span&gt;byte&lt;/span&gt;[] bytes = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;byte&lt;/span&gt;[&lt;span&gt;1024&lt;/span&gt;];&lt;br/&gt;    InputStream input = socket.getInputStream();&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt;(input.read(bytes)!=&lt;span&gt;0&lt;/span&gt;){&lt;br/&gt;        System.out.println(&lt;span&gt;new&lt;/span&gt; String(bytes));&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后启动&lt;code&gt;redis-cli&lt;/code&gt;客户端，发送一条命令：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;set key1 value1&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这时，伪装的服务端就会收到报文了，在控制台打印了：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;*3&lt;br/&gt;$3&lt;br/&gt;set&lt;br/&gt;$4&lt;br/&gt;key1&lt;br/&gt;$6&lt;br/&gt;value1&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到这里，隐隐约约看到了刚才输入的几个关键字，但是还有一些其他的字符，要怎么解释呢，是时候让我对协议报文中的格式进行一下揭秘了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我对小弟们说了，对大哥说话的时候得按规矩来，这样吧，你们在请求的时候要遵循下面的规则：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;*&amp;lt;参数数量&amp;gt; CRLF&lt;br/&gt;$&amp;lt;参数1的字节长度&amp;gt; CRLF&lt;br/&gt;&amp;lt;参数1的数据&amp;gt; CRLF&lt;br/&gt;$&amp;lt;参数2的字节长度&amp;gt; CRLF&lt;br/&gt;&amp;lt;参数2的数据&amp;gt; CRLF&lt;br/&gt;...&lt;br/&gt;$&amp;lt;参数N的字节长度&amp;gt; CRLF&lt;br/&gt;&amp;lt;参数N的数据&amp;gt; CRLF&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;首先解释一下每行末尾的&lt;code&gt;CRLF&lt;/code&gt;，转换成程序语言就是&lt;code&gt;\r\n&lt;/code&gt;，也就是回车加换行。看到这里，你也就能够明白为什么控制台打印出的指令是竖向排列了吧。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在命令的解析过程中，&lt;code&gt;set&lt;/code&gt;、&lt;code&gt;key1&lt;/code&gt;、&lt;code&gt;value1&lt;/code&gt;会被认为是3个参数，因此参数数量为3，对应第一行的&lt;code&gt;*3&lt;/code&gt;。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;第一个参数&lt;code&gt;set&lt;/code&gt;，长度为3对应&lt;code&gt;$3&lt;/code&gt;；第二个参数&lt;code&gt;key1&lt;/code&gt;，长度为4对应&lt;code&gt;$4&lt;/code&gt;；第三个参数&lt;code&gt;value1&lt;/code&gt;，长度为6对应&lt;code&gt;$6&lt;/code&gt;。在每个参数长度的下一行对应真正的参数数据。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;看到这，一条指令被转换为协议报文的过程是不是就很好理解了？&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.4444444444444444&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyf1BJ8xSic8HRQJKdbo0xVqK3ZpxPW5jFxibEcGeajCuxuoqg8PFDkINEg/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;900&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当小弟对我发送完请求后，作为大哥，我就要对小弟的请求进行&lt;strong&gt;指令回复&lt;/strong&gt;了，而且我得根据回复内容进行一下分类，要不然小弟该搞不清我的指示了。&lt;/p&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;简单字符串&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;简单字符串回复只有一行回复，回复的内容以&lt;code&gt;+&lt;/code&gt;作为开头，不允许换行，并以&lt;code&gt;\r\n&lt;/code&gt;结束。有很多指令在执行成功后只会回复一个&lt;code&gt;OK&lt;/code&gt;，使用的就是这种格式，能够有效的将传输、解析的开销降到最低。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.084033613445378&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyfqlJaHViaKC8OqiaoUCnUSleGjticb8hukVjQAVyzfiboxYDvhdCjbBLkgA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;476&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;错误回复&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在RESP协议中，错误回复可以当做简单字符串回复的变种形式，它们之间的格式也非常类似，区别只有第一个字符是以&lt;code&gt;-&lt;/code&gt;作为开头，错误回复的内容通常是错误类型及对错误描述的字符串。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;错误回复出现在一些异常的场景，例如当发送了错误的指令、操作数的数量不对时，都会进行错误回复。在客户端收到错误回复后，会将它与简单字符串回复进行区分，视为异常。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.184873949579832&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyfg3vfSI3FdGySPRlPuGDajnFfmNmqoEyDfwzDzMo1u9fWKw01Qb8PgQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;476&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;整数回复&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;整数回复的应用也非常广泛，它以&lt;code&gt;:&lt;/code&gt;作为开头，以&lt;code&gt;\r\n&lt;/code&gt;结束，用于返回一个整数。例如当执行&lt;code&gt;incr&lt;/code&gt;后返回自增后的值，执行&lt;code&gt;llen&lt;/code&gt;返回数组的长度，或者使用&lt;code&gt;exists&lt;/code&gt;命令返回的0或1作为判断一个&lt;code&gt;key&lt;/code&gt;是否存在的依据，这些都使用了整数回复。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.9537815126050421&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyfa4LiaqVYk1TOahicuRq4E2ib6nxDLEyzQsLiaRXzBtoiaKWeYzlETzhDia8Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;476&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;批量回复&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;批量回复，就是多行字符串的回复。它以&lt;code&gt;$&lt;/code&gt;作为开头，后面是发送的字节长度，然后是&lt;code&gt;\r\n&lt;/code&gt;，然后发送实际的数据，最终以&lt;code&gt;\r\n&lt;/code&gt;结束。如果要回复的数据不存在，那么回复长度为-1。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.5126050420168067&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyfBnACFwLBXNNhggIcPH9K5JXQjXeJna8zEqicQBA30rYW7ZnyzfDkic5Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;476&quot;/&gt;&lt;/figure&gt;&lt;h4 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;多条批量回复&lt;span/&gt;&lt;/h4&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当服务端要返回多个值时，例如返回一些元素的集合时，就会使用多条批量回复。它以&lt;code&gt;*&lt;/code&gt;作为开头，后面是返回元素的个数，之后再跟随多个上面讲到过的批量回复。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;1.3907563025210083&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/zpom4BeZSicZ08KPRWFa6JlBqaskXvoyfq3s6vL0Ud67Ivib4UE6BRUibInIkmiaOUf2OX8ibWpJ4ThDSwGQ4JJZwcw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;476&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;到这里，基本上我和小弟之间的通讯协议就介绍完了。刚才你尝试了伪装成一个服务端，这会再来试一试直接写一个客户端来直接和我进行交互吧。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; &lt;span&gt;client&lt;/span&gt;() &lt;span&gt;throws&lt;/span&gt; IOException &lt;/span&gt;{&lt;br/&gt;    String CRLF=&lt;span&gt;&quot;\r\n&quot;&lt;/span&gt;;&lt;br/&gt;&lt;br/&gt;    Socket socket=&lt;span&gt;new&lt;/span&gt; Socket(&lt;span&gt;&quot;localhost&quot;&lt;/span&gt;, &lt;span&gt;6379&lt;/span&gt;);&lt;br/&gt;    &lt;span&gt;try&lt;/span&gt; (OutputStream out = socket.getOutputStream()) {&lt;br/&gt;        StringBuffer sb=&lt;span&gt;new&lt;/span&gt; StringBuffer();&lt;br/&gt;        sb.append(&lt;span&gt;&quot;*3&quot;&lt;/span&gt;).append(CRLF)&lt;br/&gt;                .append(&lt;span&gt;&quot;$3&quot;&lt;/span&gt;).append(CRLF).append(&lt;span&gt;&quot;set&quot;&lt;/span&gt;).append(CRLF)&lt;br/&gt;                .append(&lt;span&gt;&quot;$4&quot;&lt;/span&gt;).append(CRLF).append(&lt;span&gt;&quot;key1&quot;&lt;/span&gt;).append(CRLF)&lt;br/&gt;                .append(&lt;span&gt;&quot;$6&quot;&lt;/span&gt;).append(CRLF).append(&lt;span&gt;&quot;value1&quot;&lt;/span&gt;).append(CRLF);&lt;br/&gt;        out.write(sb.toString().getBytes());&lt;br/&gt;        out.flush();&lt;br/&gt;&lt;br/&gt;        &lt;span&gt;try&lt;/span&gt; (InputStream inputStream = socket.getInputStream()) {&lt;br/&gt;            &lt;span&gt;byte&lt;/span&gt;[] buff = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;byte&lt;/span&gt;[&lt;span&gt;1024&lt;/span&gt;];&lt;br/&gt;            &lt;span&gt;int&lt;/span&gt; len = inputStream.read(buff);&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; (len &amp;gt; &lt;span&gt;0&lt;/span&gt;) {&lt;br/&gt;                String ret = &lt;span&gt;new&lt;/span&gt; String(buff, &lt;span&gt;0&lt;/span&gt;, len);&lt;br/&gt;                System.out.println(&lt;span&gt;&quot;Recv:&quot;&lt;/span&gt; + ret);&lt;br/&gt;            }&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;运行上面的代码，控制台输出：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;Recv:+OK&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;上面模仿了客户端发出&lt;code&gt;set&lt;/code&gt;命令的过程，并收到了回复。依此类推，你也可以自己封装其他的命令，来实现一个自己的Redis客户端，作为小弟，来和我进行通信。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;不过记住，要叫我大哥。&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d11ff44c280e28f1b108aedebe8624a2</guid>
<title>[推荐] 携程最终一致和强一致性缓存实践</title>
<link>https://toutiao.io/k/nvmnd0f</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span title=&quot;&quot; opera-tn-ra-cell=&quot;_$.pages:0.layers:0.comps:0.title1&quot;&gt;&lt;p&gt;&lt;strong&gt;作者简介&lt;/strong&gt;&lt;/p&gt;&lt;/span&gt; &lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;GSF，携程高级技术专家，关注高可用、高并发系统建设，致力于用技术驱动业务。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;一、前言&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;        &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;携程金融从成立至今，整体架构经历了从0到1再到10的变化，其中有多个场景使用了缓存来提升服务质量。从系统层面看，使用缓存的目的无外乎缓解DB压力（主要是读压力），提升服务响应速度。引入缓存，就不可避免地引入了缓存与业务DB数据的一致性问题，而不同的业务场景，对数据一致性的要求也不同。本文将从以下两个场景介绍我们的一些缓存实践方案：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;注：我们DB用的是MySQL，缓存介质用的是携程高可用Redis服务，存储介质的选型及存储服务的高可用不是本文重点，后文也不再做特别说明。&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;br/&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;二、最终一致性分布式缓存场景&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;2.1 场景描述&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;经过几年演进，携程金融形成了自顶向下的多层次系统架构，如业务层、平台层、基础服务层等，其中用户信息、产品信息、订单信息等基础数据由基础平台等底层系统产生，服务于所有的金融系统，对这部分基础数据我们引入了统一的缓存服务（系统名utag），缓存数据有三大特点：全量、准实时、永久有效，在数据实时性要求不高的场景下，业务系统可直接调用统一的缓存查询接口。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的典型使用场景有：风控流程、APP入口信息提示等，而对数据一致性要求高的场景依然需要走实时的业务接口查询。引入缓存前后系统架构对比如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4484375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1cQzdDVSm0jV87CjsyvX1dq6G3wyHYyH4YsN0ICytVicNlYFX8amhZnyicNAygAuZMtTGe71VpbGL5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统一缓存服务的构建给部门的整体系统架构带来了一些优势：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对业务系统：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;对基础服务：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;整体而言，缓存服务处于中间层，数据的写入方和数据查询方解耦，数据甚至可以在底层系统不感知的情况下写入（见下文），而数据使用方的查询也可在底层服务不可用或“堵塞”时候仍然保持可用（前提是缓存服务是可用的，而缓存服务的处理逻辑简单、统一且有多种手段保证，其可用性比单个子系统都高），整体上服务的稳定性得到了提升。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在构建此统一缓存服务时候，有三个关键目标：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据准确性：DB中单条数据的更新一定要准确同步到缓存服务。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据完整性：将对应DB表的全量数据进行缓存且永久有效，从而可以替代对应的DB查询。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;系统可用性：我们多个产品线的多个核心服务都已经接入，utag的高可用性显的尤为关键。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;接下来先说明统一缓存服务的整体方案，再逐一介绍此三个关键特性的设计实现方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;2.2 整体方案&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;我们的系统在多地都有部署，故缓存服务也做了相应的异地多机房部署，一来可以让不同地区的服务调用本地区服务，无需跨越网络专线，二来也可以作为一种灾备方案，增加可用性。&lt;/h3&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于缓存的写入，由于缓存服务是独立部署的，因此需要感知业务DB数据变更然后触发缓存的更新，本着“可以多次更新，但不能漏更新”的原则，我们设计了多种数据更新触发源：定时任务扫描，业务系统MQ、binlog变更MQ，相互之间作为互补来保证数据不会漏更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外为了缓存更新流程的统一和与触发源的解耦，我们使用MQ来驱动多地多机房的缓存更新，在不同的触发源触发后，会查询最新的DB数据，然后发出一个缓存更新的MQ消息，不同地区机房的缓存系统同时监听该主题并各自进行缓存的更新。对于MQ我们使用携程开源消息中间件QMQ 和 Kafka，在公司内部QMQ和Kafka也做了异地机房的互通。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于缓存的读取，utag系统提供dubbo协议的缓存查询接口，业务系统可调用本地区的接口，省去了网络专线的耗时（50ms延迟）。在utag内部查询redis数据，并反序列化为对应的业务model，再通过接口返回给业务方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了描述方便，以下异地多机房部署统一使用AB两地部署的概念进行说明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;   &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整体框架如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.434375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1cQzdDVSm0jV87CjsyvX1dqZxgdChGjkglNX2bdaY3KWGZLXYu8yw8MWdQDz9C8gfLIhKPCjR3nag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;接下来介绍一下几个关键点的设计 。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;2.3  数据准确性设计&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同的触发源，对缓存更新过程是一样的，整个更新步骤可抽象为4步：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;step1：触发更新，查询DB中的新数据，并发送统一的MQ&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;step2：接收MQ，查询缓存中的老数据&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;step3：新老数据对比，判断是否需要更新&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;step4：若需要，则更新缓存&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于我们业务的大部分核心系统和所有的DB都在A地机房，所以触发源（如binlog的消费、业务MQ的接收、扫表任务的执行）都在A侧，触发更新后，第一步查询DB数据也只能在A侧查询（避免跨网络专线的数据库连接，影响性能）。查询到新数据后，发送更新缓存的MQ，两地机房的utag服务进行消费，之后进行统一的缓存更新流程。总体的缓存更新方案如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;1.24765625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1cQzdDVSm0jV87CjsyvX1dqbEKRHU1XBjvibPRFOdHibroiau3YDLuL1ia4S3UIX2vqBexgykjSgOFjTA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;由于有多个触发源，不同的触发源之间可能会对同一条数据的缓存更新请求出现并发，此外可能出现同一条数据在极短时间内（如1秒内）更新多次，无法区分数据更新顺序，因此需要做两方面的操作来确保数据更新的准确性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）并发控制&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;若一条DB数据出现了多次更新，且刚好被不同的触发源触发，更新缓存时候若未加控制，可能出现数据更新错乱，如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.20859375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6ka2RxW76IBUXLWZsrkCfHNG1auzKDKYwGQTe0lib0lXKJBZVibdD2w3Wg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;故需要将第2、3、4步加锁，使得缓存刷新操作全部串行化。由于utag本身就依赖了redis，此处我们的分布式锁就基于redis实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）基于updateTime的更新顺序控制&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;即使加了锁，也需要进一步判断当前db数据与缓存数据的新老，因为到达缓存更新流程的顺序并不代表数据的真正更新顺序。我们通过对比新老数据的更新时间来实现数据更新顺序的控制。若新数据的更新时间大于老数据的更新时间，则认为当前数据可以直接写入缓存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们系统从建立之初就有自己的MySQL规范，每张表都必须有update_time字段，且设置为ON UPDATE CURRENT_TIMESTAMP，但是并没有约束时间字段的精度，大部分都是秒级别的，因此在同一秒内的多次更新操作就无法识别出数据的新老。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对同一秒数据的更新策略我们采用的方案是：先进行数据对比，若当前数据与缓存数据不相等，则直接更新，并且发送一条延迟消息，延迟1秒后再次触发更新流程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举个例子：假设同一秒内同一条数据出现了两次更新，value=1和value=2，期望最终缓存中的数据是value=2。若这两次更新后的数据被先后触发，分两种情况：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;1.1680064308681672&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6kfTib68l3Ddht8K0UFPzQkicv6wfcFILJF76HBaKy1mfAjib2gxaX1a1Rw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1244&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通过以上方案我们可以确保缓存数据的准确性。有几个点需要额外说明：  &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实不用延迟消息也是可以的，毕竟DB数据的更新时间是不变的，但是考虑到出现同一秒更新的可能是高频更新场景，若直接发消息，然后立即消费并触发二次更新，可能依然查到同一秒内更新的其他数据，为减少此种情况下的多次循环更新，延迟几秒再刷新可作为一种优化策略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为删除操作和update操作无法进行数据对比，无法确定操作的先后顺序，进而可能导致更新错乱。而在数据异常宝贵的时代，一般的业务系统中也没有物理删除的逻辑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以将查DB、查缓存、数据对比、更新缓存这四个步骤全部放到锁的范围内，这样就不需要处理同一秒的顺序问题。因为在这个串行化操作中每次都从DB中查询到了最新的数据，可以直接更新，而时间的判断、值的判断可以作为优化操作，减少缓存的更新次数，也可以减少锁定的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而我们为何不采用该方案？因为查询DB的操作我们只能在一侧机房处理，无法让AB两地系统的更新流程统一，也就降低了二者互备的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;2.4  数据完整性设计&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上述数据准确性是从单条数据更新角度的设计，而我们构建缓存服务的目的是替代对应DB表的查询，因此需要缓存对应DB表的全量数据，而数据的完整性从以下三个方面得到保证：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）“把鸡蛋放到多个篮子里”，使用多种触发源（定时任务，业务MQ，binglog MQ）来最大限度降低单条数据更新缺失的可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;     &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;单一触发源有可能出现问题，比如消息类的触发依赖业务系统、中间件canel、中间件QMQ和Kafka，扫表任务依赖分布式调度平台、MySQL等。中间任何一环都可能出现问题，而这些中间服务同时出概率的可能相对来说就极小了，相互之间可以作为互补。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）全量数据刷新任务：全表扫描定时任务，每周执行一次来进行兜底，确保缓存数据的全量准确同步。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）数据校验任务：监控Redis和DB数据是否同步并进行补偿。   &lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;2.5  系统可用性设计&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;统一缓存服务被多个业务线的核心系统所依赖，所以缓存服务的高可用是至关重要的。而对高可用的建设，除了集群部署、容量规划、熔断降级等常用手段外，针对我们自己的场景也做了一些方案。主要有以下三点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）异地机房互备&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如上所述，我们的服务在AB两地部署，两机房的缓存通过两地互通的MQ同时写入。在这套机制下，本地区的业务系统可以直接读取本地区的缓存，如果出现了本地区utag应用异常或redis服务异常，则可以快速降级到调用另外机房的服务接口。具体方案如下图所示：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.57265625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1cQzdDVSm0jV87CjsyvX1dqMnBSyTVfyyg70GAnrBEphhoBwiaofnMAVywNUmrCDz2mhrDL2Gkn3og/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本地业务系统通过dubbo调用本地的utag服务，在utag的本地处理流程中，查询本地缓存前后分别可根据一定的条件进行服务降级，即查询另一机房。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了避免循环调用，在降级调用前，需要判断当前请求是否来自本地，而此功能通过Dubbo的RpcContext透传特定标识来实现。除此之外，还建立了两机房的应用心跳，来辅助切换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.2359375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6kN6bU5TCvYGhU2EP9utQ1L3NOBSkwWP8AibZuLt0BJtbHrrBaE3ykurQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）QMQ和Kafka互备&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存更新流程通过MQ来驱动，虽然公司的MQ中间件服务由专人维护，但是万一出现问题长时间不能恢复，对我们来说将是致命的。所以我们决定同时采用Kafka和QMQ两种中间件来作为互备方案。默认情况下对于全表扫描任务和binlog消费这类大批量消息场景使用Kafka来驱动，而其他场景通过QMQ来驱动。所有的场景都可以通过开关来控制走Kafka或者QMQ。目前该功能可通过配置管理平台来实现快速切换。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（3）快速恢复&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在极端情况下，可能出现Redis数据丢失的情况，如主机房（A机房）突然断网，redis集群切换过程出现数据丢失或同步错乱，此时很可能无法通过自动触发来补齐数据，因此设计了全表快速扫描的补偿机制，通过多任务并行调度，可在30分钟内将全量数据完成刷新。此功能需要人工判断并触发。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;2.6 总结&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;        &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上介绍了我们最终一致性分布式缓存服务的设计思路和要点，其中的关键点为数据准确性、数据完整性、系统可用性的设计。除此之外，还有一些优化点如降级方案的自动触发、异地机房缓存之间、缓存与DB之间做旁路数据diff，可进一步确保缓存服务整体的健壮性，在后续的版本中进行迭代。&lt;/span&gt;&lt;/p&gt;&lt;h1&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h1&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;三、强一致性分布式缓存场景&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;3.1 场景描述&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;        &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;强一致性分布式缓存目前主要应用在我们携程金融的消金贷前服务中。随着我们用户量和业务量的增涨，贷前服务的查询量激增，给数据库带来了很大的压力，解决此问题有几种可选方案：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）分库分表：成本和复杂度相对较高，我们场景下只是数据查询流量较大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）读写分离：出于数据库性能考虑，我们的MySQL大部分采用异步复制的方式，而由于我们的场景对数据实时性要求较高，因此无法直接利用读写分离的优势来分担主库压力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综合来看，增加缓存是更加合适的方案，我们决定设计一套高可用的满足强一致性要求的分布式缓存。接下来介绍我们的具体设计实现方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;3.2 整体方案&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存的处理我们采用了较为常见的处理思路：在更新操作中，先更新数据库，再删除缓存，查询操作中，触发缓存更新。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.3497164461247637&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6kqDF2emTIUY3df2B0ibAA4MRpibmL8dYm2VrVqA2vIWUtVq4sbgvpnLew/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1058&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在此过程中，若不加控制，则会存在数据不一致性问题，主要是由于缓存操作和DB更新之间的并发导致的。具体分析如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）缓存读取和DB更新并发&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图所示，查询时候若缓存已经存在，则会直接返回缓存数据。若查询缓存的操作，发生在“更新DB数据”和“删除缓存”之间，则本次查询到数据为缓存中的老数据，导致不一致。当然下次查询可能就会查询到最新的数据。这种并发在我们服务中是存在的，比如某个产品开通后，会在更新DB（产品开通状态）后立即发送MQ（事务型消息）告知业务，业务侧处理流程中会立即发起查询操作。此场景中数据库的更新和数据的查询间隔极短，很容易出现此种并发问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.38515625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6ka3hvMuBHXJATPeIlfnWnAvVbY9O13mVjaFm5BQf61bYBE7sAUoYp9A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）缓存更新与DB更新并发&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图所示，查询的时候，若缓存不存在，则更新缓存，流程是先查询DB再更新Redis。若更新缓存时候，出现以下时序：查询DB老数据（T0时刻，DB中value=1）→ 更新DB（T1时刻，更新DB为value=2）→ 删除Redis（T2）→ 更新Redis（T3），则会导致本次查询返回数据及缓存中的数据与DB数据不一致，即接口返回和更新后的缓存都为脏数据。若T2和T3互换，即更新DB后，先更新Redis，再删除Redis ，由于缓存被删除在下次更新可能会被正确更新，但本次返回数据依然与DB更新后的数据不一致。 &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.32421875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6kJhHvrn84jZkXPHEic6uj2hYngfbAlZx5LOMsWiazD6auRjnjgGWzj54Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;基于以上分析，为了避免并发带来的缓存不一致问题，需要将&quot;更新DB&quot;+&quot;删除缓存&quot;、&quot;查询DB&quot;+&quot;更新缓存&quot;两个流程都进行加锁。此处需要加的是分布式锁，我们使用的是redis分布式锁实现。加锁后的读写整体流程如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6kpGC0WQbFQ9GTLs1n44GpgzWpFR48pPrvYE5NtwXoNyxhDy8c05NAnQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如上图所示，有两处加锁，更新DB时加锁，锁范围为&quot;更新DB&quot;+&quot;删除cache&quot;（图中lock1），更新缓存时加锁，锁范围为&quot;查询DB&quot; + &quot;更新cache&quot;（图中lock2），两处对应的锁key是相同的。基于此方案，对于上面所说的两种并发场景，做针对性分析如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）缓存查询和DB更新的并发控制&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;查询操作流程中，先判断lock是否存在，若存在，则表示当前DB或缓存正在更新，不能直接查询缓存，在查询DB后返回数据。之所以这么做，还是由场景决定的，如前文所述，我们场景下的基本处理思路是，缓存仅作为“DB降压”的辅助手段，在不确定缓存数据是否最新的情况下，宁可多查询几次DB，也不要查询到缓存中的不一致数据。此外，更新操作相对于查询操作是很少的，在我们贷前服务中，读写比例约为8:1。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此处另外的一个可行方案是可在检测到有锁后可进行短暂的等待和重试，好处是可进一步增加缓存的命中率，但是多一次锁等待，可能会影响到查询接口的性能。可根据自身场景进行抉择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，为了进行降级，在锁判断前也增加了降级开关判断，若降级开关开启，也会直接查询DB。而降级主要是由于redis故障引起的，下文详述。若检测是否有锁时发生了异常同样也会直接查询DB。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）缓存更新和DB更新的并发控制&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;     &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;查询操作流程中，若缓存不存在，则进行缓存的更新，在更新时候先尝试进行加锁，若当前有锁说明当前有DB或缓存正在更新，则进行等待和重试，从而可避免查询到DB中的老数据更新到缓存中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中lock2的流程（load cache），我们是同步进行的。另外一个可行的方案是，异步发起缓存的加载，可减少锁等待时间，但是若出现瞬时的高并发查询，可能缓存无法及时加载产生从而频繁产生瞬时压力。可根据自身场景进行抉择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上为我们的整体设计思路，接下来从实现的角度分别描述一下基于本地消息表的缓存删除策略，缓存的降级和恢复这两个方面的具体方案。&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;3.3 缓存删除策略&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;     &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在更新操作中，在锁的范围内，先更新DB，再删除缓存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;     &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中锁的选型，我们采用与缓存同介质的redis分布式锁，这样做的好处是若因为redis服务不可用导致的锁处理失败，对于缓存本身也就不可用，可以自动走降级方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;     &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外，更新流程还要考虑两点：锁的范围和删除缓存失败后如何补偿。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）锁粒度&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更新操作中加锁粒度有以下三种方案：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;方案一：事务提交后加锁，只锁定删除缓存操作。对原事务无任何额外影响，但是在事务提交后到删除缓存之间存在与查询的并发可能性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;方案二：在事务提交前加锁，删除缓存后解锁。在满足一致性要求的前提下，锁的粒度可以做到最小，但是增加了DB事务的范围，若redis出现超时则可能导致事务时间拉长，进而影响DB操作性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;方案三：在事务开始前加锁，删除缓存后解锁。锁的范围较大，但是能满足我们一致性要求，对单个DB事务也基本无影响。且对同一个用户来说，贷前数据的更新并不频繁，锁范围稍大一些是我们可以接受的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-croporisrc=&quot;https://mmbiz.qlogo.cn/mmbiz_png/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6kMBiaYaAqReicL7Fs264A4RTd053loSsXTmKcQEic96zQQicERh3Y1Sajnw/0?wx_fmt=png&quot; data-cropx1=&quot;1.679300308968452&quot; data-cropx2=&quot;972.3148788927336&quot; data-cropy1=&quot;18.52864884866979&quot; data-cropy2=&quot;614.8142572513157&quot; data-ratio=&quot;0.6125385405960946&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6k1YlA9KfrSvcO3dHak47Oyicribib07q7SIVh4jTuMS5XuT8FlgMsyMtAw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;973&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;立足自身场景，权衡一致性要求和服务性能要求，我们剔除了方案二，默认情况下使用方案三，但是若在事务开始前加锁失败，为了不影响原业务流程（缓存只是辅助方案，redis故障不影响原应用功能）会自动降级到方案一，即在事务提交后删除缓存前再加锁。而这种降级，若出现并发的查询操作，依然可能出现上述不一致的问题，但是是可以容忍的，原因如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;通常情况下加锁失败是由于操作redis异常或者锁竞争引起的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;若出现redis异常，同时出现了并发的查询，而并发的两个操作时间间隔是极短的，因此查询时候，锁检测操作通常也是异常的，此时查询会自动降级为查询DB。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;若极短时间内的redis集群抖动，事务执行前redis不可用，事务执行后redis恢复，而此时在加锁操作还没有完成前恰巧又进行了并发的查询操作，检测锁成功且锁不存在，才可能会出现查询出老数据的情况。这种是极其严苛的并发条件。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;而加锁过程会进行重试（可动态调整配置），多次重试后可解决大部分的锁竞争情况。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;综上，在上述锁降级的方案下，数据不一致出现的情况虽然无法完全避免，但是产生条件极其苛刻，而应对这种极其极端的情况，在系统层面做更加强的方案带来的复杂度提升与收益是不成正比的，一般情况下做好日志记录、监控、报警，通过人工介入来弥补即可。从该方案上线后至今两年多的时间内，没有出现过该情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）删除缓存失败的补偿&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;另外要考虑的问题是，如果更新DB成功但删除缓存失败要后如何处理，而此种情况往往因应用服务器故障、网络故障、redis故障等原因导致。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;若应用服务器突然故障，则服务整体不可用，跟缓存就没多大关系了。若是由于网络、redis故障等原因导致的删除缓存失败，此时查询缓存也不可用，查询走DB，但需要可靠地记录下哪些数据做了变更，待redis可用后需要进行恢复，需要将中间变更的记录对应的缓存全部删除。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此处的一个关键点在于数据变更的可靠性记录，受到QMQ事务消息实现方案的启发，我们的方案是构建一张简易的记录表（代表发生变更的DB数据），每次DB变更后，将该变更记录表的插入和业务DB操作放在一个事务中处理。事务提交后，对应的变更记录持久化，之后进行删除缓存，若缓存删除成功，则将对应的记录表数据也删除掉。若缓存删除失败，则可根据记录表的数据进行补偿删除，而在redis的恢复流程中，需要校验记录表中是否存在数据，若存在则表示有变更后的数据对应的缓存未清除，不可进行缓存读取的恢复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外删除操作还要进行异步重试，来避免偶尔超时引起的缓存删除失败。此方案整体流程如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.2703125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6k0VSZWI4Wiaxr2h6WyBVjiadCa2vaoYlo908TKRHcnh48zahLHunzqyvA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其中cache_key_queue表即为我们的变更记录表，放在业务的同DB内。其表结构非常简单，只有插入和删除操作，对业务DB的额外影响可以忽略。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;sql&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;CREATE TABLE `cache_key_queue` (&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    `id` bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    `cache_key` varchar(1024) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;待删除的缓存key&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    PRIMARY KEY (`id`)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;) ENGINE = InnoDB AUTO_INCREMENT = 0 CHARSET = utf8 COMMENT &#x27;缓存删除队列表&#x27;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;基于以上分析，为了锁范围尽可能小，且为了尽可能降低极端的redis抖动情况下产生的影响，我们期望可以在事务提交后立即触发缓存的删除操作。为了能够对redis不可用期间发生变更的数据进行清除，我们需要可靠地记录数据变更记录。幸运的是，基于Spring的事务同步机制 TransactionSynchronization，可以很容易实现该方案。简单来说，该机制提供了Spring环境中事务执行前后的AOP功能，可以在spring事务的执行前后添加自己的操作，如下所示（代码和注释经过了简化）：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;public interface TransactionSynchronization extends Flushable {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    /**&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     * 事务同步器挂起处理&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     */&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    void suspend();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    /**&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     * 事务同步器恢复处理&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     */&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    void resume();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    /**&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     * 事务提交前处理&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     */&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    void beforeCommit(boolean readOnly);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    /**&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     * 事务完成(提交或回滚)前处理&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     */&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    void beforeCompletion();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    /**&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     * 事务提交后处理&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     */&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    void afterCommit();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    /**&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     * 事务完成(提交或回滚)后处理&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;     */&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    void afterCompletion(int status);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;基于此机制，我们可以很方便且相对优雅地实现我们的设计思路，即在 beforeCommit方法中，插入cache_key_queue记录；在 afterCommit方法中同步删除缓存，若删除缓存成功则同步删除cache_key_queue表记录；在afterCompletion方法中进行锁的释放处理。若同步删除缓存失败，则cache_key_queue表记录也会保留下来，之后触发异步删除，并启动定时任务不断扫描cache_key_queue表进行缓存删除的补偿。需要注意的是可能存在嵌套事务，一个完整事务中，可能存在多次数据更新，可借助ThreadLocal进行多条更新记录的汇总。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;3.4 缓存的熔断和恢复&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除了上述锁处理流程中讨论的redis抖动问题外，还需要考虑缓存服务redis集群不可用（网络问题、redis集群问题等）。按照我们的基本原则，引入的缓存服务仅做辅助，并不能强依赖。如果缓存不可用，主业务依然要保持可用，这就是我们接下来要讨论的缓存的熔断和恢复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（1）缓存熔断&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;     &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;熔断的目的是在redis不可用时避免每次调用（查询或更新）都进行额外的缓存操作，这些缓存操作会进行多次尝试，比如加锁操作我们设置的自动重试3次，每次间隔50ms，总耗时会增加150ms。若redis不可用则每次调用的耗时都会有额外增加，这对主业务功能可能会产生影响，降低底层服务的质量和性能。因此我们需要识别出 redis不可用的情况，并进行熔断。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们的熔断判断逻辑为：每个redis操作都try-catch异常，并做计数统计（不区分读写操作），若在M秒内出现N次异常则开启熔断。我们的场景下设置为10秒内出现50次异常就熔断，可根据自身场景设置，需要注意的是如果redis请求次数比较少，则需要在配置上保证在M秒内至少出现N次请求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此外熔断开关的配置是放在应用服务器的内存中，即单机熔断，而非集群熔断，这样做的原因是，redis服务不可用有可能是单机与redis服务的连通性问题导致，而在其他机器上依然可以访问缓存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;（2）缓存恢复&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;熔断之后的恢复策略相对复杂一些，需要区分缓存的读操作恢复和写操作恢复。具体如下流程如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-croporisrc=&quot;https://mmbiz.qlogo.cn/mmbiz_png/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6kxeESTdYL05cFvcJr8qI3oea4og4fl1vyPgoM37D45jMBf0A226J6qg/0?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;1254&quot; data-cropy1=&quot;36.88235294117647&quot; data-cropy2=&quot;242.98961937716265&quot; data-ratio=&quot;0.16507177033492823&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6kvucAnlzYHgRhWJPhfF4WBeHj21BAGwOxj2V2qqbYU1jFmYU86fNyrg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1254&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;step1：校验redis是否可用&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;       &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;判断逻辑为，连续发起特定的set操作N次，每次间隔一定时间，若都成功，则认为redis恢复。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;此处需要注意的是，我们的redis集群是Cluster模式，不同的key会散落在不同的redis主节点上，因此最保险的做法是判断当前集群中所有的主节点都恢复才认为操作恢复，而简单的做法是每次探测恢复的set操作都设置不同的key以求能尽可能散列到不同的节点去。可按照自身场景进行方案抉择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;step2：恢复缓存写操作&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;若redis恢复，缓存的写操作就可以恢复了。即可在更新操作中进行加锁、更新DB、删除缓存。但是此时读操作还不能立即恢复，因为redis不可用期间发生了DB变更但是缓存并没有变更，依然为老数据，因此需要将这部分老数据剔除后才能恢复读操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;step3：校验挤压的cache_key_queue记录&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;     &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;轮训查看cache_key_queue表中是否有记录存在，若存在记录则认为当前有不一致的缓存数据，需要等待定时任务将暂存的key表记录对应的缓存全部删除（同时也会删除cache_key_queue表记录）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; step4：恢复缓存读操作&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;若当前不存在cache_key_queue记录则可恢复读操作。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;      &lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以上阐述了redis缓存的自动熔断和恢复方案。需要明确的是，能够进行熔断是有前提条件的，即应用完全去掉缓存，DB还是可以抗住一段时间压力的，否则一旦出现缓存服务故障，流量全部走到应用，超过了应用和DB的承受能力，将服务压垮，后果更加严重。所以不能强依赖熔断机制，不能强依赖缓存，而这就需要接口限流等其他手段来从整体上保证服务的高可用。此外可进行定期压测，来锚定服务性能上限，进而不断优化对各种策略和资源的配置。&lt;/span&gt;&lt;/section&gt;&lt;h3&gt;&lt;br/&gt;&lt;/h3&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;3.5 总结&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上描述了我们强一致性缓存方案的设计思路及一些实现细节。基于该方案，我们核心数据库的QPS降低了80%，缓存的命中率达到92%。而该方案的关键是通过加锁来控制读写，&lt;/span&gt;&lt;span&gt;从表面上看会牺牲一些性能，但是实际上高缓存命中率同样弥补了此缺陷，缓存的建立使得我们服务查询接口AVG响应时间降低了10%左右。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.18125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6kJxFSbkwNJfHIWReJ21wvic2jXhMuwr6CNDk1pjGuSZ3zRVZDEcQ42hQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;&lt;strong&gt;&lt;span&gt;四、结语&lt;/span&gt;&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;&lt;span&gt;      &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上分别描述了我们的最终一致性和强一致性缓存设计和实现思路。两套缓存方案侧重点各有不同：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;此外，我们的最终一致性缓存方案是独立的缓存服务，而该强一致缓存方案，是需要嵌入到应用系统中去使用的。方案的选择需要立足于自身场景，希望我们的分享能够给大家带来一些启发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;团队招聘信息&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们是携程金融团队，从事支付、信贷等金融业务，这里拥有优秀、强大、富有创造性的团队，可以与你一起不断研究行业新技术，找寻业务解决方案的最优解，构建可驱动业务发展的技术价值体系。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果你热爱技术，喜欢挑战，渴望不断成长，携程金融期待与你一起腾飞。目前我们前端、后端、测试等大量技术职位开放。简历投递邮箱：tech@trip.com，邮件标题：【姓名】-【携程金融】-【投递职位】。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;【推荐阅读】&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/kEeDgfCVf1fJ4bmKmXiaR8Lu16W0yug6kxzSLSBveXYicSqD1JgdicDpl9NoNy6zeY9vEBZZoxtWDDKsVlcfVwu5Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt; “携程技术”公众号&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;  分享，交流，成长&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>b144105616152d8d36cb5964fa175d60</guid>
<title>[推荐] [译] 2021 年 Java 集合面试 Top 问题（一）</title>
<link>https://toutiao.io/k/zbogucw</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;blockquote&gt;&lt;p&gt;原文:https://dzone.com/articles/top-java-collection-interview-questions-for-2021&lt;/p&gt;&lt;p&gt;作者: Sonia Mathias&lt;/p&gt;&lt;p&gt;翻译: 祝坤荣&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;在Java中，集合是一种提供了存储与操作批量对象的框架。在JDK1.2中“集合框架”就被定义了，而且它提供了所有的集合类和接口。Java集合类中最主要的两个主要接口是Collection接口（java.util.Collection）和Map接口（java.util.Map）。Java集合框架提供的接口包括Set,List,Queue,Deque，提供类包括ArrayList,Vector,LinkedList,HashSet,PriorityQueue,TreeSet和LinkedHashSet。&lt;/p&gt;&lt;h2&gt;需要一个分离的集合框架&lt;/h2&gt;&lt;p&gt;如果我们不使用集合框架，标准的用于给Java对象分组的方法是Arrays,Vectors或者HashTable。他们都没有通用的接口。他们的实现都是被单独定义的且互相之间没有任何联系。因此，要去记住所有不同的方法，语法，和创建函数都很困难。&lt;/p&gt;&lt;p&gt;比如，如果要给Vector加一个元素我们会使用addElement()方法，而给Hashtable加一个元素则使用put()方法。&lt;/p&gt;&lt;h2&gt;使用集合框架的好处&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1.&lt;/span&gt;降低编程负担：一个开发者可以聚焦在集合的最佳使用方法上而不是聚焦在集合的设计上。这对实现抽象有好处。&lt;/span&gt;&lt;span&gt;&lt;span&gt;2.&lt;/span&gt;提升编程速度：集合提供了一种数据结构的高性能实现，这可以提升速度。&lt;/span&gt;&lt;span&gt;&lt;span&gt;3.&lt;/span&gt;由于Java已经是一种广泛使用的语言了，大大小小的组织都在使用它。为自己准备好基础的和高级的Java面试题可以对面试有好处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;让我们看看java面试中被问得最多的一些问题。&lt;/p&gt;&lt;h2&gt;对初级开发者问的最多的问题&lt;/h2&gt;&lt;p&gt;问题1：什么是Java中的框架？答：框架是提供了脚手架功能的一组类和对象的集合。理想的面向对象设计都应该有一个框架提供了对于集合类的同类型任务提供同样的操作。&lt;/p&gt;&lt;p&gt;问题2：定义Java的集合框架。答：Java的集合框架是一组接口和类的集合，提供了高效保存和处理数据的方法。Java集合框架提供的接口有Set，List，Queue，Deque，提供的类包括ArrayList,Vector,LinkedList,HashSet,PriorityQueue,TreeSet和LinkedHashSet。&lt;/p&gt;&lt;p&gt;问题3：Java集合框架中ArrayList与Vector的不同之处。答：ArrayList&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;不是synchronized的&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它可以以其数组大小的50%来扩展其大小&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它不是线程安全的&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它不是遗留类 Vector：&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它是synchronized的&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它可以增加自己双倍的大小&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它是线程安全的&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它是遗留类&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;问题4：Iterator与Enumeration的不同点。答：Iterator&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它可以遍历遗留类和非遗留类&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它比Enumeration慢&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它在遍历集合时可以执行remove操作&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它是fail-fast的&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Enumeration&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它只能遍历遗留元素&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它比Iterator快&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它只能在集合上执行traverse&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它不是fail-fast的&lt;/span&gt;&lt;/p&gt;&lt;p&gt;问题5：LinkedList与ArrayList的区别？答：ArrayList&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;这个类实现了list接口&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;这个类使用了动态数组来存储元素&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;插入与移除操作的最佳复杂度是O（1），而最差复杂度是O（n）。查询操作（如存储一个特定索引的元素）会需要O（1）的时间。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;ArrayList在存储和查询数据时能干的比较好。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;LinkedList&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;这个类实现了list接口和deque接口。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;这个类存储元素使用了双链列表。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;插入与移除操作提供了O（1）的性能。查询操作（比如查询一个特定索引的元素）需要O（n）的时间。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;LinkedList在操作存储好的数据时性能更好。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;问题6：解释一下Queue接口的poll（）与remove（）方法的不同。答：两个方法都返回并移除队列头的内容。它们只有在队列为空时行为不一样；remove（）会抛一个异常而poll（）会返回null。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;问题7：Comparable与Comparator的不同。答：Comparable&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它提供了被排序元素使用的compareTo（）方法&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它属于java.lang包&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;排序逻辑必须要与我们想要排序的对象在同一个类中&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它提供单独的排序序列。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;实际类被改过了&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Comparator&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它提供排序元素用的compare（）方法&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它在java.util包中&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;排序逻辑必须要在不同的类中，以便根据不同对象的不同属性来编写排序方法&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;它提供多种排序序列&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;实际类没有被改动&lt;/span&gt;&lt;/p&gt;&lt;p&gt;问题8：计算机内存中Stack的定义是？答：stack是计算机内存中一个特殊区域，用来存储函数创建的临时变量。在stack中，变量是在运行时被声明，存储和初始化的。&lt;/p&gt;&lt;p&gt;问题9：列出map接口的集合视图。答：集合视图（Collection view）方法可以让Map在以下&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;三种方式视为一个集合：&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;键集合视图：Map中保存的所有键的Set集合。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;值集合视图：Map中保存的所有值的集合。这个集合不是一个Set，因为不同的主键key可以被映射到同一个值value。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;Entry集合视图：Map中键值对的集合Set。Map接口提供了一个小的内嵌接口Map.Entry，元素都存储在这个Set。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;问题10：定义EnumSet。答：它是可以使用enum枚举类型的Set实现。所有的元素都必须属于一个特定的enum类型。它不是synchronized。NULL key是不允许的。&lt;/p&gt;&lt;p&gt;问题11：什么方法能让集合变成线程安全的？答：这些方法是：&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;Collections.synchronizedList(list);&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;Collections.synchronizedMap(map);&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;Collections.synchronizedSet(set);&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;问题12：Queue与Deque的不同点 答：Queue&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;众所周知是单向队列&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;队列中的元素在填加或删除都在同一端&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;Less versatile Deque&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;是双端队列&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;队列中的元素可以从队尾填加或者从两端填加和删除。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;More versatile&lt;/span&gt;&lt;/p&gt;&lt;p&gt;问题13：hashmap与hashtable的不同 答：Hashmap&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;不是synchronized，不是线程安全&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;继承了AbstractMap类&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;允许一个null key和多个null value。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;可以被iterator遍历 Hashtable&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;Synchronized的，线程安全&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;继承了Dictionary类&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;不允许空key或者值&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;可以被enumerator和iterator遍历&lt;/span&gt;&lt;/p&gt;&lt;p&gt;问题14：定义Iterator。答：Iterator（）是一个提供了遍历集合方法的接口。它提供了一种普世的方式来遍历集合中的元素，并实现了iterator设计模式。&lt;/p&gt;&lt;p&gt;问题15：什么是navigable map？答：NavigableMap接口，Java集合框架的成员，属于java.util包。它是SortedMap的子接口，提供了如lowerKey，floorKey，ceilingKey和higherKey这样方便的导航方法。它也提供了从现有map创建一个子map的方法。&lt;/p&gt;&lt;p&gt;问题16：什么是queue接口的peek（）？答：Peek（）返回了队列的头。它不移除任何元素。当队列为空时返回null。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;未完待续&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;本文来自祝坤荣(时序)的微信公众号「麦芽面包」，公众号id「darkjune_think」 &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;开发者/科幻爱好者/硬核主机玩家/业余翻译 转载请注明。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;微博:祝坤荣 B站: https://space.bilibili.com/23185593/&lt;/p&gt;&lt;p&gt;交流Email: &lt;span&gt;zhukunrong@yeah.net&lt;sup&gt;[1]&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;References&lt;/h3&gt;&lt;p&gt;&lt;code&gt;[1]&lt;/code&gt; zhukunrong@yeah.net: &lt;em&gt;mailto:zhukunrong@yeah.net&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>