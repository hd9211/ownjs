<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>1b27505659a7175f349f6aebb08695fa</guid>
<title>从 Spark 做批处理到 Flink 做流批一体</title>
<link>https://toutiao.io/k/tryss1z</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p id=&quot;js_tags&quot; class=&quot;article-tag__list single-tag__wrp js_single&quot; data-len=&quot;1&quot; role=&quot;link&quot; aria-labelledby=&quot;js_article-tag-card__left&quot; aria-describedby=&quot;js_article-tag-card__right&quot;&gt;
                                            
                                                                                    &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__left&quot; class=&quot;article-tag-card__left&quot;&gt;
                                    &lt;span class=&quot;article-tag-card__title&quot;&gt;收录于话题&lt;/span&gt;
                                    &lt;span class=&quot;article-tag__item-wrp no-active js_tag&quot; data-url=&quot;https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU3Mzg4OTMyNQ==&amp;amp;action=getalbum&amp;amp;album_id=1929702550740484100#wechat_redirect&quot; data-tag_id=&quot;&quot; data-album_id=&quot;1929702550740484100&quot; data-tag_source=&quot;4&quot;&gt;
                                        &lt;span class=&quot;article-tag__item&quot;&gt;#行业案例&lt;/span&gt;
                                    &lt;/span&gt;
                                &lt;/span&gt;
                                &lt;span aria-hidden=&quot;true&quot; id=&quot;js_article-tag-card__right&quot; class=&quot;article-tag-card__right&quot;&gt;52个&lt;span class=&quot;weui-hidden_abs&quot;&gt;内容&lt;/span&gt;&lt;/span&gt;
                                                                                        &lt;/p&gt;

                
                                
                
                

                
                                                                

                
                                


                
                
                
                
                                                
                                                                
                                
                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section&gt;&lt;span&gt;&lt;span&gt;▼ 关注「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Flink 中文社区&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，获取更多技术干货 &lt;span&gt;▼&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU3Mzg4OTMyNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6FJHxaI14AsXuzeg4SybT0hiaCSohrIY75oiaOMzhQU7RouiafjNa76k2CtD6xxB2JqnawqFqV3zg3A/0?wx_fmt=png&quot; data-nickname=&quot;Flink 中文社区&quot; data-alias=&quot;&quot; data-signature=&quot;Apache Flink 官微，Flink PMC 维护&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/span&gt;本⽂由社区志愿者苗文婷整理，内容来源⾃ LinkedIn 大数据高级开发工程师张晨娅在 Flink Forward Asia 2020 分享的《从 Spark 做批处理到 Flink 做流批一体》，主要内容为：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;为什么要做流批一体？&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;当前行业已有的解决方案和现状，优势和劣势&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;探索生产实践场景的经验&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Shuflle Service 在 Spark 和 Flink 上的对比，以及 Flink 社区后面可以考虑做的工作&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Tips：&lt;/strong&gt;FFA 2021 重磅开启，点击&lt;/span&gt;&lt;span&gt;&lt;strong&gt;「阅读原&lt;/strong&gt;&lt;strong&gt;文」&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;即可报名～&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;img data-ratio=&quot;1&quot; data-type=&quot;png&quot; data-w=&quot;20&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu78FqIxdIQicVe5cg78bpax1XDKxMS06V8h6bib5fhicN8n5zK7Z4oDWWgzgbAeCibuKRnD5eibTcg73mg/640?wx_fmt=png&quot;/&gt; GitHub 地址 &lt;img data-ratio=&quot;1&quot; data-type=&quot;png&quot; data-w=&quot;20&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu78FqIxdIQicVe5cg78bpax1XDKxMS06V8h6bib5fhicN8n5zK7Z4oDWWgzgbAeCibuKRnD5eibTcg73mg/640?wx_fmt=png&quot;/&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;欢迎大家给 Flink 点赞送 star~&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.024390243902439&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu58p6JubKoFyrKVibtOyk1CTpJialGPpBBg6uRknWESa1xwDsR8yeKiah9z0lnproCED8dp6l4bmfgQQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;492&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;一、为什么要做流批一体&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p cid=&quot;n17&quot; mdtype=&quot;paragraph&quot;&gt;&lt;/p&gt;&lt;p cid=&quot;n17&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvR500asINpicaZXVQWQqwkS0seuG0KcPkxLsfw9wxJdlZhdewtibU08KQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;做流批一体到底有哪些益处，尤其是在 BI/AI/ETL 的场景下。整体来看，如果能帮助用户做到流批一体，会有以上 4 个比较明显的益处：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;可以避免代码重复，复用代码核心处理逻辑&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;代码逻辑能完全一致是最好的，但这会有一定的难度。&lt;span&gt;但整体来讲，现在的商业逻辑越来越长，越来越复杂，要求也很多，如果我们使用不同的框架，不同的引擎，用户每次都要重新写一遍逻辑，压力很大并且难以维护。所以整体来讲，尽量避免代码重复，帮助用户复用代码逻辑，就显得尤为重要。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;流批一体有两个方向&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这两个方向要考虑的问题很不一样，目前 Flink 做 Streaming、Spark 做 Batch 等等一些框架在批处理或流处理上都比较成熟，都已经产生了很多的单方面用户。&lt;span&gt;当我们想帮助用户移到另外一个方向上时，比如一些商业需求，通常会分成两类，是先从流处理开始到批处理，还是从批处理开始到流处理。之后介绍的两个生产实践场景案例，正好对应这两个方向。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;减少维护工作量&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;避免维护多套系统，系统之间的差异可能非常大，框架和引擎都不一样，会带来比较多的问题。&lt;span&gt;如果公司内部有多条 pipeline ，一个实时一个离线，会造成数据不一致性，因此会在数据验证、数据准确性查询、数据存储等方面做很多工作，尽量去维护数据的一致性。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;学习更多&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;框架和引擎很多，商业逻辑既要跑实时，也要跑离线，所以，支持用户时需要学习很多东西。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;二、当前行业现状&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p cid=&quot;n17&quot; mdtype=&quot;paragraph&quot;&gt;&lt;/p&gt;&lt;p cid=&quot;n42&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvgHibquWicWEqKvrqzC7wCRPjgzr3uLssks17l6DlcaCu28OPUsHhb8oQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink 和 Spark 都是同时支持流处理和批处理的引擎。我们一致认为 Flink 的流处理做的比较好，那么它的批处理能做到多好？同时，Spark 的批处理做的比较好，那么它的流处理能不能足够帮助用户解决现有的需求？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;现在有各种各样的引擎框架，能不能在它们之上有一个统一的框架，类似于联邦处理或者是一些简单的 physical API，比如 Beam API 或者是自定义接口。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Beam 方面需要考虑的问题，是它在批处理和流处理上的优化能做到多好？Beam 目前还是偏物理执行，之后的计划是我们需要考究的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;LinkedIn，包括其他公司，会考虑做一些自定义接口的解决方案，考虑有一个共通的 SQL 层，通用的 SQL 或 API 层，底下跑不同的框架引擎。这里需要考虑的问题是，像 Spark 、Flink 都是比较成熟的框架了，已经拥有大量的用户群体。当我们提出一个新的 API ，一个新的解决方案，用户的接受度如何? 在公司内部应该如何维护一套新的解决方案？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;三、生产案例场景&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p cid=&quot;n17&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n17&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;后面内容主要聚焦在 Flink 做 batch 的效果，Flink 和 Spark 的简单对比，以及 LinkedIn 内部的一些解决方案。分享两个生产上的实例场景，一个是在机器学习特征工程生成时如何做流批一体，另一个是复杂的 ETL 数据流中如何做流批一体。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h2 cid=&quot;n51&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3.1 案例 A - 机器学习特征工程&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n52&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvxicicoJIj0zibGnT30NsUPG2jGq0tA1HGtAKICPLnF4XRC3EDBXt8nU2w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;第一类方向，流处理 -&amp;gt; 批处理，归类为流批一体。&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;案例 A 的主体逻辑是在机器学习中做特征生成时，如何从流处理到批处理的流批一体。核心的业务逻辑就是特征转换，转化的过程和逻辑比较复杂，用它做一些标准化。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;比如在 LinkedIn 的页面上输入的一些会员信息背景等，需要将这些信息提取出来标准化掉，才能进行一些推荐，帮你找一些工作等等。当会员的身份信息有更新时，会有过滤、预处理的逻辑、包括读取 Kafka 的过程，做特征转换的过程中，可能会有一些小表查询。这个逻辑是非常直接的，没有复杂的 join 操作及其他的数据处理过程。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n56&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvd2vH2rENaw6eBTicW4YPPkzgJcJthDqOF87edz5fbKmhOZzI2r78txg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以前它的 pipeline 是实时的，需要定期从离线 pipeline 中读取补充信息来更新流。这种 backfill 对实时集群的压力是很大的，在 backfill 时，需要等待 backfill 工作起来，需要监控工作流不让实时集群宕掉。所以，用户提出能不能做离线的 backfill，不想通过实时流处理做 backfill。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;当前我们的用户是使用 Beam on Samza 做流处理，他们非常熟悉 Beam API 和 Spark Dataset API，也会用 Dataset API 去做除了 backfill 之外的一些其他业务处理。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;需要特别强调的是， Dataset API 很多都是直接对 Object 操作，对 type 安全性要求很高，如果建议这些用户直接改成 SQL 或者 DataFrame 等 workflow 是不切实际的，因为他们已有的业务逻辑都是对 Object 进行直接操作和转化等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n60&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvf0iclysXk2ZS7puelqu4oMJuzGVasbgMHdRlL83xKGYibAz8dnOSJYRw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;在这个案例下，我们能提供给用户一些方案选择，Imperative API 。看下业界提供的方案：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n70&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvQpyvspwiarPvfp0CnbzibpXZqz62EdqrfEEIIoXV6CHdnSGPO22Y9LDw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;从用户的反馈上来说，Flink 的 DataStream (DataSet) API 和 Spark 的 Dataset API 在用户 interface 上是非常接近的。作为 Infra 工程师来说，想要帮用户解决问题，对 API 的熟悉程度就比较重要了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;但是 Beam 和 Flink 、Spark 的 API 是非常不一样的，它是 Google 的一条生态系统，我们之前也帮助用户解决了一些问题，他们的 workflow 是在 Beam on Samza 上，他们用 p collections 或者 p transformation 写了一些业务逻辑，output、input 方法的 signature 都很不一样，我们开发了一些轻量级 converter 帮助用户复用已有的业务逻辑，能够更好的用在重新写的 Flink 或 Spark 作业里。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;从 DAG 上来看，案例 A 是一个非常简单的业务流程，就是简单直接的对 Object 进行转换。Flink 和 Spark 在这个案例下，性能表现上是非常接近的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n77&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvrUBWItmKI4Et279Vlk66lcTCNthAx7ujXy6ewdcibT3ewQZdR5ByvSA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;通常，我们会用 Flink Dashboard UI 看一些异常、业务流程等，相比 Spark 来说是一个比较明显的优势。Spark 去查询 Driver log，查询异常是比较麻烦的。但是 Flink 依旧有几个需要提升的地方：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;History Server - 支持更丰富的 Metrics 等&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n83&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJv8ZbdmNNMT3Y9p2sf9QjWs9PvPt0Glv0AACzMStXO0aibQne8HsjIK2w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Spark History Server UI 呈现的 metrics 比较丰富的，对用户做性能分析的帮助是比较大的。Flink 做批处理的地方是否也能让 Spark 用户能看到同等的 metrics 信息量，来降低用户的开发难度，提高用户的开发效率。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p cid=&quot;n89&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvcGM1uaLVuZhTTjhzpJnDAqkuw3tqyF02XUj42Vw2SX6ILmcGKrSkIA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;分享一个 LinkedIn 从两三年前就在做的事情。LinkedIn 每天有 200000 的作业跑在集群上，需要更好的工具支持批处理用户运维自己的作业，我们提供了 Dr. Elephant 和 GridBench 来帮助用户调试和运维自己的作业。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Dr. Elephant 已开源，能帮助用户更好的调试作业，发现问题并提供建议。另外，从测试集群到生产集群之前，会根据 Dr. Elephant 生成的报告里评估结果的分数来决定是否允许投产。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;GridBench 主要是做一些数据统计分析，包括 CPU 的方法热点分析等，帮助用户优化提升自己的作业。GridBench 后续也有计划开源，可以支持各种引擎框架，包括可以把 Flink 加进来，Flink job 可以用 GridBench 更好的做评估。GridBench Talk: Project Optimum: Spark Performance at LinkedIn Scale [7]。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;用户不仅可以看到 GridBench 生成的报告，Dr. Elephant 生成的报告，也可以通过命令行看到 job 的一些最基本信息，应用 CPU 时间、资源消耗等，还可以对不同 Spark job 和 Flink job 之间进行对比分析。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;以上就是 Flink 批处理需要提升的两块地方。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;h2 cid=&quot;n101&quot; mdtype=&quot;heading&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;3.2 案例 B - 复杂的 ETL 数据流&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n102&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJv6IPLWnsnRUwOQLPNe89TMzh2pOpxfHC6gkicc7KVDosXbmQeQGDsNxQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;第二类方向，批处理 -&amp;gt; 流处理，归类为流批一体。&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;ETL 数据流的核心逻辑相对复杂一些，比如包括 session window 聚合窗口，每个小时计算一次页面的用户浏览量，分不同的作业，中间共享 metadata table 中的 page key，第一个作业处理 00 时间点，第二个作业处理 01 时间点，做一些 sessionize 的操作，最后输出结果，分 open session、close session ，以此来做增量处理每个小时的数据。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n107&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJv5nAU6NTXTvfNQWLKekaHFicvHpgkJS8CJ4qZoTQrMWuhdFoiaticibIeUg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这个 workflow 原先是通过 Spark SQL 做的离线增量处理，是纯离线的增量处理。当用户想把作业移到线上做一些实时处理，需要重新搭建一个比如 Beam On Samza 的实时的 workflow，在搭建过程中我们和用户有非常紧密的联系和沟通，用户是遇到非常多的问题的，包括整个开发逻辑的复用，确保两条业务逻辑产生相同的结果，以及数据最终存储的地方等等，花了很长时间迁移，最终效果是不太好的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;另外，用户的作业逻辑里同时用 Hive 和 Spark 写了非常多很大很复杂的 UDF ，这块迁移也是非常大的工作量。用户对 Spark SQL 和 Spark DataFrame API 是比较熟悉的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上图中的黑色实线是实时处理的过程，灰色箭头主要是批处理的过程，相当于是一个 Lambda 的结构。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n112&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvXF6TAkRZOEwbctsxUGIDIl3ibd7mnTRZLEUcnXRz1tTrMlzxShDAFvQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;针对案例 B，作业中包括很多 join 和 session window，他们之前也是用 Spark SQL 开发作业的。很明显我们要从 Declartive API 入手，当前提供了 3 种方案：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第一个选择是 Flink Table API/SQL ，流处理批处理都可以做，同样的SQL，功能支持很全面，流处理和批处理也都有优化。可以看下文章 Alibaba Cloud Blog: What&#x27;s All Involved with Blink Merging with Apache Flink? [8] 和 FLINK-11439 INSERT INTO flink_sql SELECT * FROM blink_sql [9]。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二个选择是  Spark DataFrame API/SQL ，也是可以用相同的 interface 做批处理和流处理，但是 Spark 的流处理支持力度还是不够的。可以看下文章 Databricks Blog: Deep Dive into Spark SQL’s Catalyst Optimizer [10] 和 Databricks Blog: Project Tungsten: Bringing Apache Spark Closer to Bare Metal [11]。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第三个选择是 Beam Schema Aware API/SQL ，Beam 更多的是物理的 API ，在 Schema Aware API/SQL 上目前都在开展比较早期的工作，暂不考虑。所以，之后的主要分析结果和经验都是从 Flink Table API/SQL 和 Spark DataFrame API/SQL 的之间的对比得出来的。可以看下文章 Beam Design Document - Schema-Aware PCollections [12] 和 Beam User Guide - Beam SQL overview [13]。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n122&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvlWlcaicb7jOsuNYHQMoTPJRfC2Shj5Ub286425K651GOl3upu9FQX5Q/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;从用户的角度来说，Flink Table API/SQL 和 Spark DataFrame API/SQL 是非常接近的，有一些比较小的差别，比如 keywords、rules、 join 具体怎么写等等，也会给用户带来一定的困扰，会怀疑自己是不是用错了。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink 和 Spark 都很好的集成了 Hive ，比如 HIve UDF 复用等，对案例B中的 UDF 迁移，减轻了一半的迁移压力。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink 在 pipeline 模式下的性能是明显优于 Spark 的，可想而知，要不要落盘对性能影响肯定是比较大的，如果需要大量落盘，每个 stage 都要把数据落到磁盘上，再重新读出来，肯定是要比不落盘的 pipeline 模式的处理性能要差的。pipeline 比较适合短小的处理，在 20 分钟 40 分钟还是有比较大的优势的，如果再长的 pipeline 的容错性肯定不能和 batch 模式相比。Spark 的 batch 性能还是要比 Flink 好一些的。这一块需要根据自己公司内部的案例进行评估。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n128&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvfseKEG6efTCuX52ibWAJcUx248o8alED0VHmv1bV0GoM4HaSkWXOibcQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Flink 对 window 的支持明显比其他引擎要丰富的多，比如 session window，用户用起来非常方便。我们用户为了实现 session window ，特意写了非常多的 UDF ，包括做增量处理，把 session 全部 build 起来，把 record 拿出来做处理等等。现在直接用 session window operator ，省了大量的开发消耗。同时 group 聚合等 window 操作也都是流批同时支持的。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Session Window：&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;pre spellcheck=&quot;false&quot; cid=&quot;n132&quot; mdtype=&quot;fences&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;// Session Event-time Window&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;.window(Session withGap 10.minutes on $&quot;rowtime&quot; as $&quot;w&quot;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;// Session Processing-time Window (assuming a processing-time attribute &quot;proctime&quot;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;.window(Session withGap 10.minutes on $&quot;proctime&quot; as $&quot;w&quot;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;Slide Window：&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;pre spellcheck=&quot;false&quot; cid=&quot;n134&quot; mdtype=&quot;fences&quot;&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;// Sliding Event-time Window&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;.window(Slide over 10.minutes every 5.minutes on $&quot;rowtime&quot; as $&quot;w&quot;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;// Sliding Processing-time Window (assuming a processing-time attribute &quot;proctime&quot;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;.window(Slide over 10.minutes every 5.minutes on $&quot;proctime&quot; as $&quot;w&quot;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;// Sliding Row-count Window (assuming a processing-time attribute &quot;proctime&quot;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;.window(Slide over 10.rows every 5.rows on $&quot;proctime&quot; as $&quot;w&quot;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/pre&gt;&lt;p cid=&quot;n137&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvqegicsFpNwRCdFcHuSicLoI9G4OEFiclGSRS2fTqBfPicp07xjuTahMy0w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;UDF 是在引擎框架之间迁移时最大的障碍。如果 UDF 是用 Hive 写的，那是方便迁移的，因为不管是 Flink 还是 Spark 对 Hive UDF 的支持都是很好的，但如果 UDF 是用 Flink 或者 Spark 写的，迁移到任何一个引擎框架，都会遇到非常大的问题，比如迁移到 Presto 做 OLAP 近实时查询。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了实现 UDF 的复用，我们 LinkedIn 在内部开发了一个 transport 项目，已经开源至 github [14] 上, 可以看下 LinkedIn 发表的博客：Transport: Towards Logical Independence Using Translatable Portable UDFs [15]。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;transport 给所有引擎框架提供一个面向用户的 User API ，提供通用的函数开发接口，底下自动生成基于不同引擎框架的 UDF ，比如 Presto、Hive、Spark、Flink 等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;用一个共通的 UDF API 打通所有的引擎框架，能让用户复用自己的业务逻辑。用户可以很容易的上手使用，比如如下用户开发一个 MapFromTwoArraysFunction:&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;java&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;public class MapFromTwoArraysFunction extends StdUDF2&amp;lt;StdArray,StdArray,StdMap&amp;gt;{&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    private StdType _mapType;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    @Override&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    public List&amp;lt;String&amp;gt; getInputParameterSignatures(){&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        return ImmutableList.of(&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            &quot;array[K]&quot;,&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;            &quot;array[V]&quot;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        );&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    @Override&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    public String getOutputParameterSignature(){&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        return &quot;map(K,V)&quot;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;@Override&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;public void init(StdFactory stdFactory){&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    super.init(stdFactory);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;@Override&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;public StdMap eval(StdArray a1, StdArray a2){&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    if(a1.size() != a2.size()) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        return null;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    StdMap map = getStdFactory().createMap(_mapType);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    for(int i = 0; i &amp;lt; a1.size; i++) {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        map.put(a1.get(i), a2.get(i));&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    }&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    return map;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p cid=&quot;n147&quot; mdtype=&quot;paragraph&quot;&gt;&lt;/p&gt;&lt;p cid=&quot;n147&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJviaicsKfr43UaRicIib4Bw9WBjG5biaib6UgZGxhEAaHNdSARXnsf335Rdplw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;处理用户的 SQL 迁移问题 ，用户之前是用 Spark SQL 开发的作业，之后想使用流批一体，改成 Flink SQL 。目前的引擎框架还是比较多的，LinkedIn 开发出一个 coral 的解决方案，已在 github [16] 上开源，在 facebook 上也做了一些 talk ，包括和 transport UDF 一起给用户提供一个隔离层使用户可以更好的做到跨引擎的迁移，复用自己的业务逻辑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;看下 coral 的执行流程，首先作业脚本中定义 熟悉的 ASCII SQL 和 table 的属性等，之后会生成一个 Coral IR 树状结构，最后翻译成各个引擎的 physical plan。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n152&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJv8ydJsvo1oaDFl1rnbzoviavku17MiaeomwCRibQyXzUsfJjCJHK7Kwgvg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在案例 B 分析中，流批统一，在集群业务量特别大的情况下，用户对批处理的性能、稳定性、成功率等是非常重视的。其中 Shuffle Service ，对批处理性能影响比较大。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;四、Shuffle Service &lt;/strong&gt;&lt;/p&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;在 Spark 和 Flink 上的对比&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p cid=&quot;n157&quot; mdtype=&quot;paragraph&quot;&gt;&lt;/p&gt;&lt;p cid=&quot;n157&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJv3X0fILvqZFkbGd0yplmC72WZdn7xYFlwZqVBsUdOWWKkaPGZ4nPQIw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;In-memory Shuffle，Spark 和 Flink 都支持，比较快，但不支持可扩展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Hash-based Shuffle ，Spark 和 Flink 都支持 ， 相比 In-memory Shuffle ，容错性支持的更好一些，但同样不支持可扩展。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Sort-based Shuffle，对大的 Shuffle 支持可扩展，从磁盘读上来一点一点 Sort match 好再读回去，在 FLIP-148: Introduce Sort-Based Blocking Shuffle to Flink  [17] 中也已经支持。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;External Shuffle Service， 在集群非常繁忙，比如在做动态资源调度时，外挂服务就会非常重要，对 Shuffle 的性能和资源依赖有更好的隔离，隔离之后就可以更好的去调度资源。FLINK-11805 A Common External Shuffle Service Framework [18] 目前处于 reopen 状态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Disaggregate Shuffle，大数据领域都倡导 Cloud Native 云原生，计算存储分离在 Shuffle Service 的设计上也是要考虑的。FLINK-10653 Introduce Pluggable Shuffle Service Architecture [19] 引入了可插拔的 Shuffle Service 架构。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n165&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvAcsbmPxpmOp5aYT1SkkVVhCRODMQbk15YB5FTlGQQkd6yfdLIwUPlw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Spark 对 Shuffle Service 做了一个比较大的提升，这个工作也是由 LinkedIn 主导的 magnet 项目，形成了一篇名称为 introducing-magnet 的论文 (Magnet: A scalable and performant shuffle architecture for Apache Spark) [20]，收录到了 LinkedIn blog 2020 里。magnet 很明显的提升了磁盘读写的效率，从比较小的 random range ，到比较大的顺序读，也会做一些 merging ，而不是随意的随机读取 shuffle data ，避免 random IO 的一些问题。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n169&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvQ5QUS1icJC10EtiaGOj10kEugqCNBtutCGvC4fZLIr9vntpT3iaYic9PXA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;通过 Magent Shuffle Service 缓解了 Shuffle 稳定性和可扩展性方面的问题。在此之前，我们发现了很多 Shuffle 方面的问题，比如 Job failure 等等非常高。如果想用 Flink 做批处理，帮助到以前用 Spark 做批处理的用户，在 Shuffle 上确实要花更大功夫。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在 Shuffle 可用性上，会采用 best-effort 方式去推 shuffle blocks，忽略一些大的 block ，保证最终的一致性和准确性；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;为 shuffle 临时数据生成一个副本，确保准确性。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果 push 过程特别慢，会有提前终止技术。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Magent Shuffle 相比 Vanilla Shuffle ，读取 Shuffle data 的等待时间缩较少了几乎 100%，task 执行时间缩短了几乎 50%，端到端的任务时长也缩短了几乎 30%。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p cid=&quot;n182&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.19018867924528302&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvEicsAjo64iaoFs8gyic7DJLTXC3xiaTsEGKibObEibmE8wolEZnibXsgAicRNQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2650&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p cid=&quot;n68&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;五、总结&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p cid=&quot;n185&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6HhibXew3LttuGqCuZicWtJvjeA4x2D07KdlTeiaJtjdwWpyibwdiaHFj2yp83Rxhk6wUTISicTBia6GzicA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;LinkedIn 非常认可和开心看到 Flink 在流处理和批处理上的明显优势，做的更加统一，也在持续优化中。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Flink 批处理能力有待提升，如 history server，metrics，调试。用户在开发的时候，需要从用户社区看一些解决方案，整个生态要搭建起来，用户才能方便的用起来。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Flink 需要对 shuffle service 和大集群离线工作流投入更多的精力，确保 workflow 的成功率，如果规模大起来之后，如何提供更好的用户支持和对集群进行健康监控等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;随着越来越多的框架引擎出现，最好能给到用户一个更加统一的 interface，这一块的挑战是比较大的，包括开发和运维方面，根据 LinkedIn 的经验，还是看到了很多问题的，并不是通过一个单一的解决方案，就能囊括所有的用户使用场景，哪怕是一些 function 或者 expression，也很难完全覆盖到。像 coral、transport UDF。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;52&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;span&gt;原视频：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;https://www.bilibili.com/video/BV13a4y1H7XY?p=12&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;参考链接&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[1] &lt;span&gt;https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=158866741&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[2] &lt;span&gt;https://cwiki.apache.org/confluence/display/FLINK/FLIP-134%3A+Batch+execution+for+the+DataStream+API&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[3] &lt;span&gt;https://databricks.com/blog/2016/01/04/introducing-apache-spark-datasets.html&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[4] &lt;span&gt;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#unsupported-operations&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[5] &lt;span&gt;https://beam.apache.org/documentation/runners/spark/&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[6] &lt;span&gt;https://issues.apache.org/jira/browse/BEAM-8470&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[7] &lt;span&gt;https://www.youtube.com/watch?v=D47CSeGpBd0&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[8] &lt;span&gt;https://www.alibabacloud.com/blog/whats-all-involved-with-blink-merging-with-apache-flink_595401&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[9] &lt;span&gt;https://issues.apache.org/jira/browse/FLINK-11439&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[10] &lt;span&gt;https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[11] &lt;span&gt;https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[12] &lt;span&gt;https://docs.google.com/document/d/1tnG2DPHZYbsomvihIpXruUmQ12pHGK0QIvXS1FOTgRc/edit#heading=h.puuotbien1gf&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[13] &lt;span&gt;https://beam.apache.org/documentation/dsls/sql/overview/&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[14] &lt;span&gt;https://github.com/linkedin/transport&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[15] &lt;span&gt;https://engineering.linkedin.com/blog/2018/11/using-translatable-portable-UDFs&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[16] &lt;span&gt;https://github.com/linkedin/coral&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[17] &lt;span&gt;https://cwiki.apache.org/confluence/display/FLINK/FLIP-148%3A+Introduce+Sort-Based+Blocking+Shuffle+to+Flink&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[18] &lt;span&gt;https://issues.apache.org/jira/browse/FLINK-11805&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[19] &lt;span&gt;https://issues.apache.org/jira/browse/FLINK-10653&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;[20] &lt;span&gt;https://engineering.linkedin.com/blog/2020/introducing-magnet&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;hr/&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;&lt;img data-ratio=&quot;1&quot; data-type=&quot;png&quot; data-w=&quot;20&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu7FIXNc036LLUkKfmG7dYG4GXTiaRe5yCHLwJoVfZgIHG9mZgoBY0jnJWLIDRLeiafE0fnMYFOX9x3g/640?wx_fmt=png&quot;/&gt;  Flink Forward Asia 2021&lt;strong&gt;  &lt;img data-ratio=&quot;1&quot; data-type=&quot;png&quot; data-w=&quot;20&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu7FIXNc036LLUkKfmG7dYG4GXTiaRe5yCHLwJoVfZgIHG9mZgoBY0jnJWLIDRLeiafE0fnMYFOX9x3g/640?wx_fmt=png&quot;/&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;strong&gt;报名现已开放&lt;/strong&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;Flink Forward Asia 2021 重磅启动！FFA 2021 将于 12 月 4-5 日在北京·国家会议中心举办，预计将有 3000+ 开发者参与，探讨交流 Flink 最新动态。报名通道已开启，扫描下图二维码，或&lt;/span&gt;&lt;span&gt;点击文末「&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;阅读原文&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」即可报名 FFA 2021～&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu6ufbb8ec23OX3vzE6FpSYl22MoichPgpOcpgBNNb2ibLtr0mAYnCAaibx2CiclDADB4kIGQicCn1ibyjgA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;hr/&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;更多 Flink 相关技术问题，可扫码加入社区钉钉交流群～&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;1.2078189300411524&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6PUTQaA1BP3Fb8uViccQpspmTibIYEfM7Wv6VACia9CDQfcN8huMVCafZ5s36wThUmbYRTOzMu4hd8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;972&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt; &lt;img class=&quot;__bg_gif&quot; data-ratio=&quot;1&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/Z6bicxIx5naLWBBEcl44aIic1Mthe1nZiaramW5s4e8WwyCYYbTzu6uPBpgI6sxNXNymEnOYKpJpcrItUia7lS64mA/640?wx_fmt=gif&quot;/&gt;  &lt;/span&gt;&lt;span&gt;戳我，报名 FFA 2021 大会！&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>7c2633d12ad8359cc52691b1b484bb62</guid>
<title>实践篇：Redis 客户端缓存在 Spring Boot 应用的探究</title>
<link>https://toutiao.io/k/0qkonm0</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;p&gt;本文探究Redis最新特性--客户端缓存在SpringBoot上的应用实战。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;Redis Tracking&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;Redis客户端缓存机制基于Redis Tracking机制实现的。我们先了解一下Redis Tracking机制。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;为什么需要Redis Tracking&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;Redis由于速度快、性能高，常常作为MySQL等传统数据库的缓存数据库。但由于Redis是远程服务，查询Redis需要通过网络请求，在高并发查询情景中难免造成性能损耗。所以，高并发应用通常引入本地缓存，在查询Redis前先检查本地缓存是否存在数据。&lt;br/&gt;假如使用MySQL存储数据，那么数据查询流程下图所示。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;1.8895705521472392&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Of81vjDNtAy64LpuFbywiaWMWU8oLbic70lI9weNeA2PSuToG5DG8MXUic2KWXtblhZcaRiaqchgyXhEDHzib9HjIFA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;163&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;引入多端缓存后，修改数据时，各数据缓存端如何保证数据一致是一个难题。通常的做法是修改MySQL数据，并删除Redis缓存、本地缓存。当用户发现缓存不存在时，会重新查询MySQL数据，并设置Redis缓存、本地缓存。&lt;br/&gt;在分布式系统中，某个节点修改数据后不仅要删除当前节点的本地缓存，还需要发送请求给集群中的其他节点，要求它们删除该数据的本地缓存，如下图所示。如果分布式系统中节点很多，那么该操作会造成不少性能损耗。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;1.044776119402985&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Of81vjDNtAy64LpuFbywiaWMWU8oLbic70XYgZwaUQAa1RRibh4yrEL43eWGvLzibXTbX1FSdFR2xq6ERcuBurCicBA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;268&quot; title=&quot;&quot;/&gt;&lt;/figure&gt;&lt;p&gt;为此，Redis 6提供了Redis Tracking机制，对该缓存方案进行了优化。开启Redis Tracking后，Redis服务器会记录客户端查询的所有键，并在这些键发生变更后，发送失效消息通知客户端这些键已变更，这时客户端需要将这些键的本地缓存删除。基于Redis Tracking机制，某个节点修改数据后，不需要再在集群广播“删除本地缓存”的请求，从而降低了系统复杂度，并提高了性能。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;Redis Tracking的应用&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;下表展示了Redis Tracking的基本使用&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.5523138832997988&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Of81vjDNtAy64LpuFbywiaWMWU8oLbic70l2SABhbfreHLgHHFFwcRasEHiaRTybC3fngHsxibCyvNwZGJJqIgLkvw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;994&quot; title=&quot;picture 1&quot;/&gt;&lt;span/&gt;&lt;/figure&gt;&lt;br/&gt;（1）为了支持Redis服务器推送消息，Redis在RESP2协议上进行了扩展，实现了RESP3协议。HELLO 3命令表示客户端与Redis服务器之间使用RESP3协议通信。&lt;br/&gt;注意：Redis 6.0提供了Redis Tracking机制，但该版本的redis-cli并不支持RESP3协议，所以这里需要使用Redis 6.2版本的redis-cli进行演示。&lt;br/&gt;（2）CLIENT TRACKING on命令的作用是开启Redis Tracking机制，此后Redis服务器会记录客户端查询的键，并在这些键变更后推送失效消息通知客户端。失效消息以invalidate开头，后面是失效键数组。&lt;br/&gt;上表中的客户端 client1 查询了键 score 后，客户端 client2 修改了该键，这时 Redis 服务器会马上推送失效消息给客户端 client1，但 redis-cli 不会直接展示它收到的推送消息，而是在下一个请求返回后再展示该消息，所以 client1 重新发送了一个 PING请求。&lt;p&gt;&lt;/p&gt;&lt;p&gt;上面使用的非广播模式，另外，Redis Tracking还支持广播模式。在广播模式下，当变更的键以客户端关注的前缀开头时，Redis服务器会给所有关注了该前缀的客户端发送失效消息，不管客户端之前是否查询过这些键。&lt;br/&gt;下表展示了如何使用Redis Tracking的广播模式。&lt;/p&gt;&lt;figure&gt;&lt;img data-ratio=&quot;0.2777212614445575&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Of81vjDNtAy64LpuFbywiaWMWU8oLbic70Rjcc9hRmlfo85kDGzYCXfD9RTY2LjJDf9HNFFPZem9icqEvJPnRicaqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;983&quot; title=&quot;picture 2&quot;/&gt;&lt;/figure&gt;&lt;br/&gt;说明一下CLIENT TRACKING命令中的两个参数：&lt;br/&gt;BCAST参数：启用广播模式。&lt;br/&gt;PREFIX参数：声明客户端关注的前缀，即客户端只关注cache开头的键。&lt;/section&gt;&lt;section&gt;&lt;span&gt;可以看到，使用广播模式后，即使client1没有查询键“cached:1”，该键变更时client1仍然会收到失效消息。&lt;/span&gt;&lt;p&gt;强调一下非广播模式与广播模式的区别：&lt;br/&gt;非广播模式：Redis服务器记录客户查询过的键，当这些键发生变化时，Redis发送失效消息给客户端。&lt;br/&gt;广播模式：Redis服务器不记录客户查询过的键，当变更的键以客户端关注的前缀开头时，Redis就会发送失效消息给客户端。&lt;/p&gt;&lt;p&gt;关于Redis Tracking的更多内容，我已经在新书《Redis核心原理与实践》中详细分析，这里不再赘述。&lt;/p&gt;&lt;h2&gt;&lt;span&gt;Redis客户端缓存&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;既然Redis提供了Tracking机制，那么客户端就可以基于该机制实现客户端缓存了。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;Lettuce实现&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;Lettuce（6.1.5版本）已经支持Redis客户端缓存（单机模式下），使用CacheFrontend类可以实现客户端缓存。&lt;/p&gt;&lt;pre&gt;&lt;code&gt;public &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; main(&lt;span&gt;String&lt;/span&gt;[] args) throws InterruptedException {&lt;br/&gt;    &lt;span&gt;// [1]&lt;/span&gt;&lt;br/&gt;    RedisURI redisUri = RedisURI.builder()&lt;br/&gt;            .withHost(&lt;span&gt;&quot;127.0.0.1&quot;&lt;/span&gt;)&lt;br/&gt;            .withPort(&lt;span&gt;6379&lt;/span&gt;)&lt;br/&gt;            .build();&lt;br/&gt;    RedisClient redisClient = RedisClient.create(redisUri);&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// [2]&lt;/span&gt;&lt;br/&gt;    StatefulRedisConnection&amp;lt;&lt;span&gt;String&lt;/span&gt;, &lt;span&gt;String&lt;/span&gt;&amp;gt; connect = redisClient.connect();&lt;br/&gt;    &lt;span&gt;Map&lt;/span&gt;&amp;lt;&lt;span&gt;String&lt;/span&gt;, &lt;span&gt;String&lt;/span&gt;&amp;gt; clientCache = &lt;span&gt;new&lt;/span&gt; ConcurrentHashMap&amp;lt;&amp;gt;();&lt;br/&gt;    CacheFrontend&amp;lt;&lt;span&gt;String&lt;/span&gt;, &lt;span&gt;String&lt;/span&gt;&amp;gt; frontend = ClientSideCaching.enable(CacheAccessor.forMap(clientCache), connect,&lt;br/&gt;            TrackingArgs.Builder.enabled());&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;// [3]&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;while&lt;/span&gt; (&lt;span&gt;true&lt;/span&gt;) {&lt;br/&gt;        &lt;span&gt;String&lt;/span&gt; cachedValue = frontend.&lt;span&gt;get&lt;/span&gt;(&lt;span&gt;&quot;k1&quot;&lt;/span&gt;);&lt;br/&gt;        System.out.println(&lt;span&gt;&quot;k1 ---&amp;gt; &quot;&lt;/span&gt; + cachedValue);&lt;br/&gt;        Thread.sleep(&lt;span&gt;3000&lt;/span&gt;);&lt;br/&gt;    }&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;构建RedisClient。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;构建CacheFrontend。&lt;br/&gt;ClientSideCaching.enable开启客户端缓存，即发送“CLIENT TRACKING”命令给Redis服务器，要求Redis开启Tracking机制。&lt;br/&gt;最后一个参数指定了Redis Tracking的模式，这里用的是最简单的非广播模式。&lt;br/&gt;这里可以看到，通过Map保存客户端缓存的内容。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;重复查询同一个值，查看缓存是否生效。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们可以通过Redis的Monitor命令监控Redis服务收到的命令，使用该命令就可以看到，开启客户端缓存后，Lettuce不会重复查询同一个键。&lt;br/&gt;而且我们修改这个键后，Lettuce会重新查询这个键的最新值。&lt;/p&gt;&lt;p&gt;通过Redis的Client List命令可以查看连接的信息&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;gt; CLIENT LIST&lt;br/&gt;id=4 addr=192.168.56.1:50402 fd=7 name= age=23 idle=22 flags=t ...&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;flags=t&lt;/code&gt;代表这个连接启动了Tracking机制。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;SpringBoot应用&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;那么如何在SpringBoot上使用呢？请看下面的例子&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;@Bean&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;public&lt;/span&gt; CacheFrontend&amp;lt;String, String&amp;gt; &lt;span&gt;redisCacheFrontend&lt;/span&gt;&lt;span&gt;(RedisConnectionFactory redisConnectionFactory)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    StatefulRedisConnection connect = getRedisConnect(redisConnectionFactory);&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (connect == &lt;span&gt;null&lt;/span&gt;) {&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;    }&lt;br/&gt;&lt;br/&gt;    CacheFrontend&amp;lt;String, String&amp;gt; frontend = ClientSideCaching.enable(&lt;br/&gt;            CacheAccessor.forMap(&lt;span&gt;new&lt;/span&gt; ConcurrentHashMap&amp;lt;&amp;gt;()),&lt;br/&gt;            connect,&lt;br/&gt;            TrackingArgs.Builder.enabled());&lt;br/&gt;&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; frontend;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;&lt;span&gt;&lt;span&gt;private&lt;/span&gt; StatefulRedisConnection &lt;span&gt;getRedisConnect&lt;/span&gt;&lt;span&gt;(RedisConnectionFactory redisConnectionFactory)&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt;(redisConnectionFactory &lt;span&gt;instanceof&lt;/span&gt; LettuceConnectionFactory) {&lt;br/&gt;        AbstractRedisClient absClient = ((LettuceConnectionFactory) redisConnectionFactory).getNativeClient();&lt;br/&gt;        &lt;span&gt;if&lt;/span&gt; (absClient &lt;span&gt;instanceof&lt;/span&gt; RedisClient) {&lt;br/&gt;            &lt;span&gt;return&lt;/span&gt; ((RedisClient) absClient).connect();&lt;br/&gt;        }&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其实也简单，通过RedisConnectionFactory获取一个StatefulRedisConnection连接，就可以创建CacheFrontend了。&lt;br/&gt;这里RedisClient#connect方法会创建一个新的连接，这样可以将使用客户端缓存、不使用客户端缓存的连接区分。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;结合Guava缓存&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;Lettuce的StatefulRedisConnection类还提供了addListener方法，可以设置回调方法处理Redis推送的消息。&lt;br/&gt;利用该方法，我们可以将Guava的缓存与Redis客户端缓存结合&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;@Bean&lt;/span&gt;&lt;br/&gt;public LoadingCache&amp;lt;&lt;span&gt;String&lt;/span&gt;, &lt;span&gt;String&lt;/span&gt;&amp;gt; redisGuavaCache(RedisConnectionFactory redisConnectionFactory) {&lt;br/&gt;    &lt;span&gt;// [1]&lt;/span&gt;&lt;br/&gt;    StatefulRedisConnection connect = getRedisConnect(redisConnectionFactory);&lt;br/&gt;    &lt;span&gt;if&lt;/span&gt; (connect != &lt;span&gt;null&lt;/span&gt;) {&lt;br/&gt;        &lt;span&gt;// [2]&lt;/span&gt;&lt;br/&gt;        LoadingCache&amp;lt;&lt;span&gt;String&lt;/span&gt;, &lt;span&gt;String&lt;/span&gt;&amp;gt; redisCache = CacheBuilder.newBuilder()&lt;br/&gt;                .initialCapacity(&lt;span&gt;5&lt;/span&gt;)&lt;br/&gt;                .maximumSize(&lt;span&gt;100&lt;/span&gt;)&lt;br/&gt;                .expireAfterWrite(&lt;span&gt;5&lt;/span&gt;, TimeUnit.MINUTES)&lt;br/&gt;                .build(&lt;span&gt;new&lt;/span&gt; CacheLoader&amp;lt;&lt;span&gt;String&lt;/span&gt;, &lt;span&gt;String&lt;/span&gt;&amp;gt;() {&lt;br/&gt;                    public &lt;span&gt;String&lt;/span&gt; load(&lt;span&gt;String&lt;/span&gt; key) { &lt;br/&gt;                        &lt;span&gt;String&lt;/span&gt; val = (&lt;span&gt;String&lt;/span&gt;)connect.&lt;span&gt;sync&lt;/span&gt;().&lt;span&gt;get&lt;/span&gt;(key);&lt;br/&gt;                        &lt;span&gt;return&lt;/span&gt; val == &lt;span&gt;null&lt;/span&gt; ? &lt;span&gt;&quot;&quot;&lt;/span&gt; : val;&lt;br/&gt;                    }&lt;br/&gt;                });&lt;br/&gt;        &lt;span&gt;// [3]&lt;/span&gt;&lt;br/&gt;        connect.&lt;span&gt;sync&lt;/span&gt;().clientTracking(TrackingArgs.Builder.enabled());&lt;br/&gt;        &lt;span&gt;// [4]&lt;/span&gt;&lt;br/&gt;        connect.addListener(message -&amp;gt; {&lt;br/&gt;            &lt;span&gt;if&lt;/span&gt; (message.getType().equals(&lt;span&gt;&quot;invalidate&quot;&lt;/span&gt;)) {&lt;br/&gt;                &lt;span&gt;List&lt;/span&gt;&amp;lt;&lt;span&gt;Object&lt;/span&gt;&amp;gt; content = message.getContent(StringCodec.UTF8::decodeKey);&lt;br/&gt;                &lt;span&gt;List&lt;/span&gt;&amp;lt;&lt;span&gt;String&lt;/span&gt;&amp;gt; keys = (&lt;span&gt;List&lt;/span&gt;&amp;lt;&lt;span&gt;String&lt;/span&gt;&amp;gt;) content.&lt;span&gt;get&lt;/span&gt;(&lt;span&gt;1&lt;/span&gt;);&lt;br/&gt;                keys.forEach(key -&amp;gt; {&lt;br/&gt;                    redisCache.invalidate(key);&lt;br/&gt;                });&lt;br/&gt;            }&lt;br/&gt;        });&lt;br/&gt;        &lt;span&gt;return&lt;/span&gt; redisCache;&lt;br/&gt;    }&lt;br/&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;;&lt;br/&gt;}&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;获取Redis连接。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;创建Guava缓存类LoadingCache，该缓存类如果发现数据不存在，则查询Redis。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;开启Redis客户端缓存。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;添加回调函数，如果收到Redis发送的失效消息，则清除Guava缓存。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;span&gt;Redis Cluster模式&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;上面说的应用必须在Redis单机模式下（或者主从、Sentinel模式），遗憾的是，&lt;br/&gt;目前发现Lettuce（6.1.5版本）还没有支持Redis Cluster下的客户端缓存。&lt;br/&gt;简单看了一下源码，目前发现如下原因：&lt;br/&gt;Cluster模式下，Redis命令需要根据命令的键，重定向到键的存储节点执行。&lt;br/&gt;而对于“CLIENT TRACKING”这个没有键的命令，Lettuce并没有将它发送给Cluster中所有的节点，而是将它发送给一个固定的默认的节点（可查看ClusterDistributionChannelWriter类），所以通过StatefulRedisClusterConnection调用RedisAdvancedClusterCommands.clientTracking方法并没有开启Redis服务的Tracking机制。&lt;br/&gt;这个其实也可以修改，有时间再研究一下。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;需要注意的问题&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;那么单机模式下，Lettuce的客户端缓存就真的没有问题了吗？&lt;/p&gt;&lt;p&gt;仔细思考一下Redis Tracking的设计，发现使用Redis客户端缓存有两个点需要关注：&lt;/p&gt;&lt;p&gt;1.  开启客户端缓存后，Redis连接不能断开。&lt;br/&gt;如果Redis连接断了，并且客户端自动重连，那么新的连接是没有开启Tracking机制的，该连接查询的键不会受到失效消息，后果很严重。&lt;br/&gt;同样，开启Tracking的连接和查询缓存键的连接必须是同一个，不能使用A连接开启Tracking机制，使用B连接去查询缓存键（所以客户端不能使用连接池）。&lt;/p&gt;&lt;p&gt;Redis服务器可以设置timeout配置，自动超过该配置没有发送请求的连接。&lt;br/&gt;而Lettuce有自动重连机制，重连后的连接将收不到失效消息。&lt;br/&gt;有两个解决思路：&lt;br/&gt;（1）实现Lettuce心跳机制，定时发送PING命令以维持连接。&lt;br/&gt;（2）即使使用心跳机制，Redis连接依然可能断开（网络跳动等原因），可以修改自动重连机制（Lettuce的ReconnectionHandler类），增加如下逻辑：如果连接原来开启了Tracking机制，则重连后需要自动开启Tracking机制。&lt;br/&gt;需要注意，如果使用的是非广播模式，需要清空旧连接缓存的数据，因为连接已经变更，Redis服务器不会将旧连接的失效消息发送给新连接。&lt;/p&gt;&lt;p&gt;2. 启用缓存的连接与未启动缓存的连接应该区分。&lt;br/&gt;这点比较简单，上例例子中都使用RedisClient#connect方法创建一个新的连接，专用于客户端缓存。&lt;/p&gt;&lt;p&gt;客户端缓存是一个强大的功能，需要我们去用好它。可惜当前暂时还没有完善的Java客户端支持，本书分享了我的一些方案与思路，欢迎探讨。我后续会关注继续Lettuce的更新，如果Lettuce提供了完善的Redis客户端缓存支持，再更新本文。&lt;/p&gt;&lt;p&gt;关于Redis Tracking的详细使用与实现原理，我在新书《Redis核心原理与实践》做了详尽分析，文章最后，介绍一下这本书：&lt;br/&gt;本书通过深入分析Redis 6.0源码，总结了Redis核心功能的设计与实现。通过阅读本书，读者可以深入理解Redis内部机制及最新特性，并学习到Redis相关的数据结构与算法、Unix编程、存储系统设计，分布式系统架构等一系列知识。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;书籍详情：&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2MDQzMTU2MA==&amp;amp;mid=2247484112&amp;amp;idx=1&amp;amp;sn=c7d2d153a65a72fb3cd074803c7c2fbc&amp;amp;chksm=ea688977dd1f0061831cae4f5361182603b2e5778cae8aa0fc8f7e92ab75bc08c81afd717e6c&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;新书介绍 -- 《Redis核心原理与实践》&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>77e9b00581c50ac3d68debd181ac65d6</guid>
<title>Java GC 入门</title>
<link>https://toutiao.io/k/oyw72wo</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;container post-content&quot;&gt;&lt;p&gt;最近学了一些 Java GC 的知识，按自己的理解整理了一些 GC 算法遇到的问题和解决的思路。&lt;/p&gt;
&lt;p&gt;免责声明：以下所有内容都是个人理解，可能与事实不符。&lt;/p&gt;
&lt;h2 id=&quot;标记：三色算法&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#标记：三色算法&quot;/&gt;标记：三色算法&lt;/h2&gt;
&lt;p&gt;垃圾回收，需要先找出什么是垃圾，之后才能谈回收问题，一些方法&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;没有垃圾：认为所有对象都是存活的&lt;/li&gt;
&lt;li&gt;Reference Counting（引用计数）：每个对象/资源设置一个引用计数，有新的引用则计数加一，引用释放后计数减一，所有引用都释放后则认为该对象是垃圾&lt;/li&gt;
&lt;li&gt;Tracing（跟踪）：遍历对象的引用关系，过程中不可达的对象即为垃圾&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;引用计数在 C++ 和 Rust 之类的语言中比较常用，Java 中用的是 Tracing 的方式，遍历对象间的引用。那么从哪开始遍历呢？这些遍历的起始点称为 GC Root，在 Java 中有&lt;a href=&quot;https://help.eclipse.org/latest/index.jsp?topic=%2Forg.eclipse.mat.ui.help%2Fconcepts%2Fgcroots.html&amp;amp;cp=37_2_3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这么一些&lt;/a&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程运行栈上的所有引用，例如方法的参数，创建的临时变量等等&lt;/li&gt;
&lt;li&gt;系统加载的一些的类，比如说 &lt;code&gt;java.util.*&lt;/code&gt; 里的类&lt;/li&gt;
&lt;li&gt;JNI handles&lt;/li&gt;
&lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上面的 GC Roots 没列全，非专业做 GC 的话其实也没必要掌握。关键需要了解 GC Root 代表的就是我们“确定”还在用的引用，比如方法里创建了一个 &lt;code&gt;HashMap&lt;/code&gt;，方法还返回前都“确定”还会用到，就认为是 Root（这里说得不准确，可能 new 出的对象就没人用，但从算法角度还是认为它是 Root）。&lt;/p&gt;
&lt;p&gt;有了 GC Root，要如何扫描呢？Java 里用的是三色算法。三色算法是一个“逻辑算法”，本质上就是是树/森林的遍历，但为了方便描述和讨论，把遍历过程中的节点细化成三个状态：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Black: 对象可达，且对象的所有引用都已经扫描了（“扫描”在可以理解成遍历过了或加入了待遍历的队列）&lt;/li&gt;
&lt;li&gt;Gray: 对象可达，但对象的引用还没有扫描过（因此 Gray 对象可理解成在搜索队列里的元素）&lt;/li&gt;
&lt;li&gt;White: 不可达对象或还没有扫描过的对象&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每次迭代都会将 Grey 引用的 White 对象标成 Grey，并将 Grey 对象标记成 Black，直到没有 Grey 对象为止。标记之后一个对象最终只会是 Black 或者 White，其中所有可达的对象最终都会是 Black，如&lt;a href=&quot;https://en.wikipedia.org/wiki/Tracing_garbage_collection#Tri-color_marking&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;下例&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;Tri-color-example-20211006095339-gfbvko5.svg&quot; alt=&quot;Tri-color-example.svg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里并没的说明 Grey 对象的遍历顺序，所以实际上实现成宽搜或深搜都是可以的。&lt;/p&gt;
&lt;h2 id=&quot;回收：sweep-vs-compact-vs-copy&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#回收：sweep-vs-compact-vs-copy&quot;/&gt;回收：Sweep vs Compact vs Copy&lt;/h2&gt;
&lt;p&gt;上节说考虑的是“什么是垃圾”的问题，标识出了垃圾对象，下一步是如何“回收”。通常有 Sweep/Compact/Copy 三种处理方式，直观上理解是这样的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;sweep-compact-copy-20211006101722-qjw5r3s.svg&quot; alt=&quot;sweep-compact-copy.svg&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sweep 指的是把垃圾清除了，但它不会移动活动对象，不过久了以后内存容易碎片化&lt;/li&gt;
&lt;li&gt;Compact 除了丢弃垃圾对象外，还会移动活动对象，紧凑地放到一个新的地方，能解决碎片化问题，但可能需要先计算目标地址，修正指针再移动对象，速度较慢。&lt;/li&gt;
&lt;li&gt;Copy 本质上和 Compact 是一样的，不过它的一些计算最会更少。但通常需要保留了一半的内存，移动时直接移动到另一半，空间开销会更大。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;三种方法有各自的优势，需要使用方自己做权衡。这里引用 &lt;a href=&quot;https://hllvm-group.iteye.com/group/topic/38223#post-248757&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;R 大的帖子&lt;/a&gt; 总结如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;br/&gt;&lt;/th&gt;
&lt;th&gt;Mark-Sweep&lt;/th&gt;
&lt;th&gt;Mark-Compact&lt;/th&gt;
&lt;th&gt;Mark-Copy&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;速度&lt;/td&gt;
&lt;td&gt;中等&lt;/td&gt;
&lt;td&gt;最慢&lt;/td&gt;
&lt;td&gt;最快&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;空间开销&lt;/td&gt;
&lt;td&gt;少（但有碎片）&lt;/td&gt;
&lt;td&gt;少（无碎片）&lt;/td&gt;
&lt;td&gt;通常需要活动对象的 2 倍（无碎片）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;移动对象？&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这几种方法都有使用。如 CMS 最后的 S 代表的就是 Sweep；传统的 Serial GC 和 Parallel GC，包括新的 G1、Shenandoah、ZGC 都可以理解成是 Compact；而 Serial, Parallel, CMS 的 Young GC 都用的是 Copy。&lt;/p&gt;
&lt;h2 id=&quot;分代假设&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#分代假设&quot;/&gt;分代假设&lt;/h2&gt;
&lt;p&gt;如果接触过 GC，会知道 GC 最让人头疼的是 Stop-the-World 停顿，GC 算法的一些阶段会把用户线程的执行完全暂定，造成不可预期的停顿。我们希望这个时间尽可能短甚至完全去除。GC 的“效率”跟多方面因素有关，比如活动对象（active object）越多，Marking 需要遍历的节点越多，越耗时；比如内存越大，Sweep 清理垃圾时需要遍历的区域越大，耗时越长；等等。于是人们在想怎么“偷懒”来提升效率。&lt;/p&gt;
&lt;p&gt;分代假设就是这样一个&lt;a href=&quot;https://plumbr.io/handbook/garbage-collection-in-java#generational-hypothesis&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;发现/假设&lt;/a&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多数对象一般创建不久后就被废弃了/死了&lt;/li&gt;
&lt;li&gt;一段时间后还在使用/活着的对象，通常还会继续存在/活（非常）长的时间&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从对象存活时间和对象数量的视角来看，分代假设就是这样的（&lt;a href=&quot;https://plumbr.io/app/uploads/2015/05/object-age-based-on-GC-generation-generational-hypothesis.png&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原图&lt;/a&gt;）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;object-age-based-on-GC-generation-generational-hypothesis-20211006105013-yrmxkz4.png&quot; alt=&quot;object-age-based-on-GC-generation-generational-hypothesis.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当然这个假设不一定符合实际，比如 LRU 缓存，越老的对象越可能被淘汰。不过多数应用还是符合这个假设的。于是如果将对象按时间分成年轻代和老年代，我们就可以偷懒了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;年轻代的对象死得快，因此通常回收年轻代收益更高，于是可以更频繁回收年轻代，少最回收老年代&lt;/li&gt;
&lt;li&gt;回收年轻代时的标记阶段可以简化。例如存在 Old -&amp;gt; Young 的引用，正确的做法是用三色算法判断 Old 里的对象是死是活，再来判断 Young 对象的死活，但在分代假设下，可以偷懒地认为 Old 的对象就是活的，这样可以减少 Mark 的时间且不太影响回收的效果。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;于是在分代假设下，传统的 GC 流程变成了这样（&lt;a href=&quot;https://plumbr.io/app/uploads/2015/05/how-java-garbage-collection-works.png&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原图&lt;/a&gt;）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;how-java-garbage-collection-works-20211006105843-u5qw3te.png&quot; alt=&quot;how-java-garbage-collection-works.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;新对象从 Eden 区分配，Young GC 时存活的进 Survivor 区，Survivor 区有两个，相互做 Copy 操作。在 Survivor 区存活了 15 次 GC 的，就移动到 Old/Tenured 区。Young GC 时会忽略 Tenured 区。&lt;/p&gt;
&lt;h2 id=&quot;并发提速&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#并发提速&quot;/&gt;并发提速&lt;/h2&gt;
&lt;p&gt;前面提到了 GC 最让人头疼的是 STW 停顿，分代策略让我们频繁做 Young GC，少量做 Full GC，但真的做 Full GC 时停顿时间还是非常大，于是人们想到了并发。CMS 中的 CM 指的是 Concurrent Mark 即是“并发标记”。而 Shenandoah GC 和 ZGC 又实现了“回收”的并发。&lt;/p&gt;
&lt;p&gt;开始前要注意的是“并发”和“并行”在 GC 里的概念是不一样的，可以这么去区分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;并行：起多个线程一起处理，但对应用线程依旧是 STW 的&lt;/li&gt;
&lt;li&gt;并发：GC 线程处理 GC 任务的同时，应用线程依旧可以运行&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如早期的 Parallel GC 本质上就是“并行”而不是“并发”，GC 过程还是 STW 的。虽然仅一字之差，“并发”会带来非常多的问题，新的 GC 算法也用了许多解决方案，但这些方案都是有代价的。&lt;/p&gt;
&lt;h3 id=&quot;并发标记&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#并发标记&quot;/&gt;并发标记&lt;/h3&gt;
&lt;p&gt;前面提到 Java 里会用三色算法来遍历堆中的引用关系，算法假设引用关系在遍历期间不变，如果变化了会怎么样呢？主要有两个场景：新增对象和引用修改。&lt;/p&gt;
&lt;p&gt;第一个问题是新增对象：在标记期间新增的对象通过旧的 GC Roots 可能不可达，标记结束后可能还是 White，会被认为是垃圾而被错误释放。&lt;/p&gt;
&lt;p&gt;第二个问题是：标记期间应用线程修改引用会影响正确性。&lt;/p&gt;
&lt;p&gt;其中一些修改不会造成错误，只是会影响回收效率。如断开 Black1 -&amp;gt; Black2 引用，
Black2 最终应该被释放，但不释放 Black2 不会造成程序错误。但如果修改同时满足下面两个条件则会影响正确性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;应用线程增加 Black -&amp;gt; White 的引用，这意味着这个 White 对象标记结束后是被引用的，预期是 Black&lt;/li&gt;
&lt;li&gt;应用线程断开了 Grey -&amp;gt; White 的（直接或间接）引用，这意味着原本 White 对象能通过该 Grey 对象被遍历到，但现在却遍历不到了&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;条件一和条件二的共同结果是，标记过程会遗漏这个 White 对象，因为通过 Grey 对象不可达，且 Black 对象不会被二次扫描。于是 GC 结束后它会被释放，但它同时还被 Black 对象引用着，程序会出错。&lt;/p&gt;
&lt;p&gt;并发标记算法如何解决这两个问题？&lt;/p&gt;
&lt;h4 id=&quot;incremental-update&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#incremental-update&quot;/&gt;Incremental Update&lt;/h4&gt;
&lt;p&gt;Incremental update 的想法是破坏条件一。标记期间记录增加的每个 Black -&amp;gt; White 引用中的 White 对象，把它标记为 Grey。对于标记期间新增的对象，则需要在标记结束前重新扫描一次 GC Roots 做 Marking。&lt;/p&gt;
&lt;p&gt;在实现上，就需要去“监听” Black -&amp;gt; White 引用的创建。以 CMS 为例：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;CMS 会在程序的引用赋值语句（如 &lt;code&gt;obj.foo = bar&lt;/code&gt;）后，插入一段代码（称为 barrier，因为是在赋值结束后的 barrier，所以称为 post write barrier），这段代码会记录 foo -&amp;gt; bar 的引用。&lt;/li&gt;
&lt;li&gt;CMS 会在内存中开辟一块区域，称为 Card Table，用来记录 foo -&amp;gt; bar 的引用&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在标记过程中新增的 Black -&amp;gt; White 的引用，都可以在 Card Table 中找到。于是要保证标记的正确性，只需要在标记结束前从 Card Table 中找到 foo -&amp;gt; bar 的引用，再用三色算法遍历一下 bar 及其引用即可。当然还需要再重新扫描 GC Roots 处理新增的对象。&lt;/p&gt;
&lt;p&gt;实现细节上，Card Table 里并不会像 HashMap 一样记录一个 A -&amp;gt; B 的映射，这样存储访问的效率都很低。Card Table 是一个 bitmap，先将内存按 512B 分成一个个区域，称为 Card，每个 Card 对应 bitmap 里的一位。bitmap 置 1 代表对应 Card 中包含需要重新扫描的对象。在标记结束前找到为 dirty 的 Card，重新扫描其中的（所有）对象及其引用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;card-table-20211006153844-b500f13.svg&quot; alt=&quot;card-table.svg&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;snapshot-at-the-beginning&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#snapshot-at-the-beginning&quot;/&gt;Snapshot At The Beginning&lt;/h4&gt;
&lt;p&gt;Snapshot At The Beginning(SATB) 的想法则是破坏条件二，在标记开始之前做快照，快照之后新增的对象都不处理，认为是 Black；当要删除旧的引用（换句话说，在新的赋值 &lt;code&gt;obj.foo = bar&lt;/code&gt; 生效之前），记录旧的引用，这样在标记结束前再扫描这些旧的引用即可，这样原先的 Grey -&amp;gt; White 的引用虽然断开了，但 White 对象依旧可以扫到。以 G1 为例：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在每个 Region 会有 TAMS(top at marking start) 指针，标记开始时设置为 Top 的值，区域内新增对象后 Top 指针增长，可以认为 [TAMS, Top] 之间的对象都是新对象，都置为 Black 即可&lt;/li&gt;
&lt;li&gt;在赋值语句之前加入 barrier，例如 &lt;code&gt;obj.foo = bar&lt;/code&gt; 可以拆成 &lt;code&gt;barrier(obj.foo); obj.foo = bar&lt;/code&gt;，barrier 会对赋值前的指针做记录。因为是在写指针之前做的操作，因此也叫 pre write barrier&lt;/li&gt;
&lt;li&gt;G1 使用了和 Card Table 类似的结构叫 Remember Set(RSet)，用来记录 pre write barrier 传递的指针。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最终的操作与 Incremental Update 类似，在标记结束前，重新扫描 RSet 里记录的指针，也会有额外的操作把 [TAMS, Top] 之间的对象标记成 Black。&lt;/p&gt;
&lt;p&gt;实现细节上，G1 将内存分成了多个 Region。每个 Region 有自己的一个 RSet，这点与 Card Table 不同，它是全局的。RSet 的结构如下：
&lt;img src=&quot;RSet-20211006163543-vi8geu1.svg&quot; alt=&quot;RSet.svg&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个 Region 有自己的 RSet&lt;/li&gt;
&lt;li&gt;RSet 里记录的的：指向当前 Region 的有 Region xx Card yy, …&lt;/li&gt;
&lt;li&gt;如果要回收 Region3，只需要扫描 Region3 对应的 Reset 里的指针（即 R1C4 和 R2C2）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当然，RSet 的&lt;a href=&quot;http://09itblog.site/?p=1093&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;具体实现&lt;/a&gt;和上图不太一样，如一般用 HashMap 来存储；但如果 region 里的 card 数过多就会退化成 bitmap；引用的 region 过多，则 region 也会用 bitmap 来存储。细节上也有很多优化，比如 barrier 的更新是先记录到一个 Thread Local 的队列上，异步更新到 RSet 中的。&lt;/p&gt;
&lt;h3 id=&quot;concurrent-copy-compact&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#concurrent-copy-compact&quot;/&gt;Concurrent Copy/Compact&lt;/h3&gt;
&lt;p&gt;不管是在 CMS 和 G1 里，并发的内容主要还是以 Marking 为主，Copy/Compact 还是 STW 的。如 CMS 的 Young GC Copy，G1 的 Evacuation Compact，都是 STW 的。为了追求接近硬实时的效果，Shenandoah GC 和 ZGC 都尝试将“回收”阶段并发化，减少 Copy/Compact 的 STW 停顿时间。而正如并发标记里会需要处理新对象和并发修改的问题，并发 Copy/Compact 也会遇到不少问题。&lt;/p&gt;
&lt;h3 id=&quot;并发修改问题&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#并发修改问题&quot;/&gt;并发修改问题&lt;/h3&gt;
&lt;p&gt;Copy/Compact 的过程，需要先将对象复制到新的位置，再修改所有该对象的引用，指向新的地址。在 STW 的方案下，过程如下（摘自 &lt;a href=&quot;https://shipilev.net/talks/javazone-Sep2018-shenandoah.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://shipilev.net/talks/javazone-Sep2018-shenandoah.pdf&lt;/a&gt; ）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;Copy-STW-20211006170030-k2d6hvm.svg&quot; alt=&quot;Copy-STW.svg&quot;/&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先复制对象&lt;/li&gt;
&lt;li&gt;将复制后对象的指针存放在原对象的 Header 中（复用空间）&lt;/li&gt;
&lt;li&gt;遍历堆上的指针，将指针的值置为对象的 Header 中存储的指针（&lt;code&gt;*ref = **ref&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;所有指针更新完毕，释放旧的对象&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;但允许并发时，会出现不同线程对不同副本做读写的问题，此时应该保留哪个副本？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;Copy-Concurrent-Problem-20211006171017-agr14hx.svg&quot; alt=&quot;Copy-Concurrent-Problem.svg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;并发回收算法的核心也就在于怎么解决 Copy 期间多线程对两个副本的同步。下面会介绍 Shenadoah GC 和 ZGC 的做法，它们都会用到 load barrier 来修正并发情况下应用线程的读操作。&lt;/p&gt;
&lt;h3 id=&quot;brooks-pointer&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#brooks-pointer&quot;/&gt;Brooks Pointer&lt;/h3&gt;
&lt;p&gt;Shenandoah GC 对这个问题的解法是：为每个对象都增加一个 Forwarding 指针，在 Copy/Compact 过程中，通过 CAS 来更新这个指针指向新的副本，期间指向该对象的指针的读写，都要经过 Forwarding 找到正确的对象，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;Copy-Brooks-Pointer-20211006210633-1tpjsh4.svg&quot; alt=&quot;Copy-Brooks-Pointer.svg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这个方案的有效性本身并不难理解。技术上，这个方案需要拦截所有的对读写操作，让它通过 &lt;code&gt;FwdPtr&lt;/code&gt; 完成。Shenandoah GC 通过 Write Barrier + Load Barrier 来完成。&lt;/p&gt;
&lt;p&gt;一个小细节：在执行 Write 操作时，Write Barrier 如果发现当前处于并发 Copy 阶段，但对象还没有被 Copy，则 Write Barrier 会执行 Copy 操作，否则写到旧的副本里也没有意义。但读操作时并不会主动做 Copy 的动作。&lt;/p&gt;
&lt;p&gt;这个算法的难点在于实现和优化。Shenandoah 中做了许多额外的处理：例如在更多地方增加 barrier，比如 &lt;code&gt;==&lt;/code&gt; 、&lt;code&gt;compareAndSwap&lt;/code&gt;等操作；例如去除对 NULL 检查的 Barrier，把 barrier 放在循环外来提高性能。&lt;/p&gt;
&lt;p&gt;另外 Brooks Pointer 中的 Brooks 是人名，Rodney A. Brooks 在 1984 年为 Lisp 发明的。&lt;/p&gt;
&lt;h3 id=&quot;zgc-relocation&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#zgc-relocation&quot;/&gt;ZGC Relocation&lt;/h3&gt;
&lt;p&gt;一个 A-&amp;gt;B 的引用有两个参与者，引用方 A 和被引用方 B。Shenandoah 是在被引用方 B 中增加 Forwarding Pointer 来屏蔽底层的 Copy 的动作。而 ZGC 则是在引用方 A 处动手，具体有这么几个机制：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在指针中挑几个 bit 来做标记，其中 &lt;code&gt;remapped&lt;/code&gt; 位代表的当前指针是否指向 Copy 后的地址&lt;/li&gt;
&lt;li&gt;Copy/Compact 的过程中，ZGC 会为 Region 创建 forwarding table，用于保存新旧对象地址的映射&lt;/li&gt;
&lt;li&gt;ZGC （只）会用 Read Barrier，在访问指针时，如果当前指针的 &lt;code&gt;remapped&lt;/code&gt; 位为 &lt;code&gt;0&lt;/code&gt;，代表指针未更新，会查找 forwarding table 的值来更新当前指针，之后再进行访问&lt;/li&gt;
&lt;li&gt;如果在 Copy/Compact 的过程中指针并没有被访问，则在下次 marking 时会由 GC Thread 来更新指针。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果画成图，大概是这样：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;ZGC-Copy-20211006214331-yi4a2ex.svg&quot; alt=&quot;ZGC-Copy.svg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;相比于 Brooks Pointer，这个算法会更受限，比如无法支持 32 位的机器，不能开启指针压缩等等。&lt;/p&gt;
&lt;h2 id=&quot;那么代价呢？&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#那么代价呢？&quot;/&gt;那么代价呢？&lt;/h2&gt;
&lt;p&gt;先假设这样一个情形，如果我们看 GC 的日志，记录 GC 开始结束，（虚构）画出下面这张图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;Fake-Throughput-Diagram-20211006215644-jkdhlyg.svg&quot; alt=&quot;Fake-Throughput-Diagram.svg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图中 2 的位置，我们发现应用程序的 TPS 和响应时间都变差了，但看了下 GC 的日志发现每次 GC 的停顿时间都很短，可能会觉得 GC 没有问题。但如果仔细观察，会发现 GC 变得频繁了，而 GC 是消耗 CPU 时间的，更频繁的 GC 意味着应用线程能用的时间也更少了，因此会造成 TPS 和响应时间变差的情况。&lt;/p&gt;
&lt;p&gt;除了 GC 带来的停顿之外，要意识到 GC 是有代价的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GC 的一些内部结构需要占用额外的内存，如 Card Table, RSet, Forwarding Pointer, Forwarding Table, etc.&lt;/li&gt;
&lt;li&gt;Shenadoah, ZGC 这种重度 barrier 使用者，不发生 GC 时也会有额外的 CPU 占用（比如 Shenandoah 大概 20%，ZGC 大概 15%，视具体程序有变化），这也是低延时 GC 的额外代价&lt;/li&gt;
&lt;li&gt;另外在真正执行 GC 时，GC 线程也会占用 CPU&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一般 GC 算法保证的停顿的时间越短，则消耗的 CPU 越大，换言之吞吐越小。没有通用的最优的 GC 算法，根据应用程序的不同和愿意付出的代价来选择 GC 算法吧。&lt;/p&gt;
&lt;h2 id=&quot;小结&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#小结&quot;/&gt;小结&lt;/h2&gt;
&lt;p&gt;文章中粗浅地讨论了 Java GC 算法中的几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;标记用的三色算法，它是树遍历的一个抽象描述，有助于理解和讨论&lt;/li&gt;
&lt;li&gt;回收用的 Sweep, Compact, Copy 三种策略和各自的优缺点&lt;/li&gt;
&lt;li&gt;分代假设：越年轻的对象越可能死亡，越老的对象越可能活得久。GC 算法可以通过分代来提高性能&lt;/li&gt;
&lt;li&gt;为了减少停顿时间，GC 算法引入了并发标记和并发回收，而它们本身又引入了新的问题
&lt;ul&gt;
&lt;li&gt;并发标记的问题介绍了 Incremental Update 和 Snapshot at The Beginning，分别打破引发问题的两个必要条件的一个&lt;/li&gt;
&lt;li&gt;并发回收问题介绍了 Shenandoah GC 使用的 Brooks Pointer 和 ZGC 使用的策略。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;最后简单讨论了 GC 算法对应用程序本身的影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;参考&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#参考&quot;/&gt;参考&lt;/h2&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>aa5dad20936b0db1b3766045d0fd0d56</guid>
<title>Hum to Search 背后的机器学习</title>
<link>https://toutiao.io/k/38xpihl</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;萦绕 在您脑海中的旋律，通常被称为“耳虫”，是一种众所周知且有时令人恼火的现象——一旦耳虫出现，就很难摆脱它。研究发现，与原始歌曲互动，无论是听还是唱，都会将耳虫赶走。但是如果你不太记得这首歌的名字，只能哼着旋律怎么办？&lt;/p&gt;&lt;p&gt;将哼唱的旋律与其原始的复调录音室录音相匹配的现有方法面临着几个挑战。通过歌词、背景人声和乐器，音乐或录音室录音的音频可能与哼唱的曲调截然不同。由于错误或设计，当有人哼唱他们对歌曲的诠释时，通常音高、调、节奏或节奏可能会略有不同甚至显着不同。这就是为什么这么多现有的通过哼唱进行查询的方法将哼唱的曲调与歌曲的预先存在的仅旋律或哼唱版本的数据库相匹配，而不是直接识别歌曲。但是，这种方法通常依赖于需要手动更新的有限数据库。&lt;/p&gt;&lt;p&gt;Hum to Search 于 10 月推出，是 Google 搜索中一个全新的完全机器学习的系统，它允许人们仅使用哼唱的歌曲来查找歌曲。与现有方法相比，这种方法从歌曲的频谱图生成旋律的嵌入，而无需生成中间表示。这使模型能够将哼唱的旋律直接与原始（和弦）录音相匹配，而无需每个音轨的哼唱或 MIDI 版本或其他复杂的手工设计逻辑来提取旋律。这种方法极大地简化了 Hum to Search 的数据库，使其能够通过嵌入来自世界各地的原始录音（甚至是最新版本）不断刷新。&lt;/p&gt;&lt;h2&gt;&lt;em&gt;背景&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;许多现有的音乐识别系统在处理音频样本之前将其转换为频谱图，以便找到良好的匹配。然而，在识别哼唱旋律的一个挑战是，哼唱曲调通常包含信息相对较少，通过如示出的这个示例哼唱的啊朋友再见。哼唱版本与相应录音室录音中的相同片段之间的差异可以使用频谱图来可视化，如下所示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;img data-ratio=&quot;0.7073643410852714&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/eG1jA7faiceFhJfMKsXicUhvHHtnNSwWsImibWyRiaR0FHdHnT8JcXciawh7tI0PeibHwVzY8atcYbOuhgRTqgvwyvCQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;516&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;给定左侧的图像，模型需要从超过 5000 万张外观相似的图像（对应于其他歌曲的录音室录音片段）的集合中定位与右侧图像对应的音频。为了实现这一点，模型必须学会专注于主导旋律，而忽略背景人声、乐器和声音音色，以及来自背景噪音或房间混响的差异。为了通过肉眼找到可能用于匹配这两个频谱图的主导旋律，一个人可能会在上图底部附近的线条中寻找相似之处。&lt;/p&gt;&lt;p&gt;之前为发现音乐所做的努力，特别是在识别在咖啡馆或俱乐部等环境中播放的录制音乐的背景下，展示了如何将机器学习应用于这个问题。Now Playing于 2017 年发布到 Pixel 手机，它使用设备上的深度神经网络来识别歌曲，而无需连接服务器，而Sound Search进一步开发了这项技术，以提供基于服务器的识别服务，以实现更快、更准确的搜索超过 1 亿首歌曲。下一个挑战是利用从这些版本中学到的知识来识别来自类似大型歌曲库的哼唱或演唱的音乐。&lt;/p&gt;&lt;h2&gt;&lt;em&gt;机器学习设置&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;开发 Hum to Search 的第一步是修改“正在播放”和“声音搜索”中使用的音乐识别模型，以处理哼唱的录音。原则上，许多这样的检索系统（例如，图像识别）以类似的方式工作。神经网络使用成对的输入（这里是成对的带有录制音频的哼唱或演唱音频）进行训练，为每个输入生成嵌入，稍后将用于匹配哼唱的旋律。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7632575757575758&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/eG1jA7faiceFhJfMKsXicUhvHHtnNSwWsI7Ymiceab8cLnibLH0wmiah7A8kgfyTicpqoia6CHdWLpmPnYFbA3U4MSRIg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;528&quot;/&gt;&lt;/p&gt;&lt;p&gt;为了实现哼唱识别，网络应该生成嵌入，使包含相同旋律的音频对彼此接近，即使它们具有不同的乐器伴奏和歌声。包含不同旋律的成对音频应该相距很远。在训练中，网络会提供这样的音频对，直到它学会使用此属性生成嵌入。&lt;/p&gt;&lt;p&gt;然后，经过训练的模型可以生成类似于歌曲参考录音的嵌入的曲调嵌入。找到正确的歌曲只需从流行音乐的音频计算出的参考录音数据库中搜索类似的嵌入即可。&lt;/p&gt;&lt;h2&gt;&lt;em&gt;训练数据&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;因为模型的训练需要歌曲对（录制和演唱），所以第一个挑战是获得足够的训练数据。我们的初始数据集主要由唱歌的音乐片段组成（其中很少包含哼唱）。为了使模型更加健壮，我们在训练期间增强了音频，例如通过随机改变唱歌输入的音高或节奏。由此产生的模型对于唱歌的人来说效果很好，但对于哼唱或吹口哨的人来说却不是。&lt;/p&gt;&lt;p&gt;为了提高模型在哼唱旋律上的表现，我们使用SPICE从现有音频数据集中生成了模拟“哼唱”旋律的额外训练数据，SPICE是我们更广泛的团队开发的音高提取模型，作为FreddieMeter项目的一部分。SPICE 从给定的音频中提取音高值，然后我们使用它来生成由离散音频音调组成的旋律。这个系统的第一个版本将这个原始剪辑转换成这些音调。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.5096153846153846&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/eG1jA7faiceFhJfMKsXicUhvHHtnNSwWsIrcIxYE59dVZcicqmk36lfxBLFOTCzJxdfcl5fjRQXNqsDd6KIykuQcQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;208&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们后来通过用神经网络替换简单的音调发生器来改进这种方法，该神经网络生成类似于实际哼唱或吹口哨曲调的音频。例如，网络从上述唱歌的片段中生成了这个哼唱示例或吹口哨示例。&lt;/p&gt;&lt;p&gt;作为最后一步，我们通过混合和匹配音频样本来比较训练数据。例如，如果我们有来自两个不同歌手的相似剪辑，我们会将这两个剪辑与我们的初步模型对齐，因此能够向模型显示代表相同旋律的附加音频剪辑对。&lt;/p&gt;&lt;h2&gt;&lt;em&gt;机器学习改进&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;在训练 Hum to Search 模型时，我们从三元组损失函数开始。这种损失已被证明在各种分类任务（如图像和录制的音乐）中表现良好. 给定一对对应于相同旋律的音频（嵌入空间中的点 R 和 P，如下所示），triplet loss 将忽略源自不同旋律的训练数据的某些部分。这有助于机器改进学习行为，无论是当它发现一个太“容易”的不同旋律时，因为它已经远离 R 和 P（见点 E），或者因为它太难了，考虑到模型的当前在学习状态下，音频最终与 R 太接近了——尽管根据我们的数据，它代表了不同的旋律（见 H 点）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.2063253012048193&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/eG1jA7faiceFhJfMKsXicUhvHHtnNSwWsIY4oWr3TRicUp15JmMKHjiaAKEK7dHl8C3S2zib2KtynN9Vj7nX49dibSoQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;664&quot;/&gt;&lt;/p&gt;&lt;p&gt;我们发现，我们可以通过采取这些额外的训练数据（点H和E）考虑提高模型的精确度，即通过在一个批次的例子制订的模式的信心一般概念：如何确保是模型，所有它看到的数据可以正确分类，还是看到不符合其当前理解的示例？基于这种置信度概念，我们添加了一个损失，使嵌入空间所有区域的模型置信度达到 100%，从而提高了我们模型的精度和召回率。&lt;/p&gt;&lt;p&gt;上述变化，尤其是我们对训练数据的变化、增强和叠加，使部署在 Google 搜索中的神经网络模型能够识别唱歌或哼唱的旋律。当前系统在包含超过 50 万首歌曲的歌曲数据库上达到了很高的准确性，我们正在不断更新这些歌曲。这首歌的语料库仍有成长的空间，以包含更多世界上的许多旋律。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;2&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/eG1jA7faiceFhJfMKsXicUhvHHtnNSwWsIlcIEle86SrAaCTDNwElHalW4wUHHDPVZAQ2tGeq8QEk4KBg2TPYTwg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;200&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;em&gt;在 Google 应用中哼哼搜索&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;要试用该功能，您可以打开最新版本的 Google 应用，点按麦克风图标并说“这首歌是什么？” 或单击“搜索歌曲”按钮，之后您可以哼唱、唱歌或吹口哨！我们希望 Hum to Search 可以帮助您解决这个问题，或者可能只是帮助您查找和播放歌曲而无需输入歌曲名称。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>d8ddecec1b9034856c492b9e5284b790</guid>
<title>Kafka 架构设计的任督二脉</title>
<link>https://toutiao.io/k/ew3jom8</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p class=&quot;original_area_primary&quot;&gt;
                                                                                                &lt;/p&gt;

                    
                                            &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span&gt;大家好，我是捡田螺的小男孩。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这篇文章将带着大家参透：到底什么是 Kafka 架构设计的任督二脉？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;span&gt;把握住了这个关键点，我相信你将能更好地理解 Kafka 的架构设计，进而顺藤摸瓜地掌握 Kafka 的核心技术方案。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;废话不多说了，开始发车。&lt;/span&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;&lt;span&gt; 1. Kafka 的技术难点究竟在哪？  &lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;前一篇文章《&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU2MTM4NDAwMw==&amp;amp;mid=2247490102&amp;amp;idx=1&amp;amp;sn=68d55b3c5ac74038c76d6837b862a11c&amp;amp;chksm=fc78c51acb0f4c0cd5a1d6ceedb9948f82d48791ab789e9edfd6e83e34fbad1ace5749bee203&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;扒开 Kafka 的神秘面纱&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;扒开 Kafka 的神秘面纱&lt;/a&gt;》 交代了两个关键信息：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1、&lt;/span&gt;&lt;span&gt;Kafka 为实时日志流而生，要处理的并发和&lt;/span&gt;&lt;span&gt;数据量非常大。&lt;/span&gt;&lt;span&gt;可见，Kafka 本身就是一个高并发系统，它必然会遇到高并发场景下典型的三高挑战：&lt;/span&gt;&lt;span&gt;高性能、高可用和高扩展。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2、为了&lt;span&gt;简化实现的复杂度&lt;/span&gt;，Kafka 最终采用了很巧妙的消息模型：&lt;/span&gt;&lt;span&gt;它将所有消息进行了持久化存储，让消费者自己各取所需，想取哪个消息，想什么时候取都行，只需要传递一个消息的 offset 进行拉取即可。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;img data-ratio=&quot;0.3761467889908257&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AaabKZjib2kb2rHJ9nF8HA4uV5cgCpUMWhPlghE0S6mFhqgZ6Jb5YhYpdgm8P6gjWXVUC2D8UJ1icSJibyPRWFbOw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;872&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;最终 Kafka 将自己退化成了一个&lt;/span&gt;&lt;span&gt;&lt;span&gt;「存储系统」&lt;/span&gt;&lt;/span&gt;&lt;span&gt;。因此，海量消息的存储问题就是 Kafka 架构设计中的最大技术难点。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;&lt;span&gt;2. Kafka 架构设计的任督二脉  &lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面我们再接着分析下：Kafka 究竟是如何解决存储问题的？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;面对海量数据，单机的存储容量和读写性能肯定有限，大家很容易想到一种存储方案：&lt;/span&gt;&lt;span&gt;&lt;span&gt;对数据进行分片存储&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;span&gt;这种&lt;/span&gt;&lt;span&gt;方案在我们实际工作中也非常常见：&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1、比如数据库设计中，当单表的数据量达到几千万或者上亿时，我们会将它拆分成多个库或者多张表。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2、比如缓存设计中，当单个 Redis 实例的数据量达到几十个 G 引发性能瓶颈时，我们会将单机架构改成分片集群架构。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;类似的拆分思想在 HDFS、ElasticSearch 等中间件中都能看到。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Kafka 也不例外，它同样采用了这种水平拆分方案。在 Kafka 的术语中，拆分后的数据子集叫做 &lt;/span&gt;&lt;span&gt;&lt;span&gt;Partition（分区）&lt;/span&gt;&lt;/span&gt;&lt;span&gt;，各个分区的数据合集即全量数据。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们再来看下 Kafka 中的 Partition 具体是如何工作的？&lt;/span&gt;&lt;span&gt;举一个很形象的例子，如果我们把&lt;span&gt;「&lt;/span&gt;Kafka&lt;span&gt;」&lt;/span&gt;类比成&lt;/span&gt;&lt;span&gt;「高速公路」&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1、当大家听到京广高速的时候，知道这是一条从北京到广州的高速路，&lt;span&gt;这是逻辑上的叫法，可以理解成 Kafka 中的 Topic（主题）&lt;/span&gt;。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2、一条高速路通常会有多个车道进行分流，每个车道上的车都是通往一个目的地的（属于同一个Topic），这里&lt;span&gt;所说的车道便是 Partition。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;这样，一条消息的流转路径就如下图所示，先走主题路由，然后走分区路由&lt;span&gt;，最终决定这条消息该发往哪个分区。&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5444287729196051&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AaabKZjib2kYoV8r1cz8iakcS18uiaPaicUZ1hvzsKYS5BpvYMpkvBkNC0czv1HlyJIt2ANaibhvM8t6gatj1RSbKicQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1418&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;其中分区路由可以简单理解成一个 Hash 函数，生产者在发送消息时，完全可以自定义这个函数来决定分区规则。&lt;/span&gt;&lt;span&gt;如果分区规则设定合理，&lt;/span&gt;&lt;span&gt;所有消息将均匀地分配到不同的&lt;/span&gt;&lt;span&gt;分区中。&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;通过这样两层关系，最终&lt;span&gt;在 &lt;/span&gt;&lt;span&gt;Topic 之下，就&lt;/span&gt;有了一个新的划分单位：Partition。先通过 Topic 对消息进行逻辑分类，然后通过 Partition 进一步做物理分片，最终多个 Partition 又会均匀地分布在集群中的每台机器上，从而很好地解决了存储的扩展性问题。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;因此，Partition 是 Kafka &lt;/span&gt;&lt;span&gt;最基本的部署单元。&lt;/span&gt;&lt;span&gt;本文之所以将 Partition 称作 Kafka 架构设计的任督二脉，基于下面两点原因：&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1、Partition 是存储的关键所在，MQ「一发一存一消费」的核心流程必然围绕它展开。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、Kafka 高并发设计中最难的三高问题都能和 Partition 关联起来。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;因此，以 Partition 作为根，能很自然地联想出 Kafka 架构设计中的各个知识点，形成可靠的知识体系。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;下面，请大家&lt;span&gt;继续&lt;/span&gt;跟着我的思路，以 Partition 为线索，对 Kafka 的宏观架构进行解析。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;&lt;span&gt;3. Kafka的宏观架构设计  &lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;接下来，我们再看看 Partition 的分布式能力究竟是如何实现的？它又是怎么和 Kafka 的整体架构关联起来的？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;前面讲过 Partition 是 Topic 之下的一个划分单位，它是 Kafka 最基本的部署单元，它将决定 Kafka 集群的组织方式。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;假设现在有两个 Topic，每个 Topic 都设置了两个 Partition，如果 Kafka 集群是两台机器，部署架构将会是下面这样：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;350&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6054333764553687&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AaabKZjib2kYoV8r1cz8iakcS18uiaPaicUZtcz05mlq35knW1zjuskluicluzH8JJPkgsxa1iaEQibbX16geiajTecUjw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;773&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;span/&gt;&lt;span&gt;可以看到：同一个 Topic 的两个 Partition 分布在不同的消息服务器上，能做到消息的分布式存储了。&lt;/span&gt;&lt;span&gt;但是对于 Kafka 这个高并发系统来说，仅存储可扩展还不够，消息的拉取也必须并行才行，否则会遇到极大的性能瓶颈。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;那我们再看看消费端，它又是如何跟 Partition 结合并做到并行处理的？&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;从消费者来看，首先要满足两个基本诉求：&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;1、广播消费能力：同一个 Topic 可以被多个消费者订阅，一条消息能够被消费多次。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、集群消费能力：当消费者本身也是集群时，每一条消息只能分发给集群中的一个消费者进行处理。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;section&gt;&lt;span&gt;为了满足这两点要求，Kafka 引出了消费组的概念，每个消费者都有一个对应的消费组，组间进行广播消费，组内进行集群消费。此外，Kafka 还限定了：每个 Partition 只能由消费组中的一个消费者进行消费。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;最终的消费关系如下图所示：假设主题 A 共有 4 个分区，消费组 2 只有两个消费者，最终这两个消费组将平分整个负载，各自消费两个分区的消息。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;533&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.9221635883905013&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AaabKZjib2kbMEHsNGqQEugE853wH5eHX09BWCktCQmluWgeYcEUGdy5azA4H6CctZfdpEyhsK74Hs42A68dyqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;758&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果要加快消息的处理速度，该如何做呢？也很简单，向消费组 2 中增加新的消费者即可，Kafka 将以 Partition 为单位重新做负载均衡。当增加到 4 个消费者时，每个消费者仅需处理 1 个 Partition，处理速度将提升两倍。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;到这里，存储可扩展、消息并行处理这两个难题都解决了。但是高并发架构设计上，还遗留了一个很重要的问题：那就是高可用设计。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在 Kafka 集群中，每台机器都存储了一些 Partition，一旦某台机器宕机，上面的数据不就丢失了吗？&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;此时，你一定会想到对消息进行持久化存储，但是持久化只能解决一部分问题，它只能确保机器重启后，历史数据不丢失。但在机器恢复之前，这部分数据将一直无法访问。这对于高并发系统来说，是无法忍受的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;所以 Kafka 必须具备故障转移能力才行，当某台机器宕机后仍然能保证服务可用。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;如果大家去分析任何一个高可靠的分布式系统，比如 &lt;span&gt;ElasticSearch&lt;/span&gt;、Redis Cluster，其实它们都有一套多副本的冗余机制。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;没错，Kafka 正是通过 Partition 的多副本机制解决了高可用问题。在 Kafka 集群中，每个 Partition 都有多个副本，同一分区的不同副本中保存的是相同的消息。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;副本之间是 “一主多从” 的关系，其中 leader 副本负责读写请求，follower 副本只负责和 leader 副本同步消息，当 leader 副本发生故障时，它才有机会被选举成新的 leader 副本并对外提供服务，否则一直是待命状态。&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;现在，我假设 Kafka 集群中有 4 台服务器，主题 A 和主题 B 都有两个 Partition，且每个 Partition 各有两个副本，那最终的多副本架构将如下图所示：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;377&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6520833333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AaabKZjib2kbibTWGzuqLLliaN16ibaVen0WBS4pt0wGZ2a2quIlMTQmlWCMl7mZIPNjg119WeORrzmogYphCwSia1g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;960&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;很显然，这个集群中任何一台机器宕机，都不会影响 Kafka 的可用性，数据仍然是完整的。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;理解了上面这些内容，最后我们再反过来看下 Kafka 的整体架构：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-backh=&quot;465&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.8052147239263804&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AaabKZjib2kbibTWGzuqLLliaN16ibaVen0WsWJUn0kQoXotG9mMSf7mBmfwMhSZiazYXPl2mlgVZgHDwNJKU6egGUg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1304&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1、Producer：生产者，负责创建消息，然后投递到 Kafka 集群中，投递时需要指定消息所属的 Topic，同时确定好发往哪个 Partition。&lt;/span&gt;&lt;span/&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2、Consumer：消费者，会根据它所订阅的 Topic 以及所属的消费组，决定从哪些 Partition 中拉取消息。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3、Broker：消息服务器，可水平扩展，负责分区管理、消息的持久化、故障自动转移等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;4、Zookeeper：负责集群的元数据管理等功能，比如集群中有哪些 broker 节点以及 Topic，每个 Topic 又有哪些 Partition 等。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;很显然，在 Kafka 整体架构中，Partition 是发送消息、存储消息、消费消息的纽带。吃透了它，再去理解整体架构，脉络会更加清晰。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p&gt;&lt;span&gt;4. 写在最后  &lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;本文以 Partition 为切入点，从宏观角度解析了 Kafka 的整体架构，再简单总结下本文的内容：&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;1、Kafka 通过巧妙的模型设计，将自己退化成一个海量消息的存储系统。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2、为了解决存储的扩展性问题，Kafka 对数据进行了水平拆分，引出了 Partition（分区），这是 Kafka 部署的基本单元，同时也是 Kafka 并发处理的最小粒度。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;3、对于一个高并发系统来说，还需要做到高可用，Kafka 通过 Partition 的多副本冗余机制进行故障转移，确保了高可靠。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;希望这篇文章能让大家摆脱死记硬背的模式，先找到一个支点，再去推敲 Kafka 架构设计的来龙去脉，知其所以然。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;----------  END  &lt;span&gt;----------&lt;/span&gt;&lt;/span&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU2MTM4NDAwMw==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/AaabKZjib2kZtKI49SjA5YU5AjwJibTO6b55TSmwpSbRbE3BXZqedvCwpticVKUDZibcs1mqSnBjOqsSaFUQz9Uknw/0?wx_fmt=png&quot; data-nickname=&quot;武哥漫谈IT&quot; data-alias=&quot;BestITer&quot; data-signature=&quot;前亚马逊工程师，现大厂技术总监。程序人生很长，我将我所经历的，有感而发的，呈现在这里。&quot;/&gt;&lt;/section&gt;&lt;p&gt;求点赞、分享、在看、转发，感谢&lt;img data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/PoF8jo1Pmpx5dmRXlia6JjJ6Bav1ib6L1DibyKeL8AiacNY1AgC90MEiaYicJiauGiaLQ8JOHOCNjV2C1jia4v9nhM5WIeg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;20&quot;/&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>