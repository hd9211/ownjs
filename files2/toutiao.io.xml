<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>1fb094b8ad73698d8cee9eceeadf9000</guid>
<title>2万字，详解数据湖，概念、特征、架构、方案、场景以及建湖全过程（建议收藏）</title>
<link>https://toutiao.io/k/vcpzf1w</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section class=&quot;mp_profile_iframe_wrp&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzUyMDA4OTY3MQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/TwK74MzofXdtvHKjv7OHYYSTQ2QOVuyAia3LaU56kibxKLlX5Lo9bgeUfz1R4JDmdW7ZGYSLqsiaBl3nTOwOmFOFQ/0?wx_fmt=png&quot; data-nickname=&quot;浪尖聊大数据&quot; data-alias=&quot;bigdatatip&quot; data-signature=&quot;主要分享大数据框架，如spark，flink，kafka，hbase原理源码，同时会分享数据仓库，图计算等浪尖擅长领域。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;section data-autoskip=&quot;1&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;导读：&lt;/strong&gt;&lt;span&gt;最近，数据湖的概念非常热，许多前线的同学都在讨论数据湖应该怎么建？&lt;/span&gt;&lt;span&gt;有没有成熟的数据湖解决方案？&lt;/span&gt;&lt;span&gt;各大厂商的数据湖解决方案到底有没有实际落地的&lt;/span&gt;&lt;span&gt;案例？&lt;/span&gt;&lt;span&gt;怎么理解数据湖？&lt;/span&gt;&lt;span&gt;数据湖和大数据平台有什么不同？&lt;/span&gt;&lt;span&gt;带着这些问题，我们&lt;/span&gt;&lt;span&gt;尝试写了这样一篇文章，希望能抛砖引玉，引起大家一些思考和共鸣。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/WtGGOCsU5FPo6n8FIl8oF6NQx1vxgbRa2vUuxXaPN4wFlx5UZNQmJ4GpYUCbANZv9V2YjYzvgaCeuC9eq0icVEQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;本文共有以下7个章节：&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;什么是数据湖&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;数据湖的基本特征&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;数据湖基本架构&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;各厂商的数据湖解决方案&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;典型的数据湖应用场景&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;em&gt;&lt;span&gt;数据湖建设的基本过程&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;em&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/em&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;一、什么是数据湖&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据湖是目前比较热的一个概念，许多企业都在构建或者计划构建自己的数据湖。但是在计划构建数据湖之前，搞清楚什么是数据湖，明确一个数据湖项目的基本组成，进而设计数据湖的基本架构，对于数据湖的构建至关重要。关于什么是数据湖，有如下定义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Wikipedia是这样定义的：&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;数据湖是一类存储数据自然/原始格式的系统或存储，通常是对象块或者文件。数据湖通常是企业中全量数据的单一存储。&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/span&gt;&lt;span&gt;全量数据包括原始系统所产生的原始数据拷贝以及为了各类任务而产生的转换数据，各类任务包括报表、可视化、高级分析和机器学习。数据湖中包括来自于关系型数据库中的结构化数据（行和列）、半结构化数据（如CSV、日志、XML、JSON）、非结构化数据（如email、文档、PDF等）和二进制数据（如图像、音频、视频）。数据沼泽是一种退化的、缺乏管理的数据湖，数据沼泽对于用户来说要么是不可访问的要么就是无法提供足够的价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;AWS的定义相对就简洁一点：&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据湖是一个集中式存储库，允许您以任意规模存储所有结构化和非结构化数据。您可以按原样存储数据（无需先对数据进行结构化处理），并运行不同类型的分析 – 从控制面板和可视化到大数据处理、实时分析和机器学习，以指导做出更好的决策。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;微软的定义就更加模糊了&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，并没有明确给出什么是Data Lake，而是取巧的将数据湖的功能作为定义：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Azure的数据湖包括一切使得开发者、数据科学家、分析师能更简单的存储、处理数据的能力，这些能力使得用户可以存储任意规模、任意类型、任意产生速度的数据，并且可以跨平台、跨语言的做所有类型的分析和处理。数据湖在能帮助用户加速应用数据的同时，消除了数据采集和存储的复杂性，同时也能支持批处理、流式计算、交互式分析等。数据湖能同现有的数据管理和治理的IT投资一起工作，保证数据的一致、可管理和安全。它也能同现有的业务数据库和数据仓库无缝集成，帮助扩展现有的数据应用。Azure数据湖吸取了大量企业级用户的经验，并且在微软一些业务中支持了大规模处理和分析场景，包括Office 365, Xbox Live, Azure, Windows, Bing和Skype。Azure解决了许多效率和可扩展性的挑战，作为一类服务使得用户可以最大化数据资产的价值来满足当前和未来需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;关于数据湖的定义其实很多，但是基本上都围绕着以下几个特性展开。&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据湖需要提供足够用的数据存储能力，这个存储保存了一个企业/组织中的所有数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据湖可以存储海量的任意类型的数据，包括结构化、半结构化和非结构化数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt; 数据湖中的数据是原始数据，是业务数据的完整副本。数据湖中的数据保持了他们在业务系统中原来的样子。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据湖需要具备完善的数据管理能力（完善的元数据），可以管理各类数据相关的要素，包括数据源、数据格式、连接信息、数据schema、权限管理等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据湖需要具备多样化的分析能力，包括但不限于批处理、流式计算、交互式分析以及机器学习；同时，还需要提供一定的任务调度和管理能力。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据湖需要具备完善的数据生命周期管理能力。不光需要存储原始数据，还需要能够保存各类分析处理的中间结果，并完整的记录数据的分析处理过程，能帮助用户完整详细追溯任意一条数据的产生过程。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据湖需要具备完善的数据获取和数据发布能力。数据湖需要能支撑各种各样的数据源，并能从相关的数据源中获取全量/增量数据；然后规范存储。数据湖能将数据分析处理的结果推送到合适的存储引擎中，满足不同的应用访问需求。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;对于大数据的支持，包括超大规模存储以及可扩展的大规模数据处理能力。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综上，个人认为数据湖应该是一种不断演进中、可扩展的大数据存储、处理、分析的基础设施；以数据为导向，实现任意来源、任意速度、任意规模、任意类型数据的全量获取、全量存储、多模式处理与全生命周期管理；并通过与各类外部异构数据源的交互集成，支持各类企业级应用。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.46488294314381273&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7NbdHu645pKPcokPRQicw7zx1X5ngLXWjxLQQ0vjSibJ7I6Q3mz9LzlUA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;598&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图1. 数据湖基本能力示意&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这里需要再特别指出两点：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;可扩展是指规模的可扩展和能力的可扩展，即数据湖不但要能够随着数据量的增大，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;提供“足够”的存储和计算能力&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;；还需要根据需要不断提供新的数据处理模式，例如可能一开始业务只需要批处理能力，但随着业务的发展，可能需要交互式的即席分析能力；又随着业务的实效性要求不断提升，可能需要支持实时分析和机器学习等丰富的能力。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;以数据为导向，是指数据湖对于用户来说要足够的简单、易用，帮助用户从复杂的IT基础设施运维工作中解脱出来，关注业务、关注模型、关注算法、关注数据。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;数据湖面向的是数据科学家、分析师&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。目前来看，云原生应该是构建数据湖的一种比较理想的构建方式，后面在“数据湖基本架构”一节会详细论述这一观点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;二、数据湖的基本特征&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;对数据湖的概念有了基本的认知之后，我们需要进一步明确数据湖需要具备哪些基本特征，特别是与大数据平台或者传统数据仓库相比，数据湖具有哪些特点。在具体分析之前，我们先看一张来自AWS官网的对比表格&lt;br/&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3445544554455445&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7SqxnUP7woibXPEm4zRUhqy5FuAhOJ0YotZ7RhUfMkIua5RJCQShwrpw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;505&quot; title=&quot;image.png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span&gt;上表对比了数据湖与传统数仓的区别，个人觉得可以从数据和计算两个层面进一步分析数据湖应该具备哪些特征。在数据方面：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;保真性：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;数据湖中对于业务系统中的数据都会存储一份“一模一样”的完整拷贝。与数据仓库不同的地方在于，数据湖中必须要保存一份原始数据，无论是数据格式、数据模式、数据内容都不应该被修改。在这方面，数据湖强调的是对于业务数据“原汁原味”的保存。同时，数据湖应该能够存储任意类型/格式的数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;灵活性：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;上表一个点是 “写入型schema” v.s.“读取型schema”，其实本质上来讲是数据schema的设计发生在哪个阶段的问题。对于任何数据应用来说，其实schema的设计都是必不可少的，即使是mongoDB等一些强调“无模式”的数据库，其最佳实践里依然建议记录尽量采用相同/相似的结构。“写入型schema”背后隐含的逻辑是数据在写入之前，就需要根据业务的访问方式确定数据的schema，然后按照既定schema，完成数据导入，带来的好处是数据与业务的良好适配；但是这也意味着数仓的前期拥有成本会比较高，特别是当业务模式不清晰、业务还处于探索阶段时，数仓的灵活性不够。数据湖强调的“读取型schema”，背后的潜在逻辑则是认为业务的不确定性是常态：我们无法预期业务的变化，那么我们就保持一定的灵活性，将设计去延后，让整个基础设施具备使数据“按需”贴合业务的能力。因此，个人认为“保真性”和“灵活性”是一脉相承的：既然没办法预估业务的变化，那么索性保持数据最为原始的状态，一旦需要时，可以根据需求对数据进行加工处理。因此，数据湖更加适合创新型企业、业务高速变化发展的企业。同时，数据湖的用户也相应的要求更高，数据科学家、业务分析师（配合一定的可视化工具）是数据湖的目标客户。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;可管理：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;数据湖应该提供完善的数据管理能力。既然数据要求“保真性”和“灵活性”，那么至少数据湖中会存在两类数据：原始数据和处理后的数据。数据湖中的数据会不断的积累、演化。因此，对于数据管理能力也会要求很高，至少应该包含以下数据管理能力：数据源、数据连接、数据格式、数据schema（库/表/列/行）。同时，数据湖是单个企业/组织中统一的数据存放场所，因此，还需要具有一定的权限管理能力。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;可追溯：&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;数据湖是一个组织/企业中全量数据的存储场所，需要对数据的全生命周期进行管理，包括数据的定义、接入、存储、处理、分析、应用的全过程。一个强大的数据湖实现，需要能做到对其间的任意一条数据的接入、存储、处理、消费过程是可追溯的，能够清楚的重现数据完整的产生过程和流动过程。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在计算方面，个人认为数据湖对于计算能力要求其实非常广泛，完全取决于业务对于计算的要求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;丰富的计算引擎。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;从批处理、流式计算、交互式分析到机器学习，各类计算引擎都属于数据湖应该囊括的范畴。一般情况下，数据的加载、转换、处理会使用批处理计算引擎；需要实时计算的部分，会使用流式计算引擎；对于一些探索式的分析场景，可能又需要引入交互式分析引擎。随着大数据技术与人工智能技术的结合越来越紧密，各类机器学习/深度学习算法也被不断引入，例如TensorFlow/PyTorch框架已经支持从HDFS/S3/OSS上读取样本数据进行训练。因此，对于一个合格的数据湖项目而言，计算引擎的可扩展/可插拔，应该是一类基础能力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;多模态的存储引擎。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;理论上，数据湖本身应该内置多模态的存储引擎，以满足不同的应用对于数据访问需求（综合考虑响应时间/并发/访问频次/成本等因素）。但是，在实际的使用过程中，数据湖中的数据通常并不会被高频次的访问，而且相关的应用也多在进行探索式的数据应用，为了达到可接受的性价比，数据湖建设通常会选择相对便宜的存储引擎（如S3/OSS/HDFS/OBS），并且在需要时与外置存储引擎协同工作，满足多样化的应用需求。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;h1 data-spm-anchor-id=&quot;5176.13955521.J_1633660880.i10.50c54cfe9kTcgQ&quot;&gt;&lt;span&gt;&lt;strong&gt; 三、数据湖基本架构&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据湖可以认为是新一代的大数据基础设施。为了更好的理解数据湖的基本架构，我们先来看看大数据基础设施架构的演进过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1） 第一阶段：&lt;/span&gt;&lt;span&gt;&lt;strong&gt;以Hadoop为代表的离线数据处理基础设施。&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;如下图所示，Hadoop是以HDFS为核心存储，以MapReduce（简称MR）为基本计算模型的批量数据处理基础设施。围绕HDFS和MR，产生了一系列的组件，不断完善整个大数据平台的数据处理能力，例如面向在线KV操作的HBase、面向SQL的HIVE、面向工作流的PIG等。同时，随着大家对于批处理的性能要求越来越高，新的计算模型不断被提出，产生了Tez、Spark、Presto等计算引擎，MR模型也逐渐进化成DAG模型。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DAG模型一方面，增加计算模型的抽象并发能力：对每一个计算过程进行分解，根据计算过程中的聚合操作点对任务进行逻辑切分，任务被切分成一个个的stage，每个stage都可以有一个或者多个Task组成，Task是可以并发执行的，从而提升整个计算过程的并行能力；另一方面，为减少数据处理过程中的中间结果写文件操作，Spark、Presto等计算引擎尽量使用计算节点的内存对数据进行缓存，从而提高整个数据过程的效率和系统吞吐能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5990220048899756&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7jusFyohK3hxVu4VdqYNbcx9NL6jeUGpFxfodLO6I6g9GMbBO6BjyMg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;409&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图2. Hadoop体系结构示意&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2） 第二阶段：&lt;/span&gt;&lt;span&gt;&lt;strong&gt;lambda架构。&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;随着数据处理能力和处理需求的不断变化，越来越多的用户发现，批处理模式无论如何提升性能，也无法满足一些实时性要求高的处理场景，流式计算引擎应运而生，例如Storm、Spark Streaming、Flink等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;然而，随着越来越多的应用上线，大家发现，其实批处理和流计算配合使用，才能满足大部分应用需求；而对于用户而言，其实他们并不关心底层的计算模型是什么，用户希望无论是批处理还是流计算，都能基于统一的数据模型来返回处理结果，于是Lambda架构被提出，如下图所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6547619047619048&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7ZXUEsicxHkUmeZbhgBU1NTFtwTNj3ibXHicsiaAHk2PXPUvHMiaVj1LW0wg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;420&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图3. Lambda架构示意&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Lambda架构的核心理念是“流批一体”&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，如上图所示，整个数据流向自左向右流入平台。进入平台后一分为二，一部分走批处理模式，一部分走流式计算模式。&lt;strong&gt;无论哪种计算模式，最终的处理结果都通过服务层对应用提供，确保访问的一致性。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;3） 第三阶段：&lt;/span&gt;&lt;span&gt;&lt;strong&gt;Kappa架构。&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;Lambda架构解决了应用读取数据的一致性问题，但是“流批分离”的处理链路增大了研发的复杂性。因此，有人就提出能不能用一套系统来解决所有问题。目前比较流行的做法就是基于流计算来做。&lt;strong&gt;流计算天然的分布式特征，注定了他的扩展性更好。通过加大流计算的并发性，加大流式数据的“时间窗口”，来统一批处理与流式处理两种计算模式。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4519230769230769&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ770VTdHpjeSDiaQyCUms6vVfnvSUCGNG4R70IWiakYIFG9Cic5aewnDqbA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;416&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图4. Kappa架构示意&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综上，从传统的hadoop架构往lambda架构，从lambda架构往Kappa架构的演进，大数据平台基础架构的演进逐渐囊括了应用所需的各类数据处理能力，大数据平台逐渐演化成了一个企业/组织的全量数据处理平台。当前的企业实践中，除了关系型数据库依托于各个独立的业务系统；其余的数据，几乎都被考虑纳入大数据平台来进行统一的处理。&lt;/span&gt;&lt;span&gt;&lt;strong&gt;然而，目前的大数据平台基础架构，都将视角锁定在了存储和计算，而忽略了对于数据的资产化管理，这恰恰是数据湖作为新一代的大数据基础设施所重点关注的方向之一。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;曾经看过一个很有意思的文章，提出过如下问题：数据湖为什么叫数据湖而不叫数据河或者数据海？一个有意思的回答是：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;“河”强调的是流动性，“海纳百川”，河终究是要流入大海的，而企业级数据是需要长期沉淀的，因此叫“湖”比叫“河”要贴切；同时，湖水天然是分层的，满足不同的生态系统要求，这与企业建设统一数据中心，存放管理数据的需求是一致的，“热”数据在上层，方便应用随时使用；温数据、冷数据位于数据中心不同的存储介质中，达到数据存储容量与成本的平衡。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;不叫“海”的原因在于，海是无边无界的，而“湖”是有边界的，这个边界就是企业/组织的业务边界；因此数据湖需要更多的数据管理和权限管理能力。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;叫“湖”的另一个重要原因是数据湖是需要精细治理的，一个缺乏管控、缺乏治理的数据湖最终会退化为“数据沼泽”，从而使应用无法有效访问数据，使存于其中的数据失去价值。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大数据基础架构的演进，其实反应了一点：在企业/组织内部，数据是一类重要资产已经成为了共识；为了更好的利用数据，企业/组织需要对数据资产：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;进行长期的原样存储&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;进行有效管理与集中治理&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;提供多模式的计算能力满足处理需求&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;以及面向业务，提供统一的数据视图、数据模型与数据处理结果&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据湖就是在这个大背景下产生的，除了大数据平台所拥有的各类基础能力之外，数据湖更强调对于数据的管理、治理和资产化能力。落到具体的实现上，数据湖需要包括一系列的数据管理组件，包括：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据接入&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据搬迁&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;数据治理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;质量管理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;资产目录&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;访问控制&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;任务管理&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;任务编排&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;元数据管理等&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如下图所示，给出了一个数据湖系统的参考架构。对于一个典型的数据湖而言，它与大数据平台相同的地方在于它也具备处理超大规模数据所需的存储和计算能力，能提供多模式的数据处理能力；增强点在于数据湖提供了更为完善的数据管理能力，具体体现在：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;更强大的数据接入能力。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;数据接入能力体现在对于各类外部异构数据源的定义管理能力，以及对于外部数据源相关数据的抽取迁移能力，抽取迁移的数据包括外部数据源的元数据与实际存储的数据。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;更强大的数据管理能力。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;管理能力具体又可分为基本管理能力和扩展管理能力。基本管理能力包括对各类元数据的管理、数据访问控制、数据资产管理，是一个数据湖系统所必须的，后面我们会在“各厂商的数据湖解决方案”一节相信讨论各个厂商对于基本管理能力的支持方式。扩展管理能力包括任务管理、流程编排以及与数据质量、数据治理相关的能力。任务管理和流程编排主要用来管理、编排、调度、监测在数据湖系统中处理数据的各类任务，通常情况下，数据湖构建者会通过购买/研制定制的数据集成或数据开发子系统/模块来提供此类能力，定制的系统/模块可以通过读取数据湖的相关元数据，来实现与数据湖系统的融合。而数据质量和数据治理则是更为复杂的问题，一般情况下，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;数据湖系统不会直接提供相关功能，但是会开放各类接口或者元数据，供有能力的企业/组织与已有的数据治理软件集成或者做定制开发。&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;可共享的元数据。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;数据湖中的各类计算引擎会与数据湖中的数据深度融合，而融合的基础就是数据湖的元数据。好的数据湖系统，计算引擎在处理数据时，能从元数据中直接获取数据存储位置、数据格式、数据模式、数据分布等信息，然后直接进行数据处理，而无需进行人工/编程干预。更进一步，好的数据湖系统还可以对数据湖中的数据进行访问控制，控制的力度可以做到“库表列行”等不同级别。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5397590361445783&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7hFLce3icFD1zZaY9s74A4TbDeBBPsnGicWgGlJ14ogv6pp5l0XZIBHNg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;830&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图5. 数据湖组件参考架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;还有一点应该指出的是，上图的“集中式存储”更多的是业务概念上的集中，本质上是希望一个企业/组织内部的数据能在一个明确统一的地方进行沉淀。事实上，数据湖的存储应该是一类可按需扩展的分布式文件系统，大多数数据湖实践中也是推荐采用S3/OSS/OBS/HDFS等分布式系统作为数据湖的统一存储。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以再切换到数据维度，从数据生命周期的视角来看待数据湖对于数据的处理方式，数据在数据湖中的整个生命周期如图6所示。理论上，一&lt;/span&gt;&lt;span&gt;&lt;strong&gt;个管理完善的数据湖中的数据会永久的保留原始数据，同时过程数据会不断的完善、演化，以满足业务的需要。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.35917312661498707&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7YfuOoqmmy3Oh4PFZLuCTt5K83EBACliatI5T2QwtjJLmMFicU79COLAg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;774&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图6. 数据湖中的数据生命周期示意&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;h1 data-spm-anchor-id=&quot;5176.13955521.J_1633660880.i10.50c54cfe9kTcgQ&quot;&gt;&lt;span&gt;&lt;strong&gt;四、各厂商的数据湖解决方案&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据湖作为当前的一个风口，各大云厂商纷纷推出自己的数据湖解决方案及相关产品。本节将分析各个主流厂商推出的数据湖解决方案，并将其映射到数据湖参考架构上，帮助大家理解各类方案的优缺点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;4.1 AWS数据湖解决方案&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4119170984455959&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7yicwZSlwxECIpApcD8REiag3yeVqLsA8B7DkXDQHp15t3wBKttxHpicsg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;772&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图7. AWS数据湖解决方案&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图7是AWS推荐的数据湖解决方案。整个方案基于AWS Lake Formation构建，AWS Lake Formation本质上是一个管理性质的组件，它与其他AWS服务互相配合，来完成整个企业级数据湖构建功能。上图自左向右，体现了数据流入、数据沉淀、数据计算、数据应用四个步骤。我们进一步来看其关键点：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;1） 数据流入。&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;数据流入是整个数据湖构建的起始，包括元数据的流入和业务数据流入两个部分。元数据流入包括数据源创建、元数据抓取两步，最终会形成数据资源目录，并生成对应的安全设置与访问控制策略。解决方案提供专门的组件，获取外部数据源的相关元信息，该组件能连接外部数据源、检测数据格式和模式（schema），并在对应的数据资源目录中创建属于数据湖的元数据。业务数据的流入是通过ETL来完成的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在具体的产品形式上，元数据抓取、ETL和数据准备AWS将其单独抽象出来，形成了一个产品叫AWS GLUE。AWS GLUE与AWS Lake Formation共享同一个数据资源目录，在AWS GLUE官网文档上明确指出：“Each AWS account has one AWS Glue Data Catalog per AWS region”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于异构数据源的支持。AWS提供的数据湖解决方案，支持S3、AWS关系型数据库、AWS NoSQL数据库，AWS利用GLUE、EMR、Athena等组件支持数据的自由流动。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;2） 数据沉淀。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;采用Amazon S3作为整个数据湖的集中存储，按需扩展/按使用量付费。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;3） 数据计算。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整个解决方案利用AWS GLUE来进行基本的数据处理。GLUE基本的计算形式是各类批处理模式的ETL任务，任务的出发方式分为手动触发、定时触发、事件触发三种。不得不说，AWS的各类服务在生态上实现的非常好，事件触发模式上，可以利用AWS Lambda进行扩展开发，同时触发一个或多个任务，极大的提升了任务触发的定制开发能力；同时，各类ETL任务，可以通过CloudWatch进行很好的监控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4） 数据应用。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在提供基本的批处理计算模式之外，AWS通过各类外部计算引擎，来提供丰富的计算模式支持，例如通过Athena/Redshift来提供基于SQL的交互式批处理能力；通过EMR来提供各类基于Spark的计算能力，包括Spark能提供的流计算能力和机器学习能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;5） 权限管理。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AWS的数据湖解决方案通过Lake Formation来提供相对完善的权限管理，粒度包括“库-表-列”。但是，有一点例外的是，GLUE访问Lake Formation时，粒度只有“库-表”两级；这也从另一个侧面说明，GLUE和Lake Formation的集成是更为紧密的，GLUE对于Lake Formation中的数据有更大的访问权限。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lake Formation的权限进一步可以细分为数据资源目录访问权限和底层数据访问权限，分别对应元数据与实际存储的数据。实际存储数据的访问权限又进一步分为数据存取权限和数据存储访问权限。数据存取权限类似于数据库中对于库表的访问权限，数据存储权限则进一步细化了对于S3中具体目录的访问权限（分为显示和隐式两种）。如图8所示，用户A在只有数据存取的权限下，无法创建位于S3指定bucket下的表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;个人认为这进一步体现了数据湖需要支持各种不同的存储引擎，未来的数据湖可能不只S3/OSS/OBS/HDFS一类核心存储，可能根据应用的访问需求，纳入更多类型的存储引擎，例如，S3存储原始数据，NoSQL存储处理过后适合以“键值”模式访问的数据，OLAP引擎存储需要实时出各类报表/adhoc查询的数据。虽然当前各类材料都在强调数据湖与数据仓库的不同；但是，从本质上，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;数据湖更应该是一类融合的数据管理思想的具体实现，“湖仓一体化”也很可能是未来的一个发展趋势。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.775623268698061&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ725bxNY1DbzibuswRNqtoWfSXc51FiauO8pCqvHXIricvaCibNkADbWJH9w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;361&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图8. AWS数据湖解决方案权限分离示意&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综上，&lt;strong&gt;AWS数据湖方案成熟度高，特别是元数据管理、权限管理上考虑充分，打通了异构数据源与各类计算引擎的上下游关系，让数据能够自由“移动”起来。&lt;/strong&gt;在流计算和机器学习上，AWS的解决方案也比较完善。流计算方面AWS推出了专门的流计算组件Kinesis，Kinesis中的Kinesis data Firehose服务可以创建一个完全被托管的数据分发服务，通过Kinesis data Stream实时处理的数据，可以借助Firehose方便的写入S3中，并支持相应的格式转换，如将JSON转换成Parquet格式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;AWS整个方案最牛的地方还在与Kinesis可以访问GLUE中的元数据，这一点充分体现了AWS数据湖解决方案在生态上的完备性。同样，在机器学习方面，AWS提供了SageMaker服务，SageMaker可以读取S3中的训练数据，并将训练好的模型回写至S3中。但是，有一点需要指出的是，在AWS的数据湖解决方案中，流计算和机器学习并不是固定捆绑的，只是作为计算能力扩展，能方便的集成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，让我们回到图6的数据湖组件参考架构，看看AWS的数据湖解决方案的组件覆盖情况，参见图9。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5927710843373494&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7mQFVT1thW8Jlfl9Qmb9Z463GcJtGQ9VMqr7xtGWxJDw6pYGMNdPM0A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;830&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图9. AWS 数据湖解决方案在参考架构中的映射&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综上，AWS的数据湖解决方案覆盖了除质量管理和数据治理的所有功能。其实质量管理和数据治理这个工作和企业的组织结构、业务类型强相关，需要做大量的定制开发工作，因此通用解决方案不囊括这块内容，也是可以理解的。事实上，现在也有比较优秀的开源项目支持这个项目，比如Apache Griffin，如果对质量管理和数据治理有强诉求，可以自行定制开发。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;4.2 华为数据湖解决方案&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.633423180592992&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ73tmKVibTg7bw9jDnZZBX67NdZNmTCat7utM5cTqM2Oqj0oKbxXaXsDA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;742&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图10.华为数据湖解决方案&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;华为的数据湖解决方案相关信息来自华为官网。目前官网可见的相关产品包括数据湖探索（Data Lake Insight，DLI）和智能数据湖运营平台（DAYU）。其中DLI相当于是AWS的Lake Formation、GLUE、Athena、EMR（Flink&amp;amp;Spark）的集合。官网上没找到关于DLI的整体架构图，我根据自己的理解，尝试画了一个，主要是和AWS的解决方案有一个对比，所以形式上尽量一致，如果有非常了解华为DLI的同学，也请不吝赐教。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;华为的数据湖解决方案比较完整，DLI承担了所有的数据湖构建、数据处理、数据管理、数据应用的核心功能。DLI最大的特色是在于分析引擎的完备性，包括基于SQL的交互式分析以及基于Spark+Flink的流批一体处理引擎。在核心存储引擎上，DLI依然通过内置的OBS来提供，和AWS S3的能力基本对标。华为数据湖解决方案在上下游生态上做的比AWS相对完善，对于外部数据源，几乎支持所有目前华为云上提供的数据源服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DLI可以与华为的CDM（云数据迁移服务）和DIS（数据接入服务）对接：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;借助DIS，DLI可以定义各类数据点，这些点可以在Flink作业中被使用，做为source或者sink；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;借助CDM，DLI甚至能接入IDC、第三方云服务的数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了更好的支持数据集成、数据开发、数据治理、质量管理等数据湖高级功能，华为云提供了DAYU平台。DAYU平台是华为数据湖治理运营方法论的落地实现。&lt;/span&gt;&lt;span&gt;DAYU涵盖了整个数据湖治理的核心流程，并对其提供了相应的工具支持；甚至在华为的官方文档中，给出了数据治理组织的构建建议。DAYU的数据治理方法论的落地实现如图11所示（来自华为云官网）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.49707602339181284&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7icHYQ8TnhyIU9lIFHXzicWicAZTcQFYxzh2TU6Y2WpHnVIT2L9jOtKicVg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;513&quot; title=&quot;image.png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图11 DAYU数据治理方法论流程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看到，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;本质上DAYU数据治理的方法论其实是传统数据仓库治理方法论在数据湖基础设施上的延伸&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：从数据模型来看，依然包括贴源层、多源整合层、明细数据层，这点与数据仓库完全一致。根据数据模型和指标模型会生成质量规则和转换模型，DAYU会和DLI对接，直接调用DLI提供的相关数据处理服务，完成数据治理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;华为云整个的数据湖解决方案，完整覆盖了数据处理的生命周期，并且明确支持了数据治理，并提供了基于模型和指标的数据治理流程工具，在华为云的数据湖解决方案中逐渐开始往“湖仓一体化”方向演进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;4.3 阿里云数据湖解决方案&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;阿里云上数据类产品众多，因为本人目前在数据BU，所以本节方案将关注在如何使用数据库BU的产品来构建数据湖，其他云上产品会略有涉及。阿里云的基于数据库产品的数据湖解决方案更加聚焦，主打数据湖分析和联邦分析两个场景。阿里云数据湖解决方案如图12所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-croporisrc=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7WP0JAzV89Wz7FMZ9bpmyjMx6nSSXjFPekNy3bWqAiaXIvicfUYU7PlRg/640?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;870&quot; data-cropy1=&quot;38.55243722304284&quot; data-cropy2=&quot;469.05465288035447&quot; data-ratio=&quot;0.4954022988505747&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/TEMFmlppic0bElEmewjkNfFAgHNZKYgARo2Draw1ls87WbOUicypwud0qb3V2cIoee6s1wIHuzyMLZNhCATUsfuQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;870&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图12. 阿里云数据湖解决方案&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整个方案依然采用&lt;/span&gt;&lt;strong&gt;&lt;span&gt;OSS作为数据湖的集中存储&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。在数据源的支持上，目前也支持所有的阿里云数据库，包括OLTP、OLAP和NoSQL等各类数据库。核心关键点如下：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据接入与搬迁。在建湖过程中，DLA的Formation组件具备元数据发现和一键建湖的能力，在本文写作之时，目前“一键建湖”还只支持全量建湖，但是基于binlog的增量建湖已经在开发中了，预计近期上线。增量建湖能力会极大的增加数据湖中数据的实时性，并将对源端业务数据库的压力降到最下。这里需要注意的是，DLA Formation是一个内部组件，对外并没有暴露。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据资源目录。DLA提供Meta data catalog组件对于数据湖中的数据资产进行统一的管理，无论数据是在“湖中”还是在“湖外”。Meta data catalog也是联邦分析的统一元数据入口。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在内置计算引擎上，DLA提供了SQL计算引擎和Spark计算引擎两种。无论是SQL还是Spark引擎，都和Meta data catalog深度集成，能方便的获取元数据信息。基于Spark的能力，DLA解决方案支持批处理、流计算和机器学习等计算模式。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在外围生态上，除了支持各类异构数据源做数据接入与汇聚之外，在对外访问能力上，DLA与云原生数据仓库（原ADB）深度整合。一方面，DLA处理的结果可之际推送至ADB中，满足实时、交互式、ad hoc复杂查询；另一方面，ADB里的数据也可以借助外表功能，很方便的进行数据回流至OSS中。基于DLA，阿里云上各类异构数据源可以完全被打通，数据自由流动。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在数据集成和开发上，阿里云的数据湖解决方案提供两种选择：一种是采用dataworks完成；另一种是采用DMS来完成。无论是选择哪种，都能对外提供可视化的流程编排、任务调度、任务管理能力。在数据生命周期管理上，dataworks的数据地图能力相对更加成熟。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;在数据管理和数据安全上，DMS提供了强大的能力。&lt;strong&gt;DMS的数据管理粒度分为“库-表-列-行”，完善的支持企业级的数据安全管控需求&lt;/strong&gt;。除了权限管理之外，DMS更精细的地方是把原来基于数据库的devops理念扩展到了数据湖，使得数据湖的运维、开发更加精细化。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;进一步细化整个数据湖方案的数据应用架构，如下图所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4323308270676692&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7rcvbdiazeQw89MdIYVoo6GZpQSFcVcNvHS5WIPNzOpz1BwAhibJDbRYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;532&quot; title=&quot;image.png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;图13. 阿里云数据湖数据应用架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;自左向右从数据的流向来看，数据生产者产生各类数据（云下/云上/其他云），利用各类工具，上传至各类通用/标准数据源，包括OSS/HDFS/DB等。针对各类数据源，DLA通过数据发现、数据接入、数据迁移等能力，完整建湖操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于“入湖”的数据，DLA提供基于SQL和Spark的数据处理能力，并可以基于Dataworks/DMS，对外提供可视化的数据集成和数据开发能力；在对外应用服务能力上，DLA提供标准化的JDBC接口，可以直接对接各类报表工具、大屏展示功能等。阿里云的DLA的特色在于背靠整个阿里云数据库生态，包括OLTP、OLAP、NoSQL等各类数据库，对外提供基于SQL的数据处理能力，对于传统企业基于数据库的开发技术栈而言，转型成本相对较低，学习曲线比较平缓。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;阿里云的DLA解决方案的另一个特色在于“基于云原生的湖仓一体化”。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;传统的企业级数据仓库在大数据时代的今天，在各类报表应用上依然是无法替代的，但是数仓无法满足大数据时代的数据分析处理的灵活性需求。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此，我们推荐数据仓库应该作为数据湖的上层应用存在：即数据湖是原始业务数据在一个企业/组织中唯一官方数据存储地；数据湖根据各类业务应用需求，将原始数据进行加工处理，形成可再次利用的中间结果；当中间结果的数据模式（Schema）相对固定后，DLA可以将中间结果推送至数据仓库，供企业/组织开展基于数仓的业务应用。阿里云在提供DLA的同时，还提供了云原生数仓（原ADB），DLA和云原生数仓在以下两点上深度融合。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DLA+ADB的组合真正做到了云原生的湖仓一体（关于什么是云原生，不在本文的讨论范畴）。本质上，DLA可以看成一个能力扩展的数据仓库贴源层。与传统数仓相比，该贴源层：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可以保存各类结构化、半结构化和非结构化数据；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;可以对接各类异构数据源；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具备元数据发现、管理、同步等能力；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;内置的SQL/Spark计算引擎具备更强的数据处理能力，满足多样化的数据处理需求；&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;具备全量数据的全生命周期管理能力。基于DLA+ADB的湖仓一体化方案，将同时覆盖“大数据平台+数据仓库”的处理能力。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.576&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7BVWbJ9vkwVt9ngyWSxnMgBkQZCXaFaDALxrePPQiagUFt9FjmbeDtQQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;500&quot; title=&quot;image.png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DLA还有一个重要能力是构建了一个“四通八达”的数据流动体系，并以数据库的体验对外提供能力，无论数据在云上还是云下，无论数据在组织内部还是外部；借助数据湖，各个系统之间的数据不再存在壁垒，可以自由的流进流出；更重要的是，这种流动是受监管的，数据湖完整的记录了数据的流动情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;&lt;span&gt;4.4 Azure数据湖解决方案&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Azure的数据湖解决方案包括数据湖存储、接口层、资源调度与计算引擎层，如图15所示（来自Azure官网）。存储层是基于Azure object Storage构建的，依然是对结构化、半结构化和非结构化数据提供支撑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接口层为WebHDFS，比较特别的是在Azure object Storage实现了HDFS的接口，Azure把这个能力称为“数据湖存储上的多协议存取”。在资源调度上，Azure基于YARN实现。计算引擎上，Azure提供了U-SQL、hadoop和Spark等多种处理引擎。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4880174291938998&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ70rFLhO41C9yefAkK0ta8k7HGNONr0ubBVVdG1ldrTdthGT7AoOtNlw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;459&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图15. Azure Data lake analysis 架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Azure的特别之处是基于visual studio提供给了客户开发的支持。&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;开发工具的支持，与visual studio的深度集成；Azure推荐使用U-SQL作为数据湖分析应用的开发语言。Visual studio为U-SQL提供了完备的开发环境；同时，为了降低分布式数据湖系统开发的复杂性，visual studio基于项目进行封装，在进行U-SQL开发时，可以创建“U-SQL database project”，在此类项目中，利用visual studio，可以很方便的进行编码与调试，同时，也提供向导，将开发好的U-SQL脚本发布到生成环境。U-SQL支持Python、R进行扩展，满足定制开发需求。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;多计算引擎的适配：SQL, Apache Hadoop和Apache Spark。这里的hadoop包括Azure提供的HDInsight（Azure托管的Hadoop服务），Spark包括Azure Databricks。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;多种不同引擎任务之间的自动转换能力。微软推荐U-SQL为数据湖的缺省开发工具，并提供各类转换工具，支持U-SQL脚本与Hive、Spark（HDSight&amp;amp;databricks）、Azure Data Factory data Flow之间的转化。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;4.5 小结&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本文所讨论的是数据湖的解决方案，不会涉及到任何云厂商的单个产品。我们从数据接入、数据存储、数据计算、数据管理、应用生态几个方面，简单做了一个类似下表的总结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3924050632911392&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7TK9WV5XYqxoFpODkyff1cVjicRgRuzTKtexjDg9f4uyicF2iabUEZo5Eg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;553&quot; title=&quot;image.png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;出于篇幅关系，其实知名云厂商的数据湖解决方案还有谷歌和腾讯的。这两家从其官方网站上看，数据湖解决方案相对来讲比较简单，也仅仅是一些概念上的阐述，推荐的落地方案是“oss+hadoop（EMR）”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;其实数据湖不应该从一个简单的技术平台视角来看，实现数据湖的方式也多种多样，评价一个数据湖解决方案是否成熟，关键应该看其提供的数据管理能力，具体包括但不限于元数据、数据资产目录、数据源、数据处理任务、数据生命周期、数据治理、权限管理等；以及与外围生态的对接打通能力。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;h2&gt;&lt;strong&gt;&lt;span&gt;五、典型的数据湖应用案例&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;5.1 广告数据分析&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;近年来，流量获取的成本就越来越高，线上渠道获客成本的成倍增长让各行各业都面临着严峻的挑战。在互联网广告成本不断攀升的大背景下，以花钱买流量拉新为主要的经营策略必然行不通了。流量前端的优化已成强弩之末，利用数据工具提高流量到站后的目标转化，精细化运营广告投放的各个环节，才是改变现状更为直接有效的方式。说到底，要提高广告流量的转化率，必须依靠大数据分析。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了能够提供更多的决策支撑依据，需要采取更多的埋点数据的收集和分析，包括但不限于渠道、投放时间、投放人群，以点击率为数据指标进行数据分析，从而给出更好的、更迅速的方案和建议，实现高效率高产出。因此，面对广告投放领域多维度、多媒体、多广告位等结构化、半结构化和非结构化数据采集、存储、分析和决策建议等要求，数据湖分析产品解决方案在广告主或者发布商进行新一代技术选型中上受到了很热烈的青睐。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;DG是一家全球领先的企业国际化智能营销服务商，基于先进的广告技术、大数据和运营能力，为客户提供全球高质量用户获取及流量变现服务。DG从成立之初就决定以公有云为基础来构建其IT基础设施，最初DG选择了AWS云平台，主要将其广告数据在S3中以数据湖的形态进行存放，通过Athena进行交互式分析。然而随着互联网广告的飞速发展，广告行业带来了几大挑战，移动广告的发布与追踪系统必须解决几个关键问题：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;并发性与峰值问题。在广告行业，流量高峰时常出现，瞬间的点击量可能达到数万，甚至数十万，这就要求系统具备非常好的可扩展性以快速响应和处理每一次点击&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如何实现对海量数据的实时分析。为了监控广告投放效果，系统需要实时对用户的每一次点击和激活数据进行分析，同时把相关数据传输到下游的媒体；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;平台的数据量在急剧增长，每天的业务日志数据在持续的产生和上传，曝光、点击、推送的数据在持续处理，每天新增的数据量已经在10-50TB左右，对整个数据处理系统提出了更高的要求。如何高效地完成对广告数据的离线/近实时统计，按照广告客户的维度要求进行聚合分析。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;针对上述三点业务挑战，同时DG这个客户日增量数据正在急剧变大（当前日数据扫描量达到100+TB），继续在AWS平台使用遇到Athena读取S3数据带宽瓶颈、数据分析滞后时间越来越长、为应对数据和分析需求增长而急剧攀升的投入成本等，经过认真、仔细的测试和分析，最终决定从AWS云平台全量搬站到阿里云平台，新架构图如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4376130198915009&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7ichFZJFqSOhyszDvibAQOtIQCh3svUVeJqw6o7CtGyeS960q8nibVjU8g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;553&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图16. 改造后的广告数据湖方案架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从AWS搬站到阿里云后，我们为该客户设计了“利用Data Lake Analytics + OSS”极致分析能力来应对业务波峰波谷。一方面轻松应对来自品牌客户的临时分析。另一方面利用Data Lake Analytics的强大计算能力，分析按月、季度广告投放，精确计算出一个品牌下面会有多少个活动，每个活动分媒体，分市场，分频道，分DMP的投放效果，进一步增强了加和智能流量平台为品牌营销带来的销售转化率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;并且在广告投放与分析的总拥有成本上，Data Lake Analytics提供的Serverless的弹性服务为按需收费，不需要购买固定的资源，完全契合业务潮汐带来的资源波动，满足弹性的分析需求，同时极大地降低了运维成本和使用成本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.42857142857142855&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7ME3M35B0rXicVsPicuyYbjXMd4apEyjq3M5CM3XEV3hTgGhJv4uaTQ3A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;553&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图17 数据湖部署示意图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总体上，DG从AWS切换到阿里云后，极大地节省了硬件成本、人力成本和开发成本。由于采用DLA serverless云服务，DG无需先期投入大量的资金去购买服务器、存储等硬件设备，也无需一次性购买大量的云服务，其基础设施的规模完全是按需扩展：需求高的时候增加服务数量，需求减少的时候减少服务数量，提高了资金的利用率。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;使用阿里云平台带来的第二个显著好处是性能的提升。在DG业务的快速增长期以及后续多条业务线接入期，DG在移动广告系统的访问量经常呈爆发式增长，然而原先AWS方案和平台在Athena读取S3数据遇到数据读取带宽的极大瓶颈，数据分析的时间变得越来越长，阿里云DLA联合OSS团队等进行了极大的优化和改造，同时，DLA数据库分析在计算引擎上（与TPC-DS打榜世界第一的AnalyticDB共享计算引擎）比Presto原生计算引擎的能力提升数十倍性能，也极大的为DG提升了分析性能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;5.2 游戏运营分析&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据湖是一类TCO表现极其优秀的大数据基础设施。对于很多快速增长的游戏公司而言，一个爆款游戏，往往在短期内相关数据增长极快；同时，公司的研发人员的技术栈很难在短期内与数据的增量和增速进行匹配；此时，呈爆发增长的数据很难被有效利用。数据湖是一个解决此类问题的技术选择。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;YJ是一家高速成长的游戏公司，公司希望能依托相关用户行为数据进行深入分析，指导游戏的开发和运营。数据分析背后的核心逻辑在于随着游戏行业市场竞争局面的扩大，玩家对于品质的要求越来越高，游戏项目的生命周期越来越短，直接影响项目的投入产出比，通过数据运营则可以有效的延长项目的生命周期，对各个阶段的业务走向进行精准把控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;而随着流量成本的日益上升，如何构建经济、高效的精细化数据运营体系，以更好的支撑业务发展，也变得愈发重要起来。数据运营体系就需要有其配套的基础支撑设施，如何选择这类基础支撑设施，是公司技术决策者需要思考的问题。思考的出发点包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;要有足够的弹性。对于游戏而言，往往就是短时间爆发，数据量激增；因此，能否适应数据的爆发性增长，满足弹性需求是一个重点考量的点；无论是计算还是存储，都需要具备足够的弹性。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;要有足够的性价比。对于用户行为数据，往往需要拉到一个很长的周期去分析去对比，比如留存率，不少情况下需要考虑90天甚至180天客户的留存率；因此，如何以最具性价比的方式长期存储海量数据是需要重点考虑的问题。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;要有够用的分析能力，且具备可扩展性。许多情况下，用户行为体现在埋点数据中，埋点数据又需要与用户注册信息、登陆信息、账单等结构化数据关联分析；因此，在数据分析上，至少需要有大数据的ETL能力、异构数据源的接入能力和复杂分析的建模能力。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;要与公司现有技术栈相匹配，且后续利于招聘。对于YJ，其在技术选型的时候一个重要点就是其技术人员的技术栈，YJ的技术团队大部分只熟悉传统的数据库开发，即MySQL；并且人手紧张，做数据运营分析的技术人员只有1个，短时间内根本没有能力独立构建大数据分析的基础设施。从YJ的角度出发，最好绝大多数分析能够通过SQL完成；并且在招聘市场上，SQL开发人员的数量也远高于大数据开发工程师的数量。针对客户的情况，我们帮助客户对现有方案做了改造。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4219409282700422&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7TUgGkZ7TaI2OOb4a4Ncic1l2rAWWCAJYu0l67d0AVGDbPnEmEvXED8w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;474&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图18. 改造前的方案&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;改造前，客户所有的结构化数据都在一个高规格的MySQL里面；而玩家行为数据则是通过LogTail采集至日志服务（SLS）中，然后从日志服务中分别投递到OSS和ES里。这个架构的问题在于：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;行为数据和结构化数据完全割裂，无法联动分析；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;对于行为数据智能提供检索功能，无法做深层次的挖掘分析；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;OSS仅仅作为数据存储资源使用，并没有挖掘出足够的数据价值。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;事实上，我们分析客户现存架构其实已经具备了数据湖的雏形：全量数据已经在OSS中保存下来了，现在需要进一步补齐客户对于OSS中的数据的分析能力。而且数据湖基于SQL的数据处理模式也满足客户对于开发技术栈的需求。综上，我们对客户的架构做了如下调整，帮助客户构建了数据湖。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6059225512528473&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7Xjza9BHJE8lqh20nKDicLHL2rZLEXsqbN0J68oN6iaYURVInXCDzTpdQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;439&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图19. 改造后的数据湖解决方案&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总体上，我们没有改变客户的数据链路流转，只是在OSS的基础上，增加了DLA组件，对OSS的数据进行二次加工处理。DLA提供了标准SQL计算引擎，同时支持接入各类异构数据源。基于DLA对OSS的数据进行处理后，生成业务直接可用的数据。但是DLA的问题在于无法支撑低延迟需求的交互式分析场景，为了解决这个问题，我们引入了云原生数据仓库ADB来解决交互式分析的延迟性问题；同时，在最前端引入QuickBI作为客户的可视化分析工具。YJ方案是图14所示的湖仓一体化解决方案在游戏行业的一个经典落地案例。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;YM是一家数据智能服务提供商，面向各类中小商家提供一系列数据分析运营服务。具体实现的技术逻辑如下图所示。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3547486033519553&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7YrtQM5athtrJz4yqlOpfWC6l9Rib4ynf5V6bicf7hxmQEXY8wCWoTtKg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;716&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图20. YM智能数据服务SaaS模式示意&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;平台方提供多端SDK供用户（商家提供网页、APP、小程序等多种接入形式）接入各类埋点数据，平台方以SaaS的形式提供统一的数据接入服务和数据分析服务。商家通过访问各类数据分析服务来进行更细粒度的埋点数据分析，完成行为统计、客户画像、客户圈选、广告投放监测等基本分析功能。然而，这种SaaS模式下，会存在一定的问题：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;由于商家类型和需求的多样化，平台提供SaaS类分析功能很难覆盖所有类型的商家，无法满足商家的定制化需求；如有些商家关注销量，有些关注客户运营，有些关注成本优化，很难满足所有的需求。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;对于一些高级分析功能，如依赖于自定义标签的客户圈选、客户自定义扩展等功能，统一的数据分析服务无法满足的；特别是一些自定义的标签依赖于商家自定义的算法，无法满足客户的高级分析需求。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;数据的资产化管理需求。在大数据时代，数据是一个企业/组织的资产已经成为了大家的共识，如何能让属于商家的数据合理、长期的沉淀下来，也是SaaS服务需要考虑的事情。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;综上，我们在上图的基本模式上引入了数据湖模式，让数据湖作为商家沉淀数据、产出模型、分析运营的基础支撑设施。引入数据湖后的SaaS数据智能服务模式如下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5111731843575419&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7YNWlMKRZKbIs5AUyE47h5foPBckNhIgIMoBfU08ic2hXamqVSIMxENQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;716&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图21. 基于数据湖的数据智能服务&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如图21所示，平台方为每个用户提供一键建湖服务，商家使用该功能构建自己的数据湖，“一键建湖”能力一方面帮助商家将所有埋点数据的数据模型（schema）同步至数据湖中；另一方面，将属于该商家的所有埋点数据全量同步至数据湖中，并基于“T+1”的模式，将每天的增量数据归档入湖。基于数据湖的服务模式在传统的数据分析服务的基础上，赋予了用户数据资产化、分析模型化和服务定制化三大能力：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;数据资产化能力。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;利用数据湖，商家可以将属于自己的数据持续沉淀下来，保存多长时间的数据，耗费多少成本，完全由商家自主决定。数据湖还提供了数据资产管理能力，商家除了能管理原始数据外，还能将处理过的过程数据和结果数据分门别类保存，极大的提升了埋点数据的价值。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;分析模型化能力。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;数据湖中不仅仅有原始数据，还有埋点数据的模型（schema）。埋点数据模型体现了全域数据智能服务平台对于业务逻辑的抽象，通过数据湖，除了将原始数据作为资产输出外，还将数据模型进行了输出，借助埋点数据模型，商家可以更深入的理解埋点数据背后所体现的用户行为逻辑，帮助商家更好的洞察客户行为，获取用户需求。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;服务定制化能力。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;借助数据湖提供的数据集成和数据开发能力，基于对埋点数据模型的理解，商家可以定制数据处理过程，不断对原始数据进行迭代加工，从数据中提炼有价值的信息，最终获得超越原有数据分析服务的价值。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;h1 data-spm-anchor-id=&quot;5176.13955521.J_1633660880.i10.50c54cfe9kTcgQ&quot;&gt; &lt;span&gt;&lt;strong&gt;六、数据湖建设的基本过程&lt;/strong&gt;&lt;/span&gt;&lt;/h1&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;个人认为数据湖是比传统大数据平台更为完善的大数据处理基础支撑设施，完善在数据湖是更贴近客户业务的技术存在。&lt;strong&gt;所有数据湖所包括的、且超出大数据平台存在的特性，例如元数据、数据资产目录、权限管理、数据生命周期管理、数据集成和数据开发、数据治理和质量管理等，无一不是为了更好的贴近业务，更好的方便客户使用。&lt;/strong&gt;数据湖所强调的一些基本的技术特性，例如弹性、存储计算独立扩展、统一的存储引擎、多模式计算引擎等等，也是为了满足业务需求，并且给业务方提供最具性价比的TCO。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据湖的建设过程应该与业务紧密结合；但是数据湖的建设过程与传统的数据仓库，甚至是大热的数据中台应该是有所区别的。区别在于，&lt;/span&gt;&lt;strong&gt;&lt;span&gt;数据湖应该以一种更敏捷的方式去构建，“边建边用，边用边治理”&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。为了更好的理解数据湖建设的敏捷性，我们先来看一下传统数仓的构建过程。业界对于传统数仓的构建提出了“自下而上”和“自顶而下”两种模式，分别由Inmon和KimBall两位大牛提出。具体的过程就不详述了，不然可以再写出几百页，这里只简单阐述基本思想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Inmon提出自下而上（EDW-DM）的数据仓库建设模式，即操作型或事务型系统的数据源，通过ETL抽取转换和加载到数据仓库的ODS层。ODS层中的数据，根据预先设计好的EDW（企业级数据仓库）范式进行加工处理，然后进入到EDW。EDW一般是企业/组织的通用数据模型，不方便上层应用直接做数据分析。因此，各个业务部门会再次根据自己的需要，从EDW中处理出数据集市层（DM）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优势：易于维护，高度集成；劣势：结构一旦确定，灵活性不足，且为了适应业务，部署周期较长。此类方式构造的数仓，适合于比较成熟稳定的业务，例如金融。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;KimBall提出自顶而下（DM-DW）的数据架构，通过将操作型或事务型系统的数据源，抽取或加载到ODS层。然后通过ODS的数据，利用维度建模方法建设多维主题数据集市（DM）。各个DM，通过一致性的维度联系在一起，最终形成企业/组织通用的数据仓库。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;优势：构建迅速，最快的看到投资回报率，敏捷灵活；劣势：作为企业资源不太好维护，结构复杂，数据集市集成困难。常应用于中小企业或互联网行业。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实上述只是一个理论上的过程，其实无论是先构造EDW，还是先构造DM，都离不开对于数据的摸底，以及在数仓构建之前的数据模型的设计，包括当前大热的“数据中台”，都逃不出下图所示的基本建设过程。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3057692307692308&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7az0wHHITZMNtFMTX2kO2ecVGy5b2tsQibwLAZOm4bx55q9S9WTA8ichg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;520&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图22. 数据仓库/数据中台建设基本流程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据摸底。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;对于一个企业/组织而言，在构建数据湖初始工作就是对自己企业/组织内部的数据做一个全面的摸底和调研，包括数据来源、数据类型、数据形态、数据模式、数据总量、数据增量等。在这个阶段一个隐含的重要工作是借助数据摸底工作，进一步梳理企业的组织结构，明确数据和组织结构之间关系。为后续明确数据湖的用户角色、权限设计、服务方式奠定基础。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;模型抽象。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;针对企业/组织的业务特点梳理归类各类数据，对数据进行领域划分，形成数据管理的元数据，同时基于元数据，构建通用的数&lt;strong&gt;据模型。&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;数据接入。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;根据第一步的摸排结果，确定要接入的数据源。根据数据源，确定所必须的数据接入技术能力，完成数据接入技术选型，接入的数据至少包括：数据源元数据、原始数据元数据、原始数据。各类数据按照第二步形成的结果，分类存放。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;融合治理。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;简单来说就是利用数据湖提供的各类计算引擎对数据进行加工处理，形成各类中间数据/结果数据，并妥善管理保存。数据湖应该具备完善的数据开发、任务管理、任务调度的能力，详细记录数据的处理过程。在治理的过程中，会需要更多的数据模型和指标模型。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;业务支撑。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;在通用模型基础上，各个业务部门定制自己的细化数据模型、数据使用流程、数据访问服务。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上述过程，对于一个快速成长的互联网企业来说，太重了，很多情况下是无法落地的，最现实的问题就是第二步模型抽象，很多情况下，业务是在试错、在探索，根本不清楚未来的方向在哪里，也就根本不可能提炼出通用的数据模型；没有数据模型，后面的一切操作也就无从谈起，这也是很多高速成长的企业觉得数据仓库/数据中台无法落地、无法满足需求的重要原因之一。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据湖应该是一种更为“敏捷”的构建方式，我们建议采用如下步骤来构建数据湖。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3057692307692308&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7CGJOQM5Z2JytAq9yfABicE0fLicJGVleZIx7oZl4d5ONTdxO737F0Iaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;520&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图23. 数据湖建设基本流程&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对比图22，依然是五步，但是这五步是一个全面的简化和“可落地”的改进。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;数据摸底。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;依然需要摸清楚数据的基本情况，包括数据来源、数据类型、数据形态、数据模式、数据总量、数据增量。但是，也就需要做这么多了。数据湖是对原始数据做全量保存，因此无需事先进行深层次的设计。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;技术选型。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;根据数据摸底的情况，确定数据湖建设的技术选型。事实上，这一步也非常的简单，因为关于数据湖的技术选型，业界有很多的通行的做法，基本原则个人建议有三个：“计算与存储分离”、“弹性”、“独立扩展”。建议的存储选型是分布式对象存储系统（如S3/OSS/OBS）；计算引擎上建议重点考虑批处理需求和SQL处理能力，因为在实践中，这两类能力是数据处理的关键，关于流计算引擎后面会再讨论一下。无论是计算还是存储，建议优先考虑serverless的形式；后续可以在应用中逐步演进，真的需要独立资源池了，再考虑构建专属集群。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;数据接入。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;确定要接入的数据源，完成数据的全量抽取与增量接入。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;应用治理。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这一步是数据湖的关键，我个人把“融合治理”改成了“应用治理”。&lt;/span&gt;&lt;strong&gt;&lt;span&gt;从数据湖的角度来看，数据应用和数据治理应该是相互融合、密不可分的。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;从数据应用入手，在应用中明确需求，在数据ETL的过程中，逐步形成业务可使用的数据；同时形成数据模型、指标体系和对应的质量标准。数据湖强调对原始数据的存储，强调对数据的探索式分析与应用，但这绝对不是说数据湖不需要数据模型；恰恰相反，对业务的理解与抽象，将极大的推动数据湖的发展与应用，数据湖技术使得数据的处理与建模，保留了极大的敏捷性，能快速适应业务的发展与变化。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从技术视角来看，数据湖不同于大数据平台还在于数据湖为了支撑数据的全生命周期管理与应用，需要具备相对完善的数据管理、类目管理、流程编排、任务调度、数据溯源、数据治理、质量管理、权限管理等能力。在计算能力上，目前主流的数据湖方案都支持SQL和可编程的批处理两种模式（对机器学习的支持，可以采用Spark或者Flink的内置能力）；在处理范式上，几乎都采用基于有向无环图的工作流的模式，并提供了对应的集成开发环境。对于流式计算的支持，目前各个数据湖解决方案采取了不同的方式。在讨论具体的方式之前，我们先对流计算做一个分类：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;模式一：实时模式。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这种流计算模式相当于对数据采用“来一条处理一条”/“微批”的方式进行处理；多见于在线业务，如风控、推荐、预警等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;strong&gt;&lt;span&gt;模式二：类流式。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;这种模式需要获取指定时间点之后变化的数据/读取某一个版本的数据/读取当前的最新数据等，是一种类流式的模式；多见于数据探索类应用，如分析某一时间段内的日活、留存、转化等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;二者的本质不同在于，模式一处理数据时，数据往往还没有存储到数据湖中，仅仅是在网路/内存中流动；模式二处理数据时，数据已经存储到数据湖中了。综上，我个人建议采用如下图模式：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4679334916864608&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/tMJtfgIIibWIY9w0QuntbrPVoahRdlvJ7Xc66Em5KejlV0gyic0OMvKbcIl0FV2jxSQ6FHG7q7YrN91F2DjVU24A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;842&quot; title=&quot;image.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;图24 数据湖数据流向示意图&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;如图24所示，在需要数据湖具备模式一的处理能力时，还是应该引入类Kafka中间件，作为数据转发的基础设施。完整的数据湖解决方案方案应该提供将原始数据导流至Kafka的能力。流式引擎具备从类Kafka组件中读取数据的能力。流式计算引擎在处理数据过后，根据需要，可以将结果写入OSS/RDBMS/NoSQL/DW，供应用访问。某种意义上，模式一的流计算引擎并非一定要作为数据湖不可分割的一部分存在，只需要在应用需要时，能够方便的引入即可。但是，这里需要指出的是：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;流式引擎依然需要能够很方便的读取数据湖的元数据；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;流式引擎任务也需要统一的纳入数据湖的任务管理；&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;流式处理任务依然需要纳入到统一的权限管理中。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;对于模式二，本质上更接近于批处理。现在许多经典的大数据组件已经提供了支持方式，如HUDI/IceBerg/Delta等，均支持Spark、Presto等经典的计算引擎。以HUDI为例，通过支持特殊类型的表（COW/MOR），提供访问快照数据（指定版本）、增量数据、准实时数据的能力。目前AWS、腾讯等已经将HUDI集成到了其EMR服务中，阿里云的DLA也正在计划推出DLA on HUDI的能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;让我们再回到本文开头的第一章，我们说过，数据湖的主要用户是数据科学家和数据分析师，探索式分析和机器学习是这类人群的常见操作；流式计算（实时模式）多用于在线业务，严格来看，并非数据湖目标用户的刚需。但是，流式计算（实时模式）是目前大多数互联网公司在线业务的重要组成部分，而数据湖作为企业/组织内部的数据集中存放地，需要在架构上保持一定的扩展能力，可以很方便的进行扩展，整合流式计算能力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;业务支撑。&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;虽然大多数数据湖解决方案都对外提供标准的访问接口，如JDBC，市面上流行的各类BI报表工具、大屏工具也都可以直接访问数据湖中的数据。但是在实际的应用中，我们还是建议将数据湖处理好的数据推送到对应的各类支持在线业务的数据引擎中去，能够让应用有更好的体验。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;七、总结&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;数据湖作为新一代大数据分析处理的基础设施，需要超越传统的大数据平台。个人认为目前在以下方面，是数据湖解决方案未来可能的发展方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;1、云原生架构。关于什么是云原生架构，众说纷纭，很难找到统一的定义。但是具体到数据湖这个场景，个人认为就是以下三点特征：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;（1）存储和计算分离，计算能力和存储能力均可独立扩展；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;（2）多模态计算引擎支持，SQL、批处理、流式计算、机器学习等；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;（3）提供serverless态服务，确保足够的弹性以及支持按需付费。&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2、足够用的数据管理能力。数据湖需要提供更为强大的数据管理能力，包括但不限于数据源管理、数据类目管理、处理流程编排、任务调度、数据溯源、数据治理、质量管理、权限管理等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;3、大数据的能力，数据库的体验。目前绝大多数数据分析人员都只有数据库的使用经验，大数据平台的能力虽强，但是对于用户来说并不友好，数据科学家和数据数据分析师应该关注数据、算法、模型及其与业务场景的适配，而不是花大量的时间精力去学习大数据平台的开发。数据湖要想快速发展，如何为用户提供良好的使用体验是关键。基于SQL的数据库应用开发已经深入人心，如何将数据湖的能力通过SQL的形式释放出来，是未来的一个主要方向。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;4、完善的数据集成与数据开发能力。对各种异构数据源的管理与支持，对异构数据的全量/增量迁移支持，对各种数据格式的支持都是需要不断完善的方向。同时，需要具备一个完备的、可视化的、可扩展的集成开发环境。&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;5、与业务的深度融合与集成。典型数据湖架构的构成基本已经成为了业界共识：分布式对象存储+多模态计算引擎+数据管理。决定数据湖方案是否胜出的关键恰恰在于数据管理，无论是原始数据的管理、数据类目的管理、数据模型的管理、数据权限的管理还是处理任务的管理，都离不开与业务的适配和集成；未来，会有越来越多的行业数据湖解决方案涌现出来，与数据科学家和数据分析师形成良性发展与互动。如何在数据湖解决方案中预置行业数据模型、ETL流程、分析模型和定制算法，可能是未来数据湖领域差异化竞争的一个关键点。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;（本文来源阿里云数据库，作者惊玄）&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6764091858037579&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/TwK74MzofXd78W49nBaME6TkGc8gv8DBzMJvytIYy9Dibfsl7qq5ibATfYh9BN1xQO5qU1OejK3Gic6dfl8iafXwGg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;958&quot;/&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>8edd26a01b6320fb24a71c5dfad76c03</guid>
<title>刷新世界纪录，GitHub 又一黑科技项目面世！</title>
<link>https://toutiao.io/k/5z90ek1</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p class=&quot;original_area_primary&quot;&gt;
                                                                                                &lt;/p&gt;

                    
                                                    


                
                
                
                
                                                
                                                                
                                
                                
                
                &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p class=&quot;js_darkmode__1&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span&gt;公众号关注 “GitHubDaily”&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;设为 “&lt;/span&gt;&lt;span&gt;星标&lt;/span&gt;&lt;span&gt;”，每天带你逛 GitHub！&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.562962962962963&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/uDRkMWLia28hynWsG6J0gmT3RqHrKqhYJ2kSPeaIgNibAwOqsnsYD7MUgia1kHDVUL9r9fSejoxIjWNgW748V5EWg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;p cid=&quot;n707&quot; mdtype=&quot;paragraph&quot;&gt;大家好，我是小 G。&lt;/p&gt;&lt;p cid=&quot;n1061&quot; mdtype=&quot;paragraph&quot;&gt;你知道，当今 AI 之势，影响纵深发展的矛盾是什么吗？&lt;/p&gt;&lt;p cid=&quot;n1062&quot; mdtype=&quot;paragraph&quot;&gt;一方面，大模型风头正劲，效果惊艳，人人都想试试。但另一方面，硬件基础上动不动就是上万张 GPU 的大规模集群在日夜燃烧，钞能力劝退。&lt;/p&gt;&lt;p cid=&quot;n1062&quot; mdtype=&quot;paragraph&quot;&gt;但是，自从 GitHub 上一个名为 &lt;strong&gt;Colossal-AI&lt;/strong&gt; 的开源项目横空面世之后，便彻底打破了这一局面。&lt;/p&gt;&lt;p cid=&quot;n1062&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;Colossal-AI 只用一半数量的 GPU，就能完成同样的 GPT-3 训练工作，极大降低了整个 AI 技术研究领域的投入成本！&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n1066&quot; mdtype=&quot;paragraph&quot;&gt;因此，这一项目在开源不久后，就以迅雷不及掩耳之势，迅速登上了 Python 热榜第一。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.7953703703703704&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19UpJsFOSicqZk5tPxSednsVuIOjEkbU9X8zzLk7viaic2yZ4jCDnShrNNw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1068&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;em&gt;GitHub 地址：https://github.com/hpcaitech/ColossalAI&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n1069&quot; mdtype=&quot;paragraph&quot;&gt;该项目创始人，也是 LAMB 优化器的提出者尤洋教授，在 Google 实习期间，曾经&lt;span&gt;凭借 LAMB，打破 BERT 预训练世界纪录！&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n1069&quot; mdtype=&quot;paragraph&quot;&gt;此外，Colossal-AI 作为一个可用于 AI 大规模并行训练的深度学习系统，它能做的事情还有很多。&lt;/p&gt;&lt;p cid=&quot;n1069&quot; mdtype=&quot;paragraph&quot;&gt;不仅能加速 GPT-3，对于 GPT-2、ViT、BERT 等多种模型，Colossal-AI 的表现也都非常 nice：&lt;/p&gt;&lt;p cid=&quot;n1070&quot; mdtype=&quot;paragraph&quot;&gt;比如&lt;strong&gt;半小时&lt;/strong&gt;左右就能预训练一遍 ViT-Base/32，&lt;strong&gt;2 天&lt;/strong&gt;能训完 &lt;strong&gt;15 亿&lt;/strong&gt;参数 GPT 模型、&lt;strong&gt;5 天&lt;/strong&gt;可训完 &lt;strong&gt;83 亿&lt;/strong&gt;参数 GPT 模型。&lt;/p&gt;&lt;p cid=&quot;n1071&quot; mdtype=&quot;paragraph&quot;&gt;与业内主流的 AI 并行系统 —— 英伟达 Megatron-LM 相比，在同样使用 512 块 GPU 训练 GPT-2 模型时，Colossal-AI 的加速比是其 &lt;strong&gt;2 倍&lt;/strong&gt;。而在训练 GPT-3 时，更是可以节省近千万元的训练费用。&lt;/p&gt;&lt;p cid=&quot;n1072&quot; mdtype=&quot;paragraph&quot;&gt;此外在训练 GPT-2 时，显存消耗甚至能控制在 Megatron-LM 的&lt;strong&gt;十分之一&lt;/strong&gt;以下。&lt;/p&gt;&lt;p cid=&quot;n1073&quot; mdtype=&quot;paragraph&quot;&gt;Colossal-AI 究竟是如何做到的？&lt;/p&gt;&lt;p cid=&quot;n1074&quot; mdtype=&quot;paragraph&quot;&gt;老规矩，我们从论文扒起。&lt;/p&gt;&lt;h3 cid=&quot;n1075&quot; mdtype=&quot;heading&quot;&gt;高效 6 维并行方法&lt;/h3&gt;&lt;p cid=&quot;n1076&quot; mdtype=&quot;paragraph&quot;&gt;简单来说，Colossal-AI 就是一个整合了多种并行方法的系统，提供的功能包括多维并行、大规模优化器、自适应任务调度、消除冗余内存等。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5132275132275133&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19BMOCYrSMa78a4s4xItJ2VmRz14xnzPZgIQeYia5Hk9Q9m8mOHCjiaAKQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1512&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1078&quot; mdtype=&quot;paragraph&quot;&gt;首先来看&lt;strong&gt;多维并行&lt;/strong&gt;。&lt;/p&gt;&lt;p cid=&quot;n1079&quot; mdtype=&quot;paragraph&quot;&gt;所谓 “多维” 是指，目前主流的分布式并行方案往往使用&lt;strong&gt;多种&lt;/strong&gt;并行方法。&lt;/p&gt;&lt;p cid=&quot;n1080&quot; mdtype=&quot;paragraph&quot;&gt;比如英伟达的 Megatron-LM 使用了 &lt;strong&gt;3 种&lt;/strong&gt;方法：数据并行、流水并行和张量并行。因此这种模式也被称为&lt;strong&gt;三维并行&lt;/strong&gt;。微软的 DeepSpeed 调用 Megatron-LM 作为并行基础。&lt;/p&gt;&lt;p cid=&quot;n1081&quot; mdtype=&quot;paragraph&quot;&gt;而 Colossal-AI 能将系统的并行维度，一下子拉升到 &lt;strong&gt;6 维！&lt;/strong&gt;&lt;/p&gt;&lt;p cid=&quot;n1082&quot; mdtype=&quot;paragraph&quot;&gt;在兼容数据并行、流水并行的基础上，基于该项目团队自研的 &lt;strong&gt;2 维 / 2.5 维 / 3 维张量并行&lt;/strong&gt;方法，以及&lt;strong&gt;序列并行&lt;/strong&gt;实现。&lt;/p&gt;&lt;p cid=&quot;n1083&quot; mdtype=&quot;paragraph&quot;&gt;其中，高维张量并行正是 Colossal-AI 提升大模型显存利用率和通信效率的关键所在。&lt;/p&gt;&lt;p cid=&quot;n1084&quot; mdtype=&quot;paragraph&quot;&gt;其实张量并行并不新奇，只是过去我们常见的张量并行更多都是基于&lt;strong&gt;一维&lt;/strong&gt;的。&lt;/p&gt;&lt;p cid=&quot;n1085&quot; mdtype=&quot;paragraph&quot;&gt;它的原理是将模型层内的权重参数按&lt;strong&gt;行或列&lt;/strong&gt;切分到不同的处理器上，利用分块矩阵乘法，将一个运算分布到多个处理器上同时进行。&lt;/p&gt;&lt;p cid=&quot;n1086&quot; mdtype=&quot;paragraph&quot;&gt;比如英伟达的 Megatron-LM 就是一个典型的例子。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.6807511737089202&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19GiaZibZPfLb7rrfYlwyNkUxco6t6FBUsxL5sHyDcB9WiczRkZUSKH90sg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;852&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1088&quot; mdtype=&quot;paragraph&quot;&gt;但这种并行方式存在一定弊端。&lt;/p&gt;&lt;p cid=&quot;n1089&quot; mdtype=&quot;paragraph&quot;&gt;比如，每个处理器仍需要存储整个中间激活，使得在处理大模型时会浪费大量&lt;strong&gt;显存&lt;/strong&gt;空间。&lt;/p&gt;&lt;p cid=&quot;n1090&quot; mdtype=&quot;paragraph&quot;&gt;另一方面，这种单线方法还会导致每个处理器都需要与&lt;strong&gt;其他所有&lt;/strong&gt;处理器进行通信。&lt;/p&gt;&lt;p cid=&quot;n1091&quot; mdtype=&quot;paragraph&quot;&gt;这意味着假设有 100 个 GPU 的话，每个 GPU 都需要与其他 99 个 GPU 通信，每次计算需要通信的次数就高达 &lt;strong&gt;9900 次&lt;/strong&gt;。&lt;/p&gt;&lt;p cid=&quot;n1092&quot; mdtype=&quot;paragraph&quot;&gt;但如果将张量并行的维度扩展到 &lt;strong&gt;2 维&lt;/strong&gt;，单次计算量能立刻下降一个量级。&lt;/p&gt;&lt;p cid=&quot;n1093&quot; mdtype=&quot;paragraph&quot;&gt;因为每个 GPU 只需与自己同行或同列的 GPU 通信即可。&lt;/p&gt;&lt;p cid=&quot;n1094&quot; mdtype=&quot;paragraph&quot;&gt;同样还是 100 个 GPU 的情况，每个 GPU 需要通信的 GPU 个数就能降到 &lt;strong&gt;9 个&lt;/strong&gt;，单次计算仅需 &lt;strong&gt;900 次&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.25304136253041365&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19en4gdesiasV7SEKqI4sJFWK7nibXgf6FxmtcePZbXEsh9hGLUNUZ2ZgQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;822&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1096&quot; mdtype=&quot;paragraph&quot;&gt;实际上在此基础上，Colossal-AI 还包含 2.5 维、3 维张量并行方法，可以进一步降低传输成本。&lt;/p&gt;&lt;p cid=&quot;n1097&quot; mdtype=&quot;paragraph&quot;&gt;相较于 2 维并行方法，2.5 维并行方法可提升 1.45 倍效率，3 维方法可提升 1.57 倍。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.30648148148148147&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19xVxb2ZeMibxttD3EQRTMVMQHbMl2Mib8ibib7iaia0sE19KDvH3TtMt6kyyA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1099&quot; mdtype=&quot;paragraph&quot;&gt;针对大图片、视频、长文本、长时间医疗监控等数据，Colossal-AI 还使用了&lt;strong&gt;序列并行&lt;/strong&gt;的方法，这种方法能突破原有机器能力限制，直接处理长序列数据。&lt;/p&gt;&lt;p cid=&quot;n1100&quot; mdtype=&quot;paragraph&quot;&gt;值得一提的是，Colossal-AI 的 API 接口是可以定制的，这使得它可以便捷添加新的并行维度。&lt;/p&gt;&lt;p cid=&quot;n1101&quot; mdtype=&quot;paragraph&quot;&gt;其次，&lt;strong&gt;大规模优化器&lt;/strong&gt;也是 Colossal-AI 的亮点。&lt;/p&gt;&lt;p cid=&quot;n1102&quot; mdtype=&quot;paragraph&quot;&gt;上面我们也提到了，在分布式并行系统中会使用多种并行方法，&lt;strong&gt;数据并行&lt;/strong&gt;则是另一种常见方法。&lt;/p&gt;&lt;p cid=&quot;n1103&quot; mdtype=&quot;paragraph&quot;&gt;这种方法的原理不难理解，就是把训练数据划分成若干份，让不同的机器运算不同的数据，然后通过一个&lt;strong&gt;参数服务器&lt;/strong&gt; （Paremeter Server）收集目标数据。&lt;/p&gt;&lt;p cid=&quot;n1104&quot; mdtype=&quot;paragraph&quot;&gt;由此可以大幅提升 AI 模型训练过程中的批量大小，加速训练过程。&lt;/p&gt;&lt;p cid=&quot;n1105&quot; mdtype=&quot;paragraph&quot;&gt;不过大批量训练有个 “通病”，就是会产生&lt;strong&gt;泛化误差&lt;/strong&gt; （Generalization Gap），导致网络泛化能力下降，进而导致 AI 模型准确度下降。&lt;/p&gt;&lt;p cid=&quot;n1106&quot; mdtype=&quot;paragraph&quot;&gt;所以，Colossal-AI 在系统中使用了自研的 &lt;strong&gt;LAMB、LARS&lt;/strong&gt; 等大规模优化器。在保证训练精度的情况下，还将批大小从 &lt;strong&gt;512&lt;/strong&gt; 扩展到 &lt;strong&gt;65536&lt;/strong&gt;。&lt;/p&gt;&lt;p cid=&quot;n1107&quot; mdtype=&quot;paragraph&quot;&gt;其中，LARS 优化器是通过逐层调整学习率，来减少因为学习率导致的无法收敛情况。&lt;/p&gt;&lt;p cid=&quot;n1108&quot; mdtype=&quot;paragraph&quot;&gt;LAMB 优化器则是在 LARS 的基础上，将逐层调整学习率的思想应用到自适应梯度上。&lt;/p&gt;&lt;p cid=&quot;n1109&quot; mdtype=&quot;paragraph&quot;&gt;由此，LAMB 能够很好解决此前 LARS 在 BERT 训练中存在差异的问题，最大批量达到了 &lt;strong&gt;64K&lt;/strong&gt;。&lt;/p&gt;&lt;p cid=&quot;n1110&quot; mdtype=&quot;paragraph&quot;&gt;此前，LAMB 优化器曾成功将预训练一遍 BERT 的时间，从原本的三天三夜缩短到一个多小时。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5082236842105263&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19b2KSHhy0ySzYaQk14LjmEVGM6cyibn4V0KiaQjhVTnn9Q16x1ZkU2OGw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;2432&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1112&quot; mdtype=&quot;paragraph&quot;&gt;第三方面，Colossal-AI 使用&lt;strong&gt;自适应可扩展调度器&lt;/strong&gt;来高效处理任务。&lt;/p&gt;&lt;p cid=&quot;n1113&quot; mdtype=&quot;paragraph&quot;&gt;与现有常见的任务调度器不同，Colossal-AI 不是静态地通过 GPU 个数来判断任务规模，而是根据批大小来动态、自动管理每个任务.&lt;/p&gt;&lt;p cid=&quot;n1114&quot; mdtype=&quot;paragraph&quot;&gt;通过演化算法，该任务调度器还能不断优化调度决策，更大程度提升 GPU 利用率。&lt;/p&gt;&lt;p cid=&quot;n1115&quot; mdtype=&quot;paragraph&quot;&gt;评估结果表明，与当前最先进的方法相比，该方法在平均 JCT （job completion time）上能够缩短 &lt;strong&gt;45.6%&lt;/strong&gt; 的时间，优于现有的深度学习任务调度算法。&lt;/p&gt;&lt;p cid=&quot;n1116&quot; mdtype=&quot;paragraph&quot;&gt;此外，这种自适应可扩展调度器还能通过 NCCL 网络通信实现高效的任务迁移。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.39444444444444443&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19P2HfBGGlVLAtibqzAjdDZcQkS5AeLlhUO77UWpaYnRGKQxKodmhgdLw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1118&quot; mdtype=&quot;paragraph&quot;&gt;最后，&lt;strong&gt;消除冗余内存&lt;/strong&gt;也是加速 AI 训练的一种解决思路。&lt;/p&gt;&lt;p cid=&quot;n1119&quot; mdtype=&quot;paragraph&quot;&gt;在这方面，Colossal-AI 使用了 &lt;strong&gt;zero redundancy optimizer&lt;/strong&gt; 技术（简称 ZeRO）。&lt;/p&gt;&lt;p cid=&quot;n1120&quot; mdtype=&quot;paragraph&quot;&gt;这种方法主要通过切分优化器状态、梯度、模型参数，使 GPU 仅保存当前计算所需的部分，从而来消除数据并行、模型并行中存在的内存冗余。&lt;/p&gt;&lt;p cid=&quot;n1121&quot; mdtype=&quot;paragraph&quot;&gt;尤其是在部署模型推理时，通过 zero offload 可以将模型卸载到 CPU 内存或硬盘，仅使用少量 GPU 资源，即可实现低成本部署前沿 AI 大模型。&lt;/p&gt;&lt;p cid=&quot;n1122&quot; mdtype=&quot;paragraph&quot;&gt;综上不难看出，在技术层面 Colossal-AI 的加速效果非常明显。&lt;/p&gt;&lt;p cid=&quot;n1123&quot; mdtype=&quot;paragraph&quot;&gt;而在应用层面，Colossal-AI 的设计也顾及了&lt;strong&gt;能耗&lt;/strong&gt;问题和&lt;strong&gt;易用性&lt;/strong&gt;两个维度。&lt;/p&gt;&lt;p cid=&quot;n1124&quot; mdtype=&quot;paragraph&quot;&gt;考虑到数据移动会是能耗的主要来源，Colossal-AI 在不增加计算量的情况下尽可能减少数据移动量，以此来降低能耗。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.46779661016949153&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ192ZXrnK0xXHToqFzYEreLRTrPVPa4UdAFCGRnwVPrPEgG69YXGXlZyA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1180&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1126&quot; mdtype=&quot;paragraph&quot;&gt;另一方面，作为一个开源给所有人使用的系统，Colossal-AI 的使用门槛不高，即便是没有学习过分布式系统的人也能上手操作。&lt;/p&gt;&lt;p cid=&quot;n1127&quot; mdtype=&quot;paragraph&quot;&gt;同时，只需要极少量的代码改动，Colossal-AI 就能将已有的单机代码快速扩展到并行计算集群上。&lt;/p&gt;&lt;h3 cid=&quot;n1128&quot; mdtype=&quot;heading&quot;&gt;最新实验结果释出&lt;/h3&gt;&lt;p cid=&quot;n1129&quot; mdtype=&quot;paragraph&quot;&gt;Talk is cheap，效果如何，还是得把实验结果展开来看。&lt;/p&gt;&lt;p cid=&quot;n1130&quot; mdtype=&quot;paragraph&quot;&gt;Colossal-AI 近日释出的最新实验结果表明，这一大规模 AI 训练系统具有通用性，在 GPT-3、GPT-2、ViT、BERT 等流行模型上均有亮眼的加速表现。&lt;/p&gt;&lt;p cid=&quot;n1131&quot; mdtype=&quot;paragraph&quot;&gt;注：以下 GPU 均指英伟达 A100。&lt;/p&gt;&lt;p cid=&quot;n1132&quot; mdtype=&quot;paragraph&quot;&gt;&lt;strong&gt;GPT-3 训练速度提高 10.7%&lt;/strong&gt;&lt;/p&gt;&lt;p cid=&quot;n1133&quot; mdtype=&quot;paragraph&quot;&gt;英伟达的 Megatron-LM 在加速训练 GPT-3 时，至少需要 128 块 GPU 才能启动；而从下表可以看出，使用相同的计算资源，Colossal-AI 可以将每次迭代花费的时间从 43.1 秒降至 38.5 秒。&lt;/p&gt;&lt;p cid=&quot;n1134&quot; mdtype=&quot;paragraph&quot;&gt;这也就意味着，Colossal-AI 可以将 GPT-3 的训练速度进一步提高 10.7%。&lt;/p&gt;&lt;p cid=&quot;n1135&quot; mdtype=&quot;paragraph&quot;&gt;站在工程的角度，考虑到训练这样的大模型往往需要投入数百万美元，这一提升比例带来的收益不言而喻。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.2871046228710462&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19dxs0thNibYNRtgWFqtqiaqeTic6HiaPJ5kz0IvrdaqZZ2XQA67EWiavfFBg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1644&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1137&quot; mdtype=&quot;paragraph&quot;&gt;另外，通过系统优化，Colossal-AI 还能在训练速度损失不大（43.1→48.5）的前提下，将 GPU 数量从 128 块减少到 96 块，大幅降低训练成本。&lt;/p&gt;&lt;p cid=&quot;n1138&quot; mdtype=&quot;paragraph&quot;&gt;而进一步启用 ZeRO3（零冗余优化器）后，所需 GPU 数量甚至能&lt;strong&gt;减少一半&lt;/strong&gt; —— 至 64 块。&lt;/p&gt;&lt;p cid=&quot;n1139&quot; mdtype=&quot;paragraph&quot;&gt;&lt;strong&gt;2 天内可完成 GPT-2 训练&lt;/strong&gt;&lt;/p&gt;&lt;p cid=&quot;n1140&quot; mdtype=&quot;paragraph&quot;&gt;在 GPT-2 的加速训练结果中，可以看到，无论是在 4、16 还是 64 块 GPU 的情况下，与 Megatron-LM 相比，Colossal-AI 占用的显存都显著减少。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.3435185185185185&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19HhqPkJL4cPWdSNqpU9qVurobsyEsMdYhn91ze0dNEoPKYJicHuSqFnQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1142&quot; mdtype=&quot;paragraph&quot;&gt;也就是说，利用 Colossal-AI，工程师们可以在采用同等数量 GPU 的前提下，训练规模更大的模型，或设置更大的批量大小来加速训练。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4793187347931874&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19hIsyMhGJiaE18QHLzs1JTYPlC1icVgKFuaicibenFibCyKcgkwwn2Nf4oCQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;3288&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1144&quot; mdtype=&quot;paragraph&quot;&gt;从下表结果中还可以看出，随着批量大小的增加，Colossal-AI 的资源利用率会进一步提高，达到 Megatron-LM 速度的 &lt;strong&gt;2 倍&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.31666666666666665&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19ogACfhbia1fLvnP7nVGqAFibqCFEruhsyrjQgXr3RwWHDPxk4hjWRv1g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1146&quot; mdtype=&quot;paragraph&quot;&gt;研发团队在 256 块 GPU 上进行了实验，最终用时 82.8 个小时完成了 15 亿参数版 GPT-2 的训练。&lt;/p&gt;&lt;p cid=&quot;n1147&quot; mdtype=&quot;paragraph&quot;&gt;据此预估，后续在 512 块 GPU 上进行 GPT-2 预训练，Colossal-AI 能将训练时间加速到 &lt;strong&gt;45 小时&lt;/strong&gt;。&lt;/p&gt;&lt;p cid=&quot;n1148&quot; mdtype=&quot;paragraph&quot;&gt;&lt;strong&gt;充分兼容多种并行模式&lt;/strong&gt;&lt;/p&gt;&lt;p cid=&quot;n1149&quot; mdtype=&quot;paragraph&quot;&gt;在 BERT 上进行的实验，则体现了 Colossal-AI 作为&lt;strong&gt;世界上并行维度最多&lt;/strong&gt;的 AI 训练系统的优势。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.5185185185185185&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19B4YuS0hkXUIw71ejf8H2u75xibIxAs0XaWDY6lYAJKDmSicDdhtUxLtQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1151&quot; mdtype=&quot;paragraph&quot;&gt;与 Megatron-LM 相比，Colossal-AI 序列并行方法只需要更少的显存，就能够利用更大的批量大小来加速训练。同时，还允许开发者使用更长的序列数据。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4842592592592593&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19fhEyp4x26DdN7picYmDS7gjSRmY0gn8x3Bar5bchNKunhp58cd8hQwQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1153&quot; mdtype=&quot;paragraph&quot;&gt;Colossal-AI 的序列并行方法还与流水并行方法兼容。当开发者同时使用序列并行和流水并行时，可以进一步节省训练大模型的时间。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.9361111111111111&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19xib8fU28Pvt76bFq47h03noYHBL6FjGjibzALXyPMHz0wr66IU8MrLag/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1155&quot; mdtype=&quot;paragraph&quot;&gt;另外，在近期的学术热点 &lt;strong&gt;ViT 模型&lt;/strong&gt;上，Colossal-AI 也展现了高维张量并行方法的优势。&lt;/p&gt;&lt;p cid=&quot;n1156&quot; mdtype=&quot;paragraph&quot;&gt;在使用 64 张 GPU 的情况下，Colossal-AI 采用 2/2.5 维方式进行张量并行，充分利用更大的批量大小，达到了更快的处理速度。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.41388888888888886&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19Wicd1ibwCDg6bldENPXVULCKR2gBOF7KZlxzEItF4Cdbh3kUC8Zviahnw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;h3 cid=&quot;n1158&quot; mdtype=&quot;heading&quot;&gt;背后团队：LAMB 优化器作者尤洋领衔&lt;br/&gt;&lt;/h3&gt;&lt;p cid=&quot;n1159&quot; mdtype=&quot;paragraph&quot;&gt;看到这里，是不是觉得 Colossal-AI 确实值得标星关注一发？&lt;/p&gt;&lt;p cid=&quot;n1160&quot; mdtype=&quot;paragraph&quot;&gt;实际上，这一国产项目背后的研发团队来头不小。&lt;/p&gt;&lt;p cid=&quot;n1161&quot; mdtype=&quot;paragraph&quot;&gt;领衔者，正是 &lt;strong&gt;LAMB 优化器&lt;/strong&gt;的提出者&lt;strong&gt;尤洋&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6925675675675675&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/libMic1J2Kj4ocDicIsZiaRUDSHWdZP6UJ19ictCUeKhQX8MyEMqIVJnkA1ZIicbum77LYbgWT7eBiaibaJ355cxkgdBbg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;592&quot;/&gt;&lt;/p&gt;&lt;p cid=&quot;n1163&quot; mdtype=&quot;paragraph&quot;&gt;在谷歌实习期间，正是凭借 LAMB，尤洋曾打破 BERT 预训练世界纪录。&lt;/p&gt;&lt;p cid=&quot;n1164&quot; mdtype=&quot;paragraph&quot;&gt;据英伟达官方 GitHub 显示，LAMB 比 Adam 优化器快出整整 &lt;strong&gt;72&lt;/strong&gt; 倍。微软的 DeepSpeed 也采用了 LAMB 方法。&lt;/p&gt;&lt;p cid=&quot;n1165&quot; mdtype=&quot;paragraph&quot;&gt;说回到尤洋本人，他曾以第一名的成绩保送清华计算机系硕士研究生，后赴加州大学伯克利分校攻读 CS 博士学位。&lt;/p&gt;&lt;p cid=&quot;n1166&quot; mdtype=&quot;paragraph&quot;&gt;2020 年博士毕业后，他加入新加坡国立大学计算机系，并于 2021 年 1 月成为校长青年教授（Presidential Young Professor）。&lt;/p&gt;&lt;p cid=&quot;n1167&quot; mdtype=&quot;paragraph&quot;&gt;同样是在 2021 年，他还获得了 IEEE-CS 超算杰出新人奖。该奖项每年在全球范围内表彰不超过 3 人，仅授予在博士毕业 5 年之内，已在高性能计算领域做出有影响力的卓越贡献，并且可以为高性能计算的发展做出长期贡献的优秀青年学者。&lt;/p&gt;&lt;p cid=&quot;n1168&quot; mdtype=&quot;paragraph&quot;&gt;与此同时，尤洋回国创办&lt;strong&gt;潞晨科技&lt;/strong&gt; —— 一家主营业务为分布式软件系统、大规模人工智能平台以及企业级云计算解决方案的 AI 初创公司。&lt;/p&gt;&lt;p cid=&quot;n1169&quot; mdtype=&quot;paragraph&quot;&gt;其核心团队成员来自加州大学伯克利分校、斯坦福大学、清华大学、北京大学、新加坡国立大学、新加坡南洋理工大学等国内外知名高校，在高性能计算、人工智能、分布式系统方面有十余年的技术积累，并已在国际顶级学术刊物 / 会议上发表论文 30 余篇。&lt;/p&gt;&lt;p cid=&quot;n1170&quot; mdtype=&quot;paragraph&quot;&gt;目前，潞晨科技已拿下创新工场和真格基金合投的超千万元种子轮融资。&lt;/p&gt;&lt;h3 cid=&quot;n1171&quot; mdtype=&quot;heading&quot;&gt;传送门&lt;/h3&gt;&lt;p cid=&quot;n1172&quot; mdtype=&quot;paragraph&quot;&gt;有关 Colossal-AI，今天就先介绍到这里。&lt;/p&gt;&lt;p cid=&quot;n1173&quot; mdtype=&quot;paragraph&quot;&gt;最后，附上传送门，感兴趣的小伙伴，自行取用～&lt;/p&gt;&lt;p cid=&quot;n1174&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;&lt;em&gt;GitHub 地址：&lt;span md-inline=&quot;url&quot; spellcheck=&quot;false&quot;&gt;https://github.com/hpcaitech/ColossalAI&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n1175&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;参考链接：&lt;/span&gt;&lt;/p&gt;&lt;p cid=&quot;n1176&quot; mdtype=&quot;paragraph&quot;&gt;&lt;span&gt;https://medium.com/@hpcaitech/efficient-and-easy-training-of-large-ai-models-introducing-colossal-ai-ab571176d3ed&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzAxOTcxNTIwNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/uDRkMWLia28ia8xsyOClt8NDDCTAZNaDsEic4EEpUG1FPduFr5TUMK1GbDiaFX0qNCJiaS2XPfHzWlFicK95v1a9ic7Vg/0?wx_fmt=png&quot; data-nickname=&quot;GitHubDaily&quot; data-alias=&quot;GitHubDaily&quot; data-signature=&quot;专注于分享 GitHub 上知名的 Python、Java、Web、AI、数据分析等多个领域的优质学习资源、开源项目及开发者工具，为 GitHub 开发者提供优质编程资讯。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>564e8ce2f5aa9e4d650afbbd1e9c2258</guid>
<title>《算法通关手册》</title>
<link>https://toutiao.io/k/g61h5oi</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;以下内容选自「码农周刊 VIP 会员」圈子，每日更新，精彩不断。&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;《算法通关手册》——超详细的「算法与数据结构」基础讲解教程，「LeetCode」650+ 道题目 Python 版的详细解析。通过「算法理论学习」和「编程实战练习」相结合的方式，从零基础到彻底掌握算法知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;578&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;1022&quot; data-ratio=&quot;2.864&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/t8lpVibticjQ7AjmLD5TPPQnO3QFNFT3mx10KVKg8ia1xFeO0qyLicxUSxltafNL8ohwNib39LXtdlKhoXv7Kgq4lzA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot;/&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>67f162264efc17eeb6ad3dacd8bdb45f</guid>
<title>Kubernetes 故障排除三板斧：理解、管理和预防</title>
<link>https://toutiao.io/k/5ximy5q</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span&gt;公众号关注 「&lt;span&gt;&lt;span&gt;奇妙的 Linux 世界&lt;/span&gt;&lt;/span&gt;」&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;设为「&lt;span&gt;星标&lt;/span&gt;」，每天带你玩转 Linux ！&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;562&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;330&quot; data-ratio=&quot;0.5625&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; title=&quot;&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8ZFzrRjqatqicMZQXYvUwsIrCXUePJgM6Po5icrpuVMW8nQUokZkSRGxpaEoyHjvGRX2EVbky8icZBb9kX2Y2UOXQ/640?wx_fmt=jpeg&quot;/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Kubernetes 生态系统充斥着各种工具，例如监控、可观察性、跟踪、日志记录等，但一般很难真正理解故障排除与这些工具有何联系。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;当故障发生时，我们要掌握是从哪里发生，了解所面临的问题，解决眼前的问题，然后修复根本原因。随着系统规模的扩大，这一切会变得越来越复杂。&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzI3MTI2NzkxMA==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/8ZFzrRjqatrP1H2ykr2xId1T1xNrZaVFuqGgQ3ycnJylh6A6h0vp2yqynejepUBcBufs3NWFKxl1QPsRxJ61YQ/0?wx_fmt=png&quot; data-nickname=&quot;奇妙的Linux世界&quot; data-alias=&quot;Hi-Linux&quot; data-signature=&quot;这里是 Linux 爱好者的聚集地，不仅有各种硬核干货文章和新奇内容推荐，还常常有福利红包等你来领哟。快快加入我们，一起愉快玩耍吧！&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一名从事现代、复杂、分布式系统工作的软件工程师，会经常发现，每次出现问题或故障时，都需要了解引发问题的原因以及是谁造成的，但是，这并不是一件容易的事。更难的，是弄清楚幕后发生了什么，以及如何防止它再次发生。&lt;span&gt;一般，我们会这样思考：&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;究竟发生了什么？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;哪些事情是相关的？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;什么与我们试图排除故障的特定症状相关？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;我们如何确定根本原因？&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;最终，我们还要确保将来不再发生此问题或类似问题？&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;本文中，我们将之简化为3个步骤：&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我将深入探讨如何实施好这三个步，以及它们如何帮助我们对 Kubernetes 进行故障排除。我还将回顾哪些生态系统工具适合哪个步，以更好地掌握或使用那些工具。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;1&lt;/span&gt;&lt;/span&gt;&lt;span&gt;第一步：理解&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;毫不奇怪，这是重要的一步。理解系统资源，通常使你能够了解发生了什么、出了什么问题以及我们接下来应该做什么。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;为了尝试了解故障原因，开发人员将首先分析系统最近的修改以及可能导致此故障发生的更改。&lt;span&gt;当然，这说起来容易做起来难。&lt;/span&gt;&lt;span&gt;在复杂的分布式系统，尤其是基于 Kubernetes 的系统中，这意味着大量使用 kubectl 来对部署日志、跟踪和指标进行故障排除，验证 pod 健康状况和资源上限，以及服务连接，以及其他常见的 pod 错误，检查 YAML 配置文件，验证第三方工具和集成等等。&lt;/span&gt;&lt;span&gt;这可能是一行代码、一行配置的更改，触发了故障。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下图一张图，可以帮助我们在排除 K8s 系统进行故障时，缩小问题的范围。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-backh=&quot;790&quot; data-backw=&quot;558&quot; data-ratio=&quot;1.4151260504201681&quot; data-type=&quot;png&quot; data-w=&quot;1190&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/lPwvgkMwLNhInLHAhibqQKx2Z7UaVBTBQ2477y4QWQzsyh4hss55DsfKSN9YH5J5VB1uhPOYWTBsCmyweZ1WQgg/640?wx_fmt=png&quot;/&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;图片来源🔗：&lt;span&gt; 有关 Kubernetes 部署故障排除的指南&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;网上的也有一份国人中文版的 Kubernetes 故障排除指南，供参考&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;636&quot; data-backw=&quot;558&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.1390625&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/lPwvgkMwLNhInLHAhibqQKx2Z7UaVBTBQY1HoTpS07gOWNWaSS5BxaldicibCjjPJ2xcQiaazqVxazUULaTTZth3Fg/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;可在 &lt;strong&gt;公众号 &lt;/strong&gt;内回复&lt;strong&gt;『Kubernetes故障排除』&lt;/strong&gt;获取高清原图&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;p&gt;&lt;a class=&quot;weapp_image_link&quot; data-miniprogram-appid=&quot;wxece3a9a4c82f58c9&quot; data-miniprogram-path=&quot;pages/sharePid/web/index?scene=https://s.click.ele.me/HNXIdju&quot; data-miniprogram-nickname=&quot;饿了么 l 外卖美食超市买菜水果&quot; data-miniprogram-type=&quot;image&quot; data-miniprogram-servicetype=&quot;0&quot; href=&quot;&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.8&quot; data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; title=&quot;&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8ZFzrRjqatqQmpZFTlIWpHu1tgMT5vYiboRPj6uBcHrMzOiaDEZxqp9axqvNlV6Cj3bAI5vPkIN6LoiboEssjjrUQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;点击上方图片，打开小程序，『饿了么外卖』红包天天免费领！&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;接下来，我们将查看事件：系统中实际发生了什么 – 系统是否过载？是否丢失了数据？是否存在服务中断？这与系统的初始变化有何关系？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;然后，我们查看一下我们创建的指标、仪表板和数据，以基于数据源对问题进行某种理解。是否不止一个系统表现相同？影响两个系统的服务之一是否存在依赖性？最后，我们能否从看似相似的先前事件中学到一些东西，让我们对我们现在正在经历的事情有所了解？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;仅就某些情况而言，下面是你需要使用的一些工具的列表，以便对系统中发生的事情有一个基本的了解。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;监控工具：&lt;code&gt;Datadog&lt;/code&gt;、&lt;code&gt;Dynatrace&lt;/code&gt;、&lt;code&gt;Grafana Labs&lt;/code&gt;、&lt;code&gt;New Relic&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;可观察性工具：&lt;code&gt;Lightstep&lt;/code&gt;、&lt;code&gt;Honeycomb&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;实时调试工具：&lt;code&gt;OzCode&lt;/code&gt;、&lt;code&gt;Rookout&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;日志工具：&lt;code&gt;Splunk&lt;/code&gt;、&lt;code&gt;LogDNA&lt;/code&gt;、&lt;code&gt;Logz.io&lt;/code&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;2&lt;/span&gt;&lt;/span&gt;&lt;span&gt;第二步：管理&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在当今的微服务架构中，很多时候相互依赖的服务由不同的团队管理。发生故障时，解决问题的关键之一是团队之间的沟通与协作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;根据潜在问题的类型，你可能想要采取的操作，包括像重启系统这样简单的操作，或者更’严厉’的措施，例如版本回滚或恢复最近的配置，直到更清楚地了解潜在问题。最终，你可能需要采取主动措施，如增加内存上限或机器数量的形式增加容量。但是，所有这些都不应该是你实时尝试和弄清楚的。今天有很多工具，从 Jenkins 到 ArgoCD，云提供商的专有工具，甚至更多的 kubectl 来采取这些行动和措施。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一旦更好地理解了潜在问题，补救就不应该是主要是反复试验的临时操作，或者存在于当前团队和实践中的记录。根据公司的技术堆栈和可能的根本原因，应使用定制的运行手册来管理任何给定的事件，并针对每种警报提供具体的任务和操作。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;团队中的每一位工程师，无论是高级还是初级，都可以利用这一份友好的运行手册来实时排除故障。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;此阶段的工具包将包括以下一些内容：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;事件管理：&lt;code&gt;PagerDuty&lt;/code&gt;，&lt;code&gt;Kintaba&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;项目管理：&lt;code&gt;Jira&lt;/code&gt;、&lt;code&gt;Monday&lt;/code&gt;、&lt;code&gt;Trello&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;CI/CD 管理：&lt;code&gt;ArgoCD&lt;/code&gt;、&lt;code&gt;Jenkins&lt;/code&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;3&lt;/span&gt;&lt;/span&gt;&lt;span&gt;最后一个步：预防&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;预防可能是最重要的步，以确保类似事件不再发生。防止类似问题的方法是根据每个事件创建定义明确的策略和规则。在“理解”阶段要采取哪些行动，我们如何最快速地识别问题并将问题上报给相关团队？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们如何委派责任，确保团队之间无摩擦的沟通和协作？这包括手头任务和操作的完全透明度，以及进度的实时更新。每种警报和事件的任务的规范顺序是什么？&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;一旦我们弄清楚了上述所有内容，我们就可以开始考虑如何自动化和协调这些事件，并尽可能接近传说中的“自我修复”系统。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;mpcpc js_editor_cpcad=&quot;&quot; class=&quot;js_cpc_area cpc_iframe&quot; data-category_id_list=&quot;1|11|16|17|22|24|26|27|28|29|3|31|32|35|36|37|39|41|42|43|45|46|47|48|49|5|50|51|52|53|54|55|6|7|8&quot; data-id=&quot;1629435627598&quot; src=&quot;/cgi-bin/readtemplate?t=tmpl/cpc_tmpl#1629435627598&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这一步的特点是通过不断将系统推向极限，从而创建更具弹性和适应变化的系统的工具。例如：&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Chaos Engineering: &lt;code&gt;Gremlin&lt;/code&gt;、&lt;code&gt;Chaos Monkey&lt;/code&gt;、&lt;code&gt;ChaosIQ&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;Auto Remediation：&lt;code&gt;Shoreline&lt;/code&gt;、&lt;code&gt;OpsGenie&lt;/code&gt;&lt;span/&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;4&lt;/span&gt;&lt;/span&gt;&lt;span&gt;一步都不能少&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们相信，通过以上三步的结合，可以将故障排除与监控、可观察性、跟踪等区别开来。然而，可能最重要的是深入到系统和流程中，以防止它们再次发生。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们都见过这个表情包：&lt;img data-backh=&quot;359&quot; data-backw=&quot;480&quot; data-ratio=&quot;0.7479166666666667&quot; data-type=&quot;jpeg&quot; data-w=&quot;480&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/lPwvgkMwLNhInLHAhibqQKx2Z7UaVBTBQy5XTcovHh0b528vsxV5gMyDQfATxJ9cOt3ibolCgFuR0Hn6oc6eONMQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;或者这个：&lt;img data-backh=&quot;264&quot; data-backw=&quot;558&quot; data-ratio=&quot;0.4736196319018405&quot; data-type=&quot;jpeg&quot; data-w=&quot;1630&quot; title=&quot;&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/lPwvgkMwLNhInLHAhibqQKx2Z7UaVBTBQb7hLtjOtTYuuwJicnpSvETrB8x6Ue7ia4WLlb4zcFYt7wymn5anJdia2Q/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;它们仍然被广泛使用并如此受欢迎的原因是，即使我们在“DevOps 工具”方面取得了巨大进步后，对于实时的问题或故障，很多时候依然捉襟见肘。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;因此，我建议将应用程序和运维数据集中到一个平台中，使团队成员能够真正了解他们的系统，并最终了解对复杂系统出现的警报如何采取行动。当我们将最好的开发人员和运维人员结合在一起时，我们可以通过更好地合作来更快地解决故障。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;译文链接🔗: &lt;span&gt;https://dzone.com/articles/the-three-pillars-of-kubernetes-troubleshooting&lt;/span&gt;&lt;sup&gt;[2]&lt;/sup&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;原文链接🔗: &lt;span&gt;https://www.kubernetes.org.cn/9578.html&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;Kubernetes部署故障排除指南: &lt;em&gt;https://learnk8s.io/troubleshooting-deployments&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;[2]&lt;/span&gt;&lt;p&gt;译文链接🔗: &lt;em&gt;https://dzone.com/articles/the-three-pillars-of-kubernetes-troubleshooting&lt;/em&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;本文转载自：「云原生生态圈」，原文：https://tinyurl.com/4t62bkb4，版权归原作者所有。欢迎投稿，投稿邮箱: editor@hi-linux.com。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;__bg_gif&quot; data-ratio=&quot;1&quot; data-type=&quot;gif&quot; data-w=&quot;55&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/V3ll7FMyGyMqQC7JRNgVZlsiaJibSyp27USlRia194K6Nqfvz8Wblg7HDceOn4Y3MekppS14lazRZTKLdt2BHuYGA/640?wx_fmt=gif&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.19718309859154928&quot; data-type=&quot;png&quot; data-w=&quot;71&quot; data-width=&quot;100%&quot; title=&quot;&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/V3ll7FMyGyMSBQlhpwK0j3jOS5icKmFncGJdY8kL5kY6AswDpOBsz06GFowoDicL2dC2fr9haibnrwNdZ7rJLXqUA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;你可能还喜欢&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;点击下方图片即可阅读&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247498567&amp;amp;idx=1&amp;amp;sn=39ea59afc3687948ba2dfef25a140979&amp;amp;chksm=eac6da6eddb153789b47876a43c45f87fe846ab9ffa2c6409e04f224b3a395d6c44c3f4aa40f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img data-ratio=&quot;0.5555555555555556&quot; data-type=&quot;png&quot; data-w=&quot;900&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8ZFzrRjqatolyWENiaBj4v1BfkRF82KCnAZ5neC5tp6RZLbkJ3N8BZzwWniao5He1mA0dic4SJhGibhp9nnachRc0A/640?wx_fmt=png&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;6 张图带你搞懂 CI/CD 流水线&lt;br/&gt;&lt;br/&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&amp;amp;mid=2247497936&amp;amp;idx=1&amp;amp;sn=ec9442c73de91c5ab35dbd21dfbedcbd&amp;amp;chksm=eac6d9f9ddb150ef9fc91129ab2b34d35ffef884a726fd90bc1fe9d4014456d910b3baa73afc&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img data-ratio=&quot;0.5496957403651116&quot; data-type=&quot;png&quot; data-w=&quot;986&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8ZFzrRjqatp9P1fjdJcxb1j9gtuoFvu5tYF73myE4ZCLLUzO34rxQ1jruOX4XN3bpqWJWyZ47Mfh7UhvIOJwDA/640?wx_fmt=png&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;点击上方图片，『美团|饿了么』外卖红包天天免费领&lt;br/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-ratio=&quot;0.5555555555555556&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;900&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8ZFzrRjqatpX5KlSvhARyBhcqYmvglSE9zMfzA8CSgNIibAiaFFNHBoXujK9vo2655gRWM5RibLzzF6jPhk4CuYAg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;更多有趣的互联网新鲜事，关注「奇妙的互联网」视频号全了解！&lt;/span&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>fb302b30cdc0db22aa07231bf6287638</guid>
<title>海量Node.js网关的架构设计与工程实践！</title>
<link>https://toutiao.io/k/xfbz3fp</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-backh=&quot;58&quot; data-backw=&quot;578&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.1&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/VY8SELNGe977Xa5zfy5iaV3agpS11Cqm4psjPOibic6BZSicnBFh6uWzCFp3uqN5R114Fq85DmuCzdL3eESlQ37bFA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;导语 |&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span/&gt;&lt;span&gt;本文由InfoQ整理自腾讯云CloudBase前端负责人王伟嘉在GMTC全球大前端技术大会（深圳站）2021上的演讲《十亿级Node.js网关的架构设计与工程实践》。&lt;/span&gt;&lt;/p&gt;&lt;p data-lines=&quot;1&quot; data-type=&quot;p&quot; data-sign=&quot;b070cd070045fb49ccb297c3b5ec3cac&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大家好，我今天的演讲主题主要是讲我们业务上用Node.js写的一个网关。先做个简单的自我介绍，我叫王伟嘉，现在是腾讯云云开发CloudBase的前端负责人，说CloudBase可能很多人不太知道，但是我们旗下其实有挺多产品的，可能或多或少听说过，比如说微信云开发（原小程序·云开发），写小程序的同学应该会知道吧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;今天开门见山地讲一讲&lt;/span&gt;&lt;span&gt;&lt;strong&gt;网关是一个怎么样的组件，网关在做什么事情&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。网关这个词其实到处都在用，它可以工作在一个硬件的层面，可以工作在网络层，也可以工作在应用层。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;一、网关快速入门&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;（一）网关在做什么？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们今天讲的实际上是一个工作在HTTP七层协议的网关，它主要做的有几件事情：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一，公网入口。它作为我们公有云服务的一个入口，可以把公有云过来的请求定向到用户的资源上面去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，对接后端资源。我们云开发有很多内部的资源，像云函数、容器引擎这样的资源，便可以把请求对接到这样的云资源上面去。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，身份鉴权。云开发有自己的一套账号身份体系，请求里如果是带有身份信息的，那么网关会对身份进行鉴权。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以网关这个东西听起来好像是很底层的一个组件，大家可能会觉得很复杂，实际上并没有。我们就花几行代码，就可以实现一个非常简单的HTTP网关的逻辑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;typescript&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;import&lt;/span&gt; express &lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;express&#x27;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;import&lt;/span&gt; { requestUpstream, resolveUpstream } &lt;span class=&quot;code-snippet__keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;./upstream&#x27;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;const&lt;/span&gt; app = express()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;app.all(&lt;span class=&quot;code-snippet__string&quot;&gt;&#x27;*&#x27;&lt;/span&gt;, &lt;span class=&quot;code-snippet__function&quot;&gt;(&lt;span class=&quot;code-snippet__params&quot;&gt;req, res&lt;/span&gt;) =&amp;gt;&lt;/span&gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__built_in&quot;&gt;console&lt;/span&gt;.log(req.method, req.path, req.headers)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;const&lt;/span&gt; upstream = &lt;span class=&quot;code-snippet__keyword&quot;&gt;await&lt;/span&gt; resolveUpstream(req.method, req.path, req.headers)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;const&lt;/span&gt; response = &lt;span class=&quot;code-snippet__keyword&quot;&gt;await&lt;/span&gt; requestUpstream(upstream, req.body)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__built_in&quot;&gt;console&lt;/span&gt;.log(response.statusCode, response.headers)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    res.send(response)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;})&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__keyword&quot;&gt;const&lt;/span&gt; port = &lt;span class=&quot;code-snippet__number&quot;&gt;3000&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;app.listen(port, &lt;span class=&quot;code-snippet__function&quot;&gt;&lt;span class=&quot;code-snippet__params&quot;&gt;()&lt;/span&gt; =&amp;gt;&lt;/span&gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;code-snippet__string&quot;&gt;`App listening at &lt;span class=&quot;code-snippet__subst&quot;&gt;${port}&lt;/span&gt;`&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;})&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这段示例代码在做的事情很简单，即我们收到一个请求之后，会根据请求的方法或者路径进行解析，找出它的上游是什么，然后再去请求上游，这样就完成一个网关的逻辑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然这是最简的一个代码了，实际上里面有很多东西是没有考虑到的，比如技术框架以及内部架构模块的治理，比如性能优化、海量的日志系统、高可用保障、DevOps等等。当然这样展开就非常大了，所以我今天也不会面面俱到，会选其中几个方向来讲的比较深一点，这样我觉得会对大家比较有收获。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;（二）云开发CloudBase（TCB）是个啥？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说到这个，顺便介绍一下我们云开发CloudBase是什么，要介绍我们网关肯定要知道我们业务，像小程序·云开发、Web应用托管、微搭低代码平台，还有微信云托管这样的服务都是在我们体系内的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.412962962962963&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXkxYyNEneXFG9mBzQ5ibxdfkZYSXibRW5ajCnICOjV5aQERCOSew0nkKQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些服务它的资源都会过我们的网关来进行鉴权，你可以在云开发体系下的控制台上，看到我们URL的入口，实际上这些URL它的背后就是我们的网关。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5453703703703704&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXvXZKoUYtnbOAlHoGJhIUtQRPdiaZCznJaYu78EKjOGxHz0n7wUicscOw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;整个网关最简版的一个架构如上图所示，我们会给用户免费提供一个公网的默认域名，这个域名它背后实际上是一套CDN的分发网络，然后CDN回源到核心网关上面来。我们网关本身是无状态的服务，收到请求之后，它需要知道如何把请求分发到后端的云资源上去，所以有一个旁路的后端服务可以读取这样一套数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网关的后面就是用户自己的云上资源了，你在云开发用到任何资源几乎都可以通过这样的链路来进行访问。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5388888888888889&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMX5EPCz2bibica4CTcj6ictsKkxzorfUSwKibu6tNAVIIibnALdibMibhiaraa4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网关内部是基于Nest.js来做的，选Nest.js是因为它本身自带一套设计模式，很Spring那一套，更多的是做IOC容器这一套设计模式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从上图可以看到，我们把它的内部架构分成了两层，一层是Controller，一层是Service。Controller主要是控制各种访问资源的逻辑。比如说你去访问一个云函数（SCF），和你去访问一个静态托管的资源，它所需要的访问信息肯定是不一样的，所以这也就是分成了几种Controller来实现。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;底层的话Service这一层是非常“厚”的，Service内部又分成逻辑模块和功能性模块。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先第一大块是我们的逻辑模块，逻辑模块主要是处理我们内部服务模块的很多东西，最上面这一层主要就是处理跟资源访问相关的一些请求的逻辑，跟各种资源使用不同的协议、方法来对接。然后中间这一层，更多的是做我们内部的一些集群的逻辑。比如集群管理，作为一个公有云的服务，我们对于客户也是会分等级的，像VIP客户可能就需要最后来发布，我们肯定是先验证一些灰度的流量，像这块逻辑就属于中间这一层来管理。最下面这一层就会有各种负责I/O的Client，我这一次只画了一个HTTP的Client，实际上还会有一些别的Client。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;除此之外还有一些旁路的功能性模块，包括像怎么打日志、配置、本地缓存的管理、错误处理，还有本地配置管理DNS、调用链追踪等这些旁路的服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这一套设计其实就是老生常谈的高内聚低耦合，业务逻辑和真正的I/O实现要解耦开。因为只有解耦开，你才能够针对你的业务逻辑进行单元化的测试，可以很方便的把它底层的这种I/O读写逻辑给Mook起来，保证核心业务逻辑模块的可测试性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5333333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMX1icEqzhlQkE95yOMiaVzJ7ocS5ibJYj48AsnzxeUbw7r0JEJgRgwlnhbQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图是网关整体的链路架构，稍微更全面一点。最上层是分布在边缘的CDN节点，然后这些CDN节点会回源到我们部署在各地的集群，然后这些集群它又可以访问后面不同区域的资源，因为公有云它的资源其实也是按区域来划分的，所以这就讲到了&lt;/span&gt;&lt;span&gt;我们网关的&lt;/span&gt;&lt;span&gt;&lt;strong&gt;两个核心的要求，“快”和“稳”&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先作为一个网关肯定是要快的，因为网关作为CloudBase云函数、云托管、静态资源的公网出口，性能要求极高，需要承接C端流量，应对各种地域、各种设备的终端接入场景。如果说过你网关这一层就可能就花了几百毫秒甚至一两秒钟的时间，对于客户来讲是不可接受的。因为客户他自己的一个函数可能只跑了20毫秒，如果网关也引入20毫秒的延迟，对于客户来讲他就觉得你这条链路不行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次就是要稳，我们是大租户模式，要扛住海量的C端请求，我们需要极高的可用性。作为数据面的核心组件，需要极高的可用性，任何故障将会直接影响下游客户的业务稳定性。如果在座的有四川或者云南的同学，你回家每次打开健康码扫码，其实请求都会经过我这个网关的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以今天主要就讲两个部分，既然是快和稳，分别对应&lt;/span&gt;&lt;span&gt;&lt;strong&gt;性能优化&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;和&lt;/span&gt;&lt;span&gt;&lt;strong&gt;可用性&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，所以我现在从性能优化开始讲起。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;二、性能优化&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;网关性能优化思路&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;性能优化的思路，首先是看时间都花在哪个地方了，网关是一个网络的组件，大部分时间都是耗在I/O上，而不是本身的计算，所以它是一个高I/O、低计算的一个组件。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;网关有几个技术特点：首先，它的自身业务逻辑多，是重I/O、轻计算的一个组件；其次它的请求模式是比较固定的，模式固定我们可以理解为，你的一个客户他发送过来的请求实际上就是那么几种，它的路径、包体大小、请求头等这些都是比较趋向于固定的，很难会有一个客户他的请求是完全随机生成的，这对我们后面针对这种情况做缓存设计会有一些帮助。最后，网关的核心链路很长，涉及到多个网络平面。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么我们就找到了我们的一些优化方向：减少整个IO的消耗，并且优化核心链路。所以优化部分我就分成了两块内容来讲，第一块是网关自身核心服务优化，第二块是整体架构链路优化。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;（一）核心服务性能优化&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一部分，核心的服务怎么做优化？先提几个方向。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一，网关自身的业务逻辑很多，调用很多外部服务，其中有一些是不需要同步阻塞调用的，因此我们会把部分业务逻辑做异步化，让到后台去异步运行。比如说自定义域名来源的请求，我们要先确定这个域名是不是合法绑定的，这里的校验就会放到后台异步来进行，网关只是读取校验的结果。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，网关类似代理，转发请求响应体，这里我们使用了流式的传输方式。其实Node原生的HTTP模块里，HTTP Body已经是一个流对象（Stream），并不需要额外的引入类似body-parser这样的组件把Stream转成一个JavaScript对象。为此我们在网关的设计上就尽量避免把请求相关的元数据放到Body里，于是网关就可以只解析请求头，而不解析用户的请求体，原封不动地流式转给后端就可以了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，我们请求后端资源的时候，改用长连接，减少短连接带来的握手消耗。像Nginx这样的组件，它通常都是短连接的模式，因为我们这些业务情况比较特殊一点，是一个大租户的模式，类似于所有用户共用同个Nginx，那么你再启用短连接模式的话，就会有一个TCP TIME_WAIT的问题，下面会详细讨论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我们的请求模式比较固定，我们会针对实际情况设计一些比较合理的缓存的机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，为什么短连接会有问题？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们去请求用户资源的时候，网关所在的网络平面是内部服务的平面，但是每个用户的公有云资源实际上是另一个网络平面。那么这两个网络平面之间是需要通过一个穿透网关来通信的。这个穿透网关可以理解为是一种网络层虚拟设备，或者你可以理解为它就是一个四层转发的Nginx，作为代理客户端，单个实例可以最大承载6.5W的TCP的连接数。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果做过一些传输层协议的同学应该会知道，一个TCP连接断开之后，客户端会进入一个TIME_WAIT的阶段，然后在Linux内核里面它会等待两倍的时间，默认是60秒，两倍是120秒，120秒之后才会释放这个连接，也就是说在120秒内，客户端的端口实际上都是处于被占用的状态的。所以我们很容易能算出来单个传统网关它能够承载的最大的额定QPS大概就是不到600的样子，这个肯定是不能满足用户需求的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么我们怎么去解决短连接TIME_WAIT这个问题？其实有好几种方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一种是修改Linux的TCP传输层的内核参数，去启用重用、快速回收等机制。但对于我们的服务来说并不合适，这需要定制这样一个系统内核，维护成本会非常高。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二种，云上类似的组件怎么解决？比如腾讯内部的负载均衡，其实很简单，就是直接扩张集群内的VM数量。比如一台反向代理服务器加上TIME_WAIT快速回收，可以承载5000多QPS，但想要二十万QPS怎么办，做40个虚拟实例就行了。但这种做法，一是需要内核定制，二是需要我们付出很大的虚拟实例成本，就没有选择这种经典方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后一种就是我们改成长连接的机制，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;类似Nginx的Upstream Keepalive&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;这样的机制。改成这样一个机制之后，其实效果还挺好的，单个穿透网关就可以最大承载6.5W个连接数，相当于几乎6.5W个并发。对于同一个目标IP PORT，它可以直接复用连接，所以它穿透网关的连接数限制就不再是瓶颈了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么是不是长连接就是完美的？其实并不是。长连接会导致另外一个问题，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;竞态问题（keep-alive race condition）&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;，如果在座里有用HTTP长连接的方式做RPC调用的同学，应该经常会看到这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;客户端与服务端成功建立了长连接连接静默一段时间（无HTTP请求）服务端因为在一段时间内没有收到任何数据，主动关闭了TCP连接客户端在收到 TCP关闭的信息前，发送了一个新的HTTP请求服务端收到请求后拒绝，客户端报错ECONNRESET。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;所以怎么解决？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一种方案，就是把客户端的keep-alive超时时间设置得短一些（短于服务端即可）。这样就可以保证永远是客户端这边超时关闭的TCP连接，消除了错误的暂态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但这样在实际生产环境中是没法100%解决问题的，因为无论把客户端超时时间如何设置到多少，因为网络延迟的存在，始终无法保证所有的服务端的 keep-alive超时时间都长于客户端的值；如果把客户端超时时间设置得太小（比如1秒），又失去了意义。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么正确方法就是用短连接去重新试一次。遇到这个错误，并且它是长连接的，那么你就用短连接来发起一次重试。这个也是参考了Chrome的做法，Chromium自己的内核里面处理了这样一种情况，浏览器里它其实这种长连接也是时刻存在的，下图是一段它自己里面的内核的代码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXdDv5UbZTBvYrBtkPcPuOaf4CiaYC8HZ7UQDGuLrA8vMLeLiaf4T4GodA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;2019年的时候，社区里常用的agentkeepalive不支持识别当前请求是否开启keepalive，我们给社区提交过一个PR，支持了这个特性。也就说你只要使用了agentkeepalive这样一个包，就可以写一段代码来识别出这种情况，并且进行重试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.2898148148148148&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMX48VIq6wIjIWB0y4s7887xSkBA3LBuvPJtFQVJEWNlafQlKUnibGibYdg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是我们一个日常统计的量，大概万分之1.3的概率，会命中这样一个竞态的情况。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;小结&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;缓存在后台设计里是个万金油，“哪里慢了抹哪里”，但是如何设计缓存其实也是一门学问。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前面提到我们的请求模式都是非常固定的，我们可以根据请求模式来决定缓存数据。缓存都是些什么东西呢？是路由配置，像域名配置、环境信息、临时密钥等这些信息。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这些数据有哪些特点？首先是活跃数据占比小，这确实也是现状。假设我们全量的用户里面每天只有大概5%~10%的用户才是活跃的，这个数据才是真的会经过你的网关。其次是模式比较固定。第三是对实时性的要求不高。比如说变更了路由之后，客户通常是能够接受有1~3分钟不定的延迟的，并不要求说变更了路由之后就即刻生效。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因此我们可以针对以上这些特点来设计缓存。第一是因为我们的活跃数据占比很小，所以我们是缓存局部数据，从来不会缓存全量的数据。第二是我们会选取域名、环境这种几乎是固定的信息作为缓存Key，这样缓存的覆盖面就可以得到保证。第三是读时缓存要大于写时缓存，这个后续会提到为什么会选用读时缓存，而不是写入数据的时候把缓存推到我们的网关里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7126213592233009&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXjZwK5uycEo2pL9KLsRhbJPQDDqBzPqsx5oBJ24OUM47ibwjXh34viaJg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1030&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最早的时候，实际上我们是有一个最简单的设计，就是加了一个非常简单的本地缓存，它可能就是以域名或以路径作为缓存的Key，这样实现简单但有很多局限性：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，要写大量这样的代码，要去先读本地有没有缓存，有缓存就缓存，没缓存去后台要数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，因为网关不是一个单独的实例，它不是一个单进程的Node，单进程的 Node是扛不了这么多量的，我们是有很多很多实例，大概是有几千核，也就是说有几千个Node进程，如果这些进程它本身都有一份自己独有的内存，也就导致它这个缓存没有办法在所有实例上生效。因此当我们的网关规模变得越来越大的时候，缓存也就永远都只能出现在局部。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了解决这样的问题，我们加入了Redis中心化的缓存。我们是本地内存+Redis两层缓存，本地内存主要是为了降低Redis负载。当Redis故障的时候也可以降级到本地缓存，这样可以避免缓存击穿问题。Redis作为一个中心化的缓存，使缓存可以在所有实例上生效，也就是说只要请求过了一次网关，Redis缓存就会生效，并且所有的网关实例上都会读到这样一个缓存。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;既然有了缓存，那必然有缓存淘汰的机制，怎么样合理地淘汰你的缓存？这里是用了TTL+LRU两重的机制来保证，针对不同的数据类别，单独设置参数，为什么是TTL+LRU？后面在容灾部分会进行解释。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后就是抽象出数据加载层，它是专门用来封装读操作，包括缓存的管理、请求、刷新、容灾这样一套机制，我们内部会有一个专门模块来处理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;有了Redis之后，我们的缓存是中心化的了，只要你的请求经过了我们之后，你的东西就可以在所有的实例上生效。但是这样会引来另一个问题，因为淘汰机制是TTL的，必然遇到缓存过期。假设是每秒钟都会回头发起一次请求，那么缓存是一定是会过期的，一分钟或两分钟之后你的缓存就过期了，在过期之后的请求一定是不会命中缓存的，这导致了请求毛刺的问题。这对于在持续流量的下游业务上，体现非常明显，下图是我们的一个截图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.3611111111111111&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXmzSISFItvy944PGEibuVMJ0p5XB9ltZ4GDn97R2hLk62e9iacztpQwvA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;可以看到图上有很多毛刺，这些毛刺的尖尖就是它没有命中缓存的时候，为了解决缓存的毛刺问题，我们加入了Refresh-Ahead这样一个机制，就是说每次请求进来的时候，我们首先会去Redis里去读，使用缓存的数据来运行逻辑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5542452830188679&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXribU6WjJo4xGulG5kkQL9tS8R2e0EYibhWhbye9ic2vwLLpgMVv9OOK7Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;848&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;同时我们也会判断，如果缓存剩余TTL小于一定值，它就会即触发异步刷新的逻辑，这时候我们会去请求后端服务，并且把更新鲜一点的数据刷新到Redis里，这就是我们数据加载层内实现Refresh-Ahead机制的大概逻辑。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Refresh-Ahead其实非常简单，字面意义就是说提前去刷新缓存，缓存数据快到TTL了，那么就去提前更新一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.5763747454175152&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXniaB5zs7mxSguxy0Qice2KcAOgaQBicib3KZDJYqJ27kZcic92XHyKCoh1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;982&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;能够这样设计，更多是基于一个先验的逻辑，就是说当下这一刻被访问的数据，大概率在未来的一段时间内会再次被访问。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图是我们加入了Refresh-Ahead之后的一个效果，红色箭头处是上线时间，上线完之后发现毛刺就明显变少了。但是为什么还会有一点毛刺？因为有一些数据它可能真的就是很长的时间，刷新了之后它也依然过期了，依然会产生这样的毛刺。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.33425925925925926&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMX70VIliaDXKuWYJjvZWj5TzybjhibochPtuljEtOUMicAfJwxJUzSuIAdA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后解释一下，为什么我们是网关去后台读数据，而不是后台把数据推给网关？或者说，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;为什么是“拉”而不是“推”&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这其实有几个考量点，第一，因为是数据局部缓存，所以我们全量数据完全推过来体积很大，大概有几十个G，而活跃占比很小，如果完全存在内存里，其实也是一种反模式的做法，不太经济。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，后台能不能只推局部活跃的数据给到网关呢？其实也是不太合适的，后台很难去识别哪些数据是活跃的，哪些数据不是活跃的，这样实现复杂，难度很大。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，网关和它的持久化的后台之间会产生一个缓存Key上的耦合，所谓的 Key上的耦合就是说双方要约定一组Key，我这个数据是在Key上面去读，然后你后台要把数据推到Key上面。那么就会带来另一个问题，一旦Key写错了，或者说出现了一些不可预料的问题，那就会产生一些比较灾难性的后果，所以我们就没有使用“推”这样一种方式。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;小结&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;（二）架构、链路性能优化&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;前面讲的是服务跟服务自己核心的优化，接下来讲一讲架构和链路上的一些性能优化。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.9746835443037974&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXtJbmBOWJTM1TysX6m83yC4G6z14GHMGt1KVrDNdFt09wq22VSUejxA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;790&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图是我们整体的一个架构，可以看到一个请求，它从前面的接入层一直走到后端云资源之间，其实整个链路是很长的，这里分析一下。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先链路很长，涉及边缘节点、核心业务、后端资源。其次网关是承接C端流量的，它其实对终端的性能是很敏感的。第三个就是网络环境复杂，它涉及到数个网络平面的打通。因此我们就有了优化方向，第一个是让链路更快更短。第二个是核心服务Set化，便于多地域铺设，终端用户可以就近接入。第三个就是我们在网络平面之间会做一些针对性的优化，针对性优化怎么做，后面会提。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先先讲一下我们就近接入是怎么做的，在网关最开始上线的时候，其实会存在一个问题，你的CDN节点它其实是通过公网回源的，那为什么是公网回源？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实这涉及到国内这几家大厂的一个网络架构，简单地说就是，诸多的CDN节点中，有部分可能不是腾讯自建的，所处的网络可能不是腾讯的内网，它可能是某个运营商，比如说电信、联通或者网通这样的边缘节点，然后它是要走公网回源到腾讯的入口的，这里的公网回源就非常慢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说广州的节点回源到上海，并且走HTTPS协议，那就是60~100毫秒，但问题在于CDN节点是有很多的，HTTPS握手之后，这个链接还是没有办法复用的，等于说每次请求都要跟源站之间进行一次HTTPS握手，这个延迟是不可接受的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4462962962962963&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXTTwcFhUMibbfA0Z0QeGKNzhtBuaH4vteDnnLmE9zovyvoY13crPhvuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后我们在网关的回源接入点上做了一层就近接入，也就是说你CDN在广州的节点，可以很就近地接入到我们在部署在广州的网关，然后网关内部再进行跨地域的访问，因为这个时候就已经是内网了，速度就会很快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了能更好地铺设网关多地接入点，我们就把网关改造成了地域无感的，即业务逻辑和它所在的地域是解耦的。其次，网关支持跨地域访问后端资源。最后，配置收归统一，所有地域用同样的后端资源配置，减少了我们不同地域的配置发散的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;把这些事情做了之后，网关其实达到了“SET化部署”的概念，降低就近接入成本，任意集群能访问任意地域的后端资源。相当于网关在所有地域的集群，服务能力都是一模一样的。你可以使用任意域名去任意网关访问，获得到结果都是一样，这样SET化部署带来很多好处：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;也就是说全网只要只剩一个地域的网关可用，我们的服务就可以正常的运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;接下来涉及到网络平面之间的部署，刚才提到了我们在访问用户的资源的时候，其实会经过一个穿透网关，这个是不可避免的，因为它涉及到两个网络平面的打通，在穿透网关的这一条链路也是可以优化的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以看一个数据，就是像这种穿透网关和我们云上的资源，它通常是部署在不同的机房的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.8061224489795918&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXYzfFb0WQxkIEUnvicibawLXshib7KJYwXYwjcVtTHp8BuyjL44EmPhJYQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;784&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;举个例子，像图上的上海二区，它实际上是在上海的花桥机房，穿透网关因为它是网络层提供的设备，它会部署在上海六区。查一下地理位置可以看到，二区到六区之间其实相隔了可能有七八十公里，后端资源是在上海三区的，宝信。在地理位置上讲，它整个请求就经过了下图这样一段链路。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.8972222222222223&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXxl6m139WRbhqn7lmryRoeVaHJLa5IDRfX1A8cot841uC5P02QcgbWg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;但实际上这也是完全没有必要的，我们可以将网关和穿透网关部署在同样一个区域，这样就会极大降低从网关到后端资源这样的一个延迟。当然这个事情我们正在慢慢地铺设中，现在还在验证可行性的阶段，我们设想是这样来做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.21944444444444444&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXH7zgc8bXbNYPRlVfHhjK5zDn5g7cvfwc3icLRxxcCt3DdJiaRyXicl2DA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后来看效果，我们总体的缓存命中率大概有99.98%。你可以自己部署一个很简单的服务到我们的平台上，然后跑一下测速，你会发现全国其实都是绿的，这个也是我们觉得做的还不错的一个证明。网关自身的耗时，其实99% 的请求都会在14毫秒内被处理完毕。当然你说平均值能不能进一步降低，我觉得是可以的。但是你再进一步降低的话，可能就涉及到Node.js本身事件驱动模型这样一个调度的问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;小结&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;三、高可用保障&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;讲完性能优化，最后一个部分就是可用性保障，那么我们通常的服务怎么来做可用性保障？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;不要出事故&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。服务的健壮性，你本身服务要足够的健壮，这里有很多机制，包括灰度发布、热更新、流量管理、限流、熔断、防缓存击穿，还有缓存容灾、特性开关、柔性降级……这些东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;出事故了能感知到&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。事故永远是不可避免的，每天都会发生乱七八糟的各种事故，出了事故的时候你是要能够感知到，并且能够让你的系统自修复，或者说你自己人员上来修复。这就涉及到监控告警系统，还有像外部的拨测，用户反馈监控，社群里面的一些监控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;能立刻修复事故&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。出了事故的时候，能够有机制去立刻修复，比如快速扩容，当然最好的是整个系统它能够自愈。比如说有个节点它出问题了，你的系统可以自动剔除它，但如果做不到的话，你可以去做一些人工介入的故障隔离，还有多实例灾备切换、逻辑降级等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5268518518518519&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMX2l9c11dLtGKBmrkFTzMd6Dt4uKicicPBA0Ua4cbc7QPuUic14juTTb1pA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;上图是我们网关整体的架构，哪些地方容易出现问题？其实每一层都会出问题，所以每一层其实都要相应的去做容灾，比如CDN到CLB这一层，CLB是不是有多个实例的灾备？像CLB到网关这一层，是不是网关也是有同样的多实例，还有一些监控的指标。当然这个篇幅就非常大了，所以我今天只讲我们最核心业务层的容灾。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;核心业务层&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;先讲讲我们核心业务层面临的一些&lt;/span&gt;&lt;span&gt;&lt;strong&gt;挑战&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;：&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;（一）核心业务层：应对大流量冲击&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那我们怎么样去应对一个大流量的冲击？实际上对于一个系统来讲，它其实是非常具有破坏性的，它有可能直接把你的缓存还有你的DB击穿，导致你的DB直接就夯住了，CPU被打满。下图是我们一次真实的例子，我也不是很排斥说出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6509259259259259&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXnWZ2k1P4mOby7M2zAzQA5qtL6hlPicVibS96PgibPTiaxOwibJWSvmHsCRA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是我们今年年初1月份的时候，有一个客户他的流量突然翻了100多倍，你可以看到图上它的量就突然提升，这造成一个什么问题？它的缓存都是冷的，也就是说访问量突然提升100倍，这100倍的请求，可能都要去后台读它的一些数据，导致直接把后台数据库的CPU打满了，也导致这个灾难进一步扩散，扩散到到所有用户的数据都读不出来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;后来我们就反思了一下这个是不是有问题的？对，是有问题。我们要做什么事情来防止这样的问题出现的？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;大流量来了，你自己本身要能扛得住，这个时候要去提升你整个服务快速扩容的能力。我们的网关实际上当时已经是完全容器化的，所以这一点还好，它可以快速做到横向扩容，瞬间扩出几百核几千核的资源，可以在几分钟之内完成。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，我们是使用了单POD多Node进程，就是我们1个POD会带有8核，每个核心跑一个进程。这个在Kubernetes里面实际上是一个反模式，因为Kubernetes要求POD要尽量得小，然后里面就只跑Node一个进程。但在工程实践的时候，我们发现这样跑虽然没有问题，但是它扩容速度非常慢，因为每次实例扩出来，都是批量的。比如说我们内部的容器系统，只能说一次扩 100个实例，也就是说一批也就扩100核，并且这100核都要分配内部的虚拟 IP，可能会导致内部的IP池被耗尽了。最后我们做了合并，起码一个POD能扩出8核的资源出来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，除了提升自己抗冲击的能力以外，还要保证你的后端，保护好你后面的服务。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;比如说我们要保证服务的健壮性，在大量冲击的时候不会被打垮。首先单个实例会做一个限频限流，防止雪崩，流量限频是说你一个实例最多可能只能承载 1000QPS的流量，再多你这个实例就直接放弃掉，就不请求了，这样可以防止你的整个后台雪崩，不至于说一个POD崩了，然后其他POD请求又更多，把其他POD全部带崩。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，我们要做DB的旁路化，网关它读的永远是缓存，缓存里面读不到，那就是读不到，它永远不会直接把请求请求到DB里面去。当有数据写入或者说数据变更的时候，后台同学会先落DB，然后再把DB的数据推送到缓存里面，大概就是下图这样一个逻辑，防止缓存击穿问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;1.1548821548821548&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXhqOM0KqhJU3r6dshIjeAPpeKn8N4xOeryNZrsbiaP2MuDAnEwzmOppA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;594&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，服务降级机制。假设真的出现问题了，比如说你缓存也出问题了，我们可以做一些服务的降级。它可能有一些功能没有了，比如说有些特殊的HTTP请求，响应头可能没有了，但是它不会干扰你的主干逻辑，这个也是可以做的。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;（二）核心业务层：应对外部事故&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本身服务构建状态是没有用的，依赖的外部组件服务也一定会出问题，而且它们的可用性说不定远远比你想象的要低，那要怎么做？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们内部是有一套集群控制系统的，我们内部分成了主机群、VIP集群和灰度集群这三个集群。每次发布的时候永远是会先发灰度集群，验证一段时间之后才会全让到其他集群上。这样的集群隔离也给我们带来另一个好处，一旦其中有一个集群出现了问题，比如说灰度集群的DB挂了，或者DB被写满了等其他的事故，我们可以很快速地把流量切换到主机群和VIP集群上面去，这得益于我们内部其实有一套集群管理的快速切换机制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，做容灾缓存，假设依赖的服务全挂，服务自动启用容灾缓存，使用旧数据保证基本的可用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;年初我们有一次这样的事故，整个机房停电，机房就相当于消失了，导致后台服务全部都没有了，这种情况怎么做？这时候就只能是启用缓存容灾。我们网关本地的缓存是永远不会主动清除的，因为你使用旧数据也比直接报错要好，这时候我们就会使用一个旧数据来保证它的可用性。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这个怎么理解呢？我们网关内部的数据它永远不会被清理，它只会说通过LRU的形式被清理掉，比如说我的内存里有可能会有很老的数据，昨天或者前天的数据，但是你在灾难发生的时候，即使是昨天还是前天数据它依然是有用的，它依然可以拿出来保证你最基本的可用性，下面是我们一个逻辑图，大家可以了解。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7805555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXx1ZPtR0ojhvEqQ0ERoGvG4XYiaYDRBEOSwAamysdrPZyGCt0ibu0Y99A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;你的服务有可能会降级，我刚提到我们网关有鉴权的功能，鉴权功能其实依赖我们腾讯内部的一个组件。这样一个组件，它其实也是不稳定的，有时候会出问题，那么遇到这种问题怎么办？鉴权都没有办法鉴权了。这个时候我们在一些场景允许的情况下，会直接把鉴权的逻辑给跳过，我们不鉴权了，先放过一段时间，总比说我直接拒绝掉，直接报错这个请求要好得多。&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;（三）核心业务层：网关自身灾备、异地多活&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后一点就是我刚刚提到的，因为我们网关做了服务SET化改造、部署后，天然获得了跨AZ、跨地域热切换的能力。简单来讲，只要全网还剩一个网关可用区，业务流量就可以切换，网关的服务就不会宕机，当然切换现在还没有做到完全自动化，因为涉及到跨地域的切换，这个是需要人工介入的，不过说实话我们还没有遇到过这么大的灾难。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;做个小结，我们做了多集群切换、缓存容灾、柔性降级这些事情之后可以达到怎样一个效果：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;（四）核心业务层：还有什么能做的？&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们还有什么能做的？如果某天，容器平台全网故障，怎么办？其实也是我们现在构思的一个东西，我们是不是可以做到一个异构部署这样一个形态。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.4648148148148148&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMXMrQG65NVk1yL0icCEL3r0F6U5QF3iam56jM3I2omib3GHIcF790Zm3vEw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;服务异构部署，即使容器平台全地域全可用区故障，也能切换到基于虚拟机的架构上，这也是我们正在筹划的一个事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后说完了容灾，接下来说怎么做监控告警？做监控告警其实比较老生常谈了，但是也可以在这里稍微扫个盲，我们的所有网关，它会把自己所有的访问日志推送到我们的ES（elasticsearch）的集群上，然后我们会有一个专门的TCB Alarm这样一个模块，它会去定期的轮询这样的日志，去检查这些日志里面有没有一些异常，比如说某个用户的流量突然高了，或者某个错误码突然增多，它会把这样的信息通过电话或者企业微信推送给我们。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;因为是基于ES的，所以监控可以做得非常精细，甚至可以做到感知到某个接口，今天的耗时比昨天要高超过50%，那这个接口是不是今天做什么变更让它变慢了？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们也可以做针对下游重点客户、业务的一些监控，比如说几个省的健康码，都可以做重点的监控。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt;四、总结&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其实我只是选取了整个Node服务里面非常小的两个切面来讲，性能优化和高可用保障。可能很难覆盖到很全面，但是我想讲的稍微深一点，能够让大家有些足够的益处。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，服务核心优化这里讲了长连接和缓存机制，可能是大部分服务或多或少都会遇到的问题。然后，链路架构优化这里讲了就近接入和Set化部署这样一个机制。高可用保障我主要是介绍了核心业务层的一些高可用保障，包括应对大流量冲击，怎么做缓存容灾，柔性降级，多可用区、多地域切换，监控告警这些东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后我想就演讲做一个总结。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第一，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;Node.js服务与其它后台服务并无二致，遵循同一套方法论&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;Node.js服务本质上也是做后台开发的，与其它后台服务并无二致，遵循同一套方法论。&lt;/span&gt;&lt;span&gt;我今天的演讲如果把&lt;/span&gt;&lt;span&gt;Node.js&lt;/span&gt;&lt;span&gt;改成Golang改成Java，我就不站在这里了，可能我就去Golang的会上讲，实际上是一样的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第二，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;Node.js足以承载核心大规模服务，无须妄自菲薄&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;我们这套网关其实也现网验证两年了，它跟别的技术栈的这种后台服务来讲，其实并没有太大的缺点。&lt;/span&gt;&lt;span&gt;所以大家在拿Node.js做这种海量服务的时候，可以不用觉得Node.js好像只是个前端的小玩具，好像不是很适合这种成熟的业务，成熟业务是不是还是用Java来写，拿 C++来写，其实是没有必要的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;当然，如果你真的需要对你的IO调度非常精细的时候，那么你可能得选用C++或者Rust，这样可以直接调度IO的方案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;第三，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;前端处在技术的十字路口，不应自我局限于“Web前端”领域&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后一个也是我今天想提的，可能我讲这么多，大家觉得我不是一个前端工程师对不对？&lt;/span&gt;&lt;span&gt;但实际上我在公司内部的职级确实是个前端工程师。&lt;/span&gt;&lt;span&gt;我一直觉得前端它是站在一个技术的十字路口的，所以大家工作中也好，还是学习中也好，不用把自己局限在“Web前端”这样一个领域。&lt;/span&gt;&lt;span&gt;这次GMTC大会也可以看到，前端现在也不只是大家传统意义上的可能就是写页面这样一个领域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.9627039627039627&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMX7xwgvcWYpAibaWQjk3FaZ0k2ib8DiaYtr9Sxm63YCpOicPdrFwFU6gmLiaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;858&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;这是一个当年乔布斯演讲用的一个图，他说苹果是站在技术和人文的十字路口，实际上前端也是站在很多技术的十字路口上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;那么我的演讲就到此结束，谢谢大家。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt; 作者简介&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-cropselx1=&quot;0&quot; data-cropselx2=&quot;105&quot; data-cropsely1=&quot;0&quot; data-cropsely2=&quot;107&quot; data-fileid=&quot;100044396&quot; data-ratio=&quot;0.9991452991452991&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96QbA3hXBbAicODvLFURJhMX02TgGic3wibz27frmdXVwHEUFmic2oyn8UvJzRWXUflHbb8WsP3cW8e9g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1170&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;王伟嘉&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span/&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;腾讯前端开发工程师&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;腾讯前端开发工程师，毕业于复旦大学，现任腾讯云CloudBase前端负责人，Node.js Core Collaborator，腾讯TC39代表。目前在腾讯云CloudBase团队负责微信云开发（原小程序·云开发）、Webify 等公有云产品的核心设计和研发，服务了下游数十万开发者和用户，对Node.js服务架构、全栈开发、云原生开发、Serverless有较丰富的经验，先后在阿里D2、GMTC、腾讯TWeb等大会上发表过技术演讲。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot; data-mpa-template=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section mpa-from-tpl=&quot;t&quot; powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;strong mpa-from-tpl=&quot;t&quot; mpa-is-content=&quot;t&quot;&gt; 推荐阅读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247533957&amp;amp;idx=1&amp;amp;sn=1172a92b809048b4b29cd8a87a056750&amp;amp;chksm=eaa85fd5dddfd6c3801d17fb3188791c0a519be1a2716041285e9ca831e435933fbb69b5121c&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Monorepo——探秘源码管理新姿势！&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;&lt;span&gt;Monorepo——探秘源码管理新姿势！&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247533915&amp;amp;idx=1&amp;amp;sn=b1d0b3ac591b1ecc7aee75116d7bf88f&amp;amp;chksm=eaa85f0bdddfd61d65cfbe5ef352828a923008ca777392bff1b7aa4315d67a545a0244e26425&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;Golang高质量单测之Table-Driven：从入门到真香！&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot;&gt;&lt;span&gt;Golang高质量单测之Table-Driven：从入门到真香！&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247533847&amp;amp;idx=1&amp;amp;sn=69ac21c681a685d470aac7b042e0178f&amp;amp;chksm=eaa85f47dddfd651d00e4ef21fee02ea37355fda33e88578c84ac15d416975f5d025e284dcbe&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;10分钟搞懂！消息队列选型全方位对比&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot;&gt;&lt;span&gt;10分钟搞懂！消息队列选型全方位对比&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247533707&amp;amp;idx=1&amp;amp;sn=f903e542f42b2052cb944cd0c756fe28&amp;amp;chksm=eaa85edbdddfd7cdc6edd083457cf260f76acc487c4e1f100e51054a628aae55635531721194&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;在线教程！C++如何在云应用中快速实现编译优化？&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;在线教程！C++如何在云应用中快速实现编译优化？&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzI2NDU4OTExOQ==&amp;amp;mid=2247533590&amp;amp;idx=1&amp;amp;sn=eb944494505046a17777528559589a7c&amp;amp;chksm=eaa85e46dddfd7504c03107a963ecf6a7e80f1d43961589261e6d62b1bd0539c681e348957c5&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;CGO让Go与C手牵手，打破双方“壁垒”！&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; wah-hotarea=&quot;click&quot; hasload=&quot;1&quot;&gt;&lt;span&gt;CGO让Go与C手牵手，打破双方“壁垒”！&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzI2NDU4OTExOQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe96FK2eEg86vUicOR3n6kAHk1PHvTb8VBicYk0RmNQYsQyibgg8iaZqT0bCEU9VKo3Z3iceoQfgycyMpKWQ/0?wx_fmt=png&quot; data-nickname=&quot;云加社区&quot; data-alias=&quot;QcloudCommunity&quot; data-signature=&quot;腾讯云官方社区公众号，汇聚技术开发者群体，分享技术干货，打造技术影响力交流社区。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.59375&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/VY8SELNGe977Xa5zfy5iaV3agpS11Cqm4xV7ckfbmtFLyUjFID2k7yO4q8hvB4OqYoNkARZ2xuvzKvMtnmVN2BQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;640&quot;/&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>