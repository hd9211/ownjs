<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>1caa30ebfd7f8b3a492dd697916734b9</guid>
<title>Java无垃圾稳态设计</title>
<link>https://toutiao.io/k/ly1kfiv</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;最近在重构&lt;/span&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzNjAxODg4MQ==&amp;amp;mid=2247484045&amp;amp;idx=2&amp;amp;sn=25cf3c0399cf92edbd57e207f18afea3&amp;amp;chksm=fafde823cd8a61354d12e2355829b78b0a84b422ec4d3569bbbff711cb9b1cb3315eafaef9ac&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;《简明日志规范》&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot; hasload=&quot;1&quot; wah-hotarea=&quot;click&quot;&gt;《简明日志规范》&lt;/a&gt;&lt;span&gt;，就是重构我自己之前开源的一个统一日志的组件。对于打印日志，最重要的我认为有两点：第一点是异步，不能因为打印日志而影响正常的程序执行，导致等待IO卡顿；第二点是尽量减少垃圾，&lt;span&gt;所谓垃圾是说&lt;/span&gt;&lt;span&gt;许多日志库在日志记录期间分配临时对象，如日志事件对象，字符串，字符数组，字节数组等。这会对垃圾收集器造成压力并增加GC暂停发生的频率。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span/&gt;其中，异步设计已经是很成熟的领域了。&lt;/span&gt;但是低垃圾、无垃圾的研究还比较少。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzNjAxODg4MQ==&amp;amp;mid=2247486299&amp;amp;idx=1&amp;amp;sn=34ea00ad39901a51331bfd95dee0c641&amp;amp;chksm=fafde1f5cd8a68e31c7b8d5fa5b21fc70f5e49663f4cd6e6ea0a0639696556bc197b97ea241b&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;《应用程序怎样划分模块？》&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;《应用程序怎样划分模块？》&lt;/a&gt;里我提到使用登高类比法进行业界调研。业界调研自然不会放过Log4j、Logback这些都广泛认可的优秀日志组件。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Log4j2从版本2.6开始，默认情况下以“无垃圾”模式运行。&lt;/span&gt;&lt;span&gt;无垃&lt;/span&gt;圾原理就是&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzNjAxODg4MQ==&amp;amp;mid=2247486339&amp;amp;idx=1&amp;amp;sn=ca9b6a4ba1a98a9182b7ff9e81a7e7ea&amp;amp;chksm=fafde12dcd8a683b385853e053fb7444ef3772f09d39c977c1a69581e4ff294a45e8ab8fd53b&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;《ThreadLocal&amp;amp;MDC内存泄漏问题》&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;《ThreadLocal&amp;amp;MDC内存泄漏问题》&lt;/a&gt;中介绍的ThreadLocal。&lt;span&gt;因为&lt;/span&gt;&lt;span&gt;重用对象和缓冲区，并且尽可能不分配临时对象。从物理层面上，对象的内存区域是通过数据覆盖，而不是垃圾回收来达到日志读写和上下文信息保存的目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以下是官网对无垃圾记录响应时间行为进行的试验：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1/&gt;&lt;p&gt;下图将 Log4j 的异步 Logger 的“经典”记录与无垃圾记录响应时间行为进行了比较。在图中，“ 100k”表示以 100,000 消息/秒的持续负载进行记录，“ 800k”表示 800,000 消息/秒的持续负载。&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.6&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2tk5ianItRl8YTHlRBJKRc4TjDgKxu4dID6miansD3hOFLlr2C9B6EvibFWLaEnCMsJ4HGPRKZGtkpN0Zu2X4cZcA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;800&quot;/&gt;&lt;/p&gt;&lt;p&gt;在“经典”模式下，我们看到大量次要垃圾回收，这些垃圾回收会使应用程序线程暂停 3 毫秒或更长时间。这很快就增加了将近 10 毫秒的响应时间延迟。如您在图表中所见，增加负载将曲线向左移动(存在更多尖峰)。这是有道理的：更多的日志记录意味着对垃圾收集器施加更大的压力，从而导致更小的 GC 暂停。我们做了一些实验，将负载减少到 50,000 甚至 5000 条消息/秒，但这并没有消除 3 毫秒的暂停，只是使它们的发生频率降低了。请注意，此测试中的所有 GC 暂停都是次要的 GC 暂停。我们没有看到任何完整的垃圾回收。&lt;/p&gt;&lt;p&gt;在“无垃圾”模式下，在各种负载下，最大响应时间仍远低于 1 毫秒。(最大 780 us，800,000 消息/秒，最大 407 us，600,000 消息/秒，其中 99％围绕 5 us 达到 800,000 消息/秒的所有负载.)增加或减少负载不会改变响应时间。我们没有调查在这些测试中看到的 200-300 微秒暂停的原因。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当我们进一步增加负载时，我们开始看到经典和无垃圾记录的响应时间都有较大的暂停。在 100 万条消息/秒或更多的持续负载下，我们开始接近底层 RandomAccessFile Appender 的最大吞吐量(请参见下面的同步日志记录吞吐量图表)。在这些负载下，环形缓冲区开始填满，反压开始起作用：在环形缓冲区已满时尝试添加另一条消息将阻塞，直到有可用插槽可用为止。我们开始看到响应时间为数十毫秒或更长；尝试进一步增加负载会导致越来越大的响应时间峰值。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;试验可以看出无垃圾模式对性能提升上有极大的好处。那如果是自制结构化日志组件怎么实现无垃圾模式呢？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我自己做的简明日志组件是为了公司的结构化日志做抽象而产生。我将结构化日志要打印的列定义为一个对象LogBuilder。属性就是日志要输出的内容。这样大家就可以用面向对象的方式来组装日志对象了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;LogBuilder的变量有三种情况：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第一种是全局变量，比如机房信息，服务启动时机房就固定不变了。这种变量可以定义为静态变量，全局唯一，不会被垃圾回收器处理。&lt;/p&gt;&lt;p&gt;class LogBuilder {&lt;/p&gt;&lt;p&gt;    private static String idc; &lt;/p&gt;&lt;p&gt;    static {&lt;/p&gt;&lt;p&gt;         idc = 从配置文件等处读取并初始化；&lt;/p&gt;&lt;p&gt;    }&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第二种是线程唯一，比如线程追踪号，这种信息可以通过切面在请求入口处设置一次保存到MDC中，使用时从MDC中取得，&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzUzNjAxODg4MQ==&amp;amp;mid=2247486339&amp;amp;idx=1&amp;amp;sn=ca9b6a4ba1a98a9182b7ff9e81a7e7ea&amp;amp;chksm=fafde12dcd8a683b385853e053fb7444ef3772f09d39c977c1a69581e4ff294a45e8ab8fd53b&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;《ThreadLocal&amp;amp;MDC内存泄漏问题》&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;《ThreadLocal&amp;amp;MDC内存泄漏问题》&lt;/a&gt;中有介绍，MDC相对安全无内存泄漏风险。MDC由于跟着线程走，线程采用线程池时它可以被复写无需垃圾回收。&lt;/p&gt;&lt;p&gt;class LogBuilder {&lt;/p&gt;&lt;p&gt;    private static String traceId; &lt;/p&gt;&lt;p&gt;    &lt;/p&gt;&lt;p&gt;    public void static setTraceId(String traceId) {&lt;/p&gt;&lt;p&gt;         MDC.set(&quot;traceId&quot;, traceId);&lt;/p&gt;&lt;p&gt;    }&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第三种是线程内变化的，比如执行阶段，这种对象只能跟着LogBuilder的实例对象走，中间可以被重新赋值并打印。这时候就需要把整个LogBuilder对象放到ThreadLocal中，让它也跟着对象实例走。但是这里面有个关键，就是对象的toString方法被调用后这个打印的string就会被回收。所以我们打印日志时组装的字符串最好不用toString，而是新写一个方法来生成并将结果保存到LogBuilder的局部变量中。这样打印完成对象就不会被回收。而是在下次使用时被复写。&lt;/p&gt;&lt;p&gt;@Data&lt;/p&gt;&lt;p&gt;class LogBuilder {&lt;/p&gt;&lt;p&gt;    private static ThreadLocal threadLocal = new ThreadLocal();&lt;/p&gt;&lt;p&gt;    private static String idc; &lt;/p&gt;&lt;p&gt;    private static String traceId; &lt;/p&gt;&lt;p&gt;    private String step; &lt;/p&gt;&lt;p&gt;    private String toString;&lt;/p&gt;&lt;p&gt;    &lt;/p&gt;&lt;p&gt;    public static LogBuilder getInstance() {&lt;/p&gt;&lt;p&gt;          if(threadLocal.get()==null) {&lt;/p&gt;&lt;p&gt;            threadLocal.set(new LogBuilder());&lt;/p&gt;&lt;p&gt;          }&lt;br/&gt;          return threadLocal.get();&lt;/p&gt;&lt;p&gt;    }&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;    public String buildString() {&lt;/p&gt;&lt;p&gt;       toString = idc+&quot;|&quot;+traceId+&quot;|&quot;+step;&lt;/p&gt;&lt;p&gt;    }&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当然这里只是为了说明无垃圾写的示例代码，实际上的实现使用了一些反射等技术，代码很精简，通用性强。实际原理和Log4j2的无垃圾稳态原理一致。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;总结和小技巧&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;LogBuilder对象最初我的设计是使用静态工厂方法new出来的。这也是《有效的Java》推荐的方式，可以很好的进行实例控制，保持清晰性和简洁性。后来加入了ThreadLocal来进行无垃圾稳态设计。这时要注意提供clear方法清空属性值，因为和主题无关，我在代码中省略了这一部分。关键来了，性能提升了，内存使用减少了怎么来测试验证呢？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我使用了jol工具来监控内存情况，使用方法，先上maven坐标：&lt;/p&gt;&lt;pre&gt;&amp;lt;dependency&amp;gt;&lt;br/&gt;    &amp;lt;groupId&amp;gt;org.openjdk.jol&amp;lt;/groupId&amp;gt;&lt;br/&gt;    &amp;lt;artifactId&amp;gt;jol-core&amp;lt;/artifactId&amp;gt;&lt;br/&gt;    &amp;lt;version&amp;gt;0.14&amp;lt;/version&amp;gt;&lt;br/&gt;&amp;lt;/dependency&amp;gt;&lt;/pre&gt;&lt;p&gt;代码中使用时&lt;/p&gt;&lt;pre&gt;&lt;span&gt;log&lt;/span&gt;.info(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;内部信息：&lt;/span&gt;&lt;span&gt;[{}]&quot;&lt;/span&gt;, ClassLayout.&lt;span&gt;parseInstance&lt;/span&gt;(pojo).toPrintable());&lt;br/&gt;&lt;span&gt;log&lt;/span&gt;.info(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;外部信息&lt;/span&gt;&lt;span&gt;[{}]&quot;&lt;/span&gt;, GraphLayout.&lt;span&gt;parseInstance&lt;/span&gt;(pojo).toPrintable());&lt;br/&gt;&lt;span&gt;log&lt;/span&gt;.info(&lt;span&gt;&quot;totalSize[{}]&quot;&lt;/span&gt;, GraphLayout.&lt;span&gt;parseInstance&lt;/span&gt;(pojo).totalSize());&lt;/pre&gt;&lt;p&gt;其中pojo是自己要监控的对象，有空不妨试一试。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不要假定，要证明！-----《程序员修炼之道》&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>fd8c0844bee20cecab258bb572eb5ca0</guid>
<title>技术干货｜缓存一致性最佳实践</title>
<link>https://toutiao.io/k/zgmi04u</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4382826&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74ACnsfKcnFDT8Uf8XcCHKTbbFu7n3GktsBgczeVd0RHngWc5I6Wvf01FzUtDwQibTQEpYeZSM64W8Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;559&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;背景 &lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;概述&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;最近团队里我们在密集的讨论Redis缓存一致性相关的问题，电商核心的域如商品、营销、库存、订单等实际上在缓存的选择上各有特色，那么在这些差异的业务背后，我们有没有一些最佳实践可供参考呢？&lt;/p&gt;&lt;p&gt;本文尝试着来讨论这个问题，并给出一些建议。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在讨论之前，有两个重点我们需要达成一致：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;分布式场景下无法做到强一致&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;不同于CPU硬件缓存体系采用的MESI协议以及硬件的强时钟控制，分布式场景下我们无法做到缓存与底层数据库的强一致，即把缓存和数据库的数据变更做成一个原子操作。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;硬件工程师设计了内存屏障（Memory Barrier）的概念，提供给软件开发者不同的一致性选项在性能与一致性上进行权衡。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;就算是达到最终一致性也很难&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;分布式场景下，要做到最终一致性，就要求缓存中存储的是最新版本的数据（或者缓存为空），而且是在数据库更新后很迅速的就要达到这个一致性的状态，要做到是极其困难的。&lt;/p&gt;&lt;p&gt;我们会面临硬件、软件、通信等等组件非常多的异常情况。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5409836&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74ACnsfKcnFDT8Uf8XcCHKTbvSxeCUz3xV2YIUErVqjzgbHHKuhWXsU0JyWT3jfkpKJPI1Z14xiatxA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;976&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;CPU的缓存结构&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;缓存的一致性问题&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;一般化来说，我们面临的是这样的一个问题，如下图所示，数据库的数据会有5次更新，产生6个版本，V1~V6，图中每个方框的长度代表这个版本持续的时间。&lt;/p&gt;&lt;p&gt;我们期望，在数据库中的数据变化后，缓存层需要尽快的感知到并作出反应，如下图所示，缓存层方框中的间隔代表这个时间段缓存数据不存在，V2、V3以及V5版本在缓存中不存在并不会破坏我们的最终一致性要求，只要数据库的最终版本和缓存的最终版本是相同的就可以了。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.2796296&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74ACnsfKcnFDT8Uf8XcCHKTbpcFMVGBvhuLoH4m6rYIj8yhttcP7lbiaonk7s2MgEjNyQmj9zOCXE1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;缓存是如何写入的&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;缓存写入的代码通常情况下都是和缓存使用的代码放在一起的，包含4个步骤，如下图所示：W1读取缓存，W2判断缓存是否存在，W3组装缓存数据（这通常需要向数据库进行查询），W4写入缓存。&lt;/p&gt;&lt;p&gt;每一个步骤间可能会停顿多久是没有办法控制的，尤其是W3、W4之间的停顿最为要命，它很可能让我们将旧版本的数据写入到缓存中。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;我们可能会想，W4步的写入，带上W2的假设，即使用WriteIfNotExists语义，会不会有所改善？&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.3916667&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74ACnsfKcnFDT8Uf8XcCHKTb20FjhyT48qhUfho2h4bwblJcIsFVibcSh0dgWLCqB0hicJ8EDgk8VUyw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;考虑如下的情形，假设有3个缓存写入的并发执行，由于短时间数据库大量的更新，它们分别组装的是V1、V2、V3版本的数据。&lt;/p&gt;&lt;p&gt;使用WriteIfNotExists语义，其中必然有2个执行会失败，哪一个会成功根本无法保证。&lt;/p&gt;&lt;p&gt;我们无法简单的做决策，需要再次将缓存读取出来，然后判断是否我们即将写入的一样，如果一样那就很简单；如果不一样的话，我们有两种选择：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;将缓存删除，让后续别的请求来处理写入。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;使用缓存提供的原子操作，仅在我们的数据是较新版本时写入。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.27833&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74ACnsfKcnFDT8Uf8XcCHKTbxFk3v9PuJ3VBXYmdBKGOcvrMXAyRjrqiaXlId1X7Q849lA9Gbon5dpg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1006&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;如何感知数据库的变化&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;数据库的数据发生变化后，我们如何感知到并进行有效的缓存管理呢？&lt;/p&gt;&lt;p&gt;通常情况下有如下的3种做法：&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;使用代码执行流&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;通常我们会在数据库操作完成后，执行一些缓存操作的代码。&lt;/p&gt;&lt;p&gt;这种方式最大的问题是可靠性不高，应用重启、机器意外当机等情况都会导致后续的代码无法执行。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;使用事务消息&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;作为使用代码执行流的改进，在数据库操作完成后发出事务消息，然后在消息的消费逻辑里执行缓存的管理操作。&lt;/p&gt;&lt;p&gt;可靠性的问题就解决了，只是业务侧要为此增加事务消息的逻辑，以及运行成本。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;使用数据变更日志&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;数据库产品通常都支持在数据变更后产生变更日志，比如MySQL的binlog。&lt;/p&gt;&lt;p&gt;可以让中间件团队写一款产品，在接收到变更后执行缓存的管理操作，比如阿里的精卫。&lt;/p&gt;&lt;p&gt;可靠性有保证，同时还可以进行某个时间段变更日志的回放，功能就比较强大了。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;最佳实践一：数据库变更后失效缓存&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;这是最常用和简单的方式，应该被作为首选的方案，整体的执行逻辑如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5731481&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74ACnsfKcnFDT8Uf8XcCHKTbuFnDYpEbhQKFJQVPGlOAZaJibTSPEQ0ag8mIn1J78yhhBfdYOlLhBibA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;W4步使用最基本的put语义，这里的假设是写入较晚的请求往往也是携带的最新的数据，这在大多的情形下都是成立的。&lt;/p&gt;&lt;p&gt;D1步使用监听DB binlog的方式来删除缓存，即前述使用数据变更日志中介绍的方法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;这个方案的缺点是&lt;/strong&gt;：在数据库数据存在高并发更新且缓存读取流量较大的情况下，会有小概率存在缓存中存储的是旧版本数据的情况。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通常的解法有四种：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;限制缓存有效时间&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;设定缓存的过期时间，比如15分钟。即表示我们最多接受缓存在15分钟的时间范围内是旧的。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;小概率缓存重加载&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;根据流量比设定一定比例的缓存重加载，以保证大流量情况下的缓存数据的一致性。&lt;/p&gt;&lt;p&gt;比如1%的比例，这同时还可以帮助数据库得到充分的预热。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;结合业务特点&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;根据业务的特点做一些设计，比如：&lt;/p&gt;&lt;/li&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;针对营销的场景&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;在商品详情页/确认订单页的优惠计算时使用缓存，而在下单时不使用缓存。&lt;/p&gt;&lt;p&gt;这可以让极端情况发生时，不产生过大的业务损失。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;针对库存的场景&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;读取到旧版本的数据只是会在商品已售罄的情况下让多余的流量进入到下单而已，下单时的库存扣减是操作数据库的，所以不会有业务上的损失。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;两次删除&lt;/strong&gt;：&lt;/p&gt;&lt;p&gt;D1步删除缓存的操作执行两次，且中间有一定的间隔，比如30秒。&lt;/p&gt;&lt;p&gt;这两次动作的触发都是由“缓存管理组件”发起的，所以可以由它支持。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;最佳实践二：带版本写入&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;针对象商品信息缓存这种更新频率低、数据一致性要求较高且缓存读取流量很高的场景，通常会采用带版本更新的方式，整体的执行逻辑如下图如示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6055556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/AAQtmjCc74ACnsfKcnFDT8Uf8XcCHKTblN4aNHDMTub6GiboN4tIj5MlIj1sSpEiamGf0A9Pu2VBmPRF9fjxcayA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;和“数据库变更后失效缓存”方案最大的差异在W4步和D1步，需要缓存层提供带版本写入的API，即仅当写入数据版本较新时可以写入成功，否则写入失败。&lt;/p&gt;&lt;p&gt;这同时也要求我们在数据库增加数据版本的信息。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这个方案的最终一致性效果比较好，仅在极端情况下（新版本写入后数据丢失了，后续旧版本的写入就会成功）存在缓存中存储的是旧版本数据的可能。&lt;/p&gt;&lt;p&gt;在D1步使用写入而不是使用删除可以极大程度的避免这个极端情况的出现，同时由于该方案适用于缓存读取流量很高的场景，还可以避免缓存被删除后W3步短时间大量请求穿透到DB。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;总结与展望&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;对于缓存与数据库分离的场景，在结合了业界多家公司的实践经验以及ROI权衡之后，前述的两个最佳实践是被应用的最为广泛的，尤其是最佳实践一，应该作为我们日常应用的首选。&lt;/p&gt;&lt;p&gt;同时，为了最大限度的避免每个最佳实践背后可能发生的不一致性问题，我们还需要切合业务的特点，在关键的场景上做一些保障一致性的设计（比如前述的营销在下单时使用数据库读而不是缓存读），这也显得尤为重要（毕竟如“背景”中所述，并不存在完美的技术方案）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;除了缓存与数据库分离的方案，还有两个业界已经应用的方案也值得我们借鉴：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;阿里XKV&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;简单来讲就是在数据库上部署一个Memcache的Server，它直接绕过数据库层直接访问存储引擎层（如：InnoDB），同时使用KV client来进行数据的访问。&lt;/p&gt;&lt;p&gt;它的特点是数据实际上与数据库是强一致的，性能可以比使用SQL访问数据库提升5～10倍。&lt;/p&gt;&lt;p&gt;缺点也很明显，只能通过主键或者唯一键来访问数据（这只是相对SQL来说的，大多数缓存本来也就是KV访问协议）。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;腾讯DCache&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;不用自行维护缓存与数据库两套存储，给开发人员统一的一套数据视图，由DCache在缓存更新后自行持久化数据。&lt;/p&gt;&lt;p&gt;缺点是支持的数据结构有限（ key-value，k-k-row，list，set，zset ），未来也很难支持形如数据库表一样复杂的数据结构。&lt;span/&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>e31cf957d8b89d5f30073ca19e705e5e</guid>
<title>面试官问: 说一说ReentrantReadWriteLock的实现原理与锁获取过程</title>
<link>https://toutiao.io/k/001uotl</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;preview&quot;&gt;&lt;h2&gt;一.面试题分析&lt;/h2&gt;

&lt;p&gt;在有些业务场景中，我们大多在读取数据，很少写入数据，这种情况下，如果仍使用独占锁，效率将及其低下。针对这种情况，Java提供了读写锁——ReentrantReadWriteLock有点类似MySQL数据库为代表的读写分离机制，既然我们知道了读写锁是用于读多写少的场景。那问题来了，ReentrantReadWriteLock是怎样来实现的呢，它与ReentrantLock的实现又有什么的区别呢？&lt;/p&gt;

&lt;h2&gt;二.ReentrantReadWriteLock简介&lt;/h2&gt;

&lt;p&gt;很多情况下有这样一种场景：对共享资源有读和写的操作，且写操作没有读操作那么频繁。&lt;/p&gt;

&lt;p&gt;在没有写操作的时候，多个线程同时读一个资源没有任何问题，所以应该允许多个线程同时读取共享资源，但是如果一个线程想去写这些共享资源，就不应该允许其他线程对该资源进行读和写的操作了。&lt;/p&gt;

&lt;p&gt;针对这种场景，JAVA的并发包提供了读写锁ReentrantReadWriteLock，它表示两个锁，一个是读操作相关的锁，称为共享锁；一个是写相关的锁，称为排他锁。&lt;/p&gt;

&lt;h2&gt;三.ReentrantReadWriteLock特性&lt;/h2&gt;

&lt;p&gt;公平性：读写锁支持非公平和公平的锁获取方式，非公平锁的吞吐量优于公平锁的吞吐量，默认构造的是非公平锁&lt;/p&gt;

&lt;p&gt;可重入：在线程获取读锁之后能够再次获取读锁，但是不能获取写锁，而线程在获取写锁之后能够再次获取写锁，同时也能获取读锁&lt;/p&gt;

&lt;p&gt;锁降级：线程获取写锁之后获取读锁，再释放写锁，这样实现了写锁变为读锁，也叫锁降级&lt;/p&gt;

&lt;h2&gt;四.ReentrantReadWriteLock的主要成员和结构图&lt;/h2&gt;

&lt;h3&gt;1. ReentrantReadWriteLock的继承关系&lt;/h3&gt;

&lt;p&gt;读写锁 ReadWriteLock&lt;/p&gt;

&lt;p&gt;读写锁维护了一对相关的锁，一个用于只读操作，一个用于写入操作。&lt;/p&gt;

&lt;p&gt;只要没有写入，读取锁可以由多个读线程同时保持,写入锁是独占的。&lt;/p&gt;

&lt;h3&gt;2.ReentrantReadWriteLock的核心变量&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://storage.bytearch.com/images/reentranrwl/1.jpeg&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt;public interface ReadWriteLock {
   /**
   * Returns the lock used for reading.
   *
   * @return the lock used for reading.
   */
   Lock readLock();
   /**
   * Returns the lock used for writing.
   *
   * @return the lock used for writing.
   */
   Lock writeLock();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;ReentrantReadWriteLock类包含三个核心变量：&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;ReaderLock：读锁,实现了Lock接口&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;WriterLock：写锁,也实现了Lock接口&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Sync：继承自AbstractQueuedSynchronize(AQS),可以为公平锁FairSync 或 非公平锁NonfairSync&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;3.ReentrantReadWriteLock的成员变量和构造函数&lt;/h3&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt; /**
     * 内部提供的读锁
     */
    private final ReentrantReadWriteLock.ReadLock readerLock;
    /**
     * 内部提供的写锁
     */
    private final ReentrantReadWriteLock.WriteLock writerLock;
    /**
     * AQS来实现的同步器
     */
    final Sync sync;

    /*** Creates a new {@code ReentrantReadWriteLock} with * 默认创建非公平的读写锁 */
    public ReentrantReadWriteLock() {
        this(false);
    }

    /*** Creates a new {@code ReentrantReadWriteLock} with * the given fairness policy. ** @param fair {@code true} if this lock should use a fair ordering policy */
    public ReentrantReadWriteLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
        readerLock = new ReadLock(this);
        writerLock = new WriteLock(this);
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;五.ReentrantReadWriteLock的核心实现&lt;/h2&gt;

&lt;h3&gt;ReentrantReadWriteLock实现关键点，主要包括：&lt;/h3&gt;

&lt;p&gt;读写状态的设计&lt;/p&gt;

&lt;p&gt;写锁的获取与释放&lt;/p&gt;

&lt;p&gt;读锁的获取与释放&lt;/p&gt;

&lt;p&gt;锁降级&lt;/p&gt;

&lt;h3&gt;1.读写状态的设计&lt;/h3&gt;

&lt;p&gt;之前谈ReentrantLock的时候,Sync类是继承于AQS，主要以int state为线程锁状态,0表示没有被线程占用， 1 表示已经有线程占用。&lt;/p&gt;

&lt;p&gt;同样ReentrantReadWriteLock也是继承于AQS来实现同步，那int state怎样同时来区分读锁和写锁的？&lt;/p&gt;

&lt;p&gt;如果在一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，&lt;/p&gt;

&lt;h3&gt;ReentrantReadWriteLock将int类型的state将变量切割成两部分：&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://storage.bytearch.com/images/reentranrwl/2.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;高 16 位记录读锁状态&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;低 16 位记录写锁状态&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt;abstract static class Sync extends AbstractQueuedSynchronizer {
                // 版本序列号
         private static final long serialVersionUID = 6317671515068378041L;
                // 高 16 位为读锁，低 16 位为写锁
                static final int SHARED_SHIFT = 16 ;
                // 读锁单位
                static final int SHARED_UNIT = ( 1 &amp;lt;&amp;lt; SHARED_SHIFT);
                // 读锁最大数量
                static final int MAX_COUNT = ( 1 &amp;lt;&amp;lt; SHARED_SHIFT) - 1 ;
                // 写锁最大数量
                static final int EXCLUSIVE_MASK = ( 1 &amp;lt;&amp;lt; SHARED_SHIFT) - 1 ;
                // 本地线程计数器
                private transient ThreadLocalHoldCounter readHolds;
                // 缓存的计数器
                private transient HoldCounter cachedHoldCounter;
        // 第一个读线程 
        private transient Thread firstReader = null; 
        // 第一个读线程的计数 
        private transient int firstReaderHoldCount;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;2.写锁的获取与释放&lt;/h3&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt; protected final boolean tryAcquire(int acquires) {
            /*
             * Walkthrough:
             * 1. If read count nonzero or write count nonzero
             *    and owner is a different thread, fail.
             * 2. If count would saturate, fail. (This can only
             *    happen if count is already nonzero.)
             * 3. Otherwise, this thread is eligible for lock if
             *    it is either a reentrant acquire or
             *    queue policy allows it. If so, update state
             *    and set owner.
             */
            Thread current = Thread.currentThread();
            int c = getState();
           //获取独占锁(写锁)的被获取的数量
            int w = exclusiveCount(c);
            if (c != 0) {
                // (Note: if c != 0 and w == 0 then shared count != 0)
              //1.如果同步状态不为0，且写状态为0,则表示当前同步状态被读锁获取
              //2.或者当前拥有写锁的线程不是当前线程
                if (w == 0 || current != getExclusiveOwnerThread())
                    return false;
                if (w + exclusiveCount(acquires) &amp;gt; MAX_COUNT)
                    throw new Error(&quot;Maximum lock count exceeded&quot;);
                // Reentrant acquire
                setState(c + acquires);
                return true;
            }
            if (writerShouldBlock() ||
                !compareAndSetState(c, c + acquires))
                return false;
            setExclusiveOwnerThread(current);
            return true;
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1)c是获取当前锁状态,w是获取写锁的状态。&lt;/p&gt;

&lt;p&gt;2)如果锁状态不为零，而写锁的状态为 0 ，则表示读锁状态不为 0 ，所以当前线程不能获取写锁。或者&lt;/p&gt;

&lt;p&gt;锁状态不为零，而写锁的状态也不为 0 ，但是获取写锁的线程不是当前线程，则当前线程不能获取写锁。&lt;/p&gt;

&lt;p&gt;3)写锁是一个可重入的排它锁，在获取同步状态时，增加了一个读锁是否存在的判断。&lt;/p&gt;

&lt;p&gt;写锁的释放与ReentrantLock的释放过程类似，每次释放将写状态减 1 ，直到写状态为 0 时，才表示该写锁被释放了。&lt;/p&gt;

&lt;h3&gt;3.读锁的获取与释放&lt;/h3&gt;

&lt;pre lang=&quot;java&quot;&gt;&lt;code&gt;
    protected final int tryAcquireShared(int unused) {
        for (; ; ) {
            int c = getState();
            int nextc = c + (1 &amp;lt;&amp;lt; 16);
            if (nextc &amp;lt; c) {
                throw new Error(&quot;Maxumum lock count exceeded&quot;);
            }
            if (exclusiveCount(c) != 0 &amp;amp;&amp;amp; owner != Thread.currentThread()) return -1;
            if (compareAndSetState(c, nextc)) return 1;
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1)读锁是一个支持重进入的共享锁，可以被多个线程同时获取。&lt;/p&gt;

&lt;p&gt;2)在没有写状态为 0 时，读锁总会被成功获取，而所做的也只是增加读状态（线程安全）
3)读状态是所有线程获取读锁次数的总和，而每个线程各自获取读锁的次数只能选择保存在ThreadLocal中，由线程自身维护。读锁的每次释放均减小状态（线程安全的，可能有多个读线程同时释放锁），减小的值是1&amp;lt;&amp;lt; 16 .&lt;/p&gt;

&lt;h3&gt;4. 锁降级&lt;/h3&gt;

&lt;p&gt;降级是指当前把持住写锁，再获取到读锁，随后释放(先前拥有的)写锁的过程。&lt;/p&gt;

&lt;p&gt;锁降级过程中的读锁的获取是否有必要，答案是必要的。主要是为了保证数据的可见性，如果当前线程不获取读锁而直接释放写锁，假设此刻另一个线程获取的写锁，并修改了数据，那么当前线程就步伐感知到线程T的数据更新，如果当前线程遵循锁降级的步骤，那么线程T将会被阻塞，直到当前线程使数据并释放读锁之后，线程T才能获取写锁进行数据更新。&lt;/p&gt;

&lt;h3&gt;5.读锁与写锁的整体流程&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://storage.bytearch.com/images/reentranrwl/3.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;六.ReentrantReadWriteLock总结&lt;/h2&gt;

&lt;p&gt;本篇详细介绍了ReentrantReadWriteLock的特征、实现、锁的获取过程，通过 4 个关键点的核心设计：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;读写状态的设计&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;写锁的获取与释放&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;读锁的获取与释放&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;锁降级&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从而才能实现：共享资源有读和写的操作，且写操作没有读操作那么频繁的应用场景。&lt;/p&gt;

&lt;h2&gt;号外号外&lt;/h2&gt;

&lt;p&gt;给大家整理了Java最新大厂面试题及答案，并且整理成了PDF格式方便阅读。 欢迎大家关注”浅谈架构“ 公众号 (后台私信”面试“即可获取)。另外需要大厂内推同学也可以私信我。 &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://storage.bytearch.com/images/mianshiti.png&quot; alt=&quot;file&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>6727b3603d72053c4b0aa881a60de4d9</guid>
<title>工商银行实时大数据平台建设历程及展望</title>
<link>https://toutiao.io/k/mf1lxng</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;weui-dialog&quot;&gt;
      &lt;p class=&quot;weui-dialog__hd&quot;&gt;&lt;strong class=&quot;weui-dialog__title&quot;&gt;&quot;Top Stories&quot; is disabled&lt;/strong&gt;&lt;/p&gt;
      &lt;p class=&quot;weui-dialog__bd&quot;&gt;
        Enable &quot;Top Stories&quot; in &quot;Settings&quot; &amp;gt; &quot;General&quot; &amp;gt; &quot;Manage Discover&quot;      &lt;/p&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a2fd199ac1f04a0a4690a877dcea66c5</guid>
<title>盘点Linux Epoll那些致命弱点</title>
<link>https://toutiao.io/k/pslbv0b</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;blockquote&gt;&lt;p&gt;微信公众号：&lt;strong&gt;小梁编程汇&lt;/strong&gt;&lt;br/&gt;&lt;strong&gt;点击👆🏻，关注作者&lt;/strong&gt;可了解更多技术干货；&lt;br/&gt;因未开通留言，问题或建议，请私信留言；&lt;/p&gt;&lt;/blockquote&gt;&lt;h3&gt;&lt;span&gt;内容目录&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;1. 引言&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;2. 脉络&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;3 epoll 多线程扩展性&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;3.1特定TCP listen fd的accept(2) 的问题&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.1.1 水平触发的问题：不必要的唤醒&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.1.2 边缘触发的问题：不必要的唤醒以及饥饿&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.1.3 怎样才是正确的做法？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.1.4 其他方案&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;3.2 大量TCP连接的read(2)的问题&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.2.1 水平触发的问题：数据乱序&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.2.2 边缘触发的问题：数据乱序&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;3.2.3 怎样才是正确的做法？&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;3.3 epoll load balance 总结&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;4. epoll之file descriptor与file description&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;4.1 总结&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;5 引用&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;h3&gt;&lt;span&gt;1 引言&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;本文来自 Marek’s 博客中 I/O multiplexing part 系列之三和四，原文一共有四篇，主要讲 Linux 上 IO 多路复用的一些问题，本文加入了我的一些个人理解，如有不对之处敬请指出。原文链接如下：&lt;span/&gt;&lt;/p&gt;&lt;section&gt;The history of the Select(2) syscall &lt;span&gt;[1]&lt;/span&gt;&lt;/section&gt;&lt;section&gt;Select(2) is fundamentally broken &lt;span&gt;[2]&lt;/span&gt;&lt;/section&gt;&lt;section&gt;Epoll is fundamentally broken 1/2 &lt;span&gt;[3]&lt;/span&gt;&lt;/section&gt;&lt;section&gt;Epoll is fundamentally broken 2/2 &lt;span&gt;[4]&lt;/span&gt;&lt;/section&gt;&lt;h3&gt;&lt;span&gt;2 脉络&lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;系列三和系列四分别讲 epoll(2) 存在的两个不同的问题：&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;系列三主要讲 epoll 的多线程扩展性的问题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;系列四主要讲 epoll 所注册的 fd (file descriptor) 和实际内核中控制的结构 file description 拥有不同的生命周期&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;我们在此也按照该顺序进行阐述。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;3 epoll 多线程扩展性&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;epoll 的多线程扩展性的问题主要体现在做多核之间负载均衡上，有两个典型的场景：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;一个 TCP 服务器，对同一个 listen fd 在多个 CPU 上调用 &lt;code&gt;accept(2)&lt;/code&gt; 系统调用&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;大量 TCP 连接调用 &lt;code&gt;read(2)&lt;/code&gt; 系统调用上&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;span&gt;3.1 特定 TCP listen fd 的 accept(2) 的问题&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;一个典型的场景是一个需要处理大量短连接的 HTTP 1.0 服务器，由于需要 accept() 大量的 TCP 建连请求，所以希望把这些 accept() 分发到不同的 CPU 上来处理，以充分利用多 CPU 的能力。&lt;/p&gt;&lt;p&gt;这在实际生产环境是存在的， Tom Herbert 报告有应用需要处理每秒 4 万个建连请求；当有这么多请求的时候，很显然，将其分散到不同的 CPU 上是合理的。&lt;/p&gt;&lt;p&gt;然后实际上，事情并没有这么简单，直到 Linux 4.5 内核，都无法通过 epoll(2) 把这些请求水平扩展到其他 CPU 上。下面我们来看看 epoll 的两种模式 LT(level trigger, 水平触发) 和 ET(edge trigger, 边缘触发) 在处理这种情况下的问题。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;3.1.1 水平触发的问题：不必要的唤醒&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;一个愚蠢的做法是是将同一个 epoll fd 放到不同的线程上来 epoll_wait()，这样做显然行不通，同样，将同一个用于 accept 的 fd 加到不同的线程中的 epoll fd 中也行不通。&lt;/p&gt;&lt;p&gt;这是因为 epoll 的水平触发模式和 &lt;code&gt;select(2)&lt;/code&gt; 一样存在 “惊群效应”，在不加特殊标志的水平触发模式下，当一个新建连接请求过来时，所有的 worker 线程都都会被唤醒，下面是一个这种 case 的例子：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;1&lt;/span&gt;1. 内核：收到一个新建连接的请求&lt;br/&gt;&lt;span&gt;2&lt;/span&gt;2. 内核：由于 &quot;惊群效应&quot; ，唤醒两个正在 epoll_wait() 的线程 A 和线程 B&lt;br/&gt;&lt;span&gt;3&lt;/span&gt;3. 线程A：epoll_wait() 返回&lt;br/&gt;&lt;span&gt;4&lt;/span&gt;4. 线程B：epoll_wait() 返回&lt;br/&gt;&lt;span&gt;5&lt;/span&gt;5. 线程A：执行 accept() 并且成功&lt;br/&gt;&lt;span&gt;6&lt;/span&gt;6. 线程B：执行 accept() 失败，accept() 返回 EAGAIN&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，线程 B 的唤醒完全没有必要，仅仅只是浪费宝贵的 CPU 资源而已，水平触发模式的 epoll 的扩展性很差。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;3.1.2 边缘触发的问题：不必要的唤醒以及饥饿&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;既然水平触发模式不行，那是不是边缘触发模式会更好呢？实际上并没有。我们来看看下面这个例子：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;1&lt;/span&gt;1. 内核：收到第一个连接请求。线程 A 和 线程 B 两个线程都在 epoll_wait() 上等待。由于采用边缘触发模式，所以只有一个线程会收到通知。这里假定线程 A 收到通知&lt;br/&gt;&lt;span&gt;2&lt;/span&gt;2. 线程A：epoll_wait() 返回&lt;br/&gt;&lt;span&gt;3&lt;/span&gt;3. 线程A：调用 accpet() 并且成功&lt;br/&gt;&lt;span&gt;4&lt;/span&gt;4. 内核：此时 accept queue 为空，所以将边缘触发的 socket 的状态从可读置成不可读&lt;br/&gt;&lt;span&gt;5&lt;/span&gt;5. 内核：收到第二个建连请求&lt;br/&gt;&lt;span&gt;6&lt;/span&gt;6. 内核：此时，由于线程 A 还在执行 accept() 处理，只剩下线程 B 在等待 epoll_wait()，于是唤醒线程 B&lt;br/&gt;&lt;span&gt;7&lt;/span&gt;7. 线程A：继续执行 accept() 直到返回 EAGAIN&lt;br/&gt;&lt;span&gt;8&lt;/span&gt;8. 线程B：执行 accept()，并返回 EAGAIN，此时线程 B 可能有点困惑(&quot;明明通知我有事件，结果却返回 EAGAIN&quot;)&lt;br/&gt;&lt;span&gt;9&lt;/span&gt;9. 线程A：再次执行 accept()，这次终于返回 EAGAIN&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到在上面的例子中，线程 B 的唤醒是完全没有必要的。另外，事实上边缘触发模式还存在饥饿的问题，我们来看下面这个例子：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;1&lt;/span&gt;1. 内核：接收到两个建连请求。线程 A 和 线程 B 两个线程都在等在 epoll_wait()。由于采用边缘触发模式，只有一个线程会被唤醒，我们这里假定线程 A 先被唤醒&lt;br/&gt;&lt;span&gt;2&lt;/span&gt;2. 线程A：epoll_wait() 返回&lt;br/&gt;&lt;span&gt;3&lt;/span&gt;3. 线程A：调用 accpet() 并且成功&lt;br/&gt;&lt;span&gt;4&lt;/span&gt;4. 内核：收到第三个建连请求。由于线程 A 还没有处理完(没有返回 EAGAIN)，当前 socket 还处于可读的状态，由于是边缘触发模式，所有不会产生新的事件&lt;br/&gt;&lt;span&gt;5&lt;/span&gt;5. 线程A：继续执行 accept() 希望返回 EAGAIN 再进入 epoll_wait() 等待，然而它又 accept() 成功并处理了一个新连接&lt;br/&gt;&lt;span&gt;6&lt;/span&gt;6. 内核：又收到了第四个建连请求&lt;br/&gt;&lt;span&gt;7&lt;/span&gt;7. 线程A：又继续执行 accept()，结果又返回成功&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在这个例子中个，这个 socket 只有一次从不可读状态变成可读状态，由于 socket 处于边缘触发模式，内核只会唤醒 epoll_wait() 一次。在这个例子中个，所有的建连请求全都会给线程 A，导致这个负载均衡根本没有生效，线程 A 很忙而线程 B 没有活干。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;3.1.3 怎样才是正确的做法？&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;既然水平触发和边缘触发都不行，那怎样才是正确的做法呢？有两种 workaround 的方式:&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;最好的也是唯一支持可扩展的方式是使用从 Linux 4.5+ 开始出现的水平触发模式新增的 &lt;code&gt;EPOLLEXCLUSIVE&lt;/code&gt; 标志，这个标志会保证一个事件只有一个 epoll_wait() 会被唤醒，避免了 “惊群效应”，并且可以在多个 CPU 之间很好的水平扩展。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;当内核不支持&lt;code&gt;EPOLLEXCLUSIVE&lt;/code&gt; 时，可以通过 ET 模式下的 &lt;code&gt;EPOLLONESHOT&lt;/code&gt; 来模拟 LT + &lt;code&gt;EPOLLEXCLUSIVE&lt;/code&gt; 的效果，当然这样是有代价的，需要在每个事件处理完之后额外多调用一次 epoll_ctl(EPOLL_CTL_MOD) 重置这个 fd。这样做可以将负载均分到不同的 CPU 上，但是同一时刻，只能有一个 worker 调用 accept(2)。显然，这样又限制了处理 accept(2) 的吞吐。下面是这样做的例子：&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;内核：接收到两个建连请求。线程 A 和 线程 B 两个线程都在等在 epoll_wait()。由于采用边缘触发模式，只有一个线程会被唤醒，我们这里假定线程 A 先被唤醒&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;线程A：epoll_wait() 返回&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;线程A：调用 accpet() 并且成功&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;线程A：调用 epoll_ctl(EPOLL_CTL_MOD)，这样会重置 EPOLLONESHOT 状态并将这个 socket fd 重新准备好 “&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;&lt;span&gt;3.1.4 其他方案&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;当然，如果不依赖于 epoll() 的话，也还有其他方案。一种方案是使用 &lt;code&gt;SO_REUSEPORT&lt;/code&gt; 这个 socket option，创建多个 listen socket 共用一个端口号，不过这种方案其实也存在问题: 当一个 listen socket fd 被关了，已经被分到这个 listen socket fd 的 accept 队列上的请求会被丢掉，具体可以参考 https://engineeringblog.yelp.com/2015/04/true-zero-downtime-haproxy-reloads.html 和 LWN 上的 comment&lt;span&gt;[5]&lt;/span&gt;&lt;/p&gt;&lt;p&gt;从 Linux 4.5 开始引入了 &lt;code&gt;SO_ATTACH_REUSEPORT_CBPF&lt;/code&gt; 和 &lt;code&gt;SO_ATTACH_REUSEPORT_EBPF&lt;/code&gt; 这两个 BPF 相关的 socket option。通过巧妙的设计，应该可以避免掉建连请求被丢掉的情况。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;3.2 大量 TCP 连接的 read(2) 的问题&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;除了 3.1 中说的 accept(2) 的问题之外， 普通的 read(2) 在多核系统上也会有扩展性的问题。设想以下场景：一个 HTTP 服务器，需要跟大量的 HTTP client 通信，你希望尽快的处理每个客户端的请求。而每个客户端连接的请求的处理时间可能并不一样，有些快有些慢，并且不可预测，因此简单的将这些连接切分到不同的 CPU 上，可能导致平均响应时间变长。一种更好的排队策略可能是：用一个 epoll fd 来管理这些连接并设置 &lt;code&gt;EPOLLEXCLUSIVE&lt;/code&gt;，然后多个 worker 线程来 epoll_wait()，取出就绪的连接并处理[注1]。油管上有个视频介绍这种称之为 “combined queue” 的模型。&lt;/p&gt;&lt;p&gt;下面我们来看看 epoll 处理这种模型下的问题：&lt;/p&gt;&lt;h4&gt;&lt;span&gt;3.2.1 水平触发的问题：数据乱序&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;实际上，由于水平触发存在的 “惊群效应”，我们并不想用该模型。另外，即使加上 &lt;code&gt;EPOLLEXCLUSIVE&lt;/code&gt; 标志，仍然存在数据竞争的情况，我们来看看下面这个例子：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;1&lt;/span&gt;1. 内核：收到 2047 字节的数据&lt;br/&gt;&lt;span&gt;2&lt;/span&gt;2. 内核：线程 A 和线程 B 两个线程都在 epoll_wait()，由于设置了 EPOLLEXCLUSIVE，内核只会唤醒一个线程，假设这里先唤醒线程 A&lt;br/&gt;&lt;span&gt;3&lt;/span&gt;3. 线程A：epoll_wait() 返回&lt;br/&gt;&lt;span&gt;4&lt;/span&gt;4. 内核：内核又收到 2 个字节的数据&lt;br/&gt;&lt;span&gt;5&lt;/span&gt;5. 内核：线程 A 还在干活，当前只有线程 B 在 epoll_wait()，内核唤醒线程 B&lt;br/&gt;&lt;span&gt;6&lt;/span&gt;6. 线程A：调用 read(2048) 并读走 2048 字节数据&lt;br/&gt;&lt;span&gt;7&lt;/span&gt;7. 线程B：调用 read(2048) 并读走剩下的 1 字节数据&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这上述场景中，数据会被分片到两个不同的线程，如果没有锁保护的话，数据可能会存在乱序。&lt;/p&gt;&lt;h4&gt;&lt;span&gt;3.2.2 边缘触发的问题：数据乱序&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;既然水平触发模型不行，那么边缘触发呢？实际上也存在相同的竞争，我们看看下面这个例子：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt; 1&lt;/span&gt;1. 内核：收到 2048 字节的数据&lt;br/&gt;&lt;span&gt; 2&lt;/span&gt;2. 内核：线程 A 和线程 B 两个线程都在 epoll_wait()，由于设置了 EPOLLEXCLUSIVE，内核只会唤醒一个线程，假设这里先唤醒线程 A&lt;br/&gt;&lt;span&gt; 3&lt;/span&gt;3. 线程A：epoll_wait() 返回&lt;br/&gt;&lt;span&gt; 4&lt;/span&gt;4. 线程A：调用 read(2048) 并返回 2048 字节数据&lt;br/&gt;&lt;span&gt; 5&lt;/span&gt;5. 内核：缓冲区数据全部已经读完，又重新将该 fd 挂到 epoll 队列上&lt;br/&gt;&lt;span&gt; 6&lt;/span&gt;6. 内核：收到 1 字节的数据&lt;br/&gt;&lt;span&gt; 7&lt;/span&gt;7. 内核：线程 A 还在干活，当前只有线程 B 在 epoll_wait()，内核唤醒线程 B&lt;br/&gt;&lt;span&gt; 8&lt;/span&gt;8. 线程B：epoll_wait() 返回&lt;br/&gt;&lt;span&gt; 9&lt;/span&gt;9. 线程B：调用 read(2048) 并且只读到了 1 字节数据&lt;br/&gt;&lt;span&gt;10&lt;/span&gt;10. 线程A：再次调用 read(2048)，此时由于内核缓冲区已经没有数据，返回 EAGAIN&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;&lt;span&gt;3.2.3 怎样才是正确的做法？&lt;/span&gt;&lt;/h4&gt;&lt;p&gt;实际上，要保证同一个连接的数据始终落到同一个线程上，在上述 epoll 模型下，唯一的方法就是 epoll_ctl 的时候加上 &lt;code&gt;EPOLLONESHOT&lt;/code&gt; 标志，然后在每次处理完重新把这个 socket fd 加到 epoll 里面去。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;3.3 epoll load balance 总结&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;要正确的用好 epoll(2) 并不容易，要用 epoll 实现负载均衡并且避免数据竞争，必须掌握好 &lt;code&gt;EPOLLONESHOT&lt;/code&gt; 和 &lt;code&gt;EPOLLEXCLUSIVE&lt;/code&gt; 这两个标志。而 &lt;code&gt;EPOLLEXCLUSIVE&lt;/code&gt; 又是个 epoll 后来新加的标志，所以我们可以说 epoll 最初设计时，并没有想着支持这种多线程负载均衡的场景。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;4. epoll 之 file descriptor 与 file description&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;这一章我们主要讨论 epoll 的另一个大问题：file descriptor 与 file description 生命周期不一致的问题。&lt;/p&gt;&lt;p&gt;Foom 在 LWN&lt;span&gt;[6]&lt;/span&gt; 上说道：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;1&lt;/span&gt;显然 epoll 存在巨大的设计缺陷，任何懂得 file descriptor 的人应该都能看得出来。事实上当你回望 epoll 的历史，你会发现当时实现 epoll 的人们显然并不怎么了解 file descriptor 和 file description 的区别。:(&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;实际上，epoll() 的这个问题主要在于它混淆了用户态的 file descriptor (我们平常说的数字 fd) 和内核态中真正用于实现的 file description。当进程调用 close(2) 关闭一个 fd 时，这个问题就会体现出来。&lt;/p&gt;&lt;p&gt;&lt;code&gt;epoll_ctl(EPOLL_CTL_ADD)&lt;/code&gt; 实际上并不是注册一个 file descriptor (fd)，而是将 fd 和 一个指向内核 file description 的指针的对 (tuple) 一块注册给了 epoll，导致问题的根源在于，epoll 里管理的 fd 的生命周期，并不是 fd 本身的，而是内核中相应的 file description 的。&lt;/p&gt;&lt;p&gt;当使用 close(2) 这个系统调用关掉一个 fd 时，如果这个 fd 是内核中 file description 的唯一引用时，内核中的 file description 也会跟着一并被删除，这样是 OK 的；但是当内核中的 file description 还有其他引用时，close 并不会删除这个 file descrption。这样会导致当这个 fd 还没有从 epoll 中挪出就被直接 close 时，epoll() 还会在这个已经 close() 掉了的 fd 上上报事件。&lt;/p&gt;&lt;p&gt;这里以 dup(2) 系统调用为例来展示这个问题：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt; 1&lt;/span&gt;rfd, wfd = pipe()&lt;br/&gt;&lt;span&gt; 2&lt;/span&gt;write(wfd, &quot;a&quot;)             # Make the &quot;rfd&quot; readable&lt;br/&gt;&lt;span&gt; 3&lt;/span&gt;&lt;br/&gt;&lt;span&gt; 4&lt;/span&gt;epfd = epoll_create()&lt;br/&gt;&lt;span&gt; 5&lt;/span&gt;epoll_ctl(efpd, EPOLL_CTL_ADD, rfd, (EPOLLIN, rfd))&lt;br/&gt;&lt;span&gt; 6&lt;/span&gt;&lt;br/&gt;&lt;span&gt; 7&lt;/span&gt;rfd2 = dup(rfd)&lt;br/&gt;&lt;span&gt; 8&lt;/span&gt;close(rfd)&lt;br/&gt;&lt;span&gt; 9&lt;/span&gt;&lt;br/&gt;&lt;span&gt;10&lt;/span&gt;r = epoll_wait(epfd, -1ms)  # What will happen?&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;由于 close(rfd) 关掉了这个 rfd，你可能会认为这个 epoll_wait() 会一直阻塞不返回，而实际上并不是这样。由于调用了 dup()，内核中相应的 file description 仍然还有一个引用计数而没有被删除，所以这个 file descption 的事件仍然会上报给 epoll。因此 &lt;code&gt;epoll_wait()&lt;/code&gt; 会给一个已经不存在的 fd 上报事件。更糟糕的是，一旦你 close() 了这个 fd，再也没有机会把这个死掉的 fd 从 epoll 上摘除了，下面的做法都不行：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;1&lt;/span&gt;epoll_ctl(efpd, EPOLL_CTL_DEL, rfd)&lt;br/&gt;&lt;span&gt;2&lt;/span&gt;epoll_ctl(efpd, EPOLL_CTL_DEL, rfd2)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Marc Lehmann 也提到这个问题：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;1&lt;/span&gt;因此，存在 close 掉了一个 fd，却还一直从这个 fd 上收到 epoll 事件的可能性。并且这种情况一旦发生，不管你做什么都无法恢复了。&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;因此，并不能依赖于 &lt;code&gt;close()&lt;/code&gt; 来做清理工作，一旦调用了 close()，而正好内核里面的 file description 还有引用，这个 epoll fd 就再也修不好了，唯一的做法是把的 epoll fd 给干掉，然后创建一个新的并将之前那些 fd 全部再加到这个新的 epoll fd 上。所以记住这条忠告：&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;span&gt;1&lt;/span&gt;永远记着先在调用 close() 之前，显示的调用 epoll_ctl(EPOLL_CTL_DEL)&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;span&gt;4.1 总结&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;显式的将 fd 从 epoll 上面删掉在调用 &lt;code&gt;close()&lt;/code&gt; 的话可以工作的很好，前提是你对所有的代码都有掌控力。然后在一些场景里并不一直是这样，譬如当写一个封装 epoll 的库，有时你并不能禁止用户调用 close(2) 系统调用。因此，要写一个基于 epoll 的轻量级的抽象层并不是一个轻松的事情。&lt;/p&gt;&lt;p&gt;另外，Illumos 也实现了一套 epoll() 机制，在他们的手册上，明确提到 Linux 上这个 epoll()/close() 的奇怪语义，并且拒绝支持。&lt;/p&gt;&lt;p&gt;希望本所提到的问题对于使用 Linux 上这个糟糕的 epoll() 设计的人有所帮助。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;注1：笔者认为该场景下或许直接用一个 master 线程来做分发，多个 worker 线程做处理 或者采用每个 worker 线程一个自己独立的 epoll fd 可能是更好的方案。&lt;/p&gt;&lt;h3&gt;&lt;span&gt;5 引用&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/h3&gt;&lt;p&gt;&lt;span&gt;[1]https://idea.popcount.org/2016-11-01-a-brief-history-of-select2/&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;[2]https://idea.popcount.org/2017-01-06-select-is-fundamentally-broken/&lt;/span&gt;&lt;/p&gt;&lt;section&gt;&lt;p&gt;[3]https://idea.popcount.org/2017-02-20-epoll-is-fundamentally-broken-12/&lt;/p&gt;&lt;p&gt;[4]https://idea.popcount.org/2017-03-20-epoll-is-fundamentally-broken-22/&lt;/p&gt;&lt;p&gt;[5]https://lwn.net/Articles/542866/&lt;/p&gt;&lt;p&gt;[6]https://lwn.net/Articles/542866/&lt;/p&gt;&lt;p&gt;[7]https://kernel.taobao.org/2019/12/epoll-is-fundamentally-broken/&lt;/p&gt;&lt;p&gt;[8]https://zh.wikipedia.org/wiki/Epoll&lt;/p&gt;&lt;p&gt;&lt;span&gt;[9]https://stackoverflow.com/questions/4058368/what-does-eagain-mean&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;如果觉得本文对你有帮助的话，可以点击👇🏻的 收藏、赞和在看支持一下作者噢&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>