<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>c5116aae50c0c8e406b2d654d289d128</guid>
<title>M*N个策略造成类爆炸怎样重构？</title>
<link>https://toutiao.io/k/ddkgqz5</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;背景&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;收到朋友针对他们遇到的具体问题写一篇文章的邀请，问题是这样的&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;朋友:&lt;/p&gt;&lt;p&gt;我们公司对接了M个三方服务  然后还有N种业务  实现用策略的话感觉有点类爆炸  也想不到什么好方法了  这也是早上刚接到一个重构支付的需求想到的   根据业务和供应商搞了太多策略实现了[晕]&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我:&lt;/p&gt;&lt;p&gt;初步感觉应该用打造接入平台的方式解决&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;朋友:&lt;/p&gt;&lt;p&gt;开始的时候没有考虑到  代码一言难尽了 [捂脸]  谢谢谢老师&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我从对话中分解出下面几个问题&lt;/p&gt;&lt;p&gt;1、理解重构、重写和重新架构&lt;/p&gt;&lt;p&gt;2、怎样做重构？&lt;/p&gt;&lt;p&gt;3、重构过程与业务支撑之间怎样平衡？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;下面我针对这三个问题展开论述。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;理解重构、重写和重新架构&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;重构是对代码和功能进行&lt;span&gt;渐进式改进&lt;/span&gt;；重写是&lt;span&gt;要摧毁它，重新构建；重新架构在大框架上做修改和再设计，具体每个实现模块可能是用原来的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;举个例子，搭积木。重构就是我用积木搭建了一个小马，发现小马某些部分不好看，我就把几块积木调整调整，让小马更好看；重写就是我用积木搭建了一个小马，发现自己搭建好了完全不喜欢，把积木推到了重新搭，既然是重新搭，搭好的东西和原来差距有多大就不好说了；重新架构就是我用积木搭建了一个小马，发现自己其实想要个小桥，没有必要全部推到重做，而是可以先画好设计图，然后直接把小马的四条腿拆下来做桥墩，脊背部分做一部分桥面，实在不能用的再拆下来重安装。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;重构是小步跑的过程，如果对外提供的功能没有变化，这是稳妥的方法；重写往往伴随着功能上的升级，不然对于“我不知道这段代码是干什么用的但我不敢删”这种事情很难保证对外提供的功能没有变化。&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;重构和重写与修改量没有直接关系。有个哲学问题叫做“特修斯之船”，是说一艘船持续的在海上航行，船不断有部分老化或者坏掉进行替换，最终整艘船的所有部分都换过一遍，这时候船还是原来那艘船吗？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6666666666666666&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/2tk5ianItRl9csr5bLvWohaeCrKicQzMduZG2RWUTWG8tqmcjOXAicRBZRG1cyy4SpaDsb4ibBBKCPKsr2iaGkSQgrw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;450&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;所以咱们不再纠结概念，统一用重构这个词，聚焦于怎么解决问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;怎样做重构&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;首先需要对系统进行一个生命周期预估，包括：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;朋友说：“开始的时候没有考虑到  代码一言难尽了&lt;span&gt;”&lt;/span&gt;，其实大可不必这样想。架构和代码&lt;/span&gt;不是设计出来的，是演进出来的。如果一开始要我做，一段时间之后，也很可能会遇到相同觉得非重构不可的情况。虽然我一定会做未来需求预判，但是现实往往会出现很多例外情况，让程序充满了妥协。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那针对朋友遇到的问题，怎么设计更合理呢？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;支付重构&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果只是重构支付部分，我个人觉得相对容易。因为支付需要的要素比较好抽象，主要是下游支付渠道需要什么。自从有了网联，现在对接方也比较固定了。直接接网联或者微信支付、支付宝支付、拉卡拉…… 他们所需要的要素都差不多。因为它们都要接入网联完成国家监管的需求，所以要素主要看网联需要哪些要素。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当然，它们的签名方式可能会不同；调用的支付渠道地址不同；给支付渠道传递的时候入参组装方式也不同。甚至有的支付渠道还需要有特殊的步骤。这时候怎么抽象呢？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;推荐“工作流”+策略模式。这是一种实现积木化的方式。定义一个统一接口，比如&lt;/p&gt;&lt;p&gt;class Executor {&lt;/p&gt;&lt;p&gt;      void execute(Task task);&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;p&gt;task里放置所有的入参，以及每次执行时产生的，下游需要的中间数据。签名等流程各自实现此接口。这样就实现了自由组装的重用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;举个例子，下面&lt;span&gt;“&lt;/span&gt;积木块”各自实现了自己的execute：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;微信支付签名、微信支付入参组装、微信支付结果解析、支付宝&lt;span&gt;支付&lt;/span&gt;&lt;span&gt;签&lt;/span&gt;&lt;span&gt;名、支付宝&lt;/span&gt;&lt;span&gt;支付&lt;/span&gt;&lt;span&gt;入参组装&lt;/span&gt;&lt;span&gt;、支付宝&lt;/span&gt;&lt;span&gt;支付结果解析、&lt;/span&gt;支付宝特殊处理、下游http调用(这里假设微信和支付宝都是http的post请求来调用的，这样发起调用来说两者只是请求地址和入参不同）&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这时候可以组装微信支付流程：&lt;/p&gt;&lt;p&gt;List list = new List();&lt;/p&gt;&lt;p&gt;list.put(微信支付签名);&lt;/p&gt;&lt;p&gt;&lt;span&gt;lis&lt;/span&gt;&lt;span&gt;t.&lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;微&lt;/span&gt;&lt;span&gt;信支付入参组装&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;lis&lt;/span&gt;&lt;span&gt;t.&lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(下游http调用&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;lis&lt;/span&gt;&lt;span&gt;t.&lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;微&lt;/span&gt;&lt;span&gt;信支付结果解析&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;for(Executor e ：list) {&lt;/p&gt;&lt;p&gt;    e.execute(task);&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同样可以组装支付宝支付流程：&lt;/p&gt;&lt;p&gt;List list = new List();&lt;/p&gt;&lt;p&gt;list.put(&lt;span&gt;支&lt;/span&gt;&lt;span&gt;付宝&lt;/span&gt;支付签名);&lt;/p&gt;&lt;p&gt;&lt;span&gt;lis&lt;/span&gt;&lt;span&gt;t.&lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span/&gt;&lt;span&gt;支&lt;/span&gt;&lt;span&gt;付宝&lt;/span&gt;&lt;span&gt;支付入参组装&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;lis&lt;/span&gt;&lt;span&gt;t.&lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(下游http调用&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;span&gt;lis&lt;/span&gt;&lt;span&gt;t.&lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span/&gt;&lt;span&gt;支&lt;/span&gt;&lt;span&gt;付宝&lt;/span&gt;&lt;span&gt;支付结果解析&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;lis&lt;/span&gt;&lt;span&gt;t.&lt;/span&gt;&lt;span&gt;put&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span/&gt;&lt;span&gt;支&lt;/span&gt;&lt;span&gt;付宝&lt;/span&gt;&lt;span/&gt;&lt;span&gt;支付特殊处理&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;for(Executor e ：list) {&lt;/p&gt;&lt;p&gt;    e.execute(task);&lt;/p&gt;&lt;p&gt;}&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不同的流程只是list不同，这个list是可以时间配置化的，可以配置在配置文件中、甚至可以从数据库中读取。微信支付流程和支付宝支付流程是两种不同的策略，可以使用策略模式。入参选择哪种策略就用哪种策略执行。这样，各个流程之间没有干扰，积木块变更影响小还可以随意组合灵活性高。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;整体重构&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;朋友的业务复杂性还不在于支付，而在于收单。解决方法就是文章开头提到的接入平台的方式。打造平台的关键不是技术，而是规范。&lt;span&gt;自己制定规范。&lt;/span&gt;&lt;span&gt;别人接入&lt;/span&gt;&lt;span&gt;都要按照规范来&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里有前提：公司自身的影响力。平台是底层自己需要有决策权，比如微信开放平台，想接入就要理解并使用他们的API。而因为微信基础在，必须按照人家说的来，这就是平台影响力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在实际工作中，一般有两种情况。接入方自身也没有什么规范，本身就要求功能可用，这时候咱们自身有规范，对方比较容易接受。另外一种，对方是实力背景的大公司，也有自己的规范。这时候咱们处于弱势，要按照别人的规范来，可以使用上面支付重构的积木化方法进行进行组合。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;重构过程与业务支撑之间怎样平衡？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在重构过程中一般会遇到两顶思考帽问题：一顶是需求的帽子，一顶是重构的帽子。有限的时间怎么分配呢？建议一开始就定好目标：什么阶段要重构到什么程度，然后分解工作。最后分摊到每天比如需要2小时时间。那么在需求开发时间评估的时候就要把这个时间扣掉。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;重构做完，老逻辑迁移到新逻辑有风险。这时候我的建议是：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;首先，把新功能当成重构结果的验金石。有新功能，先在新功能上验证新逻辑的正确性。因为新功能上线到上量有一个过程，初期出了问题影响也不会很大。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;然后，老逻辑迁移需要灰度。可以一个业务一个业务的灰度迁移，也可以按照流量百分比进行迁移。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最后总结一下对重构的几点建议：&lt;/p&gt;&lt;p&gt;1、小步快跑，稳步迭代&lt;/p&gt;&lt;p&gt;2、设计与代码的重构结伴而行&lt;/p&gt;&lt;p&gt;3、如果模块或者函数不能想到一个好名字，很可能是设计出了问题&lt;/p&gt;&lt;p&gt;4、每步要保证足够简单，想象随时可能会停止&lt;br/&gt;&lt;/p&gt;&lt;/section&gt;
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>901f0c34278a17a014d847da8fe4a663</guid>
<title>直击RocketMQ面试现场</title>
<link>https://toutiao.io/k/pg4axb3</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzk0OTI0NzIzMQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/Eb8TPxx4xwyavDTedzsA7hicJ3r55tiaOxjDhO01LRxYCmqCRowLFRFjN9ZrEiafbBSYUATl9QBlJSY1UWwB25k4w/0?wx_fmt=png&quot; data-nickname=&quot;35岁程序员那些事&quot; data-alias=&quot;&quot; data-signature=&quot;畅销书-Spring Cloud Alibaba微服务架构实战派（上下册）的作者&quot; data-from=&quot;1&quot;/&gt;&lt;span/&gt;&lt;span/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;RocketMQ是一个高性能、高可用和高吞吐量的“分布式消息中间件”，如果面试官要问你它的相关原理，那太多了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;理解RocketMQ&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果你只是去背了一些八股文，然后去应付RocketMQ相关面试题，那大概率是不能通过的。比如面试官突然问你。RocketMQ是用什么语言编写的？我想很多八股文都不会提到吧，因为人家默认觉得你知道，但是万一你真的不知道呢，那这个也太好玩了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;首先，我们要理解RocketMQ，先必须知道怎么搭建环境，笔者曾经面试过很多候选人，问他们RocketMQ是如何搭建环境的，需要哪些配套的中间件环境，步骤是哪些，很多候选人都不知道。反而呢，对那些“所谓的核心技术原理，非常了解”，但是我又去问，实际的项目中，又是如何去使用RocketMQ的呢，他们又不知道。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;其次，学会搭建环境之后，那就是要自己写代码去用RocketMQ，反复的用，反复的想，反复的踩坑，这样才能更深层次的理解它的功能，从而达到理解RocketMQ的目的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;最后，我们要结合使用过程中碰到的问题，去分析原理并解决问题，做到出现了问题，我们能从日志就能快速的找到出现问题的那行代码，并能够现学现用的去解决问题，这个才能我们技术人要达到的目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直接RocketMQ面试现场&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;说来说去还是要我们自己在平常多积累一些RocketMQ的使用经验，并学习到它的优秀的架构设计思想，从而总结出自己的方法论。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;直接面试现场，那我们还是要上一些比较尖锐的面试题，如下：&lt;/span&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;说说RocketMQ的生产者组的功能，主要能做什么，注意这个是要挖坑的，因为它与分布式事务消息有关系。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;说说分布是事务消息的原理，它的应用场景有哪些？&lt;/span&gt;&lt;span/&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;平常我们是怎么使用&lt;/span&gt;&lt;span&gt;RocketMQ&lt;/span&gt;&lt;span&gt;来生产和消费消息的，这个考察我们是否关注中间件的细节？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RocketMQ&lt;/span&gt;&lt;span&gt;的集群消费和广播消费消息的区别？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RocketMQ&lt;/span&gt;&lt;span&gt;支持顺序消息吗？怎么实现的呢？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RocketMQ&lt;/span&gt;&lt;span&gt;的副本机制是什么？它解决了哪些问题？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RocketMQ&lt;/span&gt;&lt;span&gt;的主从同步机制是什么？它又解决了哪些问题？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RocketMQ&lt;/span&gt;&lt;span&gt;中消息支持重试吗？如果支持，怎么实现的？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;RocketMQ&lt;/span&gt;&lt;span&gt;是如何完&lt;/span&gt;&lt;span&gt;成消息路由的？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span/&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span&gt; &lt;/span&gt;&lt;/span&gt;&lt;span&gt;RocketMQ的负载均衡机制是什么？它主要解决什么问题？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;以上只是关于RocketMQ八股文的一部分，这里还是暂时不提供解读的答案，咱们可以先自己默默的思考一下，答案解读会在下几期的文章中。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;总结&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;要想真正的做到直击面试现场，需要我们自己平常使用RocketMQ的过程中，去认真的思考RocketMQ的思想，只有真正理解了，才能做到“以不变应万变”，不惧怕现场面试。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;粉丝福利时间&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;为了回馈广大技术人和书友，本公众号和电子工业出版社合作，一起给大家赠送一些技术类书籍。&lt;/span&gt;&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;              &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;section mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;2.2&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/ibl6u6nJ01g9icia42icDbWWvO2ObicnIUHjwQKVp30YzLS8xSInYupoEXAKjYeYDibY50CgKLz6ViaDjTjuRqUqaae0w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;20&quot;/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;参与方式&lt;/p&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;2.2&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/K8beZoNWDcUm9I6ia4UU97K1XHrQx2PavruEm3xAL2W3Vd7JxrB8PLXtmT5JkwqpC9Dg9hEmtVZkY2hibnlkib0Qg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;20&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;关注公众号：35岁程序员那些事，后台回复关键词“参与抽奖”，获取抽奖链接，点击抽奖。 中奖之后，可以联系笔者的微信号或者公众号后台回复关键词“联系笔者”，获取联系方式。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;如果没有中奖的技术人，还可以参与本次文章的点赞和留言，笔者会按照留言的时间顺序和点赞的时间顺序，随机的再抽取一名技术人，再赠送一本技术书籍&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;笔者会在抽奖结果出来之后，进行留言和点赞技术人的抽奖，抽奖结果会同步公布。&lt;/span&gt;&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;部分书单列表&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第一本 &lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__78&quot;&gt;《&lt;/strong&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__79&quot;&gt;Spring Cloud Alibaba 微服务架构实战派（上下册）&lt;/strong&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__80&quot;&gt;》&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot; data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(175, 165, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)&quot;&gt;&lt;li&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(175, 165, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)&quot;&gt;&lt;span&gt;技术新。采用目前的新版本（2.2. 5.RELEASE）来编写，相关技术也采用的是目前新的稳定版本&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(175, 165, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)&quot;&gt;&lt;span&gt;精心设计的主线：零基础入门，循序渐进，直至项目实战&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(175, 165, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)&quot;&gt;&lt;span&gt;不只介绍框架本身，而是微服务架构全栈技术（比如Seata、Skywalking、Redis、RocketMQ等），本书是“一站到底”的解决方案：读者只需从这里上车，中途无需转乘，读者需要什么，本书就提供什么，直达终点&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(175, 165, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)&quot;&gt;&lt;span&gt;绘制了大量的图，便于理解原理、架构、流程&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(175, 165, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)&quot;&gt;&lt;span&gt;本书的目标是：①让读者在动手中学习，而不是“看书时好像全明白了，一动手却发现什么都不会”；②读者可以掌握微服务全栈技术，而不仅仅是框架，对于相关的技术（Seata、RocketMQ），基本都是从零讲起，这样避免了读者为了学会微服务技术，得找Spring Cloud 框架的书、Seata的书、RocketMQ的书……本书是一站式解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(175, 165, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(175, 165, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__78&quot;&gt;《&lt;/strong&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__79&quot;&gt;Spring Cloud Alibaba 微服务架构实战派（上下册）&lt;/strong&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__80&quot;&gt;》&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;是笔者自己出版的书籍，肯定是要放在第一位的，资源多多。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;第二本 &lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__54&quot;&gt;《&lt;/strong&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__55&quot;&gt;Spring Boot实战派》&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;span&gt;本书花费大量的力气对比讲解多种同类技术的知识、使用和区别，读者可以根据自己的喜欢进行技术选型；还讲解了时下流行的接口架构风格RESTFUL、用来实现高并发的Redis、用来实现系统间通信的中间件RabbitMQ。&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;span&gt;最后两章融合了本书所讲知识点，讲解了两个常用又实用的实战项目。本书适合所有对Spring Boot感兴趣的读者阅读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__55&quot;&gt;第三本 &lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__148&quot;&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__147&quot;&gt;《&lt;/strong&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__148&quot;&gt;剑指Offer（专项突破版）：数据结构与算法名企面试题精讲&lt;/strong&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__149&quot;&gt;》&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;span&gt;本书全面、系统地总结了在准备程序员面试过程中必备的数据结构与算法。本书首先详细讨论整数、数组、链表、字符串、哈希表、栈、队列、二叉树、堆和前缀树等常用的数据结构，然后深入讨论二分查找、排序、回溯法、动态规划和图搜索等算法。除了介绍相应的基础知识，每章还通过大量的高频面试题系统地总结了各种数据结构与算法的应用场景及解题技巧。&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;span&gt;本书适合所有正在准备面试的程序员阅读。无论是计算机相关专业的应届毕业生还是初入职场的程序员，本书总结的数据结构和算法的基础知识及解题经验都不仅可以帮助他们提高准备面试的效率，还可以增加他们通过面试的成功率。&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__55&quot;&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__148&quot;&gt;第四本 《微服务项目实战派:从Spring Boot到Spring Cloud》&lt;/strong&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本书以项目实战的形式来介绍Spring Cloud微服务体系。书中所有实例都来自作者多年工作实践，内容覆盖构建Spring Cloud微服务所需的绝大部分内容——包括微服务工程搭建、微服务网关、熔断限流、分布式任务调度、自动化CI/CD构建、Kubernetes容器化部署、微服务监控系统、分布式链路追踪等。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本书适合希望快速提升项目经验的Java初学者、正在转型微服务架构的传统项目研发人员、希望提升Spring Cloud微服务全栈技术经验的高级开发人员、对特定系统设计感兴趣的产品经理及研发人员。无论读者是否接触过微服务开发，只要具备一定的Java开发基础，都能通过本书的学习快速掌握实际场景中的微服务开发技巧，并快速提升项目实战经验。&lt;/span&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__55&quot;&gt;第五本&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;span&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__55&quot;&gt; 《正本清源分布式事务之Seata》&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-darkmode-bgcolor-16460189857240=&quot;rgb(31, 31, 31)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)|rgb(253, 250, 246)&quot; data-darkmode-color-16460189857240=&quot;rgb(102, 102, 102)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(65, 58, 56)|rgb(102, 102, 102)&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;strong data-darkmode-bgcolor-16460189857240=&quot;rgb(25, 25, 25)&quot; data-darkmode-original-bgcolor-16460189857240=&quot;#fff|rgb(255, 255, 255)&quot; data-darkmode-color-16460189857240=&quot;rgb(163, 163, 163)&quot; data-darkmode-original-color-16460189857240=&quot;#fff|rgb(59, 59, 59)|rgb(0, 0, 0)&quot; data-style=&quot;max-width: 100%; max-inline-size: 100%; cursor: text; color: rgb(0, 0, 0); font-size: 16px; letter-spacing: 1.5px; caret-color: rgb(255, 0, 0); font-family: 微软雅黑, sans-serif; outline: none 0px !important; box-sizing: border-box !important; overflow-wrap: break-word !important;&quot; class=&quot;js_darkmode__55&quot;&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在微服务架构下，分布式事务一直是痛点和难点。Seata是阿里巴巴开源的分布式事务中间件，致力于以高效且对业务无侵入的方式，解决在微服务场景下面临的分布式事务问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本书作者是阿里巴巴GTS创始人和Seata作者，结合其多年在分布式事务领域设计、研发和应用的经验，深入浅出地阐述了分布式事务技术基础、Seata AT模式、TCC模式、RPC设计、事务协调器技术的原理，并给出了两个开发实例（AT模式和TCC模式）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;本书可以为微服务系统架构师、研发人员解决核心业务实际问题提供思路，也适合分布式技术相关专业的学生阅读，帮助他们建立分布式事务的知识框架。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;如上书籍只是笔者列举的一些资源，如果中奖的技术人的书架上已经入驻了上述书籍，可以通过“微信”和笔者联系。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;公众号初衷&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;知识输出是笔者的初衷，借助知识输出，能够认识更多的牛人,能够和牛人沟通，也是自己技术提升的一个机会。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;                        &lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;     本人微信ID，如有需要惠请联系&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.2982954545454546&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/Eb8TPxx4xwwHsTjeO8OsSJoG3Rg657x1BmzoeKGBExTk6yk6ibDyZwIX7zFMvX1HmDaKvaribkjWNqZPJpOeHYrw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1056&quot;/&gt;&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;Mzk0OTI0NzIzMQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/Eb8TPxx4xwwRBMXF2V1EnW3pB79Rk1CZicwibngNE3omwCwhO0A41EaR8uBx7tfSh3e30IPqVmEauR1nTTzxvlAw/0?wx_fmt=png&quot; data-nickname=&quot;35岁程序员那些事&quot; data-alias=&quot;cxynxs_35&quot; data-signature=&quot;畅销书-Spring Cloud Alibaba微服务架构实战派（上下册）的作者&quot; data-from=&quot;1&quot;/&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;一路向北&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-mpa-template=&quot;t&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.9482758620689655&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/IaMeK4iaQqbia5GiaVShU9NPibJ3wwSxZ2QVukfO2r651QwQoHwcA5hiapibrrkRh9AFJpvGZVRMFiaHzhPPKLs8RmdibQ/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;174&quot;/&gt;&lt;/section&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;section data-mid=&quot;&quot; mpa-from-tpl=&quot;t&quot;&gt;&lt;p data-mid=&quot;&quot;&gt;人间灯火无不休，爱与山水与春&lt;br/&gt;&lt;/p&gt;&lt;p data-mid=&quot;&quot;&gt;                                                                            ----无题&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.4255555555555556&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/Eb8TPxx4xwzofM1ESK3E9bErfo0AfKL8x9F7cremVGV5D6uAn1XoFMUVAp9tpK3QrunygNEJlSXUuFrMAqBm1w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;900&quot;/&gt;&lt;span/&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>13c30eb8f71350f37bc4bbc3726cac32</guid>
<title>Apache Pulsar 技术系列 - Pulsar事务实现原理</title>
<link>https://toutiao.io/k/m4medd4</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.062037&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrJJZRuicS1e24IXGHxfEZlKuIWSw0SEYgkwBMmbK8h9NBibcdxOciaHYxQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.1503268&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtr8qvT3LictZC5AOZic7fYiajiahF49qvt4ySXBGIMU3YnwISB2dOeXDb3Nw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;306&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;导语&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Apache Pulsar 是一个多租户、高性能的服务间消息传输解决方案，支持多租户、低延时、读写分离、跨地域复制、快速扩容、灵活容错等特性。腾讯云MQ Oteam Pulsar工作组对 Pulsar 做了深入调研以及大量的性能和稳定性方面优化，目前已经在TDBank、腾讯云TDMQ落地上线。本篇将简单介绍Pulsar服务端消息确认的一些概念和原理，欢迎大家阅读。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.1503268&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtr8qvT3LictZC5AOZic7fYiajiahF49qvt4ySXBGIMU3YnwISB2dOeXDb3Nw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;306&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;作者简介&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt; 林琳                                                                         &lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;腾讯云中间件专家工程师&lt;/p&gt;&lt;p&gt;Apache Pulsar PMC，《深入解析Apache Pulsar》作者。目前专注于中间件领域，在消息队列和微服务方向具有丰富的经验。负责 TDMQ的设计与开发工作，目前致力于打造稳定、高效和可扩展的基础组件与服务。&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7172996&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrbK0V07ic0bpjGtneYdUceRecMjY2d0b5LyTAhMWl1m2zpDmnian4yH3w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;237&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;在事务消息未出现前，Pulsar中支持的最高等级的消息传递保证，是通过Broker的消息去重机制，来保证Producer在单个分区上的消息只精确保存一次。当Producer发送消息失败后，即使重试发送消息，Broker也能确保消息只被持久化一次。但在Partitioned Topic的场景下，Producer没有办法保证多个分区的消息原子性。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;当Broker 宕机时，Producer可能会发送消息失败，如果Producer没有重试或已用尽重试次数，则消息不会写入 Pulsar。在消费者方面，目前的消息确认是尽力而为的操作，并不能确保消息一定被确认成功，如果消息确认失败，这将导致消息重新投递，消费者将收到重复的消息， Pulsar 只能保证消费者至少消费一次。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;类似地，Pulsar Functions 仅保证对幂等函数上的单个消息处理一次，即需要业务保证幂等。它不能保证处理多个消息或输出多个结果只发生一次。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;举个例子，某个Function的执行步骤是：从Topic-A1、Topic-A2中消费消息，然后Function中对消息进行聚合处理（如：时间窗口聚合计算），结果存储到Topic-B，最后分别确认（ACK） Topic-A1和Topic-A2中的消息。该Function可能会在“输出结果到Topic-B”和“确认消息”之间失败，甚至在确认单个消息时失败。这将导致所有（或部分）Topic-A1、Topic-A2的消息被重新传递和重新处理，并生成新的结果，进而导致整个时间窗口的计算结果错误。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;因此，Pulsar需要事务机制来保证精确一次的语义（Exactly-once），生产和消费都能保证精确一次，不会重复，也不会丢失数据，即使在Broker宕机或Function处理失败的情况下。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7172996&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrbK0V07ic0bpjGtneYdUceRecMjY2d0b5LyTAhMWl1m2zpDmnian4yH3w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;237&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;事务简介&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Pulsar事务消息的设计初衷是用于保证Pulsar Function的精确一次语义，可以保证Producer发送多条消息到不同的Partition时，可以同时全部成功或者同时全部失败。也可以保证Consumer消费多条消息在时，可以同时全部确认成功或同时全部失败。当然，也可以把生产、消费都包含在同一个事务中，要么全部成功，要么全部失败。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们以本小节开头处的Function场景为例，演示生产、消费在同一个事务中的场景：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;首先，我们需要在broker.conf中启用事务。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;ini&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__attr&quot;&gt;transactionCoordinatorEnabled&lt;/span&gt;=&lt;span class=&quot;code-snippet__literal&quot;&gt;true&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;然后，我们分别创建PulsarClient和事务对象。生产者和消费者API中都需要带上这个事务对象，才能确保它们在同一个事务中。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;javascript&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;PulsarClient pulsarClient = PulsarClient.builder()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .serviceUrl(&lt;span class=&quot;code-snippet__string&quot;&gt;&quot;pulsar://localhost:6650&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .enableTransaction(&lt;span class=&quot;code-snippet__literal&quot;&gt;true&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .build();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;Transaction txn = pulsarClient&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .newTransaction()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .withTransactionTimeout(&lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;, TimeUnit.MINUTES)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .build()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .get();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt; sourceTopic = &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;public/default/source-topic&quot;&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt; sinkTopic = &lt;span class=&quot;code-snippet__string&quot;&gt;&quot;public/default/sink-topic&quot;&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;Consumer&amp;lt;&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt;&amp;gt; sourceConsumer = pulsarClient.newConsumer(Schema.STRING)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .topic(sourceTopic)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .subscriptionName(&lt;span class=&quot;code-snippet__string&quot;&gt;&quot;my-sub&quot;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .subscribe();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;Producer&amp;lt;&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt;&amp;gt; sinkProducer = pulsarClient.newProducer(Schema.STRING)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .topic(sinkTopic)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .create();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        &lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;Message&amp;lt;&lt;span class=&quot;code-snippet__built_in&quot;&gt;String&lt;/span&gt;&amp;gt; message = sourceConsumer.receive();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;sinkProducer.newMessage(txn).value(&lt;span class=&quot;code-snippet__string&quot;&gt;&quot;sink data&quot;&lt;/span&gt;).sendAsync();&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;sourceConsumer.acknowledgeAsync(message.getMessageId(), txn);&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;txn.commit().get();&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们以本小节开头处的Function例子来说：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;当未开启事务时，如果Function先把结果写入SinkTopic，但是消息确认失败（下图Step-4失败），这会导致消息被重新被投递（下图Step-1），Function会重新计算一个结果再发送到SinkTopic，这样就会出现一条数据被重复计算并投递了两次。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;如果没有开启事务，Function会先确认消息，再把数据写入SinkTopic（先执行Step-4 再执行Step-3），此时如果写入SinkTopic失败，而SourceTopic的消息又已经被确认，则会造成数据丢失，最终的计算结果也不准确。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;如果开启了事务，只要最后没有commit，前面所有的步骤都会被回滚，生产的消息、确认过的消息都被回滚，从而让整个流程可以重新再来一遍，不会重复计算，也不会丢失数据。整个时序图如下所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6529284&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrJpXpS3zdoULfKsJI6uxznsq9thnV2774Pdw30t2Jc6p5DZfH0DSloQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;922&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们只需要根据上面步骤，了解每一步具体做了什么，就能清楚整个事务的实现方式。在下面的小节中，我们将逐步介绍。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7172996&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrbK0V07ic0bpjGtneYdUceRecMjY2d0b5LyTAhMWl1m2zpDmnian4yH3w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;237&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;事务流程&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;在了解整个事务流程之前，我们先介绍Pulsar中事务的组件，常见的分布式事务中都会有TC、TM、RM等组件：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;TM：事务发起者。定义事务的边界，负责告知 TC，分布式事务的开始，提交，回滚。在Pulsar事务中，由每个PulsarClient来扮演这个角色。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;RM：每个节点的资源管理者。管理每个分支事务的资源，每一个 RM 都会作为一个分支事务注册在 TC。在Pulsar中定义了一个TopicTransactionBuffer和PendingAckHandle来分别管理生产、消费的资源。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;TC ：事务协调者。TC用于处理来自Pulsar Client的事务请求以跟踪其事务状态的模块。每个TC都有一个 唯一id (TCID) 标识，TC之间独立维护自己的事务元数据存储。TCID 用于生成事务 ID，广播通知不同节点提交、回滚事务。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;下面，我们以一个Producer来介绍整个事务的流程，图中灰色部分代表存储，现有内存和Bookkeeper两种存储实现：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.6009259&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrEg77kBMSMBrv9zhqDeSNU7MF7DJ4Dic71enN7w5BXOm83GKib7uAickQQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;选择TC。一个Pulsar集群中可能存在多个TC（默认16个），PulsarClient在创建事务时需要先选择用哪个TC，后续所有事务的创建、提交、回滚等操作都会发往这个TC。选择的规则很简单，由于TC的Topic是固定的，首先Lookup查看所有分区所在的Broker（每个分区就是一个TC），然后每次Client创建新事务，轮询选择一个TC即可。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;开启事务。代码中通过pulsarClient.newTransaction()开启一个事务，Client会往对应的TC中发送一个newTxn命令，TC生成并返回一个新事务的ID对象，对象里保存了TC的ID（用于后续请求找节点）和事务的ID，事务ID是递增的，同一个TC生成ID不会重复。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;注册分区。Topic有可能是分区主题，消息会被发往不同的Broker节点，为了让TC知道消息会发送到哪些节点（后续事务提交、回滚时TC需要通知这些节点），Producer在发送消息之前，会先往TC上注册分区信息。这样一来，后续TC就知道要通知哪些节点的RM来提交、回滚事务了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;发送消息。这一步和普通的消息发送没有太大的区别，不过消息需要先经过每个Broker上的RM，Pulsar中RM被定义为TopicTransactionBuffer，RM里面会记录一些元数据，最后消息还是会被写入原始的Topic中。此时虽然消息已经被写入了原始Topic，但消费者是不可见的，Pulsar中的事务隔离级别是Read Commit。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;提交事务。Producer发送完所有的消息后，提交事务，TC会收到提交请求后，会广播通知RM节点提交事务，更新对应的元数据，让消息可以被消费者消费。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;Setp-4中的消息是如何保证持久化到Topic中又不可见的呢？&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;每个Topic中都会保存一个maxReadPosition属性，用来标识当前消费者可以读取的最大位置，当事务还未提交之前，虽然数据已经持久化到Topic中，但是maxReadPosition是不会改变的。因此Consumer无法消费到未提交的数据。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;消息已经持久化了，最后事务要回滚，这部分数据如何处理？&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;如果事务要回滚，RM中会记录这个事务为Aborted状态。每条消息的元数据中都会保存事务的ID等信息，Dispatcher中会根据事务ID判断这条消息是否需要投递给Consumer。如果发现事务已经结束，则直接过滤掉（内部确认掉消息）。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;最后提交事务时如果部分成功、部分失败，如何处理？&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;TC中有一个名为TransactionOpRetryTimer的定时对象，所有未全部成功广播的事务都会交给它来重试，直到所有节点最终全部成功或超过重试次数。那这个过程不会出现一致性问题吗？首先我们想想，出现这种情况的场景是什么。通常是某些Broker节点宕机导致这些节点不可用，或是网络抖动导致暂时不可达。在Pulsar中如果出现Broker宕机，Topic的归属是会转移的，除非整个集群不可用，否则总是可以找到一个新的Broker，通过重试来解决。在Topic归属转移过程中，maxReadPosition没有改变，消费者也消费不到消息。即使整个集群不可用，后续等到集群恢复后，Timer还是会通过重试让事务提交。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;如果事务未完成，会阻塞普通消息的消费吗？&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;会。假设我们开启事务，发送了几条事务消息，但是并未提交或回滚事务。此时继续往Topic中发送普通消息，由于事务消息一直没有提交，maxReadPosition不会变化，消费者会消费不到新的消息，会阻塞普通消息的消费。这是符合预期的行为，为了保证消息的顺序。而不同Topic之间不会相互影响，因为每个Topic都有自己的maxReadPosition。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7172996&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrbK0V07ic0bpjGtneYdUceRecMjY2d0b5LyTAhMWl1m2zpDmnian4yH3w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;237&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;事务的实现&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们可以把事务的实现分为五部分：环境、TC、生产者RM、消费者RM、客户端。由于生产和消费资源的管理是分开的，因此我们会分别介绍。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;环境设定&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;事务协调者的设置，需要从Pulsar集群的初始化时开始，我们在第一章中有介绍如何搭建集群，第一次需要执行一段命令，初始化ZooKeeper中的集群元数据。此时，Pulsar会自动创建一个SystemNamespace，并在里面创建一个Topic，完整的Topic如下所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;javascript&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;persistent:&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;这是一个PartitionedTopic，默认有16个分区，每个分区就是一个独立的TC。我们可以通过--initial-num-transaction-coordinators参数来设置TC的数量。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;TC与RM&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;接下来，我们看看服务端的事务组件，如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4759259&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrYJukKFGc9tBEQuPXQQkbdbXyWs3a1XT5EXqVs7MqspX8gnjMQKJp4A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1080&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;TransactionMetadataStoreService 是Broker上事务的总体协调者，我们可以认为它是TC。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;TransactionMetadataStore 被TC用来保存事务的元数据，如：新创建的事务，Producer注册上来的分区。这个接口有两个实现类，一个是把数据保存到Bookkeeper的实现，另外一个则直接把数据保存在内存中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;TransactionTimeoutTracker 服务端用于追踪超时的事务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;各种Provider，它们都属于工厂类，无需特别关注。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;TopicTransactionBuffer 生产者的RM，当事务消息被发送到Broker，RM作为代理会记录一些元数据，然后把消息存入原始Topic。内部包含了TopicTransactionBufferRecover和TransactionBufferSnapshotService，RM的元数据会被结构化为快照并定时刷盘，这两个对象分别负责快照的恢复和快照的保存。由于生产消息是以Topic为单位，因此每个Topic/Partition都会有一个。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;PendingAckHandle 消费者的RM，由于消费是以订阅为单位的，因此每个订阅都有一个。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;由于线上环境通常会使用持久化的事务，因此下面的原理都基于持久化实现。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;所有事务相关的服务，在BrokerService启动时会初始化。TC主题中，每个Partition都是一个Topic，TransactionMetadataStoreService在初始化时，会根据当前Broker纳管的TC Partition，从Bookkeeper中恢复之前持久化的元数据。每个TC会保存以下元数据：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;newTransaction。新建一个事务，返回一个唯一的事务ID对象。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;addProducedPartitionToTxn。注册生产者要发送消息的Partition信息，用于后续TC通知对应节点的RM提交/回滚事务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;addAckedPartitionToTxn。注册消费者要消费消息的Partition信息，用于后续TC通知对应节点的RM提交/回滚事务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;endTransaction。结束一个事务，可以是提交、回滚或者超时等。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;我们在初始化PulsarClient时，如果设置了enableTransaction=true，则Client初始化时，还会额外初始化一个TransactionCoordinatorClient。由于TC的Tenant、Namespace以及Topic名称都是固定的，因此TC客户端可以通过Lookup发现所有的Partition信息并缓存到本地，后续Client创建事务时，会轮询从这个缓存列表中选取下一个事务要使用的TC。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;Producer事务管理&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;接下来我们会开启一个事务：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;cs&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;/&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;Transaction txn = pulsarClient&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .newTransaction()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .withTransactionTimeout(&lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;, TimeUnit.MINUTES)&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .build()&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;        .&lt;span class=&quot;code-snippet__keyword&quot;&gt;get&lt;/span&gt;();&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;上面这段代码中，会发送一个newTxn给某个TC，并得到一个Transaction对象。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;开启事务时，TransactionCoordinatorClient会从缓存中选取一个TC，然后往选定的TC所在的Broker发送一个newTxn命令，命令的结构定义如下所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;swift&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;message &lt;span class=&quot;code-snippet__type&quot;&gt;CommandNewTxn&lt;/span&gt; {&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;required&lt;/span&gt; uint64 request_id = &lt;span class=&quot;code-snippet__number&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;optional&lt;/span&gt; uint64 txn_ttl_seconds = &lt;span class=&quot;code-snippet__number&quot;&gt;2&lt;/span&gt; [&lt;span class=&quot;code-snippet__keyword&quot;&gt;default&lt;/span&gt; = &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;];&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;    &lt;span class=&quot;code-snippet__keyword&quot;&gt;optional&lt;/span&gt; uint64 tc_id = &lt;span class=&quot;code-snippet__number&quot;&gt;3&lt;/span&gt; [&lt;span class=&quot;code-snippet__keyword&quot;&gt;default&lt;/span&gt; = &lt;span class=&quot;code-snippet__number&quot;&gt;0&lt;/span&gt;];&lt;/span&gt;&lt;/code&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;由于命令中包含了TCID，因此即使多个TC被同一个Broker纳管也没有问题。Broker会根据TCID找到对应的TC并处理请求。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Producer发送消息之前，会先发送一个AddPartitionToTxn命令给Broker，只有成功后，才会继续发送真实的消息。事务消息到达Broker后，传递给TransactionBuffer进行处理。期间Broker必定会对消息进行去重校验，通过校验后，数据会保存到TransactionBuffer里，而TransactionBuffer只是一个代理（会保存一些元数据），它最终会调用原始Topic保存消息，TransactionBuffer在初始化时，构造方法需要传入原始Topic对象。我们可以把TransactionBuffer看作是Producer端的RM。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;TransactionBuffer中会保存两种信息，一种是原始消息，直接使用Topic保存。另外一种是快照，快照中保存了Topic名称，最大可读位置信息（避免Consumer读到未提交的数据）、该Topic中已经中断（aborted）的事务列表。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;其中，中断的事务，是由TC广播告知其他Broker节点的，TransactionBuffer接到信息后，会直接在原始Topic中写入一个abortMarker，标记事务已经中断，然后更新内存中的列表。abortMarker也是一条普通的消息，但是消息头中的元数据和普通消息不一样。这些数据保存在快照中，主要是为了Broker重启后数据能快速恢复。如果快照数据丢失，TopicTransactionBufferRecover会从尾到头读取Topic中的所有数据，每遇到一个abortMarker都会更新内存中的中断列表。如果有了快照，我们只需要从快照处的起点开始读即可恢复数据。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;Consumer事务管理&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;消费者需要在消息确认时带上事务对象，标识使用事务Ack：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section class=&quot;code-snippet__fix code-snippet__js&quot;&gt;&lt;pre class=&quot;code-snippet__js&quot; data-lang=&quot;css&quot;&gt;&lt;code&gt;&lt;span class=&quot;code-snippet_outer&quot;&gt;&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;code-snippet__selector-class&quot;&gt;.acknowledge&lt;/span&gt;(&lt;span class=&quot;code-snippet__selector-tag&quot;&gt;message&lt;/span&gt;, &lt;span class=&quot;code-snippet__selector-tag&quot;&gt;txn&lt;/span&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;服务端每个订阅都有一个PendingAckHandle对象用于管理事务Ack信息，我们可以认为它是管理消费者数据的RM。当Broker发现消息确认请求中带有事务信息，则会把这个请求转交给对应的PendingAckHandle处理。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;所有开启了事务的消息确认，不会直接修改游标上的MarkDeleted位置，而是先持久化到一个额外的Ledger中，Broker内存中也会缓存一份。这个Ledger由pendingAckStore管理，我们可以认为是Consumer RM的日志。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;事务提交时，RM会调用消费者对应的Subscription，执行刚才所有的消息确认操作。同时，也会在日志Ledger中写入一个特殊的Marker，标识事务需要提交。在事务回滚时，也会先在日志中记录一个AbortMarker，然后触发Message重新投递。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;pendingAckStore中保存的日志是redo log，该组件在初始化时，会先从日志Ledger中读取所有redo log，从而在内存中重建先前的消息确认信息。因为消息确认是幂等操作，如果Broker不慎宕机，只需要把redo log中的操作重新执行一遍。当订阅中的消息被真正确认掉后，pendingAckStore中对应的redo log也可以被清理了。清理方式很简单，只需要移动pendingAckStore中Ledger的MarkDelete位置即可。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;再谈TC&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;所有的事务提交、回滚，由于Client端告知TC，或者由于超时TC自动感知。TC的日志中保存了Producer的消息要发往哪些Partition，也保存了Consumer会Ack哪些Partition。RM分散在每个Broker上，记录了整个事务中发送的消息和要确认的消息。当事务结束时，TC则以TCID为key，找到所有的元数据，通过元数据得知需要通知哪些Broker上的RM，最后发起广播，通知这些Broker上的RM，事务需要提交/回滚。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7172996&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrbK0V07ic0bpjGtneYdUceRecMjY2d0b5LyTAhMWl1m2zpDmnian4yH3w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;237&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;尾声&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Pulsar中的设计细节非常多，由于篇幅有限，作者会整理一系列的文章进行技术分享，敬请期待。如果各位希望系统性地学习Pulsar，可以购买作者出版的新书《深入解析Apache Pulsar》。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrevrraf1PDxPtDLgR878NvqJzXL1oDjicfuLH5GXUiaEx9WCwqPIqHoGw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;800&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7172996&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrbK0V07ic0bpjGtneYdUceRecMjY2d0b5LyTAhMWl1m2zpDmnian4yH3w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;237&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;one more thing&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;目前，腾讯云消息队列 TDMQ Pulsar版（TDMQ for Pulsar，简称 TDMQ Pulsar 版）已开始正式商业化。消息队列 Pulsar 版是一款基于 Apache Pulsar 自研的消息中间件，具备极好的云原生和 Serverless 特性，兼容 Pulsar 的各个组件与概念，具备计算存储分离，灵活扩缩容的底层优势。&lt;/p&gt;&lt;p&gt;各位想要了解的请点击&lt;strong&gt;&lt;span&gt;阅读原文&lt;/span&gt;&lt;/strong&gt;。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img data-ratio=&quot;0.9005682&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtr7MEIL13us1GJqmL9GbIVqNibuWvRUPUQN0npXeOKf9ib24bW0nTpL1bg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1056&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;福利时间&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;您对TDMQ Pulsar 版有什么想要了解的？&lt;/p&gt;&lt;p&gt;评论区留言并分享文章至朋友圈&lt;/p&gt;&lt;p&gt;我们将在精选留言中随机抽送&lt;/p&gt;&lt;p&gt;作者的新书&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;1&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrZibXm4gicryjOsoViayYeIMbPNialybCaPg8enx1c0biaAgA9TF5vFiatqZA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;800&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;往期&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;推荐&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;/&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;/&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;/&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.7083333&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtr6IJiarfIRmfTUe1aJtFCX4MmaLDv46daUT7b3eLiawOd5tkUOyFfRgAg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;240&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;扫描下方二维码关注本公众号，&lt;/p&gt;&lt;p&gt;了解更多微服务、消息队列的相关信息！&lt;/p&gt;&lt;p&gt;解锁超多鹅厂周边！&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzAxMTQ2NTA1Mg==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHWNawqzp8TQs4V5GYqmicTFyQDmic421MtVbM6CtzaXgHe90DhmtAV7xc3IibnwnYY22rqnxYRMkkpmQ/0?wx_fmt=png&quot; data-nickname=&quot;腾讯云中间件&quot; data-alias=&quot;&quot; data-signature=&quot;腾讯云中间件官方账号。关注微服务、容器、API网关、消息中间件、DevOps、Serverless等云原生技术热点资讯，发布腾讯云中间件产品、用户手册、实践案例以及技术干货。定期举办技术沙龙，与你分享有效的技术解决方案。&amp;#10;&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5560488&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/dPkfGGYFSHXs01Cibwy5RkZQoRHXDCHtrSMcVQrKQIUtXcMw36pBTOnSicxxka0A1SEsmnAfphibDzqdsiaazyox3w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;901&quot;/&gt;&lt;span/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>001c77646b803ed0ff03ca895e4eb3fb</guid>
<title>联通实时计算平台演进与实践</title>
<link>https://toutiao.io/k/2jffo8z</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p&gt;&lt;span&gt;&lt;span&gt;▼ 关注「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;ApacheFlink&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，看更多大咖 &lt;span&gt;▼&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;section class=&quot;channels_iframe_wrp&quot;&gt;&lt;mpvideosnap class=&quot;js_uneditable custom_select_card channels_iframe&quot; data-pluginname=&quot;videosnap&quot; data-id=&quot;export/UzFfAgtgekIEAQAAAAAAIfAo6fRcAgAAAAstQy6ubaLX4KHWvLEZgBPEp4NwVktWdKf9zNPgMItrl5Mhr2DoxXs588ft2GGC&quot; data-url=&quot;https://findermp.video.qq.com/251/20304/stodownload?encfilekey=rjD5jyTuFrIpZ2ibE8T7YmwgiahniaXswqz3r3I8Eqaauz7wgtN95k5tq7DCzicHRRcNRNWb29vD2WYngSEk1Reic2dRCRjPicpZ86IUuLngHRibBY&amp;amp;adaptivelytrans=0&amp;amp;bizid=1023&amp;amp;dotrans=0&amp;amp;hy=SH&amp;amp;idx=1&amp;amp;m=&amp;amp;scene=0&amp;amp;token=x5Y29zUxcibAU8m3vT08KHocibQgUh7UNsMaJWhQJG4xIjIVribZJOUhMkfxEiahGhFicvjmqnlqicb3Y&quot; data-headimgurl=&quot;http://wx.qlogo.cn/finderhead/XxT9TiaJ1ibf3rFKHtt2yXrJpCDia37R3rjlyd6wzzicd55QmIWDrKHqRA/0&quot; data-username=&quot;v2_060000231003b20faec8c7e7881dc1dccd00ea35b077960b9c6a44e8a5c5efa3651fa144024c@finder&quot; data-nickname=&quot;ApacheFlink&quot; data-desc=&quot;联通大数据开发专家穆纯进，带你了解联通如何基于 Flink 构建新的平台架构。 #Flink #FFA2021&quot; data-nonceid=&quot;5437257292133464785&quot; data-type=&quot;video&quot;/&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section donone=&quot;shifuMouseDownCard(&#x27;shifu_c_008&#x27;)&quot; label=&quot;Copyright Reserved by PLAYHUDONG.&quot;&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;摘要：&lt;/strong&gt;&lt;/span&gt;本篇内容整理自联通大数据技术专家穆纯进在 Flink Forward Asia 2021 平台建设专场的演讲。主要内容包括：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;实时计算平台背景&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;实时计算平台演进与实践&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;基于 Flink 的集群治理&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;未来规划&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Tips：&lt;/strong&gt;点击&lt;/span&gt;&lt;span&gt;&lt;strong&gt;「阅读原&lt;/strong&gt;&lt;strong&gt;文」&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;查看原文视频 &amp;amp; 演讲PDF～&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n144&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;一、实时计算平台背景&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n144&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p cid=&quot;n145&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVggpKOFFA1z5bv7E03HIicU9ibr9ctvNP6ZCYnx68S6FfsJnToxPyDSabQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;首先了解一下实时计算平台的背景。电信行业的业务系统非常复杂，所以它的数据源也是非常多的，目前实时计算平台接入了 30 多种数据源，这 30 多种数据源相对于总的数据种类来说是比较小的。即使这样，我们的数据量也达到了万亿级别，每天有 600TB 的数据增量，而且我们接入的数据源种类和大小还在持续增长。平台的用户来自于全国 31 个省份公司以及联通集团的各个子公司，尤其是在节假日会有大量用户去做规则的订阅。用户想要获取数据，需要在平台上进行订阅，我们会将数据源封装成标准化的场景，目前我们有 26 种标准化场景，支撑了 5000 多个规则的订阅。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n149&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgKFwO6NAlOCbrem0rjT5ic9hJd7ibOpic6PcUY94sZDhoVrH0icyeCr2ibvw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;订阅场景有三大类。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;用户行为类的场景有 14 个，比如位置类的场景，是关于用户进入某个区域后停留了多长时间，还有终端登网，是关于用户连接了哪个网络，4G 还是 5G 网，以及漫游、语音、产品订购等各种场景；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;用户使用类的场景有 6 个，比如用户使用了多少流量、账户余额是多少、是否有欠费停机等；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;用户触网类的场景大概有 10 个，比如业务的办理、充值缴费，还有新入户入网等。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n161&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVg8BxPhBoE0GIeaTTQCqTaasXhgg6ibDZPQeOYlYslJ4anejKjRlqydcg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;对于实时计算平台来说，实时性的要求是很高的。数据从产生到进入我们的系统，大概有 5~20 秒的延迟，经过系统正常处理之后大概有 3~10 秒的延迟，我们允许的最大延迟是 5 分钟，所以必须做好实时计算平台端到端的延迟的监控。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;用户定义的场景符合要求的数据最少要下发一次，这个是有严格要求的，不能漏发，而 Flink 很好地满足了这个需求；数据的准确性要求需要达到 95%，平台实时下发的数据会保存一份到 HDFS 上，每天我们会抽取部分订阅和离线数据，按照相同的规则进行数据生成以及数据质量比对，如果差异过大就需要找到原因并保证后续下发数据的质量。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n164&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgk4wxKAVUFyLTrsrkBtCuAII7oFYryoRfSgQa29BZ8fZg1qaF3DyC9w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;本次分享更多的是 Flink 在电信行业的一次企业的深度实践：如何使用 Flink 更好地支撑我们的需求。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;通用的平台无法支撑我们的特殊场景，比如以位置类的场景为例，我们会在地图上画多个电子围栏，当用户进入围栏并在围栏里面停留一段时间，并且满足用户设定性别、年龄、职业、收入等用户特征，这样的数据才进行下发。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们的平台可以认为是一个实时场景中台，将数据进行实时的清洗处理，封装成支持多个条件组合的复杂场景，集约化地提供标准实时能力的同时，更进一步靠近业务，提供给业务方简单易用、门槛很低的接入方式。业务方通过调用标准化的接口，经过网关认证鉴权，才可以订阅我们的场景。订阅成功之后会将 Kafka 的一些连接信息和数据的 Schema 返回给订阅用户，用户订阅的筛选条件跟数据流进行匹配，匹配成功之后会以 Kafka 的形式再进行数据下发。以上就是我们的实时计算平台与下游系统交互的流程。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n169&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;二、实时计算平台演进与实践&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n169&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p cid=&quot;n170&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgicUISZgguJK3qpd9QnzaicWLPKjs2OE3CticJnGMTkEf3D87icGmkGmAQQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;2020 年以前，我们的平台是使用 Kafka + Spark Streaming 来实现的，而且是采购厂商的第三方的平台，遇到了很多问题和瓶颈，难以满足我们日常的需求。现在很多企业包括我们都正在进行数字化改革，系统的自研比例也越来越高，再加上需求的驱动，自研、可灵活定制、可控的系统是迫在眉睫了。所以 2020 年我们开始接触了 Flink，并实现了基于 Flink 的实时计算平台，这个过程中我们也体会到了开源的魅力，今后也会更多地参与到社区中来。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n172&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgOOq7Ogv9SREIyByxJTz7jyia4cQZTbNGETMJoNTsMyc9w6xxWCnnliaQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们的既往平台存在很多问题。首先是三方黑盒平台，我们使用厂商的第三方平台，过多依赖了外部系统；并且在大并发下外部系统的负载会非常高，不能灵活定制个性化的需求；Kafka 的负载也特别高，因为每一个规则的订阅都会对应多个 topic，所以随着规则的增加，topic 和分区的数量也会呈线性增长，导致延时比较高。每个订阅场景会对应多个实时流，而每个实时流都会占用内存和 CPU，场景过多会导致资源消耗增长以及资源负载过高；再就是支撑的体量小，支撑场景的订阅数有限的，比如逢年过节用户订阅的数量剧增，经常需要紧急救火，无法满足日益增长的需求；此外，监控粒度也不够，无法灵活定制监控，无法进行端到端的监控，采用人肉的排查比较多。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n174&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgUwkiczyhBfAcJrT5JXy9ktIHIyQecqicU4kbDdbGyD41k48Oxwrp5dOg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;基于上述问题，我们全面自研了基于 Flink 的实时计算平台，根据每个场景的特点进行最优的定制，最大化资源的使用效率。同时我们利用 Flink 的状态减少外部依赖，降低了程序的复杂度，提升程序的性能。通过灵活定制实现了资源的优化，相同体量的需求下大大节约了资源。同时为了保证系统的低延迟率，我们进行了端到端的监控，比如增加了数据的积压、延迟、数据断传监控。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;整个平台的架构比较简单，采用了 Flink on Yarn 的运行方式，外部只依赖 HBase，数据是以 Kafka 接入并由 Kafka 下发。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n177&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgK9ib7XjM6fZGhWpCsFfOdvJQE7KoO2zC55iag1rbooKpgcv6ia75Cyhsw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;Flink 的集群是独立搭建的，它独享了 550 台服务器，没有和离线计算混用，因为它对稳定性要求比较高,需要日均处理 1.5 万亿数据，近 600TB 的数据增量。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n179&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgia5bibKR5UicbQgO2JK3YCZEPXXc4vkgR3VNWqvL5RWs6gXXB5Szh52Dw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们对场景深度定制的主要原因是数据量大，同一个场景的订阅又非常多，而且每个订阅的条件又是不一样的。从 Kafka 读取一条数据的时候，这条数据要匹配多个规则，匹配中后才会下发到规则对应的 topic 里面。所以不管有多少订阅，只从 Kafka 中读取数据一次，这样能够降低对 Kafka 的消耗。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;手机打电话或者上网都会连接到基站，相同基站的数据会按一定的时长窗口和固定消息进行压缩，比如三秒钟一个窗口，或者消息达到了 1000 再进行触发，这样下游接收到的消息就会有量级的降低。然后是围栏匹配，外部系统的压力是基于基站规模的，而不是基于消息数目。再就是充分利用了 Flink 的状态，当人员进入和滞留的时候会存入状态，用 RocksDB 状态后端减少了外部依赖，简化了系统的复杂度。此外，我们还实现了亿级标签的关联不依赖外部系统。通过数据压缩、围栏匹配、进入驻留、标签关联后，我们才开始正式匹配规则。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;用户订阅场景后，订阅的规则会以 Flink CDC 的方式同步到实时计算平台，这样可以保证延迟比较低。由于人群的进入滞留会存入到状态，基于 RocksDB 的状态后端数据量比较大，我们会通过解析状态的数据进行问题排查，比如用户到底有没有在围栏之中。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n183&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgd9Ll6BrG6WkRb3pyTv1tadC91GMoGriauwvPRnL9LtiaoGMKFXkAH6LQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们自定义了 HASH 算法，在不依赖于外部系统的情况下，实现了亿级标签的关联。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;在大并发下，如果每个用户都要关联外部系统获取标签的信息，那么外部系统的压力会非常大，尤其是在我们联通这么大数据量的情况下，依赖于外部系统建设的成本也很高，这些标签都是离线标签，数据相对比较稳定，比如有日更的有月更的。所以我们对用户使用自定义的哈希算法，比如有个手机号，按照哈希算法它被分配到 index 为 0 的 task_0 实例中，再通过离线计算将标签文件中的手机号也按照相同的哈希算法分配到编号为 0 的 0_tag 中。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;task_0 实例在 open 方法中获取自己的 index 编号，即 index=0，然后拼接出标签文件名 0.tag，并将文件加载到自己的内存中。Task_0 实例接收到手机号后就可以从本地内存获取到此手机号的标签数据，不会造成内存的冗余浪费，提升了系统性能，减少了外部依赖。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;有标签更新的时候， open 方法也会自动加载新的标签，并刷新到自己的内存中。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n187&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVguIqdnWdBSaZ91Nt34SSXCz792ViaComqGhZSR9cSgxqPPHAOJWLNAfA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上图是我们做的端到端的时延监控。因为我们的业务对延迟要求比较高，所以我们进行了事件时间的打标，比如进出 Kafka 时间的打标，这里的事件就是消息。对于算子的延迟监控，我们根据打标的时间和当前的时间计算出延迟，这里并不是每条消息来了之后都去计算，而是采用抽样的方式。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;对积压断传也做了监控，是通过采集 Kafka offset 进行前后对比来判断的，另外还有对数据延迟的监控，利用事件的时间和当前的时间来计算延迟，可以监控上游系统的数据延迟。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n190&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgjAutksG72z07xaCA2RH6RxzibxT5ESvYMwiboia2yPJSCnsPC4zicdCSrg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上图是端到端延迟监控和反压监控的图表。可以看到端到端的延迟正常是在 2~6 秒之间，也符合我们的预期，因为定位的条件是比较复杂的。我们还对反压进行了监控，通过监控算子 input channel 的使用率来定位每个算子产生的反压，比如第二个图出现了严重的反压且持续了一段时间，这时候我们需要定位到具体的算子，然后去排查原因，来保证系统的低延迟。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n192&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgswFbIO7zM1YI1WvLNnL2lIQoicW1z0cZBCLyhao6LzPwXPbVNtYI7mg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上图是我们对 Kafka 集群中的每个 topic 分区的 offset，以及对每个消费者消费到的位置进行采集来定位它的断传和积压。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;首先制定一个 source 来获取 topic 列表和消费者组列表，再这些列表下发到下游，下游的算子可以采用分布式的方式去采集 offset 值，也是利用了 Flink 的特性。最后写入 Clickhouse 中进行分析。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n195&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVg7ThO5dl1kz5JkHzHZXfGvrqb3zo4TzJUfo9Z7khtHAjpefibMEmmjqA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Flink 日常监控主要包括以下几类：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;Flink 作业的监控、告警接入联通统一告警天眼平台；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;作业的运行状态、checkpoint 的异常耗时；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;算子的时延、反压、流量、条数；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;taskmanager CPU、内存的使用率，JVM GC 等指标的监控。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n202&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;三、基于 Flink 的集群治理&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n202&quot; mdtype=&quot;heading&quot;&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p cid=&quot;n203&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVg5WVrBib2kuBs3QgnXnJcLuGib9AFcQ2IqtL2g7eEWhsaPdibxDtJKicrTQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;我们还基于 Flink 搭建了我们的集群治理平台。搭建这个平台的背景是我们的总集群节点达到了 1 万多台，单集群最大有 900 个节点，总共 40 多个集群，总数据量单副本达到了 100 个 PB，每天有 60 万个作业运行，单个集群的 NameNode 的文件数最大达到了 1.5 亿。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n205&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVghalc0FQ43kIHx83kIwCsk6DjJQQKGIHlh7qRJI8JjfxnpB8HLehVcQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;随着公司业务的高速发展，数据的需求越来越复杂，所需要的算力也越来越大，集群的规模也越来越大，承载的数据产品也越来越多，导致 Hadoop 集群面临很大的挑战：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;文件数比较多对 nameNode 造成很大的压力，影响存储系统的稳定；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;小文件特别多，导致读取同样数据量的时候需要扫描更多文件，导致更多 NameNode RPC；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;空文件多，需要扫描更多的文件，导致更多的 RPC；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;平均文件比较小，从宏观上也体现出了小文件数比较多的；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;生产上会持续产生文件，作业输出的文件要进行调优；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;冷数据多，缺少清理的机制，浪费存储资源；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;资源负载高，而且扩容成本又太大，扩容了也无法支撑太长时间；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;作业耗时长影响产品的交付；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;作业消耗资源大，占用太多的 CPU、核数和内存；&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;作业存在数据倾斜，导致执行时间非常长。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n217&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgldBCXBqsf64jqmQHOozLTYxQiajQKeCO7JAFLoFmzcXJcJpa85GUbibQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;针对这些挑战，我们搭建了基于 Flink 的集群治理架构，通过采集资源队列的信息，解析 NameNode 的元数据文件 Fsimage，采集计算引擎的作业等信息等，然后对集群做 HDFS 画像、作业画像，数据血缘、冗余计算画像、RPC 画像以及资源画像。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n219&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgx8gIQ4ftXvBZBYaMDOsWof5gpyDicRiahuoGUjo5WicCZGcyQBN0x2Jcg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;资源画像：我们会同时对多个集群的多个资源队列的情况比如它的 IO、 metric 等进行分钟级的采集，可以实时查看整个集群和细分队列的资源使用趋势。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;存储画像：我们以无侵入的方式对多集群的分布式存储进行全局性的多维度的分析。比如文件数到底分布在哪里，小文件分布在哪里，空文件分布在哪里。对于冷数据的分布，我们对每个数据库每张表的分区目录也做了精细化的画像。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;作业画像：对多集群全产品线不同计算引擎的作业，我们进行实时采集，从时间维度、队列维度以及作业提交来源等多个维度，从耗时耗资源，数据倾斜、大吞吐量、高 RPC 的作业等多方面进行洞察，找出有问题的作业，筛选出那些待优化的作业。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;数据血缘：通过分析生产环境 10 万级别的 SQL 语句，绘制出无侵入的、全局的、高精准的数据血缘关系。并在任意周期内提供了数据表级/账户级的调用频次、数据表的依赖关系、产线加工的流程变更、加工故障的影响范围和垃圾表的洞察等功能。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;此外我们还做了用户操作审计和元数据方面的一些画像。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n225&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVggfO5gzbicddbIC2XIfbK7QnhWiaZbyoGY00VvnXqtUCElib3RTjpc1TFA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上图是集群治理存储大屏。除了一些宏观指标比如总文件数、空文件数、空文件夹，还有冷目录数、冷数据量和小文件的占比等。我们还对冷数据进行分析，比如哪些数据最后访问在某个月的数据量有多大，由此可以看到冷数据的时间分布；还有比如 10 兆以下、50 兆以下、100 兆以下的文件分布在哪些租户上。除了这些指标，还可以精确定位到哪个库、哪张表、哪个分区存在小文件。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;p cid=&quot;n227&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgKqIP7HYMHMgtBiaaGop6ibIQSODWQ7NLr6s1ZZyAU5nVA6A8aPia9KSMg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;上图是集群治理的效果展示，可以看到资源负载达到 100% 的时长也明显缩短，文件数降低了 60% 以上，RPC 负载也大幅降低。每年会有千万级别的成本节约，解决了长时间的资源紧张问题，降低了扩容的机器数。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p cid=&quot;n230&quot; mdtype=&quot;heading&quot;&gt;&lt;strong&gt;四、未来规划&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;h2 cid=&quot;n230&quot; mdtype=&quot;heading&quot;&gt;&lt;span/&gt;&lt;br/&gt;&lt;/h2&gt;&lt;p cid=&quot;n231&quot; mdtype=&quot;paragraph&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVg0NffmgNZ5HpWYaII9TLjLgh9sib63kFeUiaprXxjHMe3MTJlrrcM32oQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1920&quot;/&gt;&lt;/p&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;目前我们还没有一个完善的实时流管理平台，且监控比较分散，研发通用的管理和监控平台势在必行。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;面对日益增长的需求，深度定制化虽然节约了资源，提升了支撑的规模，但是它的开发效率并不理想。针对数据量不大的场景，我们也考虑了使用 Flink SQL 来搭建通用的平台，以此来提升研发效率。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;最后，我们还会继续探索 Flink 在数据湖中的应用。&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;往期精选&lt;/p&gt;&lt;/section&gt;&lt;img data-ratio=&quot;2&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgRUS0CdtOd2icibfE0Ht0RW2j29q3effuz3GvVff3n0AvUuNPeCwFF0kw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;50&quot;/&gt; &lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247495906&amp;amp;idx=1&amp;amp;sn=8806069228df05ec3633de7a1e305227&amp;amp;chksm=fd387ea0ca4ff7b61fcde0d8b7b051b2ce91fa3bbda96789d9dc62fe1fb08077eb5a2d16e626&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4255556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgSFLCtrDvzH5KJlSjkYZO4TdngQcmkqFCgib8icaQdrQxtsicxoQ4uK1nQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247495878&amp;amp;idx=1&amp;amp;sn=d63bdeb4c790faf999bc038cd19131d5&amp;amp;chksm=fd387e84ca4ff792a0931917d19bbe6c28026f9ea09e0f1097b3626a84c851cb9afeaf763c0f&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4255556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgxTeRtdttl68oyksHFSk6OYnYeB3D35L59fLfoicQHfQibqn08aW13Nqg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;amp;mid=2247495824&amp;amp;idx=1&amp;amp;sn=332b9bb80a24856197485263c28fd093&amp;amp;chksm=fd387ed2ca4ff7c49add188b5565b8c1442df933b24b39965a2dcd88ebb4f92156cbaf0e2f0a&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;你已选中了添加链接的内容&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;1&quot;&gt;&lt;span class=&quot;js_jump_icon h5_image_link&quot; data-positionback=&quot;static&quot;&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-ratio=&quot;0.4255556&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/8AsYBicEePu7ibxvlEE3tJu8zI2yUjeoVgbf3mXydGiaqXibM3k0uuYu0gU8mxzibFsHAvlEtkkaeXdkZrJGsJGAo0g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;900&quot;/&gt;&lt;/span&gt;&lt;/a&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;span&gt;▼ 关注「&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;Apache Flink&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;」，获取更多技术干货 &lt;span&gt;▼&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzU3Mzg4OTMyNQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6FJHxaI14AsXuzeg4SybT0hiaCSohrIY75oiaOMzhQU7RouiafjNa76k2CtD6xxB2JqnawqFqV3zg3A/0?wx_fmt=png&quot; data-nickname=&quot;Apache Flink&quot; data-alias=&quot;apacheflinkcc&quot; data-signature=&quot;Flink 中文社区官微，Flink PMC 维护&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;更多 Flink 相关技术问题，可扫码加入社区钉钉交流群～&lt;/span&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-fileid=&quot;100010716&quot; data-ratio=&quot;1.2078189300411524&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/8AsYBicEePu6PUTQaA1BP3Fb8uViccQpspmTibIYEfM7Wv6VACia9CDQfcN8huMVCafZ5s36wThUmbYRTOzMu4hd8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;972&quot;/&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt; &lt;img class=&quot;__bg_gif rich_pages wxw-img&quot; data-fileid=&quot;100010714&quot; data-ratio=&quot;1&quot; data-type=&quot;gif&quot; data-w=&quot;400&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_gif/Z6bicxIx5naLWBBEcl44aIic1Mthe1nZiaramW5s4e8WwyCYYbTzu6uPBpgI6sxNXNymEnOYKpJpcrItUia7lS64mA/640?wx_fmt=gif&quot;/&gt;  &lt;/span&gt;&lt;strong&gt;&lt;span&gt;戳我，查看原文视频&amp;amp;演讲PDF～&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>88193461767b2e95eb0722f8e60347b4</guid>
<title>Robinhood的下一代数据湖实践</title>
<link>https://toutiao.io/k/u7yxbz0</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;p class=&quot;original_area_primary&quot;&gt;
                                                                                                &lt;/p&gt;

                    
                                            &lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/brR21T72gFoWhGo4DiaYCEmu6mdw0Wiaiawic5AQkUpwBlS4lkH7Y5MwrxRW6mYLCOq85PpfYChd2O2k1r3GlteNsg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;1. 摘要&lt;br/&gt;&lt;/h2&gt;&lt;p&gt;Robinhood 的使命是使所有人的金融民主化。Robinhood 内部不同级别的持续数据分析和数据驱动决策是实现这一使命的基础。我们有各种数据源——OLTP 数据库、事件流和各种第 3 方数据源。需要快速、可靠、安全和以隐私为中心的数据湖摄取服务来支持各种报告、关键业务管道和仪表板。不仅在数据存储规模和查询方面，也在我们在数据湖支持的用例方面，我们从&lt;span&gt;最初的数据湖版本&lt;sup&gt;[1]&lt;/sup&gt;&lt;/span&gt;都取得了很大的进展。在这篇博客中，我们将描述如何使用各种开源工具构建基于变更数据捕获的增量摄取，以将我们核心数据集的数据新鲜延迟从 1 天减少到 15 分钟以下。我们还将描述大批量摄取模型中的局限性，以及在大规模操作增量摄取管道时学到的经验教训。&lt;/p&gt;&lt;h2&gt;2. 数据湖和生态系统&lt;/h2&gt;&lt;p&gt;&lt;span&gt;Robinhood 的数据湖存储和计算基础架构是为我们的许多数据驱动功能提供支持的基石，例如业务分析仪表板和产品改进见解。它也是为业务和临时报告和分析运行大规模数据处理的数据源。此外，生态系统会影响以隐私为中心的原语，例如旨在保护用户隐私的匿名化和访问控制。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6634865568083261&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/brR21T72gFoOURdumu7v8q0yr4afibZKDxpiccSO783kBlb0XpNdqYwAXvYicdqrxQp3cpz1EiazlekWcTVzxMVlog/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1153&quot;/&gt;&lt;/p&gt;&lt;figure&gt;&lt;figcaption&gt;&lt;br/&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;span&gt;主要的 OLTP（在线事务处理）数据库由 Postgres RDS 管理；Amazon S3 是 Data Lake 存储，它为我们的 Data Lake 提供经济高效且可扩展的存储层；我们主要使用 Apache Spark 运行生产批处理管道；我们的仪表板由 Trino 分布式 SQL 查询引擎提供支持；Apache Hadoop Yarn 管理用于运行 Apache Spark 作业的计算集群；Apache Hive Metastore 为查询引擎管理和提供表模式；Apache Airflow 是工作流编排服务。下图是具有计算生态系统的数据湖&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.51484375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/brR21T72gFoOURdumu7v8q0yr4afibZKDcaRsxnJ9XO7QydqFdlww6xYLNWYr8opEd1n322UzNiamV2dwLVibPiavA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;在整篇文章中我们使用指标“数据新鲜度”来比较下面不同的数据摄取架构，此指标为源数据库中的表中发生的更改在相应的 Data Lake 表中可见提供了时间延迟。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;3. 大批量摄取的限制&lt;/h2&gt;&lt;p&gt;作为数据湖演进的第一步，我们首先使用在线数据库的只读副本获取在线数据库的每日快照。摄取这些表的完整快照会导致数据湖表的写入放大率很高。即使对于一个有数十亿行的表来说，一天只有几十万行的变化，摄取该表的完整快照也会导致读取和写入整个表。此外当使用实时副本（而不是作为上游的数据库备份）时，在只读副本 I/O 性能方面会出现瓶颈，这会导致快照时间过长，从而导致较大的摄取延迟。即使采用了诸如通过分区读取并行化 I/O 之类的技术，这种摄取架构也无法在一小时内交付数据。Robinhood 确实需要保持数据湖的低数据新鲜度。许多过去在市场交易时间之后或之前以每日节奏运行的批处理管道必须以每小时或更高的频率运行，以支持不断发展的用例。很明显我们需要更快的摄取管道将在线数据库复制到数据湖。&lt;/p&gt;&lt;h2&gt;4. 新架构&lt;/h2&gt;&lt;p&gt;实现 Data Lake 较低数据新鲜度的更好方法是增量摄取。增量摄取是一种众所周知的技术，用于为数据湖构建有效的摄取管道。在这里摄取管道不是拍摄快照并将它们作为一个整体转储到 Data Lake，而是以流方式使用 OLTP 数据库的预写日志并将它们摄取到 Data Lake 表中，就像数据库到数据库复制的方式一样。从概念上讲，我们有一个两阶段管道。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;变更数据捕获 (CDC) 服务使用 OLTP 数据库中的预写日志 (WAL) 数据并将它们缓冲在变更日志队列中。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;数据摄取作业定期或以连续方式拖尾队列并更新数据湖“原始”表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图是增量摄取组件&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.39609375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/brR21T72gFoOURdumu7v8q0yr4afibZKDP4aAwpcAYh6luyx8ScyDniaxMFI3EPxkvyFHibbMicKAXbe5yY8y6MceA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;中间更改日志队列允许分离两个阶段之间的关注点，这两个阶段将能够独立运行，并且每个阶段都可以暂停而不影响另一个阶段。队列提供了必要的隔离，以便将数据摄取到数据湖的任何延迟都不会对 CDC 造成背压。在第一阶段，我们选择 Debezium 作为变更数据捕获 (CDC) 提供商。Debezium 是一个构建在 Kafka Connect 之上的开源分布式变更数据捕获平台，Debezium 带有一个经过充分证明的一流 Postgres CDC 连接器。根据我们的基准测试，我们发现 Debezium 可以轻松处理我们预计的负载量，我们已经设置 Debezium 使用开源的 Confluent Schema Registry 以 avro 编码格式将更改记录写入 Kafka，与 json 编码相比，Avro 编码提供了更好的性能。在第二阶段，我们使用 Apache Hudi 从 Kafka 增量摄取变更日志，以创建数据湖表。Apache Hudi 是一个统一的数据湖平台，用于在数据湖上执行批处理和流处理，Apache Hudi 带有一个功能齐全的基于 Spark 的开箱即用的摄取系统，称为 Deltastreamer，具有一流的 Kafka 集成和一次性写入功能，与不可变数据不同，我们的 CDC 数据有相当大比例的更新和删除，Hudi Deltastreamer 利用其可插入的记录级索引在 Data Lake 表上执行快速高效的 upserts，Hudi 通过自动清理旧文件版本、数据Clustering、Hive表模式同步和文件大小调整来自我管理其表，以写入大小合适的文件，原始表当前以 Hudi 的写时复制模式存储，该模式提供原生列式读取性能。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;5. 效果总结&lt;/h2&gt;&lt;p&gt;&lt;span&gt;我们已经部署了增量摄取管道，以将 1000 个 Postgres 表摄取到数据湖中。在新架构之前，由于快照的限制和所涉及的成本，这些表只能保证能够以每天的节奏进行快照。 &lt;/span&gt;&lt;strong&gt;使用这种新架构，Data Lake 用户很高兴看到关键表的数据新鲜度从 24 小时缩短到 15 分钟以下。&lt;/strong&gt;&lt;span&gt; 大批量快照运行时间显示快照表的运行时间长。请注意由于只读副本 I/O 瓶颈，其中许多表的快照需要按顺序运行。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6183333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/brR21T72gFoOURdumu7v8q0yr4afibZKDqqjVROCicgVaHta0fwuYhRicoSbpDp5T5EKiaBmOnGhOXVRUoHTnjYhzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1200&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;显示大批量快照的大批量快照运行计划每天仅运行一次，这是因为从数据库中快照所有表的周转时间很长。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.68984375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/brR21T72gFoOURdumu7v8q0yr4afibZKDXmu1uHYxZaicibg6ribltfjRBevToyegnM8a2mOvkIvNz9ulZyMiab1nMA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;新的增量摄取数据新鲜度显示新摄取系统的端到端数据新鲜度约为 5 分钟。&lt;/strong&gt;&lt;span/&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7078125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/brR21T72gFoOURdumu7v8q0yr4afibZKDTMY4ODj6a862Yw3LZexbA1aFVPCft69diaxN5pk6WibnAAuUhbpockRw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;h2&gt;6. 经验教训&lt;/h2&gt;&lt;p&gt;在本节中我们将分享在大规模构建增量摄取管道时学到的经验教训。我们希望这对任何希望为他们的数据湖踏上类似旅程的人来说都是有价值的。&lt;/p&gt;&lt;h2&gt;7. 可缩放的初始引导程序&lt;/h2&gt;&lt;p&gt;对数据湖的增量摄取仍然需要源表的初始快照。Debezium 确实提供了初始快照模式，但需要查询主 RDS 实例，我们不想查询主 RDS 实例以进行快照，以避免生产 OLTP 查询与初始快照查询之间的任何资源竞争。此外，我们需要通过以无锁方式运行并发分区查询以及从数据库备份中获取快照来优化初始快照时间的能力。出于这些原因，我们在 Apache Hudi Deltastreamer 之上提供了专用的只读副本并实现了一个自定义快照器，它利用 Spark 运行并发分区快照查询来获取表的初始快照，Apache Hudi 的可插拔源框架允许我们用几行代码无缝实现这一点。对于带外初始快照，我们需要在增量摄取和快照之间切换时仔细跟踪 CDC 流中的正确水印，使用 Kafka，数据摄取作业的 CDC 水印转换为 Kafka 偏移量，这标志着要应用于快照表的开始更改日志事件，如果我们选择一个任意的 Kafka 偏移量，我们最终可能会错过一些应用到 Data Lake 表的更改事件。&lt;/p&gt;&lt;p&gt;从概念上讲，我们需要 3 个阶段来执行正确的快照并过渡到增量摄取：&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;保存最新的 Kafka 偏移量，以在切换到增量摄取时用于重播变更日志。设“Tₛ”为最新事件的源时间。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;确保只读副本在时间“Tₛ + Δ”时是最新的，其中 Δ 表示捕获 kafka 偏移量以及额外缓冲时间时的 Debezium 延迟。否则，整个方程式将无法保证 0% 的数据丢失。从只读副本中获取表的初始快照并创建 Data Lake 表&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;从之前存储的 kafka 偏移量开始消费并执行表的增量摄取。一旦增量摄取开始发生，将配置单元表定义同步到数据的最新位置，下游消费者现在将能够查询新引导的表。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;下图是使用引导架构的增量摄取架构&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.45625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/brR21T72gFoOURdumu7v8q0yr4afibZKDaU2U3OVyRHZU8nm8ufy2lxjI93EKkwQkKVib34lZHNXlr5QUYEZibeKg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;从专用只读副本进行快照具有局限性，例如副本端的 I/O 瓶颈以及 24 * 7 在线维护只读副本的成本开销。我们正在探索一种对 OLTP 数据库进行按需备份并使用 AWS S3 导出发布到 S3 的方法。然后我们可以依靠大规模处理这些 S3 导出并构建初始快照，这种机制可能允许更快的快照并克服只读副本端的一些 I/O 瓶颈。&lt;/span&gt;&lt;/p&gt;&lt;h2&gt;8. 使用 Postgres 逻辑复制监控背压风险&lt;/h2&gt;&lt;p&gt;Postgres 逻辑复制需要 CDC 连接器直连主 RDS。Postgres 逻辑复制协议保证保留 WAL 日志文件，直到 Debezium 完全处理它们。如果 Debezium 卡住或无法跟上消耗 WAL 日志的速度，这可能会导致 WAL 日志文件累积并耗尽可用磁盘空间，Debezium 社区建议密切监视滞后消息，我们的 Debezium 负载测试也让我们对 Debezium 能够处理预计的变更速度增加充满信心。&lt;/p&gt;&lt;h2&gt;9. 自动化恢复&lt;/h2&gt;&lt;p&gt;从每日快照切换到增量摄取的副作用之一是摄取工作流变得有状态。管道可能处于快照或增量摄取状态。此外，还需要执行架构升级、监控和数据质量验证等其他操作，新表和数据库需要定期地加入。端到端管道涉及不同的系统——在线 CDC 世界和数据湖的批处理/流摄取。为 1000 个表执行入职和常规操作需要适当的状态管理和自动化。我们意识到我们需要在内部构建一流的编排服务，该服务将利用 Apache Airflow 来管理摄取管道、跟踪载入和表状态并自动处理状态转换和其他维护，这有助于我们大规模运营管道。&lt;/p&gt;&lt;h2&gt;10. 并非所有表都是平等的&lt;/h2&gt;&lt;p&gt;当谈到这些表对我们的关键用例的重要性时，pareto原则是有效的，我们有一小部分关键表需要在 15 分钟内保证数据新鲜度，我们采取了一种方法，根据表的重要性将表分类为不同的层，高度关键的表被标记为第 0 层，对于这些表，我们提供了一个单独的 CDC 复制槽，以将这些关键表的 CDC 通道与其他表的通道隔离。此外我们为 Hudi deltastreamer 提供了专门的资源，以持续摄取增量更改日志，并能够在 5 -15 分钟内保持数据最新。对于较低优先级的表，Hudi deltastreamer 配置为以批处理模式每 15 分钟运行一次。&lt;/p&gt;&lt;h2&gt;11. 管理 Postgres 模式更新&lt;/h2&gt;&lt;p&gt;我们的业务是将表从在线 OLTP 世界复制到 Data Lake 世界，复制的数据不是不透明的，而是具有适当的模式，并且复制管道保证了将在线表模式转换为数据湖的模式的明确定义的行为。鉴于 Data Lakes 还能够存储数据更改的整个历史，因此在线和 Data Lake 世界的向后兼容性意味着什么不同。例如，在在线世界中，向 postgres 添加一个不可为空的列是非常好的，但不会遵守用于存储动态变更日志的 Avro（或 Protobuf）的模式演变规则。拥有明确定义的架构演化合约有助于保持数据湖管道更加稳定。我们发现大多数时候，Schema更改涉及添加新列，我们正在使用 Debezium 功能来冻结我们从 Postgres 表中读取的列集，并依靠重新引导表来处理模式升级，我们计划为端到端管道添加模式兼容性检测机制，以减少重新引导的次数。&lt;/p&gt;&lt;h2&gt;12. 未来规划&lt;/h2&gt;&lt;p&gt;我们看到使用增量摄取的原始数据湖表的采用速度更快，并且我们正在不断努力提高管道的可靠性。以下是我们正在着手的一些后续步骤：&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;数据质量保证：我们实施了以不同频率运行的通用和自定义数据质量和完整性检查，以发现复制数据中的差异，我们正在努力利用 Apache Hudi 的预提交验证支持在每批提交之前运行自定义验证。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;进一步减少数据新鲜度滞后：我们目前使用的是 Apache Hudi Copy-On-Write 格式。在这种模式下，我们可以看到大约 5-15 分钟范围内的数据新鲜度，我们计划探索 Apache Hudi 的 Merge-On-Read 格式，以进一步降低数据新鲜度。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;流式数据湖：Apache Hudi 提供增量处理能力，就像数据库变更日志一样，我们未来的工作涉及使用这种原语并构建端到端流管道以有效地将更改渗透到下游表，这也将使我们能够以实时流媒体的方式执行隐私保护操作，例如屏蔽和匿名化。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;用于服务间数据交换的 CDC 服务：CDC 已在 Robinhood 中用于为数据湖的增量摄取提供更改流，我们正在研究使用 CDC 流在各种在线微服务之间进行可靠的数据交换。&lt;/span&gt;&lt;span&gt;&lt;span&gt;•&lt;/span&gt;数据计算：我们一直致力于提高基于 Apache Spark 和 Trino 构建的数据计算平台的可用性、效率和性能，以支持关键数据计算工作负载。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;这些是在 Robinhood 数据基础设施团队工作的激动人心的时刻，因为我们已经开始构建下一代 Robinhood 数据湖。&lt;/p&gt;&lt;section class=&quot;mp_profile_iframe_wrp&quot;&gt;&lt;mpprofile class=&quot;js_uneditable custom_select_card mp_profile_iframe&quot; data-pluginname=&quot;mpprofile&quot; data-id=&quot;MzIyMzQ0NjA0MQ==&quot; data-headimg=&quot;http://mmbiz.qpic.cn/mmbiz_png/brR21T72gFrSJYpz6hjcEOYH86LMkT7PhEydJe1NtcENI8CvRygysXmDjUnlzobK6f2OkrwWfOWkqwfRia4fmnw/0?wx_fmt=png&quot; data-nickname=&quot;ApacheHudi&quot; data-alias=&quot;ApacheHudi&quot; data-signature=&quot;Apache Hudi是一个支持插入、更新、删除的增量数据湖处理框架；可助力构建高效的企业级数据湖。&quot; data-from=&quot;0&quot;/&gt;&lt;/section&gt;&lt;h4&gt;推荐阅读&lt;/h4&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzIyMzQ0NjA0MQ==&amp;amp;mid=2247488278&amp;amp;idx=2&amp;amp;sn=0ff28400db53197bd3e52b15f4364ba5&amp;amp;chksm=e81f4660df68cf76a3631322f7008cc49772a6ddb7eb4bc29c17a991a894f4e9bef69b7c59b8&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;字节跳动基于Apache Hudi的数据湖集成实践&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;字节跳动基于Apache Hudi的数据湖集成实践&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzIyMzQ0NjA0MQ==&amp;amp;mid=2247488110&amp;amp;idx=2&amp;amp;sn=a3316b285b8ee8880e4ebbfbd2bc9c9d&amp;amp;chksm=e81f4718df68ce0ea7ed5150e3e93cf9d6c1b1ada28077f5015dd40e162fdce4155b6d88875d&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;使用Apache RocketMQ + Hudi 快速构建 Lakehouse&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;使用Apache RocketMQ + Hudi 快速构建 Lakehouse&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzIyMzQ0NjA0MQ==&amp;amp;mid=2247488084&amp;amp;idx=1&amp;amp;sn=045d2f08a3d7e8fceb69f2bf4825e9c8&amp;amp;chksm=e81f4722df68ce34d20fd1586f58eacbb707b5a610fc4bee9c277092288cf56b0e179255cc3e&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;字节跳动数据湖技术选型的思考&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;11&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;字节跳动数据湖技术选型的思考&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=MzIyMzQ0NjA0MQ==&amp;amp;mid=2247488078&amp;amp;idx=1&amp;amp;sn=662489eac0736f5bbf3c84fa51088cc6&amp;amp;chksm=e81f4738df68ce2e3050900c0fa7ccbc5e668daced9858fcb2013b99aaf29188555c761a00e2&amp;amp;scene=21#wechat_redirect&quot; textvalue=&quot;重磅！基于Apache Hudi的商业公司Onehouse成立&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; imgdata=&quot;null&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;重磅！基于Apache Hudi的商业公司Onehouse成立&lt;/a&gt;&lt;br/&gt;&lt;/section&gt;&lt;h4&gt;引用链接&lt;/h4&gt;&lt;p&gt;&lt;code&gt;[1]&lt;/code&gt; 最初的数据湖版本: &lt;em&gt;[https://robinhood.engineering/data-lake-at-robinhood-3e9cdf963368](https://robinhood.engineering/data-lake-at-robinhood-3e9cdf963368)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img&quot; data-galleryid=&quot;&quot; data-ratio=&quot;0.52&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3EcuPIickyyEwbzUrMVnXJaXicEHYVRUz1Xar9X3Tic8ZUNJ3IfuVNP8wUpaKiafwYOY6lfXjlYbcJUJklKI7psbsg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>