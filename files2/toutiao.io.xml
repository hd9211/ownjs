<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>73284fc8941ed16fcde4a5a0ec7a0586</guid>
<title>跟 Kafka 学技术系列之时间轮</title>
<link>https://toutiao.io/k/77iozz6</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;src-views-article-detail-main-module__content--2qOBd markdown-body&quot;&gt;&lt;h1&gt;写在前面&lt;/h1&gt;
&lt;p&gt;kafka是一个分布式消息中间件，其高可用高吞吐的特点是大数据领域首选的消息中间件，Kafka是分布式消息队列的顺序读写文件分段组织串联起来思想的鼻祖，包括RocketMq这些消息队列都是借鉴了Kafka早期的架构和设计思路改造而来，所以在架构设计层面，Kafka有非常多值得借鉴的地方。本文是作者介绍Kafka优秀架构设计文章中的一篇，文中的代码和流程图均是base on 0.10.2.0版本。&lt;/p&gt;
&lt;h1&gt;引出环形队列和延迟队列&lt;/h1&gt;
&lt;p&gt;从2个面试题说起，第1个问题，如果一台机器上有10w个定时任务，如何做到高效触发？&lt;/p&gt;
&lt;p&gt;具体场景是：&lt;/p&gt;
&lt;p&gt;有一个APP实时消息通道系统，对每个用户会维护一个APP到服务器的TCP连接，用来实时收发消息，对这个TCP连接，有这样一个需求：“如果连续30s没有请求包（例如登录，消息，keepalive包），服务端就要将这个用户的状态置为离线”。&lt;/p&gt;
&lt;p&gt;其中，单机TCP同时在线量约在10w级别，keepalive请求包较分散大概30s一次，吞吐量约在3000qps。&lt;/p&gt;
&lt;p&gt;怎么做？&lt;/p&gt;
&lt;p&gt;常用方案使用time定时任务，每秒扫描一次所有连接的集合Map&amp;lt;uid, last_packet_time&amp;gt;，把连接时间（每次有新的请求更新对应连接的连接时间）比当前时间的差值大30s的连接找出来处理。&lt;/p&gt;
&lt;p&gt;另一种方案，使用环形队列法：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200308202309477.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1poaVp1aUNodW5GZW5n,size_16,color_FFFFFF,t_70&quot; alt=&quot;小桔车服 &amp;gt; 跟Kafka学技术-时间轮 &amp;gt; image2020-1-17_16-20-37.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;三个重要的数据结构：&lt;/p&gt;
&lt;p&gt;1）30s超时，就创建一个index从0到30的环形队列（本质是个数组）&lt;/p&gt;
&lt;p&gt;2）环上每一个slot是一个Set&amp;lt;uid&amp;gt;，任务集合&lt;/p&gt;
&lt;p&gt;3）同时还有一个Map&amp;lt;uid, index&amp;gt;，记录uid落在环上的哪个slot里&lt;/p&gt;
&lt;p&gt;这样当有某用户uid有请求包到达时：&lt;/p&gt;
&lt;p&gt;1）从Map结构中，查找出这个uid存储在哪一个slot里&lt;/p&gt;
&lt;p&gt;2）从这个slot的Set结构中，删除这个uid&lt;/p&gt;
&lt;p&gt;3）将uid重新加入到新的slot中，具体是哪一个slot呢 =&amp;gt; Current Index指针所指向的上一个slot，因为这个slot，会被timer在30s之后扫描到&lt;/p&gt;
&lt;p&gt;4）更新Map，这个uid对应slot的index值&lt;/p&gt;
&lt;p&gt;哪些元素会被超时掉呢？&lt;/p&gt;
&lt;p&gt;Current Index每秒种移动一个slot，这个slot对应的Set&amp;lt;uid&amp;gt;中所有uid都应该被集体超时！如果最近30s有请求包来到，一定被放到Current Index的前一个slot了，Current Index所在的slot对应Set中所有元素，都是最近30s没有请求包来到的。&lt;/p&gt;
&lt;p&gt;所以，当没有超时时，Current Index扫到的每一个slot的Set中应该都没有元素。&lt;/p&gt;
&lt;p&gt;两种方案对比：&lt;/p&gt;
&lt;p&gt;方案一每次都要轮询所有数据，而方案二使用环形队列只需要轮询这一刻需要过期的数据，如果没有数据过期则没有数据要处理，并且是批量超时，并且由于是环形结构更加节约空间，这很适合高性能场景。&lt;/p&gt;
&lt;p&gt;第二个问题：在开发过程中有延迟一定时间的任务要执行，怎么做？&lt;/p&gt;
&lt;p&gt;如果不重复造轮子的话，我们的选择当然是延迟队列或者Timer。&lt;/p&gt;
&lt;p&gt;延迟队列和在Timer中增 加延时任务采用数组表示的最小堆的数据结构实现，每次放入新元素和移除队首元素时间复杂度为O(nlog(n))。&lt;/p&gt;
&lt;h1&gt;时间轮&lt;/h1&gt;
&lt;p&gt;方案二所采用的环形队列，就是时间轮的底层数据结构，它能够让需要处理的数据（任务的抽象）集中，在Kafka中存在大量的延迟操作，比如延迟生产、延迟拉取以及延迟删除等。Kafka并没有使用JDK自带的Timer或者DelayQueue来实现延迟的功能，而是基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）。JDK的Timer和DelayQueue插入和删除操作的平均时间复杂度为O(nlog(n))，并不能满足Kafka的高性能要求，而基于时间轮可以将插入和删除操作的时间复杂度都降为O(1)。时间轮的应用并非Kafka独有，其应用场景还有很多，在Netty、Akka、Quartz、Zookeeper等组件中都存在时间轮的踪影。&lt;/p&gt;
&lt;h2&gt;时间轮的数据结构&lt;/h2&gt;
&lt;p&gt;参考下图，Kafka中的时间轮（TimingWheel）是一个存储定时任务的环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表（TimerTaskList）。TimerTaskList是一个环形的双向链表，链表中的每一项表示的都是定时任务项（TimerTaskEntry），其中封装了真正的定时任务TimerTask。在Kafka源码中对这个TimeTaskList是用一个名称为buckets的数组表示的，所以后面介绍中可能TimerTaskList也会被称为bucket。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200308202645122.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1poaVp1aUNodW5GZW5n,size_16,color_FFFFFF,t_70&quot; alt=&quot;时间轮组成&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;时间轮相关名词解释&lt;/h2&gt;
&lt;p&gt;tickMs：时间轮由多个时间格组成，每个时间格就是tickMs，它代表当前时间轮的基本时间跨度。&lt;/p&gt;
&lt;p&gt;wheelSize：代表每一层时间轮的格数&lt;/p&gt;
&lt;p&gt;interval：当前时间轮的总体时间跨度，interval=tickMs × wheelSize&lt;/p&gt;
&lt;p&gt;startMs：构造当层时间轮时候的当前时间，第一层的时间轮的startMs是TimeUnit.NANOSECONDS.toMillis(nanoseconds()),上层时间轮的startMs为下层时间轮的currentTime。&lt;/p&gt;
&lt;p&gt;currentTime：表示时间轮当前所处的时间，currentTime是tickMs的整数倍（通过currentTime=startMs - (startMs % tickMs来保正currentTime一定是tickMs的整数倍），这个运算类比钟表中分钟里65秒分针指针指向的还是1分钟）。currentTime可以将整个时间轮划分为到期部分和未到期部分，currentTime当前指向的时间格也属于到期部分，表示刚好到期，需要处理此时间格所对应的TimerTaskList的所有任务。&lt;/p&gt;
&lt;h2&gt;时间轮中的任务存放&lt;/h2&gt;
&lt;p&gt;若时间轮的tickMs=1ms，wheelSize=20，那么可以计算得出interval为20ms。初始情况下表盘指针currentTime指向时间格0，此时有一个定时为2ms的任务插入进来会存放到时间格为2的TimerTaskList中。随着时间的不断推移，指针currentTime不断向前推进，过了2ms之后，当到达时间格2时，就需要将时间格2所对应的TimeTaskList中的任务做相应的到期操作。此时若又有一个定时为8ms的任务插入进来，则会存放到时间格10中，currentTime再过8ms后会指向时间格10。如果同时有一个定时为19ms的任务插入进来怎么办？新来的TimerTaskEntry会复用原来的TimerTaskList，所以它会插入到原本已经到期的时间格1中。总之，整个时间轮的总体跨度是不变的，随着指针currentTime的不断推进，当前时间轮所能处理的时间段也在不断后移，总体时间范围在currentTime和currentTime+interval之间。&lt;/p&gt;
&lt;h2&gt;时间轮的升降级&lt;/h2&gt;
&lt;p&gt;如果此时有个定时为350ms的任务该如何处理？直接扩充wheelSize的大小么？Kafka中不乏几万甚至几十万毫秒的定时任务，这个wheelSize的扩充没有底线，就算将所有的定时任务的到期时间都设定一个上限，比如100万毫秒，那么这个wheelSize为100万毫秒的时间轮不仅占用很大的内存空间，而且效率也会拉低。Kafka为此引入了层级时间轮的概念，当任务的到期时间超过了当前时间轮所表示的时间范围时，就会尝试添加到上层时间轮中&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200308202605415.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1poaVp1aUNodW5GZW5n,size_16,color_FFFFFF,t_70&quot; alt=&quot;时间轮升降级&quot;/&gt;&lt;/p&gt;
&lt;p&gt;参考上图，复用之前的案例，第一层的时间轮tickMs=1ms, wheelSize=20, interval=20ms。第二层的时间轮的tickMs为第一层时间轮的interval，即为20ms。每一层时间轮的wheelSize是固定的，都是20，那么第二层的时间轮的总体时间跨度interval为400ms。以此类推，这个400ms也是第三层的tickMs的大小，第三层的时间轮的总体时间跨度为8000ms。&lt;br/&gt;
刚才提到的350ms的任务，不会插入到第一层时间轮，会插入到interval=20*20的第二层时间轮中，具体插入到时间轮的哪个bucket呢？先用350/tickMs(20)=virtualId(17)，然后virtualId(17) %wheelSize (20) = 17，所以350会放在第17个bucket。如果此时有一个450ms后执行的任务，那么会放在第三层时间轮中，按照刚才的计算公式，会放在第0个bucket。第0个bucket里会包含&lt;/p&gt;
&lt;p&gt;[400,800)ms的任务。随着时间流逝，当时间过去了400ms，那么450ms后就要执行的任务还剩下50ms的时间才能执行，此时有一个时间轮降级的操作，将50ms任务重新提交到层级时间轮中，那么此时50ms的任务根据公式会放入第二个时间轮的第2个bucket中，此bucket的时间范围为[40,60)ms，然后再经过40ms，这个50ms的任务又会被监控到，此时距离任务执行还有10ms，同样将10ms的任务提交到层级时间轮，此时会加入到第一层时间轮的第10个bucket，所以再经过10ms后，此任务到期，最终执行。&lt;/p&gt;
&lt;p&gt;整个时间轮的升级降级操作是不是很类似于我们的时钟？ 第一层时间轮tickMs=1s, wheelSize=60，interval=1min，此为秒钟；第二层tickMs=1min，wheelSize=60，interval=1hour，此为分钟；第三层tickMs=1hour，wheelSize为12，interval为12hours，此为时钟。而钟表的指针就对应程序中的currentTime，这个后面分析代码时候会讲到（对这个的理解也是时间轮理解的重点和难点）。&lt;/p&gt;
&lt;p&gt;Kafka中任务添加和驱动时间轮滚动的核心流程：&lt;br/&gt;
&lt;img src=&quot;https://img-blog.csdnimg.cn/20200308202809831.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1poaVp1aUNodW5GZW5n,size_16,color_FFFFFF,t_70&quot; alt=&quot;任务添加和驱动时间轮滚动核心流程图&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;重点代码介绍&lt;/h2&gt;
&lt;p&gt;这是往SystenTimer中添加一个任务&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;&lt;span class=&quot;hljs-comment&quot;&gt;//在Systemtimer中添加一个任务，任务被包装为一个TimerTaskEntry&lt;/span&gt;
&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; def &lt;span class=&quot;hljs-title&quot;&gt;addTimerTaskEntry&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(timerTaskEntry: TimerTaskEntry)&lt;/span&gt;: Unit &lt;/span&gt;= {
&lt;span class=&quot;hljs-comment&quot;&gt;//先判断是否可以添加进时间轮中，如果不可以添加进去代表任务已经过期或者任务被取消，注意这里的timingWheel持有上一层时间轮的引用，所以可能存在递归调用&lt;/span&gt;
  &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (!timingWheel.add(timerTaskEntry)) {
    &lt;span class=&quot;hljs-comment&quot;&gt;// Already expired or cancelled&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (!timerTaskEntry.cancelled)
     &lt;span class=&quot;hljs-comment&quot;&gt;//过期任务直接线程池异步执行掉&lt;/span&gt;
      taskExecutor.submit(timerTaskEntry.timerTask)
  }
}
&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;p&gt;timingWheel添加任务，递归添加直到添加该任务进合适的时间轮的bucket中&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(timerTaskEntry: TimerTaskEntry)&lt;/span&gt;: Boolean &lt;/span&gt;= {
  val expiration = timerTaskEntry.expirationMs
  &lt;span class=&quot;hljs-comment&quot;&gt;//任务取消&lt;/span&gt;
  &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (timerTaskEntry.cancelled) {
    &lt;span class=&quot;hljs-comment&quot;&gt;// Cancelled&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;false&lt;/span&gt;
  } &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (expiration &amp;lt; currentTime + tickMs) {
    &lt;span class=&quot;hljs-comment&quot;&gt;// 任务过期后会被执行&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;false&lt;/span&gt;
  } &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (expiration &amp;lt; currentTime + interval) {&lt;span class=&quot;hljs-comment&quot;&gt;//任务过期时间比当前时间轮时间加周期小说明任务过期时间在本时间轮周期内&lt;/span&gt;
    val virtualId = expiration / tickMs
    &lt;span class=&quot;hljs-comment&quot;&gt;//找到任务对应本时间轮的bucket&lt;/span&gt;
    val bucket = buckets((virtualId % wheelSize.toLong).toInt)
    bucket.add(timerTaskEntry)
    &lt;span class=&quot;hljs-comment&quot;&gt;// Set the bucket expiration time&lt;/span&gt;
   &lt;span class=&quot;hljs-comment&quot;&gt;//只有本bucket内的任务都过期后才会bucket.setExpiration返回true此时将bucket放入延迟队列&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (bucket.setExpiration(virtualId * tickMs)) {
     &lt;span class=&quot;hljs-comment&quot;&gt;//bucket是一个TimerTaskList，它实现了java.util.concurrent.Delayed接口，里面是一个多任务组成的链表，图2有说明&lt;/span&gt;
      queue.offer(bucket)
    }
    &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;
  } &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {
    &lt;span class=&quot;hljs-comment&quot;&gt;// Out of the interval. Put it into the parent timer&lt;/span&gt;
    &lt;span class=&quot;hljs-comment&quot;&gt;//任务的过期时间不在本时间轮周期内说明需要升级时间轮，如果不存在则构造上一层时间轮，继续用上一层时间轮添加任务&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (overflowWheel == &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) addOverflowWheel()
    overflowWheel.add(timerTaskEntry)
  }
}

&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;p&gt;在本层级时间轮里添加上一层时间轮里的过程，注意的是在下一层时间轮的interval为上一层时间轮的tickMs&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt;[&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;] &lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;addOverflowWheel&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt;: Unit &lt;/span&gt;= {
  &lt;span class=&quot;hljs-keyword&quot;&gt;synchronized&lt;/span&gt; {
    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (overflowWheel == &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {
      overflowWheel = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; TimingWheel(
        tickMs = interval,
        wheelSize = wheelSize,
        startMs = currentTime,
        taskCounter = taskCounter,
        queue
      )
    }
  }
}
&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;p&gt;驱动时间轮滚动过程：&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;&lt;span class=&quot;hljs-comment&quot;&gt;//注意这里会存在一个递归，一直驱动时间轮的指针滚动直到时间不足于驱动上层的时间轮滚动。&lt;/span&gt;
&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;advanceClock&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(timeMs: Long)&lt;/span&gt;: Unit &lt;/span&gt;= {
  &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (timeMs &amp;gt;= currentTime + tickMs) {
   &lt;span class=&quot;hljs-comment&quot;&gt;//把当前时间打平为时间轮tickMs的整数倍&lt;/span&gt;
    currentTime = timeMs - (timeMs % tickMs)
    &lt;span class=&quot;hljs-comment&quot;&gt;// Try to advance the clock of the overflow wheel if present&lt;/span&gt;
    &lt;span class=&quot;hljs-comment&quot;&gt;//驱动上层时间轮，这里的传给上层的currentTime时间是本层时间轮打平过的，但是在上层时间轮还是会继续打平&lt;/span&gt;
    &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (overflowWheel != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) overflowWheel.advanceClock(currentTime)
  }
}
&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;p&gt;这里是驱动源代码：&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs-code-wrap&quot;&gt;&lt;span class=&quot;hljs-comment&quot;&gt;//循环bucket里面的任务列表，一个个重新添加进时间轮，对符合条件的时间轮进行升降级或者执行任务&lt;/span&gt;
&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt;[&lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;] val reinsert = (timerTaskEntry: TimerTaskEntry) =&amp;gt; addTimerTaskEntry(timerTaskEntry)
 
&lt;span class=&quot;hljs-comment&quot;&gt;/*
 * Advances the clock if there is an expired bucket. If there isn&#x27;t any expired bucket when called,
 * waits up to timeoutMs before giving up.
 */&lt;/span&gt;
&lt;span class=&quot;hljs-function&quot;&gt;def &lt;span class=&quot;hljs-title&quot;&gt;advanceClock&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(timeoutMs: Long)&lt;/span&gt;: Boolean &lt;/span&gt;= {
  &lt;span class=&quot;hljs-keyword&quot;&gt;var&lt;/span&gt; bucket = delayQueue.poll(timeoutMs, TimeUnit.MILLISECONDS)
  &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (bucket != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {
    writeLock.lock()
    &lt;span class=&quot;hljs-keyword&quot;&gt;try&lt;/span&gt; {
      &lt;span class=&quot;hljs-keyword&quot;&gt;while&lt;/span&gt; (bucket != &lt;span class=&quot;hljs-keyword&quot;&gt;null&lt;/span&gt;) {
        &lt;span class=&quot;hljs-comment&quot;&gt;//驱动时间轮&lt;/span&gt;
        timingWheel.advanceClock(bucket.getExpiration())
       &lt;span class=&quot;hljs-comment&quot;&gt;//循环buckek也就是任务列表，任务列表一个个继续添加进时间轮以此来升级或者降级时间轮，把过期任务找出来执行&lt;/span&gt;
        bucket.flush(reinsert)
       &lt;span class=&quot;hljs-comment&quot;&gt;//循环&lt;/span&gt;
        &lt;span class=&quot;hljs-comment&quot;&gt;//这里就是从延迟队列取出bucket，bucket是有延迟时间的，取出代表该bucket过期，我们通过bucket能取到bucket包含的任务列表&lt;/span&gt;
        bucket = delayQueue.poll()
      }
    } &lt;span class=&quot;hljs-keyword&quot;&gt;finally&lt;/span&gt; {
      writeLock.unlock()
    }
    &lt;span class=&quot;hljs-keyword&quot;&gt;true&lt;/span&gt;
  } &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; {
    &lt;span class=&quot;hljs-keyword&quot;&gt;false&lt;/span&gt;
  }
}
&lt;/code&gt;&lt;button class=&quot;pre-button&quot;&gt;复制&lt;/button&gt;&lt;/pre&gt;
&lt;h1&gt;总结&lt;/h1&gt;
&lt;p&gt;kafka的延迟队列使用时间轮实现，能够支持大量任务的高效触发，但是在kafka延迟队列实现方案里还是看到了delayQueue的影子，使用delayQueue是对时间轮里面的bucket放入延迟队列，以此来推动时间轮滚动，但是基于将插入和删除操作则放入时间轮中，将这些操作的时间复杂度都降为O(1)，提升效率。Kafka对性能的极致追求让它把最合适的组件放在最适合的位置。&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>779e0494608d1b91993862a6f4173d32</guid>
<title>[推荐] 利用 Kubernetes 搭建便携式开发环境之 MySQL 和 Redis</title>
<link>https://toutiao.io/k/kkc4ght</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot; data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;之前给大家介绍过， 我自己用的开发环境都是容器化的，只不过前两年不会用K8，大部分都是用的 Docker 或者 Docker-Compose。随着这一年多对 K8 的学习和工作中的使用，一直有想法用K8 做一套便携式开发环境，以后换电脑就不用再愁数据库、缓存、队列这些基础软件的安装了。正好下个月我就能换新的办公电脑啦，也不能拿『能用就行』的理由再拖延下去了。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;如果问你 “ 平时开发程序依赖最多的基础软件时啥？”，我猜大部分人会回答：“MySQL 和 Redis”，毕竟万物皆是增删改查，整天做CURD的我们怎么能离开它们呢。&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;准备工作&lt;/span&gt;&lt;/h2&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;工具选择&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;既然是要在本地 Kubernetes 上搭建开发环境，那电脑上得先有 Kubernetes 集群才行。目前可以在本地运行 Kubernetes 集群的工具有：Minikube 、Kind 和 K3d ，我们的MySQL和Redis都是靠先编写资源定义YAML文件，再通过 kubectl 交给Kubernetes 集群执行的，所以这三种工具用哪种都行。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我自己在本地使用的是Minikube，这是 Kubernetes 官方提供的工具，说实话运行起来后电脑有点卡，Minikube的安装步骤可以参考我以前写的文章「&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&amp;amp;mid=2247485235&amp;amp;idx=1&amp;amp;sn=0cdd31c25b13790b336e0a8222f00b64&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;Minikube-运行在笔记本电脑上的Kubernetes集群&lt;/a&gt;」。另外两种 Kind 和 K3d 则是轻量级集群，支持多节点部署。其中我比较推荐K3d，尤其是使用 M1芯片MacBook的同学，现在暂时只能使用K3d安装Kubernetes集群。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;K3d 是使用 docker 容器在本地运行 k3s 集群，k3s 是由 Rancher Lab 开源的轻量级 Kubernetes。k3d 完美继承了 k3s 的简单、快速和占用资源少的优势，镜像大小只有 100 多 M，启动速度快，支持多节点集群。虽然 k3s 对 Kubernetes 进行了轻量化的裁剪，但是提供了完整了功能，像 Istio 这样复杂的云原生应用都可以在 k3s 上顺利运行。&lt;/p&gt;&lt;p&gt;K3d 除了启动速度快和占用资源少以外，在边缘计算和嵌入式领域也有着不俗的表现。因为 k3s 本身应用场景主要在边缘侧，所以支持的设备和架构很多，如：ARM64 和 ARMv7 处理器。很多老旧 PC 和树莓派这样的设备都可以拿来做成 k3s 集群，为本地研发测试燃尽最后的生命。&lt;/p&gt;&lt;/blockquote&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;预备知识点&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;说完了安装工具的选择，我们再来说一下在Kubernetes上从零搭建开发环境需要提前做哪些知识储备，如果你已经对Kubernetes这些基础概念已经有所了解可以直接跳过去看实操环节了，如果还比较生疏的话，我建议大家先看看下面这几篇文章，这些都是我们搭建开发环境时需要用到的。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&amp;amp;mid=2247485464&amp;amp;idx=1&amp;amp;sn=00ca443bbcd4b2996efdede396b6c667&amp;amp;chksm=fa80d98fcdf7509944d63f618264e36cd8082a77e23aa36428a3d57a2f4189bcce4e52986967&amp;amp;token=2033333242&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;Kubernetes Pod入门指南&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&amp;amp;mid=2247485643&amp;amp;idx=1&amp;amp;sn=6460bf2e170e4b2e8ebb2882bfe7c60f&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;应用编排利器之Deployment&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&amp;amp;mid=2247486082&amp;amp;idx=1&amp;amp;sn=42a9bc8fcfc9da09445e9e2f4cf2fb96&amp;amp;chksm=fa80db15cdf752039494992f71a3bc488cf386841bd1aaaa44115f5e7f155ba55ce468ec89ee&amp;amp;token=2033333242&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;学练结合，快速掌握Kubernetes Service&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&amp;amp;mid=2247486416&amp;amp;idx=1&amp;amp;sn=20d568f93d0f39e0f3c7ef3ce42ac1d8&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;用面向对象的方式管理配置文件&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&amp;amp;mid=2247486737&amp;amp;idx=1&amp;amp;sn=e7d0689fa74b108bae734515837c68e1&amp;amp;chksm=fa80dc86cdf755909f2f29ee8cb9dce930b95a837cb045be5c9700a9000743c9cb7f8eed6731&amp;amp;token=1423297622&amp;amp;lang=zh_CN&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;深入理解StatefulSet，用Kubernetes编排有状态应用&lt;/a&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;安装MySQL&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在正式开始在Kubernetes上安装MySQL和Redis前我先说明下安装这两个基础软件服务的思路。&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;首先因为是用作开发环境，我们就不追求高可用了，尽量精简。文章后面我会给出安装主从和集群式数据库的一些教程链接，供大家参考。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;安装MySQL和Redis的思路是一样的，每个服务都由下面几个主要的部分构成：&lt;/p&gt;&lt;p&gt;① 一个单副本 Pod 作为运行MySQL或者Redis 的载体。&lt;/p&gt;&lt;p&gt;② 一个调度Pod用的Deployment控制器，因为服务里只包含一个Pod，不需要维持构建的顺序，所以不用使用StatefulSet作为Pod的控制器。&lt;/p&gt;&lt;p&gt;③一个ConfigMap对象，包含了MySQL或者Redis配置文件里需要的配置项，在创建Pod时会作为配置文件挂载到应用所在的容器中。&lt;/p&gt;&lt;p&gt;④一个 Service 对象，将应用 Pod 作为自己的后端端点，以始终保持不变的NodeId:NodePort 方式向外暴露服务。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;下面这张图很好的解释了这四部分的协作关系。&lt;/p&gt;&lt;figure data-tool=&quot;mdnice编辑器&quot;&gt;&lt;img data-ratio=&quot;0.5279912184412733&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_jpg/z4pQ0O5h0f727NCYVkxF8ic7Bp7Ue9zn3UGfGUe5SiafCBLWQZQT9qEOTicNmq6Jd4A9NribpiaricrtTj07NGlffczA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;911&quot;/&gt;&lt;figcaption&gt;MySQL on Kubernetes&lt;/figcaption&gt;&lt;/figure&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;解释清楚我们在Kubernetes上搭建MySQL和Redis开发环境的思路后，下面就可以进入实操环节啦，我为大家准备了可以直接拿来使用的YAML资源定义文件。&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;创建MySQL配置&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;我们先来创建一个名为 mysql-db-config 的ConfigMap，稍后会把这些配置作为 my.cnf 配置文件挂载到MySQL应用Pod的容器里。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;### 文件名 mysql-configmap.yaml&lt;/span&gt;&lt;br/&gt;&lt;span&gt;apiVersion:&lt;/span&gt; &lt;span&gt;v1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;ConfigMap&lt;/span&gt;&lt;br/&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;mysql-db-config&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;namespace:&lt;/span&gt; &lt;span&gt;default&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;labels:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;app:&lt;/span&gt; &lt;span&gt;mysql-db-config&lt;/span&gt;&lt;br/&gt;&lt;span&gt;data:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;my.cnf:&lt;/span&gt; &lt;span&gt;|&lt;br/&gt;    [client]&lt;br/&gt;    default-character-set=utf8mb4&lt;br/&gt;    [mysql]&lt;br/&gt;    default-character-set=utf8mb4&lt;br/&gt;    [mysqld]&lt;br/&gt;    character-set-server = utf8mb4&lt;br/&gt;    collation-server = utf8mb4_unicode_ci&lt;br/&gt;    init_connect=&#x27;SET NAMES utf8mb4&#x27;&lt;br/&gt;    skip-character-set-client-handshake = true&lt;br/&gt;    max_connections=2000&lt;br/&gt;    secure_file_priv=/var/lib/mysql&lt;br/&gt;    datadir=/var/lib/mysql&lt;br/&gt;    bind-address=0.0.0.0&lt;br/&gt;    symbolic-links=0&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;假定MySQL相关的YAML定义文件都放在 mysql-singleton 这个目录下，通过 kubectl 把这个ConfigMap 提交给Kubernetes 进行创建即可：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;kubectl apply -f mysql-singleton/mysql-configmap.yaml&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span/&gt;&lt;span&gt;创建MySQL容器和Service&lt;/span&gt;&lt;span/&gt;&lt;/h3&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;有了MySQL配置相关的 ConfigMap后，我们就能在创建运行MySQL的容器时，把他作为配置文件挂载到容器中：&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;&lt;span&gt;### 文件名 deployment-service.yaml&lt;/span&gt;&lt;br/&gt;&lt;span&gt;apiVersion:&lt;/span&gt; &lt;span&gt;v1&lt;/span&gt;&lt;br/&gt;&lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;Service&lt;/span&gt;&lt;br/&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;mysql&lt;/span&gt;&lt;br/&gt;&lt;span&gt;spec:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;type:&lt;/span&gt; &lt;span&gt;NodePort&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;ports:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;-&lt;/span&gt; &lt;span&gt;port:&lt;/span&gt; &lt;span&gt;3306&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;nodePort:&lt;/span&gt; &lt;span&gt;30306&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;targetPort:&lt;/span&gt; &lt;span&gt;mysql&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;selector:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;app:&lt;/span&gt; &lt;span&gt;mysql&lt;/span&gt;&lt;br/&gt;&lt;span&gt;---&lt;/span&gt;&lt;br/&gt;&lt;span&gt;apiVersion:&lt;/span&gt;&lt;br/&gt;&lt;span&gt;kind:&lt;/span&gt; &lt;span&gt;Deployment&lt;/span&gt;&lt;br/&gt;&lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;mysql&lt;/span&gt;&lt;br/&gt;&lt;span&gt;spec:&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;selector:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;matchLabels:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;app:&lt;/span&gt; &lt;span&gt;mysql&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;strategy:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;type:&lt;/span&gt; &lt;span&gt;Recreate&lt;/span&gt;&lt;br/&gt;  &lt;span&gt;template:&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;metadata:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;labels:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;app:&lt;/span&gt; &lt;span&gt;mysql&lt;/span&gt;&lt;br/&gt;    &lt;span&gt;spec:&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;containers:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;-&lt;/span&gt; &lt;span&gt;image:&lt;/span&gt; &lt;span&gt;mysql:5.7&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;mysql&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;env:&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;MYSQL_ROOT_PASSWORD&lt;/span&gt;&lt;br/&gt;              &lt;span&gt;value:&lt;/span&gt; &lt;span&gt;root&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;MYSQL_USER&lt;/span&gt;&lt;br/&gt;              &lt;span&gt;value:&lt;/span&gt; &lt;span&gt;user&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;MYSQL_PASSWORD&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;ports:&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;-&lt;/span&gt; &lt;span&gt;containerPort:&lt;/span&gt; &lt;span&gt;3306&lt;/span&gt;&lt;br/&gt;              &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;mysql&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;volumeMounts:&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;mysql-persistent-storage&lt;/span&gt;&lt;br/&gt;              &lt;span&gt;mountPath:&lt;/span&gt; &lt;span&gt;/var/lib/mysql&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;mysql-config&lt;/span&gt;&lt;br/&gt;              &lt;span&gt;mountPath:&lt;/span&gt; &lt;span&gt;/etc/mysql/conf.d/my.cnf&lt;/span&gt;&lt;br/&gt;              &lt;span&gt;subPath:&lt;/span&gt; &lt;span&gt;my.cnf&lt;/span&gt;&lt;br/&gt;      &lt;span&gt;volumes:&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;mysql-persistent-storage&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;emptyDir:&lt;/span&gt; &lt;span&gt;{}&lt;/span&gt;&lt;br/&gt;        &lt;span&gt;-&lt;/span&gt; &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;mysql-config&lt;/span&gt;&lt;br/&gt;          &lt;span&gt;configMap:&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;name:&lt;/span&gt; &lt;span&gt;mysql-db-config&lt;/span&gt;&lt;br/&gt;            &lt;span&gt;items:&lt;/span&gt;&lt;br/&gt;              &lt;span&gt;-&lt;/span&gt; &lt;span&gt;key:&lt;/span&gt; &lt;span&gt;my.cnf&lt;/span&gt;&lt;br/&gt;                &lt;span&gt;path:&lt;/span&gt; &lt;span&gt;my.cnf&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;同样的，使用kubectl 把 YAML 提交给Kubernetes后，等资源创建完毕我们的开发环境MySQL就算搭建好了&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;kubectl apply -f mysql-singleton/deployment-service.yaml&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;通过上面的YAML文件中，有三点需要详细说明一下：&lt;/p&gt;&lt;ol data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;使用 mysql-db-config 这个ConfigMap 中my.cnf这个配置项以my.cnf文件名挂载到容器中去，但是因为挂载进去后会覆盖容器中conf.d 目录中的内容。通过volumeMounts.subPath可以支持选定ConfigMap中的Key-Value挂载到容器中而不覆盖容器中原有的文件。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;Service 用 30306 端口向集群外暴露了MySQL服务，客户端从电脑上使用NodeIP:NodePort即可连接到这里创建的数据库，如果用的是Minikube创建的Kubernetes集群， 可以通过minikube ip 命令查到NodeIP。&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;emptyDir 类型的数据卷的生命周期与Pod同步，这里的同步指的是Pod被kubectl delete 主动删除时才会销毁对应的数据卷，如果是Pod自己崩溃，或者是集群Shotdown，等恢复后重建出来的Pod仍然会使用之前的数据卷，不会造成数据丢失。&lt;/section&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在Kubernetes上创建完MySQL后，我们可以通过任意客户端或者mysql命令行，连接MySQL服务。&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;code&gt;mysql -uroot -puser -h {minikube-ip} -P 30306&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;安装Redis&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;聊清楚了怎么用Kubernetes创建单节点的MySQL后，对于创建单例的Redis相信大家对大致流程也就比较清楚了，唯一少的就是定义Redis服务的这些YAML文件了。我已经帮你们踩好坑了，下面这些YAML都是我在线下调试过一段时间的，并且也能正确完成Redis数据的持久化。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;由于声明 Redis 配置的 ConfigMap 篇幅太长，为了不影响文章的阅读我就把这个安装Redis需要的YAML文件都放在GitHub上了，可以点击阅读原文或者通过链接：https://github.com/kevinyan815/LearningKubernetes 访问下载。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;在这个仓库里我给出了MySQL和Redis的详细安装步骤，以及各种资源的YAML定义文件，包括之前安装ETCD集群的教程也整合到了这个仓库里。&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;安装步骤详解，参考 &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&amp;amp;mid=2247487400&amp;amp;idx=1&amp;amp;sn=bd6b3eca835cbe65fb70a4dfe9326037&amp;amp;scene=21#wechat_redirect&quot; data-linktype=&quot;2&quot;&gt;用Kubernetes搭建ETCD集群和WebUI&lt;/a&gt;&lt;/p&gt;&lt;p&gt;关于安装过程中遇到的问题可以在留言里跟我交流，大家还想看其他基础软件在Kubernetes上的安装教程的话也可以告诉我。&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span/&gt;&lt;span&gt;总结&lt;/span&gt;&lt;/h2&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;这篇文章里整理了在Kubernetes上安装MySQL和Redis这两款我们常用的基础软件的操作步骤，由于目的是在本地开发环境用，所以力求资源定义尽量简单，能做到数据可持久化就行了，高可用不再这里讨论。如果你对在Kubernetes上创建MySQL集群有兴趣，可以参考我下面给出的链接。&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;MySQL Operator FOR Kubernetnes&lt;/span&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/p&gt;&lt;h3 data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;资料引用&lt;/span&gt;&lt;/h3&gt;&lt;section data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;span&gt;[1]&lt;/span&gt;&lt;p&gt;MySQL Operator FOR Kubernetnes: &lt;span&gt;:https://medium.com/oracledevs/getting-started-with-the-mysql-operator-for-kubernetes-8df48591f592&lt;/span&gt;&lt;/p&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>cfa214ba1eee9daff4c3907737be8970</guid>
<title>[推荐] 有赞 TCP 网络编程最佳实践</title>
<link>https://toutiao.io/k/a7bxrhs</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section class=&quot;post-content&quot;&gt;
&lt;h1 id=&quot;&quot;&gt;概述&lt;/h1&gt;

&lt;p&gt;本文是根据有赞中间件团队多年的TCP网络编程实践经验总结而来，目的是为了避免应用因各种网络异常而出现各种非预期行为，从而造成非预期的影响，影响系统稳定性与可靠性。&lt;/p&gt;

&lt;p&gt;本文不会涉及TCP的各个基础知识点，主要是总结一些TCP网络编程实践中可能碰到的一些问题，以及相应的经过实践验证的解决方案等。虽然本文档很多细节主要是针对于Linux系统，不过，大部分建议适合于所有系统。&lt;/p&gt;

&lt;p&gt;本文共总结了&lt;strong&gt;16&lt;/strong&gt;项建议，下面逐一进行介绍。&lt;/p&gt;

&lt;h1 id=&quot;1so_reuseaddr&quot;&gt;1. 服务端监听设置SO_REUSEADDR选项&lt;/h1&gt;

&lt;p&gt;当我们重启服务端程序的时候可能会碰到“address already in use”这样的报错信息，即地址已被使用，导致程序无法快速成功重启。老的进程关闭退出了，为什么还会报地址已被使用呢？&lt;/p&gt;

&lt;p&gt;我们先来理解如下两点：  &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TCP连接主动关闭方存在持续2MSL的&lt;code&gt;TIME_WAIT&lt;/code&gt;状态；  &lt;/li&gt;
&lt;li&gt;TCP连接由是由四元组&amp;lt;本地地址，本地端口，远程地址，远程端口&amp;gt;来确定的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们先简单回顾一下TCP连接关闭过程中的&lt;code&gt;TIME_WAIT&lt;/code&gt;状态，如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/content/images/2021/05/tcp_close.png&quot; align=&quot;center&quot;/&gt;&lt;/p&gt;

&lt;p&gt;（图片来源：&lt;a href=&quot;https://en.wikipedia.org/wiki/Transmission_Control_Protocol&quot;&gt;Wikipedia&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;TIME_WAIT存在的意义主要有两点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;维护连接状态，使TCP连接能够可靠地关闭。如果连接主动关闭端发送的最后一条ACK丢失，连接被动关闭端会重传FIN报文。因此，主动关闭方必须维持连接状态，以支持收到重传的FIN后再次发送ACK。如果没有&lt;code&gt;TIME_WAIT&lt;/code&gt;，并且最后一个ACK丢失，那么此时被动关闭端还会处于&lt;code&gt;LAST_ACK&lt;/code&gt;一段时间，并等待重传；如果此时主动关闭方又立即创建新TCP连接且恰好使用了相同的四元组，连接会创建失败，会被对端重置。  &lt;/li&gt;
&lt;li&gt;等待网络中所有此连接老的重复的、走失的报文消亡，避免此类报文对新的相同四元组的TCP连接造成干扰，因为这些报文的序号可能恰好落在新连接的接收窗口内。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因为每个TCP报文最大存活时间为MSL，一个往返最大是2*MSL，所以&lt;code&gt;TIME_WAIT&lt;/code&gt;需要等待2MSL。&lt;/p&gt;

&lt;p&gt;当进程关闭时，进程会发起连接的主动关闭，连接最后会进入&lt;code&gt;TIME_WAIT&lt;/code&gt;状态。当新进程bind监听端口时，就会报错，因为有对应本地端口的连接还处于&lt;code&gt;TIME_WAIT&lt;/code&gt;状态。&lt;/p&gt;

&lt;p&gt;实际上，只有当新的TCP连接和老的TCP连接四元组完全一致，且老的迷走的报文序号落在新连接的接收窗口内时，才会造成干扰。为了使用&lt;code&gt;TIME_WAIT&lt;/code&gt;状态的端口，现在大部分系统的实现都做了相关改进与扩展：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;新连接SYN告知的初始序列号，要求一定要比&lt;code&gt;TIME_WAIT&lt;/code&gt;状态老连接的序列号大，可以一定程度保证不会与老连接的报文序列号重叠。&lt;/li&gt;
&lt;li&gt;开启TCP &lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc6191&quot;&gt;timestamps扩展选项&lt;/a&gt;后，新连接的时间戳要求一定要比&lt;code&gt;TIME_WAIT&lt;/code&gt;状态老连接的时间戳大，可以保证老连接的报文不会影响新连接。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，在开启了TCP timestamps扩展选项的情况下（&lt;code&gt;net.ipv4.tcp_timestamps = 1&lt;/code&gt;），可以放心的设置&lt;code&gt;SO_REUSEADDR&lt;/code&gt;选项，支持程序快速重启。&lt;/p&gt;

&lt;p&gt;注意不要与&lt;code&gt;net.ipv4.tcp_tw_reuse&lt;/code&gt;系统参数混淆，该参数仅在客户端调用connect创建连接时才生效，可以使用&lt;code&gt;TIME_WAIT&lt;/code&gt;状态超过1秒的端口（防止最后一个ACK丢失）；而&lt;code&gt;SO_REUSEADDR&lt;/code&gt;是在bind端口时生效，一般用于服务端监听时，可以使用本地非&lt;code&gt;LISTEN&lt;/code&gt;状态的端口（另一个端口也必须设置&lt;code&gt;SO_REUSEADDR&lt;/code&gt;），不仅仅是&lt;code&gt;TIME_WAIT&lt;/code&gt;状态端口。&lt;/p&gt;

&lt;h1 id=&quot;2&quot;&gt;2. 建立并遵守应用监听端口规范&lt;/h1&gt;

&lt;p&gt;每个应用、每个通信协议要有固定统一的监听端口，便于在公司内部形成共识，降低协作成本，提升运维效率。如对于一些网络ACL控制，规范统一的端口会给运维带来极大的便利。&lt;/p&gt;

&lt;p&gt;应用监听端口不能在&lt;code&gt;net.ipv4.ip_local_port_range&lt;/code&gt;区间内，这个区间是操作系统用于本地端口号自动分配的（bind或connect时没有指定端口号），Linux系统默认值为[32768, 60999]。现在一个应用服务器实例（无论是VM还是K8S Pod等），本地不仅仅会包含应用进程自身，还可能会包括监控采集、sidecar代理等进程。如果选了&lt;code&gt;net.ipv4.ip_local_port_range&lt;/code&gt;这个范围内的端口作为监听端口，你的应用进程启动前，对应的端口很可能已经被自动分配给其他进程的TCP连接，就会导致监听端口绑定失败，从而导致进程启动失败；当然，如果已经分配的端口设置了&lt;code&gt;SO_REUSEADDR&lt;/code&gt;也不会导致你的应用监听端口绑定失败，但这些临时端口一般都不会设置&lt;code&gt;SO_REUSEADDR&lt;/code&gt;。如果确实有需求监听&lt;code&gt;net.ipv4.ip_local_port_range&lt;/code&gt;区间内的端口（如保留三方系统的默认端口），可以设置&lt;code&gt;net.ipv4.ip_local_reserved_ports&lt;/code&gt;系统参数进行预留，预留的端口不会被自动分配出去；但这样会给运维增加系统的交付难度，所以，一般不建议这样做。&lt;/p&gt;

&lt;p&gt;有赞的&lt;code&gt;net.ipv4.ip_local_port_range&lt;/code&gt;系统值设置为[9000, 65535]，并且对所有类型的应用、通信协议监听端口都进行了统一规范，监听端口都小于9000。&lt;/p&gt;

&lt;h1 id=&quot;3&quot;&gt;3. 应用服务端口与管理端口分离&lt;/h1&gt;

&lt;p&gt;服务端口即业务请求的处理端口，管理端口为框架或应用的管理请求处理端口（如服务注册上线、下线）。以Spring Boot为例，应用端口对应&lt;code&gt;server.port&lt;/code&gt;，管理端口对应&lt;code&gt;management.port&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;应用的服务端口与管理端口分离有如下意义：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;避免业务请求与管理请求互相影响，如线程池等。&lt;/li&gt;
&lt;li&gt;更好地进行权限管理、ACL控制等。管理端口一般可以控制应用的核心行为，需要进行严格的权限管理、ACL控制，比如通过防火墙仅允许特定IP访问管理端口等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有赞线上曾经碰到过一个问题：一个Dubbo业务应用提供HTTP服务和Dubbo服务，HTTP服务端口与HTTP管理端口是同一个，该应用的一个实例因内部逻辑问题发生了死锁，造成请求阻塞超时，但这时服务注册的健康保活线程仍然正常，所以该异常服务实例还是在线的，客户端仍在发送请求到该实例。这时想将该实例进行服务注册下线操作但保留进程以便排查问题，但由于业务线程阻塞导致HTTP线程池所有线程阻塞，进而导致管理模块无线程可处理HTTP服务注册下线请求，最终无法正常下线。有赞Dubbo框架已经对应用服务端口与管理端口进行了分离，并进行了线程池隔离，避免再出现类似的问题。当然，熔断等其他机制也有助于应对个别实例异常问题，这里我们主要关注端口分离问题。&lt;/p&gt;

&lt;h1 id=&quot;4&quot;&gt;4. 建立连接设置超时时间&lt;/h1&gt;

&lt;p&gt;网络拥塞、IP不可达、握手队列满时，都可能会导致建立连接阻塞与超时，为了避免不可控的阻塞时间对应用造成难以预知的影响，建议在建立连接时设置超时时间，进行超时控制。如果没有主动进行设置，超时时间是由系统默认行为进行控制的，而系统的默认行为肯定是无法满足所有应用场景的。（注：握手队列满时，如果设置了系统参数&lt;code&gt;net.ipv4tcp_abort_on_overflow&lt;/code&gt;，连接会立刻被重置）&lt;/p&gt;

&lt;p&gt;我们看一下系统默认是如何控制连接建立超时时间的？&lt;/p&gt;

&lt;p&gt;TCP三次握手的第一个SYN报文没有收到ACK，系统会自动对SYN报文进行重试，最大重试次数由系统参数&lt;code&gt;net.ipv4.tcp_syn_retries&lt;/code&gt;控制，默认值为6。初始RTO为1s，如果一直收不到SYN ACK，依次等待1s、2s、4s、8s、16s、32s发起重传，最后一次重传等待64s后放弃，最终在127s后才会返回ETIMEOUT超时错误。&lt;/p&gt;

&lt;p&gt;建议根据整个公司的业务场景，调整&lt;code&gt;net.ipv4.tcp_syn_retries&lt;/code&gt;系统参数进行兜底。有赞将该参数设为3，即最大15s左右可返回超时错误。&lt;/p&gt;

&lt;h1 id=&quot;5&quot;&gt;5. 使用应用层心跳对连接进行健康检查&lt;/h1&gt;

&lt;p&gt;当TCP连接有异常时，我们需要尽快感知到，然后进行相应的异常处理与恢复。对于FIN或RST这种连接关闭、重置场景，应用层是可以快速感知到的。但是对于对端机器掉电、网线脱落、网络设备异常等造成的假连接，如果没有特殊措施，应用层很长时间都感知不到。&lt;/p&gt;

&lt;p&gt;提到网络异常检测，大家可能首先想到的是TCP Keepalive。系统TCP Keepalive相关的三个参数为&lt;code&gt;net.ipv4.tcp_keepalive_time&lt;/code&gt;、&lt;code&gt;net.ipv4.tcp_keepalive_intvl&lt;/code&gt;、&lt;code&gt;net.ipv4.tcp_keepalive_probes&lt;/code&gt;，默认值分别为7200s、75s、9，即如果7200s没有收到对端的数据，就开始发送TCP Keepalive报文，如果75s内，没有收到响应，会继续重试，直到重试9次都失败后，返回应用层错误信息。&lt;/p&gt;

&lt;p&gt;为什么需要实现应用层的心跳检查呢？系统的TCP Keepalive满足不了需求吗？是的，系统的TCP Keepalive只能作为一个最基本的防御方案，而满足不了高稳定性、高可靠性场景的需求。原因有如下几点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TCP Keepalive是扩展选项，不一定所有的设备都支持；&lt;/li&gt;
&lt;li&gt;TCP Keepalive报文可能被设备特意过滤或屏蔽，如运营商设备；&lt;/li&gt;
&lt;li&gt;TCP Keepalive无法检测应用层状态，如进程阻塞、死锁、TCP缓冲区满等情况；&lt;/li&gt;
&lt;li&gt;TCP Keepalive容易与TCP重传控制冲突，从而导致失效。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于TCP状态无法反应应用层状态问题，这里稍微介绍几个场景。第一个是TCP连接成功建立，不代表对端应用感知到了该连接，因为TCP三次握手是内核中完成的，虽然连接已建立完成，但对端可能根本没有Accept；因此，一些场景仅通过TCP连接能否建立成功来判断对端应用的健康状况是不准确的，这种方案仅能探测进程是否存活。另一个是，本地TCP写操作成功，但数据可能还在本地写缓冲区中、网络链路设备中、对端读缓冲区中，并不代表对端应用读取到了数据。&lt;/p&gt;

&lt;p&gt;这里重点解释一下TCP KeepAlive与TCP重传的冲突问题。Linux系统通过&lt;code&gt;net.ipv4.tcp_retries2&lt;/code&gt;参数控制TCP的超时重传次数，即影响TCP超时时间。初始RTO为&lt;code&gt;TCP_RTO_MIN&lt;/code&gt;（200ms），RTO进行指数退让，最大RTO为&lt;code&gt;TCP_RTO_MAX&lt;/code&gt;（2min），&lt;code&gt;net.ipv4.tcp_retries2&lt;/code&gt;默认为15，大概924.6s超时。详细重传次数、RTO、超时时间关系，如下表所示。&lt;/p&gt;

&lt;table border=&quot;1&quot;&gt;  
&lt;tr&gt;  
&lt;th&gt;重传次数&lt;/th&gt;  
&lt;th&gt;RTO（毫秒）&lt;/th&gt;  
&lt;th colspan=&quot;2&quot;&gt;总超时时间&lt;/th&gt;  
&lt;/tr&gt;  
&lt;tr&gt; &lt;td&gt; 1&lt;/td&gt; &lt;td&gt;   200&lt;/td&gt; &lt;td&gt;  0.2 秒&lt;/td&gt; &lt;td&gt;0.0 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 2&lt;/td&gt; &lt;td&gt;   400&lt;/td&gt; &lt;td&gt;  0.6 秒&lt;/td&gt; &lt;td&gt;0.0 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 3&lt;/td&gt; &lt;td&gt;   800&lt;/td&gt; &lt;td&gt;  1.4 秒&lt;/td&gt; &lt;td&gt;0.0 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 4&lt;/td&gt; &lt;td&gt;  1600&lt;/td&gt; &lt;td&gt;  3.0 秒&lt;/td&gt; &lt;td&gt;0.1 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 5&lt;/td&gt; &lt;td&gt;  3200&lt;/td&gt; &lt;td&gt;  6.2 秒&lt;/td&gt; &lt;td&gt;0.1 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 6&lt;/td&gt; &lt;td&gt;  6400&lt;/td&gt; &lt;td&gt; 12.6 秒&lt;/td&gt; &lt;td&gt;0.2 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 7&lt;/td&gt; &lt;td&gt; 12800&lt;/td&gt; &lt;td&gt; 25.4 秒&lt;/td&gt; &lt;td&gt;0.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 8&lt;/td&gt; &lt;td&gt; 25600&lt;/td&gt; &lt;td&gt; 51.0 秒&lt;/td&gt; &lt;td&gt;0.9 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt; 9&lt;/td&gt; &lt;td&gt; 51200&lt;/td&gt; &lt;td&gt;102.2 秒&lt;/td&gt; &lt;td&gt;1.7 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;10&lt;/td&gt; &lt;td&gt;102400&lt;/td&gt; &lt;td&gt;204.6 秒&lt;/td&gt; &lt;td&gt;3.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;11&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;324.6 秒&lt;/td&gt; &lt;td&gt;5.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;12&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;444.6 秒&lt;/td&gt; &lt;td&gt;7.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;13&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;564.6 秒&lt;/td&gt; &lt;td&gt;9.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;14&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;684.6 秒&lt;/td&gt; &lt;td&gt;11.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;15&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;804.6 秒&lt;/td&gt; &lt;td&gt;13.4 分钟&lt;/td&gt;  
&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;16&lt;/td&gt; &lt;td&gt;120000&lt;/td&gt; &lt;td&gt;924.6 秒&lt;/td&gt; &lt;td&gt;15.4 分钟&lt;/td&gt;  
&lt;/tr&gt;  
&lt;/table&gt;

&lt;p&gt;如果TCP发送缓冲区中有数据未发送成功，TCP会进行超时重传，而不会触发TCP Keepalive。也就是说，即使应用设置了很小的TCP Keepalive参数，如time=10s、interval=10s、probes=3，在&lt;code&gt;net.ipv4.tcp_retries2&lt;/code&gt;默认配置下，可能还是一直等到15min左右才能感知到网络异常。可能有的人不理解为什么Keepalive会被重传干扰，其实这里就是个优先级的问题。TCP最大重传次数的作用高于Keepalive参数的作用，未达到最大重传次数，不会向应用层报告网络错误信息。如果Keepalive不受重传影响，同样也会对关注重传的人造成干扰，比如为什么还没达到最大重传次数就放弃重传并关闭连接了？我们可以通过&lt;code&gt;netstat -ot&lt;/code&gt;或&lt;code&gt;ss -ot&lt;/code&gt;命令查看当前连接的计时器信息。&lt;/p&gt;

&lt;p&gt;建议根据实际情况调低&lt;code&gt;net.ipv4.tcp_retries2&lt;/code&gt;参数。RFC 1122建议对应的超时时间不低于100s，即至少为8，有赞系统该参数默认为10。&lt;/p&gt;

&lt;p&gt;因此，想实现一个网络健壮的应用，应用层心跳必不可少。对于&lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc7540#section-6.7&quot;&gt;HTTP2&lt;/a&gt;、&lt;a href=&quot;https://github.com/grpc/grpc/blob/master/doc/keepalive.md&quot;&gt;gRPC&lt;/a&gt;、&lt;a href=&quot;https://dubbo.apache.org/zh/docs/v2.7/dev/implementation/#%E5%8D%8F%E8%AE%AE%E5%A4%B4%E7%BA%A6%E5%AE%9A&quot;&gt;Dubbo&lt;/a&gt;等协议都支持心跳，如果是基于这些协议开发的应用，可以直接使用这些协议的特性来实现应用层心跳。&lt;/p&gt;

&lt;p&gt;实现应用层心跳需要考虑如下点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;心跳间隔不能太小也不能太大。间隔太小心可能会对轻微抖动过于敏感，造成过度反应，反而会影响稳定性，同时也有一定的性能开销；间隔太大会导致异常检测延迟比较高。可以严格地定期发送心跳，也可以一段时间内没有收到对端数据才发起心跳。建议心跳间隔为5s~20s。&lt;/li&gt;
&lt;li&gt;设置连续失败阈值，避免瞬间抖动造成误判等。建议连续失败阈值为2~5。&lt;/li&gt;
&lt;li&gt;不要使用独立的TCP连接进行心跳检查，因为不同连接的网络路径、TCP缓冲区等都不同，无法真实反映业务通信连接的真实状态。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;6&quot;&gt;6. 连接重连需要增加退让与窗口抖动&lt;/h1&gt;

&lt;p&gt;当网络异常恢复后，大量客户端可能会同时发起TCP重连及进行应用层请求，可能会造成服务端过载、网络带宽耗尽等问题，从而导致客户端连接与请求处理失败，进而客户端触发新的重试。如果没有退让与窗口抖动机制，该状况可能会一直持续下去，很难快速收敛。&lt;/p&gt;

&lt;p&gt;建议增加指数退让，如1s、2s、4s、8s...，同时必须限制最大退让时间（如64s），否则重试等待时间可能越来越大，同样导致无法快速收敛。同时，为了降低大量客户端同时建连并请求，也需要增加窗口抖动，窗口大小可以与退让等待时间保持一致，如:
nextRetryWaitTime = backOffWaitTime + rand(0.0, 1.0) * backOffWaitTime。&lt;/p&gt;

&lt;p&gt;在进行网络异常测试或演练时，需要把网络异常时间变量考虑进来，因为不同的时长，给应用带来的影响可能会完全不同。&lt;/p&gt;

&lt;h1 id=&quot;7&quot;&gt;7. 服务端需要限制最大连接数&lt;/h1&gt;

&lt;p&gt;一个服务端口，理论上能接收的最大TCP连接数是多少呢？TCP四元组中的服务端IP、服务端端口已经固定了，理论上的上限就是客户端可用IP数量*客户端可用端口数量。去除一些IP分类、端口保留等细节，理论上限就是2^32 * 2 ^16 = 2^48。&lt;/p&gt;

&lt;p&gt;当然，目前现实中肯定达不到理论上限的瓶颈。一个TCP socket所关联的主要资源有内存缓冲区、文件描述符等，因此，实际限制主要取决于系统内存大小与文件描述符数量限制。&lt;/p&gt;

&lt;p&gt;服务端限制最大连接数，主要有两个目的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;避免服务过载导致CPU、内存耗尽；&lt;/li&gt;
&lt;li&gt;避免文件描述符耗尽。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每个TCP连接的socket都占用一个FD，每个进程以及整个系统的FD数量都是有限制的。Linux系统下，通过&lt;code&gt;ulimit -n&lt;/code&gt;可以查看单个用户的进程运行打开的FD最大数量，通过&lt;code&gt;cat /proc/sys/fs/file-max&lt;/code&gt;可以查看所有进程运行打开的最大FD数量，如果不符合应用的需求，那就需要进行相应的调整。&lt;/p&gt;

&lt;p&gt;达到FD上限会有什么影响呢？首先，肯定是无法接收新TCP连接了；其次，除了TCP连接占用的FD外，你的应用肯定还有内部场景占用或需要分配新的FD，比如日志文件发生轮转创建新日志文件时，如果日志文件创建失败，对于依赖本地存储的应用（如KV、MQ等存储型应用），就导致服务不可用了。所以，要在系统限制的基础上，根据应用的特性预留一定数量的FD，而不能把所有的FD都给客户端TCP连接使用。&lt;/p&gt;

&lt;p&gt;有赞在线上压测时，一个应用就碰到过类似的一个问题。压测期间，压力比较高，导致磁盘IO压力增高，请求处理延迟增高，导致客户端超时。客户端发现超时关闭连接，创建新连接重试，但此时服务端由于IO阻塞带来的延迟并未能够及时回收连接关闭（CLOSE_WAIT）的socket以及FD，导致FD消耗越来越多，最终导致FD耗尽，新日志文件创建失败，而该应用又是存储类型应用，强依赖于日志落盘，最终导致服务不可用。&lt;/p&gt;

&lt;p&gt;除了服务端限制最大连接数外，如果应用有对应的客户端SDK，最好也在客户端SDK也做一层保护。&lt;/p&gt;

&lt;h1 id=&quot;8&quot;&gt;8. 尽量不要依赖中心化四层负载均衡器&lt;/h1&gt;

&lt;p&gt;LVS是一个经典的中心化四层负载均衡解决方案，也有各种云厂商提供的类似LVS的产品，原理大多是一致的。它们的优点这里我们就不谈了。使用该类方案可能会面临如下问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每次应用伸缩容，需要变更后端实例列表配置，运维成本高、风险高；&lt;/li&gt;
&lt;li&gt;中心化的组件可伸缩性较差，容易触达瓶颈，如网络带宽瓶颈等；&lt;/li&gt;
&lt;li&gt;中心化的组件可用性较差，一旦负载均衡器出问题，整个服务受影响；&lt;/li&gt;
&lt;li&gt;四层健康检查对后端实例异常不敏感，无法进行应用层健康检查；&lt;/li&gt;
&lt;li&gt;负载均衡器的拆分、迁移对应用影响较大，需要应用配合更新配置、发布等，使用成本较高；&lt;/li&gt;
&lt;li&gt;负载均衡器会可能丢弃一段时间内没有通信的空闲连接，给应用带来非预期的影响；&lt;/li&gt;
&lt;li&gt;客户端访问服务端需经过负载均衡器中转，可能对RT有一定影响。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;建议通过分布式的动态服务注册与发现以及客户端负载均衡来替代中心化负载均衡方案，如微服务架构中的服务注册、服务发现、负载均衡等解决方案。&lt;/p&gt;

&lt;p&gt;在不得不使用中心化负载均衡器的场景下，也需要注意以下问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;注意选择合适的负载均衡算法，避免长连接分布不均衡。比如，如果选择了轮询负载均衡算法，正常情况下各个后端实例的连接数是均衡的，但当某个实例重启后，该实例的连接断开后，客户端会发起重连，重连就大概率转移其他实例上，导致最近启动的实例连接数较少，最早启动的实例连接数较多。可以考虑最少连接数负载均衡，长连接增加TTL限制等。&lt;/li&gt;
&lt;li&gt;注意空闲超时，超时后负载均衡器可能不会给两端发送Close或Reset信号，从而导致无法通信的假连接，如果客户端与服务端双方都没有心跳、空闲超时等，假连接会一直存在，占用系统资源；应用层或TCP层的健康检查周期需要小于负载均衡器的空闲超时。&lt;/li&gt;
&lt;li&gt;注意摘除后端实例时保证平滑，如果直接移除后端实例，可能不会给两端发送Close或Reset信号，从而导致无法通信的假连接，且客户端和服务端无法及时感知到。一般先将实例权重调整为0，保证新连接不再分配到该实例，然后等待已有的连接释放，最后再完全移除后端实例。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有赞线上环境曾多次碰到过LVS引起的相关问题，也正在研发分布式的四层代理。&lt;/p&gt;

&lt;h1 id=&quot;9close_wait&quot;&gt;9. 警惕大量CLOSE_WAIT&lt;/h1&gt;

&lt;p&gt;先介绍曾经碰到的一个问题。线上环境告警提示有服务器发生较高的TCP重传，经抓包分析重传包都是FIN包，且目标IP已不存在。查看连接状态发现大量&lt;code&gt;CLOSE_WAIT&lt;/code&gt;状态连接。该问题并不是一直持续，时有时无。经过对应用日志与应用代码分析，发现某个场景应用读取到EOF时，未关闭本地socket。进一步分析，原因是客户端应用是K8S部署的，发布后，旧实例下线，作为客户端发起主动关闭连接，并且旧实例的IP很快会被回收；服务端未关闭的socket，在几分钟后GC时（Go语言应用）才会进行socket回收关闭操作，但此时，客户端IP已不存在，因此，最后一个FIN报文不断重传，一直到超过最大重传次数，从而问题恢复。等到再次有客户端应用发布时，又会出现。该问题对于没有GC机制的编程语言开发的应用，可能会造成更严重的后果，socket不断泄露，导致FD耗尽、内存耗尽等问题。&lt;/p&gt;

&lt;p&gt;因此，一定要警惕大量CLOSE_WAIT状态连接的出现，这种情况出现时，首先要排除一些相关代码。同时，开发过程中，一定要注意正确关闭socket，通过一些语言特性进行兜底处理，如Go语言的&lt;code&gt;defer&lt;/code&gt;，Java语言的&lt;code&gt;try...catch...finally&lt;/code&gt;，C++语言的&lt;code&gt;RAII&lt;/code&gt;机制等。&lt;/p&gt;

&lt;h1 id=&quot;10ttl&quot;&gt;10. 合理设置长连接TTL&lt;/h1&gt;

&lt;p&gt;长连接减少了像短连接频繁建立连接的开销，包括三次握手开销、慢启动开销等。但也有一定的弊端：长连接的持续时间过长，可能会导致一些负载均衡问题，以及其他一些长时间难以收敛的问题。比如LVS场景，随着后端应用实例的重启，对于一些负载均衡算法（如轮询），会导致最新启动的实例连接数最少，最早启动的实例连接数最多。对于一些客户端负载均衡方案，当只需要连接后端集群中的一个节点时，长连接也会出现类似的问题，比如类似Etcd watch的场景。有赞内部有很多使用Etcd的场景，早期运维每次变更Etcd集群的时候都特别谨慎，避免连接的不均衡。&lt;/p&gt;

&lt;p&gt;有赞中间件团队规定任何应用的TCP长连接TTL不能超过2小时。当然，这已经是一个很保守的时长了，建议根据应用场景，合理设置TTL。&lt;/p&gt;

&lt;h1 id=&quot;11dns&quot;&gt;11. 通过域名访问服务需定期解析DNS&lt;/h1&gt;

&lt;p&gt;DNS是一种服务发现机制，应用通过配置DNS访问其他服务，本意是为了解决其他服务实例IP变动带来的影响，但如果处理不当还是会有问题。通过域名访问其他服务时，需要定时更新域名解析，如果解析有更新，则需要重新建立连接，避免后端实例迁移（IP有变化）时导致难以收敛。千万不要只在应用启动的时候进行一次域名解析，这种情况在DNS变更后想实现快速收敛，只能重启或发布所有相关应用了。一些语言内置了DNS相关的实现，需要注意对应的一些参数以及行为是否符合预期。&lt;/p&gt;

&lt;p&gt;另外，某些应用提供了获取最新集群成员列表的接口，如Etcd、Redis，这样即使客户端启动的时候只进行一次域名解析，只要定期从服务端同步服务集群的成员列表也能支持服务端集群成员的动态变化。&lt;/p&gt;

&lt;h1 id=&quot;12&quot;&gt;12. 降低网络读写系统调用次数&lt;/h1&gt;

&lt;p&gt;当我们调用read/write系统函数从socket读写数据时，每次调用都至少进行两次用户态与内核态的上下文切换，成本比较高。针对该问题，一般有两种优化思路：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;使用读写缓冲区；读数据时，先一次性从socket读入缓冲区，然后再按需要分次从缓冲区读取；写数据时，先分次写入缓冲区，缓冲区满时或所有写操作完成时，一次性写入socket。&lt;/li&gt;
&lt;li&gt;当不方便将数据合并到连续内存时，使用readv/writev一次性读取/写入多段内存数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于批量写操作还有一个优点，就是可以避免&lt;a href=&quot;https://en.wikipedia.org/wiki/Nagle%27s_algorithm&quot;&gt;Nagle算法&lt;/a&gt;带来的延迟（一般也不建议开启Nagle算法）。假如当前写缓冲区中没有数据，我们先通过write写4个字节，这时TCP协议栈将其发送出去，然后再通过write写96个字节，这时，由于前面发送了一个报文，还没有收到ACK，并且当前可发送数据未达到MSS，Nagle算法不允许继续发送报文，必须等到前一个报文的ACK回来才能继续发送数据，大大降低了吞吐量并且提高了延迟。如果接收端开启了&lt;a href=&quot;https://en.wikipedia.org/wiki/TCP_delayed_acknowledgment&quot;&gt;延迟ACK&lt;/a&gt;，影响更大。&lt;/p&gt;

&lt;p&gt;因此，应该尽量批量读写网络数据，以提升性能。&lt;/p&gt;

&lt;h1 id=&quot;13tcp&quot;&gt;13. 谨慎设置TCP缓冲区大小&lt;/h1&gt;

&lt;p&gt;一般来说我们不需要更改TCP默认缓冲区大小，如果我们确实有需求设置，也需要谨慎考虑与评估。&lt;/p&gt;

&lt;p&gt;TCP缓冲区大小设置为多少合适呢？我们知道，TCP 的传输速度，受制于发送窗口与接收窗口大小，以及网络传输能力。其中，两个窗口由缓冲区大小决定，如果缓冲区大小与网络传输能力匹配，那么缓冲区的利用率就是最高的。&lt;/p&gt;

&lt;p&gt;带宽时延积（缩写为 BDP，&lt;a href=&quot;https://en.wikipedia.org/wiki/Bandwidth-delay_product&quot;&gt;Bandwidth-delay Product&lt;/a&gt;）是用来描述网络传输能力的。如最大带宽是 100MB/s、网络时延是 10ms 时，客户端到服务端之间的网络一共可以存放 100MB/s * 0.01s = 1MB 的字节，这个 1MB 是带宽与时延的乘积，也就是带宽时延积。这 1MB 字节存在于飞行中的 TCP 报文，它们就在网络线路、路由器等网络设备上。如果飞行报文超过了 1MB，就一定会让网络过载，最终导致丢包。&lt;/p&gt;

&lt;p&gt;由于发送缓冲区决定了发送窗口的上限，而发送窗口又决定了已发送但未确认的飞行报文的上限，因此，发送缓冲区不能超过带宽时延积，因为超出的部分没有办法用于有效的网络传输，且飞行字节大于带宽时延积还会导致丢包，从而触发网络拥塞避免；而且，缓冲区也不能小于带宽时延积，否则无法发挥出高速网络的价值。&lt;/p&gt;

&lt;p&gt;总结而言：缓冲区太小，会降低TCP吞吐量，无法高效利用网络带宽，导致通信延迟升高；缓冲区太大，会导致TCP连接内存占用高以及受限于带宽时延积的瓶颈，从而造成内存浪费。如果缓冲区过小，如2K，还可能会导致&lt;a href=&quot;https://en.wikipedia.org/wiki/TCP_congestion_control#Fast_retransmit&quot;&gt;快速重传&lt;/a&gt;无法生效，因为未确认的报文可能最多只有2个，不会出现3个重复的ACK。&lt;/p&gt;

&lt;p&gt;Linux系统是可以根据系统状态自动调节缓冲区大小的，相关参数由&lt;code&gt;net.ipv4.tcp_wmem&lt;/code&gt;和&lt;code&gt;net.ipv4.tcp_rmem&lt;/code&gt;控制，参数是一个3元组&lt;min default=&quot;&quot; max=&quot;&quot;&gt;，即最大值、初始默认值、最大值。但如果在 socket 上直接设置 SO&lt;em&gt;SNDBUF 或者 SO&lt;/em&gt;RCVBUF，这样会关闭缓冲区的系统动态调整功能，这样操作前务必要进行充分的评估。 &lt;br/&gt;
因此，除非非常明确自己的需求，以及进行充分的评估与验证，否则，不要轻易设置TCP缓冲区大小。&lt;/min&gt;&lt;/p&gt;

&lt;h1 id=&quot;14&quot;&gt;14. 网络相关参数支持灵活配置&lt;/h1&gt;

&lt;p&gt;当应用可能有多种部署环境、部署场景时，需要根据使用场景、网络环境等因素，调整合适的网络相关参数。LAN和WAN的网络状况差别很大，会涉及到诸多参数的调整。&lt;/p&gt;

&lt;p&gt;比如对于有赞的服务代理组件&lt;a href=&quot;https://tech.youzan.com/service-meshzai-you-zan-de-shi-jian-yu-fa-zhan/&quot;&gt;Tether&lt;/a&gt;，既有数据中心内的sidecar部署场景，又有跨公网的网关部署场景，这时就需要按需调整对应的参数，否则难以适应不同的网络环境。如连接超时、读写超时、健康检查超时、健康检查失败阈值等都应该支持灵活配置。&lt;/p&gt;

&lt;h1 id=&quot;15&quot;&gt;15. 合理设置连接池大小&lt;/h1&gt;

&lt;p&gt;对于不同类型的协议，连接池的设计也不同。我们将协议是否支持连接多路复用划分为两类：非多路复用协议和多路复用协议。非多路复用协议，一个连接发送请求后，必须等待响应返回后，该连接才能发送新的请求，如HTTP1.1、Redis等；多路复用协议，支持同一个连接同时发送多个请求，如HTTP2、gRPC、Dubbo等。&lt;/p&gt;

&lt;p&gt;我们先看一下非多路复用协议如何设置连接池大小。连接池涉及到的参数一般有：最小连接数、最大连接数、最大空闲时间、连接获取超时时间、连接获取超时重试次数等。应用与连接池主要交互逻辑如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/content/images/2021/05/conn_pool-1.png&quot; align=&quot;center&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我们主要讨论最小连接数和最大连接数。之所以不是固定连接数，是因为流量有高峰、有低谷；固定连接数太小，流量高峰期容易导致请求等待时间过长；固定连接数太大，流量低谷期容易造成资源浪费。因此，最小连接数对应的就是流量低谷期连接数多少为合适，最大连接数对应的就是流量高峰期连接数多少为合适，也就是连接数与流量大小是相关的。除了流量大小，还需要考虑请求RT，即每个请求占用连接的时间。所需要的连接数其实就是请求并发数，这里我们可以利用著名的利特尔法则（&lt;a href=&quot;https://en.wikipedia.org/wiki/Little%27s_law&quot;&gt;Little&#x27;s law&lt;/a&gt;）来计算，&lt;em&gt;L=λW&lt;/em&gt;，在该场景即：并发数 = 请求QPS * 请求RT。比如流量低谷期请求QPS为100，请求RT为0.05s，则并发数为5，所需连接数为5；流量高峰期请求QPS为500，请求RT为0.1s，则并发数为50，所需连接数为50。这类问题其实与&lt;a href=&quot;https://en.wikipedia.org/wiki/Queueing_theory&quot;&gt;排队论&lt;/a&gt;相关，不过我们这里不做过多讨论，如果有更复杂的需求场景，可以参考更多排队论相关资料。&lt;/p&gt;

&lt;p&gt;接下来我们继续看一下多路复用协议如何设置连接池大小。连接池涉及到的参数一般有：最小连接数、最大连接数、单连接并发请求数高水位、单连接并发请求数低水位。当单连接并发请求数高于高水位时，如果连接池未达到最大连接数，进行连接池扩容，创建连接；当单连接并发请求数低于低水位时，如果连接池未达到最小连接数，进行连接池缩容，释放连接（释放过程需要做到平滑）。由于每个请求不独占连接，请求是可以选择任意连接的，所以这里也面临负载均衡的问题，需要尽可能的确保每个连接上的处理中的请求数接近平均值。一般使用最少请求数负载均衡，但最少请求数负载均衡时间复杂度可能比较高，最简单的实现需要扫描整个连接池。我们可以使用其近似的优化实现，随机选择两个连接，选择Pending请求数少的连接；为了更加近似最少请求，可以选择3个、5个，甚至更多个连接，取其中Pending请求数最少的连接。&lt;/p&gt;

&lt;h1 id=&quot;16&quot;&gt;16. 完善网络指标监控&lt;/h1&gt;

&lt;p&gt;需要对各个关键网络指标进行监控与告警，包括但不限于：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TCP连接建立失败数&lt;/li&gt;
&lt;li&gt;TCP报文重传率&lt;/li&gt;
&lt;li&gt;TCP各个状态连接数（尤其是&lt;code&gt;ESTABLISHED&lt;/code&gt;、&lt;code&gt;TIME_WAIT&lt;/code&gt;、&lt;code&gt;CLOSE_WAIT&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;TCP主动关闭连接数&lt;/li&gt;
&lt;li&gt;TCP被动关闭连接数&lt;/li&gt;
&lt;li&gt;连接健康检查失败数&lt;/li&gt;
&lt;li&gt;系统及进程FD使用数&lt;/li&gt;
&lt;li&gt;连接池大小 &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果能尽早发现这些指标的异常，那么就可以尽快发现问题，从而降低问题影响面。&lt;/p&gt;

&lt;h1 id=&quot;&quot;&gt;总结&lt;/h1&gt;

&lt;p&gt;本文根据有赞TCP网络编程实践经验总结了&lt;strong&gt;16&lt;/strong&gt;项建议，希望能够在TCP网络编程方面帮助大家提升应用的健壮性、可靠性，减少线上问题与故障。&lt;/p&gt;

&lt;h1 id=&quot;&quot;&gt;参考资料&lt;/h1&gt;



&lt;p&gt;`&lt;/p&gt;
                    &lt;p class=&quot;break-line&quot;&gt;欢迎关注我们的公众号&lt;/p&gt;
                    &lt;img src=&quot;https://tech.youzan.com/static_image/coder_qrcode.png&quot;/&gt;
&lt;/section&gt;

&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>35b847572daa0a8491692d02ce6fff69</guid>
<title>[推荐] 面试题：MySQL 一棵 B+ 树能存多少条数据？</title>
<link>https://toutiao.io/k/85kvlje</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;大家好，我是Tom哥~&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;&lt;span&gt;今日寄语：充满活力的新人，能让身边的人都重回初心，真是不可思议。&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;span&gt;my&lt;/span&gt;&lt;span&gt;sql 的InnoDB存储引擎 一棵B+树可以存放多少行数据?&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.41114982578397213&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzpVLicRx4bhoYFC2IyEJGQichDkNPaf1ubltvu1LibkZTwU9dP5pyVJejA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;574&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;（答案在文章中！！）&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;要搞清楚这个问题，首先要从InnoDB索引数据结构、数据组织方式说起。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们都知道计算机有五大组成部分：控制器，运算器，存储器，输入设备，输出设备。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;其中很重要的，也跟今天这个题目有关系的是存储器。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们知道万事万物都有自己的单元体系，若干个小单体组成一个个大的个体。就像拼乐高一样，可以自由组合。所以说，如果能熟悉最小单元，就意味着我们抓住了事物的本事，再复杂的问题也会迎刃而解。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;存储单元&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;br/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;存储器范围比较大，但是数据具体怎么存储，有自己的最小存储单元。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1、数据持久化存储磁盘里，磁盘的最小单元是扇区，&lt;/span&gt;&lt;code&gt;&lt;span&gt;一个扇区的大小是 512个字节&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2、文件系统的最小单元是块，&lt;/span&gt;&lt;code&gt;&lt;span&gt;一个块的大小是 4K&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3、InnoDB存储引擎，有自己的最小单元，称之为页，&lt;/span&gt;&lt;code&gt;&lt;span&gt;一个页的大小是16K&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;扇区、块、页这三者的存储关系？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4234375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzlYj9YicSEnH5fHR3M2vhZXRAx5ziaicicGYF8ticfyhddjfoMDSsia5F2kzA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;InnoDB引擎&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果mysql部署在本地，通过命令行方式连接mysql，默认的端口 &lt;/span&gt;&lt;code&gt;&lt;span&gt;3306&lt;/span&gt;&lt;/code&gt;&lt;span&gt; ，然后输入密码即可进入&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;mysql -u root -p&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;查看InnoDB的页大小&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;&lt;span&gt;show variables like &lt;span&gt;&#x27;innodb_page_size&#x27;&lt;/span&gt;;&lt;br/&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.3391304347826087&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzEFG2ibmpdO3d6tPLUeKoXj30aAaJKib31DbJrsucRC8RGAffyxIcNO6w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;690&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;mysql数据库中，table表中的记录都是存储在页中，那么一页可以存多少行数据？假如一行数据的大小约为1K字节，那么按 &lt;/span&gt;&lt;code&gt;&lt;span&gt;16K / 1K = 16&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，可以计算出一页大约能存放16条数据。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;mysql 的最小存储单元叫做“页”，这么多的页是如何构建一个庞大的数据组织，我们又如何知道数据存储在哪一个页中？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;如果逐条遍历，性能肯定很差。为了提升查找速度，我们引入了&lt;/span&gt;&lt;code&gt;&lt;span&gt;B+树&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，先来看下&lt;/span&gt;&lt;code&gt;&lt;span&gt;B+树&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的存储结构&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.7431972789115646&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzQoknttTWIrdxibtddSIiaXkNRwaa7nbLNhzAZic8jOx7ExBGFkDT5hZQg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1176&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;页除了可以存放&lt;/span&gt;&lt;code&gt;&lt;span&gt;数据&lt;/span&gt;&lt;/code&gt;&lt;span&gt;（叶子节点），还可以存放&lt;/span&gt;&lt;code&gt;&lt;span&gt;健值和指针&lt;/span&gt;&lt;/code&gt;&lt;span&gt;（非叶子节点），当然他们是有序的。这样的数据组织形式，我们称为索引组织表。&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;如：上图中 page number=3的页，该页存放键值和指向数据页的指针，这样的页由N个键值+指针组成&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;B+ 树是如何检索记录？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;首先找到根页，你怎么知道一张表的根页在哪呢？&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;其实每张表的根页位置在表空间文件中是固定的，即page number=3的页&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;找到根页后通过二分查找法，定位到id=5的数据应该在指针P5指向的页中&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;然后再去page number=5的页中查找，同样通过二分查询法即可找到id=5的记录&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;如何计算B+树的高度？&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在&lt;/span&gt;&lt;code&gt;&lt;span&gt;InnoDB&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 的表空间文件中，约定&lt;/span&gt;&lt;code&gt;&lt;span&gt;page number = 3&lt;/span&gt;&lt;/code&gt;&lt;span&gt;表示主键索引的根页&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;SELECT&lt;br/&gt;b.name, a.name, index_id, &lt;span&gt;type&lt;/span&gt;, a.space, a.PAGE_NO&lt;br/&gt;FROM&lt;br/&gt;information_schema.INNODB_SYS_INDEXES a,&lt;br/&gt;information_schema.INNODB_SYS_TABLES b&lt;br/&gt;WHERE&lt;br/&gt;a.table_id = b.table_id AND a.space &amp;lt;&amp;gt; 0&lt;br/&gt;and b.name like &lt;span&gt;&#x27;%sp_job_log&#x27;&lt;/span&gt;;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.4416326530612245&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzDYSy4C3FBQGVAicTia8eWaE0ibSbmR1nR0fQrxvPzpH314j8wwD7BQzJQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1225&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;从图中可以看出，每个表的主键索引的根页的page number都是3，而其他的二级索引page number为4&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;在根页偏移量为&lt;/span&gt;&lt;code&gt;&lt;span&gt;64&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的地方存放了该B+树的&lt;/span&gt;&lt;code&gt;&lt;span&gt;page level&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。主键索引B+树的根页在整个表空间文件中的第3个页开始，所以算出它在文件中的偏移量：&lt;/span&gt;&lt;code&gt;&lt;span&gt;16384*3 + 64 = 49152 + 64 =49216&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，前2个字节中。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;首先，找到MySql数据库物理文件存放位置：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;show global variables like &lt;span&gt;&quot;%datadir%&quot;&lt;/span&gt; ;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.23905723905723905&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketznDFboCv74nXKOaM99gicGfGPWOX4iaV47GdCokFqSrlUv32h8z5mS6wA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;594&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;hexdump工具，查看表空间文件指定偏移量上的数据：&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;hexdump -s 49216 -n 10  sp_job_log.ibd&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.09765625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzuZepNfX9ZfrDShVg5coaEoKmmZEe5jAxad1Te2Q5y8v5IcI09mzzpw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;page_level 值是 1，那么 B+树高度为 &lt;/span&gt;&lt;code&gt;&lt;span&gt;page level + 1 = 2&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;特别说明：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;查询数据库时，不论读一行，还是读多行，都是将这些行所在的整页数据加载，然后在内存中匹配过滤出最终结果。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;p&gt;&lt;span&gt;表的检索速度跟树的深度有直接关系，毕竟一次页加载就是一次IO，而磁盘IO又是比较费时间。&lt;/span&gt;&lt;code&gt;&lt;span&gt;对于一张千万级条数B+树高度为3的表与几十万级B+树高度也为3的表，其实查询效率相差不大。&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;一棵树可以存放多少行数据？&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;假设B+树的深度为2&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;这棵B+树的存储总记录数 = &lt;/span&gt;&lt;code&gt;&lt;span&gt;根节点指针数 * 单个叶子节点记录条数&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;strong&gt;&lt;span&gt;那么指针数如何计算？&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;假设主键ID为&lt;/span&gt;&lt;code&gt;&lt;span&gt;bigint&lt;/span&gt;&lt;/code&gt;&lt;span&gt;类型，长度为&lt;/span&gt;&lt;code&gt;&lt;span&gt;8字节&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，而指针大小在InnoDB源码中设置为&lt;/span&gt;&lt;code&gt;&lt;span&gt;6字节&lt;/span&gt;&lt;/code&gt;&lt;span&gt;，这样一共&lt;/span&gt;&lt;code&gt;&lt;span&gt;14字节&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;那么一个页中能存放多少这样的组合，就代表有多少指针，即 &lt;/span&gt;&lt;code&gt;&lt;span&gt;16384 / 14 = 1170&lt;/span&gt;&lt;/code&gt;&lt;span&gt;。那么可以算出一棵高度为2 的B+树，能存放 &lt;/span&gt;&lt;code&gt;&lt;span&gt;1170 * 16 = 18720&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 条这样的数据记录。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;同理：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;高度为3的B+树可以存放的行数 =  &lt;/span&gt;&lt;code&gt;&lt;span&gt;1170 * 1170 * 16 = 21902400&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;千万级的数据存储只需要约3层B+树，查询数据时，每加载一页（page）代表一次IO。所以说，根据主键id索引查询约3次IO便可以找到目标结果。&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;对于一些复杂的查询，可能需要走二级索引，那么通过二级索引查找记录最多需要花费多少次IO呢？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.66640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketz38TgsCyJTkFxDq7psbdsdsbYqoL9le40CKiaeaiaObAliaFWnOaGs48aA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;首先，从二级索引B+树中，根据&lt;/span&gt;&lt;code&gt;&lt;span&gt;name&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 找到对应的主键id&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.69296875&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzk8Vt860QGV3uwh5GjeEgfwmRcYFpADH8hZNwV2ic5eTutzYPGhVEttQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;然后，再根据主键id 从 聚簇索引查找到对应的记录。如上图所示，二级索引有3层，聚簇索引有3层，那么最多花费的IO次数是：3+3 = 6&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;聚簇索引默认是主键，如果表中没有定义主键，InnoDB 会选择一个唯一的非空索引代替。如果没有这样的索引，InnoDB 会隐式定义一个主键来作为聚簇索引。&lt;/span&gt;&lt;/p&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;这也是为什么InnoDB表必须有主键，并且推荐使用整型的自增主键！！！&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote data-tool=&quot;mdnice编辑器&quot;&gt;&lt;p&gt;InnoDB使用的是聚簇索引，将主键组织到一棵B+树中，而行数据就储存在叶子节点上&lt;/p&gt;&lt;/blockquote&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;&lt;strong&gt;举例说明：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1、若使用&lt;/span&gt;&lt;code&gt;&lt;span&gt;&quot;where id = 14&quot;&lt;/span&gt;&lt;/code&gt;&lt;span&gt;这样的条件查找记录，则按照B+树的检索算法即可查找到对应的叶节点，之后获得行数据。&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2、若对Name列进行条件搜索，则需要两个步骤：&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键值。&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;第二步使用主键值在主索引B+树中再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据。（重点在于通过其他键需要建立辅助索引）&lt;/span&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;span/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;实战演示&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;实际项目中，每个表的结构设计都不一样，占用的存储空间大小也各不相等。如何计算不同的B+树深度下，一个表可以存储的记录条数？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;我们以业务日志表 &lt;/span&gt;&lt;code&gt;&lt;span&gt;sp_job_log&lt;/span&gt;&lt;/code&gt;&lt;span&gt; 为例，讲解详细的计算过程：&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;1、查看表的状态信息&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;show table status like &lt;span&gt;&#x27;sp_job_log&#x27;&lt;/span&gt;\G&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.54140625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzPSO6icytqwXDU2rF2yy2CJKyc3V4462NyPbvuVroIicBhoz7Bk5TILDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;图中看到&lt;/span&gt;&lt;code&gt;&lt;span&gt;sp_job_log&lt;/span&gt;&lt;/code&gt;&lt;span&gt;表的行平均大小为&lt;/span&gt;&lt;code&gt;&lt;span&gt;153&lt;/span&gt;&lt;/code&gt;&lt;span&gt;个字节&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;2、查看表结构&lt;/span&gt;&lt;/p&gt;&lt;pre data-tool=&quot;mdnice编辑器&quot;&gt;&lt;code&gt;desc sp_job_log;&lt;br/&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img class=&quot;rich_pages js_insertlocalimg&quot; data-ratio=&quot;0.2640625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/2KTof9YshwfxA7iaBRvMqhOtRNlUOketzlKOpFialibXWIiaZOIY26AZjhr2lTWicGTfOxAdq7xeZTzCZS0ib5ZQgVicQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;3、计算B+树的行数&lt;/span&gt;&lt;/p&gt;&lt;ul data-tool=&quot;mdnice编辑器&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;单个叶子节点（页）中的记录数 = 16K / 153 = 105&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;非叶子节点能存放多少指针， 16384 / 14 = 1170&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;li&gt;&lt;section&gt;&lt;span&gt;如果树的高度为3，可以存放的记录行数 =  1170 * 1170 * 105 = 143,734,500&lt;/span&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;span&gt;最后加餐&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;h2 data-tool=&quot;mdnice编辑器&quot;/&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;普通索引和唯一索引在查询效率上有什么不同？&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;span&gt;唯一索引就是在普通索引上增加了约束性，也就是关键字唯一，找到了关键字就停止检索。而普通索引，可能会存在用户记录中的关键字相同的情况，根据页结构的原理，当我们读取一条记录的时候，不是单独将这条记录从磁盘中读出去，而是将这个记录所在的页全部加载到内存中进行读取。InnoDB 存储引擎的页大小为 16KB，在一个页中可能存储着上千个记录，因此在普通索引的字段上进行查找也就是在内存中多几次&lt;/span&gt;&lt;code&gt;&lt;span&gt;判断下一条记录&lt;/span&gt;&lt;/code&gt;&lt;span&gt;的操作，对于 CPU 来说，这些操作所消耗的时间是可以忽略不计的。所以对一个索引字段进行检索，采用普通索引还是唯一索引在检索效率上基本上没有差别。&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;p&gt;&lt;/p&gt;&lt;hr/&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section&gt;&lt;span&gt;关于我：前阿里架构师，出过专利，竞赛拿过奖，CSDN博客专家，负责过电商交易、社区生鲜、营销、金融等业务，多年团队管理经验，爱思考，喜欢结交朋友&lt;/span&gt;&lt;/section&gt;&lt;h1 accuse=&quot;qTitle&quot;&gt;&lt;span&gt;&lt;span&gt;「长按2秒」↓↓&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;↓ 二维码，拉你进群，一线大厂技术交流&lt;/span&gt;&lt;/span&gt;&lt;/h1&gt;&lt;section data-tool=&quot;mdnice编辑器&quot; data-website=&quot;https://www.mdnice.com&quot;&gt;&lt;section&gt;&lt;p&gt;&lt;img class=&quot;rich_pages&quot; data-galleryid=&quot;&quot; data-ratio=&quot;1.2021660649819494&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/3Ohm6WHibeXLL4AVYEUeBKzcTZJd7mrk9XicnYiccg6n8YjsA4ibpRk6hkog7Qqx6cJNIF1rhicl992vID1IFUKWYuw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;554&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;推荐阅读&lt;/span&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&amp;amp;mid=2247484947&amp;amp;idx=1&amp;amp;sn=5a70f88fba83b435b8144bf1ddd3cc9f&amp;amp;chksm=ceb9fab8f9ce73ae97afc43f87314dd3bb61c966b9a40c12801cddc454dcf2845bbb605694e3&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;亿级系统的Redis缓存如何设计？？？&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&amp;amp;mid=2247484957&amp;amp;idx=1&amp;amp;sn=e50e0808cb6503ca7214bdd6fee4f134&amp;amp;chksm=ceb9fab6f9ce73a0c0725e381673fc7dc50c0594fb995b5f985b263143b34371e5e2936d7be0&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;【高并发、高性能、高可用】系统设计经验&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&amp;amp;mid=2247484929&amp;amp;idx=1&amp;amp;sn=d8cb3306dea9f1b92fd30d59da3f536a&amp;amp;chksm=ceb9faaaf9ce73bca59b46021a450fdc84aa0f85d6b49ff0e5578cc3abaa1433447f7dffc5e4&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;人人都是架构师？？？谈何容易！！&lt;/a&gt;&lt;/p&gt;&lt;p data-tool=&quot;mdnice编辑器&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg2NzYyNjQzNg==&amp;amp;mid=2247484921&amp;amp;idx=1&amp;amp;sn=b429efe7e622759fc8f3bb24c2979a90&amp;amp;chksm=ceb9f952f9ce7044b001528ce8ae0ec89ed63727764081c21a8400e9f8f685345ec9cb0a54d7&amp;amp;scene=21#wechat_redirect&quot; data-itemshowtype=&quot;0&quot; tab=&quot;innerlink&quot; data-linktype=&quot;2&quot;&gt;【万级并发】电商库存扣减如何设计？不超卖！&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>a5436073ffaaf6f7ac60381a52090cc4</guid>
<title>[推荐] 网络连接存在大量 time_wait 和 close_wait 的原因以及解决方法</title>
<link>https://toutiao.io/k/b9vlrcu</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;rich_media_content &quot; id=&quot;js_content&quot;&gt;
                    

                    
                    
                    
                    &lt;p data-source-line=&quot;1&quot;&gt;如果对tcp中的握手挥手不了解的同学，请先看这篇博客：《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247483765&amp;amp;idx=1&amp;amp;sn=70179fa0e28aacd42d4c15dbd08bc6fc&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;关于三次握手与四次挥手你要知道这些&lt;/a&gt;》。&lt;/p&gt;&lt;p data-source-line=&quot;3&quot;&gt;&lt;img data-ratio=&quot;0.6995305164319249&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/OqTAl3WTC7Gzia45CTkHaZ3W8ewRXgOZ5ayNKNuHChs2vHVS9qBKiaxTnpb6vbcmkl9nCEGQich82xDS8wSBzx5zQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;426&quot;/&gt;&lt;/p&gt;&lt;p data-source-line=&quot;5&quot;&gt;四次挥手过程：&lt;/p&gt;&lt;p data-source-line=&quot;7&quot;&gt;第一次挥手：主机A（可以是客户端，也可以是服务器端），设置Sequence Number和Acknowledgment Number，向主机B发送一个FIN报文段；此时，主机A进入FIN_WAIT_1状态；这表示主机A没有数据要发送给主机B了。&lt;/p&gt;&lt;p data-source-line=&quot;9&quot;&gt;第二次挥手：主机B收到了主机A发送的FIN报文段，向主机A回一个ACK报文段，Acknowledgment Number为Sequence Number加1，主机A进入FIN_WAIT_2状态；主机B告诉主机A，我也没有数据要发送了，可以进行关闭连接了。&lt;/p&gt;&lt;p data-source-line=&quot;11&quot;&gt;第三次挥手：主机B向主机A发送FIN报文段，请求关闭连接，同时主机B进入CLOSE_WAIT状态。&lt;/p&gt;&lt;p data-source-line=&quot;13&quot;&gt;第四次挥手：主机A收到主机B发送的FIN报文段，向主机B发送ACK报文段，然后主机A进入TIME_WAIT状态；主机B收到主机A的ACK报文段以后，就关闭连接；此时，主机A等待2MSL后依然没有收到回复，则证明主机B已正常关闭，那好，主机A也可以关闭连接了。&lt;/p&gt;&lt;h2 data-source-line=&quot;15&quot;&gt;大量time_wait&lt;/h2&gt;&lt;h3 data-source-line=&quot;17&quot;&gt;问题原因&lt;/h3&gt;&lt;p data-source-line=&quot;19&quot;&gt;《&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;amp;mid=2247483765&amp;amp;idx=1&amp;amp;sn=70179fa0e28aacd42d4c15dbd08bc6fc&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; data-linktype=&quot;2&quot;&gt;关于三次握手与四次挥手你要知道这些&lt;/a&gt;》中有关于“四次挥手释放连接时，等待2MSL的意义”的解释。正因为有2ML的存在，所以可能会发生大量time_wait存在的现象，从而影响服务器性能，甚至导致套接字数量达到服务器上限。&lt;/p&gt;&lt;blockquote data-source-line=&quot;21&quot;&gt;&lt;p&gt;实际上，TIME_WAIT对于系统资源的消耗影响比较小，而真正需要考虑因为TIME_WAIT多而触碰到限制的是如下几个方面：&lt;/p&gt;&lt;ol class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;源端口数量 (net.ipv4.ip_local_port_range)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;TIME_WAIT bucket 数量 (net.ipv4.tcp_max_tw_buckets)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;文件描述符数量 (max open files)&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/blockquote&gt;&lt;h3 data-source-line=&quot;26&quot;&gt;解决方法&lt;/h3&gt;&lt;p data-source-line=&quot;28&quot;&gt;只需要优化服务器系统的网络配置，连接配置，使用socket重用或及时释放资源即可。（由于系统不断迭代，所以这里不给出具体参数修改）&lt;/p&gt;&lt;h2 data-source-line=&quot;30&quot;&gt;大量close_wait&lt;/h2&gt;&lt;h3 data-source-line=&quot;32&quot;&gt;问题原因&lt;/h3&gt;&lt;p data-source-line=&quot;34&quot;&gt;主机B一直没有进行第三次挥手，会导致主机B存在大量close_wait状态的连接。大量这种情况发生会影响服务器性能，同样可能导致套接字数量达到服务器上限。&lt;/p&gt;&lt;p data-source-line=&quot;36&quot;&gt;网络连接未及时释放，通常是服务端发生异常后未关闭连接或者close_wait的配置时间过长。如果是mysql数据库也可能存在事务开启后没有正确rollback或commit的可能。&lt;/p&gt;&lt;p data-source-line=&quot;38&quot;&gt;总之，都是大概率是服务端代码或配置的问题。&lt;/p&gt;&lt;h3 data-source-line=&quot;40&quot;&gt;解决方法&lt;/h3&gt;&lt;p data-source-line=&quot;42&quot;&gt;以下方法并不存在顺序，定位问题时也并不是一定同时需要。&lt;/p&gt;&lt;ul data-source-line=&quot;44&quot; class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;top查看cpu利用率和load情况（大量close_wait属于io密集型，会导致load相比cpu利用率高出很多）&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;netstat观察close_wait的数量变化。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;wireshark辅助查看网络包的发送情况。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;perf或者火焰图定位热点函数。&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;java可以将服务器线程堆栈dump，查看大量线程在哪里blocked。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;
                &lt;/div&gt;

                

                



                
                &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>