<?xml version="1.0" encoding="UTF-8"?>
        <rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
            <channel>
            <title>开发者头条</title>
            <link>http://toutiao.io/</link>
            <description></description>
<item>
<guid>ff8c596ee779d910bb850b613bf71bee</guid>
<title>用 JuiceFS 备份 Nginx 日志可以这么简单</title>
<link>https://toutiao.io/k/mqopme2</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;post_content markdown&quot;&gt;&lt;p&gt;前一段，我们写了一篇讲异地备份重要性的文章，一周之后北京真的地震了，当时的时间是傍晚 6 点多一点，大部分工程师写代码正嗨的时候，地震之后就看到朋友圈里有人说感觉到地震的第一反应就是 git push，多么冰雪聪明、尽职尽责，可是你的线上数据做好备份了么？&lt;/p&gt;&lt;p&gt;在我们线上的生产环境中要备份的东西很多，各种服务日志、数据库数据、用户上传数据、代码等等。用 JuiceFS 来备份可以节省你大量时间，我们会围绕这个主题写一系列的教程，整理出一套最佳实践，方便大家。&lt;/p&gt;&lt;p&gt;今天第一篇就写写最常用的 Nginx 日志备份。&lt;/p&gt;&lt;h1 id=&quot;如何用-juicefs-备份-nginx-日志&quot;&gt;如何用 JuiceFS 备份 Nginx 日志&lt;/h1&gt;&lt;p&gt;生产环境中的 Nginx 经常作为反向代理，配置多台，用来对接后面的各种应用服务。日志主要有两类，访问日志 (access.log) 和错误日志 (error.log)。&lt;/p&gt;&lt;p&gt;日志是分散在每个 Nginx 节点的磁盘上的，每台机器自己的磁盘并不安全，而且分散的日志也难以维护和使用。所以，我们都会将日志汇总在一个更靠谱的存储系统中，一方面长期存储安全可靠，一方面也方便做分析使用。&lt;/p&gt;&lt;p&gt;在日志的存储上需要里，容量扩展性强，稳定安全，方便运维操作，价格便宜，最好按使用量付费是重点，对于存储性能的要求会低一些。目前常用的有 NFS、HDFS、对象存储等，把这些存储与 JuiceFS 做个比较：&lt;/p&gt;&lt;p&gt;说到日志的收集方式，主要有两种：&lt;strong&gt;定时收集&lt;/strong&gt; 和 &lt;strong&gt;实时收集&lt;/strong&gt;，我们在下面分别说明。JuiceFS 使用客户自己的对象存储保存文件数据，所以也自然继承了对象存储的好处，在此之上，我们提供了高性能的元数据服务和完整的 POSIX 兼容，使用上又比对象存储便利的多。&lt;/p&gt;&lt;h2 id=&quot;定时收集&quot;&gt;定时收集&lt;/h2&gt;&lt;p&gt;通常按照 小时、天，把日志拷贝到一个统一的存储点。这方面的工具集很多，我们用 Linux 默认安装的 logrotate 举例说明。&lt;/p&gt;&lt;p&gt;首先，要在 &lt;a href=&quot;https://juicefs.com&quot;&gt;JuiceFS 网站&lt;/a&gt; 注册个账号，并创建了一个文件系统，假设叫 super-backup。&lt;/p&gt;&lt;p&gt;第一步，每台机器安装 JuiceFS 客户端，挂载到 &lt;code&gt;/jfs&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;下载 JuiceFS 客户端&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;curl -L juicefs.io/static/juicefs -o juicefs &amp;amp;&amp;amp; chmod +x juicefs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;挂载文件系统&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;sudo ./juicefs mount super-backup /jfs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在自动化配置管理中使用 JuiceFS 也同样方便，具体方法请在上手指南中查看 &lt;a href=&quot;https://juicefs.io/docs/zh/getting_started.html#remember-authentication&quot;&gt;如何通过命令行认证&lt;/a&gt; 和 &lt;a href=&quot;https://juicefs.io/docs/zh/getting_started.html#mount-on-boot&quot;&gt;开机自动挂载&lt;/a&gt;，我们支持 &lt;a href=&quot;https://juicefs.io/docs/zh/getting_started.html#docker&quot;&gt;Docker 中挂载&lt;/a&gt; 和 &lt;a href=&quot;https://juicefs.io/docs/zh/use_juicefs_in_kubernetes.html&quot;&gt;Kubernates&lt;/a&gt; 中挂载。&lt;/p&gt;&lt;p&gt;第二步，在每台机器上用 logrotate 配置日志的滚动策略，修改 &lt;code&gt;/etc/logrotate.d/nginx&lt;/code&gt;&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;/var/log/nginx/*.log {
    daily    # 每天滚动一次
    compress
    dateext # 把日期添加到文件名中
    sharedscripts
    postrotate
        [ -f /var/run/nginx.pid ] &amp;amp;&amp;amp; kill -USR1 `cat /var/run/nginx.pid` # 重新加载日志文件
    endscript
    lastaction
        rsync -au *.gz /jfs/nginx-logs/`hostname -s`/ # 把压缩好的日志同步到 JuiceFS
    endscript
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;到此，Nginx 日志就可以每天 rotate 并保存到 JuiceFS 中了。增加 Nginx 节点时，只需要在新增节点上做同样的配置即可。&lt;/p&gt;&lt;p&gt;如果使用 NFS，在 logrotate 中的配置是基本一样的。但是 NFS 有几个不足之处：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;大部分 NFS 存在单点故障，而 JuiceFS 是高可用的（专业版承诺 99.95% SLA）。&lt;/li&gt;&lt;li&gt;NFS 协议传输不加密，所以你需要保证 NFS 和 Nginx 在同一个 VPC 中，如果还有其他要备份的服务，部署上就很麻烦。JuiceFS 传输有 SSL 加密，不受 VPC 限制。&lt;/li&gt;&lt;li&gt;NFS 需要事先容量规划，JuiceFS 是弹性扩容，按容量付费的，更省心，更便宜。
如果使用 HDFS 或者 对象存储，日后访问备份数据时，就比较麻烦。JuiceFS 就简单很多，比如可以直接用 &lt;code&gt;zgrep&lt;/code&gt; 查询。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;再分享几个 Tips：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;执行 &lt;code&gt;logrotate -f /etc/logrotate.d/nginx&lt;/code&gt; 立即执行对 logrotate 配置做个验证。还可以用 -d 做调试。&lt;/li&gt;&lt;li&gt;Logrotate 基于 cron 运行，无论你设置 weekly、daily 还是 hourly，具体的执行时间可以在 &lt;code&gt;/etc/crontab&lt;/code&gt; 中修改。&lt;/li&gt;&lt;li&gt;如果你觉得日志文件太多，我们还提供了 &lt;code&gt;juicefs merge&lt;/code&gt; 命令可以快速合并 gzip 压缩过的日志文件。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;说完定时汇总，下一节我们再说说日志实时收集。&lt;/p&gt;&lt;h2 id=&quot;实时收集&quot;&gt;实时收集&lt;/h2&gt;&lt;p&gt;日志的实时收集已经有了很多开源工具，常用的有 &lt;a href=&quot;https://www.elastic.co/products/logstash&quot;&gt;Logstash&lt;/a&gt;、&lt;a href=&quot;https://flume.apache.org/&quot;&gt;Flume&lt;/a&gt;、&lt;a href=&quot;https://github.com/facebookarchive/scribe&quot;&gt;Scribe&lt;/a&gt;、&lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Kafka&lt;/a&gt; 等。&lt;/p&gt;&lt;p&gt;在集群不是很大的时候，日志收集、分析、索引、展示有个全家桶方案 ELK，其中用 &lt;a href=&quot;https://www.elastic.co/products/logstash&quot;&gt;Logstash&lt;/a&gt; 做日志收集和分析。&lt;/p&gt;&lt;p&gt;需要下面的部署方式：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在每台机器上部署一个 Logstash Agent（Flume 等其他工具同理）；&lt;/li&gt;&lt;li&gt;部署一个 Logstash Central 做日志汇总；&lt;/li&gt;&lt;li&gt;部署一个 Redis 做整个服务的 Broker，目的是在日志收集和写入中间做个缓冲，避免 Central 挂了导致日志丢失；&lt;/li&gt;&lt;li&gt;然后再配置 Central 的落盘方式，将日志存储到 JuiceFS / NFS / 对象存储 / HDFS 等。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;先看看架构图：&lt;/p&gt;&lt;p&gt;这里不讲 Logstash 在收集、分析、过滤环节的配置了，网络上有很多文章可查（比如：&lt;a href=&quot;https://doc.yonyoucloud.com/doc/logstash-best-practice-cn/index.html&quot;&gt;Logstash 最佳实践&lt;/a&gt;），说一下输出环节。&lt;/p&gt;&lt;p&gt;把 Logstash 收集处理好的日志保存到 JuiceFS 只要在配置的 output 部分设置一下：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;output {
   file {
       path =&amp;gt; &quot;/jfs/nginx-logs/%{host}-%{+yyyy/MM/dd/HH}.log.gz&quot;
       message_format =&amp;gt; &quot;%{message}&quot;
       gzip =&amp;gt; true
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;存储到 NFS 也可以用上面的配置，&lt;strong&gt;缺点和上文定时收集部分提到的相同&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;如果要保存到对象存储、HDFS，需要再配置 Logstash 的第三方插件，大部分是非官方的，随着 Logstash 版本的升级，使用时可能需要折腾一下。&lt;/p&gt;&lt;h2 id=&quot;最简单的实时收集方案&quot;&gt;最简单的实时收集方案&lt;/h2&gt;&lt;p&gt;其实还有更简单的实时日志收集方法，就是直接让 Nginx 把日志输出到 JuiceFS 中，省去了维护和部署日志收集系统的麻烦。使用这个方案可能会担心 JuiceFS 出问题时影响 Nginx 的正常运行，有两方面可以帮大家减少一些顾虑：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;JuiceFS 本身是一个高可用的服务，专业版承诺 99.95%的可用性，应该跟你的数据库等服务在一个可用性级别；&lt;/li&gt;&lt;li&gt;Nginx 的日志输出是使用异步IO来实现的，即使 JuiceFS 出现暂时性的抖动，也基本不影响 Nginx 的正常运行（restart 或者 reload 可能会受影响）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;如果不喜欢运维复杂的日志收集系统，这个方案值得一试。&lt;/p&gt;&lt;h1 id=&quot;给-nginx-日志加一份异地备份&quot;&gt;给 Nginx 日志加一份异地备份&lt;/h1&gt;&lt;p&gt;定时收集和实时收集都讲完了，在 super-backup 中存储的 Nginx 日志如何做个&lt;strong&gt;异地备份&lt;/strong&gt;呢？&lt;/p&gt;&lt;p&gt;只要两步：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;去 JuiceFS 网站控制台中，访问你文件系统的设置菜单，勾选 “启动复制”，然后选择你要复制到的对象存储，保存。&lt;/li&gt;&lt;li&gt;在所有挂载 super-backup 的机器上重新挂载 super-backup 即可。之后新写入的数据会很快同步到要复制的 Bucket 中，旧的数据也会在客户端定时扫描（默认每周一次）时同步。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这样可以全自动的在另外一个对象存储中同步一份数据，有效防止单一对象存储的故障或者所在区域的灾难。&lt;/p&gt;&lt;p&gt;你一定会问：JuiceFS 挂了怎么办？元数据访问不了，光有对象存储里的数据也没用啊。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;我们最近发布了一个重要功能 – 兼容模式的 JuiceFS&lt;/strong&gt;，所有的文件会按原样保存在对象存储中，脱离 JuiceFS 的元数据服务，也仍然可以访问里面的文件。对于备份这类一次写入不做修改的场景适合使用。&lt;/p&gt;&lt;h1 id=&quot;后记&quot;&gt;后记&lt;/h1&gt;&lt;p&gt;上面我们详细讲解了在 JuiceFS 备份 Nginx 日志的方法，后续还会介绍如何备份 Gitlab、MySQL、MongoDB、用户上传数据等等，欢迎大家踊跃&lt;a href=&quot;mailto:success@juicedata.io&quot;&gt;提需求和投稿&lt;/a&gt;。&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>242c08229b14d10b5b8bca413c2f029a</guid>
<title>《Rust 编码规范》</title>
<link>https://toutiao.io/k/injccgg</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;div class=&quot;weui-dialog&quot;&gt;
      &lt;p class=&quot;weui-dialog__hd&quot;&gt;&lt;strong class=&quot;weui-dialog__title&quot;&gt;&quot;Top Stories&quot; is disabled&lt;/strong&gt;&lt;/p&gt;
      &lt;p class=&quot;weui-dialog__bd&quot;&gt;
        Enable &quot;Top Stories&quot; in &quot;Settings&quot; &amp;gt; &quot;General&quot; &amp;gt; &quot;Manage Discover&quot;      &lt;/p&gt;
      
    &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>4fc0fc999523139db801ded9f0987c2c</guid>
<title>浴缸猫抓板｜猫咪玩具，点击领券9.9元包邮！</title>
<link>https://toutiao.io/k/caq2j5n</link>
<content:encoded>&lt;div&gt;&lt;body data-spm=&quot;10720394/n&quot; id=&quot;readabilityBody&quot;&gt;
    
    
    
    
    
    
      
      
    
    
    
    
    
  &lt;/body&gt;
&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>7e713fec1368de203559b85cdfebc4c2</guid>
<title>快手实时数仓建设实践</title>
<link>https://toutiao.io/k/21bsuqp</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;a class=&quot;weui-flex original_primary_card appmsg_card_context wx_tap_card js_wx_tap_highlight&quot; href=&quot;#&quot; id=&quot;copyright_info&quot;&gt;
                                
                                &lt;div class=&quot;weui-flex__item&quot; role=&quot;option&quot;&gt;
                                    &lt;strong class=&quot;original_primary_nickname&quot;&gt;Apache Flink&lt;/strong&gt;
                                                                            &lt;span class=&quot;weui-hidden_abs&quot;&gt;.&lt;/span&gt;
                                        &lt;p class=&quot;original_primary_desc&quot;&gt;Flink 中文社区官微，Flink PMC 维护&lt;/p&gt;
                                                                    &lt;/div&gt;
                                &lt;p class=&quot;weui-flex__ft&quot;/&gt;
                            &lt;/a&gt;
                        &lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
<item>
<guid>71718c23052e15e48f95825864043e77</guid>
<title>基于 Kafka 的实时数仓在搜索的实践应用</title>
<link>https://toutiao.io/k/tynr8z3</link>
<content:encoded>&lt;div&gt;&lt;div&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;24&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;作者：vivo互联网服务器团队-Deng jie&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;一、概述&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Apache Kafka 发展至今，已经是一个很成熟的消息队列组件了，也是大数据生态圈中不可或缺的一员。Apache Kafka 社区非常的活跃，通过社区成员不断的贡献代码和迭代项目，使得 Apache Kafka 功能越发丰富、性能越发稳定，成为企业大数据技术架构解决方案中重要的一环。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Apache Kafka 作为一个热门消息队列中间件，具备高效可靠的消息处理能力，且拥有非常广泛的应用领域。那么，今天就来聊一聊基于 Kafka 的实时数仓在搜索的实践应用。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;二、为什么需要 Kafka&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;在设计大数据技术架构之前，通常会做一些技术调研。我们会去思考一下为什么需要 Kafka？怎么判断选择的 Kafka 技术能否满足当前的技术要求？&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;2.1 早期的数据架构&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;早期的数据类型比较简单，业务架构也比较简单，就是将需要的数据存储下来。比如将游戏类的数据存储到数据库（MySQL、Oracle）。但是，随着业务的增量，存储的数据类型也随之增加了，然后我们需要使用的大数据集群，利用数据仓库来将这些数据进行分类存储，如下图所示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;236&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.4087301587301587&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHbOv5Z4kzKJ5SDEUUDn19fWLNAA10OJYLj32wTop6y31s1xhha8Q6Pg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;756&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;但是，数据仓库存储数据是有时延的，通常时延为T+1。而现在的数据服务对象对时延要求均有很高的要求，例如物联网、微服务、移动端APP等等，皆需要实时处理这些数据。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;2.2 Kafka 的出现&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Kafka 的出现，给日益增长的复杂业务，提供了新的存储方案。将各种复杂的业务数据统一存储到 Kafka 里面，然后在通过 Kafka 做数据分流。如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;268&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.46365914786967416&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHic6iaIbZg6bfmdoiap8VYiaM2WSqJK0y5y7icM2mqNIDXAFG3SkS8lLxVeg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1197&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;这里，可以将视频、游戏、音乐等不同类型的数据统一存储到 Kafka 里面，然后在通过流处理对 Kafka 里面的数据做分流操作。例如，将数据存储到数据仓库、将计算的结果存储到KV做实时分析等。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通常消息系统常见的有两种，它们分别是：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这两种方式都是有效和实用的，通过消息队列将工作内容分开，用于容错和扩展；生产和消费能够允许多租户，来使得系统解耦。而 Apache Kafka 的优点之一在于它将消息队列、生产和消费结合到了一个强大的消息系统当中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同时，Kafka 拥有正确的消息处理特性，主要体现在以下几个方面：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;：当 Kafka 的性能（如存储、吞吐等）达到瓶颈时，可以通过水平扩展来提升性能；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;真实存储&lt;/strong&gt;：Kafka 的数据是实时落地在磁盘上的，不会因为集群重启或故障而丢失数据；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;实时处理&lt;/strong&gt;：能够集成主流的计算引擎（如Flink、Spark等），对数据进行实时处理；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;顺序写入&lt;/strong&gt;：磁盘顺序 I/O 读写，跳过磁头“寻址”时间，提高读写速度；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;内存映射&lt;/strong&gt;：操作系统分页存储利用内存提升 I/O 性能，实现文件到内存的映射，通过同步或者异步来控制 Flush；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;零拷贝&lt;/strong&gt;：将磁盘文件的数据复制到“页面缓存”一次，然后将数据从“页面缓存”直接发送到网络；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;高效存储&lt;/strong&gt;：Topic 和 Partition 拆为多个文件片段（Segment），定期清理无效文件。采用稀疏存储，间隔若干字节建立一条索引，防止索引文件过大。&lt;/p&gt;&lt;/section&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;2.3 简单的应用场景&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;这里，我们可以通过一个简单直观的应用场景，来了解 Kafka 的用途。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;场景：假如用户A正在玩一款游戏，某一天用户A喜欢上了游戏里面的一款道具，打算购买，于是在当天 14:00 时充值了 10 元，在逛游戏商店时又喜欢上了另一款道具，于是在 14:30 时又充值了 30 元，接着在 15:00 时开始下单购买，花费了 20 元，剩余金额为 20 元。那么，整个事件流，对应到库表里面的数据明细应该是如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;226&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.3911792905081496&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXH4nFeKsqKQiccyeQpkia4QPGDwKusmCtGyumzOzBsb9jRBVsbic4FmfW7w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1043&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;三、Kafka解决了什么问题&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;早期为响应项目快速上线，在服务器或者云服务器上部署一个 WebServer，为个人电脑或者移动用户提供访问体验，然后后台在对接一个数据库，为 Web 应用提供数据持久化以及数据查询，流程如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;397&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.6862275449101797&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHMenfH7gmQlsxqdBYEwPKDcNcYNBMX9cjicibAMV8mXYFkcu3p6SoCVibw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;835&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;但是，随着用户的迅速增长，用户所有的访问都直接通过 SQL 数据库使得它不堪重负，数据库的压力也越来越大，不得不加上缓存服务以降低 SQL 数据库的荷载。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同时，为了理解用户行为，又开始收集日志并保存到 Hadoop 这样的大数据集群上做离线处理，并且把日志放在全文检索系统（比如 ElasticSearch）中以便快速定位问题。由于需要给投资方看业务状况，也需要把数据汇总到数据仓库（比如 Hive）中以便提供交互式报表。此时的系统架构已经具有一定的复杂性了，将来可能还会加入实时模块以及外部数据交互。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;本质上，这是一个数据集成问题。没有任何一个系统能够解决所有的事情，所以业务数据根据不同用途，存放在不同的系统，比如归档、分析、搜索、缓存等。数据冗余本身没有任何问题，但是不同系统之间太过复杂的数据同步却是一种挑战。如下图所示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.7608142493638677&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHnIKbtOuMHcHSGMOQKpqDKGagQqPgXU7rlayMuTjT8zgO2NYBjyqAfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;786&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;而 Kafka 可以让合适的数据以合适的形式出现在合适的地方。Kafka 的做法是提供消息队列，让生产者向队列的末尾添加数据，让多个消费者从队列里面依次读取数据然后自行处理。如果说之前连接的复杂度是 O(N^2)，那么现在复杂度降低到了 O(N)，扩展起来也方便多了，流程如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.665083135391924&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHpLYwqQgw7XcJaCT2NRIpZp44aibJic25p7tsTQM3jgWzE3NCcpNxHH8A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;842&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;四、Kafka的实践应用&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.1 为什么需要建设实时数仓&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;4.1.1 目的&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通常情况下，在大数据场景中，存储海量数据建设数据仓库一般都是离线数仓（时延T+1），通过定时任务每天拉取增量数据，然后创建各个业务不同维度的数据，对外提供 T+1 的数据服务。计算和数据的实时性均比较差，业务人员无法根据自己的即时性需求获取几分钟之前的实时数据。数据本身的价值随着时间的流逝会逐步减弱，因此数据产生后必须尽快的到达用户的手中，实时数仓的建设需求由此而来。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;4.1.2 目标&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了适应业务高速迭代的特点，分析用户行为，挖掘用户价值，提高用户留存，在实时数据可用性、可扩展性、易用性、以及准确性等方面提供更好的支持，因此需要建设实时数仓。主要目标包含如下所示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.2 如何构建实时数仓为搜索提供数据&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;当前实时数仓比较主流的架构一般来说包含三个大的模块，它们分别是消息队列、计算引擎、以及存储。结合上述对 Kafka 的综合分析，结合搜索的业务场景，引入 Kafka 作为消息队列，复用大数据平台（BDSP）的能力作为计算引擎和存储，具体架构如下图所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.6093591047812817&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHO9AIzIshksuN2x0BgtLibhZGbxn1PM4ut8GFJotl2BbeK8hGcGjwgSg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;983&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.3 流处理引擎选择&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;目前业界比较通用的流处理引擎主要有两种，它们分别是Flink和Spark，那么如何选择流处理引擎呢？我们可以对比以下特征来决定选择哪一种流处理引擎？&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;254&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.43867243867243866&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHcK5QeNJ0xfHiagfMTCPCfYwzXZIpgDvFntRY1dOicfTpeaicAlOEjCl9Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;693&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Flink作为一款开源的大数据流式计算引擎，它同时支持流批一体，引入Flink作为实时数仓建设的流引擎的主要原因如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;高吞吐、低延时；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;灵活的流窗口；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;轻量级容错机制；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;流批一体&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.4 建设实时数仓遇到的问题&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;在建设初期，用于实时处理的 Kafka 集群规模较小，单个 Topic 的数据容量非常大，不同的实时任务都会消费同一个大数据量的 Topic，这样会导致 Kafka 集群的 I/O 压力非常的大。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此，在使用的过程中会发现 Kafka 的压力非常大，经常出现延时、I/O能性能告警。因此，我们采取了将大数据量的单 Topic 进行实时分发来解决这种问题，基于 Flink 设计了如下图所示的数据分发流程。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHIiaMdoXuGZDJicfvKernZ29sXNxggwCOX3cia7ukKUamUVcUnAJMWu2og/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;上述流程，随着业务类型和数据量的增加，又会面临新的问题：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.5 实时数仓方案进阶&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;目前，主流的实时数仓架构通常有2种，它们分别是Lambda、Kappa。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4.5.1 Lambda&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着实时性需求的提出，为了快速计算一些实时指标（比如，实时点击、曝光等），会在离线数仓大数据架构的基础上增加一个实时计算的链路，并对消息队列实现数据来源的流失处理，通过消费消息队列中的数据 ，用流计算引擎来实现指标的增量计算，并推送到下游的数据服务中去，由下游数据服务层完成离线和实时结果的汇总。具体流程如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHx8YkTBU4u1OJF482vyfXbnob0c5rQ79cY6MDSq3P9GUVo80Hjtl2Pg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;4.5.2 Kappa&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Kappa架构只关心流式计算，数据以流的方式写入到 Kafka ，然后通过 Flink 这类实时计算引擎将计算结果存放到数据服务层以供查询。可以看作是在Lambda架构的基础上简化了离线数仓的部分。具体流程如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;325&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXH2f7SsJ4bCU8FULRMLkibn56SCHB4ue2ka4H5Br3GxIAO3HWKibgvBNNw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;在实际建设实时数仓的过程中，我们结合这2种架构的思想来使用。实时数仓引入了类似于离线数仓的分层理念，主要是为了提供模型的复用率，同时也要考虑易用性、一致性、以及计算的成本。&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;4.5.3 实时数仓分层&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;在进阶建设实时数仓时，分层架构的设计并不会像离线数仓那边复杂，这是为了避免数据计算链路过长造成不必要的延时情况。具体流程图如下所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHtZDYvXiam5DkkyF8Ka5AYV5ILw3iaibDrOl3R78yxsRZMsPRLa0K3MopQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;ODS层&lt;/strong&gt;：以Kafka 作为消息队列，将所有需要实时计算处理的数据放到对应的 Topic 进行处理；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;DW层&lt;/strong&gt;：通过Flink实时消费Topic中的数据，然后通过数据清理、多维度关联（JOIN）等，将一些相同维度的业务系统、维表中的特征属性进行关联，提供数据易用性和复用性能力，最终得到实时明细数据；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;DIM层&lt;/strong&gt;：用来存储关联的查询的维度信息，存储介质可以按需选择，比如HBase、Redis、MySQL等；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;DA层&lt;/strong&gt;：针对实时数据场景需求，进行高度聚合汇总，服务于KV、BI等场景。OLAP分析可以使用ClickHouse，KV可以选择HBase（若数据量较小，可以采用Redis）。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;通过上面的流程，建设实时数仓分层时，确保了对实时计算要求比较高的任务不会影响到BI报表、或者KV查询。但是，会有新的问题需要解决：&lt;/p&gt;&lt;blockquote class=&quot;js_blockquote_wrap&quot; data-type=&quot;2&quot; data-url=&quot;&quot; data-author-name=&quot;&quot; data-content-utf8-length=&quot;27&quot; data-source-title=&quot;&quot;&gt;&lt;section class=&quot;js_blockquote_digest&quot;&gt;&lt;section&gt;&lt;p&gt;Kafka 实时数据如何点查？&lt;/p&gt;&lt;p&gt;消费任务异常时如何分析？&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;4.5.4 Kafka监控&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;针对这些问题，我们调研和引入了Kafka 监控系统——Kafka Eagle（目前改名为EFAK）。复用该监控系统中比较重要的维度监控功能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Kafka Eagle处理能够满足上诉两个维度的监控需求之外，还提供了一些日常比较实用的功能，比如Topic记录查看、Topic容量查看、消费和生产任务的速率、消费积压等。我们采用了 Kafka-Eagle 来作为对实时数仓的任务监控。Kafka-Eagle 系统设计架构如下图所示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;371&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.6418242491657397&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHRvfaYYemEfaSVLc950FHtpdyCicoY3w3PyQXBcuj0XZHDPdnDt6yNbA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;899&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;Kafka-Eagle 是一款完全开源的对 Kafka 集群及应用做全面监控的系统，其核心由以下几个部分组成：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul class=&quot;list-paddingleft-2&quot;&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据采集&lt;/strong&gt;：核心数据来源 JMX 和 API 获取；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据存储&lt;/strong&gt;：支持 MySQL 和 Sqlite 存储；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据展示&lt;/strong&gt;：消费者应用、图表趋势监控（包括集群状态、消费生产速率、消费积压等）、开发的分布式 KSQL 查询引擎，通过 KSQL 消息查询；&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;数据告警&lt;/strong&gt;：支持常用的 IM 告警（微信，钉钉，WebHook等），同时邮件、短信、电话告警也一并支持。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;部分预览截图如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;1）Topic最近7天写入量分布&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;默认展示所有Topic的每天写入总量分布，可选择时间维度、Topic聚合维度，来查看写入量的分布情况，预览截图如下所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;180&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.3109375&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHe04uicakXl7dMv5fhCria3r50nFGkyHwRDbSqYkTe3pPLfASRhddJHYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;2）KSQL查询Topic消息记录&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;可以通过编写SQL语句，来查询（支持过滤条件）Topic中的消息记录，预览截图如下所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;315&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.5453125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHUib0icea9QCd0zvzGZBsO0hUv9Mo4UEGUslGOHwreNV8O3uBpPXL3CqA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;strong&gt;3）消费Topic积压详情&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;可以监控所有被消费的Topic的消费速率、消费积压等详情，预览截图如下所示：&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;img class=&quot;rich_pages wxw-img js_insertlocalimg&quot; data-backh=&quot;264&quot; data-backw=&quot;578&quot; data-ratio=&quot;0.45703125&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/4g5IMGibSxt6XCXAChXeKHX0IrwCiaJYXHeBicJxLicdUj8qeKSj9KJGN5gMGEBJSBMiaS5G1qOVN5S19e4WXCYanYg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1280&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;p&gt;五、参考资料&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://kafka.apache.org/documentation/&quot; textvalue=&quot;https://kafka.apache.org/documentation/&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;1.https://kafka.apache.org/documentation/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;2.&lt;a target=&quot;_blank&quot; href=&quot;http://www.kafka-eagle.org/&quot; textvalue=&quot;http://www.kafka-eagle.org/&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;http://www.kafka-eagle.org/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;3.&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/smartloli/EFAK&quot; textvalue=&quot;https://github.com/smartloli/kafka-eagle&quot; linktype=&quot;text&quot; imgurl=&quot;&quot; tab=&quot;outerlink&quot; data-linktype=&quot;2&quot;&gt;https://github.com/smartloli/kafka-eagle&lt;/a&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;p&gt;END&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;svg viewbox=&quot;0 0 1 1&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section powered-by=&quot;xiumi.us&quot;&gt;&lt;section&gt;&lt;span title=&quot;&quot; opera-tn-ra-cell=&quot;_$.pages:0.layers:0.comps:119.title1&quot;&gt;&lt;p&gt;猜你喜欢&lt;/p&gt;&lt;/span&gt; &lt;/section&gt;&lt;section&gt;&lt;section powered-by=&quot;xiumi.us&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
</item>
</channel></rss>